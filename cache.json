{"2025-03-03T00:00:00Z":{"Computation and Language":[{"id":"http://arxiv.org/abs/2502.12215v2","updated":"2025-03-03T15:29:43Z","published":"2025-02-17T07:21:11Z","title":"Revisiting the Test-Time Scaling of o1-like Models: Do they Truly\n  Possess Test-Time Scaling Capabilities?","summary":"  The advent of test-time scaling in large language models (LLMs), exemplified\nby OpenAI's o1 series, has advanced reasoning capabilities by scaling\ncomputational resource allocation during inference. While successors like QwQ,\nDeepseek-R1 (R1) and LIMO replicate these advancements, whether these models\ntruly possess test-time scaling capabilities remains underexplored. This study\nfound that longer CoTs of these o1-like models do not consistently enhance\naccuracy; in fact, correct solutions are often shorter than incorrect ones for\nthe same questions. Further investigation shows this phenomenon is closely\nrelated to models' self-revision capabilities - longer CoTs contain more\nself-revisions, which often lead to performance degradation. We then compare\nsequential and parallel scaling strategies on QwQ, R1 and LIMO, finding that\nparallel scaling achieves better coverage and scalability. Based on these\ninsights, we propose Shortest Majority Vote, a method that combines parallel\nscaling strategies with CoT length characteristics, significantly improving\nmodels' test-time scalability compared to conventional majority voting\napproaches.\n","authors":["Zhiyuan Zeng","Qinyuan Cheng","Zhangyue Yin","Yunhua Zhou","Xipeng Qiu"],"pdf_url":"https://arxiv.org/pdf/2502.12215v2.pdf","comment":"Add the github link"},{"id":"http://arxiv.org/abs/2502.19723v2","updated":"2025-03-03T15:07:28Z","published":"2025-02-27T03:25:34Z","title":"CNsum:Automatic Summarization for Chinese News Text","summary":"  Obtaining valuable information from massive data efficiently has become our\nresearch goal in the era of Big Data. Text summarization technology has been\ncontinuously developed to meet this demand. Recent work has also shown that\ntransformer-based pre-trained language models have achieved great success on\nvarious tasks in Natural Language Processing (NLP). Aiming at the problem of\nChinese news text summary generation and the application of Transformer\nstructure on Chinese, this paper proposes a Chinese news text summarization\nmodel (CNsum) based on Transformer structure, and tests it on Chinese datasets\nsuch as THUCNews. The results of the conducted experiments show that CNsum\nachieves better ROUGE score than the baseline models, which verifies the\noutperformance of the model.\n","authors":["Yu Zhao","Songping Huang","Dongsheng Zhou","Zhaoyun Ding","Fei Wang","Aixin Nian"],"pdf_url":"https://arxiv.org/pdf/2502.19723v2.pdf","comment":"This withdrawal is due to the lack of authorization from all\n  co-authors for the publication of this version"},{"id":"http://arxiv.org/abs/2502.18858v2","updated":"2025-03-03T13:38:50Z","published":"2025-02-26T05:59:45Z","title":"Evaluating Intelligence via Trial and Error","summary":"  Intelligence is a crucial trait for species to find solutions within a\nlimited number of trial-and-error attempts. Building on this idea, we introduce\nSurvival Game as a framework to evaluate intelligence based on the number of\nfailed attempts in a trial-and-error process. Fewer failures indicate higher\nintelligence. When the expectation and variance of failure counts are both\nfinite, it signals the ability to consistently find solutions to new\nchallenges, which we define as the Autonomous Level of intelligence. Using\nSurvival Game, we comprehensively evaluate existing AI systems. Our results\nshow that while AI systems achieve the Autonomous Level in simple tasks, they\nare still far from it in more complex tasks, such as vision, search,\nrecommendation, and language. While scaling current AI technologies might help,\nthis would come at an astronomical cost. Projections suggest that achieving the\nAutonomous Level for general tasks would require $10^{26}$ parameters. To put\nthis into perspective, loading such a massive model requires so many H100 GPUs\nthat their total value is $10^{7}$ times that of Apple Inc.'s market value.\nEven with Moore's Law, supporting such a parameter scale would take $70$ years.\nThis staggering cost highlights the complexity of human tasks and the\ninadequacies of current AI technologies. To further investigate this\nphenomenon, we conduct a theoretical analysis of Survival Game and its\nexperimental results. Our findings suggest that human tasks possess a\ncriticality property. As a result, Autonomous Level requires a deep\nunderstanding of the task's underlying mechanisms. Current AI systems, however,\ndo not fully grasp these mechanisms and instead rely on superficial mimicry,\nmaking it difficult for them to reach an autonomous level. We believe Survival\nGame can not only guide the future development of AI but also offer profound\ninsights into human intelligence.\n","authors":["Jingtao Zhan","Jiahao Zhao","Jiayu Li","Yiqun Liu","Bo Zhang","Qingyao Ai","Jiaxin Mao","Hongning Wang","Min Zhang","Shaoping Ma"],"pdf_url":"https://arxiv.org/pdf/2502.18858v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2501.07596v2","updated":"2025-03-03T13:27:01Z","published":"2025-01-10T01:42:43Z","title":"Optimize Incompatible Parameters through Compatibility-aware Knowledge\n  Integration","summary":"  Deep neural networks have become foundational to advancements in multiple\ndomains, including recommendation systems, natural language processing, and so\non. Despite their successes, these models often contain incompatible parameters\nthat can be underutilized or detrimental to model performance, particularly\nwhen faced with specific, varying data distributions. Existing research excels\nin removing such parameters or merging the outputs of multiple different\npretrained models. However, the former focuses on efficiency rather than\nperformance, while the latter requires several times more computing and storage\nresources to support inference. In this paper, we set the goal to explicitly\nimprove these incompatible parameters by leveraging the complementary strengths\nof different models, thereby directly enhancing the models without any\nadditional parameters. Specifically, we propose Compatibility-aware Knowledge\nIntegration (CKI), which consists of Parameter Compatibility Assessment and\nParameter Splicing, which are used to evaluate the knowledge content of\nmultiple models and integrate the knowledge into one model, respectively. The\nintegrated model can be used directly for inference or for further fine-tuning.\nWe conduct extensive experiments on various datasets for recommendation and\nlanguage tasks, and the results show that Compatibility-aware Knowledge\nIntegration can effectively optimize incompatible parameters under multiple\ntasks and settings to break through the training limit of the original model\nwithout increasing the inference cost.\n","authors":["Zheqi Lv","Keming Ye","Zishu Wei","Qi Tian","Shengyu Zhang","Wenqiao Zhang","Wenjie Wang","Kun Kuang","Tat-Seng Chua","Fei Wu"],"pdf_url":"https://arxiv.org/pdf/2501.07596v2.pdf","comment":"Published on AAAI'25(Oral): The Annual AAAI Conference on Artificial\n  Intelligence"},{"id":"http://arxiv.org/abs/2408.08291v2","updated":"2025-03-03T13:18:21Z","published":"2024-08-15T17:46:54Z","title":"The ShareLM Collection and Plugin: Contributing Human-Model Chats for\n  the Benefit of the Community","summary":"  Human-model conversations provide a window into users' real-world scenarios,\nbehavior, and needs, and thus are a valuable resource for model development and\nresearch. While for-profit companies collect user data through the APIs of\ntheir models, using it internally to improve their own models, the open source\nand research community lags behind.\n  We introduce the ShareLM collection, a unified set of human conversations\nwith large language models, and its accompanying plugin, a Web extension for\nvoluntarily contributing user-model conversations. Where few platforms share\ntheir chats, the ShareLM plugin adds this functionality, thus, allowing users\nto share conversations from most platforms. The plugin allows the user to rate\ntheir conversations, both at the conversation and the response levels, and\ndelete conversations they prefer to keep private before they ever leave the\nuser's local storage. We release the plugin conversations as part of the\nShareLM collection, and call for more community effort in the field of open\nhuman-model data.\n  The code, plugin, and data are available.\n","authors":["Shachar Don-Yehiya","Leshem Choshen","Omri Abend"],"pdf_url":"https://arxiv.org/pdf/2408.08291v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.07076v4","updated":"2025-03-03T13:17:24Z","published":"2024-10-09T17:19:58Z","title":"MOOSE-Chem: Large Language Models for Rediscovering Unseen Chemistry\n  Scientific Hypotheses","summary":"  Scientific discovery contributes largely to human society's prosperity, and\nrecent progress shows that LLMs could potentially catalyze this process.\nHowever, it is still unclear whether LLMs can discover novel and valid\nhypotheses in chemistry. In this work, we investigate this central research\nquestion: Can LLMs automatically discover novel and valid chemistry research\nhypotheses given only a chemistry research background (consisting of a research\nquestion and/or a background survey), without limitation on the domain of the\nresearch question? After extensive discussions with chemistry experts, we\npropose an assumption that a majority of chemistry hypotheses can be resulted\nfrom a research background and several inspirations. With this key insight, we\nbreak the central question into three smaller fundamental questions. In brief,\nthey are: (1) given a background question, whether LLMs can retrieve good\ninspirations; (2) with background and inspirations, whether LLMs can lead to\nhypothesis; and (3) whether LLMs can identify good hypotheses to rank them\nhigher. To investigate these questions, we construct a benchmark consisting of\n51 chemistry papers published in Nature, Science, or a similar level in 2024\n(all papers are only available online since 2024). Every paper is divided by\nchemistry PhD students into three components: background, inspirations, and\nhypothesis. The goal is to rediscover the hypothesis, given only the background\nand a large randomly selected chemistry literature corpus consisting the ground\ntruth inspiration papers, with LLMs trained with data up to 2023. We also\ndevelop an LLM-based multi-agent framework that leverages the assumption,\nconsisting of three stages reflecting the three smaller questions. The proposed\nmethod can rediscover many hypotheses with very high similarity with the ground\ntruth ones, covering the main innovations.\n","authors":["Zonglin Yang","Wanhao Liu","Ben Gao","Tong Xie","Yuqiang Li","Wanli Ouyang","Soujanya Poria","Erik Cambria","Dongzhan Zhou"],"pdf_url":"https://arxiv.org/pdf/2410.07076v4.pdf","comment":"Accepted by ICLR 2025"},{"id":"http://arxiv.org/abs/2502.11142v2","updated":"2025-03-03T12:56:35Z","published":"2025-02-16T14:17:36Z","title":"NavRAG: Generating User Demand Instructions for Embodied Navigation\n  through Retrieval-Augmented LLM","summary":"  Vision-and-Language Navigation (VLN) is an essential skill for embodied\nagents, allowing them to navigate in 3D environments following natural language\ninstructions. High-performance navigation models require a large amount of\ntraining data, the high cost of manually annotating data has seriously hindered\nthis field. Therefore, some previous methods translate trajectory videos into\nstep-by-step instructions for expanding data, but such instructions do not\nmatch well with users' communication styles that briefly describe destinations\nor state specific needs. Moreover, local navigation trajectories overlook\nglobal context and high-level task planning. To address these issues, we\npropose NavRAG, a retrieval-augmented generation (RAG) framework that generates\nuser demand instructions for VLN. NavRAG leverages LLM to build a hierarchical\nscene description tree for 3D scene understanding from global layout to local\ndetails, then simulates various user roles with specific demands to retrieve\nfrom the scene tree, generating diverse instructions with LLM. We annotate over\n2 million navigation instructions across 861 scenes and evaluate the data\nquality and navigation performance of trained models.\n","authors":["Zihan Wang","Yaohui Zhu","Gim Hee Lee","Yachun Fan"],"pdf_url":"https://arxiv.org/pdf/2502.11142v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2502.19732v2","updated":"2025-03-03T12:21:14Z","published":"2025-02-27T03:53:45Z","title":"Speculative Decoding and Beyond: An In-Depth Survey of Techniques","summary":"  Sequential dependencies present a fundamental bottleneck in deploying\nlarge-scale autoregressive models, particularly for real-time applications.\nWhile traditional optimization approaches like pruning and quantization often\ncompromise model quality, recent advances in generation-refinement frameworks\ndemonstrate that this trade-off can be significantly mitigated.\n  This survey presents a comprehensive taxonomy of generation-refinement\nframeworks, analyzing methods across autoregressive sequence tasks. We\ncategorize methods based on their generation strategies (from simple n-gram\nprediction to sophisticated draft models) and refinement mechanisms (including\nsingle-pass verification and iterative approaches). Through systematic analysis\nof both algorithmic innovations and system-level implementations, we examine\ndeployment strategies across computing environments and explore applications\nspanning text, images, and speech generation. This systematic examination of\nboth theoretical frameworks and practical implementations provides a foundation\nfor future research in efficient autoregressive decoding.\n","authors":["Yunhai Hu","Zining Liu","Zhenyuan Dong","Tianfan Peng","Bradley McDanel","Sai Qian Zhang"],"pdf_url":"https://arxiv.org/pdf/2502.19732v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2407.06057v2","updated":"2025-03-03T11:08:15Z","published":"2024-07-08T15:59:44Z","title":"Variational Best-of-N Alignment","summary":"  Best-of-N (BoN) is a popular and effective algorithm for aligning language\nmodels to human preferences. The algorithm works as follows: at inference time,\nN samples are drawn from the language model, and the sample with the highest\nreward, as judged by a reward model, is returned as the output. Despite its\neffectiveness, BoN is computationally expensive; it reduces sampling throughput\nby a factor of N. To make BoN more efficient at inference time, one strategy is\nto fine-tune the language model to mimic what BoN does during inference. To\nachieve this, we derive the distribution induced by the BoN algorithm. We then\npropose to fine-tune the language model to minimize backward KL divergence to\nthe BoN distribution. Our approach is analogous to mean-field variational\ninference and, thus, we term it variational BoN (vBoN). To the extent this\nfine-tuning is successful and we end up with a good approximation, we have\nreduced the inference cost by a factor of N. Our experiments on controlled\ngeneration and summarization tasks show that BoN is the most effective\nalignment method, and our variational approximation to BoN achieves the closest\nperformance to BoN and surpasses models fine-tuned using the standard\nKL-constrained RL objective. In the controlled generation task, vBoN appears\nmore frequently on the Pareto frontier of reward and KL divergence compared to\nother alignment methods. In the summarization task, vBoN achieves high reward\nvalues across various sampling temperatures.\n","authors":["Afra Amini","Tim Vieira","Elliott Ash","Ryan Cotterell"],"pdf_url":"https://arxiv.org/pdf/2407.06057v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.12460v2","updated":"2025-03-03T10:35:27Z","published":"2024-11-19T12:36:02Z","title":"Exploring Iterative Controllable Summarization with Large Language\n  Models","summary":"  Large language models (LLMs) have demonstrated remarkable performance in\nabstractive summarization tasks. However, their ability to precisely control\nsummary attributes (e.g., length or topic) remains underexplored, limiting\ntheir adaptability to specific user preferences. In this paper, we\nsystematically explore the controllability of LLMs. To this end, we revisit\nsummary attribute measurements and introduce iterative evaluation metrics,\nfailure rate and average iteration count to precisely evaluate controllability\nof LLMs, rather than merely assessing errors. Our findings show that LLMs\nstruggle more with numerical attributes than with linguistic attributes. To\naddress this challenge, we propose a guide-to-explain framework (GTE) for\ncontrollable summarization. Our GTE framework enables the model to identify\nmisaligned attributes in the initial draft and guides it in self-explaining\nerrors in the previous output. By allowing the model to reflect on its\nmisalignment, GTE generates well-adjusted summaries that satisfy the desired\nattributes with robust effectiveness, requiring surprisingly fewer iterations\nthan other iterative approaches.\n","authors":["Sangwon Ryu","Heejin Do","Daehee Kim","Hwanjo Yu","Dongwoo Kim","Yunsu Kim","Gary Geunbae Lee","Jungseul Ok"],"pdf_url":"https://arxiv.org/pdf/2411.12460v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2502.11355v2","updated":"2025-03-03T09:45:24Z","published":"2025-02-17T02:11:17Z","title":"\"Nuclear Deployed!\": Analyzing Catastrophic Risks in Decision-making of\n  Autonomous LLM Agents","summary":"  Large language models (LLMs) are evolving into autonomous decision-makers,\nraising concerns about catastrophic risks in high-stakes scenarios,\nparticularly in Chemical, Biological, Radiological and Nuclear (CBRN) domains.\nBased on the insight that such risks can originate from trade-offs between the\nagent's Helpful, Harmlessness and Honest (HHH) goals, we build a novel\nthree-stage evaluation framework, which is carefully constructed to effectively\nand naturally expose such risks. We conduct 14,400 agentic simulations across\n12 advanced LLMs, with extensive experiments and analysis. Results reveal that\nLLM agents can autonomously engage in catastrophic behaviors and deception,\nwithout being deliberately induced. Furthermore, stronger reasoning abilities\noften increase, rather than mitigate, these risks. We also show that these\nagents can violate instructions and superior commands. On the whole, we\nempirically prove the existence of catastrophic risks in autonomous LLM agents.\nWe will release our code upon request.\n","authors":["Rongwu Xu","Xiaojian Li","Shuo Chen","Wei Xu"],"pdf_url":"https://arxiv.org/pdf/2502.11355v2.pdf","comment":"Please visit https://llm-catastrophic-risks.github.io for a quick\n  tour of our project"},{"id":"http://arxiv.org/abs/2403.07260v2","updated":"2025-03-03T09:36:14Z","published":"2024-03-12T02:37:11Z","title":"LaERC-S: Improving LLM-based Emotion Recognition in Conversation with\n  Speaker Characteristics","summary":"  Emotion recognition in conversation (ERC), the task of discerning human\nemotions for each utterance within a conversation, has garnered significant\nattention in human-computer interaction systems. Previous ERC studies focus on\nspeaker-specific information that predominantly stems from relationships among\nutterances, which lacks sufficient information around conversations. Recent\nresearch in ERC has sought to exploit pre-trained large language models (LLMs)\nwith speaker modelling to comprehend emotional states. Although these methods\nhave achieved encouraging results, the extracted speaker-specific information\nstruggles to indicate emotional dynamics. In this paper, motivated by the fact\nthat speaker characteristics play a crucial role and LLMs have rich world\nknowledge, we present LaERC-S, a novel framework that stimulates LLMs to\nexplore speaker characteristics involving the mental state and behavior of\ninterlocutors, for accurate emotion predictions. To endow LLMs with this\nknowledge information, we adopt the two-stage learning to make the models\nreason speaker characteristics and track the emotion of the speaker in complex\nconversation scenarios. Extensive experiments on three benchmark datasets\ndemonstrate the superiority of LaERC-S, reaching the new state-of-the-art.\n","authors":["Yumeng Fu","Junjie Wu","Zhongjie Wang","Meishan Zhang","Lili Shan","Yulin Wu","Bingquan Li"],"pdf_url":"https://arxiv.org/pdf/2403.07260v2.pdf","comment":"COLING 2025"},{"id":"http://arxiv.org/abs/2402.09911v2","updated":"2025-03-03T09:21:11Z","published":"2024-02-15T12:20:02Z","title":"Enhancing Large Language Models with Pseudo- and Multisource- Knowledge\n  Graphs for Open-ended Question Answering","summary":"  Mitigating the hallucinations of Large Language Models is a crucial task.\nAlthough some existing methods employ self-enhancement techniques, they fall\nshort of effectively addressing unknown factual hallucinations. Meanwhile,\nKnowledge Graph (KG) enhancement approaches fail to address the generalization\nacross different KG sources and the enhancement of open-ended answer questions\nsimultaneously. To tackle these limitations, we propose a framework that\ncombines Pseudo-Graph Generation and Atomic Knowledge Verification (PG\\&AKV).\nEnhancement of open-ended question-answering begins with leveraging the\nPseudo-Graph Generation to provide the related knowledge framework.\nSubsequently, Atomic Knowledge Verification utilizes atomic-level knowledge\nquerying and verification to achieve generalizability under different KG\nsources. Compared to the baseline, this approach yields a minimum improvement\nof 11.5 in the ROUGE-L score for open-ended questions. For precise-answered\nquestions, we observe a minimum accuracy improvement of 7.5%. Moreover, PG\\&AKV\nalso exhibits generalizability across different KG sources. Utilizing KG\ndifferent from the question sources, PG\\&AKV can even achieve at least a 3.5 %\nperformance improvement. In summary, our results pave the way for enhancing\nLLMs by incorporating Pseudo- and Multisource-KGs, particularly in the filed of\nopen-ended questions.\n","authors":["Jiaxiang Liu","Tong Zhou","Yubo Chen","Kang Liu","Jun Zhao"],"pdf_url":"https://arxiv.org/pdf/2402.09911v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2502.21228v2","updated":"2025-03-03T09:11:46Z","published":"2025-02-28T16:59:30Z","title":"ECLeKTic: a Novel Challenge Set for Evaluation of Cross-Lingual\n  Knowledge Transfer","summary":"  To achieve equitable performance across languages, multilingual large\nlanguage models (LLMs) must be able to abstract knowledge beyond the language\nin which it was acquired. However, the current literature lacks reliable ways\nto measure LLMs' capability of cross-lingual knowledge transfer. To that end,\nwe present ECLeKTic, a multilingual closed-book QA (CBQA) dataset that\nEvaluates Cross-Lingual Knowledge Transfer in a simple, black-box manner. We\ndetected information with uneven coverage across languages by controlling for\npresence and absence of Wikipedia articles in 12 languages. We generated\nknowledge-seeking questions in a source language, for which the answer appears\nin a relevant Wikipedia article and translated them to all other 11 languages,\nfor which the respective Wikipedias lack equivalent articles. Assuming that\nWikipedia reflects the prominent knowledge in the LLM's training data, to solve\nECLeKTic's CBQA task the model is required to transfer knowledge between\nlanguages. Experimenting with 8 LLMs, we show that SOTA models struggle to\neffectively share knowledge across, languages even if they can predict the\nanswer well for queries in the same language the knowledge was acquired in.\n","authors":["Omer Goldman","Uri Shaham","Dan Malkin","Sivan Eiger","Avinatan Hassidim","Yossi Matias","Joshua Maynez","Adi Mayrav Gilady","Jason Riesa","Shruti Rijhwani","Laura Rimell","Idan Szpektor","Reut Tsarfaty","Matan Eyal"],"pdf_url":"https://arxiv.org/pdf/2502.21228v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2502.11167v2","updated":"2025-03-03T08:26:12Z","published":"2025-02-16T15:38:19Z","title":"SURGE: On the Potential of Large Language Models as General-Purpose\n  Surrogate Code Executors","summary":"  Neural surrogate models have emerged as powerful and efficient tools in data\nmining. Meanwhile, large language models (LLMs) have demonstrated remarkable\ncapabilities in code-related tasks. We investigate a novel application: using\nLLMs as surrogate models for code execution prediction. Given LLMs' unique\nability to understand and process diverse programs, they present a promising\ndirection for building general-purpose surrogate models. To systematically\ninvestigate this capability, we introduce SURGE, a comprehensive benchmark with\n$1160$ problems covering $8$ key aspects: multi-language programming tasks,\ncompetition-level programming problems, repository-level code analysis,\nhigh-cost scientific computing, time-complexity-intensive algorithms, buggy\ncode analysis, programs dependent on specific compilers or execution\nenvironments, and formal mathematical proof verification. Through extensive\nempirical analysis of $21$ open-source and proprietary LLMs, we examine scaling\nlaws, data efficiency, and predictive accuracy. Our findings reveal important\ninsights about the feasibility of LLMs as efficient surrogates for\ncomputational processes, with implications for automated software testing,\nprogram analysis, and computational resource optimization in data mining\napplications. Code and dataset are released at\nhttps://github.com/Imbernoulli/SURGE.\n","authors":["Bohan Lyu","Siqiao Huang","Zichen Liang"],"pdf_url":"https://arxiv.org/pdf/2502.11167v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2405.19316v2","updated":"2025-03-03T08:22:25Z","published":"2024-05-29T17:39:48Z","title":"Robust Preference Optimization through Reward Model Distillation","summary":"  Language model (LM) post-training (or alignment) involves maximizing a reward\nfunction that is derived from preference annotations. Direct Preference\nOptimization (DPO) is a popular offline alignment method that trains a policy\ndirectly on preference data without the need to train a reward model or apply\nreinforcement learning. However, the empirical evidence suggests that DPO\ntypically assigns implicit rewards that overfit, and trend towards infinite\nmagnitude. This frequently leads to degenerate policies, sometimes causing even\nthe probabilities of the preferred generations to go to zero. In this work, we\nanalyze this phenomenon and use distillation to get a better proxy for the true\npreference distribution over generation pairs: we train the LM such that its\ninduced implicit reward, i.e., the scaled log-likelihood ratio of the model to\nthe reference model, matches an explicit reward model trained on the preference\ndata. Moreover, to account for uncertainty in the reward model we are\ndistilling from, we optimize against a family of reward models that, as a\nwhole, is likely to include at least one reasonable proxy for the preference\ndistribution. Our results show that distilling from such a family of reward\nmodels leads to improved robustness to distribution shift in preference\nannotations, while preserving the simple supervised nature of DPO.\n","authors":["Adam Fisch","Jacob Eisenstein","Vicky Zayats","Alekh Agarwal","Ahmad Beirami","Chirag Nagpal","Pete Shaw","Jonathan Berant"],"pdf_url":"https://arxiv.org/pdf/2405.19316v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2310.19651v3","updated":"2025-03-03T07:49:17Z","published":"2023-10-30T15:37:10Z","title":"Dynamics of Instruction Fine-Tuning for Chinese Large Language Models","summary":"  Instruction tuning is a burgeoning method to elicit the general intelligence\nof Large Language Models (LLMs). While numerous studies have examined the\nimpact of factors such as data volume and model size on English models, the\nscaling properties of instruction tuning in other languages remain largely\nunexplored. In this work, we systematically investigate the effects of data\nquantity, model size, and data construction methods on instruction tuning for\nChinese LLMs. We utilize a newly curated dataset, DoIT, which includes over\n40,000 high-quality instruction instances covering ten underlying abilities,\nsuch as creative writing, code generation, and logical reasoning. Our\nexperiments, conducted on models ranging from 7b to 33b parameters, yield three\nkey findings: (i) While these factors directly affect overall model\nperformance, some abilities are more responsive to scaling, whereas others\ndemonstrate significant resistance. (ii) The scaling sensitivity of different\nabilities to these factors can be explained by two features: Complexity and\nTransference. (iii) By tailoring training strategies to their varying\nsensitivities, specific abilities can be efficiently learned, enhancing\nperformance on two public benchmarks.\n","authors":["Chiyu Song","Zhanchao Zhou","Jianhao Yan","Yuejiao Fei","Zhenzhong Lan","Yue Zhang"],"pdf_url":"https://arxiv.org/pdf/2310.19651v3.pdf","comment":"Accepted to COLING 2025"},{"id":"http://arxiv.org/abs/2406.14434v3","updated":"2025-03-03T07:36:49Z","published":"2024-06-20T15:59:07Z","title":"Selected Languages are All You Need for Cross-lingual Truthfulness\n  Transfer","summary":"  Truthfulness stands out as an essential challenge for Large Language Models\n(LLMs). Although many works have developed various ways for truthfulness\nenhancement, they seldom focus on truthfulness in multilingual scenarios.\nMeanwhile, contemporary multilingual aligning technologies struggle to balance\nnumerous languages and often exhibit serious truthfulness gaps across different\nlanguages, especially those that differ greatly from English. In our work, we\nextend truthfulness evaluation to multilingual contexts and propose a practical\nmethod for cross-lingual truthfulness transfer called Fact-aware Multilingual\nSelective Synergy (FaMSS). FaMSS is able to select an optimal subset of all\ntested languages by language bias and transfer contributions, and then employ\ntranslation instruction tuning for cross-lingual truthfulness transfer.\nExperimental results demonstrate that our approach can effectively reduce the\nmultilingual representation disparity and boost cross-lingual truthfulness\ntransfer of LLMs.\n","authors":["Weihao Liu","Ning Wu","Wenbiao Ding","Shining Liang","Ming Gong","Dongmei Zhang"],"pdf_url":"https://arxiv.org/pdf/2406.14434v3.pdf","comment":"16 pages, COLING2025"},{"id":"http://arxiv.org/abs/2409.16644v2","updated":"2025-03-03T07:22:54Z","published":"2024-09-25T05:44:44Z","title":"Enabling Auditory Large Language Models for Automatic Speech Quality\n  Evaluation","summary":"  Speech quality assessment typically requires evaluating audio from multiple\naspects, such as mean opinion score (MOS) and speaker similarity (SIM) \\etc.,\nwhich can be challenging to cover using one small model designed for a single\ntask. In this paper, we propose leveraging recently introduced auditory large\nlanguage models (LLMs) for automatic speech quality assessment. By employing\ntask-specific prompts, auditory LLMs are finetuned to predict MOS, SIM and A/B\ntesting results, which are commonly used for evaluating text-to-speech systems.\nAdditionally, the finetuned auditory LLM is able to generate natural language\ndescriptions assessing aspects like noisiness, distortion, discontinuity, and\noverall quality, providing more interpretable outputs. Extensive experiments\nhave been performed on the NISQA, BVCC, SOMOS and VoxSim speech quality\ndatasets, using open-source auditory LLMs such as SALMONN, Qwen-Audio, and\nQwen2-Audio. For the natural language descriptions task, a commercial model\nGoogle Gemini 1.5 Pro is also evaluated. The results demonstrate that auditory\nLLMs achieve competitive performance compared to state-of-the-art task-specific\nsmall models in predicting MOS and SIM, while also delivering promising results\nin A/B testing and natural language descriptions. Our data processing scripts\nand finetuned model checkpoints can be found at\nhttps://github.com/bytedance/SALMONN.\n","authors":["Siyin Wang","Wenyi Yu","Yudong Yang","Changli Tang","Yixuan Li","Jimin Zhuang","Xianzhao Chen","Xiaohai Tian","Jun Zhang","Guangzhi Sun","Lu Lu","Chao Zhang"],"pdf_url":"https://arxiv.org/pdf/2409.16644v2.pdf","comment":"Accepted by ICASSP 2025"},{"id":"http://arxiv.org/abs/2410.02683v2","updated":"2025-03-03T07:20:54Z","published":"2024-10-03T17:08:52Z","title":"DailyDilemmas: Revealing Value Preferences of LLMs with Quandaries of\n  Daily Life","summary":"  As users increasingly seek guidance from LLMs for decision-making in daily\nlife, many of these decisions are not clear-cut and depend significantly on the\npersonal values and ethical standards of people. We present DailyDilemmas, a\ndataset of 1,360 moral dilemmas encountered in everyday life. Each dilemma\npresents two possible actions, along with affected parties and relevant human\nvalues for each action. Based on these dilemmas, we gather a repository of\nhuman values covering diverse everyday topics, such as interpersonal\nrelationships, workplace, and environmental issues. With DailyDilemmas, we\nevaluate LLMs on these dilemmas to determine what action they will choose and\nthe values represented by these action choices. Then, we analyze values through\nthe lens of five theoretical frameworks inspired by sociology, psychology, and\nphilosophy, including the World Values Survey, Moral Foundations Theory,\nMaslow's Hierarchy of Needs, Aristotle's Virtues, and Plutchik's Wheel of\nEmotions. For instance, we find LLMs are most aligned with self-expression over\nsurvival in World Values Survey and care over loyalty in Moral Foundations\nTheory. Interestingly, we find substantial preference differences in models for\nsome core values. For example, for truthfulness, Mixtral-8x7B neglects it by\n9.7% while GPT-4-turbo selects it by 9.4%. We also study the recent guidance\nreleased by OpenAI (ModelSpec), and Anthropic (Constitutional AI) to understand\nhow their designated principles reflect their models' actual value\nprioritization when facing nuanced moral reasoning in daily-life settings.\nFinally, we find that end users cannot effectively steer such prioritization\nusing system prompts.\n","authors":["Yu Ying Chiu","Liwei Jiang","Yejin Choi"],"pdf_url":"https://arxiv.org/pdf/2410.02683v2.pdf","comment":"Accepted into ICLR 2025 (spotlight)"},{"id":"http://arxiv.org/abs/2501.02497v2","updated":"2025-03-03T07:16:16Z","published":"2025-01-05T10:24:20Z","title":"Test-Time Compute: from System-1 Thinking to System-2 Thinking","summary":"  The remarkable performance of the o1 model in complex reasoning demonstrates\nthat test-time compute scaling can further unlock the model's potential,\nenabling powerful System-2 thinking. However, there is still a lack of\ncomprehensive surveys for test-time compute scaling. We trace the concept of\ntest-time compute back to System-1 models. In System-1 models, test-time\ncompute addresses distribution shifts and improves robustness and\ngeneralization through parameter updating, input modification, representation\nediting, and output calibration. In System-2 models, it enhances the model's\nreasoning ability to solve complex problems through repeated sampling,\nself-correction, and tree search. We organize this survey according to the\ntrend of System-1 to System-2 thinking, highlighting the key role of test-time\ncompute in the transition from System-1 models to weak System-2 models, and\nthen to strong System-2 models. We also point out a few possible future\ndirections.\n","authors":["Yixin Ji","Juntao Li","Hai Ye","Kaixin Wu","Kai Yao","Jia Xu","Linjian Mo","Min Zhang"],"pdf_url":"https://arxiv.org/pdf/2501.02497v2.pdf","comment":"work in progress"},{"id":"http://arxiv.org/abs/2502.18874v2","updated":"2025-03-03T07:13:12Z","published":"2025-02-26T06:31:45Z","title":"Learning to Align Multi-Faceted Evaluation: A Unified and Robust\n  Framework","summary":"  Large Language Models (LLMs) are being used more and more extensively for\nautomated evaluation in various scenarios. Previous studies have attempted to\nfine-tune open-source LLMs to replicate the evaluation explanations and\njudgments of powerful proprietary models, such as GPT-4. However, these methods\nare largely limited to text-based analyses under predefined general criteria,\nresulting in reduced adaptability for unseen instructions and demonstrating\ninstability in evaluating adherence to quantitative and structural constraints.\nTo address these limitations, we propose a novel evaluation framework, ARJudge,\nthat adaptively formulates evaluation criteria and synthesizes both text-based\nand code-driven analyses to evaluate LLM responses. ARJudge consists of two\ncomponents: a fine-tuned Analyzer that generates multi-faceted evaluation\nanalyses and a tuning-free Refiner that combines and refines all analyses to\nmake the final judgment. We construct a Composite Analysis Corpus that\nintegrates tasks for evaluation criteria generation alongside text-based and\ncode-driven analysis generation to train the Analyzer. Our results demonstrate\nthat ARJudge outperforms existing fine-tuned evaluators in effectiveness and\nrobustness. Furthermore, it demonstrates the importance of multi-faceted\nevaluation and code-driven analyses in enhancing evaluation capabilities.\n","authors":["Kaishuai Xu","Tiezheng Yu","Wenjun Hou","Yi Cheng","Liangyou Li","Xin Jiang","Lifeng Shang","Qun Liu","Wenjie Li"],"pdf_url":"https://arxiv.org/pdf/2502.18874v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.06638v3","updated":"2025-03-03T07:09:42Z","published":"2024-10-09T07:43:38Z","title":"Subtle Errors Matter: Preference Learning via Error-injected\n  Self-editing","summary":"  Large Language Models (LLMs) have exhibited strong mathematical reasoning\nprowess, tackling tasks ranging from basic arithmetic to advanced\ncompetition-level problems. However, frequently occurring subtle yet critical\nerrors, such as miscalculations or incorrect substitutions, limit the LLMs'\nfull potential. Existing studies to improve mathematical ability typically\ninvolve applying preference learning to step-wise solution pairs. Although\nthese methods leverage samples of varying granularity to mitigate reasoning\nerrors, they overlook critical subtle errors. In this work, we propose a novel\npreference learning framework called eRror-Injected Self-Editing (RISE), which\ninjects predefined subtle errors into pivotal tokens in reasoning or\ncomputation steps to construct hard pairs for error mitigation. In detail, RISE\nuses the LLM itself to edit a small number of tokens in the solution, injecting\ndesigned subtle errors. Then, pairs composed of self-edited solutions and their\ncorresponding correct ones, along with pairs of correct and incorrect solutions\nobtained through sampling, are used together for subtle error-aware DPO\ntraining. Compared with other preference learning methods, RISE further refines\nthe training objective without requiring fine-grained sampling or preference\nannotation. Extensive experiments validate the effectiveness of RISE, with\npreference learning on Qwen2-7B-Instruct yielding notable improvements of 3.0%\non GSM8K and 7.9% on MATH with only 4.5K training samples. Moreover, the effect\nof error mitigation extends from mathematical reasoning to logical reasoning\nand code generation.\n","authors":["Kaishuai Xu","Tiezheng Yu","Wenjun Hou","Yi Cheng","Chak Tou Leong","Liangyou Li","Xin Jiang","Lifeng Shang","Qun Liu","Wenjie Li"],"pdf_url":"https://arxiv.org/pdf/2410.06638v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2409.07170v3","updated":"2025-03-03T07:02:20Z","published":"2024-09-11T10:33:30Z","title":"Learning Efficient Recursive Numeral Systems via Reinforcement Learning","summary":"  It has previously been shown that by using reinforcement learning (RL),\nagents can derive simple approximate and exact-restricted numeral systems that\nare similar to human ones (Carlsson, 2021). However, it is a major challenge to\nshow how more complex recursive numeral systems, similar to for example\nEnglish, could arise via a simple learning mechanism such as RL. Here, we\nintroduce an approach towards deriving a mechanistic explanation of the\nemergence of efficient recursive number systems. We consider pairs of agents\nlearning how to communicate about numerical quantities through a meta-grammar\nthat can be gradually modified throughout the interactions. %We find that the\nseminal meta-grammar of Hurford (Hurford, 1975) is not suitable for this\napplication as its optimization results in systems that deviate from standard\nconventions observed within human numeral systems. We propose a simple\nmodification which addresses this issue. Utilising a slightly modified version\nof the meta-grammar of Hurford, we demonstrate that our RL agents, shaped by\nthe pressures for efficient communication, can effectively modify their lexicon\ntowards Pareto-optimal configurations which are comparable to those observed\nwithin human numeral systems in terms of their efficiency.\n","authors":["Andrea Silvi","Jonathan Thomas","Emil Carlsson","Devdatt Dubhashi","Moa Johansson"],"pdf_url":"https://arxiv.org/pdf/2409.07170v3.pdf","comment":"8 pages, 5 figures"},{"id":"http://arxiv.org/abs/2407.04752v2","updated":"2025-03-03T06:46:33Z","published":"2024-07-05T08:37:17Z","title":"SpikeLLM: Scaling up Spiking Neural Network to Large Language Models via\n  Saliency-based Spiking","summary":"  Recent advancements in large language models (LLMs) with billions of\nparameters have improved performance in various applications, but their\ninference processes demand significant energy and computational resources. In\ncontrast, the human brain, with approximately 86 billion neurons, is much more\nenergy-efficient than LLMs with similar parameters. Inspired by this, we\nredesign 7$\\sim$70 billion parameter LLMs using bio-plausible spiking\nmechanisms, emulating the efficient behavior of the human brain. We propose the\nfirst spiking large language model, SpikeLLM. Coupled with the proposed model,\ntwo essential approaches are proposed to improve spike training efficiency:\nGeneralized Integrate-and-Fire (GIF) neurons to compress spike length from $T$\nto $\\frac{T}{L} \\log_2 L$ bits, and an Optimal Brain Spiking framework to\ndivide outlier channels and allocate different $T$ for GIF neurons, which\nfurther compresses spike length to approximate $log_2T$ bits. The necessity of\nspike-driven LLM is proved by comparison with quantized LLMs with similar\noperations. In the OmniQuant pipeline, SpikeLLM reduces 11.01% WikiText2\nperplexity and improves 2.55% accuracy of common scene reasoning on a LLAMA-7B\nW4A4 model. In the GPTQ pipeline, SpikeLLM achieves direct additive in linear\nlayers, significantly exceeding PB-LLMs.\n","authors":["Xingrun Xing","Boyan Gao","Zheng Zhang","David A. Clifton","Shitao Xiao","Li Du","Guoqi Li","Jiajun Zhang"],"pdf_url":"https://arxiv.org/pdf/2407.04752v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2402.18945v4","updated":"2025-03-03T06:34:48Z","published":"2024-02-29T08:20:49Z","title":"SynGhost: Invisible and Universal Task-agnostic Backdoor Attack via\n  Syntactic Transfer","summary":"  Although pre-training achieves remarkable performance, it suffers from\ntask-agnostic backdoor attacks due to vulnerabilities in data and training\nmechanisms. These attacks can transfer backdoors to various downstream tasks.\nIn this paper, we introduce $\\mathtt{maxEntropy}$, an entropy-based poisoning\nfilter that mitigates such risks. To overcome the limitations of manual target\nsetting and explicit triggers, we propose $\\mathtt{SynGhost}$, an invisible and\nuniversal task-agnostic backdoor attack via syntactic transfer, further\nexposing vulnerabilities in pre-trained language models (PLMs). Specifically,\n$\\mathtt{SynGhost}$ injects multiple syntactic backdoors into the pre-training\nspace through corpus poisoning, while preserving the PLM's pre-training\ncapabilities. Second, $\\mathtt{SynGhost}$ adaptively selects optimal targets\nbased on contrastive learning, creating a uniform distribution in the\npre-training space. To identify syntactic differences, we also introduce an\nawareness module to minimize interference between backdoors. Experiments show\nthat $\\mathtt{SynGhost}$ poses significant threats and can transfer to various\ndownstream tasks. Furthermore, $\\mathtt{SynGhost}$ resists defenses based on\nperplexity, fine-pruning, and $\\mathtt{maxEntropy}$. The code is available at\nhttps://github.com/Zhou-CyberSecurity-AI/SynGhost.\n","authors":["Pengzhou Cheng","Wei Du","Zongru Wu","Fengwei Zhang","Libo Chen","Zhuosheng Zhang","Gongshen Liu"],"pdf_url":"https://arxiv.org/pdf/2402.18945v4.pdf","comment":"17 pages, 16 figures, 12 tables, accepted at NAACL 2025 Findings"},{"id":"http://arxiv.org/abs/2412.07298v2","updated":"2025-03-03T06:33:49Z","published":"2024-12-10T08:28:57Z","title":"The Rise and Down of Babel Tower: Investigating the Evolution Process of\n  Multilingual Code Large Language Model","summary":"  Large language models (LLMs) have shown significant multilingual\ncapabilities. However, the mechanisms underlying the development of these\ncapabilities during pre-training are not well understood. In this paper, we use\ncode LLMs as an experimental platform to explore the evolution of multilingual\ncapabilities in LLMs during the pre-training process. Based on our\nobservations, we propose the Babel Tower Hypothesis, which describes the entire\nprocess of LLMs acquiring new language capabilities. During the learning\nprocess, multiple languages initially share a single knowledge system dominated\nby the primary language and gradually develop language-specific knowledge\nsystems. We then validate the above hypothesis by tracking the internal states\nof the LLMs through identifying working languages and language transferring\nneurons. Experimental results show that the internal state changes of the LLM\nare consistent with our Babel Tower Hypothesis. Building on these insights, we\npropose a novel method to construct an optimized pre-training corpus for\nmultilingual code LLMs, which significantly outperforms LLMs trained on the\noriginal corpus. The proposed Babel Tower Hypothesis provides new insights into\ndesigning pre-training data distributions to achieve optimal multilingual\ncapabilities in LLMs.\n","authors":["Jiawei Chen","Wentao Chen","Jing Su","Jingjing Xu","Hongyu Lin","Mengjie Ren","Yaojie Lu","Xianpei Han","Le Sun"],"pdf_url":"https://arxiv.org/pdf/2412.07298v2.pdf","comment":"Accepted to ICLR 2025"},{"id":"http://arxiv.org/abs/2502.17204v2","updated":"2025-03-03T06:29:31Z","published":"2025-02-24T14:39:28Z","title":"Order Matters: Investigate the Position Bias in Multi-constraint\n  Instruction Following","summary":"  Real-world instructions with multiple constraints pose a significant\nchallenge to existing large language models (LLMs). An observation is that the\nLLMs exhibit dramatic performance fluctuation when disturbing the order of the\nincorporated constraints. Yet, none of the existing works has systematically\ninvestigated this position bias problem in the field of multi-constraint\ninstruction following. To bridge this gap, we design a probing task where we\nquantitatively measure the difficulty distribution of the constraints by a\nnovel Difficulty Distribution Index (CDDI). Through the experimental results,\nwe find that LLMs are more performant when presented with the constraints in a\n``hard-to-easy'' order. This preference can be generalized to LLMs with\ndifferent architecture or different sizes of parameters. Additionally, we\nconduct an explanation study, providing an intuitive insight into the\ncorrelation between the LLM's attention and constraint orders. Our code and\ndataset are publicly available at https://github.com/meowpass/PBIF.\n","authors":["Jie Zeng","Qianyu He","Qingyu Ren","Jiaqing Liang","Yanghua Xiao","Weikang Zhou","Zeye Sun","Fei Yu"],"pdf_url":"https://arxiv.org/pdf/2502.17204v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2310.01405v4","updated":"2025-03-03T06:14:14Z","published":"2023-10-02T17:59:07Z","title":"Representation Engineering: A Top-Down Approach to AI Transparency","summary":"  In this paper, we identify and characterize the emerging area of\nrepresentation engineering (RepE), an approach to enhancing the transparency of\nAI systems that draws on insights from cognitive neuroscience. RepE places\npopulation-level representations, rather than neurons or circuits, at the\ncenter of analysis, equipping us with novel methods for monitoring and\nmanipulating high-level cognitive phenomena in deep neural networks (DNNs). We\nprovide baselines and an initial analysis of RepE techniques, showing that they\noffer simple yet effective solutions for improving our understanding and\ncontrol of large language models. We showcase how these methods can provide\ntraction on a wide range of safety-relevant problems, including honesty,\nharmlessness, power-seeking, and more, demonstrating the promise of top-down\ntransparency research. We hope that this work catalyzes further exploration of\nRepE and fosters advancements in the transparency and safety of AI systems.\n","authors":["Andy Zou","Long Phan","Sarah Chen","James Campbell","Phillip Guo","Richard Ren","Alexander Pan","Xuwang Yin","Mantas Mazeika","Ann-Kathrin Dombrowski","Shashwat Goel","Nathaniel Li","Michael J. Byun","Zifan Wang","Alex Mallen","Steven Basart","Sanmi Koyejo","Dawn Song","Matt Fredrikson","J. Zico Kolter","Dan Hendrycks"],"pdf_url":"https://arxiv.org/pdf/2310.01405v4.pdf","comment":"Code is available at\n  https://github.com/andyzoujm/representation-engineering"},{"id":"http://arxiv.org/abs/2411.02886v2","updated":"2025-03-03T05:49:41Z","published":"2024-11-05T07:56:24Z","title":"TokenSelect: Efficient Long-Context Inference and Length Extrapolation\n  for LLMs via Dynamic Token-Level KV Cache Selection","summary":"  The rapid advancement of Large Language Models (LLMs) has driven growing\ndemand for processing extended context sequences in contemporary applications.\nHowever, this progress faces two major challenges: performance degradation due\nto sequence lengths out-of-distribution, and excessively long inference times\ncaused by the quadratic computational complexity of attention. These issues\nhinder the application of LLMs in long-context scenarios. In this paper, we\npropose Dynamic Token-Level KV Cache Selection (TokenSelect), a training-free\nmethod for efficient and accurate long-context inference. TokenSelect builds\nupon the observation of non-contiguous attention sparsity, using Query-Key dot\nproducts to measure per-head KV Cache criticality at token-level. By per-head\nsoft voting mechanism, TokenSelect selectively involves a few critical KV cache\ntokens in attention calculation without sacrificing accuracy. To further\naccelerate TokenSelect, we design the Selection Cache based on observations of\nconsecutive Query similarity and implemented efficient dot product kernel,\nsignificantly reducing the overhead. A comprehensive evaluation of TokenSelect\ndemonstrates up to 23.84x speedup in attention computation and up to 2.28x\nacceleration in end-to-end latency, while providing superior performance\ncompared to state-of-the-art long-context inference methods.\n","authors":["Wei Wu","Zhuoshi Pan","Chao Wang","Liyi Chen","Yunchu Bai","Tianfu Wang","Kun Fu","Zheng Wang","Hui Xiong"],"pdf_url":"https://arxiv.org/pdf/2411.02886v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2502.14171v3","updated":"2025-03-03T05:44:29Z","published":"2025-02-20T00:39:05Z","title":"Enhancing Conversational Agents with Theory of Mind: Aligning Beliefs,\n  Desires, and Intentions for Human-Like Interaction","summary":"  Natural language interaction with agentic Artificial Intelligence (AI),\ndriven by Large Language Models (LLMs), is expected to remain a dominant\nparadigm in the near future. While humans instinctively align their\ncommunication with mental states -- an ability known as Theory of Mind (ToM),\ncurrent LLM powered systems exhibit significant limitations in this regard.\nThis study examines the extent to which open source language models (LLaMA) can\ncapture and preserve ToM related information and how effectively it contributes\nto consistent ToM reasoning in generated responses. We further investigate\nwhether explicit manipulation of ToM related components, such as beliefs,\ndesires, and intentions, can enhance response alignment. Experiments on two\nLLaMA 3 variants demonstrate that incorporating ToM informed alignment improves\nresponse quality, achieving win rates of 67 and 63 percent for the 3B and 8B\nmodels, respectively. These findings highlight the potential of ToM driven\nstrategies to improve alignment in LLM based conversational agents.\n","authors":["Mehdi Jafari","Devin Yuncheng Hua","Hao Xue","Flora Salim"],"pdf_url":"https://arxiv.org/pdf/2502.14171v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.02268v3","updated":"2025-03-03T05:32:47Z","published":"2024-10-03T07:40:14Z","title":"Structural-Entropy-Based Sample Selection for Efficient and Effective\n  Learning","summary":"  Sample selection improves the efficiency and effectiveness of machine\nlearning models by providing informative and representative samples. Typically,\nsamples can be modeled as a sample graph, where nodes are samples and edges\nrepresent their similarities. Most existing methods are based on local\ninformation, such as the training difficulty of samples, thereby overlooking\nglobal information, such as connectivity patterns. This oversight can result in\nsuboptimal selection because global information is crucial for ensuring that\nthe selected samples well represent the structural properties of the graph. To\naddress this issue, we employ structural entropy to quantify global information\nand losslessly decompose it from the whole graph to individual nodes using the\nShapley value. Based on the decomposition, we present\n$\\textbf{S}$tructural-$\\textbf{E}$ntropy-based sample $\\textbf{S}$election\n($\\textbf{SES}$), a method that integrates both global and local information to\nselect informative and representative samples. SES begins by constructing a\n$k$NN-graph among samples based on their similarities. It then measures sample\nimportance by combining structural entropy (global metric) with training\ndifficulty (local metric). Finally, SES applies importance-biased blue noise\nsampling to select a set of diverse and representative samples. Comprehensive\nexperiments on three learning scenarios -- supervised learning, active\nlearning, and continual learning -- clearly demonstrate the effectiveness of\nour method.\n","authors":["Tianchi Xie","Jiangning Zhu","Guozu Ma","Minzhi Lin","Wei Chen","Weikai Yang","Shixia Liu"],"pdf_url":"https://arxiv.org/pdf/2410.02268v3.pdf","comment":"Published as a conference paper at ICLR 2025"},{"id":"http://arxiv.org/abs/2502.17720v2","updated":"2025-03-03T04:31:48Z","published":"2025-02-24T23:23:27Z","title":"Spontaneous Giving and Calculated Greed in Language Models","summary":"  Large language models demonstrate advanced problem-solving capabilities by\nincorporating reasoning techniques such as chain of thought and reflection.\nHowever, how these reasoning capabilities extend to social intelligence remains\nunclear. In this study, we investigate this question using economic games that\nmodel social dilemmas, where social intelligence plays a crucial role. First,\nwe examine the effects of chain-of-thought and reflection techniques in a\npublic goods game. We then extend our analysis to six economic games on\ncooperation and punishment, comparing off-the-shelf non-reasoning and reasoning\nmodels. We find that reasoning models significantly reduce cooperation and norm\nenforcement, prioritizing individual rationality. Consequently, groups with\nmore reasoning models exhibit less cooperation and lower gains through repeated\ninteractions. These behaviors parallel human tendencies of \"spontaneous giving\nand calculated greed.\" Our results suggest the need for AI architectures that\nincorporate social intelligence alongside reasoning capabilities to ensure that\nAI supports, rather than disrupts, human cooperative intuition.\n","authors":["Yuxuan Li","Hirokazu Shirado"],"pdf_url":"https://arxiv.org/pdf/2502.17720v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2402.09906v3","updated":"2025-03-03T04:28:49Z","published":"2024-02-15T12:12:19Z","title":"Generative Representational Instruction Tuning","summary":"  All text-based language problems can be reduced to either generation or\nembedding. Current models only perform well at one or the other. We introduce\ngenerative representational instruction tuning (GRIT) whereby a large language\nmodel is trained to handle both generative and embedding tasks by\ndistinguishing between them through instructions. Compared to other open\nmodels, our resulting GritLM 7B sets a new state of the art on the Massive Text\nEmbedding Benchmark (MTEB) and outperforms all models up to its size on a range\nof generative tasks. By scaling up further, GritLM 8x7B outperforms all open\ngenerative language models that we tried while still being among the best\nembedding models. Notably, we find that GRIT matches training on only\ngenerative or embedding data, thus we can unify both at no performance loss.\nAmong other benefits, the unification via GRIT speeds up Retrieval-Augmented\nGeneration (RAG) by > 60% for long documents, by no longer requiring separate\nretrieval and generation models. Models, code, etc. are freely available at\nhttps://github.com/ContextualAI/gritlm.\n","authors":["Niklas Muennighoff","Hongjin Su","Liang Wang","Nan Yang","Furu Wei","Tao Yu","Amanpreet Singh","Douwe Kiela"],"pdf_url":"https://arxiv.org/pdf/2402.09906v3.pdf","comment":"67 pages (16 main), 25 figures, 34 tables"},{"id":"http://arxiv.org/abs/2405.16821v3","updated":"2025-03-03T04:25:41Z","published":"2024-05-27T04:40:56Z","title":"Perturbation-Restrained Sequential Model Editing","summary":"  Model editing is an emerging field that focuses on updating the knowledge\nembedded within large language models (LLMs) without extensive retraining.\nHowever, current model editing methods significantly compromise the general\nabilities of LLMs as the number of edits increases, and this trade-off poses a\nsubstantial challenge to the continual learning of LLMs. In this paper, we\nfirst theoretically analyze that the factor affecting the general abilities in\nsequential model editing lies in the condition number of the edited matrix. The\ncondition number of a matrix represents its numerical sensitivity, and\ntherefore can be used to indicate the extent to which the original knowledge\nassociations stored in LLMs are perturbed after editing. Subsequently,\nstatistical findings demonstrate that the value of this factor becomes larger\nas the number of edits increases, thereby exacerbating the deterioration of\ngeneral abilities. To this end, a framework termed Perturbation Restraint on\nUpper bouNd for Editing (PRUNE) is proposed, which applies the condition number\nrestraints in sequential editing. These restraints can lower the upper bound on\nperturbation to edited models, thus preserving the general abilities.\nSystematically, we conduct experiments employing three editing methods on three\nLLMs across four downstream tasks. The results show that PRUNE can preserve\ngeneral abilities while maintaining the editing performance effectively in\nsequential model editing. The code are available at\nhttps://github.com/mjy1111/PRUNE.\n","authors":["Jun-Yu Ma","Hong Wang","Hao-Xiang Xu","Zhen-Hua Ling","Jia-Chen Gu"],"pdf_url":"https://arxiv.org/pdf/2405.16821v3.pdf","comment":"Accepted by ICLR 2025"},{"id":"http://arxiv.org/abs/2502.12110v2","updated":"2025-03-03T04:14:02Z","published":"2025-02-17T18:36:14Z","title":"A-MEM: Agentic Memory for LLM Agents","summary":"  While large language model (LLM) agents can effectively use external tools\nfor complex real-world tasks, they require memory systems to leverage\nhistorical experiences. Current memory systems enable basic storage and\nretrieval but lack sophisticated memory organization, despite recent attempts\nto incorporate graph databases. Moreover, these systems' fixed operations and\nstructures limit their adaptability across diverse tasks. To address this\nlimitation, this paper proposes a novel agentic memory system for LLM agents\nthat can dynamically organize memories in an agentic way. Following the basic\nprinciples of the Zettelkasten method, we designed our memory system to create\ninterconnected knowledge networks through dynamic indexing and linking. When a\nnew memory is added, we generate a comprehensive note containing multiple\nstructured attributes, including contextual descriptions, keywords, and tags.\nThe system then analyzes historical memories to identify relevant connections,\nestablishing links where meaningful similarities exist. Additionally, this\nprocess enables memory evolution - as new memories are integrated, they can\ntrigger updates to the contextual representations and attributes of existing\nhistorical memories, allowing the memory network to continuously refine its\nunderstanding. Our approach combines the structured organization principles of\nZettelkasten with the flexibility of agent-driven decision making, allowing for\nmore adaptive and context-aware memory management. Empirical experiments on six\nfoundation models show superior improvement against existing SOTA baselines.\nThe source code is available at https://github.com/WujiangXu/AgenticMemory.\n","authors":["Wujiang Xu","Zujie Liang","Kai Mei","Hang Gao","Juntao Tan","Yongfeng Zhang"],"pdf_url":"https://arxiv.org/pdf/2502.12110v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2502.14189v2","updated":"2025-03-03T04:11:31Z","published":"2025-02-20T01:46:12Z","title":"QUAD-LLM-MLTC: Large Language Models Ensemble Learning for Healthcare\n  Text Multi-Label Classification","summary":"  The escalating volume of collected healthcare textual data presents a unique\nchallenge for automated Multi-Label Text Classification (MLTC), which is\nprimarily due to the scarcity of annotated texts for training and their nuanced\nnature. Traditional machine learning models often fail to fully capture the\narray of expressed topics. However, Large Language Models (LLMs) have\ndemonstrated remarkable effectiveness across numerous Natural Language\nProcessing (NLP) tasks in various domains, which show impressive computational\nefficiency and suitability for unsupervised learning through prompt\nengineering. Consequently, these LLMs promise an effective MLTC of medical\nnarratives. However, when dealing with various labels, different prompts can be\nrelevant depending on the topic. To address these challenges, the proposed\napproach, QUAD-LLM-MLTC, leverages the strengths of four LLMs: GPT-4o, BERT,\nPEGASUS, and BART. QUAD-LLM-MLTC operates in a sequential pipeline in which\nBERT extracts key tokens, PEGASUS augments textual data, GPT-4o classifies, and\nBART provides topics' assignment probabilities, which results in four\nclassifications, all in a 0-shot setting. The outputs are then combined using\nensemble learning and processed through a meta-classifier to produce the final\nMLTC result. The approach is evaluated using three samples of annotated texts,\nwhich contrast it with traditional and single-model methods. The results show\nsignificant improvements across the majority of the topics in the\nclassification's F1 score and consistency (F1 and Micro-F1 scores of 78.17% and\n80.16% with standard deviations of 0.025 and 0.011, respectively). This\nresearch advances MLTC using LLMs and provides an efficient and scalable\nsolution to rapidly categorize healthcare-related text data without further\ntraining.\n","authors":["Hajar Sakai","Sarah S. Lam"],"pdf_url":"https://arxiv.org/pdf/2502.14189v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2407.00617v4","updated":"2025-03-03T03:41:11Z","published":"2024-06-30T08:00:34Z","title":"Iterative Nash Policy Optimization: Aligning LLMs with General\n  Preferences via No-Regret Learning","summary":"  Reinforcement Learning with Human Feedback (RLHF) has achieved great success\nin aligning large language models (LLMs) with human preferences. Prevalent RLHF\napproaches are reward-based, following the Bradley-Terry (BT) model assumption,\nwhich may not fully capture the complexity of human preferences. In this paper,\nwe explore RLHF under a general preference framework and approach it from a\ngame-theoretic perspective. Specifically, we formulate the problem as a\ntwo-player game and propose a novel online algorithm, iterative Nash policy\noptimization (INPO). The key idea is to let the policy play against itself via\nno-regret learning, thereby approximating the Nash policy. Unlike previous\nmethods, INPO bypasses the need for estimating the expected win rate for\nindividual responses, which typically incurs high computational or annotation\ncosts. Instead, we introduce a new loss objective that is directly minimized\nover a preference dataset. We provide theoretical analysis for our approach and\ndemonstrate its effectiveness through experiments on various representative\nbenchmarks. With an LLaMA-3-8B-based SFT model, INPO achieves a 42.6%\nlength-controlled win rate on AlpacaEval 2.0 and a 37.8% win rate on\nArena-Hard, showing substantial improvement over the state-of-the-art online\nRLHF algorithms.\n","authors":["Yuheng Zhang","Dian Yu","Baolin Peng","Linfeng Song","Ye Tian","Mingyue Huo","Nan Jiang","Haitao Mi","Dong Yu"],"pdf_url":"https://arxiv.org/pdf/2407.00617v4.pdf","comment":null},{"id":"http://arxiv.org/abs/2405.14093v3","updated":"2025-03-03T03:19:31Z","published":"2024-05-23T01:43:54Z","title":"A Survey on Vision-Language-Action Models for Embodied AI","summary":"  Embodied AI is widely recognized as a key element of artificial general\nintelligence because it involves controlling embodied agents to perform tasks\nin the physical world. Building on the success of large language models and\nvision-language models, a new category of multimodal models -- referred to as\nvision-language-action models (VLAs) -- has emerged to address\nlanguage-conditioned robotic tasks in embodied AI by leveraging their distinct\nability to generate actions. In recent years, a myriad of VLAs have been\ndeveloped, making it imperative to capture the rapidly evolving landscape\nthrough a comprehensive survey. To this end, we present the first survey on\nVLAs for embodied AI. This work provides a detailed taxonomy of VLAs, organized\ninto three major lines of research. The first line focuses on individual\ncomponents of VLAs. The second line is dedicated to developing control policies\nadept at predicting low-level actions. The third line comprises high-level task\nplanners capable of decomposing long-horizon tasks into a sequence of subtasks,\nthereby guiding VLAs to follow more general user instructions. Furthermore, we\nprovide an extensive summary of relevant resources, including datasets,\nsimulators, and benchmarks. Finally, we discuss the challenges faced by VLAs\nand outline promising future directions in embodied AI.\n","authors":["Yueen Ma","Zixing Song","Yuzheng Zhuang","Jianye Hao","Irwin King"],"pdf_url":"https://arxiv.org/pdf/2405.14093v3.pdf","comment":"16 pages, a survey of vision-language-action models"},{"id":"http://arxiv.org/abs/2412.17242v3","updated":"2025-03-03T03:08:43Z","published":"2024-12-23T03:30:34Z","title":"On the Generalization and Adaptation Ability of Machine-Generated Text\n  Detectors in Academic Writing","summary":"  The rising popularity of large language models (LLMs) has raised concerns\nabout machine-generated text (MGT), particularly in academic settings, where\nissues like plagiarism and misinformation are prevalent. As a result,\ndeveloping a highly generalizable and adaptable MGT detection system has become\nan urgent priority. Given that LLMs are most commonly misused in academic\nwriting, this work investigates the generalization and adaptation capabilities\nof MGT detectors in three key aspects specific to academic writing: First, we\nconstruct MGT-Acedemic, a large-scale dataset comprising over 336M tokens and\n749K samples. MGT-Acedemic focuses on academic writing, featuring human-written\ntexts (HWTs) and MGTs across STEM, Humanities, and Social Sciences, paired with\nan extensible code framework for efficient benchmarking. Second, we benchmark\nthe performance of various detectors for binary classification and attribution\ntasks in both in-domain and cross-domain settings. This benchmark reveals the\noften-overlooked challenges of attribution tasks. Third, we introduce a novel\nattribution task where models have to adapt to new classes over time without\n(or with very limited) access to prior training data in both few-shot and\nmany-shot scenarios. We implement eight different adapting techniques to\nimprove the performance and highlight the inherent complexity of the task. Our\nfindings provide insights into the generalization and adaptation ability of MGT\ndetectors across diverse scenarios and lay the foundation for building robust,\nadaptive detection systems. The code framework is available at\nhttps://github.com/Y-L-LIU/MGTBench-2.0.\n","authors":["Yule Liu","Zhiyuan Zhong","Yifan Liao","Zhen Sun","Jingyi Zheng","Jiaheng Wei","Qingyuan Gong","Fenghua Tong","Yang Chen","Yang Zhang","Xinlei He"],"pdf_url":"https://arxiv.org/pdf/2412.17242v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.13085v2","updated":"2025-03-03T03:08:28Z","published":"2024-10-16T23:03:27Z","title":"MMed-RAG: Versatile Multimodal RAG System for Medical Vision Language\n  Models","summary":"  Artificial Intelligence (AI) has demonstrated significant potential in\nhealthcare, particularly in disease diagnosis and treatment planning. Recent\nprogress in Medical Large Vision-Language Models (Med-LVLMs) has opened up new\npossibilities for interactive diagnostic tools. However, these models often\nsuffer from factual hallucination, which can lead to incorrect diagnoses.\nFine-tuning and retrieval-augmented generation (RAG) have emerged as methods to\naddress these issues. However, the amount of high-quality data and distribution\nshifts between training data and deployment data limit the application of\nfine-tuning methods. Although RAG is lightweight and effective, existing\nRAG-based approaches are not sufficiently general to different medical domains\nand can potentially cause misalignment issues, both between modalities and\nbetween the model and the ground truth. In this paper, we propose a versatile\nmultimodal RAG system, MMed-RAG, designed to enhance the factuality of\nMed-LVLMs. Our approach introduces a domain-aware retrieval mechanism, an\nadaptive retrieved contexts selection method, and a provable RAG-based\npreference fine-tuning strategy. These innovations make the RAG process\nsufficiently general and reliable, significantly improving alignment when\nintroducing retrieved contexts. Experimental results across five medical\ndatasets (involving radiology, ophthalmology, pathology) on medical VQA and\nreport generation demonstrate that MMed-RAG can achieve an average improvement\nof 43.8% in the factual accuracy of Med-LVLMs. Our data and code are available\nin https://github.com/richard-peng-xia/MMed-RAG.\n","authors":["Peng Xia","Kangyu Zhu","Haoran Li","Tianze Wang","Weijia Shi","Sheng Wang","Linjun Zhang","James Zou","Huaxiu Yao"],"pdf_url":"https://arxiv.org/pdf/2410.13085v2.pdf","comment":"ICLR 2025"},{"id":"http://arxiv.org/abs/2406.06600v3","updated":"2025-03-03T03:05:30Z","published":"2024-06-06T13:44:57Z","title":"HORAE: A Domain-Agnostic Modeling Language for Automating Multimodal\n  Service Regulation","summary":"  Artificial intelligence is rapidly encroaching on the field of service\nregulation. This work-in-progress article presents the design principles behind\nHORAE, a unified specification language to model multimodal regulation rules\nacross a diverse set of domains. We show how HORAE facilitates an intelligent\nservice regulation pipeline by further exploiting a fine-tuned large language\nmodel named HORAE that automates the HORAE modeling process, thereby yielding\nan end-to-end framework for fully automated intelligent service regulation.\n","authors":["Yutao Sun","Mingshuai Chen","Kangjia Zhao","Jintao Chen"],"pdf_url":"https://arxiv.org/pdf/2406.06600v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.07404v2","updated":"2025-03-03T03:02:55Z","published":"2024-11-11T22:22:21Z","title":"Controllable Context Sensitivity and the Knob Behind It","summary":"  When making predictions, a language model must trade off how much it relies\non its context vs. its prior knowledge. Choosing how sensitive the model is to\nits context is a fundamental functionality, as it enables the model to excel at\ntasks like retrieval-augmented generation and question-answering. In this\npaper, we search for a knob which controls this sensitivity, determining\nwhether language models answer from the context or their prior knowledge. To\nguide this search, we design a task for controllable context sensitivity. In\nthis task, we first feed the model a context (Paris is in England) and a\nquestion (Where is Paris?); we then instruct the model to either use its prior\nor contextual knowledge and evaluate whether it generates the correct answer\nfor both intents (either France or England). When fine-tuned on this task,\ninstruction-tuned versions of Llama-3.1, Mistral-v0.3, and Gemma-2 can solve it\nwith high accuracy (85-95%). Analyzing these high-performing models, we narrow\ndown which layers may be important to context sensitivity using a novel linear\ntime algorithm. Then, in each model, we identify a 1-D subspace in a single\nlayer that encodes whether the model follows context or prior knowledge.\nInterestingly, while we identify this subspace in a fine-tuned model, we find\nthat the exact same subspace serves as an effective knob in not only that model\nbut also non-fine-tuned instruct and base models of that model family. Finally,\nwe show a strong correlation between a model's performance and how distinctly\nit separates context-agreeing from context-ignoring answers in this subspace.\nThese results suggest a single subspace facilitates how the model chooses\nbetween context and prior knowledge, hinting at a simple fundamental mechanism\nthat controls this behavior.\n","authors":["Julian Minder","Kevin Du","Niklas Stoehr","Giovanni Monea","Chris Wendler","Robert West","Ryan Cotterell"],"pdf_url":"https://arxiv.org/pdf/2411.07404v2.pdf","comment":"Published as a conference paper at ICLR 2025"},{"id":"http://arxiv.org/abs/2502.20854v2","updated":"2025-03-03T03:00:59Z","published":"2025-02-28T08:53:08Z","title":"A Pilot Empirical Study on When and How to Use Knowledge Graphs as\n  Retrieval Augmented Generation","summary":"  The integration of Knowledge Graphs (KGs) into the Retrieval Augmented\nGeneration (RAG) framework has attracted significant interest, with early\nstudies showing promise in mitigating hallucinations and improving model\naccuracy. However, a systematic understanding and comparative analysis of the\nrapidly emerging KG-RAG methods are still lacking. This paper seeks to lay the\nfoundation for systematically answering the question of when and how to use\nKG-RAG by analyzing their performance in various application scenarios\nassociated with different technical configurations. After outlining the mind\nmap using KG-RAG framework and summarizing its popular pipeline, we conduct a\npilot empirical study of KG-RAG works to reimplement and evaluate 6 KG-RAG\nmethods across 7 datasets in diverse scenarios, analyzing the impact of 9\nKG-RAG configurations in combination with 17 LLMs. Our results underscore the\ncritical role of appropriate application conditions and optimal configurations\nof KG-RAG components.\n","authors":["Xujie Yuan","Yongxu Liu","Shimin Di","Shiwen Wu","Libin Zheng","Rui Meng","Lei Chen","Xiaofang Zhou","Jian Yin"],"pdf_url":"https://arxiv.org/pdf/2502.20854v2.pdf","comment":"8 pages, 2 figures, 14 tables"},{"id":"http://arxiv.org/abs/2410.08109v3","updated":"2025-03-03T02:45:58Z","published":"2024-10-10T16:56:05Z","title":"A Closer Look at Machine Unlearning for Large Language Models","summary":"  Large language models (LLMs) may memorize sensitive or copyrighted content,\nraising privacy and legal concerns. Due to the high cost of retraining from\nscratch, researchers attempt to employ machine unlearning to remove specific\ncontent from LLMs while preserving the overall performance. In this paper, we\ndiscuss several issues in machine unlearning for LLMs and provide our insights\non possible approaches. To address the issue of inadequate evaluation of model\noutputs after unlearning, we introduce three additional metrics to evaluate\ntoken diversity, sentence semantics, and factual correctness. We then\ncategorize unlearning methods into untargeted and targeted, and discuss their\nissues respectively. Specifically, the behavior that untargeted unlearning\nattempts to approximate is unpredictable and may involve hallucinations, and\nexisting regularization is insufficient for targeted unlearning. To alleviate\nthese issues, we propose using the objective of maximizing entropy (ME) for\nuntargeted unlearning and incorporate answer preservation (AP) loss as\nregularization for targeted unlearning. Experimental results across three\nscenarios, i.e., fictitious unlearning, continual unlearning, and real-world\nunlearning, demonstrate the effectiveness of our approaches. The code is\navailable at https://github.com/sail-sg/closer-look-LLM-unlearning.\n","authors":["Xiaojian Yuan","Tianyu Pang","Chao Du","Kejiang Chen","Weiming Zhang","Min Lin"],"pdf_url":"https://arxiv.org/pdf/2410.08109v3.pdf","comment":"ICLR 2025"},{"id":"http://arxiv.org/abs/2409.19788v2","updated":"2025-03-03T02:38:52Z","published":"2024-09-29T21:20:57Z","title":"Exploring Adversarial Robustness in Classification tasks using DNA\n  Language Models","summary":"  DNA Language Models, such as GROVER, DNABERT2 and the Nucleotide Transformer,\noperate on DNA sequences that inherently contain sequencing errors, mutations,\nand laboratory-induced noise, which may significantly impact model performance.\nDespite the importance of this issue, the robustness of DNA language models\nremains largely underexplored. In this paper, we comprehensivly investigate\ntheir robustness in DNA classification by applying various adversarial attack\nstrategies: the character (nucleotide substitutions), word (codon\nmodifications), and sentence levels (back-translation-based transformations) to\nsystematically analyze model vulnerabilities. Our results demonstrate that DNA\nlanguage models are highly susceptible to adversarial attacks, leading to\nsignificant performance degradation. Furthermore, we explore adversarial\ntraining method as a defense mechanism, which enhances both robustness and\nclassification accuracy. This study highlights the limitations of DNA language\nmodels and underscores the necessity of robustness in bioinformatics.\n","authors":["Hyunwoo Yoo","Haebin Shin","Kaidi Xu","Gail Rosen"],"pdf_url":"https://arxiv.org/pdf/2409.19788v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.12952v2","updated":"2025-03-03T02:27:02Z","published":"2024-10-16T18:40:26Z","title":"Facilitating Multi-turn Function Calling for LLMs via Compositional\n  Instruction Tuning","summary":"  Large Language Models (LLMs) have exhibited significant potential in\nperforming diverse tasks, including the ability to call functions or use\nexternal tools to enhance their performance. While current research on function\ncalling by LLMs primarily focuses on single-turn interactions, this paper\naddresses the overlooked necessity for LLMs to engage in multi-turn function\ncalling--critical for handling compositional, real-world queries that require\nplanning with functions but not only use functions. To facilitate this, we\nintroduce an approach, BUTTON, which generates synthetic compositional\ninstruction tuning data via bottom-up instruction construction and top-down\ntrajectory generation. In the bottom-up phase, we generate simple atomic tasks\nbased on real-world scenarios and build compositional tasks using heuristic\nstrategies based on atomic tasks. Corresponding function definitions are then\nsynthesized for these compositional tasks. The top-down phase features a\nmulti-agent environment where interactions among simulated humans, assistants,\nand tools are utilized to gather multi-turn function calling trajectories. This\napproach ensures task compositionality and allows for effective function and\ntrajectory generation by examining atomic tasks within compositional tasks. We\nproduce a dataset BUTTONInstruct comprising 8k data points and demonstrate its\neffectiveness through extensive experiments across various LLMs.\n","authors":["Mingyang Chen","Haoze Sun","Tianpeng Li","Fan Yang","Hao Liang","Keer Lu","Bin Cui","Wentao Zhang","Zenan Zhou","Weipeng Chen"],"pdf_url":"https://arxiv.org/pdf/2410.12952v2.pdf","comment":"Accepted to ICLR 2025"},{"id":"http://arxiv.org/abs/2501.13983v3","updated":"2025-03-03T02:06:47Z","published":"2025-01-23T06:57:24Z","title":"AdEval: Alignment-based Dynamic Evaluation to Mitigate Data\n  Contamination in Large Language Models","summary":"  As Large Language Models (LLMs) are pretrained on massive-scale corpora, the\nissue of data contamination has become increasingly severe, leading to\npotential overestimation of model performance during evaluation. To address\nthis, we propose AdEval (Alignment-based Dynamic Evaluation), a dynamic data\nevaluation method aimed at mitigating the impact of data contamination on\nevaluation reliability. Experimental results on multiple datasets demonstrate\nthat AdEval effectively reduces the impact of data contamination on evaluation\noutcomes, enhancing both the fairness and reliability of the evaluation\nprocess.\n","authors":["Yang Fan"],"pdf_url":"https://arxiv.org/pdf/2501.13983v3.pdf","comment":"There are serious academic problems in this paper, such as data\n  falsification and plagiarism in the method of the paper"},{"id":"http://arxiv.org/abs/2409.02060v2","updated":"2025-03-03T01:25:46Z","published":"2024-09-03T17:08:20Z","title":"OLMoE: Open Mixture-of-Experts Language Models","summary":"  We introduce OLMoE, a fully open, state-of-the-art language model leveraging\nsparse Mixture-of-Experts (MoE). OLMoE-1B-7B has 7 billion (B) parameters but\nuses only 1B per input token. We pretrain it on 5 trillion tokens and further\nadapt it to create OLMoE-1B-7B-Instruct. Our models outperform all available\nmodels with similar active parameters, even surpassing larger ones like\nLlama2-13B-Chat and DeepSeekMoE-16B. We present various experiments on MoE\ntraining, analyze routing in our model showing high specialization, and\nopen-source all aspects of our work: model weights, training data, code, and\nlogs.\n","authors":["Niklas Muennighoff","Luca Soldaini","Dirk Groeneveld","Kyle Lo","Jacob Morrison","Sewon Min","Weijia Shi","Pete Walsh","Oyvind Tafjord","Nathan Lambert","Yuling Gu","Shane Arora","Akshita Bhagia","Dustin Schwenk","David Wadden","Alexander Wettig","Binyuan Hui","Tim Dettmers","Douwe Kiela","Ali Farhadi","Noah A. Smith","Pang Wei Koh","Amanpreet Singh","Hannaneh Hajishirzi"],"pdf_url":"https://arxiv.org/pdf/2409.02060v2.pdf","comment":"63 pages (24 main), 36 figures, 17 tables"},{"id":"http://arxiv.org/abs/2410.01417v2","updated":"2025-03-03T00:41:36Z","published":"2024-10-02T10:58:54Z","title":"The Labyrinth of Links: Navigating the Associative Maze of Multi-modal\n  LLMs","summary":"  Multi-modal Large Language Models (MLLMs) have exhibited impressive\ncapability. However, recently many deficiencies of MLLMs have been found\ncompared to human intelligence, $\\textit{e.g.}$, hallucination. To drive the\nMLLMs study, the community dedicated efforts to building larger benchmarks with\ncomplex tasks. In this paper, we propose benchmarking an essential but usually\noverlooked intelligence: $\\textbf{association}$, a human's basic capability to\nlink observation and prior practice memory. To comprehensively investigate\nMLLM's performance on the association, we formulate the association task and\ndevise a standard benchmark based on adjective and verb semantic concepts.\nInstead of costly data annotation and curation, we propose a convenient\n$\\textbf{annotation-free}$ construction method transforming the general dataset\nfor our association tasks. Simultaneously, we devise a rigorous data refinement\nprocess to eliminate confusion in the raw dataset. Building on this database,\nwe establish three levels of association tasks: single-step, synchronous, and\nasynchronous associations. Moreover, we conduct a comprehensive investigation\ninto the MLLMs' zero-shot association capabilities, addressing multiple\ndimensions, including three distinct memory strategies, both open-source and\nclosed-source MLLMs, cutting-edge Mixture-of-Experts (MoE) models, and the\ninvolvement of human experts. Our systematic investigation shows that current\nopen-source MLLMs consistently exhibit poor capability in our association\ntasks, even the currently state-of-the-art GPT-4V(vision) also has a\nsignificant gap compared to humans. We believe our benchmark would pave the way\nfor future MLLM studies. $\\textit{Our data and code are available at:}$\nhttps://mvig-rhos.com/llm_inception.\n","authors":["Hong Li","Nanxi Li","Yuanjie Chen","Jianbin Zhu","Qinlu Guo","Cewu Lu","Yong-Lu Li"],"pdf_url":"https://arxiv.org/pdf/2410.01417v2.pdf","comment":"Accepted by ICLR 2025. Project page:\n  https://mvig-rhos.com/llm_inception"},{"id":"http://arxiv.org/abs/2405.02318v2","updated":"2025-03-03T00:38:48Z","published":"2024-04-18T00:20:48Z","title":"NL2FOL: Translating Natural Language to First-Order Logic for Logical\n  Fallacy Detection","summary":"  Translating natural language into formal language such as First-Order Logic\n(FOL) is a foundational challenge in NLP with wide-ranging applications in\nautomated reasoning, misinformation tracking, and knowledge validation. In this\npaper, we introduce Natural Language to First-Order Logic (NL2FOL), a framework\nto autoformalize natural language to FOL step by step using Large Language\nModels (LLMs). Our approach addresses key challenges in this translation\nprocess, including the integration of implicit background knowledge. By\nleveraging structured representations generated by NL2FOL, we use\nSatisfiability Modulo Theory (SMT) solvers to reason about the logical validity\nof natural language statements. We present logical fallacy detection as a case\nstudy to evaluate the efficacy of NL2FOL. Being neurosymbolic, our approach\nalso provides interpretable insights into the reasoning process and\ndemonstrates robustness without requiring model fine-tuning or labeled training\ndata. Our framework achieves strong performance on multiple datasets. On the\nLOGIC dataset, NL2FOL achieves an F1-score of 78%, while generalizing\neffectively to the LOGICCLIMATE dataset with an F1-score of 80%.\n","authors":["Abhinav Lalwani","Tasha Kim","Lovish Chopra","Christopher Hahn","Zhijing Jin","Mrinmaya Sachan"],"pdf_url":"https://arxiv.org/pdf/2405.02318v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2502.15850v2","updated":"2025-03-03T17:11:16Z","published":"2025-02-21T02:34:17Z","title":"Forecasting Frontier Language Model Agent Capabilities","summary":"  As Language Models (LMs) increasingly operate as autonomous agents,\naccurately forecasting their capabilities becomes crucial for societal\npreparedness. We evaluate six forecasting methods that predict downstream\ncapabilities of LM agents. We use \"one-step\" approaches that predict benchmark\nscores from input metrics like compute or model release date directly or\n\"two-step\" approaches that first predict an intermediate metric like the\nprincipal component of cross-benchmark performance (PC-1) and human-evaluated\ncompetitive Elo ratings. We evaluate our forecasting methods by backtesting\nthem on a dataset of 38 LMs from the OpenLLM 2 leaderboard. We then use the\nvalidated two-step approach (Release Date$\\to$Elo$\\to$Benchmark) to predict LM\nagent performance for frontier models on three benchmarks: SWE-Bench Verified\n(software development), Cybench (cybersecurity assessment), and RE-Bench (ML\nresearch engineering). Our forecast predicts that by the beginning of 2026,\nnon-specialized LM agents with low capability elicitation will reach a success\nrate of 54% on SWE-Bench Verified, while state-of-the-art LM agents will reach\nan 87% success rate. Our approach does not account for recent advances in\ninference-compute scaling and might thus be too conservative.\n","authors":["Govind Pimpale","Axel Hjmark","Jrmy Scheurer","Marius Hobbhahn"],"pdf_url":"https://arxiv.org/pdf/2502.15850v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2502.18600v2","updated":"2025-03-03T17:08:21Z","published":"2025-02-25T19:36:06Z","title":"Chain of Draft: Thinking Faster by Writing Less","summary":"  Large Language Models (LLMs) have demonstrated remarkable performance in\nsolving complex reasoning tasks through mechanisms like Chain-of-Thought (CoT)\nprompting, which emphasizes verbose, step-by-step reasoning. However, humans\ntypically employ a more efficient strategy: drafting concise intermediate\nthoughts that capture only essential information. In this work, we propose\nChain of Draft (CoD), a novel paradigm inspired by human cognitive processes,\nwhere LLMs generate minimalistic yet informative intermediate reasoning outputs\nwhile solving tasks. By reducing verbosity and focusing on critical insights,\nCoD matches or surpasses CoT in accuracy while using as little as only 7.6% of\nthe tokens, significantly reducing cost and latency across various reasoning\ntasks. Our code and data are available at\nhttps://github.com/sileix/chain-of-draft.\n","authors":["Silei Xu","Wenhao Xie","Lingxiao Zhao","Pengcheng He"],"pdf_url":"https://arxiv.org/pdf/2502.18600v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2501.04974v3","updated":"2025-03-03T17:03:49Z","published":"2025-01-09T05:06:44Z","title":"SensorQA: A Question Answering Benchmark for Daily-Life Monitoring","summary":"  With the rapid growth in sensor data, effectively interpreting and\ninterfacing with these data in a human-understandable way has become crucial.\nWhile existing research primarily focuses on learning classification models,\nfewer studies have explored how end users can actively extract useful insights\nfrom sensor data, often hindered by the lack of a proper dataset. To address\nthis gap, we introduce SensorQA, the first human-created question-answering\n(QA) dataset for long-term time-series sensor data for daily life monitoring.\nSensorQA is created by human workers and includes 5.6K diverse and practical\nqueries that reflect genuine human interests, paired with accurate answers\nderived from sensor data. We further establish benchmarks for state-of-the-art\nAI models on this dataset and evaluate their performance on typical edge\ndevices. Our results reveal a gap between current models and optimal QA\nperformance and efficiency, highlighting the need for new contributions. The\ndataset and code are available at:\nhttps://github.com/benjamin-reichman/SensorQA.\n","authors":["Benjamin Reichman","Xiaofan Yu","Lanxiang Hu","Jack Truxal","Atishay Jain","Rushil Chandrupatla","Tajana imuni Rosing","Larry Heck"],"pdf_url":"https://arxiv.org/pdf/2501.04974v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2502.05589v3","updated":"2025-03-03T16:49:18Z","published":"2025-02-08T14:28:36Z","title":"On Memory Construction and Retrieval for Personalized Conversational\n  Agents","summary":"  To deliver coherent and personalized experiences in long-term conversations,\nexisting approaches typically perform retrieval augmented response generation\nby constructing memory banks from conversation history at either the\nturn-level, session-level, or through summarization techniques.In this paper,\nwe present two key findings: (1) The granularity of memory unit matters:\nturn-level, session-level, and summarization-based methods each exhibit\nlimitations in both memory retrieval accuracy and the semantic quality of the\nretrieved content. (2) Prompt compression methods, such as LLMLingua-2, can\neffectively serve as a denoising mechanism, enhancing memory retrieval accuracy\nacross different granularities. Building on these insights, we propose SeCom, a\nmethod that constructs the memory bank at segment level by introducing a\nconversation segmentation model that partitions long-term conversations into\ntopically coherent segments, while applying compression based denoising on\nmemory units to enhance memory retrieval. Experimental results show that SeCom\nexhibits a significant performance advantage over baselines on long-term\nconversation benchmarks LOCOMO and Long-MT-Bench+. Additionally, the proposed\nconversation segmentation method demonstrates superior performance on dialogue\nsegmentation datasets such as DialSeg711, TIAGE, and SuperDialSeg.\n","authors":["Zhuoshi Pan","Qianhui Wu","Huiqiang Jiang","Xufang Luo","Hao Cheng","Dongsheng Li","Yuqing Yang","Chin-Yew Lin","H. Vicky Zhao","Lili Qiu","Jianfeng Gao"],"pdf_url":"https://arxiv.org/pdf/2502.05589v3.pdf","comment":"10 pages, 5 figures, conference"},{"id":"http://arxiv.org/abs/2502.19735v2","updated":"2025-03-03T16:44:25Z","published":"2025-02-27T03:57:00Z","title":"R1-T1: Fully Incentivizing Translation Capability in LLMs via Reasoning\n  Learning","summary":"  Despite recent breakthroughs in reasoning-enhanced large language models\n(LLMs) like DeepSeek-R1, incorporating inference-time reasoning into machine\ntranslation (MT), where human translators naturally employ structured,\nmulti-layered reasoning chain-of-thoughts (CoTs), is yet underexplored.\nExisting methods either design a fixed CoT tailored for a specific MT sub-task\n(e.g., literature translation), or rely on synthesizing CoTs unaligned with\nhumans, limiting their adaptability to diverse translation scenarios. This\npaper introduces R1-Translator (R1-T1), a novel framework to achieve\ninference-time reasoning for general MT via reinforcement learning (RL) with\nhuman-aligned CoTs comprising six common patterns. Our approach pioneers three\ninnovations: (1) extending reasoning-based translation beyond MT sub-tasks to\nsix languages and diverse tasks (e.g., legal/medical domain adaptation, idiom\nresolution); (2) formalizing six expert-curated CoT templates that mirror\nhybrid human strategies like context-aware paraphrasing and back translation;\nand (3) enabling self-evolving CoT discovery through RL. Experimental results\nindicate a steady translation performance improvement in 11 languages and 40\ntranslation directions on Flores-101 test set, especially on the languages\nunseen from training.\n","authors":["Minggui He","Yilun Liu","Shimin Tao","Yuanchang Luo","Hongyong Zeng","Chang Su","Li Zhang","Hongxia Ma","Daimeng Wei","Weibin Meng","Hao Yang","Boxing Chen","Osamu Yoshie"],"pdf_url":"https://arxiv.org/pdf/2502.19735v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2502.15823v3","updated":"2025-03-03T16:38:10Z","published":"2025-02-20T03:48:00Z","title":"InductionBench: LLMs Fail in the Simplest Complexity Class","summary":"  Large language models (LLMs) have shown remarkable improvements in reasoning\nand many existing benchmarks have been addressed by models such as o1 and o3\neither fully or partially. However, a majority of these benchmarks emphasize\ndeductive reasoning, including mathematical and coding tasks in which rules\nsuch as mathematical axioms or programming syntax are clearly defined, based on\nwhich LLMs can plan and apply these rules to arrive at a solution. In contrast,\ninductive reasoning, where one infers the underlying rules from observed data,\nremains less explored. Such inductive processes lie at the heart of scientific\ndiscovery, as they enable researchers to extract general principles from\nempirical observations. To assess whether LLMs possess this capacity, we\nintroduce InductionBench, a new benchmark designed to evaluate the inductive\nreasoning ability of LLMs. Our experimental findings reveal that even the most\nadvanced models available struggle to master the simplest complexity classes\nwithin the subregular hierarchy of functions, highlighting a notable deficiency\nin current LLMs' inductive reasoning capabilities. Coda and data are available\nhttps://github.com/Wenyueh/inductive_reasoning_benchmark.\n","authors":["Wenyue Hua","Tyler Wong","Sun Fei","Liangming Pan","Adam Jardine","William Yang Wang"],"pdf_url":"https://arxiv.org/pdf/2502.15823v3.pdf","comment":"24 pages, 7 figures"},{"id":"http://arxiv.org/abs/2410.16251v3","updated":"2025-03-03T15:37:23Z","published":"2024-10-21T17:55:54Z","title":"Can Knowledge Editing Really Correct Hallucinations?","summary":"  Large Language Models (LLMs) suffer from hallucinations, referring to the\nnon-factual information in generated content, despite their superior capacities\nacross tasks. Meanwhile, knowledge editing has been developed as a new popular\nparadigm to correct erroneous factual knowledge encoded in LLMs with the\nadvantage of avoiding retraining from scratch. However, a common issue of\nexisting evaluation datasets for knowledge editing is that they do not ensure\nthat LLMs actually generate hallucinated answers to the evaluation questions\nbefore editing. When LLMs are evaluated on such datasets after being edited by\ndifferent techniques, it is hard to directly adopt the performance to assess\nthe effectiveness of different knowledge editing methods in correcting\nhallucinations. Thus, the fundamental question remains insufficiently\nvalidated: Can knowledge editing really correct hallucinations in LLMs? We\nproposed HalluEditBench to holistically benchmark knowledge editing methods in\ncorrecting real-world hallucinations. First, we rigorously construct a massive\nhallucination dataset with 9 domains, 26 topics and more than 6,000\nhallucinations. Then, we assess the performance of knowledge editing methods in\na holistic way on five dimensions including Efficacy, Generalization,\nPortability, Locality, and Robustness. Through HalluEditBench, we have provided\nnew insights into the potentials and limitations of different knowledge editing\nmethods in correcting hallucinations, which could inspire future improvements\nand facilitate progress in the field of knowledge editing.\n","authors":["Baixiang Huang","Canyu Chen","Xiongxiao Xu","Ali Payani","Kai Shu"],"pdf_url":"https://arxiv.org/pdf/2410.16251v3.pdf","comment":"ICLR 2025. Main paper: 10 pages; total: 34 pages (including\n  appendix). The first two authors contributed equally to this work. Code,\n  data, results, and additional resources are available on the project website:\n  https://llm-editing.github.io"},{"id":"http://arxiv.org/abs/2410.19803v2","updated":"2025-03-03T15:13:10Z","published":"2024-10-16T17:59:47Z","title":"First-Person Fairness in Chatbots","summary":"  Evaluating chatbot fairness is crucial given their rapid proliferation, yet\ntypical chatbot tasks (e.g., resume writing, entertainment) diverge from the\ninstitutional decision-making tasks (e.g., resume screening) which have\ntraditionally been central to discussion of algorithmic fairness. The\nopen-ended nature and diverse use-cases of chatbots necessitate novel methods\nfor bias assessment. This paper addresses these challenges by introducing a\nscalable counterfactual approach to evaluate \"first-person fairness,\" meaning\nfairness toward chatbot users based on demographic characteristics. Our method\nemploys a Language Model as a Research Assistant (LMRA) to yield quantitative\nmeasures of harmful stereotypes and qualitative analyses of demographic\ndifferences in chatbot responses. We apply this approach to assess biases in\nsix of our language models across millions of interactions, covering sixty-six\ntasks in nine domains and spanning two genders and four races. Independent\nhuman annotations corroborate the LMRA-generated bias evaluations. This study\nrepresents the first large-scale fairness evaluation based on real-world chat\ndata. We highlight that post-training reinforcement learning techniques\nsignificantly mitigate these biases. This evaluation provides a practical\nmethodology for ongoing bias monitoring and mitigation.\n","authors":["Tyna Eloundou","Alex Beutel","David G. Robinson","Keren Gu-Lemberg","Anna-Luisa Brakman","Pamela Mishkin","Meghan Shah","Johannes Heidecke","Lilian Weng","Adam Tauman Kalai"],"pdf_url":"https://arxiv.org/pdf/2410.19803v2.pdf","comment":"In ICLR 2025, 59 pages, 27 figures"},{"id":"http://arxiv.org/abs/2411.07180v4","updated":"2025-03-03T14:56:17Z","published":"2024-11-11T17:57:30Z","title":"Gumbel Counterfactual Generation From Language Models","summary":"  Understanding and manipulating the causal generation mechanisms in language\nmodels is essential for controlling their behavior. Previous work has primarily\nrelied on techniques such as representation surgery -- e.g., model ablations or\nmanipulation of linear subspaces tied to specific concepts -- to\n\\emph{intervene} on these models. To understand the impact of interventions\nprecisely, it is useful to examine \\emph{counterfactuals} -- e.g., how a given\nsentence would have appeared had it been generated by the model following a\nspecific intervention. We highlight that counterfactual reasoning is\nconceptually distinct from interventions, as articulated in Pearl's causal\nhierarchy. Based on this observation, we propose a framework for generating\ntrue string counterfactuals by reformulating language models as a structural\nequation model using the Gumbel-max trick, which we called Gumbel\ncounterfactual generation. This reformulation allows us to model the joint\ndistribution over original strings and their counterfactuals resulting from the\nsame instantiation of the sampling noise. We develop an algorithm based on\nhindsight Gumbel sampling that allows us to infer the latent noise variables\nand generate counterfactuals of observed strings. Our experiments demonstrate\nthat the approach produces meaningful counterfactuals while at the same time\nshowing that commonly used intervention techniques have considerable undesired\nside effects.\n","authors":["Shauli Ravfogel","Anej Svete","Vsteinn Snbjarnarson","Ryan Cotterell"],"pdf_url":"https://arxiv.org/pdf/2411.07180v4.pdf","comment":"Accepted in ICLR 2025"},{"id":"http://arxiv.org/abs/2410.05864v4","updated":"2025-03-03T14:30:07Z","published":"2024-10-08T09:53:35Z","title":"From Tokens to Words: On the Inner Lexicon of LLMs","summary":"  Natural language is composed of words, but modern large language models\n(LLMs) process sub-words as input. A natural question raised by this\ndiscrepancy is whether LLMs encode words internally, and if so how. We present\nevidence that LLMs engage in an intrinsic detokenization process, where\nsub-word sequences are combined into coherent whole-word representations at\ntheir last token. Our experiments show that this process primarily takes place\nwithin the early and middle layers of the model. We further demonstrate its\nrobustness to arbitrary splits (e.g., \"cats\" to \"ca\" and \"ts\"), typos, and\nimportantly-to out-of-vocabulary words: when feeding the last token internal\nrepresentations of such words to the model as input, it can \"understand\" them\nas the complete word despite never seeing such representations as input during\ntraining. Our findings suggest that LLMs maintain a latent vocabulary beyond\nthe tokenizer's scope. These insights provide a practical, finetuning-free\napplication for expanding the vocabulary of pre-trained models. By enabling the\naddition of new vocabulary words, we reduce input length and inference\niterations, which reduces both space and model latency, with little to no loss\nin model accuracy.\n","authors":["Guy Kaplan","Matanel Oren","Yuval Reif","Roy Schwartz"],"pdf_url":"https://arxiv.org/pdf/2410.05864v4.pdf","comment":"Accepted to the International Conference on Learning Representations\n  (ICLR) 2025"},{"id":"http://arxiv.org/abs/2407.10944v2","updated":"2025-03-03T13:41:46Z","published":"2024-07-15T17:41:34Z","title":"Naturally Occurring Feedback is Common, Extractable and Useful","summary":"  Human feedback data is a critical component in developing language models.\nHowever, collecting this feedback is costly and ultimately not scalable.\nInspired by the way human interlocutors provide spontaneous unsolicited\nfeedback to each other, we propose to extract feedback that users naturally\ninclude when interacting with chat models. We manually annotated conversations\nto confirm the presence of naturally occurring feedback in a standard corpus,\nfinding that as much as 30% of the chats include explicit feedback. Comparing\nto older datasets, we find that naturally occurring feedback is more prevalent\nin recent conversation datasets, suggesting that more than ever, naturally\noccurring feedback can serve as a valuable resource for feedback data. We\npropose a method for automatically extracting this feedback, and apply it to\nover 1M conversations to obtain hundreds of thousands of feedback samples. The\nextracted feedback shows promise: training with it improves over baseline\nmodels and enhances model alignment to human preferences.\n","authors":["Shachar Don-Yehiya","Leshem Choshen","Omri Abend"],"pdf_url":"https://arxiv.org/pdf/2407.10944v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2405.18915v2","updated":"2025-03-03T13:25:36Z","published":"2024-05-29T09:17:46Z","title":"Towards Better Chain-of-Thought: A Reflection on Effectiveness and\n  Faithfulness","summary":"  Chain-of-thought (CoT) prompting demonstrates varying performance under\ndifferent reasoning tasks. Previous work attempts to evaluate it but falls\nshort in providing an in-depth analysis of patterns that influence the CoT. In\nthis paper, we study the CoT performance from the perspective of effectiveness\nand faithfulness. For the former, we identify key factors that influence CoT\neffectiveness on performance improvement, including problem difficulty,\ninformation gain, and information flow. For the latter, we interpret the\nunfaithful CoT issue by conducting a joint analysis of the information\ninteraction among the question, CoT, and answer. The result demonstrates that,\nwhen the LLM predicts answers, it can recall correct information missing in the\nCoT from the question, leading to the problem. Finally, we propose a novel\nalgorithm to mitigate this issue, in which we recall extra information from the\nquestion to enhance the CoT generation and evaluate CoTs based on their\ninformation gain. Extensive experiments demonstrate that our approach enhances\nboth the faithfulness and effectiveness of CoT.\n","authors":["Jiachun Li","Pengfei Cao","Yubo Chen","Jiexin Xu","Huaijun Li","Xiaojian Jiang","Kang Liu","Jun Zhao"],"pdf_url":"https://arxiv.org/pdf/2405.18915v2.pdf","comment":"18 pages, under review"},{"id":"http://arxiv.org/abs/2410.03415v2","updated":"2025-03-03T23:46:14Z","published":"2024-10-04T13:25:32Z","title":"Surgical, Cheap, and Flexible: Mitigating False Refusal in Language\n  Models via Single Vector Ablation","summary":"  Training a language model to be both helpful and harmless requires careful\ncalibration of refusal behaviours: Models should refuse to follow malicious\ninstructions or give harmful advice (e.g.\"how do I kill someone?\"), but they\nshould not refuse safe requests, even if they superficially resemble unsafe\nones (e.g. \"how do I kill a Python process?\"). Avoiding such false refusal, as\nprior work has shown, is challenging even for highly-capable language models.\nIn this paper, we propose a simple and surgical method for mitigating false\nrefusal in language models via single vector ablation. For a given model, we\nextract a false refusal vector and show that ablating this vector reduces false\nrefusal rate while preserving the model's safety and general capabilities. We\nalso show that our approach can be used for fine-grained calibration of model\nsafety. Our approach is training-free and model-agnostic, making it useful for\nmitigating the problem of false refusal in current and future language models.\n","authors":["Xinpeng Wang","Chengzhi Hu","Paul Rttger","Barbara Plank"],"pdf_url":"https://arxiv.org/pdf/2410.03415v2.pdf","comment":"ICLR 2025"},{"id":"http://arxiv.org/abs/2503.02130v1","updated":"2025-03-03T23:35:23Z","published":"2025-03-03T23:35:23Z","title":"Forgetting Transformer: Softmax Attention with a Forget Gate","summary":"  An essential component of modern recurrent sequence models is the forget\ngate. While Transformers do not have an explicit recurrent form, we show that a\nforget gate can be naturally incorporated into Transformers by down-weighting\nthe unnormalized attention scores in a data-dependent way. We name this\nattention mechanism the Forgetting Attention and the resulting model the\nForgetting Transformer (FoX). We show that FoX outperforms the Transformer on\nlong-context language modeling, length extrapolation, and short-context\ndownstream tasks, while performing on par with the Transformer on long-context\ndownstream tasks. Moreover, it is compatible with the FlashAttention algorithm\nand does not require any positional embeddings. Several analyses, including the\nneedle-in-the-haystack test, show that FoX also retains the Transformer's\nsuperior long-context capabilities over recurrent sequence models such as\nMamba-2, HGRN2, and DeltaNet. We also introduce a \"Pro\" block design that\nincorporates some common architectural components in recurrent sequence models\nand find it significantly improves the performance of both FoX and the\nTransformer. Our code is available at\nhttps://github.com/zhixuan-lin/forgetting-transformer.\n","authors":["Zhixuan Lin","Evgenii Nikishin","Xu Owen He","Aaron Courville"],"pdf_url":"https://arxiv.org/pdf/2503.02130v1.pdf","comment":"Published as a conference paper at ICLR 2025"},{"id":"http://arxiv.org/abs/2502.00585v3","updated":"2025-03-03T23:19:39Z","published":"2025-02-01T22:44:46Z","title":"Converting Transformers into DGNNs Form","summary":"  Recent advances in deep learning have established Transformer architectures\nas the predominant modeling paradigm. Central to the success of Transformers is\nthe self-attention mechanism, which scores the similarity between query and key\nmatrices to modulate a value matrix. This operation bears striking similarities\nto digraph convolution, prompting an investigation into whether digraph\nconvolution could serve as an alternative to self-attention. In this study, we\nformalize this concept by introducing a synthetic unitary digraph convolution\nbased on the digraph Fourier transform. The resulting model, which we term\nConverter, effectively converts a Transformer into a Directed Graph Neural\nNetwork (DGNN) form. We have tested Converter on Long-Range Arena benchmark,\nlong document classification, and DNA sequence-based taxonomy classification.\nOur experimental results demonstrate that Converter achieves superior\nperformance while maintaining computational efficiency and architectural\nsimplicity, which establishes it as a lightweight yet powerful Transformer\nvariant.\n","authors":["Jie Zhang","Mao-Hsuan Mao","Bo-Wei Chiu","Min-Te Sun"],"pdf_url":"https://arxiv.org/pdf/2502.00585v3.pdf","comment":"21 pages, 3 figures, and 8 tables; pseudocode improved"},{"id":"http://arxiv.org/abs/2408.01262v5","updated":"2025-03-03T22:45:57Z","published":"2024-08-02T13:35:11Z","title":"RAGEval: Scenario Specific RAG Evaluation Dataset Generation Framework","summary":"  Retrieval-Augmented Generation (RAG) is a powerful approach that enables\nlarge language models (LLMs) to incorporate external knowledge. However,\nevaluating the effectiveness of RAG systems in specialized scenarios remains\nchallenging due to the high costs of data construction and the lack of suitable\nevaluation metrics. This paper introduces RAGEval, a framework designed to\nassess RAG systems across diverse scenarios by generating high-quality\ndocuments, questions, answers, and references through a schema-based pipeline.\nWith a focus on factual accuracy, we propose three novel metrics: Completeness,\nHallucination, and Irrelevance to evaluate LLM generated responses rigorously.\nExperimental results show that RAGEval outperforms zero-shot and one-shot\nmethods in terms of clarity, safety, conformity, and richness of generated\nsamples. Furthermore, the use of LLMs for scoring the proposed metrics\ndemonstrates a high level of consistency with human evaluations. RAGEval\nestablishes a new paradigm for evaluating RAG systems in real-world\napplications. The code and dataset are released at\nhttps://github.com/OpenBMB/RAGEval.\n","authors":["Kunlun Zhu","Yifan Luo","Dingling Xu","Yukun Yan","Zhenghao Liu","Shi Yu","Ruobing Wang","Shuo Wang","Yishan Li","Nan Zhang","Xu Han","Zhiyuan Liu","Maosong Sun"],"pdf_url":"https://arxiv.org/pdf/2408.01262v5.pdf","comment":"https://github.com/OpenBMB/RAGEval"},{"id":"http://arxiv.org/abs/2503.02103v1","updated":"2025-03-03T22:41:25Z","published":"2025-03-03T22:41:25Z","title":"Superficial Self-Improved Reasoners Benefit from Model Merging","summary":"  As scaled language models (LMs) approach human-level reasoning capabilities,\nself-improvement emerges as a solution to synthesizing high-quality data\ncorpus. While previous research has identified model collapse as a risk in\nself-improvement, where model outputs become increasingly deterministic, we\ndiscover a more fundamental challenge: the superficial self-improved reasoners\nphenomenon. In particular, our analysis reveals that even when LMs show\nimproved in-domain (ID) reasoning accuracy, they actually compromise their\ngeneralized reasoning capabilities on out-of-domain (OOD) tasks due to\nmemorization rather than genuine. Through a systematic investigation of LM\narchitecture, we discover that during self-improvement, LM weight updates are\nconcentrated in less reasoning-critical layers, leading to superficial\nlearning. To address this, we propose Iterative Model Merging (IMM), a method\nthat strategically combines weights from original and self-improved models to\npreserve generalization while incorporating genuine reasoning improvements. Our\napproach effectively mitigates both LM collapse and superficial learning,\nmoving towards more stable self-improving systems.\n","authors":["Xiangchi Yuan","Chunhui Zhang","Zheyuan Liu","Dachuan Shi","Soroush Vosoughi","Wenke Lee"],"pdf_url":"https://arxiv.org/pdf/2503.02103v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.02102v1","updated":"2025-03-03T22:37:03Z","published":"2025-03-03T22:37:03Z","title":"Provable Benefits of Task-Specific Prompts for In-context Learning","summary":"  The in-context learning capabilities of modern language models have motivated\na deeper mathematical understanding of sequence models. A line of recent work\nhas shown that linear attention models can emulate projected gradient descent\niterations to implicitly learn the task vector from the data provided in the\ncontext window. In this work, we consider a novel setting where the global task\ndistribution can be partitioned into a union of conditional task distributions.\nWe then examine the use of task-specific prompts and prediction heads for\nlearning the prior information associated with the conditional task\ndistribution using a one-layer attention model. Our results on loss landscape\nshow that task-specific prompts facilitate a covariance-mean decoupling where\nprompt-tuning explains the conditional mean of the distribution whereas the\nvariance is learned/explained through in-context learning. Incorporating\ntask-specific head further aids this process by entirely decoupling estimation\nof mean and variance components. This covariance-mean perspective similarly\nexplains how jointly training prompt and attention weights can provably help\nover fine-tuning after pretraining.\n","authors":["Xiangyu Chang","Yingcong Li","Muti Kara","Samet Oymak","Amit K. Roy-Chowdhury"],"pdf_url":"https://arxiv.org/pdf/2503.02102v1.pdf","comment":"Proceedings of the 28th International Conference on Artificial\n  Intelligence and Statistics (AISTATS) 2025"},{"id":"http://arxiv.org/abs/2410.08968v2","updated":"2025-03-03T22:10:04Z","published":"2024-10-11T16:38:01Z","title":"Controllable Safety Alignment: Inference-Time Adaptation to Diverse\n  Safety Requirements","summary":"  The current paradigm for safety alignment of large language models (LLMs)\nfollows a one-size-fits-all approach: the model refuses to interact with any\ncontent deemed unsafe by the model provider. This approach lacks flexibility in\nthe face of varying social norms across cultures and regions. In addition,\nusers may have diverse safety needs, making a model with static safety\nstandards too restrictive to be useful, as well as too costly to be re-aligned.\n  We propose Controllable Safety Alignment (CoSA), a framework designed to\nadapt models to diverse safety requirements without re-training. Instead of\naligning a fixed model, we align models to follow safety configs -- free-form\nnatural language descriptions of the desired safety behaviors -- that are\nprovided as part of the system prompt. To adjust model safety behavior,\nauthorized users only need to modify such safety configs at inference time. To\nenable that, we propose CoSAlign, a data-centric method for aligning LLMs to\neasily adapt to diverse safety configs. Furthermore, we devise a novel\ncontrollability evaluation protocol that considers both helpfulness and\nconfigured safety, summarizing them into CoSA-Score, and construct CoSApien, a\nhuman-authored benchmark that consists of real-world LLM use cases with diverse\nsafety requirements and corresponding evaluation prompts. We show that CoSAlign\nleads to substantial gains of controllability over strong baselines including\nin-context alignment. Our framework encourages better representation and\nadaptation to pluralistic human values in LLMs, and thereby increasing their\npracticality.\n","authors":["Jingyu Zhang","Ahmed Elgohary","Ahmed Magooda","Daniel Khashabi","Benjamin Van Durme"],"pdf_url":"https://arxiv.org/pdf/2410.08968v2.pdf","comment":"ICLR 2025 camera ready"},{"id":"http://arxiv.org/abs/2503.02082v1","updated":"2025-03-03T22:03:48Z","published":"2025-03-03T22:03:48Z","title":"Twenty Years of Personality Computing: Threats, Challenges and Future\n  Directions","summary":"  Personality Computing is a field at the intersection of Personality\nPsychology and Computer Science. Started in 2005, research in the field\nutilizes computational methods to understand and predict human personality\ntraits. The expansion of the field has been very rapid and, by analyzing\ndigital footprints (text, images, social media, etc.), it helped to develop\nsystems that recognize and even replicate human personality. While offering\npromising applications in talent recruiting, marketing and healthcare, the\nethical implications of Personality Computing are significant. Concerns include\ndata privacy, algorithmic bias, and the potential for manipulation by\npersonality-aware Artificial Intelligence. This paper provides an overview of\nthe field, explores key methodologies, discusses the challenges and threats,\nand outlines potential future directions for responsible development and\ndeployment of Personality Computing technologies.\n","authors":["Fabio Celli","Aleksandar Kartelj","Miljan orevi","Derwin Suhartono","Vladimir Filipovi","Veljko Milutinovi","Georgios Spathoulas","Alessandro Vinciarelli","Michal Kosinski","Bruno Lepri"],"pdf_url":"https://arxiv.org/pdf/2503.02082v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.02080v1","updated":"2025-03-03T21:59:01Z","published":"2025-03-03T21:59:01Z","title":"Linear Representations of Political Perspective Emerge in Large Language\n  Models","summary":"  Large language models (LLMs) have demonstrated the ability to generate text\nthat realistically reflects a range of different subjective human perspectives.\nThis paper studies how LLMs are seemingly able to reflect more liberal versus\nmore conservative viewpoints among other political perspectives in American\npolitics. We show that LLMs possess linear representations of political\nperspectives within activation space, wherein more similar perspectives are\nrepresented closer together. To do so, we probe the attention heads across the\nlayers of three open transformer-based LLMs (\\texttt{Llama-2-7b-chat},\n\\texttt{Mistral-7b-instruct}, \\texttt{Vicuna-7b}). We first prompt models to\ngenerate text from the perspectives of different U.S.~lawmakers. We then\nidentify sets of attention heads whose activations linearly predict those\nlawmakers' DW-NOMINATE scores, a widely-used and validated measure of political\nideology. We find that highly predictive heads are primarily located in the\nmiddle layers, often speculated to encode high-level concepts and tasks. Using\nprobes only trained to predict lawmakers' ideology, we then show that the same\nprobes can predict measures of news outlets' slant from the activations of\nmodels prompted to simulate text from those news outlets. These linear probes\nallow us to visualize, interpret, and monitor ideological stances implicitly\nadopted by an LLM as it generates open-ended responses. Finally, we demonstrate\nthat by applying linear interventions to these attention heads, we can steer\nthe model outputs toward a more liberal or conservative stance. Overall, our\nresearch suggests that LLMs possess a high-level linear representation of\nAmerican political ideology and that by leveraging recent advances in\nmechanistic interpretability, we can identify, monitor, and steer the\nsubjective perspective underlying generated text.\n","authors":["Junsol Kim","James Evans","Aaron Schein"],"pdf_url":"https://arxiv.org/pdf/2503.02080v1.pdf","comment":"Published as a conference paper at ICLR 2025"},{"id":"http://arxiv.org/abs/2503.02078v1","updated":"2025-03-03T21:58:12Z","published":"2025-03-03T21:58:12Z","title":"Superscopes: Amplifying Internal Feature Representations for Language\n  Model Interpretation","summary":"  Understanding and interpreting the internal representations of large language\nmodels (LLMs) remains an open challenge. Patchscopes introduced a method for\nprobing internal activations by patching them into new prompts, prompting\nmodels to self-explain their hidden representations. We introduce Superscopes,\na technique that systematically amplifies superposed features in MLP outputs\n(multilayer perceptron) and hidden states before patching them into new\ncontexts. Inspired by the \"features as directions\" perspective and the\nClassifier-Free Guidance (CFG) approach from diffusion models, Superscopes\namplifies weak but meaningful features, enabling the interpretation of internal\nrepresentations that previous methods failed to explain-all without requiring\nadditional training. This approach provides new insights into how LLMs build\ncontext and represent complex concepts, further advancing mechanistic\ninterpretability.\n","authors":["Jonathan Jacobi","Gal Niv"],"pdf_url":"https://arxiv.org/pdf/2503.02078v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.23825v2","updated":"2025-03-03T21:51:52Z","published":"2024-10-31T11:14:12Z","title":"GlotCC: An Open Broad-Coverage CommonCrawl Corpus and Pipeline for\n  Minority Languages","summary":"  The need for large text corpora has increased with the advent of pretrained\nlanguage models and, in particular, the discovery of scaling laws for these\nmodels. Most available corpora have sufficient data only for languages with\nlarge dominant communities. However, there is no corpus available that (i)\ncovers a wide range of minority languages; (ii) is generated by an open-source\nreproducible pipeline; and (iii) is rigorously cleaned from noise, making it\ntrustworthy to use. We present GlotCC, a clean, document-level, 2TB general\ndomain corpus derived from CommonCrawl, covering more than 1000 languages. We\nmake GlotCC and the system used to generate it - including the pipeline,\nlanguage identification model, and filters - available to the research\ncommunity. Corpus v. 1.0 https://huggingface.co/datasets/cis-lmu/GlotCC-v1,\nPipeline v. 3.0 https://github.com/cisnlp/GlotCC.\n","authors":["Amir Hossein Kargaran","Franois Yvon","Hinrich Schtze"],"pdf_url":"https://arxiv.org/pdf/2410.23825v2.pdf","comment":"NeurIPS 2024"},{"id":"http://arxiv.org/abs/2406.09519v3","updated":"2025-03-03T21:19:42Z","published":"2024-06-13T18:12:01Z","title":"Talking Heads: Understanding Inter-layer Communication in Transformer\n  Language Models","summary":"  Although it is known that transformer language models (LMs) pass features\nfrom early layers to later layers, it is not well understood how this\ninformation is represented and routed by the model. We analyze a mechanism used\nin two LMs to selectively inhibit items in a context in one task, and find that\nit underlies a commonly used abstraction across many context-retrieval\nbehaviors. Specifically, we find that models write into low-rank subspaces of\nthe residual stream to represent features which are then read out by later\nlayers, forming low-rank communication channels (Elhage et al., 2021) between\nlayers. A particular 3D subspace in model activations in GPT-2 can be traversed\nto positionally index items in lists, and we show that this mechanism can\nexplain an otherwise arbitrary-seeming sensitivity of the model to the order of\nitems in the prompt. That is, the model has trouble copying the correct\ninformation from context when many items ``crowd\" this limited space. By\ndecomposing attention heads with the Singular Value Decomposition (SVD), we\nfind that previously described interactions between heads separated by one or\nmore layers can be predicted via analysis of their weight matrices alone. We\nshow that it is possible to manipulate the internal model representations as\nwell as edit model weights based on the mechanism we discover in order to\nsignificantly improve performance on our synthetic Laundry List task, which\nrequires recall from a list, often improving task accuracy by over 20%. Our\nanalysis reveals a surprisingly intricate interpretable structure learned from\nlanguage model pretraining, and helps us understand why sophisticated LMs\nsometimes fail in simple domains, facilitating future analysis of more complex\nbehaviors.\n","authors":["Jack Merullo","Carsten Eickhoff","Ellie Pavlick"],"pdf_url":"https://arxiv.org/pdf/2406.09519v3.pdf","comment":"Neurips 2024"},{"id":"http://arxiv.org/abs/2503.02057v1","updated":"2025-03-03T21:15:57Z","published":"2025-03-03T21:15:57Z","title":"Hebbian learning the local structure of language","summary":"  Learning in the brain is local and unsupervised (Hebbian). We derive the\nfoundations of an effective human language model inspired by these microscopic\nconstraints. It has two parts: (1) a hierarchy of neurons which learns to\ntokenize words from text (whichiswhatyoudowhenyoureadthis); and (2) additional\nneurons which bind the learned symanticless patterns of the tokenizer into a\nsymanticful token (an embedding). The model permits continuous parallel\nlearning without forgetting; and is a powerful tokenizer which performs\nrenormalization group. This allows it to exploit redundancy, such that it\ngenerates tokens which are always decomposable into a basis set (e.g an\nalphabet), and can mix features learned from multiple languages. We find that\nthe structure of this model allows it to learn a natural language morphology\nWITHOUT data. The language data generated by this model predicts the correct\ndistribution of word-forming patterns observed in real languages, and further\ndemonstrates why microscopically human speech is broken up into words. This\nmodel provides the basis for understanding the microscopic origins of language\nand human creativity.\n","authors":["P. Myles Eugenio"],"pdf_url":"https://arxiv.org/pdf/2503.02057v1.pdf","comment":"10 figures, 14 pages"},{"id":"http://arxiv.org/abs/2501.17148v3","updated":"2025-03-03T21:15:30Z","published":"2025-01-28T18:51:24Z","title":"AxBench: Steering LLMs? Even Simple Baselines Outperform Sparse\n  Autoencoders","summary":"  Fine-grained steering of language model outputs is essential for safety and\nreliability. Prompting and finetuning are widely used to achieve these goals,\nbut interpretability researchers have proposed a variety of\nrepresentation-based techniques as well, including sparse autoencoders (SAEs),\nlinear artificial tomography, supervised steering vectors, linear probes, and\nrepresentation finetuning. At present, there is no benchmark for making direct\ncomparisons between these proposals. Therefore, we introduce AxBench, a\nlarge-scale benchmark for steering and concept detection, and report\nexperiments on Gemma-2-2B and 9B. For steering, we find that prompting\noutperforms all existing methods, followed by finetuning. For concept\ndetection, representation-based methods such as difference-in-means, perform\nthe best. On both evaluations, SAEs are not competitive. We introduce a novel\nweakly-supervised representational method (Rank-1 Representation Finetuning;\nReFT-r1), which is competitive on both tasks while providing the\ninterpretability advantages that prompting lacks. Along with AxBench, we train\nand publicly release SAE-scale feature dictionaries for ReFT-r1 and DiffMean.\n","authors":["Zhengxuan Wu","Aryaman Arora","Atticus Geiger","Zheng Wang","Jing Huang","Dan Jurafsky","Christopher D. Manning","Christopher Potts"],"pdf_url":"https://arxiv.org/pdf/2501.17148v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.02056v1","updated":"2025-03-03T21:14:14Z","published":"2025-03-03T21:14:14Z","title":"CareerBERT: Matching Resumes to ESCO Jobs in a Shared Embedding Space\n  for Generic Job Recommendations","summary":"  The rapidly evolving labor market, driven by technological advancements and\neconomic shifts, presents significant challenges for traditional job matching\nand consultation services. In response, we introduce an advanced support tool\nfor career counselors and job seekers based on CareerBERT, a novel approach\nthat leverages the power of unstructured textual data sources, such as resumes,\nto provide more accurate and comprehensive job recommendations. In contrast to\nprevious approaches that primarily focus on job recommendations based on a\nfixed set of concrete job advertisements, our approach involves the creation of\na corpus that combines data from the European Skills, Competences, and\nOccupations (ESCO) taxonomy and EURopean Employment Services (EURES) job\nadvertisements, ensuring an up-to-date and well-defined representation of\ngeneral job titles in the labor market. Our two-step evaluation approach,\nconsisting of an application-grounded evaluation using EURES job advertisements\nand a human-grounded evaluation using real-world resumes and Human Resources\n(HR) expert feedback, provides a comprehensive assessment of CareerBERT's\nperformance. Our experimental results demonstrate that CareerBERT outperforms\nboth traditional and state-of-the-art embedding approaches while showing robust\neffectiveness in human expert evaluations. These results confirm the\neffectiveness of CareerBERT in supporting career consultants by generating\nrelevant job recommendations based on resumes, ultimately enhancing the\nefficiency of job consultations and expanding the perspectives of job seekers.\nThis research contributes to the field of NLP and job recommendation systems,\noffering valuable insights for both researchers and practitioners in the domain\nof career consulting and job matching.\n","authors":["Julian Rosenberger","Lukas Wolfrum","Sven Weinzierl","Mathias Kraus","Patrick Zschech"],"pdf_url":"https://arxiv.org/pdf/2503.02056v1.pdf","comment":"Accepted at Expert Systems with Applications. In Press, see\n  https://doi.org/10.1016/j.eswa.2025.127043"},{"id":"http://arxiv.org/abs/2503.02053v1","updated":"2025-03-03T21:11:13Z","published":"2025-03-03T21:11:13Z","title":"EPEE: Towards Efficient and Effective Foundation Models in Biomedicine","summary":"  Foundation models, including language models, e.g., GPT, and vision models,\ne.g., CLIP, have significantly advanced numerous biomedical tasks. Despite\nthese advancements, the high inference latency and the \"overthinking\" issues in\nmodel inference impair the efficiency and effectiveness of foundation models,\nthus limiting their application in real-time clinical settings. To address\nthese challenges, we proposed EPEE (Entropy- and Patience-based Early Exiting),\na novel hybrid strategy designed to improve the inference efficiency of\nfoundation models. The core idea was to leverage the strengths of entropy-based\nand patience-based early exiting methods to overcome their respective\nweaknesses. To evaluate EPEE, we conducted experiments on three core biomedical\ntasks-classification, relation extraction, and event extraction-using four\nfoundation models (BERT, ALBERT, GPT-2, and ViT) across twelve datasets,\nincluding clinical notes and medical images. The results showed that EPEE\nsignificantly reduced inference time while maintaining or improving accuracy,\ndemonstrating its adaptability to diverse datasets and tasks. EPEE addressed\ncritical barriers to deploying foundation models in healthcare by balancing\nefficiency and effectiveness. It potentially provided a practical solution for\nreal-time clinical decision-making with foundation models, supporting reliable\nand efficient workflows.\n","authors":["Zaifu Zhan","Shuang Zhou","Huixue Zhou","Zirui Liu","Rui Zhang"],"pdf_url":"https://arxiv.org/pdf/2503.02053v1.pdf","comment":"Submitted to npj Digital Medicine"},{"id":"http://arxiv.org/abs/2402.00179v2","updated":"2025-03-03T21:05:13Z","published":"2024-01-31T21:14:01Z","title":"De-identification is not enough: a comparison between de-identified and\n  synthetic clinical notes","summary":"  For sharing privacy-sensitive data, de-identification is commonly regarded as\nadequate for safeguarding privacy. Synthetic data is also being considered as a\nprivacy-preserving alternative. Recent successes with numerical and tabular\ndata generative models and the breakthroughs in large generative language\nmodels raise the question of whether synthetically generated clinical notes\ncould be a viable alternative to real notes for research purposes. In this\nwork, we demonstrated that (i) de-identification of real clinical notes does\nnot protect records against a membership inference attack, (ii) proposed a\nnovel approach to generate synthetic clinical notes using the current\nstate-of-the-art large language models, (iii) evaluated the performance of the\nsynthetically generated notes in a clinical domain task, and (iv) proposed a\nway to mount a membership inference attack where the target model is trained\nwith synthetic data. We observed that when synthetically generated notes\nclosely match the performance of real data, they also exhibit similar privacy\nconcerns to the real data. Whether other approaches to synthetically generated\nclinical notes could offer better trade-offs and become a better alternative to\nsensitive real notes warrants further investigation.\n","authors":["Atiquer Rahman Sarkar","Yao-Shun Chuang","Noman Mohammed","Xiaoqian Jiang"],"pdf_url":"https://arxiv.org/pdf/2402.00179v2.pdf","comment":"https://www.nature.com/articles/s41598-024-81170-y"},{"id":"http://arxiv.org/abs/2409.14494v2","updated":"2025-03-03T20:35:03Z","published":"2024-09-13T19:14:18Z","title":"CPT-Boosted Wav2vec2.0: Towards Noise Robust Speech Recognition for\n  Classroom Environments","summary":"  Creating Automatic Speech Recognition (ASR) systems that are robust and\nresilient to classroom conditions is paramount to the development of AI tools\nto aid teachers and students. In this work, we study the efficacy of continued\npretraining (CPT) in adapting Wav2vec2.0 to the classroom domain. We show that\nCPT is a powerful tool in that regard and reduces the Word Error Rate (WER) of\nWav2vec2.0-based models by upwards of 10%. More specifically, CPT improves the\nmodel's robustness to different noises, microphones and classroom conditions.\n","authors":["Ahmed Adel Attia","Dorottya Demszky","Tolulope Ogunremi","Jing Liu","Carol Espy-Wilson"],"pdf_url":"https://arxiv.org/pdf/2409.14494v2.pdf","comment":"arXiv admin note: substantial text overlap with arXiv:2405.13018"}],"Computer Vision and Pattern Recognition":[{"id":"http://arxiv.org/abs/2501.09695v2","updated":"2025-03-03T14:48:45Z","published":"2025-01-16T17:48:03Z","title":"Mitigating Hallucinations in Large Vision-Language Models via DPO:\n  On-Policy Data Hold the Key","summary":"  Hallucination remains a major challenge for Large Vision-Language Models\n(LVLMs). Direct Preference Optimization (DPO) has gained increasing attention\nas a simple solution to hallucination issues. It directly learns from\nconstructed preference pairs that reflect the severity of hallucinations in\nresponses to the same prompt and image. Nonetheless, different data\nconstruction methods in existing works bring notable performance variations. We\nidentify a crucial factor here: outcomes are largely contingent on whether the\nconstructed data aligns on-policy w.r.t the initial (reference) policy of DPO.\nTheoretical analysis suggests that learning from off-policy data is impeded by\nthe presence of KL-divergence between the updated policy and the reference\npolicy. From the perspective of dataset distribution, we systematically\nsummarize the inherent flaws in existing algorithms that employ DPO to address\nhallucination issues. To alleviate the problems, we propose On-Policy Alignment\n(OPA)-DPO framework, which uniquely leverages expert feedback to correct\nhallucinated responses and aligns both the original and expert-revised\nresponses in an on-policy manner. Notably, with only 4.8k data, OPA-DPO\nachieves an additional reduction in the hallucination rate of LLaVA-1.5-7B:\n13.26% on the AMBER benchmark and 5.39% on the Object-Hal benchmark, compared\nto the previous SOTA algorithm trained with 16k samples. Our implementation is\navailable at https://github.com/zhyang2226/OPA-DPO.\n","authors":["Zhihe Yang","Xufang Luo","Dongqi Han","Yunjian Xu","Dongsheng Li"],"pdf_url":"https://arxiv.org/pdf/2501.09695v2.pdf","comment":"Accepted by CVPR 2025"},{"id":"http://arxiv.org/abs/2412.07487v2","updated":"2025-03-03T14:04:23Z","published":"2024-12-10T13:12:32Z","title":"Stereo Hand-Object Reconstruction for Human-to-Robot Handover","summary":"  Jointly estimating hand and object shape facilitates the grasping task in\nhuman-to-robot handovers. However, relying on hand-crafted prior knowledge\nabout the geometric structure of the object fails when generalising to unseen\nobjects, and depth sensors fail to detect transparent objects such as drinking\nglasses. In this work, we propose a stereo-based method for hand-object\nreconstruction that combines single-view reconstructions probabilistically to\nform a coherent stereo reconstruction. We learn 3D shape priors from a large\nsynthetic hand-object dataset to ensure that our method is generalisable, and\nuse RGB inputs to better capture transparent objects. We show that our method\nreduces the object Chamfer distance compared to existing RGB based hand-object\nreconstruction methods on single view and stereo settings. We process the\nreconstructed hand-object shape with a projection-based outlier removal step\nand use the output to guide a human-to-robot handover pipeline with\nwide-baseline stereo RGB cameras. Our hand-object reconstruction enables a\nrobot to successfully receive a diverse range of household objects from the\nhuman.\n","authors":["Yik Lung Pang","Alessio Xompero","Changjae Oh","Andrea Cavallaro"],"pdf_url":"https://arxiv.org/pdf/2412.07487v2.pdf","comment":"8 pages, 9 figures, 1 table"},{"id":"http://arxiv.org/abs/2412.02993v2","updated":"2025-03-03T13:59:01Z","published":"2024-12-04T03:19:43Z","title":"EchoONE: Segmenting Multiple echocardiography Planes in One Model","summary":"  In clinical practice of echocardiography examinations, multiple planes\ncontaining the heart structures of different view are usually required in\nscreening, diagnosis and treatment of cardiac disease. AI models for\nechocardiography have to be tailored for each specific plane due to the\ndramatic structure differences, thus resulting in repetition development and\nextra complexity. Effective solution for such a multi-plane segmentation (MPS)\nproblem is highly demanded for medical images, yet has not been well\ninvestigated. In this paper, we propose a novel solution, EchoONE, for this\nproblem with a SAM-based segmentation architecture, a prior-composable mask\nlearning (PC-Mask) module for semantic-aware dense prompt generation, and a\nlearnable CNN-branch with a simple yet effective local feature fusion and\nadaption (LFFA) module for SAM adapting. We extensively evaluated our method on\nmultiple internal and external echocardiography datasets, and achieved\nconsistently state-of-the-art performance for multi-source datasets with\ndifferent heart planes. This is the first time that the MPS problem is solved\nin one model for echocardiography data. The code will be available at\nhttps://github.com/a2502503/EchoONE.\n","authors":["Jiongtong Hu","Wei Zhuo","Jun Cheng","Yingying Liu","Wufeng Xue","Dong Ni"],"pdf_url":"https://arxiv.org/pdf/2412.02993v2.pdf","comment":"Accepted by CVPR 2025"},{"id":"http://arxiv.org/abs/2502.18858v2","updated":"2025-03-03T13:38:50Z","published":"2025-02-26T05:59:45Z","title":"Evaluating Intelligence via Trial and Error","summary":"  Intelligence is a crucial trait for species to find solutions within a\nlimited number of trial-and-error attempts. Building on this idea, we introduce\nSurvival Game as a framework to evaluate intelligence based on the number of\nfailed attempts in a trial-and-error process. Fewer failures indicate higher\nintelligence. When the expectation and variance of failure counts are both\nfinite, it signals the ability to consistently find solutions to new\nchallenges, which we define as the Autonomous Level of intelligence. Using\nSurvival Game, we comprehensively evaluate existing AI systems. Our results\nshow that while AI systems achieve the Autonomous Level in simple tasks, they\nare still far from it in more complex tasks, such as vision, search,\nrecommendation, and language. While scaling current AI technologies might help,\nthis would come at an astronomical cost. Projections suggest that achieving the\nAutonomous Level for general tasks would require $10^{26}$ parameters. To put\nthis into perspective, loading such a massive model requires so many H100 GPUs\nthat their total value is $10^{7}$ times that of Apple Inc.'s market value.\nEven with Moore's Law, supporting such a parameter scale would take $70$ years.\nThis staggering cost highlights the complexity of human tasks and the\ninadequacies of current AI technologies. To further investigate this\nphenomenon, we conduct a theoretical analysis of Survival Game and its\nexperimental results. Our findings suggest that human tasks possess a\ncriticality property. As a result, Autonomous Level requires a deep\nunderstanding of the task's underlying mechanisms. Current AI systems, however,\ndo not fully grasp these mechanisms and instead rely on superficial mimicry,\nmaking it difficult for them to reach an autonomous level. We believe Survival\nGame can not only guide the future development of AI but also offer profound\ninsights into human intelligence.\n","authors":["Jingtao Zhan","Jiahao Zhao","Jiayu Li","Yiqun Liu","Bo Zhang","Qingyao Ai","Jiaxin Mao","Hongning Wang","Min Zhang","Shaoping Ma"],"pdf_url":"https://arxiv.org/pdf/2502.18858v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2409.15517v2","updated":"2025-03-03T13:22:14Z","published":"2024-09-23T20:09:43Z","title":"MATCH POLICY: A Simple Pipeline from Point Cloud Registration to\n  Manipulation Policies","summary":"  Many manipulation tasks require the robot to rearrange objects relative to\none another. Such tasks can be described as a sequence of relative poses\nbetween parts of a set of rigid bodies. In this work, we propose MATCH POLICY,\na simple but novel pipeline for solving high-precision pick and place tasks.\nInstead of predicting actions directly, our method registers the pick and place\ntargets to the stored demonstrations. This transfers action inference into a\npoint cloud registration task and enables us to realize nontrivial manipulation\npolicies without any training. MATCH POLICY is designed to solve high-precision\ntasks with a key-frame setting. By leveraging the geometric interaction and the\nsymmetries of the task, it achieves extremely high sample efficiency and\ngeneralizability to unseen configurations. We demonstrate its state-of-the-art\nperformance across various tasks on RLBench benchmark compared with several\nstrong baselines and test it on a real robot with six tasks.\n","authors":["Haojie Huang","Haotian Liu","Dian Wang","Robin Walters","Robert Platt"],"pdf_url":"https://arxiv.org/pdf/2409.15517v2.pdf","comment":"project url: https://haojhuang.github.io/match_page/"},{"id":"http://arxiv.org/abs/2409.20171v3","updated":"2025-03-03T13:12:48Z","published":"2024-09-30T10:29:41Z","title":"Annotation-Free Curb Detection Leveraging Altitude Difference Image","summary":"  Road curbs are considered as one of the crucial and ubiquitous traffic\nfeatures, which are essential for ensuring the safety of autonomous vehicles.\nCurrent methods for detecting curbs primarily rely on camera imagery or LiDAR\npoint clouds. Image-based methods are vulnerable to fluctuations in lighting\nconditions and exhibit poor robustness, while methods based on point clouds\ncircumvent the issues associated with lighting variations. However, it is the\ntypical case that significant processing delays are encountered due to the\nvoluminous amount of 3D points contained in each frame of the point cloud data.\nFurthermore, the inherently unstructured characteristics of point clouds poses\nchallenges for integrating the latest deep learning advancements into point\ncloud data applications. To address these issues, this work proposes an\nannotation-free curb detection method leveraging Altitude Difference Image\n(ADI), which effectively mitigates the aforementioned challenges. Given that\nmethods based on deep learning generally demand extensive, manually annotated\ndatasets, which are both expensive and labor-intensive to create, we present an\nAutomatic Curb Annotator (ACA) module. This module utilizes a deterministic\ncurb detection algorithm to automatically generate a vast quantity of training\ndata. Consequently, it facilitates the training of the curb detection model\nwithout necessitating any manual annotation of data. Finally, by incorporating\na post-processing module, we manage to achieve state-of-the-art results on the\nKITTI 3D curb dataset with considerably reduced processing delays compared to\nexisting methods, which underscores the effectiveness of our approach in curb\ndetection tasks.\n","authors":["Fulong Ma","Peng Hou","Yuxuan Liu","Yang Liu","Ming Liu","Jun Ma"],"pdf_url":"https://arxiv.org/pdf/2409.20171v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2501.09555v3","updated":"2025-03-03T13:05:35Z","published":"2025-01-16T14:18:06Z","title":"Text-driven Adaptation of Foundation Models for Few-shot Surgical\n  Workflow Analysis","summary":"  Purpose: Surgical workflow analysis is crucial for improving surgical\nefficiency and safety. However, previous studies rely heavily on large-scale\nannotated datasets, posing challenges in cost, scalability, and reliance on\nexpert annotations. To address this, we propose Surg-FTDA (Few-shot Text-driven\nAdaptation), designed to handle various surgical workflow analysis tasks with\nminimal paired image-label data.\n  Methods: Our approach has two key components. First, Few-shot selection-based\nmodality alignment selects a small subset of images and aligns their embeddings\nwith text embeddings from the downstream task, bridging the modality gap.\nSecond, Text-driven adaptation leverages only text data to train a decoder,\neliminating the need for paired image-text data. This decoder is then applied\nto aligned image embeddings, enabling image-related tasks without explicit\nimage-text pairs.\n  Results: We evaluate our approach to generative tasks (image captioning) and\ndiscriminative tasks (triplet recognition and phase recognition). Results show\nthat Surg-FTDA outperforms baselines and generalizes well across downstream\ntasks.\n  Conclusion: We propose a text-driven adaptation approach that mitigates the\nmodality gap and handles multiple downstream tasks in surgical workflow\nanalysis, with minimal reliance on large annotated datasets. The code and\ndataset will be released in https://github.com/CAMMA-public/Surg-FTDA\n","authors":["Tingxuan Chen","Kun Yuan","Vinkle Srivastav","Nassir Navab","Nicolas Padoy"],"pdf_url":"https://arxiv.org/pdf/2501.09555v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2502.11142v2","updated":"2025-03-03T12:56:35Z","published":"2025-02-16T14:17:36Z","title":"NavRAG: Generating User Demand Instructions for Embodied Navigation\n  through Retrieval-Augmented LLM","summary":"  Vision-and-Language Navigation (VLN) is an essential skill for embodied\nagents, allowing them to navigate in 3D environments following natural language\ninstructions. High-performance navigation models require a large amount of\ntraining data, the high cost of manually annotating data has seriously hindered\nthis field. Therefore, some previous methods translate trajectory videos into\nstep-by-step instructions for expanding data, but such instructions do not\nmatch well with users' communication styles that briefly describe destinations\nor state specific needs. Moreover, local navigation trajectories overlook\nglobal context and high-level task planning. To address these issues, we\npropose NavRAG, a retrieval-augmented generation (RAG) framework that generates\nuser demand instructions for VLN. NavRAG leverages LLM to build a hierarchical\nscene description tree for 3D scene understanding from global layout to local\ndetails, then simulates various user roles with specific demands to retrieve\nfrom the scene tree, generating diverse instructions with LLM. We annotate over\n2 million navigation instructions across 861 scenes and evaluate the data\nquality and navigation performance of trained models.\n","authors":["Zihan Wang","Yaohui Zhu","Gim Hee Lee","Yachun Fan"],"pdf_url":"https://arxiv.org/pdf/2502.11142v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2502.14616v2","updated":"2025-03-03T12:37:18Z","published":"2025-02-20T14:57:01Z","title":"Monocular Depth Estimation and Segmentation for Transparent Object with\n  Iterative Semantic and Geometric Fusion","summary":"  Transparent object perception is indispensable for numerous robotic tasks.\nHowever, accurately segmenting and estimating the depth of transparent objects\nremain challenging due to complex optical properties. Existing methods\nprimarily delve into only one task using extra inputs or specialized sensors,\nneglecting the valuable interactions among tasks and the subsequent refinement\nprocess, leading to suboptimal and blurry predictions. To address these issues,\nwe propose a monocular framework, which is the first to excel in both\nsegmentation and depth estimation of transparent objects, with only a\nsingle-image input. Specifically, we devise a novel semantic and geometric\nfusion module, effectively integrating the multi-scale information between\ntasks. In addition, drawing inspiration from human perception of objects, we\nfurther incorporate an iterative strategy, which progressively refines initial\nfeatures for clearer results. Experiments on two challenging synthetic and\nreal-world datasets demonstrate that our model surpasses state-of-the-art\nmonocular, stereo, and multi-view methods by a large margin of about\n38.8%-46.2% with only a single RGB input. Codes and models are publicly\navailable at https://github.com/L-J-Yuan/MODEST.\n","authors":["Jiangyuan Liu","Hongxuan Ma","Yuxin Guo","Yuhao Zhao","Chi Zhang","Wei Sui","Wei Zou"],"pdf_url":"https://arxiv.org/pdf/2502.14616v2.pdf","comment":"Accepted by ICRA(2025). The code is accessible through:\n  https://github.com/L-J-Yuan/MODEST"},{"id":"http://arxiv.org/abs/2408.04591v2","updated":"2025-03-03T12:35:33Z","published":"2024-08-08T17:04:06Z","title":"HiLo: A Learning Framework for Generalized Category Discovery Robust to\n  Domain Shifts","summary":"  Generalized Category Discovery (GCD) is a challenging task in which, given a\npartially labelled dataset, models must categorize all unlabelled instances,\nregardless of whether they come from labelled categories or from new ones. In\nthis paper, we challenge a remaining assumption in this task: that all images\nshare the same domain. Specifically, we introduce a new task and method to\nhandle GCD when the unlabelled data also contains images from different domains\nto the labelled set. Our proposed `HiLo' networks extract High-level semantic\nand Low-level domain features, before minimizing the mutual information between\nthe representations. Our intuition is that the clusterings based on domain\ninformation and semantic information should be independent. We further extend\nour method with a specialized domain augmentation tailored for the GCD task, as\nwell as a curriculum learning approach. Finally, we construct a benchmark from\ncorrupted fine-grained datasets as well as a large-scale evaluation on\nDomainNet with real-world domain shifts, reimplementing a number of GCD\nbaselines in this setting. We demonstrate that HiLo outperforms SoTA category\ndiscovery models by a large margin on all evaluations.\n","authors":["Hongjun Wang","Sagar Vaze","Kai Han"],"pdf_url":"https://arxiv.org/pdf/2408.04591v2.pdf","comment":"v2: Accepted as a conference paper at ICLR 2025; Project page:\n  https://github.com/Visual-AI/hilo/"},{"id":"http://arxiv.org/abs/2410.09400v2","updated":"2025-03-03T12:33:49Z","published":"2024-10-12T07:04:32Z","title":"CtrLoRA: An Extensible and Efficient Framework for Controllable Image\n  Generation","summary":"  Recently, large-scale diffusion models have made impressive progress in\ntext-to-image (T2I) generation. To further equip these T2I models with\nfine-grained spatial control, approaches like ControlNet introduce an extra\nnetwork that learns to follow a condition image. However, for every single\ncondition type, ControlNet requires independent training on millions of data\npairs with hundreds of GPU hours, which is quite expensive and makes it\nchallenging for ordinary users to explore and develop new types of conditions.\nTo address this problem, we propose the CtrLoRA framework, which trains a Base\nControlNet to learn the common knowledge of image-to-image generation from\nmultiple base conditions, along with condition-specific LoRAs to capture\ndistinct characteristics of each condition. Utilizing our pretrained Base\nControlNet, users can easily adapt it to new conditions, requiring as few as\n1,000 data pairs and less than one hour of single-GPU training to obtain\nsatisfactory results in most scenarios. Moreover, our CtrLoRA reduces the\nlearnable parameters by 90% compared to ControlNet, significantly lowering the\nthreshold to distribute and deploy the model weights. Extensive experiments on\nvarious types of conditions demonstrate the efficiency and effectiveness of our\nmethod. Codes and model weights will be released at\nhttps://github.com/xyfJASON/ctrlora.\n","authors":["Yifeng Xu","Zhenliang He","Shiguang Shan","Xilin Chen"],"pdf_url":"https://arxiv.org/pdf/2410.09400v2.pdf","comment":"ICLR 2025. Code: https://github.com/xyfJASON/ctrlora"},{"id":"http://arxiv.org/abs/2410.08190v2","updated":"2025-03-03T12:18:29Z","published":"2024-10-10T17:57:29Z","title":"Poison-splat: Computation Cost Attack on 3D Gaussian Splatting","summary":"  3D Gaussian splatting (3DGS), known for its groundbreaking performance and\nefficiency, has become a dominant 3D representation and brought progress to\nmany 3D vision tasks. However, in this work, we reveal a significant security\nvulnerability that has been largely overlooked in 3DGS: the computation cost of\ntraining 3DGS could be maliciously tampered by poisoning the input data. By\ndeveloping an attack named Poison-splat, we reveal a novel attack surface where\nthe adversary can poison the input images to drastically increase the\ncomputation memory and time needed for 3DGS training, pushing the algorithm\ntowards its worst computation complexity. In extreme cases, the attack can even\nconsume all allocable memory, leading to a Denial-of-Service (DoS) that\ndisrupts servers, resulting in practical damages to real-world 3DGS service\nvendors. Such a computation cost attack is achieved by addressing a bi-level\noptimization problem through three tailored strategies: attack objective\napproximation, proxy model rendering, and optional constrained optimization.\nThese strategies not only ensure the effectiveness of our attack but also make\nit difficult to defend with simple defensive measures. We hope the revelation\nof this novel attack surface can spark attention to this crucial yet overlooked\nvulnerability of 3DGS systems. Our code is available at\nhttps://github.com/jiahaolu97/poison-splat .\n","authors":["Jiahao Lu","Yifan Zhang","Qiuhong Shen","Xinchao Wang","Shuicheng Yan"],"pdf_url":"https://arxiv.org/pdf/2410.08190v2.pdf","comment":"Accepted by ICLR 2025 as a spotlight paper"},{"id":"http://arxiv.org/abs/2502.12138v3","updated":"2025-03-03T12:09:29Z","published":"2025-02-17T18:54:05Z","title":"FLARE: Feed-forward Geometry, Appearance and Camera Estimation from\n  Uncalibrated Sparse Views","summary":"  We present FLARE, a feed-forward model designed to infer high-quality camera\nposes and 3D geometry from uncalibrated sparse-view images (i.e., as few as 2-8\ninputs), which is a challenging yet practical setting in real-world\napplications. Our solution features a cascaded learning paradigm with camera\npose serving as the critical bridge, recognizing its essential role in mapping\n3D structures onto 2D image planes. Concretely, FLARE starts with camera pose\nestimation, whose results condition the subsequent learning of geometric\nstructure and appearance, optimized through the objectives of geometry\nreconstruction and novel-view synthesis. Utilizing large-scale public datasets\nfor training, our method delivers state-of-the-art performance in the tasks of\npose estimation, geometry reconstruction, and novel view synthesis, while\nmaintaining the inference efficiency (i.e., less than 0.5 seconds). The project\npage and code can be found at: https://zhanghe3z.github.io/FLARE/\n","authors":["Shangzhan Zhang","Jianyuan Wang","Yinghao Xu","Nan Xue","Christian Rupprecht","Xiaowei Zhou","Yujun Shen","Gordon Wetzstein"],"pdf_url":"https://arxiv.org/pdf/2502.12138v3.pdf","comment":"CVPR 2025. Website: https://zhanghe3z.github.io/FLARE/"},{"id":"http://arxiv.org/abs/2502.17941v2","updated":"2025-03-03T12:00:57Z","published":"2025-02-25T08:03:04Z","title":"Optimal Brain Apoptosis","summary":"  The increasing complexity and parameter count of Convolutional Neural\nNetworks (CNNs) and Transformers pose challenges in terms of computational\nefficiency and resource demands. Pruning has been identified as an effective\nstrategy to address these challenges by removing redundant elements such as\nneurons, channels, or connections, thereby enhancing computational efficiency\nwithout heavily compromising performance. This paper builds on the foundational\nwork of Optimal Brain Damage (OBD) by advancing the methodology of parameter\nimportance estimation using the Hessian matrix. Unlike previous approaches that\nrely on approximations, we introduce Optimal Brain Apoptosis (OBA), a novel\npruning method that calculates the Hessian-vector product value directly for\neach parameter. By decomposing the Hessian matrix across network layers and\nidentifying conditions under which inter-layer Hessian submatrices are\nnon-zero, we propose a highly efficient technique for computing the\nsecond-order Taylor expansion of parameters. This approach allows for a more\nprecise pruning process, particularly in the context of CNNs and Transformers,\nas validated in our experiments including VGG19, ResNet32, ResNet50, and\nViT-B/16 on CIFAR10, CIFAR100 and Imagenet datasets. Our code is available at\nhttps://github.com/NEU-REAL/OBA.\n","authors":["Mingyuan Sun","Zheng Fang","Jiaxu Wang","Junjie Jiang","Delei Kong","Chenming Hu","Yuetong Fang","Renjing Xu"],"pdf_url":"https://arxiv.org/pdf/2502.17941v2.pdf","comment":"Accepted to ICLR 2025"},{"id":"http://arxiv.org/abs/2407.15589v5","updated":"2025-03-03T11:48:03Z","published":"2024-07-22T12:26:08Z","title":"Exploring the Effectiveness of Object-Centric Representations in Visual\n  Question Answering: Comparative Insights with Foundation Models","summary":"  Object-centric (OC) representations, which model visual scenes as\ncompositions of discrete objects, have the potential to be used in various\ndownstream tasks to achieve systematic compositional generalization and\nfacilitate reasoning. However, these claims have yet to be thoroughly validated\nempirically. Recently, foundation models have demonstrated unparalleled\ncapabilities across diverse domains, from language to computer vision,\npositioning them as a potential cornerstone of future research for a wide range\nof computational tasks. In this paper, we conduct an extensive empirical study\non representation learning for downstream Visual Question Answering (VQA),\nwhich requires an accurate compositional understanding of the scene. We\nthoroughly investigate the benefits and trade-offs of OC models and alternative\napproaches including large pre-trained foundation models on both synthetic and\nreal-world data, ultimately identifying a promising path to leverage the\nstrengths of both paradigms. The extensiveness of our study, encompassing over\n600 downstream VQA models and 15 different types of upstream representations,\nalso provides several additional insights that we believe will be of interest\nto the community at large.\n","authors":["Amir Mohammad Karimi Mamaghan","Samuele Papa","Karl Henrik Johansson","Stefan Bauer","Andrea Dittadi"],"pdf_url":"https://arxiv.org/pdf/2407.15589v5.pdf","comment":"Published at ICLR 2025"},{"id":"http://arxiv.org/abs/2502.21291v2","updated":"2025-03-03T11:33:31Z","published":"2025-02-28T18:21:08Z","title":"MIGE: A Unified Framework for Multimodal Instruction-Based Image\n  Generation and Editing","summary":"  Despite significant progress in diffusion-based image generation,\nsubject-driven generation and instruction-based editing remain challenging.\nExisting methods typically treat them separately, struggling with limited\nhigh-quality data and poor generalization. However, both tasks require\ncapturing complex visual variations while maintaining consistency between\ninputs and outputs. Therefore, we propose MIGE, a unified framework that\nstandardizes task representations using multimodal instructions. It treats\nsubject-driven generation as creation on a blank canvas and instruction-based\nediting as modification of an existing image, establishing a shared\ninput-output formulation. MIGE introduces a novel multimodal encoder that maps\nfree-form multimodal instructions into a unified vision-language space,\nintegrating visual and semantic features through a feature fusion mechanism.\nThis unification enables joint training of both tasks, providing two key\nadvantages: (1) Cross-Task Enhancement: By leveraging shared visual and\nsemantic representations, joint training improves instruction adherence and\nvisual consistency in both subject-driven generation and instruction-based\nediting. (2) Generalization: Learning in a unified format facilitates\ncross-task knowledge transfer, enabling MIGE to generalize to novel\ncompositional tasks, including instruction-based subject-driven editing.\nExperiments show that MIGE excels in both subject-driven generation and\ninstruction-based editing while setting a state-of-the-art in the new task of\ninstruction-based subject-driven editing. Code and model have been publicly\navailable at https://github.com/Eureka-Maggie/MIGE.\n","authors":["Xueyun Tian","Wei Li","Bingbing Xu","Yige Yuan","Yuanzhuo Wang","Huawei Shen"],"pdf_url":"https://arxiv.org/pdf/2502.21291v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2501.18936v4","updated":"2025-03-03T11:00:24Z","published":"2025-01-31T07:41:06Z","title":"Adaptive Prompt: Unlocking the Power of Visual Prompt Tuning","summary":"  Visual Prompt Tuning (VPT) has recently emerged as a powerful method for\nadapting pre-trained vision models to downstream tasks. By introducing\nlearnable prompt tokens as task-specific instructions, VPT effectively guides\npre-trained transformer models with minimal overhead. Despite its empirical\nsuccess, a comprehensive theoretical understanding of VPT remains an active\narea of research. Building on recent insights into the connection between\nmixture of experts and prompt-based approaches, we identify a key limitation in\nVPT: the restricted functional expressiveness in prompt formulation. To address\nthis limitation, we propose Visual Adaptive Prompt Tuning (VAPT), a new\ngeneration of prompts that redefines prompts as adaptive functions of the\ninput. Our theoretical analysis shows that this simple yet intuitive approach\nachieves optimal sample efficiency. Empirical results on VTAB-1K and FGVC\nfurther demonstrate VAPT's effectiveness, with performance gains of 7.34% and\n1.04% over fully fine-tuning baselines, respectively. Notably, VAPT also\nsurpasses VPT by a substantial margin while using fewer parameters. These\nresults highlight both the effectiveness and efficiency of our method and pave\nthe way for future research to explore the potential of adaptive prompts.\n","authors":["Minh Le","Anh Nguyen","Huy Nguyen","Chau Nguyen","Nhat Ho"],"pdf_url":"https://arxiv.org/pdf/2501.18936v4.pdf","comment":"57 pages, 10 figures, 18 tables"},{"id":"http://arxiv.org/abs/2410.02423v2","updated":"2025-03-03T10:44:06Z","published":"2024-10-03T12:13:56Z","title":"PnP-Flow: Plug-and-Play Image Restoration with Flow Matching","summary":"  In this paper, we introduce Plug-and-Play (PnP) Flow Matching, an algorithm\nfor solving imaging inverse problems. PnP methods leverage the strength of\npre-trained denoisers, often deep neural networks, by integrating them in\noptimization schemes. While they achieve state-of-the-art performance on\nvarious inverse problems in imaging, PnP approaches face inherent limitations\non more generative tasks like inpainting. On the other hand, generative models\nsuch as Flow Matching pushed the boundary in image sampling yet lack a clear\nmethod for efficient use in image restoration. We propose to combine the PnP\nframework with Flow Matching (FM) by defining a time-dependent denoiser using a\npre-trained FM model. Our algorithm alternates between gradient descent steps\non the data-fidelity term, reprojections onto the learned FM path, and\ndenoising. Notably, our method is computationally efficient and\nmemory-friendly, as it avoids backpropagation through ODEs and trace\ncomputations. We evaluate its performance on denoising, super-resolution,\ndeblurring, and inpainting tasks, demonstrating superior results compared to\nexisting PnP algorithms and Flow Matching based state-of-the-art methods.\n","authors":["Sgolne Martin","Anne Gagneux","Paul Hagemann","Gabriele Steidl"],"pdf_url":"https://arxiv.org/pdf/2410.02423v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2412.11542v2","updated":"2025-03-03T10:39:41Z","published":"2024-12-16T08:22:23Z","title":"Meta Curvature-Aware Minimization for Domain Generalization","summary":"  Domain generalization (DG) aims to enhance the ability of models trained on\nsource domains to generalize effectively to unseen domains. Recently,\nSharpness-Aware Minimization (SAM) has shown promise in this area by reducing\nthe sharpness of the loss landscape to obtain more generalized models. However,\nSAM and its variants sometimes fail to guide the model toward a flat minimum,\nand their training processes exhibit limitations, hindering further\nimprovements in model generalization. In this paper, we first propose an\nimproved model training process aimed at encouraging the model to converge to a\nflat minima. To achieve this, we design a curvature metric that has a minimal\neffect when the model is far from convergence but becomes increasingly\ninfluential in indicating the curvature of the minima as the model approaches a\nlocal minimum. Then we derive a novel algorithm from this metric, called Meta\nCurvature-Aware Minimization (MeCAM), to minimize the curvature around the\nlocal minima. Specifically, the optimization objective of MeCAM simultaneously\nminimizes the regular training loss, the surrogate gap of SAM, and the\nsurrogate gap of meta-learning. We provide theoretical analysis on MeCAM's\ngeneralization error and convergence rate, and demonstrate its superiority over\nexisting DG methods through extensive experiments on five benchmark DG\ndatasets, including PACS, VLCS, OfficeHome, TerraIncognita, and DomainNet. Code\nwill be available on GitHub.\n","authors":["Ziyang Chen","Yiwen Ye","Feilong Tang","Yongsheng Pan","Yong Xia"],"pdf_url":"https://arxiv.org/pdf/2412.11542v2.pdf","comment":"22 pages, 5 figures, 17 tables"},{"id":"http://arxiv.org/abs/2502.08005v2","updated":"2025-03-03T10:38:34Z","published":"2025-02-11T23:02:14Z","title":"Towards Training One-Step Diffusion Models Without Distillation","summary":"  Recent advances in one-step generative models typically follow a two-stage\nprocess: first training a teacher diffusion model and then distilling it into a\none-step student model. This distillation process traditionally relies on both\nthe teacher model's score function to compute the distillation loss and its\nweights for student initialization. In this paper, we explore whether one-step\ngenerative models can be trained directly without this distillation process.\nFirst, we show that the teacher's score function is not essential and propose a\nfamily of distillation methods that achieve competitive results without relying\non score estimation. Next, we demonstrate that initialization from teacher\nweights is indispensable in successful training. Surprisingly, we find that\nthis benefit is not due to improved ``input-output\" mapping but rather the\nlearned feature representations, which dominate distillation quality. Our\nfindings provide a better understanding of the role of initialization in\none-step model training and its impact on distillation quality.\n","authors":["Mingtian Zhang","Jiajun He","Wenlin Chen","Zijing Ou","Jos Miguel Hernndez-Lobato","Bernhard Schlkopf","David Barber"],"pdf_url":"https://arxiv.org/pdf/2502.08005v2.pdf","comment":"13 pages, Technical Report"},{"id":"http://arxiv.org/abs/2502.21264v2","updated":"2025-03-03T10:35:23Z","published":"2025-02-28T17:40:45Z","title":"Foundation Models -- A Panacea for Artificial Intelligence in Pathology?","summary":"  The role of artificial intelligence (AI) in pathology has evolved from aiding\ndiagnostics to uncovering predictive morphological patterns in whole slide\nimages (WSIs). Recently, foundation models (FMs) leveraging self-supervised\npre-training have been widely advocated as a universal solution for diverse\ndownstream tasks. However, open questions remain about their clinical\napplicability and generalization advantages over end-to-end learning using\ntask-specific (TS) models. Here, we focused on AI with clinical-grade\nperformance for prostate cancer diagnosis and Gleason grading. We present the\nlargest validation of AI for this task, using over 100,000 core needle biopsies\nfrom 7,342 patients across 15 sites in 11 countries. We compared two FMs with a\nfully end-to-end TS model in a multiple instance learning framework. Our\nfindings challenge assumptions that FMs universally outperform TS models. While\nFMs demonstrated utility in data-scarce scenarios, their performance converged\nwith - and was in some cases surpassed by - TS models when sufficient labeled\ntraining data were available. Notably, extensive task-specific training\nmarkedly reduced clinically significant misgrading, misdiagnosis of challenging\nmorphologies, and variability across different WSI scanners. Additionally, FMs\nused up to 35 times more energy than the TS model, raising concerns about their\nsustainability. Our results underscore that while FMs offer clear advantages\nfor rapid prototyping and research, their role as a universal solution for\nclinically applicable medical AI remains uncertain. For high-stakes clinical\napplications, rigorous validation and consideration of task-specific training\nremain critically important. We advocate for integrating the strengths of FMs\nand end-to-end learning to achieve robust and resource-efficient AI pathology\nsolutions fit for clinical use.\n","authors":["Nita Mulliqi","Anders Blilie","Xiaoyi Ji","Kelvin Szolnoky","Henrik Olsson","Sol Erika Boman","Matteo Titus","Geraldine Martinez Gonzalez","Julia Anna Mielcarz","Masi Valkonen","Einar Gudlaugsson","Svein R. Kjosavik","Jos Asenjo","Marcello Gambacorta","Paolo Libretti","Marcin Braun","Radzislaw Kordek","Roman owicki","Kristina Hotakainen","Pivi Vre","Bodil Ginnerup Pedersen","Karina Dalsgaard Srensen","Benedicte Parm Ulhi","Pekka Ruusuvuori","Brett Delahunt","Hemamali Samaratunga","Toyonori Tsuzuki","Emilius A. M. Janssen","Lars Egevad","Martin Eklund","Kimmo Kartasalo"],"pdf_url":"https://arxiv.org/pdf/2502.21264v2.pdf","comment":"50 pages, 15 figures and an appendix (study protocol) which is\n  previously published, see https://doi.org/10.1101/2024.07.04.24309948;\n  updated authors list format"},{"id":"http://arxiv.org/abs/2502.21201v2","updated":"2025-03-03T10:32:20Z","published":"2025-02-28T16:18:57Z","title":"The PanAf-FGBG Dataset: Understanding the Impact of Backgrounds in\n  Wildlife Behaviour Recognition","summary":"  Computer vision analysis of camera trap video footage is essential for\nwildlife conservation, as captured behaviours offer some of the earliest\nindicators of changes in population health. Recently, several high-impact\nanimal behaviour datasets and methods have been introduced to encourage their\nuse; however, the role of behaviour-correlated background information and its\nsignificant effect on out-of-distribution generalisation remain unexplored. In\nresponse, we present the PanAf-FGBG dataset, featuring 20 hours of wild\nchimpanzee behaviours, recorded at over 350 individual camera locations.\nUniquely, it pairs every video with a chimpanzee (referred to as a foreground\nvideo) with a corresponding background video (with no chimpanzee) from the same\ncamera location. We present two views of the dataset: one with overlapping\ncamera locations and one with disjoint locations. This setup enables, for the\nfirst time, direct evaluation of in-distribution and out-of-distribution\nconditions, and for the impact of backgrounds on behaviour recognition models\nto be quantified. All clips come with rich behavioural annotations and metadata\nincluding unique camera IDs and detailed textual scene descriptions.\nAdditionally, we establish several baselines and present a highly effective\nlatent-space normalisation technique that boosts out-of-distribution\nperformance by +5.42% mAP for convolutional and +3.75% mAP for\ntransformer-based models. Finally, we provide an in-depth analysis on the role\nof backgrounds in out-of-distribution behaviour recognition, including the so\nfar unexplored impact of background durations (i.e., the count of background\nframes within foreground videos).\n","authors":["Otto Brookes","Maksim Kukushkin","Majid Mirmehdi","Colleen Stephens","Paula Dieguez","Thurston C. Hicks","Sorrel Jones","Kevin Lee","Maureen S. McCarthy","Amelia Meier","Emmanuelle Normand","Erin G. Wessling","Roman M. Wittig","Kevin Langergraber","Klaus Zuberbhler","Lukas Boesch","Thomas Schmid","Mimi Arandjelovic","Hjalmar Khl","Tilo Burghardt"],"pdf_url":"https://arxiv.org/pdf/2502.21201v2.pdf","comment":"Accepted at the IEEE / CVF Computer Vision and Pattern Recognition\n  Conference 2025"},{"id":"http://arxiv.org/abs/2410.05643v3","updated":"2025-03-03T10:28:30Z","published":"2024-10-08T02:46:30Z","title":"TRACE: Temporal Grounding Video LLM via Causal Event Modeling","summary":"  Video Temporal Grounding (VTG) is a crucial capability for video\nunderstanding models and plays a vital role in downstream tasks such as video\nbrowsing and editing. To effectively handle various tasks simultaneously and\nenable zero-shot prediction, there is a growing trend in employing video LLMs\nfor VTG tasks. However, current video LLM-based methods rely exclusively on\nnatural language generation, lacking the ability to model the clear structure\ninherent in videos, which restricts their effectiveness in tackling VTG tasks.\nTo address this issue, this paper first formally introduces causal event\nmodeling framework, which represents video LLM outputs as sequences of events,\nand predict the current event using previous events, video inputs, and textural\ninstructions. Each event consists of three components: timestamps, salient\nscores, and textual captions. We then propose a novel task-interleaved video\nLLM called TRACE to effectively implement the causal event modeling framework\nin practice. The TRACE process visual frames, timestamps, salient scores, and\ntext as distinct tasks, employing various encoders and decoding heads for each.\nTask tokens are arranged in an interleaved sequence according to the causal\nevent modeling framework's formulation. Extensive experiments on various VTG\ntasks and datasets demonstrate the superior performance of TRACE compared to\nstate-of-the-art video LLMs. Our model and code are available at\nhttps://github.com/gyxxyg/TRACE.\n","authors":["Yongxin Guo","Jingyu Liu","Mingda Li","Qingbin Liu","Xi Chen","Xiaoying Tang"],"pdf_url":"https://arxiv.org/pdf/2410.05643v3.pdf","comment":"ICLR 2025"},{"id":"http://arxiv.org/abs/2411.06916v2","updated":"2025-03-03T10:22:24Z","published":"2024-11-11T12:19:28Z","title":"Slowing Down Forgetting in Continual Learning","summary":"  A common challenge in continual learning (CL) is catastrophic forgetting,\nwhere the performance on old tasks drops after new, additional tasks are\nlearned. In this paper, we propose a novel framework called ReCL to slow down\nforgetting in CL. Our framework exploits an implicit bias of gradient-based\nneural networks due to which these converge to margin maximization points. Such\nconvergence points allow us to reconstruct old data from previous tasks, which\nwe then combine with the current training data. Our framework is flexible and\ncan be applied on top of existing, state-of-the-art CL methods. We further\ndemonstrate the performance gain from our framework across a large series of\nexperiments, including two challenging CL scenarios (class incremental and\ndomain incremental learning), different datasets (MNIST, CIFAR10,\nTinyImagenet), and different network architectures. Across all experiments, we\nfind large performance gains through ReCL. To the best of our knowledge, our\nframework is the first to address catastrophic forgetting by leveraging models\nin CL as their own memory buffers.\n","authors":["Pascal Janetzky","Tobias Schlagenhauf","Stefan Feuerriegel"],"pdf_url":"https://arxiv.org/pdf/2411.06916v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2407.14651v3","updated":"2025-03-03T09:31:01Z","published":"2024-07-19T20:05:10Z","title":"Improving Representation of High-frequency Components for Medical Visual\n  Foundation Models","summary":"  Foundation models have recently attracted significant attention for their\nimpressive generalizability across diverse downstream tasks. However, these\nmodels are demonstrated to exhibit great limitations in representing\nhigh-frequency components and fine-grained details. In many medical imaging\ntasks, the precise representation of such information is crucial due to the\ninherently intricate anatomical structures, sub-visual features, and complex\nboundaries involved. Consequently, the limited representation of prevalent\nfoundation models can result in significant performance degradation or even\nfailure in these tasks. To address these challenges, we propose a novel\npretraining strategy, named Frequency-advanced Representation Autoencoder\n(Frepa). Through high-frequency masking and low-frequency perturbation combined\nwith adversarial learning, Frepa encourages the encoder to effectively\nrepresent and preserve high-frequency components in the image embeddings.\nAdditionally, we introduce an innovative histogram-equalized image masking\nstrategy, extending the Masked Autoencoder approach beyond ViT to other\narchitectures such as Swin Transformer and convolutional networks. We develop\nFrepa across nine medical modalities and validate it on 32 downstream tasks for\nboth 2D images and 3D volume data. Without fine-tuning, Frepa can outperform\nother self-supervised pretraining methods and, in some cases, even surpasses\ntask-specific trained models. This improvement is particularly significant for\ntasks involving fine-grained details, such as achieving up to a +15% increase\nin DSC for retina vessel segmentation and a +7% increase in IoU for lung nodule\ndetection. Further experiments quantitatively reveal that Frepa enables\nsuperior high-frequency representations and preservation in the embeddings,\nunderscoring its potential for developing more generalized and universal\nmedical image foundation models.\n","authors":["Yuetan Chu","Yilan Zhang","Zhongyi Han","Changchun Yang","Longxi Zhou","Gongning Luo","Chao Huang","Xin Gao"],"pdf_url":"https://arxiv.org/pdf/2407.14651v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.23751v2","updated":"2025-03-03T09:30:42Z","published":"2024-10-31T09:11:56Z","title":"EXACFS -- A CIL Method to mitigate Catastrophic Forgetting","summary":"  Deep neural networks (DNNS) excel at learning from static datasets but\nstruggle with continual learning, where data arrives sequentially. Catastrophic\nforgetting, the phenomenon of forgetting previously learned knowledge, is a\nprimary challenge. This paper introduces EXponentially Averaged Class-wise\nFeature Significance (EXACFS) to mitigate this issue in the class incremental\nlearning (CIL) setting. By estimating the significance of model features for\neach learned class using loss gradients, gradually aging the significance\nthrough the incremental tasks and preserving the significant features through a\ndistillation loss, EXACFS effectively balances remembering old knowledge\n(stability) and learning new knowledge (plasticity). Extensive experiments on\nCIFAR-100 and ImageNet-100 demonstrate EXACFS's superior performance in\npreserving stability while acquiring plasticity.\n","authors":["S Balasubramanian","M Sai Subramaniam","Sai Sriram Talasu","Yedu Krishna P","Manepalli Pranav Phanindra Sai","Ravi Mukkamala","Darshan Gera"],"pdf_url":"https://arxiv.org/pdf/2410.23751v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2501.16751v3","updated":"2025-03-03T09:07:59Z","published":"2025-01-28T07:08:20Z","title":"HiBug2: Efficient and Interpretable Error Slice Discovery for\n  Comprehensive Model Debugging","summary":"  Despite the significant success of deep learning models in computer vision,\nthey often exhibit systematic failures on specific data subsets, known as error\nslices. Identifying and mitigating these error slices is crucial to enhancing\nmodel robustness and reliability in real-world scenarios. In this paper, we\nintroduce HiBug2, an automated framework for error slice discovery and model\nrepair. HiBug2 first generates task-specific visual attributes to highlight\ninstances prone to errors through an interpretable and structured process. It\nthen employs an efficient slice enumeration algorithm to systematically\nidentify error slices, overcoming the combinatorial challenges that arise\nduring slice exploration. Additionally, HiBug2 extends its capabilities by\npredicting error slices beyond the validation set, addressing a key limitation\nof prior approaches. Extensive experiments across multiple domains, including\nimage classification, pose estimation, and object detection - show that HiBug2\nnot only improves the coherence and precision of identified error slices but\nalso significantly enhances the model repair capabilities.\n","authors":["Muxi Chen","Chenchen Zhao","Qiang Xu"],"pdf_url":"https://arxiv.org/pdf/2501.16751v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2406.12275v2","updated":"2025-03-03T09:05:52Z","published":"2024-06-18T05:05:12Z","title":"VoCo-LLaMA: Towards Vision Compression with Large Language Models","summary":"  Vision-Language Models (VLMs) have achieved remarkable success in various\nmulti-modal tasks, but they are often bottlenecked by the limited context\nwindow and high computational cost of processing high-resolution image inputs\nand videos. Vision compression can alleviate this problem by reducing the\nvision token count. Previous approaches compress vision tokens with external\nmodules and force LLMs to understand the compressed ones, leading to visual\ninformation loss. However, the LLMs' understanding paradigm of vision tokens is\nnot fully utilised in the compression learning process. We propose VoCo-LLaMA,\nthe first approach to compress vision tokens using LLMs. By introducing Vision\nCompression tokens during the vision instruction tuning phase and leveraging\nattention distillation, our method distill how LLMs comprehend vision tokens\ninto their processing of VoCo tokens. VoCo-LLaMA facilitates effective vision\ncompression and improves the computational efficiency during the inference\nstage. Specifically, our method achieves minimal performance loss with a\ncompression ratio of 576$\\times$, resulting in up to 94.8$\\%$ fewer FLOPs and\n69.6$\\%$ acceleration in inference time. Furthermore, through continuous\ntraining using time-series compressed token sequences of video frames,\nVoCo-LLaMA demonstrates the ability to understand temporal correlations,\noutperforming previous methods on popular video question-answering benchmarks.\nOur approach presents a promising way to unlock the full potential of VLMs'\ncontextual window, enabling more scalable multi-modal applications. The project\npage, along with the associated code, can be accessed via\nhttps://yxxxb.github.io/VoCo-LLaMA-page/.\n","authors":["Xubing Ye","Yukang Gan","Xiaoke Huang","Yixiao Ge","Yansong Tang"],"pdf_url":"https://arxiv.org/pdf/2406.12275v2.pdf","comment":"11 pages, 4 figures"},{"id":"http://arxiv.org/abs/2502.21130v2","updated":"2025-03-03T08:39:54Z","published":"2025-02-28T15:10:07Z","title":"Fast and Accurate Gigapixel Pathological Image Classification with\n  Hierarchical Distillation Multi-Instance Learning","summary":"  Although multi-instance learning (MIL) has succeeded in pathological image\nclassification, it faces the challenge of high inference costs due to\nprocessing numerous patches from gigapixel whole slide images (WSIs). To\naddress this, we propose HDMIL, a hierarchical distillation multi-instance\nlearning framework that achieves fast and accurate classification by\neliminating irrelevant patches. HDMIL consists of two key components: the\ndynamic multi-instance network (DMIN) and the lightweight instance\npre-screening network (LIPN). DMIN operates on high-resolution WSIs, while LIPN\noperates on the corresponding low-resolution counterparts. During training,\nDMIN are trained for WSI classification while generating attention-score-based\nmasks that indicate irrelevant patches. These masks then guide the training of\nLIPN to predict the relevance of each low-resolution patch. During testing,\nLIPN first determines the useful regions within low-resolution WSIs, which\nindirectly enables us to eliminate irrelevant regions in high-resolution WSIs,\nthereby reducing inference time without causing performance degradation. In\naddition, we further design the first Chebyshev-polynomials-based\nKolmogorov-Arnold classifier in computational pathology, which enhances the\nperformance of HDMIL through learnable activation layers. Extensive experiments\non three public datasets demonstrate that HDMIL outperforms previous\nstate-of-the-art methods, e.g., achieving improvements of 3.13% in AUC while\nreducing inference time by 28.6% on the Camelyon16 dataset.\n","authors":["Jiuyang Dong","Junjun Jiang","Kui Jiang","Jiahan Li","Yongbing Zhang"],"pdf_url":"https://arxiv.org/pdf/2502.21130v2.pdf","comment":"11 pages, 4 figures, accepted by CVPR2025"},{"id":"http://arxiv.org/abs/2311.14922v3","updated":"2025-03-03T07:41:00Z","published":"2023-11-25T03:55:06Z","title":"GDTS: Goal-Guided Diffusion Model with Tree Sampling for Multi-Modal\n  Pedestrian Trajectory Prediction","summary":"  Accurate prediction of pedestrian trajectories is crucial for improving the\nsafety of autonomous driving. However, this task is generally nontrivial due to\nthe inherent stochasticity of human motion, which naturally requires the\npredictor to generate multi-modal prediction. Previous works leverage various\ngenerative methods, such as GAN and VAE, for pedestrian trajectory prediction.\nNevertheless, these methods may suffer from mode collapse and relatively\nlow-quality results. The denoising diffusion probabilistic model (DDPM) has\nrecently been applied to trajectory prediction due to its simple training\nprocess and powerful reconstruction ability. However, current diffusion-based\nmethods do not fully utilize input information and usually require many\ndenoising iterations that lead to a long inference time or an additional\nnetwork for initialization. To address these challenges and facilitate the use\nof diffusion models in multi-modal trajectory prediction, we propose GDTS, a\nnovel Goal-Guided Diffusion Model with Tree Sampling for multi-modal trajectory\nprediction. Considering the \"goal-driven\" characteristics of human motion, GDTS\nleverages goal estimation to guide the generation of the diffusion network. A\ntwo-stage tree sampling algorithm is presented, which leverages common features\nto reduce the inference time and improve accuracy for multi-modal prediction.\nExperimental results demonstrate that our proposed framework achieves\ncomparable state-of-the-art performance with real-time inference speed in\npublic datasets.\n","authors":["Ge Sun","Sheng Wang","Lei Zhu","Ming Liu","Jun Ma"],"pdf_url":"https://arxiv.org/pdf/2311.14922v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2405.01217v2","updated":"2025-03-03T07:38:09Z","published":"2024-05-02T11:58:06Z","title":"CromSS: Cross-modal pre-training with noisy labels for remote sensing\n  image segmentation","summary":"  We explore the potential of large-scale noisily labeled data to enhance\nfeature learning by pretraining semantic segmentation models within a\nmulti-modal framework for geospatial applications. We propose a novel\nCross-modal Sample Selection (CromSS) method, a weakly supervised pretraining\nstrategy designed to improve feature representations through cross-modal\nconsistency and noise mitigation techniques. Unlike conventional pretraining\napproaches, CromSS exploits massive amounts of noisy and easy-to-come-by labels\nfor improved feature learning beneficial to semantic segmentation tasks. We\ninvestigate middle and late fusion strategies to optimize the multi-modal\npretraining architecture design. We also introduce a cross-modal sample\nselection module to mitigate the adverse effects of label noise, which employs\na cross-modal entangling strategy to refine the estimated confidence masks\nwithin each modality to guide the sampling process. Additionally, we introduce\na spatial-temporal label smoothing technique to counteract overconfidence for\nenhanced robustness against noisy labels. To validate our approach, we\nassembled the multi-modal dataset, NoLDO-S12, which consists of a large-scale\nnoisy label subset from Google's Dynamic World (DW) dataset for pretraining and\ntwo downstream subsets with high-quality labels from Google DW and\nOpenStreetMap (OSM) for transfer learning. Experimental results on two\ndownstream tasks and the publicly available DFC2020 dataset demonstrate that\nwhen effectively utilized, the low-cost noisy labels can significantly enhance\nfeature learning for segmentation tasks. All data, code, and pretrained weights\nwill be made publicly available.\n","authors":["Chenying Liu","Conrad Albrecht","Yi Wang","Xiao Xiang Zhu"],"pdf_url":"https://arxiv.org/pdf/2405.01217v2.pdf","comment":"The 1st short version was accepted as an oral presentation by ICLR\n  2024 ML4RS workshop. The 2nd extended version is being under review"},{"id":"http://arxiv.org/abs/2501.15394v2","updated":"2025-03-03T07:30:55Z","published":"2025-01-26T04:24:07Z","title":"Doracamom: Joint 3D Detection and Occupancy Prediction with Multi-view\n  4D Radars and Cameras for Omnidirectional Perception","summary":"  3D object detection and occupancy prediction are critical tasks in autonomous\ndriving, attracting significant attention. Despite the potential of recent\nvision-based methods, they encounter challenges under adverse conditions. Thus,\nintegrating cameras with next-generation 4D imaging radar to achieve unified\nmulti-task perception is highly significant, though research in this domain\nremains limited. In this paper, we propose Doracamom, the first framework that\nfuses multi-view cameras and 4D radar for joint 3D object detection and\nsemantic occupancy prediction, enabling comprehensive environmental perception.\nSpecifically, we introduce a novel Coarse Voxel Queries Generator that\nintegrates geometric priors from 4D radar with semantic features from images to\ninitialize voxel queries, establishing a robust foundation for subsequent\nTransformer-based refinement. To leverage temporal information, we design a\nDual-Branch Temporal Encoder that processes multi-modal temporal features in\nparallel across BEV and voxel spaces, enabling comprehensive spatio-temporal\nrepresentation learning. Furthermore, we propose a Cross-Modal BEV-Voxel Fusion\nmodule that adaptively fuses complementary features through attention\nmechanisms while employing auxiliary tasks to enhance feature quality.\nExtensive experiments on the OmniHD-Scenes, View-of-Delft (VoD), and TJ4DRadSet\ndatasets demonstrate that Doracamom achieves state-of-the-art performance in\nboth tasks, establishing new benchmarks for multi-modal 3D perception. Code and\nmodels will be publicly available.\n","authors":["Lianqing Zheng","Jianan Liu","Runwei Guan","Long Yang","Shouyi Lu","Yuanzhe Li","Xiaokai Bai","Jie Bai","Zhixiong Ma","Hui-Liang Shen","Xichan Zhu"],"pdf_url":"https://arxiv.org/pdf/2501.15394v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.19289v3","updated":"2025-03-03T07:18:14Z","published":"2024-11-28T17:41:33Z","title":"ADUGS-VINS: Generalized Visual-Inertial Odometry for Robust Navigation\n  in Highly Dynamic and Complex Environments","summary":"  Visual-inertial odometry (VIO) is widely used in various fields, such as\nrobots, drones, and autonomous vehicles. However, real-world scenes often\nfeature dynamic objects, compromising the accuracy of VIO. The diversity and\npartial occlusion of these objects present a tough challenge for existing\ndynamic VIO methods. To tackle this challenge, we introduce ADUGS-VINS, which\nintegrates an enhanced SORT algorithm along with a promptable foundation model\ninto VIO, thereby improving pose estimation accuracy in environments with\ndiverse dynamic objects and frequent occlusions. We evaluated our proposed\nmethod using multiple public datasets representing various scenes, as well as\nin a real-world scenario involving diverse dynamic objects. The experimental\nresults demonstrate that our proposed method performs impressively in multiple\nscenarios, outperforming other state-of-the-art methods. This highlights its\nremarkable generalization and adaptability in diverse dynamic environments,\nshowcasing its potential to handle various dynamic objects in practical\napplications.\n","authors":["Rui Zhou","Jingbin Liu","Junbin Xie","Jianyu Zhang","Yingze Hu","Jiele Zhao"],"pdf_url":"https://arxiv.org/pdf/2411.19289v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2501.05757v2","updated":"2025-03-03T07:07:28Z","published":"2025-01-10T07:19:41Z","title":"Locality-aware Gaussian Compression for Fast and High-quality Rendering","summary":"  We present LocoGS, a locality-aware 3D Gaussian Splatting (3DGS) framework\nthat exploits the spatial coherence of 3D Gaussians for compact modeling of\nvolumetric scenes. To this end, we first analyze the local coherence of 3D\nGaussian attributes, and propose a novel locality-aware 3D Gaussian\nrepresentation that effectively encodes locally-coherent Gaussian attributes\nusing a neural field representation with a minimal storage requirement. On top\nof the novel representation, LocoGS is carefully designed with additional\ncomponents such as dense initialization, an adaptive spherical harmonics\nbandwidth scheme and different encoding schemes for different Gaussian\nattributes to maximize compression performance. Experimental results\ndemonstrate that our approach outperforms the rendering quality of existing\ncompact Gaussian representations for representative real-world 3D datasets\nwhile achieving from 54.6$\\times$ to 96.6$\\times$ compressed storage size and\nfrom 2.1$\\times$ to 2.4$\\times$ rendering speed than 3DGS. Even our approach\nalso demonstrates an averaged 2.4$\\times$ higher rendering speed than the\nstate-of-the-art compression method with comparable compression performance.\n","authors":["Seungjoo Shin","Jaesik Park","Sunghyun Cho"],"pdf_url":"https://arxiv.org/pdf/2501.05757v2.pdf","comment":"Accepted to ICLR 2025. Project page:\n  https://seungjooshin.github.io/LocoGS"},{"id":"http://arxiv.org/abs/2501.12296v2","updated":"2025-03-03T06:45:12Z","published":"2025-01-21T17:03:06Z","title":"RALAD: Bridging the Real-to-Sim Domain Gap in Autonomous Driving with\n  Retrieval-Augmented Learning","summary":"  In the pursuit of robust autonomous driving systems, models trained on\nreal-world datasets often struggle to adapt to new environments, particularly\nwhen confronted with corner cases such as extreme weather conditions.\nCollecting these corner cases in the real world is non-trivial, which\nnecessitates the use of simulators for validation. However,the high\ncomputational cost and the domain gap in data distribution have hindered the\nseamless transition between real and simulated driving scenarios. To tackle\nthis challenge, we propose Retrieval-Augmented Learning for Autonomous Driving\n(RALAD), a novel framework designed to bridge the real-to-sim gap at a low\ncost. RALAD features three primary designs, including (1) domain adaptation via\nan enhanced Optimal Transport (OT) method that accounts for both individual and\ngrouped image distances, (2) a simple and unified framework that can be applied\nto various models, and (3) efficient fine-tuning techniques that freeze the\ncomputationally expensive layers while maintaining robustness. Experimental\nresults demonstrate that RALAD compensates for the performance degradation in\nsimulated environments while maintaining accuracy in real-world scenarios\nacross three different models. Taking Cross View as an example, the mIOU and\nmAP metrics in real-world scenarios remain stable before and after RALAD\nfine-tuning, while in simulated environments,the mIOU and mAP metrics are\nimproved by 10.30% and 12.29%, respectively. Moreover, the re-training cost of\nour approach is reduced by approximately 88.1%. Our code is available at\nhttps://github.com/JiachengZuo/RALAD.git.\n","authors":["Jiacheng Zuo","Haibo Hu","Zikang Zhou","Yufei Cui","Ziquan Liu","Jianping Wang","Nan Guan","Jin Wang","Chun Jason Xue"],"pdf_url":"https://arxiv.org/pdf/2501.12296v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2412.19160v2","updated":"2025-03-03T06:34:25Z","published":"2024-12-26T10:40:15Z","title":"Cross-Spectral Vision Transformer for Biometric Authentication using\n  Forehead Subcutaneous Vein Pattern and Periocular Pattern","summary":"  Traditional biometric systems have encountered significant setbacks due to\nvarious unavoidable factors, for example, face recognition-based biometrics\nfails due to the wearing of face masks and fingerprints create hygiene\nconcerns. This paper proposes a novel lightweight cross-spectral vision\ntransformer (CS-ViT) for biometric authentication using forehead subcutaneous\nvein patterns and periocular patterns, offering a promising alternative to\ntraditional methods, capable of performing well even with the face masks and\nwithout any physical touch. The proposed framework comprises a cross-spectral\ndual-channel architecture designed to handle two distinct biometric traits and\nto capture inter-dependencies in terms of relative spectral patterns. Each\nchannel consists of a Phase-Only Correlation Cross-Spectral Attention (POC-CSA)\nthat captures their individual as well as correlated patterns. The computation\nof cross-spectral attention using POC extracts the phase correlation in the\nspatial features. Therefore, it is robust against the resolution/intensity\nvariations and illumination of the input images, assuming both biometric traits\nare from the same person. The lightweight model is suitable for edge device\ndeployment. The performance of the proposed algorithm was rigorously evaluated\nusing the Forehead Subcutaneous Vein Pattern and Periocular Biometric Pattern\n(FSVP-PBP) database. The results demonstrated the superiority of the algorithm\nover state-of-the-art methods, achieving a remarkable classification accuracy\nof 98.8% with the combined vein and periocular patterns.\n","authors":["Arun K. Sharma","Shubhobrata Bhattacharya","Motahar Reza","Bishakh Bhattacharya"],"pdf_url":"https://arxiv.org/pdf/2412.19160v2.pdf","comment":"Submitted to IEEE TPAMI"},{"id":"http://arxiv.org/abs/2502.20041v2","updated":"2025-03-03T06:21:57Z","published":"2025-02-27T12:29:44Z","title":"3D-AffordanceLLM: Harnessing Large Language Models for Open-Vocabulary\n  Affordance Detection in 3D Worlds","summary":"  3D Affordance detection is a challenging problem with broad applications on\nvarious robotic tasks. Existing methods typically formulate the detection\nparadigm as a label-based semantic segmentation task. This paradigm relies on\npredefined labels and lacks the ability to comprehend complex natural language,\nresulting in limited generalization in open-world scene. To address these\nlimitations, we reformulate the traditional affordance detection paradigm into\n\\textit{Instruction Reasoning Affordance Segmentation} (IRAS) task. This task\nis designed to output a affordance mask region given a query reasoning text,\nwhich avoids fixed categories of input labels. We accordingly propose the\n\\textit{3D-AffordanceLLM} (3D-ADLLM), a framework designed for reasoning\naffordance detection in 3D open-scene. Specifically, 3D-ADLLM introduces large\nlanguage models (LLMs) to 3D affordance perception with a custom-designed\ndecoder for generating affordance masks, thus achieving open-world reasoning\naffordance detection. In addition, given the scarcity of 3D affordance datasets\nfor training large models, we seek to extract knowledge from general\nsegmentation data and transfer it to affordance detection. Thus, we propose a\nmulti-stage training strategy that begins with a novel pre-training task, i.e.,\n\\textit{Referring Object Part Segmentation}~(ROPS). This stage is designed to\nequip the model with general recognition and segmentation capabilities at the\nobject-part level. Then followed by fine-tuning with the IRAS task, 3D-ADLLM\nobtains the reasoning ability for affordance detection. In summary, 3D-ADLLM\nleverages the rich world knowledge and human-object interaction reasoning\nability of LLMs, achieving approximately an 8\\% improvement in mIoU on\nopen-vocabulary affordance detection tasks.\n","authors":["Hengshuo Chu","Xiang Deng","Qi Lv","Xiaoyang Chen","Yinchuan Li","Jianye Hao","Liqiang Nie"],"pdf_url":"https://arxiv.org/pdf/2502.20041v2.pdf","comment":"ICLR"},{"id":"http://arxiv.org/abs/2310.01405v4","updated":"2025-03-03T06:14:14Z","published":"2023-10-02T17:59:07Z","title":"Representation Engineering: A Top-Down Approach to AI Transparency","summary":"  In this paper, we identify and characterize the emerging area of\nrepresentation engineering (RepE), an approach to enhancing the transparency of\nAI systems that draws on insights from cognitive neuroscience. RepE places\npopulation-level representations, rather than neurons or circuits, at the\ncenter of analysis, equipping us with novel methods for monitoring and\nmanipulating high-level cognitive phenomena in deep neural networks (DNNs). We\nprovide baselines and an initial analysis of RepE techniques, showing that they\noffer simple yet effective solutions for improving our understanding and\ncontrol of large language models. We showcase how these methods can provide\ntraction on a wide range of safety-relevant problems, including honesty,\nharmlessness, power-seeking, and more, demonstrating the promise of top-down\ntransparency research. We hope that this work catalyzes further exploration of\nRepE and fosters advancements in the transparency and safety of AI systems.\n","authors":["Andy Zou","Long Phan","Sarah Chen","James Campbell","Phillip Guo","Richard Ren","Alexander Pan","Xuwang Yin","Mantas Mazeika","Ann-Kathrin Dombrowski","Shashwat Goel","Nathaniel Li","Michael J. Byun","Zifan Wang","Alex Mallen","Steven Basart","Sanmi Koyejo","Dawn Song","Matt Fredrikson","J. Zico Kolter","Dan Hendrycks"],"pdf_url":"https://arxiv.org/pdf/2310.01405v4.pdf","comment":"Code is available at\n  https://github.com/andyzoujm/representation-engineering"},{"id":"http://arxiv.org/abs/2412.10831v2","updated":"2025-03-03T06:13:35Z","published":"2024-12-14T13:28:40Z","title":"Low-Biased General Annotated Dataset Generation","summary":"  Pre-training backbone networks on a general annotated dataset (e.g.,\nImageNet) that comprises numerous manually collected images with category\nannotations has proven to be indispensable for enhancing the generalization\ncapacity of downstream visual tasks. However, those manually collected images\noften exhibit bias, which is non-transferable across either categories or\ndomains, thus causing the model's generalization capacity degeneration. To\nmitigate this problem, we present an low-biased general annotated dataset\ngeneration framework (lbGen). Instead of expensive manual collection, we aim at\ndirectly generating low-biased images with category annotations. To achieve\nthis goal, we propose to leverage the advantage of a multimodal foundation\nmodel (e.g., CLIP), in terms of aligning images in an low-biased semantic space\ndefined by language. Specifically, we develop a bi-level semantic alignment\nloss, which not only forces all generated images to be consistent with the\nsemantic distribution of all categories belonging to the target dataset in an\nadversarial learning manner, but also requires each generated image to match\nthe semantic description of its category name. In addition, we further cast an\nexisting image quality scoring model into a quality assurance loss to preserve\nthe quality of the generated image. By leveraging these two loss functions, we\ncan obtain an low-biased image generation model by simply fine-tuning a\npre-trained diffusion model using only all category names in the target dataset\nas input. Experimental results confirm that, compared with the manually labeled\ndataset or other synthetic datasets, the utilization of our generated\nlow-biased datasets leads to stable generalization capacity enhancement of\ndifferent backbone networks across various tasks, especially in tasks where the\nmanually labeled samples are scarce.\n","authors":["Dengyang Jiang","Haoyu Wang","Lei Zhang","Wei Wei","Guang Dai","Mengmeng Wang","Jingdong Wang","Yanning Zhang"],"pdf_url":"https://arxiv.org/pdf/2412.10831v2.pdf","comment":"Preprint"},{"id":"http://arxiv.org/abs/2410.02268v3","updated":"2025-03-03T05:32:47Z","published":"2024-10-03T07:40:14Z","title":"Structural-Entropy-Based Sample Selection for Efficient and Effective\n  Learning","summary":"  Sample selection improves the efficiency and effectiveness of machine\nlearning models by providing informative and representative samples. Typically,\nsamples can be modeled as a sample graph, where nodes are samples and edges\nrepresent their similarities. Most existing methods are based on local\ninformation, such as the training difficulty of samples, thereby overlooking\nglobal information, such as connectivity patterns. This oversight can result in\nsuboptimal selection because global information is crucial for ensuring that\nthe selected samples well represent the structural properties of the graph. To\naddress this issue, we employ structural entropy to quantify global information\nand losslessly decompose it from the whole graph to individual nodes using the\nShapley value. Based on the decomposition, we present\n$\\textbf{S}$tructural-$\\textbf{E}$ntropy-based sample $\\textbf{S}$election\n($\\textbf{SES}$), a method that integrates both global and local information to\nselect informative and representative samples. SES begins by constructing a\n$k$NN-graph among samples based on their similarities. It then measures sample\nimportance by combining structural entropy (global metric) with training\ndifficulty (local metric). Finally, SES applies importance-biased blue noise\nsampling to select a set of diverse and representative samples. Comprehensive\nexperiments on three learning scenarios -- supervised learning, active\nlearning, and continual learning -- clearly demonstrate the effectiveness of\nour method.\n","authors":["Tianchi Xie","Jiangning Zhu","Guozu Ma","Minzhi Lin","Wei Chen","Weikai Yang","Shixia Liu"],"pdf_url":"https://arxiv.org/pdf/2410.02268v3.pdf","comment":"Published as a conference paper at ICLR 2025"},{"id":"http://arxiv.org/abs/2404.12379v3","updated":"2025-03-03T05:31:09Z","published":"2024-04-18T17:58:16Z","title":"Dynamic Gaussians Mesh: Consistent Mesh Reconstruction from Dynamic\n  Scenes","summary":"  Modern 3D engines and graphics pipelines require mesh as a memory-efficient\nrepresentation, which allows efficient rendering, geometry processing, texture\nediting, and many other downstream operations. However, it is still highly\ndifficult to obtain high-quality mesh in terms of detailed structure and time\nconsistency from dynamic observations. To this end, we introduce Dynamic\nGaussians Mesh (DG-Mesh), a framework to reconstruct a high-fidelity and\ntime-consistent mesh from dynamic input. Our work leverages the recent\nadvancement in 3D Gaussian Splatting to construct the mesh sequence with\ntemporal consistency from dynamic observations. Building on top of this\nrepresentation, DG-Mesh recovers high-quality meshes from the Gaussian points\nand can track the mesh vertices over time, which enables applications such as\ntexture editing on dynamic objects. We introduce the Gaussian-Mesh Anchoring,\nwhich encourages evenly distributed Gaussians, resulting better mesh\nreconstruction through mesh-guided densification and pruning on the deformed\nGaussians. By applying cycle-consistent deformation between the canonical and\nthe deformed space, we can project the anchored Gaussian back to the canonical\nspace and optimize Gaussians across all time frames. During the evaluation on\ndifferent datasets, DG-Mesh provides significantly better mesh reconstruction\nand rendering than baselines. Project page: https://www.liuisabella.com/DG-Mesh\n","authors":["Isabella Liu","Hao Su","Xiaolong Wang"],"pdf_url":"https://arxiv.org/pdf/2404.12379v3.pdf","comment":"Project page: https://www.liuisabella.com/DG-Mesh"},{"id":"http://arxiv.org/abs/2410.09374v3","updated":"2025-03-03T05:31:05Z","published":"2024-10-12T05:35:27Z","title":"ESVO2: Direct Visual-Inertial Odometry with Stereo Event Cameras","summary":"  Event-based visual odometry is a specific branch of visual Simultaneous\nLocalization and Mapping (SLAM) techniques, which aims at solving tracking and\nmapping subproblems (typically in parallel), by exploiting the special working\nprinciples of neuromorphic (i.e., event-based) cameras. Due to the\nmotion-dependent nature of event data, explicit data association (i.e., feature\nmatching) under large-baseline view-point changes is difficult to establish,\nmaking direct methods a more rational choice. However, state-of-the-art direct\nmethods are limited by the high computational complexity of the mapping\nsub-problem and the degeneracy of camera pose tracking in certain degrees of\nfreedom (DoF) in rotation. In this paper, we tackle these issues by building an\nevent-based stereo visual-inertial odometry system on top of a direct pipeline.\nSpecifically, to speed up the mapping operation, we propose an efficient\nstrategy for sampling contour points according to the local dynamics of events.\nThe mapping performance is also improved in terms of structure completeness and\nlocal smoothness by merging the temporal stereo and static stereo results. To\ncircumvent the degeneracy of camera pose tracking in recovering the pitch and\nyaw components of general 6-DoF motion, we introduce IMU measurements as motion\npriors via pre-integration. To this end, a compact back-end is proposed for\ncontinuously updating the IMU bias and predicting the linear velocity, enabling\nan accurate motion prediction for camera pose tracking. The resulting system\nscales well with modern high-resolution event cameras and leads to better\nglobal positioning accuracy in large-scale outdoor environments. Extensive\nevaluations on five publicly available datasets featuring different resolutions\nand scenarios justify the superior performance of the proposed system against\nfive state-of-the-art methods.\n","authors":["Junkai Niu","Sheng Zhong","Xiuyuan Lu","Shaojie Shen","Guillermo Gallego","Yi Zhou"],"pdf_url":"https://arxiv.org/pdf/2410.09374v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2502.10988v2","updated":"2025-03-03T05:26:25Z","published":"2025-02-16T04:18:41Z","title":"OMG: Opacity Matters in Material Modeling with Gaussian Splatting","summary":"  Decomposing geometry, materials and lighting from a set of images, namely\ninverse rendering, has been a long-standing problem in computer vision and\ngraphics. Recent advances in neural rendering enable photo-realistic and\nplausible inverse rendering results. The emergence of 3D Gaussian Splatting has\nboosted it to the next level by showing real-time rendering potentials. An\nintuitive finding is that the models used for inverse rendering do not take\ninto account the dependency of opacity w.r.t. material properties, namely cross\nsection, as suggested by optics. Therefore, we develop a novel approach that\nadds this dependency to the modeling itself. Inspired by radiative transfer, we\naugment the opacity term by introducing a neural network that takes as input\nmaterial properties to provide modeling of cross section and a physically\ncorrect activation function. The gradients for material properties are\ntherefore not only from color but also from opacity, facilitating a constraint\nfor their optimization. Therefore, the proposed method incorporates more\naccurate physical properties compared to previous works. We implement our\nmethod into 3 different baselines that use Gaussian Splatting for inverse\nrendering and achieve significant improvements universally in terms of novel\nview synthesis and material modeling.\n","authors":["Silong Yong","Venkata Nagarjun Pudureddiyur Manivannan","Bernhard Kerbl","Zifu Wan","Simon Stepputtis","Katia Sycara","Yaqi Xie"],"pdf_url":"https://arxiv.org/pdf/2502.10988v2.pdf","comment":"Published as a conference paper at ICLR 2025"},{"id":"http://arxiv.org/abs/2502.01912v2","updated":"2025-03-03T05:25:43Z","published":"2025-02-04T01:05:12Z","title":"PATCH: a deep learning method to assess heterogeneity of artistic\n  practice in historical paintings","summary":"  The history of art has seen significant shifts in the manner in which\nartworks are created, making understanding of creative processes a central\nquestion in technical art history. In the Renaissance and Early Modern period,\npaintings were largely produced by master painters directing workshops of\napprentices who often contributed to projects. The masters varied significantly\nin artistic and managerial styles, meaning different combinations of artists\nand implements might be seen both between masters and within workshops or even\nindividual canvases. Information on how different workshops were managed and\nthe processes by which artworks were created remains elusive. Machine learning\nmethods have potential to unearth new information about artists' creative\nprocesses by extending the analysis of brushwork to a microscopic scale.\nAnalysis of workshop paintings, however, presents a challenge in that\ndocumentation of the artists and materials involved is sparse, meaning external\nexamples are not available to train networks to recognize their contributions.\nHere we present a novel machine learning approach we call pairwise assignment\ntraining for classifying heterogeneity (PATCH) that is capable of identifying\nindividual artistic practice regimes with no external training data, or \"ground\ntruth.\" The method achieves unsupervised results by supervised means, and\noutperforms both simple statistical procedures and unsupervised machine\nlearning methods. We apply this method to two historical paintings by the\nSpanish Renaissance master, El Greco: The Baptism of Christ and Christ on the\nCross with Landscape, and our findings regarding the former potentially\nchallenge previous work that has assigned the painting to workshop members.\nFurther, the results of our analyses create a measure of heterogeneity of\nartistic practice that can be used to characterize artworks across time and\nspace.\n","authors":["Andrew Van Horn","Lauryn Smith","Mahamad Mahmoud","Michael McMaster","Clara Pinchbeck","Ina Martin","Andrew Lininger","Anthony Ingrisano","Adam Lowe","Carlos Bayod","Elizabeth Bolman","Kenneth Singer","Michael Hinczewski"],"pdf_url":"https://arxiv.org/pdf/2502.01912v2.pdf","comment":"main text: 16 pages, 6 figures; SI: 7 pages, 3 figures; v2: minor\n  typo corrections, higher resolution figures"},{"id":"http://arxiv.org/abs/2402.02112v5","updated":"2025-03-03T04:42:15Z","published":"2024-02-03T10:35:42Z","title":"S-NeRF++: Autonomous Driving Simulation via Neural Reconstruction and\n  Generation","summary":"  Autonomous driving simulation system plays a crucial role in enhancing\nself-driving data and simulating complex and rare traffic scenarios, ensuring\nnavigation safety. However, traditional simulation systems, which often heavily\nrely on manual modeling and 2D image editing, struggled with scaling to\nextensive scenes and generating realistic simulation data. In this study, we\npresent S-NeRF++, an innovative autonomous driving simulation system based on\nneural reconstruction. Trained on widely-used self-driving datasets such as\nnuScenes and Waymo, S-NeRF++ can generate a large number of realistic street\nscenes and foreground objects with high rendering quality as well as offering\nconsiderable flexibility in manipulation and simulation. Specifically, S-NeRF++\nis an enhanced neural radiance field for synthesizing large-scale scenes and\nmoving vehicles, with improved scene parameterization and camera pose learning.\nThe system effectively utilizes noisy and sparse LiDAR data to refine training\nand address depth outliers, ensuring high-quality reconstruction and novel-view\nrendering. It also provides a diverse foreground asset bank by reconstructing\nand generating different foreground vehicles to support comprehensive scenario\ncreation.Moreover, we have developed an advanced foreground-background fusion\npipeline that skillfully integrates illumination and shadow effects, further\nenhancing the realism of our simulations. With the high-quality simulated data\nprovided by our S-NeRF++, we found the perception methods enjoy performance\nboosts on several autonomous driving downstream tasks, further demonstrating\nour proposed simulator's effectiveness.\n","authors":["Yurui Chen","Junge Zhang","Ziyang Xie","Wenye Li","Feihu Zhang","Jiachen Lu","Li Zhang"],"pdf_url":"https://arxiv.org/pdf/2402.02112v5.pdf","comment":"IEEE TPAMI 2025"},{"id":"http://arxiv.org/abs/2409.07002v2","updated":"2025-03-03T04:32:29Z","published":"2024-09-11T04:30:45Z","title":"AdvLogo: Adversarial Patch Attack against Object Detectors based on\n  Diffusion Models","summary":"  With the rapid development of deep learning, object detectors have\ndemonstrated impressive performance; however, vulnerabilities still exist in\ncertain scenarios. Current research exploring the vulnerabilities using\nadversarial patches often struggles to balance the trade-off between attack\neffectiveness and visual quality. To address this problem, we propose a novel\nframework of patch attack from semantic perspective, which we refer to as\nAdvLogo. Based on the hypothesis that every semantic space contains an\nadversarial subspace where images can cause detectors to fail in recognizing\nobjects, we leverage the semantic understanding of the diffusion denoising\nprocess and drive the process to adversarial subareas by perturbing the latent\nand unconditional embeddings at the last timestep. To mitigate the distribution\nshift that exposes a negative impact on image quality, we apply perturbation to\nthe latent in frequency domain with the Fourier Transform. Experimental results\ndemonstrate that AdvLogo achieves strong attack performance while maintaining\nhigh visual quality.\n","authors":["Boming Miao","Chunxiao Li","Yao Zhu","Weixiang Sun","Zizhe Wang","Xiaoyi Wang","Chuanlong Xie"],"pdf_url":"https://arxiv.org/pdf/2409.07002v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.18084v2","updated":"2025-03-03T04:31:23Z","published":"2024-10-23T17:59:58Z","title":"DynamicCity: Large-Scale 4D Occupancy Generation from Dynamic Scenes","summary":"  Urban scene generation has been developing rapidly recently. However,\nexisting methods primarily focus on generating static and single-frame scenes,\noverlooking the inherently dynamic nature of real-world driving environments.\nIn this work, we introduce DynamicCity, a novel 4D occupancy generation\nframework capable of generating large-scale, high-quality dynamic 4D scenes\nwith semantics. DynamicCity mainly consists of two key models. 1) A VAE model\nfor learning HexPlane as the compact 4D representation. Instead of using naive\naveraging operations, DynamicCity employs a novel Projection Module to\neffectively compress 4D features into six 2D feature maps for HexPlane\nconstruction, which significantly enhances HexPlane fitting quality (up to\n12.56 mIoU gain). Furthermore, we utilize an Expansion & Squeeze Strategy to\nreconstruct 3D feature volumes in parallel, which improves both network\ntraining efficiency and reconstruction accuracy than naively querying each 3D\npoint (up to 7.05 mIoU gain, 2.06x training speedup, and 70.84% memory\nreduction). 2) A DiT-based diffusion model for HexPlane generation. To make\nHexPlane feasible for DiT generation, a Padded Rollout Operation is proposed to\nreorganize all six feature planes of the HexPlane as a squared 2D feature map.\nIn particular, various conditions could be introduced in the diffusion or\nsampling process, supporting versatile 4D generation applications, such as\ntrajectory- and command-driven generation, inpainting, and layout-conditioned\ngeneration. Extensive experiments on the CarlaSC and Waymo datasets demonstrate\nthat DynamicCity significantly outperforms existing state-of-the-art 4D\noccupancy generation methods across multiple metrics. The code and models have\nbeen released to facilitate future research.\n","authors":["Hengwei Bian","Lingdong Kong","Haozhe Xie","Liang Pan","Yu Qiao","Ziwei Liu"],"pdf_url":"https://arxiv.org/pdf/2410.18084v2.pdf","comment":"ICLR 2025 Spotlight; 35 pages, 18 figures, 15 tables; Project Page at\n  https://dynamic-city.github.io/"},{"id":"http://arxiv.org/abs/2403.17010v3","updated":"2025-03-03T04:22:19Z","published":"2024-03-25T17:59:59Z","title":"Calib3D: Calibrating Model Preferences for Reliable 3D Scene\n  Understanding","summary":"  Safety-critical 3D scene understanding tasks necessitate not only accurate\nbut also confident predictions from 3D perception models. This study introduces\nCalib3D, a pioneering effort to benchmark and scrutinize the reliability of 3D\nscene understanding models from an uncertainty estimation viewpoint. We\ncomprehensively evaluate 28 state-of-the-art models across 10 diverse 3D\ndatasets, uncovering insightful phenomena that cope with both the aleatoric and\nepistemic uncertainties in 3D scene understanding. We discover that despite\nachieving impressive levels of accuracy, existing models frequently fail to\nprovide reliable uncertainty estimates -- a pitfall that critically undermines\ntheir applicability in safety-sensitive contexts. Through extensive analysis of\nkey factors such as network capacity, LiDAR representations, rasterization\nresolutions, and 3D data augmentation techniques, we correlate these aspects\ndirectly with the model calibration efficacy. Furthermore, we introduce DeptS,\na novel depth-aware scaling approach aimed at enhancing 3D model calibration.\nExtensive experiments across a wide range of configurations validate the\nsuperiority of our method. We hope this work could serve as a cornerstone for\nfostering reliable 3D scene understanding. Code and benchmark toolkit are\npublicly available.\n","authors":["Lingdong Kong","Xiang Xu","Jun Cen","Wenwei Zhang","Liang Pan","Kai Chen","Ziwei Liu"],"pdf_url":"https://arxiv.org/pdf/2403.17010v3.pdf","comment":"WACV 2025 Oral; 26 pages, 8 figures, 12 tables; Code at\n  https://github.com/ldkong1205/Calib3D"},{"id":"http://arxiv.org/abs/2410.03190v3","updated":"2025-03-03T04:11:46Z","published":"2024-10-04T07:05:16Z","title":"Tuning Timestep-Distilled Diffusion Model Using Pairwise Sample\n  Optimization","summary":"  Recent advancements in timestep-distilled diffusion models have enabled\nhigh-quality image generation that rivals non-distilled multi-step models, but\nwith significantly fewer inference steps. While such models are attractive for\napplications due to the low inference cost and latency, fine-tuning them with a\nnaive diffusion objective would result in degraded and blurry outputs. An\nintuitive alternative is to repeat the diffusion distillation process with a\nfine-tuned teacher model, which produces good results but is cumbersome and\ncomputationally intensive; the distillation training usually requires magnitude\nhigher of training compute compared to fine-tuning for specific image styles.\nIn this paper, we present an algorithm named pairwise sample optimization\n(PSO), which enables the direct fine-tuning of an arbitrary timestep-distilled\ndiffusion model. PSO introduces additional reference images sampled from the\ncurrent time-step distilled model, and increases the relative likelihood margin\nbetween the training images and reference images. This enables the model to\nretain its few-step generation ability, while allowing for fine-tuning of its\noutput distribution. We also demonstrate that PSO is a generalized formulation\nwhich can be flexibly extended to both offline-sampled and online-sampled\npairwise data, covering various popular objectives for diffusion model\npreference optimization. We evaluate PSO in both preference optimization and\nother fine-tuning tasks, including style transfer and concept customization. We\nshow that PSO can directly adapt distilled models to human-preferred generation\nwith both offline and online-generated pairwise preference image data. PSO also\ndemonstrates effectiveness in style transfer and concept customization by\ndirectly tuning timestep-distilled diffusion models.\n","authors":["Zichen Miao","Zhengyuan Yang","Kevin Lin","Ze Wang","Zicheng Liu","Lijuan Wang","Qiang Qiu"],"pdf_url":"https://arxiv.org/pdf/2410.03190v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2502.21093v2","updated":"2025-03-03T03:48:47Z","published":"2025-02-28T14:32:04Z","title":"FlexDrive: Toward Trajectory Flexibility in Driving Scene Reconstruction\n  and Rendering","summary":"  Driving scene reconstruction and rendering have advanced significantly using\nthe 3D Gaussian Splatting. However, most prior research has focused on the\nrendering quality along a pre-recorded vehicle path and struggles to generalize\nto out-of-path viewpoints, which is caused by the lack of high-quality\nsupervision in those out-of-path views. To address this issue, we introduce an\nInverse View Warping technique to create compact and high-quality images as\nsupervision for the reconstruction of the out-of-path views, enabling\nhigh-quality rendering results for those views. For accurate and robust inverse\nview warping, a depth bootstrap strategy is proposed to obtain on-the-fly dense\ndepth maps during the optimization process, overcoming the sparsity and\nincompleteness of LiDAR depth data. Our method achieves superior in-path and\nout-of-path reconstruction and rendering performance on the widely used Waymo\nOpen dataset. In addition, a simulator-based benchmark is proposed to obtain\nthe out-of-path ground truth and quantitatively evaluate the performance of\nout-of-path rendering, where our method outperforms previous methods by a\nsignificant margin.\n","authors":["Jingqiu Zhou","Lue Fan","Linjiang Huang","Xiaoyu Shi","Si Liu","Zhaoxiang Zhang","Hongsheng Li"],"pdf_url":"https://arxiv.org/pdf/2502.21093v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2305.02586v2","updated":"2025-03-03T03:38:29Z","published":"2023-05-04T06:40:11Z","title":"Semantically Structured Image Compression via Irregular Group-Based\n  Decoupling","summary":"  Image compression techniques typically focus on compressing rectangular\nimages for human consumption, however, resulting in transmitting redundant\ncontent for downstream applications. To overcome this limitation, some previous\nworks propose to semantically structure the bitstream, which can meet specific\napplication requirements by selective transmission and reconstruction.\nNevertheless, they divide the input image into multiple rectangular regions\naccording to semantics and ignore avoiding information interaction among them,\ncausing waste of bitrate and distorted reconstruction of region boundaries. In\nthis paper, we propose to decouple an image into multiple groups with irregular\nshapes based on a customized group mask and compress them independently. Our\ngroup mask describes the image at a finer granularity, enabling significant\nbitrate saving by reducing the transmission of redundant content. Moreover, to\nensure the fidelity of selective reconstruction, this paper proposes the\nconcept of group-independent transform that maintain the independence among\ndistinct groups. And we instantiate it by the proposed Group-Independent\nSwin-Block (GI Swin-Block). Experimental results demonstrate that our framework\nstructures the bitstream with negligible cost, and exhibits superior\nperformance on both visual quality and intelligent task supporting.\n","authors":["Ruoyu Feng","Yixin Gao","Xin Jin","Runsen Feng","Zhibo Chen"],"pdf_url":"https://arxiv.org/pdf/2305.02586v2.pdf","comment":"Accept by ICCV2023"},{"id":"http://arxiv.org/abs/2502.01117v2","updated":"2025-03-03T03:35:00Z","published":"2025-02-03T07:13:59Z","title":"Learning to Learn Weight Generation via Trajectory Diffusion","summary":"  Diffusion-based algorithms have emerged as promising techniques for weight\ngeneration, particularly in scenarios like multi-task learning that require\nfrequent weight updates. However, existing solutions suffer from limited\ncross-task transferability. In addition, they only utilize optimal weights as\ntraining samples, ignoring the value of other weights in the optimization\nprocess. To address these issues, we propose Lt-Di, which integrates the\ndiffusion algorithm with meta-learning to generate weights for unseen tasks.\nFurthermore, we extend the vanilla diffusion algorithm into a trajectory\ndiffusion algorithm to utilize other weights along the optimization trajectory.\nTrajectory diffusion decomposes the entire diffusion chain into multiple\nshorter ones, improving training and inference efficiency. We analyze the\nconvergence properties of the weight generation paradigm and improve\nconvergence efficiency without additional time overhead. Our experiments\ndemonstrate Lt-Di's higher accuracy while reducing computational overhead\nacross various tasks, including zero-shot and few-shot learning, multi-domain\ngeneralization, and large-scale language model fine-tuning.Our code is released\nat https://anonymous.4open.science/r/Lt-Di-0E51.\n","authors":["Yunchuan Guan","Yu Liu","Ke Zhou","Zhiqi Shen","Serge Belongie","Jenq-Neng Hwang","Lei Li"],"pdf_url":"https://arxiv.org/pdf/2502.01117v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.21256v2","updated":"2025-03-03T03:23:44Z","published":"2024-10-28T17:54:29Z","title":"Multi-modal AI for comprehensive breast cancer prognostication","summary":"  Treatment selection in breast cancer is guided by molecular subtypes and\nclinical characteristics. However, current tools including genomic assays lack\nthe accuracy required for optimal clinical decision-making. We developed a\nnovel artificial intelligence (AI)-based approach that integrates digital\npathology images with clinical data, providing a more robust and effective\nmethod for predicting the risk of cancer recurrence in breast cancer patients.\nSpecifically, we utilized a vision transformer pan-cancer foundation model\ntrained with self-supervised learning to extract features from digitized\nH&E-stained slides. These features were integrated with clinical data to form a\nmulti-modal AI test predicting cancer recurrence and death. The test was\ndeveloped and evaluated using data from a total of 8,161 female breast cancer\npatients across 15 cohorts originating from seven countries. Of these, 3,502\npatients from five cohorts were used exclusively for evaluation, while the\nremaining patients were used for training. Our test accurately predicted our\nprimary endpoint, disease-free interval, in the five evaluation cohorts\n(C-index: 0.71 [0.68-0.75], HR: 3.63 [3.02-4.37, p<0.001]). In a direct\ncomparison (n=858), the AI test was more accurate than Oncotype DX, the\nstandard-of-care 21-gene assay, achieving a C-index of 0.67 [0.61-0.74] versus\n0.61 [0.49-0.73], respectively. Additionally, the AI test added independent\nprognostic information to Oncotype DX in a multivariate analysis (HR: 3.11\n[1.91-5.09, p<0.001)]). The test demonstrated robust accuracy across major\nmolecular breast cancer subtypes, including TNBC (C-index: 0.71 [0.62-0.81],\nHR: 3.81 [2.35-6.17, p=0.02]), where no diagnostic tools are currently\nrecommended by clinical guidelines. These results suggest that our AI test\nimproves upon the accuracy of existing prognostic tests, while being applicable\nto a wider range of patients.\n","authors":["Jan Witowski","Ken G. Zeng","Joseph Cappadona","Jailan Elayoubi","Khalil Choucair","Elena Diana Chiru","Nancy Chan","Young-Joon Kang","Frederick Howard","Irina Ostrovnaya","Carlos Fernandez-Granda","Freya Schnabel","Zoe Steinsnyder","Ugur Ozerdem","Kangning Liu","Waleed Abdulsattar","Yu Zong","Lina Daoud","Rafic Beydoun","Anas Saad","Nitya Thakore","Mohammad Sadic","Frank Yeung","Elisa Liu","Theodore Hill","Benjamin Swett","Danielle Rigau","Andrew Clayburn","Valerie Speirs","Marcus Vetter","Lina Sojak","Simone Soysal","Daniel Baumhoer","Jia-Wern Pan","Haslina Makmur","Soo-Hwang Teo","Linda Ma Pak","Victor Angel","Dovile Zilenaite-Petrulaitiene","Arvydas Laurinavicius","Natalie Klar","Brian D. Piening","Carlo Bifulco","Sun-Young Jun","Jae Pak Yi","Su Hyun Lim","Adam Brufsky","Francisco J. Esteva","Lajos Pusztai","Yann LeCun","Krzysztof J. Geras"],"pdf_url":"https://arxiv.org/pdf/2410.21256v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2405.14093v3","updated":"2025-03-03T03:19:31Z","published":"2024-05-23T01:43:54Z","title":"A Survey on Vision-Language-Action Models for Embodied AI","summary":"  Embodied AI is widely recognized as a key element of artificial general\nintelligence because it involves controlling embodied agents to perform tasks\nin the physical world. Building on the success of large language models and\nvision-language models, a new category of multimodal models -- referred to as\nvision-language-action models (VLAs) -- has emerged to address\nlanguage-conditioned robotic tasks in embodied AI by leveraging their distinct\nability to generate actions. In recent years, a myriad of VLAs have been\ndeveloped, making it imperative to capture the rapidly evolving landscape\nthrough a comprehensive survey. To this end, we present the first survey on\nVLAs for embodied AI. This work provides a detailed taxonomy of VLAs, organized\ninto three major lines of research. The first line focuses on individual\ncomponents of VLAs. The second line is dedicated to developing control policies\nadept at predicting low-level actions. The third line comprises high-level task\nplanners capable of decomposing long-horizon tasks into a sequence of subtasks,\nthereby guiding VLAs to follow more general user instructions. Furthermore, we\nprovide an extensive summary of relevant resources, including datasets,\nsimulators, and benchmarks. Finally, we discuss the challenges faced by VLAs\nand outline promising future directions in embodied AI.\n","authors":["Yueen Ma","Zixing Song","Yuzheng Zhuang","Jianye Hao","Irwin King"],"pdf_url":"https://arxiv.org/pdf/2405.14093v3.pdf","comment":"16 pages, a survey of vision-language-action models"},{"id":"http://arxiv.org/abs/2501.12844v2","updated":"2025-03-03T03:18:40Z","published":"2025-01-22T12:45:09Z","title":"GAMED-Snake: Gradient-aware Adaptive Momentum Evolution Deep Snake Model\n  for Multi-organ Segmentation","summary":"  Multi-organ segmentation is a critical yet challenging task due to complex\nanatomical backgrounds, blurred boundaries, and diverse morphologies. This\nstudy introduces the Gradient-aware Adaptive Momentum Evolution Deep Snake\n(GAMED-Snake) model, which establishes a novel paradigm for contour-based\nsegmentation by integrating gradient-based learning with adaptive momentum\nevolution mechanisms. The GAMED-Snake model incorporates three major\ninnovations: First, the Distance Energy Map Prior (DEMP) generates a\npixel-level force field that effectively attracts contour points towards the\ntrue boundaries, even in scenarios with complex backgrounds and blurred edges.\nSecond, the Differential Convolution Inception Module (DCIM) precisely extracts\ncomprehensive energy gradients, significantly enhancing segmentation accuracy.\nThird, the Adaptive Momentum Evolution Mechanism (AMEM) employs cross-attention\nto establish dynamic features across different iterations of evolution,\nenabling precise boundary alignment for diverse morphologies. Experimental\nresults on four challenging multi-organ segmentation datasets demonstrate that\nGAMED-Snake improves the mDice metric by approximately 2% compared to\nstate-of-the-art methods. Code will be available at\nhttps://github.com/SYSUzrc/GAMED-Snake.\n","authors":["Ruicheng Zhang","Haowei Guo","Zeyu Zhang","Puxin Yan","Shen Zhao"],"pdf_url":"https://arxiv.org/pdf/2501.12844v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2502.16826v2","updated":"2025-03-03T03:09:49Z","published":"2025-02-24T04:23:21Z","title":"Noise2Score3D:Unsupervised Tweedie's Approach for Point Cloud Denoising","summary":"  Building on recent advances in Bayesian statistics and image denoising, we\npropose Noise2Score3D, a fully unsupervised framework for point cloud denoising\nthat addresses the critical challenge of limited availability of clean data.\nNoise2Score3D learns the gradient of the underlying point cloud distribution\ndirectly from noisy data, eliminating the need for clean data during training.\nBy leveraging Tweedie's formula, our method performs inference in a single\nstep, avoiding the iterative processes used in existing unsupervised methods,\nthereby improving both performance and efficiency. Experimental results\ndemonstrate that Noise2Score3D achieves state-of-the-art performance on\nstandard benchmarks, outperforming other unsupervised methods in Chamfer\ndistance and point-to-mesh metrics, and rivaling some supervised approaches.\nFurthermore, Noise2Score3D demonstrates strong generalization ability beyond\ntraining datasets. Additionally, we introduce Total Variation for Point Cloud,\na criterion that allows for the estimation of unknown noise parameters, which\nfurther enhances the method's versatility and real-world utility.\n","authors":["Xiangbin Wei"],"pdf_url":"https://arxiv.org/pdf/2502.16826v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.13085v2","updated":"2025-03-03T03:08:28Z","published":"2024-10-16T23:03:27Z","title":"MMed-RAG: Versatile Multimodal RAG System for Medical Vision Language\n  Models","summary":"  Artificial Intelligence (AI) has demonstrated significant potential in\nhealthcare, particularly in disease diagnosis and treatment planning. Recent\nprogress in Medical Large Vision-Language Models (Med-LVLMs) has opened up new\npossibilities for interactive diagnostic tools. However, these models often\nsuffer from factual hallucination, which can lead to incorrect diagnoses.\nFine-tuning and retrieval-augmented generation (RAG) have emerged as methods to\naddress these issues. However, the amount of high-quality data and distribution\nshifts between training data and deployment data limit the application of\nfine-tuning methods. Although RAG is lightweight and effective, existing\nRAG-based approaches are not sufficiently general to different medical domains\nand can potentially cause misalignment issues, both between modalities and\nbetween the model and the ground truth. In this paper, we propose a versatile\nmultimodal RAG system, MMed-RAG, designed to enhance the factuality of\nMed-LVLMs. Our approach introduces a domain-aware retrieval mechanism, an\nadaptive retrieved contexts selection method, and a provable RAG-based\npreference fine-tuning strategy. These innovations make the RAG process\nsufficiently general and reliable, significantly improving alignment when\nintroducing retrieved contexts. Experimental results across five medical\ndatasets (involving radiology, ophthalmology, pathology) on medical VQA and\nreport generation demonstrate that MMed-RAG can achieve an average improvement\nof 43.8% in the factual accuracy of Med-LVLMs. Our data and code are available\nin https://github.com/richard-peng-xia/MMed-RAG.\n","authors":["Peng Xia","Kangyu Zhu","Haoran Li","Tianze Wang","Weijia Shi","Sheng Wang","Linjun Zhang","James Zou","Huaxiu Yao"],"pdf_url":"https://arxiv.org/pdf/2410.13085v2.pdf","comment":"ICLR 2025"},{"id":"http://arxiv.org/abs/2409.06214v3","updated":"2025-03-03T01:46:42Z","published":"2024-09-10T04:45:25Z","title":"Towards Generalizable Scene Change Detection","summary":"  While current state-of-the-art Scene Change Detection (SCD) approaches\nachieve impressive results in well-trained research data, they become\nunreliable under unseen environments and different temporal conditions;\nin-domain performance drops from 77.6\\% to 8.0\\% in a previously unseen\nenvironment and to 4.6\\% under a different temporal condition -- calling for\ngeneralizable SCD and benchmark. In this work, we propose the Generalizable\nScene Change Detection Framework (GeSCF), which addresses unseen domain\nperformance and temporal consistency -- to meet the growing demand for anything\nSCD. Our method leverages the pre-trained Segment Anything Model (SAM) in a\nzero-shot manner. For this, we design Initial Pseudo-mask Generation and\nGeometric-Semantic Mask Matching -- seamlessly turning user-guided prompt and\nsingle-image based segmentation into scene change detection for a pair of\ninputs without guidance. Furthermore, we define the Generalizable Scene Change\nDetection (GeSCD) benchmark along with novel metrics and an evaluation protocol\nto facilitate SCD research in generalizability. In the process, we introduce\nthe ChangeVPR dataset, a collection of challenging image pairs with diverse\nenvironmental scenarios -- including urban, suburban, and rural settings.\nExtensive experiments across various datasets demonstrate that GeSCF achieves\nan average performance gain of 19.2\\% on existing SCD datasets and 30.0\\% on\nthe ChangeVPR dataset, nearly doubling the prior art performance. We believe\nour work can lay a solid foundation for robust and generalizable SCD research.\n","authors":["Jaewoo Kim","Uehwan Kim"],"pdf_url":"https://arxiv.org/pdf/2409.06214v3.pdf","comment":"Manuscript. Accepted to CVPR 2025"},{"id":"http://arxiv.org/abs/2502.08079v3","updated":"2025-03-03T01:35:58Z","published":"2025-02-12T02:53:27Z","title":"MAA: Meticulous Adversarial Attack against Vision-Language Pre-trained\n  Models","summary":"  Current adversarial attacks for evaluating the robustness of vision-language\npre-trained (VLP) models in multi-modal tasks suffer from limited\ntransferability, where attacks crafted for a specific model often struggle to\ngeneralize effectively across different models, limiting their utility in\nassessing robustness more broadly. This is mainly attributed to the\nover-reliance on model-specific features and regions, particularly in the image\nmodality. In this paper, we propose an elegant yet highly effective method\ntermed Meticulous Adversarial Attack (MAA) to fully exploit model-independent\ncharacteristics and vulnerabilities of individual samples, achieving enhanced\ngeneralizability and reduced model dependence. MAA emphasizes fine-grained\noptimization of adversarial images by developing a novel resizing and sliding\ncrop (RScrop) technique, incorporating a multi-granularity similarity\ndisruption (MGSD) strategy. Extensive experiments across diverse VLP models,\nmultiple benchmark datasets, and a variety of downstream tasks demonstrate that\nMAA significantly enhances the effectiveness and transferability of adversarial\nattacks. A large cohort of performance studies is conducted to generate\ninsights into the effectiveness of various model configurations, guiding future\nadvancements in this domain.\n","authors":["Peng-Fei Zhang","Guangdong Bai","Zi Huang"],"pdf_url":"https://arxiv.org/pdf/2502.08079v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2409.14519v2","updated":"2025-03-03T00:51:41Z","published":"2024-09-22T16:25:31Z","title":"RobotFingerPrint: Unified Gripper Coordinate Space for Multi-Gripper\n  Grasp Synthesis and Transfer","summary":"  We introduce a novel grasp representation named the Unified Gripper\nCoordinate Space (UGCS) for grasp synthesis and grasp transfer. Our\nrepresentation leverages spherical coordinates to create a shared coordinate\nspace across different robot grippers, enabling it to synthesize and transfer\ngrasps for both novel objects and previously unseen grippers. The strength of\nthis representation lies in the ability to map palm and fingers of a gripper\nand the unified coordinate space. Grasp synthesis is formulated as predicting\nthe unified spherical coordinates on object surface points via a conditional\nvariational autoencoder. The predicted unified gripper coordinates establish\nexact correspondences between the gripper and object points, which is used to\noptimize grasp pose and joint values. Grasp transfer is facilitated through the\npoint-to-point correspondence between any two (potentially unseen) grippers and\nsolved via a similar optimization. Extensive simulation and real-world\nexperiments showcase the efficacy of the unified grasp representation for grasp\nsynthesis in generating stable and diverse grasps. Similarly, we showcase\nreal-world grasp transfer from human demonstrations across different objects.\n","authors":["Ninad Khargonkar","Luis Felipe Casas","Balakrishnan Prabhakaran","Yu Xiang"],"pdf_url":"https://arxiv.org/pdf/2409.14519v2.pdf","comment":"8 pages, 11 figures, 3 tables. Project page available at\n  https://irvlutd.github.io/RobotFingerPrint"},{"id":"http://arxiv.org/abs/2410.01417v2","updated":"2025-03-03T00:41:36Z","published":"2024-10-02T10:58:54Z","title":"The Labyrinth of Links: Navigating the Associative Maze of Multi-modal\n  LLMs","summary":"  Multi-modal Large Language Models (MLLMs) have exhibited impressive\ncapability. However, recently many deficiencies of MLLMs have been found\ncompared to human intelligence, $\\textit{e.g.}$, hallucination. To drive the\nMLLMs study, the community dedicated efforts to building larger benchmarks with\ncomplex tasks. In this paper, we propose benchmarking an essential but usually\noverlooked intelligence: $\\textbf{association}$, a human's basic capability to\nlink observation and prior practice memory. To comprehensively investigate\nMLLM's performance on the association, we formulate the association task and\ndevise a standard benchmark based on adjective and verb semantic concepts.\nInstead of costly data annotation and curation, we propose a convenient\n$\\textbf{annotation-free}$ construction method transforming the general dataset\nfor our association tasks. Simultaneously, we devise a rigorous data refinement\nprocess to eliminate confusion in the raw dataset. Building on this database,\nwe establish three levels of association tasks: single-step, synchronous, and\nasynchronous associations. Moreover, we conduct a comprehensive investigation\ninto the MLLMs' zero-shot association capabilities, addressing multiple\ndimensions, including three distinct memory strategies, both open-source and\nclosed-source MLLMs, cutting-edge Mixture-of-Experts (MoE) models, and the\ninvolvement of human experts. Our systematic investigation shows that current\nopen-source MLLMs consistently exhibit poor capability in our association\ntasks, even the currently state-of-the-art GPT-4V(vision) also has a\nsignificant gap compared to humans. We believe our benchmark would pave the way\nfor future MLLM studies. $\\textit{Our data and code are available at:}$\nhttps://mvig-rhos.com/llm_inception.\n","authors":["Hong Li","Nanxi Li","Yuanjie Chen","Jianbin Zhu","Qinlu Guo","Cewu Lu","Yong-Lu Li"],"pdf_url":"https://arxiv.org/pdf/2410.01417v2.pdf","comment":"Accepted by ICLR 2025. Project page:\n  https://mvig-rhos.com/llm_inception"},{"id":"http://arxiv.org/abs/2409.04607v2","updated":"2025-03-03T00:20:29Z","published":"2024-09-06T20:32:53Z","title":"Self-Supervised Contrastive Learning for Videos using Differentiable\n  Local Alignment","summary":"  Robust frame-wise embeddings are essential to perform video analysis and\nunderstanding tasks. We present a self-supervised method for representation\nlearning based on aligning temporal video sequences. Our framework uses a\ntransformer-based encoder to extract frame-level features and leverages them to\nfind the optimal alignment path between video sequences. We introduce the novel\nLocal-Alignment Contrastive (LAC) loss, which combines a differentiable local\nalignment loss to capture local temporal dependencies with a contrastive loss\nto enhance discriminative learning. Prior works on video alignment have focused\non using global temporal ordering across sequence pairs, whereas our loss\nencourages identifying the best-scoring subsequence alignment. LAC uses the\ndifferentiable Smith-Waterman (SW) affine method, which features a flexible\nparameterization learned through the training phase, enabling the model to\nadjust the temporal gap penalty length dynamically. Evaluations show that our\nlearned representations outperform existing state-of-the-art approaches on\naction recognition tasks.\n","authors":["Keyne Oei","Amr Gomaa","Anna Maria Feit","Joo Belo"],"pdf_url":"https://arxiv.org/pdf/2409.04607v2.pdf","comment":"Accepted in 2nd Workshop on Video Understanding and its Applications,\n  held in conjunction with the British Machine Vision Conference (BMVC) 2024"},{"id":"http://arxiv.org/abs/2411.18135v2","updated":"2025-03-03T16:00:39Z","published":"2024-11-27T08:33:42Z","title":"ModeDreamer: Mode Guiding Score Distillation for Text-to-3D Generation\n  using Reference Image Prompts","summary":"  Existing Score Distillation Sampling (SDS)-based methods have driven\nsignificant progress in text-to-3D generation. However, 3D models produced by\nSDS-based methods tend to exhibit over-smoothing and low-quality outputs. These\nissues arise from the mode-seeking behavior of current methods, where the\nscores used to update the model oscillate between multiple modes, resulting in\nunstable optimization and diminished output quality. To address this problem,\nwe introduce a novel image prompt score distillation loss named ISD, which\nemploys a reference image to direct text-to-3D optimization toward a specific\nmode. Our ISD loss can be implemented by using IP-Adapter, a lightweight\nadapter for integrating image prompt capability to a text-to-image diffusion\nmodel, as a mode-selection module. A variant of this adapter, when not being\nprompted by a reference image, can serve as an efficient control variate to\nreduce variance in score estimates, thereby enhancing both output quality and\noptimization stability. Our experiments demonstrate that the ISD loss\nconsistently achieves visually coherent, high-quality outputs and improves\noptimization speed compared to prior text-to-3D methods, as demonstrated\nthrough both qualitative and quantitative evaluations on the T3Bench benchmark\nsuite.\n","authors":["Uy Dieu Tran","Minh Luu","Phong Ha Nguyen","Khoi Nguyen","Binh-Son Hua"],"pdf_url":"https://arxiv.org/pdf/2411.18135v2.pdf","comment":"Project page: https://modedreamer.github.io/"},{"id":"http://arxiv.org/abs/2409.18459v2","updated":"2025-03-03T15:04:18Z","published":"2024-09-27T05:43:22Z","title":"FoodMLLM-JP: Leveraging Multimodal Large Language Models for Japanese\n  Recipe Generation","summary":"  Research on food image understanding using recipe data has been a\nlong-standing focus due to the diversity and complexity of the data. Moreover,\nfood is inextricably linked to people's lives, making it a vital research area\nfor practical applications such as dietary management. Recent advancements in\nMultimodal Large Language Models (MLLMs) have demonstrated remarkable\ncapabilities, not only in their vast knowledge but also in their ability to\nhandle languages naturally. While English is predominantly used, they can also\nsupport multiple languages including Japanese. This suggests that MLLMs are\nexpected to significantly improve performance in food image understanding\ntasks. We fine-tuned open MLLMs LLaVA-1.5 and Phi-3 Vision on a Japanese recipe\ndataset and benchmarked their performance against the closed model GPT-4o. We\nthen evaluated the content of generated recipes, including ingredients and\ncooking procedures, using 5,000 evaluation samples that comprehensively cover\nJapanese food culture. Our evaluation demonstrates that the open models trained\non recipe data outperform GPT-4o, the current state-of-the-art model, in\ningredient generation. Our model achieved F1 score of 0.531, surpassing\nGPT-4o's F1 score of 0.481, indicating a higher level of accuracy. Furthermore,\nour model exhibited comparable performance to GPT-4o in generating cooking\nprocedure text.\n","authors":["Yuki Imajuku","Yoko Yamakata","Kiyoharu Aizawa"],"pdf_url":"https://arxiv.org/pdf/2409.18459v2.pdf","comment":"15 pages, 5 figures. We found errors in the calculation of evaluation\n  metrics, which were corrected in this version with\n  $\\color{blue}{\\text{modifications highlighted in blue}}$. Please also see the\n  Appendix"},{"id":"http://arxiv.org/abs/2408.11561v2","updated":"2025-03-03T15:04:03Z","published":"2024-08-21T12:15:20Z","title":"Self-Supervised Iterative Refinement for Anomaly Detection in Industrial\n  Quality Control","summary":"  This study introduces the Iterative Refinement Process (IRP), a robust\nanomaly detection methodology designed for high-stakes industrial quality\ncontrol. The IRP enhances defect detection accuracy through a cyclic data\nrefinement strategy, iteratively removing misleading data points to improve\nmodel performance and robustness. We validate the IRP's effectiveness using two\nbenchmark datasets, Kolektor SDD2 (KSDD2) and MVTec AD, covering a wide range\nof industrial products and defect types. Our experimental results demonstrate\nthat the IRP consistently outperforms traditional anomaly detection models,\nparticularly in environments with high noise levels. This study highlights the\nIRP's potential to significantly enhance anomaly detection processes in\nindustrial settings, effectively managing the challenges of sparse and noisy\ndata.\n","authors":["Muhammad Aqeel","Shakiba Sharifi","Marco Cristani","Francesco Setti"],"pdf_url":"https://arxiv.org/pdf/2408.11561v2.pdf","comment":"Accepted to VISAPP 2025"},{"id":"http://arxiv.org/abs/2409.15259v2","updated":"2025-03-03T15:01:03Z","published":"2024-09-23T17:56:03Z","title":"StarVid: Enhancing Semantic Alignment in Video Diffusion Models via\n  Spatial and SynTactic Guided Attention Refocusing","summary":"  Recent advances in text-to-video (T2V) generation with diffusion models have\ngarnered significant attention. However, they typically perform well in scenes\nwith a single object and motion, struggling in compositional scenarios with\nmultiple objects and distinct motions to accurately reflect the semantic\ncontent of text prompts. To address these challenges, we propose\n\\textbf{StarVid}, a plug-and-play, training-free method that improves semantic\nalignment between multiple subjects, their motions, and text prompts in T2V\nmodels. StarVid first leverages the spatial reasoning capabilities of large\nlanguage models (LLMs) for two-stage motion trajectory planning based on text\nprompts. Such trajectories serve as spatial priors, guiding a spatial-aware\nloss to refocus cross-attention (CA) maps into distinctive regions.\nFurthermore, we propose a syntax-guided contrastive constraint to strengthen\nthe correlation between the CA maps of verbs and their corresponding nouns,\nenhancing motion-subject binding. Both qualitative and quantitative evaluations\ndemonstrate that the proposed framework significantly outperforms baseline\nmethods, delivering videos of higher quality with improved semantic\nconsistency.\n","authors":["Yuanhang Li","Qi Mao","Lan Chen","Zhen Fang","Lei Tian","Xinyan Xiao","Libiao Jin","Hua Wu"],"pdf_url":"https://arxiv.org/pdf/2409.15259v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2409.10071v4","updated":"2025-03-03T14:47:34Z","published":"2024-09-16T08:21:22Z","title":"Towards Physically Realizable Adversarial Attacks in Embodied Vision\n  Navigation","summary":"  The significant advancements in embodied vision navigation have raised\nconcerns about its susceptibility to adversarial attacks exploiting deep neural\nnetworks. Investigating the adversarial robustness of embodied vision\nnavigation is crucial, especially given the threat of 3D physical attacks that\ncould pose risks to human safety. However, existing attack methods for embodied\nvision navigation often lack physical feasibility due to challenges in\ntransferring digital perturbations into the physical world. Moreover, current\nphysical attacks for object detection struggle to achieve both multi-view\neffectiveness and visual naturalness in navigation scenarios. To address this,\nwe propose a practical attack method for embodied navigation by attaching\nadversarial patches to objects, where both opacity and textures are learnable.\nSpecifically, to ensure effectiveness across varying viewpoints, we employ a\nmulti-view optimization strategy based on object-aware sampling, which\noptimizes the patch's texture based on feedback from the vision-based\nperception model used in navigation. To make the patch inconspicuous to human\nobservers, we introduce a two-stage opacity optimization mechanism, in which\nopacity is fine-tuned after texture optimization. Experimental results\ndemonstrate that our adversarial patches decrease the navigation success rate\nby an average of 22.39%, outperforming previous methods in practicality,\neffectiveness, and naturalness. Code is available at:\nhttps://github.com/chen37058/Physical-Attacks-in-Embodied-Nav\n","authors":["Meng Chen","Jiawei Tu","Chao Qi","Yonghao Dang","Feng Zhou","Wei Wei","Jianqin Yin"],"pdf_url":"https://arxiv.org/pdf/2409.10071v4.pdf","comment":"7 pages, 7 figures, submitted to IEEE/RSJ International Conference on\n  Intelligent Robots and Systems (IROS) 2025"},{"id":"http://arxiv.org/abs/2403.19243v4","updated":"2025-03-03T12:32:47Z","published":"2024-03-28T08:58:20Z","title":"Efficient Learning With Sine-Activated Low-rank Matrices","summary":"  Low-rank decomposition has emerged as a vital tool for enhancing parameter\nefficiency in neural network architectures, gaining traction across diverse\napplications in machine learning. These techniques significantly lower the\nnumber of parameters, striking a balance between compactness and performance.\nHowever, a common challenge has been the compromise between parameter\nefficiency and the accuracy of the model, where reduced parameters often lead\nto diminished accuracy compared to their full-rank counterparts. In this work,\nwe propose a novel theoretical framework that integrates a sinusoidal function\nwithin the low-rank decomposition process. This approach not only preserves the\nbenefits of the parameter efficiency characteristic of low-rank methods but\nalso increases the decomposition's rank, thereby enhancing model performance.\nOur method proves to be a plug in enhancement for existing low-rank models, as\nevidenced by its successful application in Vision Transformers (ViT), Large\nLanguage Models (LLMs), Neural Radiance Fields (NeRF) and 3D shape modelling.\n","authors":["Yiping Ji","Hemanth Saratchandran","Cameron Gordon","Zeyu Zhang","Simon Lucey"],"pdf_url":"https://arxiv.org/pdf/2403.19243v4.pdf","comment":"The first two authors contributed equally. Paper accepted at ICLR\n  2025"},{"id":"http://arxiv.org/abs/2403.08632v2","updated":"2025-03-03T12:01:27Z","published":"2024-03-13T15:46:37Z","title":"A Decade's Battle on Dataset Bias: Are We There Yet?","summary":"  We revisit the \"dataset classification\" experiment suggested by Torralba &\nEfros (2011) a decade ago, in the new era with large-scale, diverse, and\nhopefully less biased datasets as well as more capable neural network\narchitectures. Surprisingly, we observe that modern neural networks can achieve\nexcellent accuracy in classifying which dataset an image is from: e.g., we\nreport 84.7% accuracy on held-out validation data for the three-way\nclassification problem consisting of the YFCC, CC, and DataComp datasets. Our\nfurther experiments show that such a dataset classifier could learn semantic\nfeatures that are generalizable and transferable, which cannot be explained by\nmemorization. We hope our discovery will inspire the community to rethink\nissues involving dataset bias.\n","authors":["Zhuang Liu","Kaiming He"],"pdf_url":"https://arxiv.org/pdf/2403.08632v2.pdf","comment":"Published in ICLR 2025 (Oral Presentation)"},{"id":"http://arxiv.org/abs/2310.08537v3","updated":"2025-03-03T09:26:26Z","published":"2023-10-12T17:26:16Z","title":"Saliency-Bench: A Comprehensive Benchmark for Evaluating Visual\n  Explanations","summary":"  Explainable AI (XAI) has gained significant attention for providing insights\ninto the decision-making processes of deep learning models, particularly for\nimage classification tasks through visual explanations visualized by saliency\nmaps. Despite their success, challenges remain due to the lack of annotated\ndatasets and standardized evaluation pipelines. In this paper, we introduce\nSaliency-Bench, a novel benchmark suite designed to evaluate visual\nexplanations generated by saliency methods across multiple datasets. We\ncurated, constructed, and annotated eight datasets, each covering diverse tasks\nsuch as scene classification, cancer diagnosis, object classification, and\naction classification, with corresponding ground-truth explanations. The\nbenchmark includes a standardized and unified evaluation pipeline for assessing\nfaithfulness and alignment of the visual explanation, providing a holistic\nvisual explanation performance assessment. We benchmark these eight datasets\nwith widely used saliency methods on different image classifier architectures\nto evaluate explanation quality. Additionally, we developed an easy-to-use API\nfor automating the evaluation pipeline, from data accessing, and data loading,\nto result evaluation. The benchmark is available via our website:\nhttps://xaidataset.github.io.\n","authors":["Yifei Zhang","James Song","Siyi Gu","Tianxu Jiang","Bo Pan","Guangji Bai","Liang Zhao"],"pdf_url":"https://arxiv.org/pdf/2310.08537v3.pdf","comment":null}],"Information Retrieval":[{"id":"http://arxiv.org/abs/2502.18858v2","updated":"2025-03-03T13:38:50Z","published":"2025-02-26T05:59:45Z","title":"Evaluating Intelligence via Trial and Error","summary":"  Intelligence is a crucial trait for species to find solutions within a\nlimited number of trial-and-error attempts. Building on this idea, we introduce\nSurvival Game as a framework to evaluate intelligence based on the number of\nfailed attempts in a trial-and-error process. Fewer failures indicate higher\nintelligence. When the expectation and variance of failure counts are both\nfinite, it signals the ability to consistently find solutions to new\nchallenges, which we define as the Autonomous Level of intelligence. Using\nSurvival Game, we comprehensively evaluate existing AI systems. Our results\nshow that while AI systems achieve the Autonomous Level in simple tasks, they\nare still far from it in more complex tasks, such as vision, search,\nrecommendation, and language. While scaling current AI technologies might help,\nthis would come at an astronomical cost. Projections suggest that achieving the\nAutonomous Level for general tasks would require $10^{26}$ parameters. To put\nthis into perspective, loading such a massive model requires so many H100 GPUs\nthat their total value is $10^{7}$ times that of Apple Inc.'s market value.\nEven with Moore's Law, supporting such a parameter scale would take $70$ years.\nThis staggering cost highlights the complexity of human tasks and the\ninadequacies of current AI technologies. To further investigate this\nphenomenon, we conduct a theoretical analysis of Survival Game and its\nexperimental results. Our findings suggest that human tasks possess a\ncriticality property. As a result, Autonomous Level requires a deep\nunderstanding of the task's underlying mechanisms. Current AI systems, however,\ndo not fully grasp these mechanisms and instead rely on superficial mimicry,\nmaking it difficult for them to reach an autonomous level. We believe Survival\nGame can not only guide the future development of AI but also offer profound\ninsights into human intelligence.\n","authors":["Jingtao Zhan","Jiahao Zhao","Jiayu Li","Yiqun Liu","Bo Zhang","Qingyao Ai","Jiaxin Mao","Hongning Wang","Min Zhang","Shaoping Ma"],"pdf_url":"https://arxiv.org/pdf/2502.18858v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2501.07596v2","updated":"2025-03-03T13:27:01Z","published":"2025-01-10T01:42:43Z","title":"Optimize Incompatible Parameters through Compatibility-aware Knowledge\n  Integration","summary":"  Deep neural networks have become foundational to advancements in multiple\ndomains, including recommendation systems, natural language processing, and so\non. Despite their successes, these models often contain incompatible parameters\nthat can be underutilized or detrimental to model performance, particularly\nwhen faced with specific, varying data distributions. Existing research excels\nin removing such parameters or merging the outputs of multiple different\npretrained models. However, the former focuses on efficiency rather than\nperformance, while the latter requires several times more computing and storage\nresources to support inference. In this paper, we set the goal to explicitly\nimprove these incompatible parameters by leveraging the complementary strengths\nof different models, thereby directly enhancing the models without any\nadditional parameters. Specifically, we propose Compatibility-aware Knowledge\nIntegration (CKI), which consists of Parameter Compatibility Assessment and\nParameter Splicing, which are used to evaluate the knowledge content of\nmultiple models and integrate the knowledge into one model, respectively. The\nintegrated model can be used directly for inference or for further fine-tuning.\nWe conduct extensive experiments on various datasets for recommendation and\nlanguage tasks, and the results show that Compatibility-aware Knowledge\nIntegration can effectively optimize incompatible parameters under multiple\ntasks and settings to break through the training limit of the original model\nwithout increasing the inference cost.\n","authors":["Zheqi Lv","Keming Ye","Zishu Wei","Qi Tian","Shengyu Zhang","Wenqiao Zhang","Wenjie Wang","Kun Kuang","Tat-Seng Chua","Fei Wu"],"pdf_url":"https://arxiv.org/pdf/2501.07596v2.pdf","comment":"Published on AAAI'25(Oral): The Annual AAAI Conference on Artificial\n  Intelligence"},{"id":"http://arxiv.org/abs/2502.17494v4","updated":"2025-03-03T22:21:09Z","published":"2025-02-20T22:35:52Z","title":"External Large Foundation Model: How to Efficiently Serve Trillions of\n  Parameters for Online Ads Recommendation","summary":"  Ads recommendation is a prominent service of online advertising systems and\nhas been actively studied. Recent studies indicate that scaling-up and advanced\ndesign of the recommendation model can bring significant performance\nimprovement. However, with a larger model scale, such prior studies have a\nsignificantly increasing gap from industry as they often neglect two\nfundamental challenges in industrial-scale applications. First, training and\ninference budgets are restricted for the model to be served, exceeding which\nmay incur latency and impair user experience. Second, large-volume data arrive\nin a streaming mode with data distributions dynamically shifting, as new\nusers/ads join and existing users/ads leave the system. We propose the External\nLarge Foundation Model (ExFM) framework to address the overlooked challenges.\nSpecifically, we develop external distillation and a data augmentation system\n(DAS) to control the computational cost of training/inference while maintaining\nhigh performance. We design the teacher in a way like a foundation model (FM)\nthat can serve multiple students as vertical models (VMs) to amortize its\nbuilding cost. We propose Auxiliary Head and Student Adapter to mitigate the\ndata distribution gap between FM and VMs caused by the streaming data issue.\nComprehensive experiments on internal industrial-scale applications and public\ndatasets demonstrate significant performance gain by ExFM.\n","authors":["Mingfu Liang","Xi Liu","Rong Jin","Boyang Liu","Qiuling Suo","Qinghai Zhou","Song Zhou","Laming Chen","Hua Zheng","Zhiyuan Li","Shali Jiang","Jiyan Yang","Xiaozhen Xia","Fan Yang","Yasmine Badr","Ellie Wen","Shuyu Xu","Hansey Chen","Zhengyu Zhang","Jade Nie","Chunzhi Yang","Zhichen Zeng","Weilin Zhang","Xingliang Huang","Qianru Li","Shiquan Wang","Evelyn Lyu","Wenjing Lu","Rui Zhang","Wenjun Wang","Jason Rudy","Mengyue Hang","Kai Wang","Yinbin Ma","Shuaiwen Wang","Sihan Zeng","Tongyi Tang","Xiaohan Wei","Longhao Jin","Jamey Zhang","Marcus Chen","Jiayi Zhang","Angie Huang","Chi Zhang","Zhengli Zhao","Jared Yang","Qiang Jin","Xian Chen","Amit Anand Amlesahwaram","Lexi Song","Liang Luo","Yuchen Hao","Nan Xiao","Yavuz Yetim","Luoshang Pan","Gaoxiang Liu","Yuxi Hu","Yuzhen Huang","Jackie Xu","Rich Zhu","Xin Zhang","Yiqun Liu","Hang Yin","Yuxin Chen","Buyun Zhang","Xiaoyi Liu","Xingyuan Wang","Wenguang Mao","Zhijing Li","Qin Huang","Chonglin Sun","Nancy Yu","Shuo Gu","Shupin Mao","Benjamin Au","Jingzheng Qin","Peggy Yao","Jae-Woo Choi","Bin Gao","Ernest Wang","Lei Zhang","Wen-Yen Chen","Ted Lee","Jay Zha","Yi Meng","Alex Gong","Edison Gao","Alireza Vahdatpour","Yiping Han","Yantao Yao","Toshinari Kureha","Shuo Chang","Musharaf Sultan","John Bocharov","Sagar Chordia","Xiaorui Gan","Peng Sun","Rocky Liu","Bo Long","Wenlin Chen","Santanu Kolay","Huayu Li"],"pdf_url":"https://arxiv.org/pdf/2502.17494v4.pdf","comment":"Accepted by the ACM Web Conference (WWW) 2025 Industrial Track as\n  Oral Presentation"},{"id":"http://arxiv.org/abs/2408.01262v5","updated":"2025-03-03T22:45:57Z","published":"2024-08-02T13:35:11Z","title":"RAGEval: Scenario Specific RAG Evaluation Dataset Generation Framework","summary":"  Retrieval-Augmented Generation (RAG) is a powerful approach that enables\nlarge language models (LLMs) to incorporate external knowledge. However,\nevaluating the effectiveness of RAG systems in specialized scenarios remains\nchallenging due to the high costs of data construction and the lack of suitable\nevaluation metrics. This paper introduces RAGEval, a framework designed to\nassess RAG systems across diverse scenarios by generating high-quality\ndocuments, questions, answers, and references through a schema-based pipeline.\nWith a focus on factual accuracy, we propose three novel metrics: Completeness,\nHallucination, and Irrelevance to evaluate LLM generated responses rigorously.\nExperimental results show that RAGEval outperforms zero-shot and one-shot\nmethods in terms of clarity, safety, conformity, and richness of generated\nsamples. Furthermore, the use of LLMs for scoring the proposed metrics\ndemonstrates a high level of consistency with human evaluations. RAGEval\nestablishes a new paradigm for evaluating RAG systems in real-world\napplications. The code and dataset are released at\nhttps://github.com/OpenBMB/RAGEval.\n","authors":["Kunlun Zhu","Yifan Luo","Dingling Xu","Yukun Yan","Zhenghao Liu","Shi Yu","Ruobing Wang","Shuo Wang","Yishan Li","Nan Zhang","Xu Han","Zhiyuan Liu","Maosong Sun"],"pdf_url":"https://arxiv.org/pdf/2408.01262v5.pdf","comment":"https://github.com/OpenBMB/RAGEval"},{"id":"http://arxiv.org/abs/2503.02065v1","updated":"2025-03-03T21:39:15Z","published":"2025-03-03T21:39:15Z","title":"Survey Perspective: The Role of Explainable AI in Threat Intelligence","summary":"  The increasing reliance on AI-based security tools in Security Operations\nCenters (SOCs) has transformed threat detection and response, yet analysts\nfrequently struggle with alert overload, false positives, and lack of\ncontextual relevance. The inability to effectively analyze AI-generated\nsecurity alerts lead to inefficiencies in incident response and reduces trust\nin automated decision-making. In this paper, we show results and analysis of\nour investigation of how SOC analysts navigate AI-based alerts, their\nchallenges with current security tools, and how explainability (XAI) integrated\ninto their security workflows has the potential to become an effective decision\nsupport. In this vein, we conducted an industry survey. Using the survey\nresponses, we analyze how security analysts' process, retrieve, and prioritize\nalerts. Our findings indicate that most analysts have not yet adopted\nXAI-integrated tools, but they express high interest in attack attribution,\nconfidence scores, and feature contribution explanations to improve\ninterpretability, and triage efficiency. Based on our findings, we also propose\npractical design recommendations for XAI-enhanced security alert systems,\nenabling AI-based cybersecurity solutions to be more transparent,\ninterpretable, and actionable.\n","authors":["Nidhi Rastogi","Devang Dhanuka","Amulya Saxena","Pranjal Mairal","Le Nguyen"],"pdf_url":"https://arxiv.org/pdf/2503.02065v1.pdf","comment":"5 pages, SIGIR Symposium on IR in Practice (SIRIP), 2025"},{"id":"http://arxiv.org/abs/2410.19302v2","updated":"2025-03-03T21:07:27Z","published":"2024-10-25T04:26:00Z","title":"TEARS: Textual Representations for Scrutable Recommendations","summary":"  Traditional recommender systems rely on high-dimensional (latent) embeddings\nfor modeling user-item interactions, often resulting in opaque representations\nthat lack interpretability. Moreover, these systems offer limited control to\nusers over their recommendations. Inspired by recent work, we introduce TExtuAl\nRepresentations for Scrutable recommendations (TEARS) to address these\nchallenges. Instead of representing a user's interests through a latent\nembedding, TEARS encodes them in natural text, providing transparency and\nallowing users to edit them. To do so, TEARS uses a modern LLM to generate user\nsummaries based on user preferences. We find the summaries capture user\npreferences uniquely. Using these summaries, we take a hybrid approach where we\nuse an optimal transport procedure to align the summaries' representation with\nthe learned representation of a standard VAE for collaborative filtering. We\nfind this approach can surpass the performance of three popular VAE models\nwhile providing user-controllable recommendations. We also analyze the\ncontrollability of TEARS through three simulated user tasks to evaluate the\neffectiveness of a user editing its summary.\n","authors":["Emiliano Penaloza","Olivier Gouvert","Haolun Wu","Laurent Charlin"],"pdf_url":"https://arxiv.org/pdf/2410.19302v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.01814v1","updated":"2025-03-03T18:41:59Z","published":"2025-03-03T18:41:59Z","title":"LLMInit: A Free Lunch from Large Language Models for Selective\n  Initialization of Recommendation","summary":"  Collaborative filtering models, particularly graph-based approaches, have\ndemonstrated strong performance in capturing user-item interactions for\nrecommendation systems. However, they continue to struggle in cold-start and\ndata-sparse scenarios. The emergence of large language models (LLMs) like GPT\nand LLaMA presents new possibilities for enhancing recommendation performance,\nespecially in cold-start settings. Despite their promise, LLMs pose challenges\nrelated to scalability and efficiency due to their high computational demands\nand limited ability to model complex user-item relationships effectively. In\nthis work, we introduce a novel perspective on leveraging LLMs for CF model\ninitialization. Through experiments, we uncover an embedding collapse issue\nwhen scaling CF models to larger embedding dimensions. To effectively harness\nlarge-scale LLM embeddings, we propose innovative selective initialization\nstrategies utilizing random, uniform, and variance-based index sampling. Our\ncomprehensive evaluation on multiple real-world datasets demonstrates\nsignificant performance gains across various CF models while maintaining a\nlower computational cost compared to existing LLM-based recommendation\napproaches.\n","authors":["Weizhi Zhang","Liangwei Yang","Wooseong Yang","Henry Peng Zou","Yuqing Liu","Ke Xu","Sourav Medya","Philip S. Yu"],"pdf_url":"https://arxiv.org/pdf/2503.01814v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.01776v1","updated":"2025-03-03T17:59:48Z","published":"2025-03-03T17:59:48Z","title":"Beyond Matryoshka: Revisiting Sparse Coding for Adaptive Representation","summary":"  Many large-scale systems rely on high-quality deep representations\n(embeddings) to facilitate tasks like retrieval, search, and generative\nmodeling. Matryoshka Representation Learning (MRL) recently emerged as a\nsolution for adaptive embedding lengths, but it requires full model retraining\nand suffers from noticeable performance degradations at short lengths. In this\npaper, we show that sparse coding offers a compelling alternative for achieving\nadaptive representation with minimal overhead and higher fidelity. We propose\nContrastive Sparse Representation (CSR), a method that sparsifies pre-trained\nembeddings into a high-dimensional but selectively activated feature space. By\nleveraging lightweight autoencoding and task-aware contrastive objectives, CSR\npreserves semantic quality while allowing flexible, cost-effective inference at\ndifferent sparsity levels. Extensive experiments on image, text, and multimodal\nbenchmarks demonstrate that CSR consistently outperforms MRL in terms of both\naccuracy and retrieval speed-often by large margins-while also cutting training\ntime to a fraction of that required by MRL. Our results establish sparse coding\nas a powerful paradigm for adaptive representation learning in real-world\napplications where efficiency and fidelity are both paramount. Code is\navailable at https://github.com/neilwen987/CSR_Adaptive_Rep\n","authors":["Tiansheng Wen","Yifei Wang","Zequn Zeng","Zhong Peng","Yudi Su","Xinyang Liu","Bo Chen","Hongwei Liu","Stefanie Jegelka","Chenyu You"],"pdf_url":"https://arxiv.org/pdf/2503.01776v1.pdf","comment":"A novel sparse coding framework designed for learning adaptive\n  representation"},{"id":"http://arxiv.org/abs/2503.01763v1","updated":"2025-03-03T17:37:16Z","published":"2025-03-03T17:37:16Z","title":"Retrieval Models Aren't Tool-Savvy: Benchmarking Tool Retrieval for\n  Large Language Models","summary":"  Tool learning aims to augment large language models (LLMs) with diverse\ntools, enabling them to act as agents for solving practical tasks. Due to the\nlimited context length of tool-using LLMs, adopting information retrieval (IR)\nmodels to select useful tools from large toolsets is a critical initial step.\nHowever, the performance of IR models in tool retrieval tasks remains\nunderexplored and unclear. Most tool-use benchmarks simplify this step by\nmanually pre-annotating a small set of relevant tools for each task, which is\nfar from the real-world scenarios. In this paper, we propose ToolRet, a\nheterogeneous tool retrieval benchmark comprising 7.6k diverse retrieval tasks,\nand a corpus of 43k tools, collected from existing datasets. We benchmark six\ntypes of models on ToolRet. Surprisingly, even the models with strong\nperformance in conventional IR benchmarks, exhibit poor performance on ToolRet.\nThis low retrieval quality degrades the task pass rate of tool-use LLMs. As a\nfurther step, we contribute a large-scale training dataset with over 200k\ninstances, which substantially optimizes the tool retrieval ability of IR\nmodels.\n","authors":["Zhengliang Shi","Yuhan Wang","Lingyong Yan","Pengjie Ren","Shuaiqiang Wang","Dawei Yin","Zhaochun Ren"],"pdf_url":"https://arxiv.org/pdf/2503.01763v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.01713v1","updated":"2025-03-03T16:25:58Z","published":"2025-03-03T16:25:58Z","title":"SAGE: A Framework of Precise Retrieval for RAG","summary":"  Retrieval-augmented generation (RAG) has demonstrated significant proficiency\nin conducting question-answering (QA) tasks within a specified corpus.\nNonetheless, numerous failure instances of RAG in QA still exist. These\nfailures are not solely attributable to the limitations of Large Language\nModels (LLMs); instead, they predominantly arise from the retrieval of\ninaccurate information for LLMs due to two limitations: (1) Current RAG methods\nsegment the corpus without considering semantics, making it difficult to find\nrelevant context due to impaired correlation between questions and the\nsegments. (2) There is a trade-off between missing essential context with fewer\ncontext retrieved and getting irrelevant context with more context retrieved.\n  In this paper, we introduce a RAG framework (SAGE), to overcome these\nlimitations. First, to address the segmentation issue without considering\nsemantics, we propose to train a semantic segmentation model. This model is\ntrained to segment the corpus into semantically complete chunks. Second, to\nensure that only the most relevant chunks are retrieved while the irrelevant\nones are ignored, we design a chunk selection algorithm to dynamically select\nchunks based on the decreasing speed of the relevance score, leading to a more\nrelevant selection. Third, to further ensure the precision of the retrieved\nchunks, we propose letting LLMs assess whether retrieved chunks are excessive\nor lacking and then adjust the amount of context accordingly. Experiments show\nthat SAGE outperforms baselines by 61.25% in the quality of QA on average.\nMoreover, by avoiding retrieving noisy context, SAGE lowers the cost of the\ntokens consumed in LLM inference and achieves a 49.41% enhancement in cost\nefficiency on average. Additionally, our work offers valuable insights for\nboosting RAG.\n","authors":["Jintao Zhang","Guoliang Li","Jinyang Su"],"pdf_url":"https://arxiv.org/pdf/2503.01713v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.01670v1","updated":"2025-03-03T15:42:57Z","published":"2025-03-03T15:42:57Z","title":"Evaluating LLMs' Assessment of Mixed-Context Hallucination Through the\n  Lens of Summarization","summary":"  With the rapid development of large language models (LLMs), LLM-as-a-judge\nhas emerged as a widely adopted approach for text quality evaluation, including\nhallucination evaluation. While previous studies have focused exclusively on\nsingle-context evaluation (e.g., discourse faithfulness or world factuality),\nreal-world hallucinations typically involve mixed contexts, which remains\ninadequately evaluated. In this study, we use summarization as a representative\ntask to comprehensively evaluate LLMs' capability in detecting mixed-context\nhallucinations, specifically distinguishing between factual and non-factual\nhallucinations. Through extensive experiments across direct generation and\nretrieval-based models of varying scales, our main observations are: (1) LLMs'\nintrinsic knowledge introduces inherent biases in hallucination evaluation; (2)\nThese biases particularly impact the detection of factual hallucinations,\nyielding a significant performance bottleneck; (3) The fundamental challenge\nlies in effective knowledge utilization, balancing between LLMs' intrinsic\nknowledge and external context for accurate mixed-context hallucination\nevaluation.\n","authors":["Siya Qi","Rui Cao","Yulan He","Zheng Yuan"],"pdf_url":"https://arxiv.org/pdf/2503.01670v1.pdf","comment":"8 pages, 5 figures for main body"},{"id":"http://arxiv.org/abs/2503.01658v1","updated":"2025-03-03T15:32:02Z","published":"2025-03-03T15:32:02Z","title":"CoPL: Collaborative Preference Learning for Personalizing LLMs","summary":"  Personalizing large language models (LLMs) is important for aligning outputs\nwith diverse user preferences, yet existing methods struggle with flexibility\nand generalization. We propose CoPL (Collaborative Preference Learning), a\ngraph-based collaborative filtering framework that models user-response\nrelationships to enhance preference estimation, particularly in sparse\nannotation settings. By integrating a mixture of LoRA experts, CoPL efficiently\nfine-tunes LLMs while dynamically balancing shared and user-specific\npreferences. Additionally, an optimization-free adaptation strategy enables\ngeneralization to unseen users without fine-tuning. Experiments on\nUltraFeedback-P demonstrate that CoPL outperforms existing personalized reward\nmodels, effectively capturing both common and controversial preferences, making\nit a scalable solution for personalized LLM alignment.\n","authors":["Youngbin Choi","Seunghyuk Cho","Minjong Lee","MoonJeong Park","Yesong Ko","Jungseul Ok","Dongwoo Kim"],"pdf_url":"https://arxiv.org/pdf/2503.01658v1.pdf","comment":"13pages, 4 figures, 6tables"},{"id":"http://arxiv.org/abs/2503.01442v1","updated":"2025-03-03T11:48:01Z","published":"2025-03-03T11:48:01Z","title":"Leveraging LLMs for Mental Health: Detection and Recommendations from\n  Social Discussions","summary":"  Textual data from social platforms captures various aspects of mental health\nthrough discussions around and across issues, while users reach out for help\nand others sympathize and offer support. We propose a comprehensive framework\nthat leverages Natural Language Processing (NLP) and Generative AI techniques\nto identify and assess mental health disorders, detect their severity, and\ncreate recommendations for behavior change and therapeutic interventions based\non users' posts on Reddit.\n  To classify the disorders, we use rule-based labeling methods as well as\nadvanced pre-trained NLP models to extract nuanced semantic features from the\ndata. We fine-tune domain-adapted and generic pre-trained NLP models based on\npredictions from specialized Large Language Models (LLMs) to improve\nclassification accuracy. Our hybrid approach combines the generalization\ncapabilities of pre-trained models with the domain-specific insights captured\nby LLMs, providing an improved understanding of mental health discourse. Our\nfindings highlight the strengths and limitations of each model, offering\nvaluable insights into their practical applicability.\n  This research potentially facilitates early detection and personalized care\nto aid practitioners and aims to facilitate timely interventions and improve\noverall well-being, thereby contributing to the broader field of mental health\nsurveillance and digital health analytics.\n","authors":["Vaishali Aggarwal","Sachin Thukral","Krushil Patel","Arnab Chatterjee"],"pdf_url":"https://arxiv.org/pdf/2503.01442v1.pdf","comment":"5 pages, 4 figures, 3 tables, to be published in WI-IAT 2024"},{"id":"http://arxiv.org/abs/2503.01362v1","updated":"2025-03-03T09:55:54Z","published":"2025-03-03T09:55:54Z","title":"Streaming Piano Transcription Based on Consistent Onset and Offset\n  Decoding with Sustain Pedal Detection","summary":"  This paper describes a streaming audio-to-MIDI piano transcription approach\nthat aims to sequentially translate a music signal into a sequence of note\nonset and offset events. The sequence-to-sequence nature of this task may call\nfor the computationally-intensive transformer model for better performance,\nwhich has recently been used for offline transcription benchmarks and could be\nextended for streaming transcription with causal attention mechanisms. We\nassume that the performance limitation of this naive approach lies in the\ndecoder. Although time-frequency features useful for onset detection are\nconsiderably different from those for offset detection, the single decoder is\ntrained to output a mixed sequence of onset and offset events without guarantee\nof the correspondence between the onset and offset events of the same note. To\novercome this limitation, we propose a streaming encoder-decoder model that\nuses a convolutional encoder aggregating local acoustic features, followed by\nan autoregressive Transformer decoder detecting a variable number of onset\nevents and another decoder detecting the offset events for the active pitches\nwith validation of the sustain pedal at each time frame. Experiments using the\nMAESTRO dataset showed that the proposed streaming method performed comparably\nwith or even better than the state-of-the-art offline methods while\nsignificantly reducing the computational cost.\n","authors":["Weixing Wei","Jiahao Zhao","Yulun Wu","Kazuyoshi Yoshii"],"pdf_url":"https://arxiv.org/pdf/2503.01362v1.pdf","comment":"Accepted to ISMIR 2024"},{"id":"http://arxiv.org/abs/2503.01346v1","updated":"2025-03-03T09:37:33Z","published":"2025-03-03T09:37:33Z","title":"SRAG: Structured Retrieval-Augmented Generation for Multi-Entity\n  Question Answering over Wikipedia Graph","summary":"  Multi-entity question answering (MEQA) poses significant challenges for large\nlanguage models (LLMs), which often struggle to consolidate scattered\ninformation across multiple documents. An example question might be \"What is\nthe distribution of IEEE Fellows among various fields of study?\", which\nrequires retrieving information from diverse sources e.g., Wikipedia pages. The\neffectiveness of current retrieval-augmented generation (RAG) methods is\nlimited by the LLMs' capacity to aggregate insights from numerous pages. To\naddress this gap, this paper introduces a structured RAG (SRAG) framework that\nsystematically organizes extracted entities into relational tables (e.g.,\ntabulating entities with schema columns like \"name\" and \"field of study\") and\nthen apply table-based reasoning techniques. Our approach decouples retrieval\nand reasoning, enabling LLMs to focus on structured data analysis rather than\nraw text aggregation. Extensive experiments on Wikipedia-based multi-entity QA\ntasks demonstrate that SRAG significantly outperforms state-of-the-art\nlong-context LLMs and RAG solutions, achieving a 29.6% improvement in accuracy.\nThe results underscore the efficacy of structuring unstructured data to enhance\nLLMs' reasoning capabilities.\n","authors":["Teng Lin","Yizhang Zhu","Yuyu Luo","Nan Tang"],"pdf_url":"https://arxiv.org/pdf/2503.01346v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.01334v1","updated":"2025-03-03T09:18:43Z","published":"2025-03-03T09:18:43Z","title":"Composed Multi-modal Retrieval: A Survey of Approaches and Applications","summary":"  With the rapid growth of multi-modal data from social media, short video\nplatforms, and e-commerce, content-based retrieval has become essential for\nefficiently searching and utilizing heterogeneous information. Over time,\nretrieval techniques have evolved from Unimodal Retrieval (UR) to Cross-modal\nRetrieval (CR) and, more recently, to Composed Multi-modal Retrieval (CMR). CMR\nenables users to retrieve images or videos by integrating a reference visual\ninput with textual modifications, enhancing search flexibility and precision.\nThis paper provides a comprehensive review of CMR, covering its fundamental\nchallenges, technical advancements, and categorization into supervised,\nzero-shot, and semi-supervised learning paradigms. We discuss key research\ndirections, including data augmentation, model architecture, and loss\noptimization in supervised CMR, as well as transformation frameworks and\nexternal knowledge integration in zero-shot CMR. Additionally, we highlight the\napplication potential of CMR in composed image retrieval, video retrieval, and\nperson retrieval, which have significant implications for e-commerce, online\nsearch, and public security. Given its ability to refine and personalize search\nexperiences, CMR is poised to become a pivotal technology in next-generation\nretrieval systems. A curated list of related works and resources is available\nat: https://github.com/kkzhang95/Awesome-Composed-Multi-modal-Retrieval\n","authors":["Kun Zhang","Jingyu Li","Zhe Li","Jingjing Zhang"],"pdf_url":"https://arxiv.org/pdf/2503.01334v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.01305v1","updated":"2025-03-03T08:43:40Z","published":"2025-03-03T08:43:40Z","title":"HI-Series Algorithms A Hybrid of Substance Diffusion Algorithm and\n  Collaborative Filtering","summary":"  Recommendation systems face the challenge of balancing accuracy and\ndiversity, as traditional collaborative filtering (CF) and network-based\ndiffusion algorithms exhibit complementary limitations. While item-based CF\n(ItemCF) enhances diversity through item similarity, it compromises accuracy.\nConversely, mass diffusion (MD) algorithms prioritize accuracy by favoring\npopular items but lack diversity. To address this trade-off, we propose the\nHI-series algorithms, hybrid models integrating ItemCF with diffusion-based\napproaches (MD, HHP, BHC, BD) through a nonlinear combination controlled by\nparameter $\\epsilon$. This hybridization leverages ItemCF's diversity and MD's\naccuracy, extending to advanced diffusion models (HI-HHP, HI-BHC, HI-BD) for\nenhanced performance. Experiments on MovieLens, Netflix, and RYM datasets\ndemonstrate that HI-series algorithms significantly outperform their base\ncounterparts. In sparse data ($20\\%$ training), HI-MD achieves a\n$0.8\\%$-$4.4\\%$ improvement in F1-score over MD while maintaining higher\ndiversity (Diversity@20: 459 vs. 396 on MovieLens). For dense data ($80\\%$\ntraining), HI-BD improves F1-score by $2.3\\%$-$5.2\\%$ compared to BD, with\ndiversity gains up to $18.6\\%$. Notably, hybrid models consistently enhance\nnovelty in sparse settings and exhibit robust parameter adaptability. The\nresults validate that strategic hybridization effectively breaks the\naccuracy-diversity trade-off, offering a flexible framework for optimizing\nrecommendation systems across data sparsity levels.\n","authors":["Yu Peng","Ya-Hui An"],"pdf_url":"https://arxiv.org/pdf/2503.01305v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.01194v1","updated":"2025-03-03T05:41:16Z","published":"2025-03-03T05:41:16Z","title":"Cancer Type, Stage and Prognosis Assessment from Pathology Reports using\n  LLMs","summary":"  Large Language Models (LLMs) have shown significant promise across various\nnatural language processing tasks. However, their application in the field of\npathology, particularly for extracting meaningful insights from unstructured\nmedical texts such as pathology reports, remains underexplored and not well\nquantified. In this project, we leverage state-of-the-art language models,\nincluding the GPT family, Mistral models, and the open-source Llama models, to\nevaluate their performance in comprehensively analyzing pathology reports.\nSpecifically, we assess their performance in cancer type identification, AJCC\nstage determination, and prognosis assessment, encompassing both information\nextraction and higher-order reasoning tasks. Based on a detailed analysis of\ntheir performance metrics in a zero-shot setting, we developed two\ninstruction-tuned models: Path-llama3.1-8B and Path-GPT-4o-mini-FT. These\nmodels demonstrated superior performance in zero-shot cancer type\nidentification, staging, and prognosis assessment compared to the other models\nevaluated.\n","authors":["Rachit Saluja","Jacob Rosenthal","Yoav Artzi","David J. Pisapia","Benjamin L. Liechty","Mert R. Sabuncu"],"pdf_url":"https://arxiv.org/pdf/2503.01194v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.01151v1","updated":"2025-03-03T03:57:04Z","published":"2025-03-03T03:57:04Z","title":"ReaderLM-v2: Small Language Model for HTML to Markdown and JSON","summary":"  We present ReaderLM-v2, a compact 1.5 billion parameter language model\ndesigned for efficient web content extraction. Our model processes documents up\nto 512K tokens, transforming messy HTML into clean Markdown or JSON formats\nwith high accuracy -- making it an ideal tool for grounding large language\nmodels. The model's effectiveness results from two key innovations: (1) a\nthree-stage data synthesis pipeline that generates high quality, diverse\ntraining data by iteratively drafting, refining, and critiquing web content\nextraction; and (2) a unified training framework combining continuous\npre-training with multi-objective optimization. Intensive evaluation\ndemonstrates that ReaderLM-v2 outperforms GPT-4o-2024-08-06 and other larger\nmodels by 15-20\\% on carefully curated benchmarks, particularly excelling at\ndocuments exceeding 100K tokens, while maintaining significantly lower\ncomputational requirements.\n","authors":["Feng Wang","Zesheng Shi","Bo Wang","Nan Wang","Han Xiao"],"pdf_url":"https://arxiv.org/pdf/2503.01151v1.pdf","comment":"9 pages, 10-12 refs"}],"Machine Learning":[{"id":"http://arxiv.org/abs/2502.19210v2","updated":"2025-03-03T15:32:09Z","published":"2025-02-26T15:13:08Z","title":"Langevin Multiplicative Weights Update with Applications in Polynomial\n  Portfolio Management","summary":"  We consider nonconvex optimization problem over simplex, and more generally,\na product of simplices. We provide an algorithm, Langevin Multiplicative\nWeights Update (LMWU) for solving global optimization problems by adding a\nnoise scaling with the non-Euclidean geometry in the simplex. Non-convex\noptimization has been extensively studied by machine learning community due to\nits application in various scenarios such as neural network approximation and\nfinding Nash equilibrium. Despite recent progresses on provable guarantee of\nescaping and avoiding saddle point (convergence to local minima) and global\nconvergence of Langevin gradient based method without constraints, the global\noptimization with constraints is less studied. We show that LMWU algorithm is\nprovably convergent to interior global minima with a non-asymptotic convergence\nanalysis. We verify the efficiency of the proposed algorithm in real data set\nfrom polynomial portfolio management, where optimization of a highly non-linear\nobjective function plays a crucial role.\n","authors":["Yi Feng","Xiao Wang","Tian Xie"],"pdf_url":"https://arxiv.org/pdf/2502.19210v2.pdf","comment":"Accepted for AAAI-2025"},{"id":"http://arxiv.org/abs/2502.12215v2","updated":"2025-03-03T15:29:43Z","published":"2025-02-17T07:21:11Z","title":"Revisiting the Test-Time Scaling of o1-like Models: Do they Truly\n  Possess Test-Time Scaling Capabilities?","summary":"  The advent of test-time scaling in large language models (LLMs), exemplified\nby OpenAI's o1 series, has advanced reasoning capabilities by scaling\ncomputational resource allocation during inference. While successors like QwQ,\nDeepseek-R1 (R1) and LIMO replicate these advancements, whether these models\ntruly possess test-time scaling capabilities remains underexplored. This study\nfound that longer CoTs of these o1-like models do not consistently enhance\naccuracy; in fact, correct solutions are often shorter than incorrect ones for\nthe same questions. Further investigation shows this phenomenon is closely\nrelated to models' self-revision capabilities - longer CoTs contain more\nself-revisions, which often lead to performance degradation. We then compare\nsequential and parallel scaling strategies on QwQ, R1 and LIMO, finding that\nparallel scaling achieves better coverage and scalability. Based on these\ninsights, we propose Shortest Majority Vote, a method that combines parallel\nscaling strategies with CoT length characteristics, significantly improving\nmodels' test-time scalability compared to conventional majority voting\napproaches.\n","authors":["Zhiyuan Zeng","Qinyuan Cheng","Zhangyue Yin","Yunhua Zhou","Xipeng Qiu"],"pdf_url":"https://arxiv.org/pdf/2502.12215v2.pdf","comment":"Add the github link"},{"id":"http://arxiv.org/abs/2501.10945v2","updated":"2025-03-03T15:09:31Z","published":"2025-01-19T04:56:55Z","title":"Gradient-Based Multi-Objective Deep Learning: Algorithms, Theories,\n  Applications, and Beyond","summary":"  Multi-objective optimization (MOO) in deep learning aims to simultaneously\noptimize multiple conflicting objectives, a challenge frequently encountered in\nareas like multi-task learning and multi-criteria learning. Recent advancements\nin gradient-based MOO methods have enabled the discovery of diverse types of\nsolutions, ranging from a single balanced solution to finite or even infinite\nPareto sets, tailored to user needs. These developments have broad applications\nacross domains such as reinforcement learning, computer vision, recommendation\nsystems, and large language models. This survey provides the first\ncomprehensive review of gradient-based MOO in deep learning, covering\nalgorithms, theories, and practical applications. By unifying various\napproaches and identifying critical challenges, it serves as a foundational\nresource for driving innovation in this evolving field. A comprehensive list of\nMOO algorithms in deep learning is available at\nhttps://github.com/Baijiong-Lin/Awesome-Multi-Objective-Deep-Learning.\n","authors":["Weiyu Chen","Xiaoyuan Zhang","Baijiong Lin","Xi Lin","Han Zhao","Qingfu Zhang","James T. Kwok"],"pdf_url":"https://arxiv.org/pdf/2501.10945v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2502.10784v2","updated":"2025-03-03T15:02:37Z","published":"2025-02-15T12:28:51Z","title":"Preconditioned Inexact Stochastic ADMM for Deep Model","summary":"  The recent advancement of foundation models (FMs) has brought about a\nparadigm shift, revolutionizing various sectors worldwide. The popular\noptimizers used to train these models are stochastic gradient descent-based\nalgorithms, which face inherent limitations, such as slow convergence and\nstringent assumptions for convergence. In particular, data heterogeneity\narising from distributed settings poses significant challenges to their\ntheoretical and numerical performance. This paper develops an algorithm, PISA\n({P}reconditioned {I}nexact {S}tochastic {A}lternating Direction Method of\nMultipliers), which enables scalable parallel computing and supports various\nsecond-moment schemes. Grounded in rigorous theoretical guarantees, the\nalgorithm converges under the sole assumption of Lipschitz continuity of the\ngradient, thereby removing the need for other conditions commonly imposed by\nstochastic methods. This capability enables PISA to tackle the challenge of\ndata heterogeneity effectively. Comprehensive experimental evaluations for\ntraining or fine-tuning diverse FMs, including vision models, large language\nmodels, reinforcement learning models, generative adversarial networks, and\nrecurrent neural networks, demonstrate its superior numerical performance\ncompared to various state-of-the-art optimizers.\n","authors":["Shenglong Zhou","Ouya Wang","Ziyan Luo","Yongxu Zhu","Geoffrey Ye Li"],"pdf_url":"https://arxiv.org/pdf/2502.10784v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.23208v2","updated":"2025-03-03T14:29:16Z","published":"2024-10-30T16:59:41Z","title":"Kinetix: Investigating the Training of General Agents through Open-Ended\n  Physics-Based Control Tasks","summary":"  While large models trained with self-supervised learning on offline datasets\nhave shown remarkable capabilities in text and image domains, achieving the\nsame generalisation for agents that act in sequential decision problems remains\nan open challenge. In this work, we take a step towards this goal by\nprocedurally generating tens of millions of 2D physics-based tasks and using\nthese to train a general reinforcement learning (RL) agent for physical\ncontrol. To this end, we introduce Kinetix: an open-ended space of\nphysics-based RL environments that can represent tasks ranging from robotic\nlocomotion and grasping to video games and classic RL environments, all within\na unified framework. Kinetix makes use of our novel hardware-accelerated\nphysics engine Jax2D that allows us to cheaply simulate billions of environment\nsteps during training. Our trained agent exhibits strong physical reasoning\ncapabilities in 2D space, being able to zero-shot solve unseen human-designed\nenvironments. Furthermore, fine-tuning this general agent on tasks of interest\nshows significantly stronger performance than training an RL agent *tabula\nrasa*. This includes solving some environments that standard RL training\ncompletely fails at. We believe this demonstrates the feasibility of large\nscale, mixed-quality pre-training for online RL and we hope that Kinetix will\nserve as a useful framework to investigate this further.\n","authors":["Michael Matthews","Michael Beukman","Chris Lu","Jakob Foerster"],"pdf_url":"https://arxiv.org/pdf/2410.23208v2.pdf","comment":"ICLR 2025 Oral. The first two authors contributed equally. Project\n  page located at: https://kinetix-env.github.io/"},{"id":"http://arxiv.org/abs/2410.15474v2","updated":"2025-03-03T14:08:48Z","published":"2024-10-20T19:12:14Z","title":"Optimizing Backward Policies in GFlowNets via Trajectory Likelihood\n  Maximization","summary":"  Generative Flow Networks (GFlowNets) are a family of generative models that\nlearn to sample objects with probabilities proportional to a given reward\nfunction. The key concept behind GFlowNets is the use of two stochastic\npolicies: a forward policy, which incrementally constructs compositional\nobjects, and a backward policy, which sequentially deconstructs them. Recent\nresults show a close relationship between GFlowNet training and\nentropy-regularized reinforcement learning (RL) problems with a particular\nreward design. However, this connection applies only in the setting of a fixed\nbackward policy, which might be a significant limitation. As a remedy to this\nproblem, we introduce a simple backward policy optimization algorithm that\ninvolves direct maximization of the value function in an entropy-regularized\nMarkov Decision Process (MDP) over intermediate rewards. We provide an\nextensive experimental evaluation of the proposed approach across various\nbenchmarks in combination with both RL and GFlowNet algorithms and demonstrate\nits faster convergence and mode discovery in complex environments.\n","authors":["Timofei Gritsaev","Nikita Morozov","Sergey Samsonov","Daniil Tiapkin"],"pdf_url":"https://arxiv.org/pdf/2410.15474v2.pdf","comment":"ICLR 2025"},{"id":"http://arxiv.org/abs/2501.07596v2","updated":"2025-03-03T13:27:01Z","published":"2025-01-10T01:42:43Z","title":"Optimize Incompatible Parameters through Compatibility-aware Knowledge\n  Integration","summary":"  Deep neural networks have become foundational to advancements in multiple\ndomains, including recommendation systems, natural language processing, and so\non. Despite their successes, these models often contain incompatible parameters\nthat can be underutilized or detrimental to model performance, particularly\nwhen faced with specific, varying data distributions. Existing research excels\nin removing such parameters or merging the outputs of multiple different\npretrained models. However, the former focuses on efficiency rather than\nperformance, while the latter requires several times more computing and storage\nresources to support inference. In this paper, we set the goal to explicitly\nimprove these incompatible parameters by leveraging the complementary strengths\nof different models, thereby directly enhancing the models without any\nadditional parameters. Specifically, we propose Compatibility-aware Knowledge\nIntegration (CKI), which consists of Parameter Compatibility Assessment and\nParameter Splicing, which are used to evaluate the knowledge content of\nmultiple models and integrate the knowledge into one model, respectively. The\nintegrated model can be used directly for inference or for further fine-tuning.\nWe conduct extensive experiments on various datasets for recommendation and\nlanguage tasks, and the results show that Compatibility-aware Knowledge\nIntegration can effectively optimize incompatible parameters under multiple\ntasks and settings to break through the training limit of the original model\nwithout increasing the inference cost.\n","authors":["Zheqi Lv","Keming Ye","Zishu Wei","Qi Tian","Shengyu Zhang","Wenqiao Zhang","Wenjie Wang","Kun Kuang","Tat-Seng Chua","Fei Wu"],"pdf_url":"https://arxiv.org/pdf/2501.07596v2.pdf","comment":"Published on AAAI'25(Oral): The Annual AAAI Conference on Artificial\n  Intelligence"},{"id":"http://arxiv.org/abs/2411.17711v2","updated":"2025-03-03T13:19:42Z","published":"2024-11-17T17:32:58Z","title":"AnyECG: Foundational Models for Multitask Cardiac Analysis in Real-World\n  Settings","summary":"  Electrocardiogram (ECG), a non-invasive and affordable tool for cardiac\nmonitoring, is highly sensitive in detecting acute heart attacks. However, due\nto the lengthy nature of ECG recordings, numerous machine learning methods have\nbeen developed for automated heart disease detection to reduce human workload.\nDespite these efforts, performance remains suboptimal. A key obstacle is the\ninherent complexity of ECG data, which includes heterogeneity (e.g., varying\nsampling rates), high levels of noise, demographic-related pattern shifts, and\nintricate rhythm-event associations. To overcome these challenges, this paper\nintroduces AnyECG, a foundational model designed to extract robust\nrepresentations from any real-world ECG data. Specifically, a tailored ECG\nTokenizer encodes each fixed-duration ECG fragment into a token and, guided by\nproxy tasks, converts noisy, continuous ECG features into discrete, compact,\nand clinically meaningful local rhythm codes. These codes encapsulate basic\nmorphological, frequency, and demographic information (e.g., sex), effectively\nmitigating signal noise. We further pre-train the AnyECG to learn rhythmic\npattern associations across ECG tokens, enabling the capture of cardiac event\nsemantics. By being jointly pre-trained on diverse ECG data sources, AnyECG is\ncapable of generalizing across a wide range of downstream tasks where ECG\nsignals are recorded from various devices and scenarios. The experimental\nresults show that AnyECG achieves an average performance improvement of 6%\nacross four critical tasks-anomaly detection, arrhythmia classification,\ncorrupted lead generation, and ultra-long ECG recognition. AnyECG learns common\nECG rhythm from data and significantly outperforms state-of-the-art methods in\neach of these tasks.\n","authors":["Yue Wang","Xu Cao","Yaojun Hu","Haochao Ying","Hongxia Xu","Ruijia Wu","James Matthew Rehg","Jimeng Sun","Jian Wu","Jintai Chen"],"pdf_url":"https://arxiv.org/pdf/2411.17711v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.05106v2","updated":"2025-03-03T13:18:55Z","published":"2024-10-07T15:02:48Z","title":"Nonasymptotic Analysis of Stochastic Gradient Descent with the\n  Richardson-Romberg Extrapolation","summary":"  We address the problem of solving strongly convex and smooth minimization\nproblems using stochastic gradient descent (SGD) algorithm with a constant step\nsize. Previous works suggested to combine the Polyak-Ruppert averaging\nprocedure with the Richardson-Romberg extrapolation to reduce the asymptotic\nbias of SGD at the expense of a mild increase of the variance. We significantly\nextend previous results by providing an expansion of the mean-squared error of\nthe resulting estimator with respect to the number of iterations $n$. We show\nthat the root mean-squared error can be decomposed into the sum of two terms: a\nleading one of order $\\mathcal{O}(n^{-1/2})$ with explicit dependence on a\nminimax-optimal asymptotic covariance matrix, and a second-order term of order\n$\\mathcal{O}(n^{-3/4})$, where the power $3/4$ is best known. We also extend\nthis result to the higher-order moment bounds. Our analysis relies on the\nproperties of the SGD iterates viewed as a time-homogeneous Markov chain. In\nparticular, we establish that this chain is geometrically ergodic with respect\nto a suitably defined weighted Wasserstein semimetric.\n","authors":["Marina Sheshukova","Denis Belomestny","Alain Durmus","Eric Moulines","Alexey Naumov","Sergey Samsonov"],"pdf_url":"https://arxiv.org/pdf/2410.05106v2.pdf","comment":"ICLR-2025, camera-ready version"},{"id":"http://arxiv.org/abs/2410.07076v4","updated":"2025-03-03T13:17:24Z","published":"2024-10-09T17:19:58Z","title":"MOOSE-Chem: Large Language Models for Rediscovering Unseen Chemistry\n  Scientific Hypotheses","summary":"  Scientific discovery contributes largely to human society's prosperity, and\nrecent progress shows that LLMs could potentially catalyze this process.\nHowever, it is still unclear whether LLMs can discover novel and valid\nhypotheses in chemistry. In this work, we investigate this central research\nquestion: Can LLMs automatically discover novel and valid chemistry research\nhypotheses given only a chemistry research background (consisting of a research\nquestion and/or a background survey), without limitation on the domain of the\nresearch question? After extensive discussions with chemistry experts, we\npropose an assumption that a majority of chemistry hypotheses can be resulted\nfrom a research background and several inspirations. With this key insight, we\nbreak the central question into three smaller fundamental questions. In brief,\nthey are: (1) given a background question, whether LLMs can retrieve good\ninspirations; (2) with background and inspirations, whether LLMs can lead to\nhypothesis; and (3) whether LLMs can identify good hypotheses to rank them\nhigher. To investigate these questions, we construct a benchmark consisting of\n51 chemistry papers published in Nature, Science, or a similar level in 2024\n(all papers are only available online since 2024). Every paper is divided by\nchemistry PhD students into three components: background, inspirations, and\nhypothesis. The goal is to rediscover the hypothesis, given only the background\nand a large randomly selected chemistry literature corpus consisting the ground\ntruth inspiration papers, with LLMs trained with data up to 2023. We also\ndevelop an LLM-based multi-agent framework that leverages the assumption,\nconsisting of three stages reflecting the three smaller questions. The proposed\nmethod can rediscover many hypotheses with very high similarity with the ground\ntruth ones, covering the main innovations.\n","authors":["Zonglin Yang","Wanhao Liu","Ben Gao","Tong Xie","Yuqiang Li","Wanli Ouyang","Soujanya Poria","Erik Cambria","Dongzhan Zhou"],"pdf_url":"https://arxiv.org/pdf/2410.07076v4.pdf","comment":"Accepted by ICLR 2025"},{"id":"http://arxiv.org/abs/2412.16577v2","updated":"2025-03-03T12:21:35Z","published":"2024-12-21T10:52:56Z","title":"A Meta-Learning Approach to Bayesian Causal Discovery","summary":"  Discovering a unique causal structure is difficult due to both inherent\nidentifiability issues, and the consequences of finite data. As such,\nuncertainty over causal structures, such as those obtained from a Bayesian\nposterior, are often necessary for downstream tasks. Finding an accurate\napproximation to this posterior is challenging, due to the large number of\npossible causal graphs, as well as the difficulty in the subproblem of finding\nposteriors over the functional relationships of the causal edges. Recent works\nhave used meta-learning to view the problem of estimating the maximum\na-posteriori causal graph as supervised learning. Yet, these methods are\nlimited when estimating the full posterior as they fail to encode key\nproperties of the posterior, such as correlation between edges and permutation\nequivariance with respect to nodes. Further, these methods also cannot reliably\nsample from the posterior over causal structures. To address these limitations,\nwe propose a Bayesian meta learning model that allows for sampling causal\nstructures from the posterior and encodes these key properties. We compare our\nmeta-Bayesian causal discovery against existing Bayesian causal discovery\nmethods, demonstrating the advantages of directly learning a posterior over\ncausal structure.\n","authors":["Anish Dhir","Matthew Ashman","James Requeima","Mark van der Wilk"],"pdf_url":"https://arxiv.org/pdf/2412.16577v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.08190v2","updated":"2025-03-03T12:18:29Z","published":"2024-10-10T17:57:29Z","title":"Poison-splat: Computation Cost Attack on 3D Gaussian Splatting","summary":"  3D Gaussian splatting (3DGS), known for its groundbreaking performance and\nefficiency, has become a dominant 3D representation and brought progress to\nmany 3D vision tasks. However, in this work, we reveal a significant security\nvulnerability that has been largely overlooked in 3DGS: the computation cost of\ntraining 3DGS could be maliciously tampered by poisoning the input data. By\ndeveloping an attack named Poison-splat, we reveal a novel attack surface where\nthe adversary can poison the input images to drastically increase the\ncomputation memory and time needed for 3DGS training, pushing the algorithm\ntowards its worst computation complexity. In extreme cases, the attack can even\nconsume all allocable memory, leading to a Denial-of-Service (DoS) that\ndisrupts servers, resulting in practical damages to real-world 3DGS service\nvendors. Such a computation cost attack is achieved by addressing a bi-level\noptimization problem through three tailored strategies: attack objective\napproximation, proxy model rendering, and optional constrained optimization.\nThese strategies not only ensure the effectiveness of our attack but also make\nit difficult to defend with simple defensive measures. We hope the revelation\nof this novel attack surface can spark attention to this crucial yet overlooked\nvulnerability of 3DGS systems. Our code is available at\nhttps://github.com/jiahaolu97/poison-splat .\n","authors":["Jiahao Lu","Yifan Zhang","Qiuhong Shen","Xinchao Wang","Shuicheng Yan"],"pdf_url":"https://arxiv.org/pdf/2410.08190v2.pdf","comment":"Accepted by ICLR 2025 as a spotlight paper"},{"id":"http://arxiv.org/abs/2410.00722v2","updated":"2025-03-03T12:18:16Z","published":"2024-10-01T14:13:05Z","title":"On the Geometry and Optimization of Polynomial Convolutional Networks","summary":"  We study convolutional neural networks with monomial activation functions.\nSpecifically, we prove that their parameterization map is regular and is an\nisomorphism almost everywhere, up to rescaling the filters. By leveraging on\ntools from algebraic geometry, we explore the geometric properties of the image\nin function space of this map - typically referred to as neuromanifold. In\nparticular, we compute the dimension and the degree of the neuromanifold, which\nmeasure the expressivity of the model, and describe its singularities.\nMoreover, for a generic large dataset, we derive an explicit formula that\nquantifies the number of critical points arising in the optimization of a\nregression loss.\n","authors":["Vahid Shahverdi","Giovanni Luca Marchetti","Kathln Kohn"],"pdf_url":"https://arxiv.org/pdf/2410.00722v2.pdf","comment":"Accepted at AISTATS 2025"},{"id":"http://arxiv.org/abs/2410.12343v3","updated":"2025-03-03T12:15:38Z","published":"2024-10-16T08:04:57Z","title":"Federated Temporal Graph Clustering","summary":"  Temporal graph clustering is a complex task that involves discovering\nmeaningful structures in dynamic graphs where relationships and entities change\nover time. Existing methods typically require centralized data collection,\nwhich poses significant privacy and communication challenges. In this work, we\nintroduce a novel Federated Temporal Graph Clustering (FTGC) framework that\nenables decentralized training of graph neural networks (GNNs) across multiple\nclients, ensuring data privacy throughout the process. Our approach\nincorporates a temporal aggregation mechanism to effectively capture the\nevolution of graph structures over time and a federated optimization strategy\nto collaboratively learn high-quality clustering representations. By preserving\ndata privacy and reducing communication overhead, our framework achieves\ncompetitive performance on temporal graph datasets, making it a promising\nsolution for privacy-sensitive, real-world applications involving dynamic data.\n","authors":["Zihao Zhou","Yang Liu","Xianghong Xu","Qian Li"],"pdf_url":"https://arxiv.org/pdf/2410.12343v3.pdf","comment":"8 pages, 1 figure"},{"id":"http://arxiv.org/abs/2409.02143v2","updated":"2025-03-03T12:08:50Z","published":"2024-09-02T22:04:08Z","title":"MLOmics: Benchmark for Machine Learning on Cancer Multi-Omics Data","summary":"  Framing the investigation of diverse cancers as a machine learning problem\nhas recently shown significant potential in multi-omics analysis and cancer\nresearch. Empowering these successful machine learning models are the\nhigh-quality training datasets with sufficient data volume and adequate\npreprocessing. However, while there exist several public data portals including\nThe Cancer Genome Atlas (TCGA) multi-omics initiative or open-bases such as the\nLinkedOmics, these databases are not off-the-shelf for existing machine\nlearning models. In this paper we propose MLOmics, an open cancer multi-omics\nbenchmark aiming at serving better the development and evaluation of\nbioinformatics and machine learning models. MLOmics contains 8,314 patient\nsamples covering all 32 cancer types with four omics types, stratified\nfeatures, and extensive baselines. Complementary support for downstream\nanalysis and bio-knowledge linking are also included to support\ninterdisciplinary analysis.\n","authors":["Ziwei Yang","Rikuto Kotoge","Xihao Piao","Zheng Chen","Lingwei Zhu","Peng Gao","Yasuko Matsubara","Yasushi Sakurai","Jimeng Sun"],"pdf_url":"https://arxiv.org/pdf/2409.02143v2.pdf","comment":"Under review"},{"id":"http://arxiv.org/abs/2502.17941v2","updated":"2025-03-03T12:00:57Z","published":"2025-02-25T08:03:04Z","title":"Optimal Brain Apoptosis","summary":"  The increasing complexity and parameter count of Convolutional Neural\nNetworks (CNNs) and Transformers pose challenges in terms of computational\nefficiency and resource demands. Pruning has been identified as an effective\nstrategy to address these challenges by removing redundant elements such as\nneurons, channels, or connections, thereby enhancing computational efficiency\nwithout heavily compromising performance. This paper builds on the foundational\nwork of Optimal Brain Damage (OBD) by advancing the methodology of parameter\nimportance estimation using the Hessian matrix. Unlike previous approaches that\nrely on approximations, we introduce Optimal Brain Apoptosis (OBA), a novel\npruning method that calculates the Hessian-vector product value directly for\neach parameter. By decomposing the Hessian matrix across network layers and\nidentifying conditions under which inter-layer Hessian submatrices are\nnon-zero, we propose a highly efficient technique for computing the\nsecond-order Taylor expansion of parameters. This approach allows for a more\nprecise pruning process, particularly in the context of CNNs and Transformers,\nas validated in our experiments including VGG19, ResNet32, ResNet50, and\nViT-B/16 on CIFAR10, CIFAR100 and Imagenet datasets. Our code is available at\nhttps://github.com/NEU-REAL/OBA.\n","authors":["Mingyuan Sun","Zheng Fang","Jiaxu Wang","Junjie Jiang","Delei Kong","Chenming Hu","Yuetong Fang","Renjing Xu"],"pdf_url":"https://arxiv.org/pdf/2502.17941v2.pdf","comment":"Accepted to ICLR 2025"},{"id":"http://arxiv.org/abs/2407.15589v5","updated":"2025-03-03T11:48:03Z","published":"2024-07-22T12:26:08Z","title":"Exploring the Effectiveness of Object-Centric Representations in Visual\n  Question Answering: Comparative Insights with Foundation Models","summary":"  Object-centric (OC) representations, which model visual scenes as\ncompositions of discrete objects, have the potential to be used in various\ndownstream tasks to achieve systematic compositional generalization and\nfacilitate reasoning. However, these claims have yet to be thoroughly validated\nempirically. Recently, foundation models have demonstrated unparalleled\ncapabilities across diverse domains, from language to computer vision,\npositioning them as a potential cornerstone of future research for a wide range\nof computational tasks. In this paper, we conduct an extensive empirical study\non representation learning for downstream Visual Question Answering (VQA),\nwhich requires an accurate compositional understanding of the scene. We\nthoroughly investigate the benefits and trade-offs of OC models and alternative\napproaches including large pre-trained foundation models on both synthetic and\nreal-world data, ultimately identifying a promising path to leverage the\nstrengths of both paradigms. The extensiveness of our study, encompassing over\n600 downstream VQA models and 15 different types of upstream representations,\nalso provides several additional insights that we believe will be of interest\nto the community at large.\n","authors":["Amir Mohammad Karimi Mamaghan","Samuele Papa","Karl Henrik Johansson","Stefan Bauer","Andrea Dittadi"],"pdf_url":"https://arxiv.org/pdf/2407.15589v5.pdf","comment":"Published at ICLR 2025"},{"id":"http://arxiv.org/abs/2405.16195v3","updated":"2025-03-03T11:39:53Z","published":"2024-05-25T11:57:43Z","title":"Adaptive $Q$-Network: On-the-fly Target Selection for Deep Reinforcement\n  Learning","summary":"  Deep Reinforcement Learning (RL) is well known for being highly sensitive to\nhyperparameters, requiring practitioners substantial efforts to optimize them\nfor the problem at hand. This also limits the applicability of RL in real-world\nscenarios. In recent years, the field of automated Reinforcement Learning\n(AutoRL) has grown in popularity by trying to address this issue. However,\nthese approaches typically hinge on additional samples to select\nwell-performing hyperparameters, hindering sample-efficiency and practicality.\nFurthermore, most AutoRL methods are heavily based on already existing AutoML\nmethods, which were originally developed neglecting the additional challenges\ninherent to RL due to its non-stationarities. In this work, we propose a new\napproach for AutoRL, called Adaptive $Q$-Network (AdaQN), that is tailored to\nRL to take into account the non-stationarity of the optimization procedure\nwithout requiring additional samples. AdaQN learns several $Q$-functions, each\none trained with different hyperparameters, which are updated online using the\n$Q$-function with the smallest approximation error as a shared target. Our\nselection scheme simultaneously handles different hyperparameters while coping\nwith the non-stationarity induced by the RL optimization procedure and being\northogonal to any critic-based RL algorithm. We demonstrate that AdaQN is\ntheoretically sound and empirically validate it in MuJoCo control problems and\nAtari $2600$ games, showing benefits in sample-efficiency, overall performance,\nrobustness to stochasticity and training stability.\n","authors":["Tho Vincent","Fabian Wahren","Jan Peters","Boris Belousov","Carlo D'Eramo"],"pdf_url":"https://arxiv.org/pdf/2405.16195v3.pdf","comment":"Accepted at ICLR https://iclr.cc/virtual/2025/poster/28508"},{"id":"http://arxiv.org/abs/2410.11502v2","updated":"2025-03-03T11:38:11Z","published":"2024-10-15T11:15:03Z","title":"Offline Model-Based Optimization by Learning to Rank","summary":"  Offline model-based optimization (MBO) aims to identify a design that\nmaximizes a black-box function using only a fixed, pre-collected dataset of\ndesigns and their corresponding scores. A common approach in offline MBO is to\ntrain a regression-based surrogate model by minimizing mean squared error (MSE)\nand then find the best design within this surrogate model by different\noptimizers (e.g., gradient ascent). However, a critical challenge is the risk\nof out-of-distribution errors, i.e., the surrogate model may typically\noverestimate the scores and mislead the optimizers into suboptimal regions.\nPrior works have attempted to address this issue in various ways, such as using\nregularization techniques and ensemble learning to enhance the robustness of\nthe model, but it still remains. In this paper, we argue that regression models\ntrained with MSE are not well-aligned with the primary goal of offline MBO,\nwhich is to select promising designs rather than to predict their scores\nprecisely. Notably, if a surrogate model can maintain the order of candidate\ndesigns based on their relative score relationships, it can produce the best\ndesigns even without precise predictions. To validate it, we conduct\nexperiments to compare the relationship between the quality of the final\ndesigns and MSE, finding that the correlation is really very weak. In contrast,\na metric that measures order-maintaining quality shows a significantly stronger\ncorrelation. Based on this observation, we propose learning a ranking-based\nmodel that leverages learning to rank techniques to prioritize promising\ndesigns based on their relative scores. We show that the generalization error\non ranking loss can be well bounded. Empirical results across diverse tasks\ndemonstrate the superior performance of our proposed ranking-based models than\ntwenty existing methods.\n","authors":["Rong-Xi Tan","Ke Xue","Shen-Huan Lyu","Haopu Shang","Yao Wang","Yaoyuan Wang","Sheng Fu","Chao Qian"],"pdf_url":"https://arxiv.org/pdf/2410.11502v2.pdf","comment":"ICLR 2025"},{"id":"http://arxiv.org/abs/2407.06057v2","updated":"2025-03-03T11:08:15Z","published":"2024-07-08T15:59:44Z","title":"Variational Best-of-N Alignment","summary":"  Best-of-N (BoN) is a popular and effective algorithm for aligning language\nmodels to human preferences. The algorithm works as follows: at inference time,\nN samples are drawn from the language model, and the sample with the highest\nreward, as judged by a reward model, is returned as the output. Despite its\neffectiveness, BoN is computationally expensive; it reduces sampling throughput\nby a factor of N. To make BoN more efficient at inference time, one strategy is\nto fine-tune the language model to mimic what BoN does during inference. To\nachieve this, we derive the distribution induced by the BoN algorithm. We then\npropose to fine-tune the language model to minimize backward KL divergence to\nthe BoN distribution. Our approach is analogous to mean-field variational\ninference and, thus, we term it variational BoN (vBoN). To the extent this\nfine-tuning is successful and we end up with a good approximation, we have\nreduced the inference cost by a factor of N. Our experiments on controlled\ngeneration and summarization tasks show that BoN is the most effective\nalignment method, and our variational approximation to BoN achieves the closest\nperformance to BoN and surpasses models fine-tuned using the standard\nKL-constrained RL objective. In the controlled generation task, vBoN appears\nmore frequently on the Pareto frontier of reward and KL divergence compared to\nother alignment methods. In the summarization task, vBoN achieves high reward\nvalues across various sampling temperatures.\n","authors":["Afra Amini","Tim Vieira","Elliott Ash","Ryan Cotterell"],"pdf_url":"https://arxiv.org/pdf/2407.06057v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.05841v2","updated":"2025-03-03T11:00:24Z","published":"2024-11-06T15:06:42Z","title":"FLEXtime: Filterbank learning to explain time series","summary":"  State-of-the-art methods for explaining predictions from time series involve\nlearning an instance-wise saliency mask for each time step; however, many types\nof time series are difficult to interpret in the time domain, due to the\ninherently complex nature of the data. Instead, we propose to view time series\nexplainability as saliency maps over interpretable parts, leaning on\nestablished signal processing methodology on signal decomposition.\nSpecifically, we propose a new method called FLEXtime that uses a bank of\nbandpass filters to split the time series into frequency bands. Then, we learn\nthe combination of these bands that optimally explains the model's prediction.\nOur extensive evaluation shows that, on average, FLEXtime outperforms\nstate-of-the-art explainability methods across a range of datasets. FLEXtime\nfills an important gap in the current time series explainability methodology\nand is a valuable tool for a wide range of time series such as EEG and audio.\nCode will be made available at https://github.com/theabrusch/FLEXtime.\n","authors":["Thea Brsch","Kristoffer K. Wickstrm","Mikkel N. Schmidt","Robert Jenssen","Tommy S. Alstrm"],"pdf_url":"https://arxiv.org/pdf/2411.05841v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2501.18936v4","updated":"2025-03-03T11:00:24Z","published":"2025-01-31T07:41:06Z","title":"Adaptive Prompt: Unlocking the Power of Visual Prompt Tuning","summary":"  Visual Prompt Tuning (VPT) has recently emerged as a powerful method for\nadapting pre-trained vision models to downstream tasks. By introducing\nlearnable prompt tokens as task-specific instructions, VPT effectively guides\npre-trained transformer models with minimal overhead. Despite its empirical\nsuccess, a comprehensive theoretical understanding of VPT remains an active\narea of research. Building on recent insights into the connection between\nmixture of experts and prompt-based approaches, we identify a key limitation in\nVPT: the restricted functional expressiveness in prompt formulation. To address\nthis limitation, we propose Visual Adaptive Prompt Tuning (VAPT), a new\ngeneration of prompts that redefines prompts as adaptive functions of the\ninput. Our theoretical analysis shows that this simple yet intuitive approach\nachieves optimal sample efficiency. Empirical results on VTAB-1K and FGVC\nfurther demonstrate VAPT's effectiveness, with performance gains of 7.34% and\n1.04% over fully fine-tuning baselines, respectively. Notably, VAPT also\nsurpasses VPT by a substantial margin while using fewer parameters. These\nresults highlight both the effectiveness and efficiency of our method and pave\nthe way for future research to explore the potential of adaptive prompts.\n","authors":["Minh Le","Anh Nguyen","Huy Nguyen","Chau Nguyen","Nhat Ho"],"pdf_url":"https://arxiv.org/pdf/2501.18936v4.pdf","comment":"57 pages, 10 figures, 18 tables"},{"id":"http://arxiv.org/abs/2405.20579v3","updated":"2025-03-03T10:57:41Z","published":"2024-05-31T02:17:51Z","title":"HOPE: A Reinforcement Learning-based Hybrid Policy Path Planner for\n  Diverse Parking Scenarios","summary":"  Automated parking stands as a highly anticipated application of autonomous\ndriving technology. However, existing path planning methodologies fall short of\naddressing this need due to their incapability to handle the diverse and\ncomplex parking scenarios in reality. While non-learning methods provide\nreliable planning results, they are vulnerable to intricate occasions, whereas\nlearning-based ones are good at exploration but unstable in converging to\nfeasible solutions. To leverage the strengths of both approaches, we introduce\nHybrid pOlicy Path plannEr (HOPE). This novel solution integrates a\nreinforcement learning agent with Reeds-Shepp curves, enabling effective\nplanning across diverse scenarios. HOPE guides the exploration of the\nreinforcement learning agent by applying an action mask mechanism and employs a\ntransformer to integrate the perceived environmental information with the mask.\nTo facilitate the training and evaluation of the proposed planner, we propose a\ncriterion for categorizing the difficulty level of parking scenarios based on\nspace and obstacle distribution. Experimental results demonstrate that our\napproach outperforms typical rule-based algorithms and traditional\nreinforcement learning methods, showing higher planning success rates and\ngeneralization across various scenarios. We also conduct real-world experiments\nto verify the practicability of HOPE. The code for our solution is openly\navailable on https://github.com/jiamiya/HOPE.\n","authors":["Mingyang Jiang","Yueyuan Li","Songan Zhang","Siyuan Chen","Chunxiang Wang","Ming Yang"],"pdf_url":"https://arxiv.org/pdf/2405.20579v3.pdf","comment":"Accepted by T-ITS. 11 pages, 5 tables, 6 figures, 2 page appendix"},{"id":"http://arxiv.org/abs/2410.02423v2","updated":"2025-03-03T10:44:06Z","published":"2024-10-03T12:13:56Z","title":"PnP-Flow: Plug-and-Play Image Restoration with Flow Matching","summary":"  In this paper, we introduce Plug-and-Play (PnP) Flow Matching, an algorithm\nfor solving imaging inverse problems. PnP methods leverage the strength of\npre-trained denoisers, often deep neural networks, by integrating them in\noptimization schemes. While they achieve state-of-the-art performance on\nvarious inverse problems in imaging, PnP approaches face inherent limitations\non more generative tasks like inpainting. On the other hand, generative models\nsuch as Flow Matching pushed the boundary in image sampling yet lack a clear\nmethod for efficient use in image restoration. We propose to combine the PnP\nframework with Flow Matching (FM) by defining a time-dependent denoiser using a\npre-trained FM model. Our algorithm alternates between gradient descent steps\non the data-fidelity term, reprojections onto the learned FM path, and\ndenoising. Notably, our method is computationally efficient and\nmemory-friendly, as it avoids backpropagation through ODEs and trace\ncomputations. We evaluate its performance on denoising, super-resolution,\ndeblurring, and inpainting tasks, demonstrating superior results compared to\nexisting PnP algorithms and Flow Matching based state-of-the-art methods.\n","authors":["Sgolne Martin","Anne Gagneux","Paul Hagemann","Gabriele Steidl"],"pdf_url":"https://arxiv.org/pdf/2410.02423v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2412.11542v2","updated":"2025-03-03T10:39:41Z","published":"2024-12-16T08:22:23Z","title":"Meta Curvature-Aware Minimization for Domain Generalization","summary":"  Domain generalization (DG) aims to enhance the ability of models trained on\nsource domains to generalize effectively to unseen domains. Recently,\nSharpness-Aware Minimization (SAM) has shown promise in this area by reducing\nthe sharpness of the loss landscape to obtain more generalized models. However,\nSAM and its variants sometimes fail to guide the model toward a flat minimum,\nand their training processes exhibit limitations, hindering further\nimprovements in model generalization. In this paper, we first propose an\nimproved model training process aimed at encouraging the model to converge to a\nflat minima. To achieve this, we design a curvature metric that has a minimal\neffect when the model is far from convergence but becomes increasingly\ninfluential in indicating the curvature of the minima as the model approaches a\nlocal minimum. Then we derive a novel algorithm from this metric, called Meta\nCurvature-Aware Minimization (MeCAM), to minimize the curvature around the\nlocal minima. Specifically, the optimization objective of MeCAM simultaneously\nminimizes the regular training loss, the surrogate gap of SAM, and the\nsurrogate gap of meta-learning. We provide theoretical analysis on MeCAM's\ngeneralization error and convergence rate, and demonstrate its superiority over\nexisting DG methods through extensive experiments on five benchmark DG\ndatasets, including PACS, VLCS, OfficeHome, TerraIncognita, and DomainNet. Code\nwill be available on GitHub.\n","authors":["Ziyang Chen","Yiwen Ye","Feilong Tang","Yongsheng Pan","Yong Xia"],"pdf_url":"https://arxiv.org/pdf/2412.11542v2.pdf","comment":"22 pages, 5 figures, 17 tables"},{"id":"http://arxiv.org/abs/2502.08005v2","updated":"2025-03-03T10:38:34Z","published":"2025-02-11T23:02:14Z","title":"Towards Training One-Step Diffusion Models Without Distillation","summary":"  Recent advances in one-step generative models typically follow a two-stage\nprocess: first training a teacher diffusion model and then distilling it into a\none-step student model. This distillation process traditionally relies on both\nthe teacher model's score function to compute the distillation loss and its\nweights for student initialization. In this paper, we explore whether one-step\ngenerative models can be trained directly without this distillation process.\nFirst, we show that the teacher's score function is not essential and propose a\nfamily of distillation methods that achieve competitive results without relying\non score estimation. Next, we demonstrate that initialization from teacher\nweights is indispensable in successful training. Surprisingly, we find that\nthis benefit is not due to improved ``input-output\" mapping but rather the\nlearned feature representations, which dominate distillation quality. Our\nfindings provide a better understanding of the role of initialization in\none-step model training and its impact on distillation quality.\n","authors":["Mingtian Zhang","Jiajun He","Wenlin Chen","Zijing Ou","Jos Miguel Hernndez-Lobato","Bernhard Schlkopf","David Barber"],"pdf_url":"https://arxiv.org/pdf/2502.08005v2.pdf","comment":"13 pages, Technical Report"},{"id":"http://arxiv.org/abs/2502.15425v3","updated":"2025-03-03T10:35:14Z","published":"2025-02-21T12:52:16Z","title":"TAG: A Decentralized Framework for Multi-Agent Hierarchical\n  Reinforcement Learning","summary":"  Hierarchical organization is fundamental to biological systems and human\nsocieties, yet artificial intelligence systems often rely on monolithic\narchitectures that limit adaptability and scalability. Current hierarchical\nreinforcement learning (HRL) approaches typically restrict hierarchies to two\nlevels or require centralized training, which limits their practical\napplicability. We introduce TAME Agent Framework (TAG), a framework for\nconstructing fully decentralized hierarchical multi-agent systems.TAG enables\nhierarchies of arbitrary depth through a novel LevelEnv concept, which\nabstracts each hierarchy level as the environment for the agents above it. This\napproach standardizes information flow between levels while preserving loose\ncoupling, allowing for seamless integration of diverse agent types. We\ndemonstrate the effectiveness of TAG by implementing hierarchical architectures\nthat combine different RL agents across multiple levels, achieving improved\nperformance over classical multi-agent RL baselines on standard benchmarks. Our\nresults show that decentralized hierarchical organization enhances both\nlearning speed and final performance, positioning TAG as a promising direction\nfor scalable multi-agent systems.\n","authors":["Giuseppe Paolo","Abdelhakim Benechehab","Hamza Cherkaoui","Albert Thomas","Balzs Kgl"],"pdf_url":"https://arxiv.org/pdf/2502.15425v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.06916v2","updated":"2025-03-03T10:22:24Z","published":"2024-11-11T12:19:28Z","title":"Slowing Down Forgetting in Continual Learning","summary":"  A common challenge in continual learning (CL) is catastrophic forgetting,\nwhere the performance on old tasks drops after new, additional tasks are\nlearned. In this paper, we propose a novel framework called ReCL to slow down\nforgetting in CL. Our framework exploits an implicit bias of gradient-based\nneural networks due to which these converge to margin maximization points. Such\nconvergence points allow us to reconstruct old data from previous tasks, which\nwe then combine with the current training data. Our framework is flexible and\ncan be applied on top of existing, state-of-the-art CL methods. We further\ndemonstrate the performance gain from our framework across a large series of\nexperiments, including two challenging CL scenarios (class incremental and\ndomain incremental learning), different datasets (MNIST, CIFAR10,\nTinyImagenet), and different network architectures. Across all experiments, we\nfind large performance gains through ReCL. To the best of our knowledge, our\nframework is the first to address catastrophic forgetting by leveraging models\nin CL as their own memory buffers.\n","authors":["Pascal Janetzky","Tobias Schlagenhauf","Stefan Feuerriegel"],"pdf_url":"https://arxiv.org/pdf/2411.06916v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2502.21123v2","updated":"2025-03-03T10:00:03Z","published":"2025-02-28T14:57:33Z","title":"Causality Is Key to Understand and Balance Multiple Goals in Trustworthy\n  ML and Foundation Models","summary":"  Ensuring trustworthiness in machine learning (ML) systems is crucial as they\nbecome increasingly embedded in high-stakes domains. This paper advocates for\nintegrating causal methods into machine learning to navigate the trade-offs\namong key principles of trustworthy ML, including fairness, privacy,\nrobustness, accuracy, and explainability. While these objectives should ideally\nbe satisfied simultaneously, they are often addressed in isolation, leading to\nconflicts and suboptimal solutions. Drawing on existing applications of\ncausality in ML that successfully align goals such as fairness and accuracy or\nprivacy and robustness, this paper argues that a causal approach is essential\nfor balancing multiple competing objectives in both trustworthy ML and\nfoundation models. Beyond highlighting these trade-offs, we examine how\ncausality can be practically integrated into ML and foundation models, offering\nsolutions to enhance their reliability and interpretability. Finally, we\ndiscuss the challenges, limitations, and opportunities in adopting causal\nframeworks, paving the way for more accountable and ethically sound AI systems.\n","authors":["Ruta Binkyte","Ivaxi Sheth","Zhijing Jin","Mohammad Havaei","Bernhard Schlkopf","Mario Fritz"],"pdf_url":"https://arxiv.org/pdf/2502.21123v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.02392v2","updated":"2025-03-03T09:50:18Z","published":"2024-10-03T11:13:55Z","title":"MANTRA: The Manifold Triangulations Assemblage","summary":"  The rising interest in leveraging higher-order interactions present in\ncomplex systems has led to a surge in more expressive models exploiting\nhigher-order structures in the data, especially in topological deep learning\n(TDL), which designs neural networks on higher-order domains such as simplicial\ncomplexes. However, progress in this field is hindered by the scarcity of\ndatasets for benchmarking these architectures. To address this gap, we\nintroduce MANTRA, the first large-scale, diverse, and intrinsically\nhigher-order dataset for benchmarking higher-order models, comprising over\n43,000 and 250,000 triangulations of surfaces and three-dimensional manifolds,\nrespectively. With MANTRA, we assess several graph- and simplicial\ncomplex-based models on three topological classification tasks. We demonstrate\nthat while simplicial complex-based neural networks generally outperform their\ngraph-based counterparts in capturing simple topological invariants, they also\nstruggle, suggesting a rethink of TDL. Thus, MANTRA serves as a benchmark for\nassessing and advancing topological methods, leading the way for more effective\nhigher-order models.\n","authors":["Rubn Ballester","Ernst Rell","Daniel Bn Schmid","Mathieu Alain","Sergio Escalera","Carles Casacuberta","Bastian Rieck"],"pdf_url":"https://arxiv.org/pdf/2410.02392v2.pdf","comment":"Accepted at ICLR 2025 (https://openreview.net/forum?id=X6y5CC44HM)"},{"id":"http://arxiv.org/abs/2402.09154v2","updated":"2025-03-03T09:37:27Z","published":"2024-02-14T13:13:26Z","title":"Attacking Large Language Models with Projected Gradient Descent","summary":"  Current LLM alignment methods are readily broken through specifically crafted\nadversarial prompts. While crafting adversarial prompts using discrete\noptimization is highly effective, such attacks typically use more than 100,000\nLLM calls. This high computational cost makes them unsuitable for, e.g.,\nquantitative analyses and adversarial training. To remedy this, we revisit\nProjected Gradient Descent (PGD) on the continuously relaxed input prompt.\nAlthough previous attempts with ordinary gradient-based attacks largely failed,\nwe show that carefully controlling the error introduced by the continuous\nrelaxation tremendously boosts their efficacy. Our PGD for LLMs is up to one\norder of magnitude faster than state-of-the-art discrete optimization to\nachieve the same devastating attack results.\n","authors":["Simon Geisler","Tom Wollschlger","M. H. I. Abdalla","Johannes Gasteiger","Stephan Gnnemann"],"pdf_url":"https://arxiv.org/pdf/2402.09154v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.23751v2","updated":"2025-03-03T09:30:42Z","published":"2024-10-31T09:11:56Z","title":"EXACFS -- A CIL Method to mitigate Catastrophic Forgetting","summary":"  Deep neural networks (DNNS) excel at learning from static datasets but\nstruggle with continual learning, where data arrives sequentially. Catastrophic\nforgetting, the phenomenon of forgetting previously learned knowledge, is a\nprimary challenge. This paper introduces EXponentially Averaged Class-wise\nFeature Significance (EXACFS) to mitigate this issue in the class incremental\nlearning (CIL) setting. By estimating the significance of model features for\neach learned class using loss gradients, gradually aging the significance\nthrough the incremental tasks and preserving the significant features through a\ndistillation loss, EXACFS effectively balances remembering old knowledge\n(stability) and learning new knowledge (plasticity). Extensive experiments on\nCIFAR-100 and ImageNet-100 demonstrate EXACFS's superior performance in\npreserving stability while acquiring plasticity.\n","authors":["S Balasubramanian","M Sai Subramaniam","Sai Sriram Talasu","Yedu Krishna P","Manepalli Pranav Phanindra Sai","Ravi Mukkamala","Darshan Gera"],"pdf_url":"https://arxiv.org/pdf/2410.23751v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2412.00537v2","updated":"2025-03-03T09:26:05Z","published":"2024-11-30T17:05:12Z","title":"Exact Certification of (Graph) Neural Networks Against Label Poisoning","summary":"  Machine learning models are highly vulnerable to label flipping, i.e., the\nadversarial modification (poisoning) of training labels to compromise\nperformance. Thus, deriving robustness certificates is important to guarantee\nthat test predictions remain unaffected and to understand worst-case robustness\nbehavior. However, for Graph Neural Networks (GNNs), the problem of certifying\nlabel flipping has so far been unsolved. We change this by introducing an exact\ncertification method, deriving both sample-wise and collective certificates.\nOur method leverages the Neural Tangent Kernel (NTK) to capture the training\ndynamics of wide networks enabling us to reformulate the bilevel optimization\nproblem representing label flipping into a Mixed-Integer Linear Program (MILP).\nWe apply our method to certify a broad range of GNN architectures in node\nclassification tasks. Thereby, concerning the worst-case robustness to label\nflipping: $(i)$ we establish hierarchies of GNNs on different benchmark graphs;\n$(ii)$ quantify the effect of architectural choices such as activations, depth\nand skip-connections; and surprisingly, $(iii)$ uncover a novel phenomenon of\nthe robustness plateauing for intermediate perturbation budgets across all\ninvestigated datasets and architectures. While we focus on GNNs, our\ncertificates are applicable to sufficiently wide NNs in general through their\nNTK. Thus, our work presents the first exact certificate to a poisoning attack\never derived for neural networks, which could be of independent interest. The\ncode is available at https://github.com/saper0/qpcert.\n","authors":["Mahalakshmi Sabanayagam","Lukas Gosch","Stephan Gnnemann","Debarghya Ghoshdastidar"],"pdf_url":"https://arxiv.org/pdf/2412.00537v2.pdf","comment":"Published as a spotlight presentation at ICLR 2025"},{"id":"http://arxiv.org/abs/2502.16890v2","updated":"2025-03-03T08:58:48Z","published":"2025-02-24T06:40:33Z","title":"ReFocus: Reinforcing Mid-Frequency and Key-Frequency Modeling for\n  Multivariate Time Series Forecasting","summary":"  Recent advancements have progressively incorporated frequency-based\ntechniques into deep learning models, leading to notable improvements in\naccuracy and efficiency for time series analysis tasks. However, the\nMid-Frequency Spectrum Gap in the real-world time series, where the energy is\nconcentrated at the low-frequency region while the middle-frequency band is\nnegligible, hinders the ability of existing deep learning models to extract the\ncrucial frequency information. Additionally, the shared Key-Frequency in\nmultivariate time series, where different time series share indistinguishable\nfrequency patterns, is rarely exploited by existing literature. This work\nintroduces a novel module, Adaptive Mid-Frequency Energy Optimizer, based on\nconvolution and residual learning, to emphasize the significance of\nmid-frequency bands. We also propose an Energy-based Key-Frequency Picking\nBlock to capture shared Key-Frequency, which achieves superior inter-series\nmodeling performance with fewer parameters. A novel Key-Frequency Enhanced\nTraining strategy is employed to further enhance Key-Frequency modeling, where\nspectral information from other channels is randomly introduced into each\nchannel. Our approach advanced multivariate time series forecasting on the\nchallenging Traffic, ECL, and Solar benchmarks, reducing MSE by 4%, 6%, and 5%\ncompared to the previous SOTA iTransformer. Code is available at this GitHub\nRepository: https://github.com/Levi-Ackman/ReFocus.\n","authors":["Guoqi Yu","Yaoming Li","Juncheng Wang","Xiaoyu Guo","Angelica I. Aviles-Rivero","Tong Yang","Shujun Wang"],"pdf_url":"https://arxiv.org/pdf/2502.16890v2.pdf","comment":"Under Review"},{"id":"http://arxiv.org/abs/2502.08679v3","updated":"2025-03-03T08:50:28Z","published":"2025-02-12T08:56:35Z","title":"Deep Learning-Driven Malware Classification with API Call Sequence\n  Analysis and Concept Drift Handling","summary":"  Malware classification in dynamic environments presents a significant\nchallenge due to concept drift, where the statistical properties of malware\ndata evolve over time, complicating detection efforts. To address this issue,\nwe propose a deep learning framework enhanced with a genetic algorithm to\nimprove malware classification accuracy and adaptability. Our approach\nincorporates mutation operations and fitness score evaluations within genetic\nalgorithms to continuously refine the deep learning model, ensuring robustness\nagainst evolving malware threats. Experimental results demonstrate that this\nhybrid method significantly enhances classification performance and\nadaptability, outperforming traditional static models. Our proposed approach\noffers a promising solution for real-time malware classification in\never-changing cybersecurity landscapes.\n","authors":["Bishwajit Prasad Gond","Durga Prasad Mohapatra"],"pdf_url":"https://arxiv.org/pdf/2502.08679v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2407.03856v4","updated":"2025-03-03T08:48:38Z","published":"2024-07-04T11:42:36Z","title":"Q-Adapter: Customizing Pre-trained LLMs to New Preferences with\n  Forgetting Mitigation","summary":"  Large Language Models (LLMs), trained on a large amount of corpus, have\ndemonstrated remarkable abilities. However, it may not be sufficient to\ndirectly apply open-source LLMs like Llama to certain real-world scenarios,\nsince most of them are trained for \\emph{general} purposes. Thus, the demands\nfor customizing publicly available LLMs emerge, but are currently\nunder-studied. In this work, we consider customizing pre-trained LLMs with new\nhuman preferences. Specifically, the LLM should not only meet the new\npreference but also preserve its original capabilities after customization.\nDrawing inspiration from the observation that human preference can be expressed\nas a reward model, we propose to cast LLM customization as optimizing the sum\nof two reward functions, one of which (denoted as $r_1$) was used to pre-train\nthe LLM while the other (denoted as $r_2$) characterizes the new human\npreference. The obstacle here is that both reward functions are unknown, making\nthe application of modern reinforcement learning methods infeasible. Thanks to\nthe residual Q-learning framework, we can restore the customized LLM with the\npre-trained LLM and the \\emph{residual Q-function} without the reward function\n$r_1$. Moreover, we find that for a fixed pre-trained LLM, the reward function\n$r_2$ can be derived from the residual Q-function, enabling us to directly\nlearn the residual Q-function from the new human preference data upon the\nBradley-Terry model. We name our method Q-Adapter as it introduces an adapter\nmodule to approximate the residual Q-function for customizing the pre-trained\nLLM towards the new preference. Experiments based on the Llama-3.1 model on the\nDSP dataset and HH-RLHF dataset illustrate the superior effectiveness of\nQ-Adapter on both retaining existing knowledge and learning new preferences.\nCode is available at https://github.com/mansicer/Q-Adapter.\n","authors":["Yi-Chen Li","Fuxiang Zhang","Wenjie Qiu","Lei Yuan","Chengxing Jia","Zongzhang Zhang","Yang Yu","Bo An"],"pdf_url":"https://arxiv.org/pdf/2407.03856v4.pdf","comment":"Camera ready version of ICLR 2025"},{"id":"http://arxiv.org/abs/2410.07267v2","updated":"2025-03-03T08:45:31Z","published":"2024-10-09T02:44:53Z","title":"Scintillation pulse characterization with spectrum-inspired temporal\n  neural networks: case studies on particle detector signals","summary":"  Particle detectors based on scintillators are widely used in high-energy\nphysics and astroparticle physics experiments, nuclear medicine imaging,\nindustrial and environmental detection, etc. Precisely extracting scintillation\nsignal characteristics at the event level is important for these applications,\nnot only in respect of understanding the scintillator itself, but also kinds\nand physical property of incident particles. Recent researches demonstrate\ndata-driven neural networks surpass traditional statistical methods, especially\nwhen the analytical form of signals is hard to obtain, or noise is significant.\nHowever, most densely connected or convolution-based networks fail to fully\nexploit the spectral and temporal structure of scintillation signals, leaving\nlarge space for performance improvement. In this paper, we propose a network\narchitecture specially tailored for scintillation pulse characterization based\non previous works on time series analysis. The core insight is that, by\ndirectly applying Fast Fourier Transform on original signals and utilizing\ndifferent frequency components, the proposed network architecture can serve as\na lightweight and enhanced representation learning backbone. We prove our idea\nin two case studies: (a) simulation data generated with the setting of the LUX\ndark matter detector, and (b) experimental electrical signals with fast\nelectronics to emulate scintillation variations for the NICA/MPD calorimeter.\nThe proposed model achieves significantly better results than the reference\nmodel in literature and densely connected models, and demonstrates higher\ncost-efficiency than conventional machine learning methods.\n","authors":["Pengcheng Ai","Xiangming Sun","Zhi Deng","Xinchi Ran"],"pdf_url":"https://arxiv.org/pdf/2410.07267v2.pdf","comment":"29 pages, 14 figures"},{"id":"http://arxiv.org/abs/2502.11167v2","updated":"2025-03-03T08:26:12Z","published":"2025-02-16T15:38:19Z","title":"SURGE: On the Potential of Large Language Models as General-Purpose\n  Surrogate Code Executors","summary":"  Neural surrogate models have emerged as powerful and efficient tools in data\nmining. Meanwhile, large language models (LLMs) have demonstrated remarkable\ncapabilities in code-related tasks. We investigate a novel application: using\nLLMs as surrogate models for code execution prediction. Given LLMs' unique\nability to understand and process diverse programs, they present a promising\ndirection for building general-purpose surrogate models. To systematically\ninvestigate this capability, we introduce SURGE, a comprehensive benchmark with\n$1160$ problems covering $8$ key aspects: multi-language programming tasks,\ncompetition-level programming problems, repository-level code analysis,\nhigh-cost scientific computing, time-complexity-intensive algorithms, buggy\ncode analysis, programs dependent on specific compilers or execution\nenvironments, and formal mathematical proof verification. Through extensive\nempirical analysis of $21$ open-source and proprietary LLMs, we examine scaling\nlaws, data efficiency, and predictive accuracy. Our findings reveal important\ninsights about the feasibility of LLMs as efficient surrogates for\ncomputational processes, with implications for automated software testing,\nprogram analysis, and computational resource optimization in data mining\napplications. Code and dataset are released at\nhttps://github.com/Imbernoulli/SURGE.\n","authors":["Bohan Lyu","Siqiao Huang","Zichen Liang"],"pdf_url":"https://arxiv.org/pdf/2502.11167v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2405.19316v2","updated":"2025-03-03T08:22:25Z","published":"2024-05-29T17:39:48Z","title":"Robust Preference Optimization through Reward Model Distillation","summary":"  Language model (LM) post-training (or alignment) involves maximizing a reward\nfunction that is derived from preference annotations. Direct Preference\nOptimization (DPO) is a popular offline alignment method that trains a policy\ndirectly on preference data without the need to train a reward model or apply\nreinforcement learning. However, the empirical evidence suggests that DPO\ntypically assigns implicit rewards that overfit, and trend towards infinite\nmagnitude. This frequently leads to degenerate policies, sometimes causing even\nthe probabilities of the preferred generations to go to zero. In this work, we\nanalyze this phenomenon and use distillation to get a better proxy for the true\npreference distribution over generation pairs: we train the LM such that its\ninduced implicit reward, i.e., the scaled log-likelihood ratio of the model to\nthe reference model, matches an explicit reward model trained on the preference\ndata. Moreover, to account for uncertainty in the reward model we are\ndistilling from, we optimize against a family of reward models that, as a\nwhole, is likely to include at least one reasonable proxy for the preference\ndistribution. Our results show that distilling from such a family of reward\nmodels leads to improved robustness to distribution shift in preference\nannotations, while preserving the simple supervised nature of DPO.\n","authors":["Adam Fisch","Jacob Eisenstein","Vicky Zayats","Alekh Agarwal","Ahmad Beirami","Chirag Nagpal","Pete Shaw","Jonathan Berant"],"pdf_url":"https://arxiv.org/pdf/2405.19316v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2412.07407v2","updated":"2025-03-03T08:05:53Z","published":"2024-12-10T10:58:47Z","title":"Towards Graph Foundation Models: A Study on the Generalization of\n  Positional and Structural Encodings","summary":"  Recent advances in integrating positional and structural encodings (PSEs)\ninto graph neural networks (GNNs) have significantly enhanced their performance\nacross various graph learning tasks. However, the general applicability of\nthese encodings and their potential to serve as foundational representations\nfor graphs remain uncertain. This paper investigates the fine-tuning\nefficiency, scalability with sample size, and generalization capability of\nlearnable PSEs across diverse graph datasets. Specifically, we evaluate their\npotential as universal pre-trained models that can be easily adapted to new\ntasks with minimal fine-tuning and limited data. Furthermore, we assess the\nexpressivity of the learned representations, particularly, when used to augment\ndownstream GNNs. We demonstrate through extensive benchmarking and empirical\nanalysis that PSEs generally enhance downstream models. However, some datasets\nmay require specific PSE-augmentations to achieve optimal performance.\nNevertheless, our findings highlight their significant potential to become\nintegral components of future graph foundation models. We provide new insights\ninto the strengths and limitations of PSEs, contributing to the broader\ndiscourse on foundation models in graph learning.\n","authors":["Billy Joe Franks","Moshe Eliasof","Semih Cantrk","Guy Wolf","Carola-Bibiane Schnlieb","Sophie Fellenz","Marius Kloft"],"pdf_url":"https://arxiv.org/pdf/2412.07407v2.pdf","comment":"Published at TMLR (https://openreview.net/forum?id=mSoDRZXsqj)"},{"id":"http://arxiv.org/abs/2410.02683v2","updated":"2025-03-03T07:20:54Z","published":"2024-10-03T17:08:52Z","title":"DailyDilemmas: Revealing Value Preferences of LLMs with Quandaries of\n  Daily Life","summary":"  As users increasingly seek guidance from LLMs for decision-making in daily\nlife, many of these decisions are not clear-cut and depend significantly on the\npersonal values and ethical standards of people. We present DailyDilemmas, a\ndataset of 1,360 moral dilemmas encountered in everyday life. Each dilemma\npresents two possible actions, along with affected parties and relevant human\nvalues for each action. Based on these dilemmas, we gather a repository of\nhuman values covering diverse everyday topics, such as interpersonal\nrelationships, workplace, and environmental issues. With DailyDilemmas, we\nevaluate LLMs on these dilemmas to determine what action they will choose and\nthe values represented by these action choices. Then, we analyze values through\nthe lens of five theoretical frameworks inspired by sociology, psychology, and\nphilosophy, including the World Values Survey, Moral Foundations Theory,\nMaslow's Hierarchy of Needs, Aristotle's Virtues, and Plutchik's Wheel of\nEmotions. For instance, we find LLMs are most aligned with self-expression over\nsurvival in World Values Survey and care over loyalty in Moral Foundations\nTheory. Interestingly, we find substantial preference differences in models for\nsome core values. For example, for truthfulness, Mixtral-8x7B neglects it by\n9.7% while GPT-4-turbo selects it by 9.4%. We also study the recent guidance\nreleased by OpenAI (ModelSpec), and Anthropic (Constitutional AI) to understand\nhow their designated principles reflect their models' actual value\nprioritization when facing nuanced moral reasoning in daily-life settings.\nFinally, we find that end users cannot effectively steer such prioritization\nusing system prompts.\n","authors":["Yu Ying Chiu","Liwei Jiang","Yejin Choi"],"pdf_url":"https://arxiv.org/pdf/2410.02683v2.pdf","comment":"Accepted into ICLR 2025 (spotlight)"},{"id":"http://arxiv.org/abs/2501.02497v2","updated":"2025-03-03T07:16:16Z","published":"2025-01-05T10:24:20Z","title":"Test-Time Compute: from System-1 Thinking to System-2 Thinking","summary":"  The remarkable performance of the o1 model in complex reasoning demonstrates\nthat test-time compute scaling can further unlock the model's potential,\nenabling powerful System-2 thinking. However, there is still a lack of\ncomprehensive surveys for test-time compute scaling. We trace the concept of\ntest-time compute back to System-1 models. In System-1 models, test-time\ncompute addresses distribution shifts and improves robustness and\ngeneralization through parameter updating, input modification, representation\nediting, and output calibration. In System-2 models, it enhances the model's\nreasoning ability to solve complex problems through repeated sampling,\nself-correction, and tree search. We organize this survey according to the\ntrend of System-1 to System-2 thinking, highlighting the key role of test-time\ncompute in the transition from System-1 models to weak System-2 models, and\nthen to strong System-2 models. We also point out a few possible future\ndirections.\n","authors":["Yixin Ji","Juntao Li","Hai Ye","Kaixin Wu","Kai Yao","Jia Xu","Linjian Mo","Min Zhang"],"pdf_url":"https://arxiv.org/pdf/2501.02497v2.pdf","comment":"work in progress"},{"id":"http://arxiv.org/abs/2403.03636v3","updated":"2025-03-03T06:56:29Z","published":"2024-03-06T11:48:08Z","title":"SheetAgent: Towards A Generalist Agent for Spreadsheet Reasoning and\n  Manipulation via Large Language Models","summary":"  Spreadsheets are ubiquitous across the World Wide Web, playing a critical\nrole in enhancing work efficiency across various domains. Large language model\n(LLM) has been recently attempted for automatic spreadsheet manipulation but\nhas not yet been investigated in complicated and realistic tasks where\nreasoning challenges exist (e.g., long horizon manipulation with multi-step\nreasoning and ambiguous requirements). To bridge the gap with the real-world\nrequirements, we introduce SheetRM, a benchmark featuring long-horizon and\nmulti-category tasks with reasoning-dependent manipulation caused by real-life\nchallenges. To mitigate the above challenges, we further propose SheetAgent, a\nnovel autonomous agent that utilizes the power of LLMs. SheetAgent consists of\nthree collaborative modules: Planner, Informer, and Retriever, achieving both\nadvanced reasoning and accurate manipulation over spreadsheets without human\ninteraction through iterative task reasoning and reflection. Extensive\nexperiments demonstrate that SheetAgent delivers 20--40\\% pass rate\nimprovements on multiple benchmarks over baselines, achieving enhanced\nprecision in spreadsheet manipulation and demonstrating superior table\nreasoning abilities. More details and visualizations are available at the\nproject website: https://sheetagent.github.io/. The datasets and source code\nare available at https://anonymous.4open.science/r/SheetAgent.\n","authors":["Yibin Chen","Yifu Yuan","Zeyu Zhang","Yan Zheng","Jinyi Liu","Fei Ni","Jianye Hao","Hangyu Mao","Fuzheng Zhang"],"pdf_url":"https://arxiv.org/pdf/2403.03636v3.pdf","comment":"Accepted by International World Wide Web Conference (WWW) 2025 (oral)"},{"id":"http://arxiv.org/abs/2407.04752v2","updated":"2025-03-03T06:46:33Z","published":"2024-07-05T08:37:17Z","title":"SpikeLLM: Scaling up Spiking Neural Network to Large Language Models via\n  Saliency-based Spiking","summary":"  Recent advancements in large language models (LLMs) with billions of\nparameters have improved performance in various applications, but their\ninference processes demand significant energy and computational resources. In\ncontrast, the human brain, with approximately 86 billion neurons, is much more\nenergy-efficient than LLMs with similar parameters. Inspired by this, we\nredesign 7$\\sim$70 billion parameter LLMs using bio-plausible spiking\nmechanisms, emulating the efficient behavior of the human brain. We propose the\nfirst spiking large language model, SpikeLLM. Coupled with the proposed model,\ntwo essential approaches are proposed to improve spike training efficiency:\nGeneralized Integrate-and-Fire (GIF) neurons to compress spike length from $T$\nto $\\frac{T}{L} \\log_2 L$ bits, and an Optimal Brain Spiking framework to\ndivide outlier channels and allocate different $T$ for GIF neurons, which\nfurther compresses spike length to approximate $log_2T$ bits. The necessity of\nspike-driven LLM is proved by comparison with quantized LLMs with similar\noperations. In the OmniQuant pipeline, SpikeLLM reduces 11.01% WikiText2\nperplexity and improves 2.55% accuracy of common scene reasoning on a LLAMA-7B\nW4A4 model. In the GPTQ pipeline, SpikeLLM achieves direct additive in linear\nlayers, significantly exceeding PB-LLMs.\n","authors":["Xingrun Xing","Boyan Gao","Zheng Zhang","David A. Clifton","Shitao Xiao","Li Du","Guoqi Li","Jiajun Zhang"],"pdf_url":"https://arxiv.org/pdf/2407.04752v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2502.12949v2","updated":"2025-03-03T06:42:17Z","published":"2025-02-18T16:00:10Z","title":"Efficient Learning Under Density Shift in Incremental Settings Using\n  Cramr-Rao-Based Regularization","summary":"  The continuous surge in data volume and velocity is often dealt with using\ndata orchestration and distributed processing approaches, abstracting away the\nmachine learning challenges that exist at the algorithmic level. With growing\ninterest in automating the learning loop, training with data that arrive in a\nsequence rather than in the classical in-memory training data form will face a\nmachine learning challenge because of evolving feature distributions across\nbatches of training data biasing the cross-validation step\n(\\cite{sugiyama2012machine}). This work takes a distributed density estimation\nangle to the problem where data are temporally distributed. It processes data\nin batches and allows a neural network to treat a batch as training data. The\nmethod accumulates knowledge about the data density via posterior probability\nabsorption using the Fisher Information Matrix, which contains information\nabout the local optimization gradients for the batch. This is then used as a\nregularizer for the loss in the following batch, and therefore the density\nestimate for the entire dataset constructively gets more robust to the non-iid\ndistribution shift. This needs the presence of a pair of batches in memory at a\ntime, so the space cost is not a function of the size of the complete,\ndistributed dataset. We proposed a novel regularization-based approach\nCovariate Shift Correction $C^{2}A$ that leverages Fisher information and\nKullback-Leibler divergence to adapt to both natural and sequential covariate\nshift caused by dataset fragmentation. $C^{2}A$ achieves $19\\%$ accuracy at\nmaximum against state-of-the-art methods.\n","authors":["Behraj Khan","Behroz Mirza","Nouman Durrani","Tahir Syed"],"pdf_url":"https://arxiv.org/pdf/2502.12949v2.pdf","comment":"It is the older version of our this paper arXiv:2502.15756. So this\n  is the duplicate older version mistakenly uploaded. There are mistakes in the\n  method part of this paper"},{"id":"http://arxiv.org/abs/2412.15598v2","updated":"2025-03-03T06:39:17Z","published":"2024-12-20T06:42:58Z","title":"Long-Term EEG Partitioning for Seizure Onset Detection","summary":"  Deep learning models have recently shown great success in classifying\nepileptic patients using EEG recordings. Unfortunately, classification-based\nmethods lack a sound mechanism to detect the onset of seizure events. In this\nwork, we propose a two-stage framework, SODor, that explicitly models seizure\nonset through a novel task formulation of subsequence clustering. Given an EEG\nsequence, the framework first learns a set of second-level embeddings with\nlabel supervision. It then employs model-based clustering to explicitly capture\nlong-term temporal dependencies in EEG sequences and identify meaningful\nsubsequences. Epochs within a subsequence share a common cluster assignment\n(normal or seizure), with cluster or state transitions representing successful\nonset detections. Extensive experiments on three datasets demonstrate that our\nmethod can correct misclassifications, achieving 5\\%-11\\% classification\nimprovements over other baselines and accurately detecting seizure onsets.\n","authors":["Zheng Chen","Yasuko Matsubara","Yasushi Sakurai","Jimeng Sun"],"pdf_url":"https://arxiv.org/pdf/2412.15598v2.pdf","comment":"Accepted at AAAI 2025"},{"id":"http://arxiv.org/abs/2309.15531v3","updated":"2025-03-03T06:37:01Z","published":"2023-09-27T09:48:31Z","title":"Rethinking Channel Dimensions to Isolate Outliers for Low-bit Weight\n  Quantization of Large Language Models","summary":"  Large Language Models (LLMs) have recently demonstrated remarkable success\nacross various tasks. However, efficiently serving LLMs has been a challenge\ndue to the large memory bottleneck, specifically in small batch inference\nsettings (e.g. mobile devices). Weight-only quantization can be a promising\napproach, but sub-4 bit quantization remains a challenge due to large-magnitude\nactivation outliers. To mitigate the undesirable outlier effect, we first\npropose per-IC quantization, a simple yet effective method that creates\nquantization groups within each input channel (IC) rather than the conventional\nper-output-channel (per-OC). Our method is motivated by the observation that\nactivation outliers affect the input dimension of the weight matrix, so\nsimilarly grouping the weights in the IC direction can isolate outliers within\na group. We also find that activation outliers do not dictate quantization\ndifficulty, and inherent weight sensitivities also exist. With per-IC\nquantization as a new outlier-friendly scheme, we propose Adaptive Dimensions\n(AdaDim), a versatile quantization framework that can adapt to various weight\nsensitivity patterns. We demonstrate the effectiveness of AdaDim by augmenting\nprior methods such as Round-To-Nearest and GPTQ, showing significant\nimprovements across various language modeling benchmarks for both base (up to\n+4.7% on MMLU) and instruction-tuned (up to +10% on HumanEval) LLMs. Code is\navailable at https://github.com/johnheo/adadim-llm\n","authors":["Jung Hwan Heo","Jeonghoon Kim","Beomseok Kwon","Byeongwook Kim","Se Jung Kwon","Dongsoo Lee"],"pdf_url":"https://arxiv.org/pdf/2309.15531v3.pdf","comment":"ICLR 2024"},{"id":"http://arxiv.org/abs/2412.19160v2","updated":"2025-03-03T06:34:25Z","published":"2024-12-26T10:40:15Z","title":"Cross-Spectral Vision Transformer for Biometric Authentication using\n  Forehead Subcutaneous Vein Pattern and Periocular Pattern","summary":"  Traditional biometric systems have encountered significant setbacks due to\nvarious unavoidable factors, for example, face recognition-based biometrics\nfails due to the wearing of face masks and fingerprints create hygiene\nconcerns. This paper proposes a novel lightweight cross-spectral vision\ntransformer (CS-ViT) for biometric authentication using forehead subcutaneous\nvein patterns and periocular patterns, offering a promising alternative to\ntraditional methods, capable of performing well even with the face masks and\nwithout any physical touch. The proposed framework comprises a cross-spectral\ndual-channel architecture designed to handle two distinct biometric traits and\nto capture inter-dependencies in terms of relative spectral patterns. Each\nchannel consists of a Phase-Only Correlation Cross-Spectral Attention (POC-CSA)\nthat captures their individual as well as correlated patterns. The computation\nof cross-spectral attention using POC extracts the phase correlation in the\nspatial features. Therefore, it is robust against the resolution/intensity\nvariations and illumination of the input images, assuming both biometric traits\nare from the same person. The lightweight model is suitable for edge device\ndeployment. The performance of the proposed algorithm was rigorously evaluated\nusing the Forehead Subcutaneous Vein Pattern and Periocular Biometric Pattern\n(FSVP-PBP) database. The results demonstrated the superiority of the algorithm\nover state-of-the-art methods, achieving a remarkable classification accuracy\nof 98.8% with the combined vein and periocular patterns.\n","authors":["Arun K. Sharma","Shubhobrata Bhattacharya","Motahar Reza","Bishakh Bhattacharya"],"pdf_url":"https://arxiv.org/pdf/2412.19160v2.pdf","comment":"Submitted to IEEE TPAMI"},{"id":"http://arxiv.org/abs/2410.01746v2","updated":"2025-03-03T06:17:54Z","published":"2024-10-02T17:01:01Z","title":"Leray-Schauder Mappings for Operator Learning","summary":"  We present an algorithm for learning operators between Banach spaces, based\non the use of Leray-Schauder mappings to learn a finite-dimensional\napproximation of compact subspaces. We show that the resulting method is a\nuniversal approximator of (possibly nonlinear) operators. We demonstrate the\nefficiency of the approach on two benchmark datasets showing it achieves\nresults comparable to state of the art models.\n","authors":["Emanuele Zappala"],"pdf_url":"https://arxiv.org/pdf/2410.01746v2.pdf","comment":"13 pages, 2 figures, 1 table. Comments are welcome! v2: Theoretical\n  analysis expanded, several explanations regarding the experiments have been\n  added for improved clarity"},{"id":"http://arxiv.org/abs/2310.01405v4","updated":"2025-03-03T06:14:14Z","published":"2023-10-02T17:59:07Z","title":"Representation Engineering: A Top-Down Approach to AI Transparency","summary":"  In this paper, we identify and characterize the emerging area of\nrepresentation engineering (RepE), an approach to enhancing the transparency of\nAI systems that draws on insights from cognitive neuroscience. RepE places\npopulation-level representations, rather than neurons or circuits, at the\ncenter of analysis, equipping us with novel methods for monitoring and\nmanipulating high-level cognitive phenomena in deep neural networks (DNNs). We\nprovide baselines and an initial analysis of RepE techniques, showing that they\noffer simple yet effective solutions for improving our understanding and\ncontrol of large language models. We showcase how these methods can provide\ntraction on a wide range of safety-relevant problems, including honesty,\nharmlessness, power-seeking, and more, demonstrating the promise of top-down\ntransparency research. We hope that this work catalyzes further exploration of\nRepE and fosters advancements in the transparency and safety of AI systems.\n","authors":["Andy Zou","Long Phan","Sarah Chen","James Campbell","Phillip Guo","Richard Ren","Alexander Pan","Xuwang Yin","Mantas Mazeika","Ann-Kathrin Dombrowski","Shashwat Goel","Nathaniel Li","Michael J. Byun","Zifan Wang","Alex Mallen","Steven Basart","Sanmi Koyejo","Dawn Song","Matt Fredrikson","J. Zico Kolter","Dan Hendrycks"],"pdf_url":"https://arxiv.org/pdf/2310.01405v4.pdf","comment":"Code is available at\n  https://github.com/andyzoujm/representation-engineering"},{"id":"http://arxiv.org/abs/2411.02886v2","updated":"2025-03-03T05:49:41Z","published":"2024-11-05T07:56:24Z","title":"TokenSelect: Efficient Long-Context Inference and Length Extrapolation\n  for LLMs via Dynamic Token-Level KV Cache Selection","summary":"  The rapid advancement of Large Language Models (LLMs) has driven growing\ndemand for processing extended context sequences in contemporary applications.\nHowever, this progress faces two major challenges: performance degradation due\nto sequence lengths out-of-distribution, and excessively long inference times\ncaused by the quadratic computational complexity of attention. These issues\nhinder the application of LLMs in long-context scenarios. In this paper, we\npropose Dynamic Token-Level KV Cache Selection (TokenSelect), a training-free\nmethod for efficient and accurate long-context inference. TokenSelect builds\nupon the observation of non-contiguous attention sparsity, using Query-Key dot\nproducts to measure per-head KV Cache criticality at token-level. By per-head\nsoft voting mechanism, TokenSelect selectively involves a few critical KV cache\ntokens in attention calculation without sacrificing accuracy. To further\naccelerate TokenSelect, we design the Selection Cache based on observations of\nconsecutive Query similarity and implemented efficient dot product kernel,\nsignificantly reducing the overhead. A comprehensive evaluation of TokenSelect\ndemonstrates up to 23.84x speedup in attention computation and up to 2.28x\nacceleration in end-to-end latency, while providing superior performance\ncompared to state-of-the-art long-context inference methods.\n","authors":["Wei Wu","Zhuoshi Pan","Chao Wang","Liyi Chen","Yunchu Bai","Tianfu Wang","Kun Fu","Zheng Wang","Hui Xiong"],"pdf_url":"https://arxiv.org/pdf/2411.02886v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2407.04495v4","updated":"2025-03-03T05:38:10Z","published":"2024-07-05T13:35:14Z","title":"Speed-accuracy relations for the diffusion models: Wisdom from\n  nonequilibrium thermodynamics and optimal transport","summary":"  We discuss a connection between a generative model, called the diffusion\nmodel, and nonequilibrium thermodynamics for the Fokker-Planck equation, called\nstochastic thermodynamics. Based on the techniques of stochastic\nthermodynamics, we derive the speed-accuracy relations for the diffusion\nmodels, which are inequalities that relate the accuracy of data generation to\nthe entropy production rate, which can be interpreted as the speed of the\ndiffusion dynamics in the absence of the non-conservative force. From a\nstochastic thermodynamic perspective, our results provide a quantitative\ninsight into how best to generate data in diffusion models. The optimal\nlearning protocol is introduced by the geodesic of space of the 2-Wasserstein\ndistance in optimal transport theory. We numerically illustrate the validity of\nthe speed-accuracy relations for the diffusion models with different noise\nschedules and the different data. We numerically discuss our results for the\noptimal and suboptimal learning protocols. We also show the inaccurate data\ngeneration due to the non-conservative force, and the applicability of our\nresults to data generation from the real-world image datasets.\n","authors":["Kotaro Ikeda","Tomoya Uda","Daisuke Okanohara","Sosuke Ito"],"pdf_url":"https://arxiv.org/pdf/2407.04495v4.pdf","comment":"36 pages, 7 figures"},{"id":"http://arxiv.org/abs/2410.02268v3","updated":"2025-03-03T05:32:47Z","published":"2024-10-03T07:40:14Z","title":"Structural-Entropy-Based Sample Selection for Efficient and Effective\n  Learning","summary":"  Sample selection improves the efficiency and effectiveness of machine\nlearning models by providing informative and representative samples. Typically,\nsamples can be modeled as a sample graph, where nodes are samples and edges\nrepresent their similarities. Most existing methods are based on local\ninformation, such as the training difficulty of samples, thereby overlooking\nglobal information, such as connectivity patterns. This oversight can result in\nsuboptimal selection because global information is crucial for ensuring that\nthe selected samples well represent the structural properties of the graph. To\naddress this issue, we employ structural entropy to quantify global information\nand losslessly decompose it from the whole graph to individual nodes using the\nShapley value. Based on the decomposition, we present\n$\\textbf{S}$tructural-$\\textbf{E}$ntropy-based sample $\\textbf{S}$election\n($\\textbf{SES}$), a method that integrates both global and local information to\nselect informative and representative samples. SES begins by constructing a\n$k$NN-graph among samples based on their similarities. It then measures sample\nimportance by combining structural entropy (global metric) with training\ndifficulty (local metric). Finally, SES applies importance-biased blue noise\nsampling to select a set of diverse and representative samples. Comprehensive\nexperiments on three learning scenarios -- supervised learning, active\nlearning, and continual learning -- clearly demonstrate the effectiveness of\nour method.\n","authors":["Tianchi Xie","Jiangning Zhu","Guozu Ma","Minzhi Lin","Wei Chen","Weikai Yang","Shixia Liu"],"pdf_url":"https://arxiv.org/pdf/2410.02268v3.pdf","comment":"Published as a conference paper at ICLR 2025"},{"id":"http://arxiv.org/abs/2502.01912v2","updated":"2025-03-03T05:25:43Z","published":"2025-02-04T01:05:12Z","title":"PATCH: a deep learning method to assess heterogeneity of artistic\n  practice in historical paintings","summary":"  The history of art has seen significant shifts in the manner in which\nartworks are created, making understanding of creative processes a central\nquestion in technical art history. In the Renaissance and Early Modern period,\npaintings were largely produced by master painters directing workshops of\napprentices who often contributed to projects. The masters varied significantly\nin artistic and managerial styles, meaning different combinations of artists\nand implements might be seen both between masters and within workshops or even\nindividual canvases. Information on how different workshops were managed and\nthe processes by which artworks were created remains elusive. Machine learning\nmethods have potential to unearth new information about artists' creative\nprocesses by extending the analysis of brushwork to a microscopic scale.\nAnalysis of workshop paintings, however, presents a challenge in that\ndocumentation of the artists and materials involved is sparse, meaning external\nexamples are not available to train networks to recognize their contributions.\nHere we present a novel machine learning approach we call pairwise assignment\ntraining for classifying heterogeneity (PATCH) that is capable of identifying\nindividual artistic practice regimes with no external training data, or \"ground\ntruth.\" The method achieves unsupervised results by supervised means, and\noutperforms both simple statistical procedures and unsupervised machine\nlearning methods. We apply this method to two historical paintings by the\nSpanish Renaissance master, El Greco: The Baptism of Christ and Christ on the\nCross with Landscape, and our findings regarding the former potentially\nchallenge previous work that has assigned the painting to workshop members.\nFurther, the results of our analyses create a measure of heterogeneity of\nartistic practice that can be used to characterize artworks across time and\nspace.\n","authors":["Andrew Van Horn","Lauryn Smith","Mahamad Mahmoud","Michael McMaster","Clara Pinchbeck","Ina Martin","Andrew Lininger","Anthony Ingrisano","Adam Lowe","Carlos Bayod","Elizabeth Bolman","Kenneth Singer","Michael Hinczewski"],"pdf_url":"https://arxiv.org/pdf/2502.01912v2.pdf","comment":"main text: 16 pages, 6 figures; SI: 7 pages, 3 figures; v2: minor\n  typo corrections, higher resolution figures"},{"id":"http://arxiv.org/abs/2405.13937v8","updated":"2025-03-03T05:10:46Z","published":"2024-05-22T19:10:24Z","title":"Node-Time Conditional Prompt Learning In Dynamic Graphs","summary":"  Dynamic graphs capture evolving interactions between entities, such as in\nsocial networks, online learning platforms, and crowdsourcing projects. For\ndynamic graph modeling, dynamic graph neural networks (DGNNs) have emerged as a\nmainstream technique. However, they are generally pre-trained on the link\nprediction task, leaving a significant gap from the objectives of downstream\ntasks such as node classification. To bridge the gap, prompt-based learning has\ngained traction on graphs, but most existing efforts focus on static graphs,\nneglecting the evolution of dynamic graphs. In this paper, we propose\nDYGPROMPT, a novel pre-training and prompt learning framework for dynamic graph\nmodeling. First, we design dual prompts to address the gap in both task\nobjectives and temporal variations across pre-training and downstream tasks.\nSecond, we recognize that node and time features mutually characterize each\nother, and propose dual condition-nets to model the evolving node-time patterns\nin downstream tasks. Finally, we thoroughly evaluate and analyze DYGPROMPT\nthrough extensive experiments on four public datasets.\n","authors":["Xingtong Yu","Zhenghao Liu","Xinming Zhang","Yuan Fang"],"pdf_url":"https://arxiv.org/pdf/2405.13937v8.pdf","comment":"Accepted by ICLR 2025"},{"id":"http://arxiv.org/abs/2409.07002v2","updated":"2025-03-03T04:32:29Z","published":"2024-09-11T04:30:45Z","title":"AdvLogo: Adversarial Patch Attack against Object Detectors based on\n  Diffusion Models","summary":"  With the rapid development of deep learning, object detectors have\ndemonstrated impressive performance; however, vulnerabilities still exist in\ncertain scenarios. Current research exploring the vulnerabilities using\nadversarial patches often struggles to balance the trade-off between attack\neffectiveness and visual quality. To address this problem, we propose a novel\nframework of patch attack from semantic perspective, which we refer to as\nAdvLogo. Based on the hypothesis that every semantic space contains an\nadversarial subspace where images can cause detectors to fail in recognizing\nobjects, we leverage the semantic understanding of the diffusion denoising\nprocess and drive the process to adversarial subareas by perturbing the latent\nand unconditional embeddings at the last timestep. To mitigate the distribution\nshift that exposes a negative impact on image quality, we apply perturbation to\nthe latent in frequency domain with the Fourier Transform. Experimental results\ndemonstrate that AdvLogo achieves strong attack performance while maintaining\nhigh visual quality.\n","authors":["Boming Miao","Chunxiao Li","Yao Zhu","Weixiang Sun","Zizhe Wang","Xiaoyi Wang","Chuanlong Xie"],"pdf_url":"https://arxiv.org/pdf/2409.07002v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2402.09906v3","updated":"2025-03-03T04:28:49Z","published":"2024-02-15T12:12:19Z","title":"Generative Representational Instruction Tuning","summary":"  All text-based language problems can be reduced to either generation or\nembedding. Current models only perform well at one or the other. We introduce\ngenerative representational instruction tuning (GRIT) whereby a large language\nmodel is trained to handle both generative and embedding tasks by\ndistinguishing between them through instructions. Compared to other open\nmodels, our resulting GritLM 7B sets a new state of the art on the Massive Text\nEmbedding Benchmark (MTEB) and outperforms all models up to its size on a range\nof generative tasks. By scaling up further, GritLM 8x7B outperforms all open\ngenerative language models that we tried while still being among the best\nembedding models. Notably, we find that GRIT matches training on only\ngenerative or embedding data, thus we can unify both at no performance loss.\nAmong other benefits, the unification via GRIT speeds up Retrieval-Augmented\nGeneration (RAG) by > 60% for long documents, by no longer requiring separate\nretrieval and generation models. Models, code, etc. are freely available at\nhttps://github.com/ContextualAI/gritlm.\n","authors":["Niklas Muennighoff","Hongjin Su","Liang Wang","Nan Yang","Furu Wei","Tao Yu","Amanpreet Singh","Douwe Kiela"],"pdf_url":"https://arxiv.org/pdf/2402.09906v3.pdf","comment":"67 pages (16 main), 25 figures, 34 tables"},{"id":"http://arxiv.org/abs/2403.17010v3","updated":"2025-03-03T04:22:19Z","published":"2024-03-25T17:59:59Z","title":"Calib3D: Calibrating Model Preferences for Reliable 3D Scene\n  Understanding","summary":"  Safety-critical 3D scene understanding tasks necessitate not only accurate\nbut also confident predictions from 3D perception models. This study introduces\nCalib3D, a pioneering effort to benchmark and scrutinize the reliability of 3D\nscene understanding models from an uncertainty estimation viewpoint. We\ncomprehensively evaluate 28 state-of-the-art models across 10 diverse 3D\ndatasets, uncovering insightful phenomena that cope with both the aleatoric and\nepistemic uncertainties in 3D scene understanding. We discover that despite\nachieving impressive levels of accuracy, existing models frequently fail to\nprovide reliable uncertainty estimates -- a pitfall that critically undermines\ntheir applicability in safety-sensitive contexts. Through extensive analysis of\nkey factors such as network capacity, LiDAR representations, rasterization\nresolutions, and 3D data augmentation techniques, we correlate these aspects\ndirectly with the model calibration efficacy. Furthermore, we introduce DeptS,\na novel depth-aware scaling approach aimed at enhancing 3D model calibration.\nExtensive experiments across a wide range of configurations validate the\nsuperiority of our method. We hope this work could serve as a cornerstone for\nfostering reliable 3D scene understanding. Code and benchmark toolkit are\npublicly available.\n","authors":["Lingdong Kong","Xiang Xu","Jun Cen","Wenwei Zhang","Liang Pan","Kai Chen","Ziwei Liu"],"pdf_url":"https://arxiv.org/pdf/2403.17010v3.pdf","comment":"WACV 2025 Oral; 26 pages, 8 figures, 12 tables; Code at\n  https://github.com/ldkong1205/Calib3D"},{"id":"http://arxiv.org/abs/2410.08892v2","updated":"2025-03-03T04:14:17Z","published":"2024-10-11T15:10:38Z","title":"Federated Learning in Practice: Reflections and Projections","summary":"  Federated Learning (FL) is a machine learning technique that enables multiple\nentities to collaboratively learn a shared model without exchanging their local\ndata. Over the past decade, FL systems have achieved substantial progress,\nscaling to millions of devices across various learning domains while offering\nmeaningful differential privacy (DP) guarantees. Production systems from\norganizations like Google, Apple, and Meta demonstrate the real-world\napplicability of FL. However, key challenges remain, including verifying\nserver-side DP guarantees and coordinating training across heterogeneous\ndevices, limiting broader adoption. Additionally, emerging trends such as large\n(multi-modal) models and blurred lines between training, inference, and\npersonalization challenge traditional FL frameworks. In response, we propose a\nredefined FL framework that prioritizes privacy principles rather than rigid\ndefinitions. We also chart a path forward by leveraging trusted execution\nenvironments and open-source ecosystems to address these challenges and\nfacilitate future advancements in FL.\n","authors":["Katharine Daly","Hubert Eichner","Peter Kairouz","H. Brendan McMahan","Daniel Ramage","Zheng Xu"],"pdf_url":"https://arxiv.org/pdf/2410.08892v2.pdf","comment":"Published at 2024 IEEE 6th International Conference on Trust, Privacy\n  and Security in Intelligent Systems, and Applications (TPS-ISA)"},{"id":"http://arxiv.org/abs/2411.02728v2","updated":"2025-03-03T04:04:30Z","published":"2024-11-05T01:55:07Z","title":"Compositional simulation-based inference for time series","summary":"  Amortized simulation-based inference (SBI) methods train neural networks on\nsimulated data to perform Bayesian inference. While this strategy avoids the\nneed for tractable likelihoods, it often requires a large number of simulations\nand has been challenging to scale to time series data. Scientific simulators\nfrequently emulate real-world dynamics through thousands of single-state\ntransitions over time. We propose an SBI approach that can exploit such\nMarkovian simulators by locally identifying parameters consistent with\nindividual state transitions. We then compose these local results to obtain a\nposterior over parameters that align with the entire time series observation.\nWe focus on applying this approach to neural posterior score estimation but\nalso show how it can be applied, e.g., to neural likelihood (ratio) estimation.\nWe demonstrate that our approach is more simulation-efficient than directly\nestimating the global posterior on several synthetic benchmark tasks and\nsimulators used in ecology and epidemiology. Finally, we validate scalability\nand simulation efficiency of our approach by applying it to a high-dimensional\nKolmogorov flow simulator with around one million data dimensions.\n","authors":["Manuel Gloeckler","Shoji Toyota","Kenji Fukumizu","Jakob H. Macke"],"pdf_url":"https://arxiv.org/pdf/2411.02728v2.pdf","comment":"To be published in the proceedings of the Thirteenth International\n  Conference on Learning Representations (ICLR 2025), Singapore, 2025"},{"id":"http://arxiv.org/abs/2502.02954v2","updated":"2025-03-03T03:56:38Z","published":"2025-02-05T07:35:15Z","title":"Direct Distributional Optimization for Provable Alignment of Diffusion\n  Models","summary":"  We introduce a novel alignment method for diffusion models from distribution\noptimization perspectives while providing rigorous convergence guarantees. We\nfirst formulate the problem as a generic regularized loss minimization over\nprobability distributions and directly optimize the distribution using the Dual\nAveraging method. Next, we enable sampling from the learned distribution by\napproximating its score function via Doob's $h$-transform technique. The\nproposed framework is supported by rigorous convergence guarantees and an\nend-to-end bound on the sampling error, which imply that when the original\ndistribution's score is known accurately, the complexity of sampling from\nshifted distributions is independent of isoperimetric conditions. This\nframework is broadly applicable to general distribution optimization problems,\nincluding alignment tasks in Reinforcement Learning with Human Feedback (RLHF),\nDirect Preference Optimization (DPO), and Kahneman-Tversky Optimization (KTO).\nWe empirically validate its performance on synthetic and image datasets using\nthe DPO objective.\n","authors":["Ryotaro Kawata","Kazusato Oko","Atsushi Nitanda","Taiji Suzuki"],"pdf_url":"https://arxiv.org/pdf/2502.02954v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2407.00617v4","updated":"2025-03-03T03:41:11Z","published":"2024-06-30T08:00:34Z","title":"Iterative Nash Policy Optimization: Aligning LLMs with General\n  Preferences via No-Regret Learning","summary":"  Reinforcement Learning with Human Feedback (RLHF) has achieved great success\nin aligning large language models (LLMs) with human preferences. Prevalent RLHF\napproaches are reward-based, following the Bradley-Terry (BT) model assumption,\nwhich may not fully capture the complexity of human preferences. In this paper,\nwe explore RLHF under a general preference framework and approach it from a\ngame-theoretic perspective. Specifically, we formulate the problem as a\ntwo-player game and propose a novel online algorithm, iterative Nash policy\noptimization (INPO). The key idea is to let the policy play against itself via\nno-regret learning, thereby approximating the Nash policy. Unlike previous\nmethods, INPO bypasses the need for estimating the expected win rate for\nindividual responses, which typically incurs high computational or annotation\ncosts. Instead, we introduce a new loss objective that is directly minimized\nover a preference dataset. We provide theoretical analysis for our approach and\ndemonstrate its effectiveness through experiments on various representative\nbenchmarks. With an LLaMA-3-8B-based SFT model, INPO achieves a 42.6%\nlength-controlled win rate on AlpacaEval 2.0 and a 37.8% win rate on\nArena-Hard, showing substantial improvement over the state-of-the-art online\nRLHF algorithms.\n","authors":["Yuheng Zhang","Dian Yu","Baolin Peng","Linfeng Song","Ye Tian","Mingyue Huo","Nan Jiang","Haitao Mi","Dong Yu"],"pdf_url":"https://arxiv.org/pdf/2407.00617v4.pdf","comment":null},{"id":"http://arxiv.org/abs/2407.04405v3","updated":"2025-03-03T03:39:50Z","published":"2024-07-05T10:41:15Z","title":"Discovering physical laws with parallel combinatorial tree search","summary":"  Symbolic regression plays a crucial role in modern scientific research thanks\nto its capability of discovering concise and interpretable mathematical\nexpressions from data. A grand challenge lies in the arduous search for\nparsimonious and generalizable mathematical formulas, in an infinite search\nspace, while intending to fit the training data. Existing algorithms have faced\na critical bottleneck of accuracy and efficiency over a decade when handling\nproblems of complexity, which essentially hinders the pace of applying symbolic\nregression for scientific exploration across interdisciplinary domains. To this\nend, we introduce a parallel combinatorial tree search (PCTS) model to\nefficiently distill generic mathematical expressions from limited data. Through\na series of extensive experiments, we demonstrate the superior accuracy and\nefficiency of PCTS for equation discovery, which greatly outperforms the\nstate-of-the-art baseline models on over 200 synthetic and experimental\ndatasets (e.g., lifting its performance by up to 99% accuracy improvement and\none-order of magnitude speed up). PCTS represents a key advance in accurate and\nefficient data-driven discovery of symbolic, interpretable models (e.g.,\nunderlying physical laws) and marks a pivotal transition towards scalable\nsymbolic learning.\n","authors":["Kai Ruan","Yilong Xu","Ze-Feng Gao","Yike Guo","Hao Sun","Ji-Rong Wen","Yang Liu"],"pdf_url":"https://arxiv.org/pdf/2407.04405v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2502.01117v2","updated":"2025-03-03T03:35:00Z","published":"2025-02-03T07:13:59Z","title":"Learning to Learn Weight Generation via Trajectory Diffusion","summary":"  Diffusion-based algorithms have emerged as promising techniques for weight\ngeneration, particularly in scenarios like multi-task learning that require\nfrequent weight updates. However, existing solutions suffer from limited\ncross-task transferability. In addition, they only utilize optimal weights as\ntraining samples, ignoring the value of other weights in the optimization\nprocess. To address these issues, we propose Lt-Di, which integrates the\ndiffusion algorithm with meta-learning to generate weights for unseen tasks.\nFurthermore, we extend the vanilla diffusion algorithm into a trajectory\ndiffusion algorithm to utilize other weights along the optimization trajectory.\nTrajectory diffusion decomposes the entire diffusion chain into multiple\nshorter ones, improving training and inference efficiency. We analyze the\nconvergence properties of the weight generation paradigm and improve\nconvergence efficiency without additional time overhead. Our experiments\ndemonstrate Lt-Di's higher accuracy while reducing computational overhead\nacross various tasks, including zero-shot and few-shot learning, multi-domain\ngeneralization, and large-scale language model fine-tuning.Our code is released\nat https://anonymous.4open.science/r/Lt-Di-0E51.\n","authors":["Yunchuan Guan","Yu Liu","Ke Zhou","Zhiqi Shen","Serge Belongie","Jenq-Neng Hwang","Lei Li"],"pdf_url":"https://arxiv.org/pdf/2502.01117v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2407.17674v2","updated":"2025-03-03T03:24:09Z","published":"2024-07-24T23:47:05Z","title":"Struc2mapGAN: improving synthetic cryo-EM density maps with generative\n  adversarial networks","summary":"  Generating synthetic cryogenic electron microscopy 3D density maps from\nmolecular structures has potential important applications in structural\nbiology. Yet existing simulation-based methods cannot mimic all the complex\nfeatures present in experimental maps, such as secondary structure elements. As\nan alternative, we propose struc2mapGAN, a novel data-driven method that\nemploys a generative adversarial network to produce improved experimental-like\ndensity maps from molecular structures. More specifically, struc2mapGAN uses a\nnested U-Net architecture as the generator, with an additional L1 loss term and\nfurther processing of raw training experimental maps to enhance learning\nefficiency. While struc2mapGAN can promptly generate maps after training, we\ndemonstrate that it outperforms existing simulation-based methods for a wide\narray of tested maps and across various evaluation metrics.\n","authors":["Chenwei Zhang","Anne Condon","Khanh Dao Duc"],"pdf_url":"https://arxiv.org/pdf/2407.17674v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.13213v2","updated":"2025-03-03T03:20:08Z","published":"2024-10-17T04:37:37Z","title":"LLMOPT: Learning to Define and Solve General Optimization Problems from\n  Scratch","summary":"  Optimization problems are prevalent across various scenarios. Formulating and\nthen solving optimization problems described by natural language often requires\nhighly specialized human expertise, which could block the widespread\napplication of optimization-based decision making. To automate problem\nformulation and solving, leveraging large language models (LLMs) has emerged as\na potential way. However, this kind of approach suffers from the issue of\noptimization generalization. Namely, the accuracy of most current LLM-based\nmethods and the generality of optimization problem types that they can model\nare still limited. In this paper, we propose a unified learning-based framework\ncalled LLMOPT to boost optimization generalization. Starting from the natural\nlanguage descriptions of optimization problems and a pre-trained LLM, LLMOPT\nconstructs the introduced five-element formulation as a universal model for\nlearning to define diverse optimization problem types. Then, LLMOPT employs the\nmulti-instruction tuning to enhance both problem formalization and solver code\ngeneration accuracy and generality. After that, to prevent hallucinations in\nLLMs, such as sacrificing solving accuracy to avoid execution errors, the model\nalignment and self-correction mechanism are adopted in LLMOPT. We evaluate the\noptimization generalization ability of LLMOPT and compared methods across six\nreal-world datasets covering roughly 20 fields such as health, environment,\nenergy and manufacturing, etc. Extensive experiment results show that LLMOPT is\nable to model various optimization problem types such as linear/nonlinear\nprogramming, mixed integer programming, and combinatorial optimization, and\nachieves a notable 11.08% average solving accuracy improvement compared with\nthe state-of-the-art methods. The code is available at\nhttps://github.com/caigaojiang/LLMOPT.\n","authors":["Caigao Jiang","Xiang Shu","Hong Qian","Xingyu Lu","Jun Zhou","Aimin Zhou","Yang Yu"],"pdf_url":"https://arxiv.org/pdf/2410.13213v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.00645v2","updated":"2025-03-03T03:19:08Z","published":"2024-10-01T12:58:37Z","title":"TSVD: Bridging Theory and Practice in Continual Learning with\n  Pre-trained Models","summary":"  The goal of continual learning (CL) is to train a model that can solve\nmultiple tasks presented sequentially. Recent CL approaches have achieved\nstrong performance by leveraging large pre-trained models that generalize well\nto downstream tasks. However, such methods lack theoretical guarantees, making\nthem prone to unexpected failures. Conversely, principled CL approaches often\nfail to achieve competitive performance. In this work, we aim to bridge this\ngap between theory and practice by designing a simple CL method that is\ntheoretically sound and highly performant. Specifically, we lift pre-trained\nfeatures into a higher dimensional space and formulate an over-parametrized\nminimum-norm least-squares problem. We find that the lifted features are highly\nill-conditioned, potentially leading to large training errors (numerical\ninstability) and increased generalization errors. We address these challenges\nby continually truncating the singular value decomposition (SVD) of the lifted\nfeatures. Our approach, termed TSVD, is stable with respect to the choice of\nhyperparameters, can handle hundreds of tasks, and outperforms state-of-the-art\nCL methods on multiple datasets. Importantly, our method satisfies a recurrence\nrelation throughout its continual learning process, which allows us to prove it\nmaintains small training and generalization errors by appropriately truncating\na fraction of SVD factors. This results in a stable continual learning method\nwith strong empirical performance and theoretical guarantees. Code available:\nhttps://github.com/liangzu/tsvd.\n","authors":["Liangzu Peng","Juan Elenter","Joshua Agterberg","Alejandro Ribeiro","Ren Vidal"],"pdf_url":"https://arxiv.org/pdf/2410.00645v2.pdf","comment":"47 pages, 18 figures, 16 tables (v2, accepted to ICLR 2025)"},{"id":"http://arxiv.org/abs/2410.13085v2","updated":"2025-03-03T03:08:28Z","published":"2024-10-16T23:03:27Z","title":"MMed-RAG: Versatile Multimodal RAG System for Medical Vision Language\n  Models","summary":"  Artificial Intelligence (AI) has demonstrated significant potential in\nhealthcare, particularly in disease diagnosis and treatment planning. Recent\nprogress in Medical Large Vision-Language Models (Med-LVLMs) has opened up new\npossibilities for interactive diagnostic tools. However, these models often\nsuffer from factual hallucination, which can lead to incorrect diagnoses.\nFine-tuning and retrieval-augmented generation (RAG) have emerged as methods to\naddress these issues. However, the amount of high-quality data and distribution\nshifts between training data and deployment data limit the application of\nfine-tuning methods. Although RAG is lightweight and effective, existing\nRAG-based approaches are not sufficiently general to different medical domains\nand can potentially cause misalignment issues, both between modalities and\nbetween the model and the ground truth. In this paper, we propose a versatile\nmultimodal RAG system, MMed-RAG, designed to enhance the factuality of\nMed-LVLMs. Our approach introduces a domain-aware retrieval mechanism, an\nadaptive retrieved contexts selection method, and a provable RAG-based\npreference fine-tuning strategy. These innovations make the RAG process\nsufficiently general and reliable, significantly improving alignment when\nintroducing retrieved contexts. Experimental results across five medical\ndatasets (involving radiology, ophthalmology, pathology) on medical VQA and\nreport generation demonstrate that MMed-RAG can achieve an average improvement\nof 43.8% in the factual accuracy of Med-LVLMs. Our data and code are available\nin https://github.com/richard-peng-xia/MMed-RAG.\n","authors":["Peng Xia","Kangyu Zhu","Haoran Li","Tianze Wang","Weijia Shi","Sheng Wang","Linjun Zhang","James Zou","Huaxiu Yao"],"pdf_url":"https://arxiv.org/pdf/2410.13085v2.pdf","comment":"ICLR 2025"},{"id":"http://arxiv.org/abs/2406.06600v3","updated":"2025-03-03T03:05:30Z","published":"2024-06-06T13:44:57Z","title":"HORAE: A Domain-Agnostic Modeling Language for Automating Multimodal\n  Service Regulation","summary":"  Artificial intelligence is rapidly encroaching on the field of service\nregulation. This work-in-progress article presents the design principles behind\nHORAE, a unified specification language to model multimodal regulation rules\nacross a diverse set of domains. We show how HORAE facilitates an intelligent\nservice regulation pipeline by further exploiting a fine-tuned large language\nmodel named HORAE that automates the HORAE modeling process, thereby yielding\nan end-to-end framework for fully automated intelligent service regulation.\n","authors":["Yutao Sun","Mingshuai Chen","Kangjia Zhao","Jintao Chen"],"pdf_url":"https://arxiv.org/pdf/2406.06600v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.00564v3","updated":"2025-03-03T02:59:29Z","published":"2024-10-01T10:25:03Z","title":"Scaling Offline Model-Based RL via Jointly-Optimized World-Action Model\n  Pretraining","summary":"  A significant aspiration of offline reinforcement learning (RL) is to develop\na generalist agent with high capabilities from large and heterogeneous\ndatasets. However, prior approaches that scale offline RL either rely heavily\non expert trajectories or struggle to generalize to diverse unseen tasks.\nInspired by the excellent generalization of world model in conditional video\ngeneration, we explore the potential of image observation-based world model for\nscaling offline RL and enhancing generalization on novel tasks. In this paper,\nwe introduce JOWA: Jointly-Optimized World-Action model, an offline model-based\nRL agent pretrained on multiple Atari games with 6 billion tokens data to learn\ngeneral-purpose representation and decision-making ability. Our method jointly\noptimizes a world-action model through a shared transformer backbone, which\nstabilize temporal difference learning with large models during pretraining.\nMoreover, we propose a provably efficient and parallelizable planning algorithm\nto compensate for the Q-value estimation error and thus search out better\npolicies. Experimental results indicate that our largest agent, with 150\nmillion parameters, achieves 78.9% human-level performance on pretrained games\nusing only 10% subsampled offline data, outperforming existing state-of-the-art\nlarge-scale offline RL baselines by 31.6% on averange. Furthermore, JOWA scales\nfavorably with model capacity and can sample-efficiently transfer to novel\ngames using only 5k offline fine-tuning data (approximately 4 trajectories) per\ngame, demonstrating superior generalization. We will release codes and model\nweights at https://github.com/CJReinforce/JOWA\n","authors":["Jie Cheng","Ruixi Qiao","Yingwei Ma","Binhua Li","Gang Xiong","Qinghai Miao","Yongbin Li","Yisheng Lv"],"pdf_url":"https://arxiv.org/pdf/2410.00564v3.pdf","comment":"Accepted by ICLR 2025"},{"id":"http://arxiv.org/abs/2410.01337v3","updated":"2025-03-03T02:50:30Z","published":"2024-10-02T08:54:18Z","title":"PhyMPGN: Physics-encoded Message Passing Graph Network for\n  spatiotemporal PDE systems","summary":"  Solving partial differential equations (PDEs) serves as a cornerstone for\nmodeling complex dynamical systems. Recent progresses have demonstrated grand\nbenefits of data-driven neural-based models for predicting spatiotemporal\ndynamics (e.g., tremendous speedup gain compared with classical numerical\nmethods). However, most existing neural models rely on rich training data, have\nlimited extrapolation and generalization abilities, and suffer to produce\nprecise or reliable physical prediction under intricate conditions (e.g.,\nirregular mesh or geometry, complex boundary conditions, diverse PDE\nparameters, etc.). To this end, we propose a new graph learning approach,\nnamely, Physics-encoded Message Passing Graph Network (PhyMPGN), to model\nspatiotemporal PDE systems on irregular meshes given small training datasets.\nSpecifically, we incorporate a GNN into a numerical integrator to approximate\nthe temporal marching of spatiotemporal dynamics for a given PDE system.\nConsidering that many physical phenomena are governed by diffusion processes,\nwe further design a learnable Laplace block, which encodes the discrete\nLaplace-Beltrami operator, to aid and guide the GNN learning in a physically\nfeasible solution space. A boundary condition padding strategy is also designed\nto improve the model convergence and accuracy. Extensive experiments\ndemonstrate that PhyMPGN is capable of accurately predicting various types of\nspatiotemporal dynamics on coarse unstructured meshes, consistently achieves\nthe state-of-the-art results, and outperforms other baselines with considerable\ngains.\n","authors":["Bocheng Zeng","Qi Wang","Mengtao Yan","Yang Liu","Ruizhi Chengze","Yi Zhang","Hongsheng Liu","Zidong Wang","Hao Sun"],"pdf_url":"https://arxiv.org/pdf/2410.01337v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.08109v3","updated":"2025-03-03T02:45:58Z","published":"2024-10-10T16:56:05Z","title":"A Closer Look at Machine Unlearning for Large Language Models","summary":"  Large language models (LLMs) may memorize sensitive or copyrighted content,\nraising privacy and legal concerns. Due to the high cost of retraining from\nscratch, researchers attempt to employ machine unlearning to remove specific\ncontent from LLMs while preserving the overall performance. In this paper, we\ndiscuss several issues in machine unlearning for LLMs and provide our insights\non possible approaches. To address the issue of inadequate evaluation of model\noutputs after unlearning, we introduce three additional metrics to evaluate\ntoken diversity, sentence semantics, and factual correctness. We then\ncategorize unlearning methods into untargeted and targeted, and discuss their\nissues respectively. Specifically, the behavior that untargeted unlearning\nattempts to approximate is unpredictable and may involve hallucinations, and\nexisting regularization is insufficient for targeted unlearning. To alleviate\nthese issues, we propose using the objective of maximizing entropy (ME) for\nuntargeted unlearning and incorporate answer preservation (AP) loss as\nregularization for targeted unlearning. Experimental results across three\nscenarios, i.e., fictitious unlearning, continual unlearning, and real-world\nunlearning, demonstrate the effectiveness of our approaches. The code is\navailable at https://github.com/sail-sg/closer-look-LLM-unlearning.\n","authors":["Xiaojian Yuan","Tianyu Pang","Chao Du","Kejiang Chen","Weiming Zhang","Min Lin"],"pdf_url":"https://arxiv.org/pdf/2410.08109v3.pdf","comment":"ICLR 2025"},{"id":"http://arxiv.org/abs/2411.18872v2","updated":"2025-03-03T02:41:10Z","published":"2024-11-28T02:50:42Z","title":"A Lean Dataset for International Math Olympiad: Small Steps towards\n  Writing Math Proofs for Hard Problems","summary":"  Using AI to write formal proofs for mathematical problems is a challenging\ntask that has seen some advancements in recent years. Automated systems such as\nLean can verify the correctness of proofs written in formal language, yet\nwriting the proofs in formal language can be challenging for humans and\nmachines. The miniF2F benchmark has 20 IMO problems in its test set, yet formal\nproofs are available only for 6 of these problems (3 of which are only written\nby mathematicians). The model with best accuracy can only prove 2 of these 20\nIMO problems, from 1950s and 60s, while its training set is a secret. In this\nwork, we write complete, original formal proofs for the remaining IMO problems\nin Lean along with 3 extra problems from IMO 2022 and 2023. This effort expands\nthe availability of proof currently in the public domain by creating 5,880\nlines of Lean proof. The goal of the paper is to pave the way for developing AI\nmodels that can automatically write the formal proofs for all the IMO problems\nin miniF2F and beyond by providing an evaluation benchmark. In this pursuit, we\ndevise a method to decompose the proofs of these problems into their building\nblocks, constructing a dataset of 1,329 lemmas with more than 40k lines of Lean\ncode. These lemmas are not trivial, yet they are approachable, providing the\nopportunity to evaluate and diagnose the failures and successes of AI models.\nWe evaluate the ability of the SOTA LLMs on our dataset and analyze their\nsuccess and failure modes from different perspectives. Our dataset and code is\navailable at: https://github.com/roozbeh-yz/IMO-Steps.\n","authors":["Roozbeh Yousefzadeh","Xuenan Cao","Azim Ospanov"],"pdf_url":"https://arxiv.org/pdf/2411.18872v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2502.21186v2","updated":"2025-03-03T02:33:31Z","published":"2025-02-28T16:02:23Z","title":"Scalable Decision-Making in Stochastic Environments through Learned\n  Temporal Abstraction","summary":"  Sequential decision-making in high-dimensional continuous action spaces,\nparticularly in stochastic environments, faces significant computational\nchallenges. We explore this challenge in the traditional offline RL setting,\nwhere an agent must learn how to make decisions based on data collected through\na stochastic behavior policy. We present Latent Macro Action Planner (L-MAP),\nwhich addresses this challenge by learning a set of temporally extended\nmacro-actions through a state-conditional Vector Quantized Variational\nAutoencoder (VQ-VAE), effectively reducing action dimensionality. L-MAP employs\na (separate) learned prior model that acts as a latent transition model and\nallows efficient sampling of plausible actions. During planning, our approach\naccounts for stochasticity in both the environment and the behavior policy by\nusing Monte Carlo tree search (MCTS). In offline RL settings, including\nstochastic continuous control tasks, L-MAP efficiently searches over discrete\nlatent actions to yield high expected returns. Empirical results demonstrate\nthat L-MAP maintains low decision latency despite increased action\ndimensionality. Notably, across tasks ranging from continuous control with\ninherently stochastic dynamics to high-dimensional robotic hand manipulation,\nL-MAP significantly outperforms existing model-based methods and performs\non-par with strong model-free actor-critic baselines, highlighting the\neffectiveness of the proposed approach in planning in complex and stochastic\nenvironments with high-dimensional action spaces.\n","authors":["Baiting Luo","Ava Pettet","Aron Laszka","Abhishek Dubey","Ayan Mukhopadhyay"],"pdf_url":"https://arxiv.org/pdf/2502.21186v2.pdf","comment":"Accepted by ICLR2025. Code would be available at\n  https://github.com/BaitingLuo/L-MAP.git"},{"id":"http://arxiv.org/abs/2412.01021v2","updated":"2025-03-03T02:13:49Z","published":"2024-12-02T00:41:25Z","title":"On the Feature Learning in Diffusion Models","summary":"  The predominant success of diffusion models in generative modeling has\nspurred significant interest in understanding their theoretical foundations. In\nthis work, we propose a feature learning framework aimed at analyzing and\ncomparing the training dynamics of diffusion models with those of traditional\nclassification models. Our theoretical analysis demonstrates that diffusion\nmodels, due to the denoising objective, are encouraged to learn more balanced\nand comprehensive representations of the data. In contrast, neural networks\nwith a similar architecture trained for classification tend to prioritize\nlearning specific patterns in the data, often focusing on easy-to-learn\ncomponents. To support these theoretical insights, we conduct several\nexperiments on both synthetic and real-world datasets, which empirically\nvalidate our findings and highlight the distinct feature learning dynamics in\ndiffusion models compared to classification.\n","authors":["Andi Han","Wei Huang","Yuan Cao","Difan Zou"],"pdf_url":"https://arxiv.org/pdf/2412.01021v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2404.19228v3","updated":"2025-03-03T02:06:52Z","published":"2024-04-30T03:15:04Z","title":"Weighted Point Set Embedding for Multimodal Contrastive Learning Toward\n  Optimal Similarity Metric","summary":"  In typical multimodal contrastive learning, such as CLIP, encoders produce\none point in the latent representation space for each input. However, one-point\nrepresentation has difficulty in capturing the relationship and the similarity\nstructure of a huge amount of instances in the real world. For richer classes\nof the similarity, we propose the use of weighted point sets, namely, sets of\npairs of weight and vector, as representations of instances. In this work, we\ntheoretically show the benefit of our proposed method through a new\nunderstanding of the contrastive loss of CLIP, which we call symmetric InfoNCE.\nWe clarify that the optimal similarity that minimizes symmetric InfoNCE is the\npointwise mutual information, and show an upper bound of excess risk on\ndownstream classification tasks of representations that achieve the optimal\nsimilarity. In addition, we show that our proposed similarity based on weighted\npoint sets consistently achieves the optimal similarity. To verify the\neffectiveness of our proposed method, we demonstrate pretraining of text-image\nrepresentation models and classification tasks on common benchmarks.\n","authors":["Toshimitsu Uesaka","Taiji Suzuki","Yuhta Takida","Chieh-Hsin Lai","Naoki Murata","Yuki Mitsufuji"],"pdf_url":"https://arxiv.org/pdf/2404.19228v3.pdf","comment":"ICLR 2025 (Spotlight)"},{"id":"http://arxiv.org/abs/2309.13838v2","updated":"2025-03-03T01:47:00Z","published":"2023-09-25T02:50:22Z","title":"Penalized Principal Component Analysis Using Smoothing","summary":"  Principal components computed via PCA (principal component analysis) are\ntraditionally used to reduce dimensionality in genomic data or to correct for\npopulation stratification. In this paper, we explore the penalized eigenvalue\nproblem (PEP) which reformulates the computation of the first eigenvector as an\noptimization problem and adds an $L_1$ penalty constraint to enforce sparseness\nof the solution. The contribution of our article is threefold. First, we extend\nPEP by applying smoothing to the original LASSO-type $L_1$ penalty. This allows\none to compute analytical gradients which enable faster and more efficient\nminimization of the objective function associated with the optimization\nproblem. Second, we demonstrate how higher order eigenvectors can be calculated\nwith PEP using established results from singular value decomposition (SVD).\nThird, we present four experimental studies to demonstrate the usefulness of\nthe smoothed penalized eigenvectors. Using data from the 1000 Genomes Project\ndataset, we empirically demonstrate that our proposed smoothed PEP allows one\nto increase numerical stability and obtain meaningful eigenvectors. We also\nemploy the penalized eigenvector approach in two additional real data\napplications (computation of a polygenic risk score and clustering),\ndemonstrating that exchanging the penalized eigenvectors for their smoothed\ncounterparts can increase prediction accuracy in polygenic risk scores and\nenhance discernibility of clusterings. Moreover, we compare our proposed\nsmoothed PEP to seven state-of-the-art algorithms for sparse PCA and evaluate\nthe accuracy of the obtained eigenvectors, their support recovery, and their\nruntime.\n","authors":["Rebecca M. Hurwitz","Georg Hahn"],"pdf_url":"https://arxiv.org/pdf/2309.13838v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2409.02060v2","updated":"2025-03-03T01:25:46Z","published":"2024-09-03T17:08:20Z","title":"OLMoE: Open Mixture-of-Experts Language Models","summary":"  We introduce OLMoE, a fully open, state-of-the-art language model leveraging\nsparse Mixture-of-Experts (MoE). OLMoE-1B-7B has 7 billion (B) parameters but\nuses only 1B per input token. We pretrain it on 5 trillion tokens and further\nadapt it to create OLMoE-1B-7B-Instruct. Our models outperform all available\nmodels with similar active parameters, even surpassing larger ones like\nLlama2-13B-Chat and DeepSeekMoE-16B. We present various experiments on MoE\ntraining, analyze routing in our model showing high specialization, and\nopen-source all aspects of our work: model weights, training data, code, and\nlogs.\n","authors":["Niklas Muennighoff","Luca Soldaini","Dirk Groeneveld","Kyle Lo","Jacob Morrison","Sewon Min","Weijia Shi","Pete Walsh","Oyvind Tafjord","Nathan Lambert","Yuling Gu","Shane Arora","Akshita Bhagia","Dustin Schwenk","David Wadden","Alexander Wettig","Binyuan Hui","Tim Dettmers","Douwe Kiela","Ali Farhadi","Noah A. Smith","Pang Wei Koh","Amanpreet Singh","Hannaneh Hajishirzi"],"pdf_url":"https://arxiv.org/pdf/2409.02060v2.pdf","comment":"63 pages (24 main), 36 figures, 17 tables"},{"id":"http://arxiv.org/abs/2407.10223v2","updated":"2025-03-03T01:21:39Z","published":"2024-07-14T14:26:17Z","title":"On Large Language Model Continual Unlearning","summary":"  While large language models have demonstrated impressive performance across\nvarious domains and tasks, their security issues have become increasingly\nsevere. Machine unlearning has emerged as a representative approach for model\nsafety and security by removing the influence of undesired data on the target\nmodel. However, these methods do not sufficiently consider that unlearning\nrequests in real-world scenarios are continuously emerging, especially in the\ncontext of LLMs, which may lead to accumulated model utility loss that\neventually becomes unacceptable. Moreover, existing LLM unlearning methods\noften ignore previous data access limitations due to privacy concerns and\ncopyright protection. Without previous data, the utility preservation during\nunlearning is much harder. To overcome these challenges, we propose the OOO\nframework that includes an Orthogonal low-rank adapter (LoRA) for continually\nunlearning requested data and an Out-Of-Distribution (OOD) detector to measure\nthe similarity between input and unlearning data. The orthogonal LoRA achieves\nparameter disentanglement among continual unlearning requests. The OOD detector\nis trained with a novel contrastive entropy loss and utilizes a glocal-aware\nscoring mechanism. During inference, our OOO framework can decide whether and\nto what extent to load the unlearning LoRA based on the OOD detector's\npredicted similarity between the input and the unlearned knowledge. Notably,\nOOO's effectiveness does not rely on any retained data. We conducted extensive\nexperiments on OOO and state-of-the-art LLM unlearning methods across three\ntasks and seven datasets. The results indicate that OOO consistently achieves\nthe best unlearning effectiveness and utility preservation, especially when\nfacing continuous unlearning requests. The source codes can be found at\nhttps://github.com/GCYZSL/O3-LLM-UNLEARNING.\n","authors":["Chongyang Gao","Lixu Wang","Kaize Ding","Chenkai Weng","Xiao Wang","Qi Zhu"],"pdf_url":"https://arxiv.org/pdf/2407.10223v2.pdf","comment":"This paper has been accepted by ICLR 2025. The first two authors\n  contribute equally and they are ordered alphabetically"},{"id":"http://arxiv.org/abs/2407.10967v2","updated":"2025-03-03T01:19:23Z","published":"2024-07-15T17:59:23Z","title":"BECAUSE: Bilinear Causal Representation for Generalizable Offline\n  Model-based Reinforcement Learning","summary":"  Offline model-based reinforcement learning (MBRL) enhances data efficiency by\nutilizing pre-collected datasets to learn models and policies, especially in\nscenarios where exploration is costly or infeasible. Nevertheless, its\nperformance often suffers from the objective mismatch between model and policy\nlearning, resulting in inferior performance despite accurate model predictions.\nThis paper first identifies the primary source of this mismatch comes from the\nunderlying confounders present in offline data for MBRL. Subsequently, we\nintroduce \\textbf{B}ilin\\textbf{E}ar \\textbf{CAUS}al\nr\\textbf{E}presentation~(BECAUSE), an algorithm to capture causal\nrepresentation for both states and actions to reduce the influence of the\ndistribution shift, thus mitigating the objective mismatch problem.\nComprehensive evaluations on 18 tasks that vary in data quality and environment\ncontext demonstrate the superior performance of BECAUSE over existing offline\nRL algorithms. We show the generalizability and robustness of BECAUSE under\nfewer samples or larger numbers of confounders. Additionally, we offer\ntheoretical analysis of BECAUSE to prove its error bound and sample efficiency\nwhen integrating causal representation into offline MBRL.\n","authors":["Haohong Lin","Wenhao Ding","Jian Chen","Laixi Shi","Jiacheng Zhu","Bo Li","Ding Zhao"],"pdf_url":"https://arxiv.org/pdf/2407.10967v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2409.14519v2","updated":"2025-03-03T00:51:41Z","published":"2024-09-22T16:25:31Z","title":"RobotFingerPrint: Unified Gripper Coordinate Space for Multi-Gripper\n  Grasp Synthesis and Transfer","summary":"  We introduce a novel grasp representation named the Unified Gripper\nCoordinate Space (UGCS) for grasp synthesis and grasp transfer. Our\nrepresentation leverages spherical coordinates to create a shared coordinate\nspace across different robot grippers, enabling it to synthesize and transfer\ngrasps for both novel objects and previously unseen grippers. The strength of\nthis representation lies in the ability to map palm and fingers of a gripper\nand the unified coordinate space. Grasp synthesis is formulated as predicting\nthe unified spherical coordinates on object surface points via a conditional\nvariational autoencoder. The predicted unified gripper coordinates establish\nexact correspondences between the gripper and object points, which is used to\noptimize grasp pose and joint values. Grasp transfer is facilitated through the\npoint-to-point correspondence between any two (potentially unseen) grippers and\nsolved via a similar optimization. Extensive simulation and real-world\nexperiments showcase the efficacy of the unified grasp representation for grasp\nsynthesis in generating stable and diverse grasps. Similarly, we showcase\nreal-world grasp transfer from human demonstrations across different objects.\n","authors":["Ninad Khargonkar","Luis Felipe Casas","Balakrishnan Prabhakaran","Yu Xiang"],"pdf_url":"https://arxiv.org/pdf/2409.14519v2.pdf","comment":"8 pages, 11 figures, 3 tables. Project page available at\n  https://irvlutd.github.io/RobotFingerPrint"},{"id":"http://arxiv.org/abs/2410.01417v2","updated":"2025-03-03T00:41:36Z","published":"2024-10-02T10:58:54Z","title":"The Labyrinth of Links: Navigating the Associative Maze of Multi-modal\n  LLMs","summary":"  Multi-modal Large Language Models (MLLMs) have exhibited impressive\ncapability. However, recently many deficiencies of MLLMs have been found\ncompared to human intelligence, $\\textit{e.g.}$, hallucination. To drive the\nMLLMs study, the community dedicated efforts to building larger benchmarks with\ncomplex tasks. In this paper, we propose benchmarking an essential but usually\noverlooked intelligence: $\\textbf{association}$, a human's basic capability to\nlink observation and prior practice memory. To comprehensively investigate\nMLLM's performance on the association, we formulate the association task and\ndevise a standard benchmark based on adjective and verb semantic concepts.\nInstead of costly data annotation and curation, we propose a convenient\n$\\textbf{annotation-free}$ construction method transforming the general dataset\nfor our association tasks. Simultaneously, we devise a rigorous data refinement\nprocess to eliminate confusion in the raw dataset. Building on this database,\nwe establish three levels of association tasks: single-step, synchronous, and\nasynchronous associations. Moreover, we conduct a comprehensive investigation\ninto the MLLMs' zero-shot association capabilities, addressing multiple\ndimensions, including three distinct memory strategies, both open-source and\nclosed-source MLLMs, cutting-edge Mixture-of-Experts (MoE) models, and the\ninvolvement of human experts. Our systematic investigation shows that current\nopen-source MLLMs consistently exhibit poor capability in our association\ntasks, even the currently state-of-the-art GPT-4V(vision) also has a\nsignificant gap compared to humans. We believe our benchmark would pave the way\nfor future MLLM studies. $\\textit{Our data and code are available at:}$\nhttps://mvig-rhos.com/llm_inception.\n","authors":["Hong Li","Nanxi Li","Yuanjie Chen","Jianbin Zhu","Qinlu Guo","Cewu Lu","Yong-Lu Li"],"pdf_url":"https://arxiv.org/pdf/2410.01417v2.pdf","comment":"Accepted by ICLR 2025. Project page:\n  https://mvig-rhos.com/llm_inception"},{"id":"http://arxiv.org/abs/2405.02318v2","updated":"2025-03-03T00:38:48Z","published":"2024-04-18T00:20:48Z","title":"NL2FOL: Translating Natural Language to First-Order Logic for Logical\n  Fallacy Detection","summary":"  Translating natural language into formal language such as First-Order Logic\n(FOL) is a foundational challenge in NLP with wide-ranging applications in\nautomated reasoning, misinformation tracking, and knowledge validation. In this\npaper, we introduce Natural Language to First-Order Logic (NL2FOL), a framework\nto autoformalize natural language to FOL step by step using Large Language\nModels (LLMs). Our approach addresses key challenges in this translation\nprocess, including the integration of implicit background knowledge. By\nleveraging structured representations generated by NL2FOL, we use\nSatisfiability Modulo Theory (SMT) solvers to reason about the logical validity\nof natural language statements. We present logical fallacy detection as a case\nstudy to evaluate the efficacy of NL2FOL. Being neurosymbolic, our approach\nalso provides interpretable insights into the reasoning process and\ndemonstrates robustness without requiring model fine-tuning or labeled training\ndata. Our framework achieves strong performance on multiple datasets. On the\nLOGIC dataset, NL2FOL achieves an F1-score of 78%, while generalizing\neffectively to the LOGICCLIMATE dataset with an F1-score of 80%.\n","authors":["Abhinav Lalwani","Tasha Kim","Lovish Chopra","Christopher Hahn","Zhijing Jin","Mrinmaya Sachan"],"pdf_url":"https://arxiv.org/pdf/2405.02318v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.22729v2","updated":"2025-03-03T00:23:28Z","published":"2024-10-30T06:28:21Z","title":"Identifying Drift, Diffusion, and Causal Structure from Temporal\n  Snapshots","summary":"  Stochastic differential equations (SDEs) are a fundamental tool for modelling\ndynamic processes, including gene regulatory networks (GRNs), contaminant\ntransport, financial markets, and image generation. However, learning the\nunderlying SDE from data is a challenging task, especially if individual\ntrajectories are not observable. Motivated by burgeoning research in\nsingle-cell datasets, we present the first comprehensive approach for jointly\nidentifying the drift and diffusion of an SDE from its temporal marginals.\nAssuming linear drift and additive diffusion, we prove that these parameters\nare identifiable from marginals if and only if the initial distribution lacks\nany generalized rotational symmetries. We further prove that the causal graph\nof any SDE with additive diffusion can be recovered from the SDE parameters. To\ncomplement this theory, we adapt entropy-regularized optimal transport to\nhandle anisotropic diffusion, and introduce APPEX (Alternating Projection\nParameter Estimation from $X_0$), an iterative algorithm designed to estimate\nthe drift, diffusion, and causal graph of an additive noise SDE, solely from\ntemporal marginals. We show that APPEX iteratively decreases Kullback-Leibler\ndivergence to the true solution, and demonstrate its effectiveness on simulated\ndata from linear additive noise SDEs.\n","authors":["Vincent Guan","Joseph Janssen","Hossein Rahmani","Andrew Warren","Stephen Zhang","Elina Robeva","Geoffrey Schiebinger"],"pdf_url":"https://arxiv.org/pdf/2410.22729v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2405.16002v2","updated":"2025-03-03T00:11:11Z","published":"2024-05-25T01:44:35Z","title":"Does SGD really happen in tiny subspaces?","summary":"  Understanding the training dynamics of deep neural networks is challenging\ndue to their high-dimensional nature and intricate loss landscapes. Recent\nstudies have revealed that, along the training trajectory, the gradient\napproximately aligns with a low-rank top eigenspace of the training loss\nHessian, referred to as the dominant subspace. Given this alignment, this paper\nexplores whether neural networks can be trained within the dominant subspace,\nwhich, if feasible, could lead to more efficient training methods. Our primary\nobservation is that when the SGD update is projected onto the dominant\nsubspace, the training loss does not decrease further. This suggests that the\nobserved alignment between the gradient and the dominant subspace is spurious.\nSurprisingly, projecting out the dominant subspace proves to be just as\neffective as the original update, despite removing the majority of the original\nupdate component. We observe similar behavior across practical setups,\nincluding the large learning rate regime (also known as Edge of Stability),\nSharpness-Aware Minimization, momentum, and adaptive optimizers. We discuss the\nmain causes and implications of this spurious alignment, shedding light on the\ndynamics of neural network training.\n","authors":["Minhak Song","Kwangjun Ahn","Chulhee Yun"],"pdf_url":"https://arxiv.org/pdf/2405.16002v2.pdf","comment":"Published at ICLR 2025"},{"id":"http://arxiv.org/abs/2401.15262v2","updated":"2025-03-03T00:04:46Z","published":"2024-01-27T01:16:33Z","title":"Asymptotic Behavior of Adversarial Training Estimator under\n  $\\ell_\\infty$-Perturbation","summary":"  Adversarial training has been proposed to protect machine learning models\nagainst adversarial attacks. This paper focuses on adversarial training under\n$\\ell_\\infty$-perturbation, which has recently attracted much research\nattention. The asymptotic behavior of the adversarial training estimator is\ninvestigated in the generalized linear model. The results imply that the\nasymptotic distribution of the adversarial training estimator under\n$\\ell_\\infty$-perturbation could put a positive probability mass at $0$ when\nthe true parameter is $0$, providing a theoretical guarantee of the associated\nsparsity-recovery ability. Alternatively, a two-step procedure is proposed --\nadaptive adversarial training, which could further improve the performance of\nadversarial training under $\\ell_\\infty$-perturbation. Specifically, the\nproposed procedure could achieve asymptotic variable-selection consistency and\nunbiasedness. Numerical experiments are conducted to show the sparsity-recovery\nability of adversarial training under $\\ell_\\infty$-perturbation and to compare\nthe empirical performance between classic adversarial training and adaptive\nadversarial training.\n","authors":["Yiling Xie","Xiaoming Huo"],"pdf_url":"https://arxiv.org/pdf/2401.15262v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2502.06786v3","updated":"2025-03-03T17:54:53Z","published":"2025-02-10T18:59:10Z","title":"Matryoshka Quantization","summary":"  Quantizing model weights is critical for reducing the communication and\ninference costs of large models. However, quantizing models -- especially to\nlow precisions like int4 or int2 -- requires a trade-off in model quality;\nint2, in particular, is known to severely degrade model quality. Consequently,\npractitioners are often forced to maintain multiple models with different\nquantization levels or serve a single model that best satisfies the\nquality-latency trade-off. On the other hand, integer data types, such as int8,\ninherently possess a nested (Matryoshka) structure where smaller bit-width\nintegers, like int4 or int2, are nested within the most significant bits.\nLeveraging this insight, in this paper, we propose Matryoshka Quantization\n(MatQuant), a novel multi-scale quantization technique that alleviates the\naforementioned challenge. This technique allows us to train and maintain a\nsingle quantized model but serve it with the precision demanded by the\ndeployment. Furthermore, leveraging MatQuant's co-training and co-distillation\nregularization, int2 precision models extracted by MatQuant outperform standard\nint2 quantization by up to to 4% and 7% with OmniQuant and QAT as base\nalgorithms respectively. Finally, we demonstrate that by using an extra bit to\nrepresent outliers, a model with an effective precision of 2.05-bit gives an\nadditional 6% improvement with OmniQuant as the base algorithm.\n","authors":["Pranav Nair","Puranjay Datta","Jeff Dean","Prateek Jain","Aditya Kusupati"],"pdf_url":"https://arxiv.org/pdf/2502.06786v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2502.15823v3","updated":"2025-03-03T16:38:10Z","published":"2025-02-20T03:48:00Z","title":"InductionBench: LLMs Fail in the Simplest Complexity Class","summary":"  Large language models (LLMs) have shown remarkable improvements in reasoning\nand many existing benchmarks have been addressed by models such as o1 and o3\neither fully or partially. However, a majority of these benchmarks emphasize\ndeductive reasoning, including mathematical and coding tasks in which rules\nsuch as mathematical axioms or programming syntax are clearly defined, based on\nwhich LLMs can plan and apply these rules to arrive at a solution. In contrast,\ninductive reasoning, where one infers the underlying rules from observed data,\nremains less explored. Such inductive processes lie at the heart of scientific\ndiscovery, as they enable researchers to extract general principles from\nempirical observations. To assess whether LLMs possess this capacity, we\nintroduce InductionBench, a new benchmark designed to evaluate the inductive\nreasoning ability of LLMs. Our experimental findings reveal that even the most\nadvanced models available struggle to master the simplest complexity classes\nwithin the subregular hierarchy of functions, highlighting a notable deficiency\nin current LLMs' inductive reasoning capabilities. Coda and data are available\nhttps://github.com/Wenyueh/inductive_reasoning_benchmark.\n","authors":["Wenyue Hua","Tyler Wong","Sun Fei","Liangming Pan","Adam Jardine","William Yang Wang"],"pdf_url":"https://arxiv.org/pdf/2502.15823v3.pdf","comment":"24 pages, 7 figures"},{"id":"http://arxiv.org/abs/2410.22371v2","updated":"2025-03-03T16:16:00Z","published":"2024-10-28T23:25:55Z","title":"Error Bounds for Physics-Informed Neural Networks in Fokker-Planck PDEs","summary":"  Stochastic differential equations are commonly used to describe the evolution\nof stochastic processes. The state uncertainty of such processes is best\nrepresented by the probability density function (PDF), whose evolution is\ngoverned by the Fokker-Planck partial differential equation (FP-PDE). However,\nit is generally infeasible to solve the FP-PDE in closed form. In this work, we\nshow that physics-informed neural networks (PINNs) can be trained to\napproximate the solution PDF. Our main contribution is the analysis of PINN\napproximation error: we develop a theoretical framework to construct tight\nerror bounds using PINNs. In addition, we derive a practical error bound that\ncan be efficiently constructed with standard training methods. We discuss that\nthis error-bound framework generalizes to approximate solutions of other linear\nPDEs. Empirical results on nonlinear, high-dimensional, and chaotic systems\nvalidate the correctness of our error bounds while demonstrating the\nscalability of PINNs and their significant computational speedup in obtaining\naccurate PDF solutions compared to the Monte Carlo approach.\n","authors":["Chun-Wei Kong","Luca Laurenti","Jay McMahon","Morteza Lahijanian"],"pdf_url":"https://arxiv.org/pdf/2410.22371v2.pdf","comment":"paper under review"},{"id":"http://arxiv.org/abs/2502.18821v2","updated":"2025-03-03T16:12:50Z","published":"2025-02-26T04:52:31Z","title":"CAMEx: Curvature-aware Merging of Experts","summary":"  Existing methods for merging experts during model training and fine-tuning\npredominantly rely on Euclidean geometry, which assumes a flat parameter space.\nThis assumption can limit the model's generalization ability, especially during\nthe pre-training phase, where the parameter manifold might exhibit more complex\ncurvature. Curvature-aware merging methods typically require additional\ninformation and computational resources to approximate the Fisher Information\nMatrix, adding memory overhead. In this paper, we introduce CAMEx\n(Curvature-Aware Merging of Experts), a novel expert merging protocol that\nincorporates natural gradients to account for the non-Euclidean curvature of\nthe parameter manifold. By leveraging natural gradients, CAMEx adapts more\neffectively to the structure of the parameter space, improving alignment\nbetween model updates and the manifold's geometry. This approach enhances both\npre-training and fine-tuning, resulting in better optimization trajectories and\nimproved generalization without the substantial memory overhead typically\nassociated with curvature-aware methods. Our contributions are threefold: (1)\nCAMEx significantly outperforms traditional Euclidean-based expert merging\ntechniques across various natural language processing tasks, leading to\nenhanced performance during pre-training and fine-tuning; (2) we introduce a\ndynamic merging architecture that optimizes resource utilization, achieving\nhigh performance while reducing computational costs, facilitating efficient\nscaling of large language models; and (3) we provide both theoretical and\nempirical evidence to demonstrate the efficiency of our proposed method. The\ncode is publicly available at: https://github.com/kpup1710/CAMEx.\n","authors":["Dung V. Nguyen","Minh H. Nguyen","Luc Q. Nguyen","Rachel S. Y. Teo","Tan M. Nguyen","Linh Duy Tran"],"pdf_url":"https://arxiv.org/pdf/2502.18821v2.pdf","comment":"10 pages, 5 Figures, 7 Tables. Published at ICLR 2025"},{"id":"http://arxiv.org/abs/2412.19495v2","updated":"2025-03-03T16:05:29Z","published":"2024-12-27T07:31:14Z","title":"Disparate Model Performance and Stability in Machine Learning Clinical\n  Support for Diabetes and Heart Diseases","summary":"  Machine Learning (ML) algorithms are vital for supporting clinical\ndecision-making in biomedical informatics. However, their predictive\nperformance can vary across demographic groups, often due to the\nunderrepresentation of historically marginalized populations in training\ndatasets. The investigation reveals widespread sex- and age-related inequities\nin chronic disease datasets and their derived ML models. Thus, a novel\nanalytical framework is introduced, combining systematic arbitrariness with\ntraditional metrics like accuracy and data complexity. The analysis of data\nfrom over 25,000 individuals with chronic diseases revealed mild sex-related\ndisparities, favoring predictive accuracy for males, and significant\nage-related differences, with better accuracy for younger patients. Notably,\nolder patients showed inconsistent predictive accuracy across seven datasets,\nlinked to higher data complexity and lower model performance. This highlights\nthat representativeness in training data alone does not guarantee equitable\noutcomes, and model arbitrariness must be addressed before deploying models in\nclinical settings.\n","authors":["Ioannis Bilionis","Ricardo C. Berrios","Luis Fernandez-Luque","Carlos Castillo"],"pdf_url":"https://arxiv.org/pdf/2412.19495v2.pdf","comment":"This paper will be presented in American Medical Informatics\n  Association (AMIA) Informatics Summit Conference 2025 (Pittsburgh, PA). 10\n  pages, 2 figures, 5 tables"},{"id":"http://arxiv.org/abs/2501.11972v2","updated":"2025-03-03T15:45:44Z","published":"2025-01-21T08:34:10Z","title":"\"FRAME: Forward Recursive Adaptive Model Extraction-A Technique for\n  Advance Feature Selection\"","summary":"  The challenges in feature selection, particularly in balancing model\naccuracy, interpretability, and computational efficiency, remain a critical\nissue in advancing machine learning methodologies. To address these\ncomplexities, this study introduces a novel hybrid approach, the Forward\nRecursive Adaptive Model Extraction Technique (FRAME), which combines Forward\nSelection and Recursive Feature Elimination (RFE) to enhance feature selection\nacross diverse datasets. By combining the exploratory capabilities of Forward\nSelection with the refinement strengths of RFE, FRAME systematically identifies\noptimal feature subsets, striking a harmonious trade-off between\nexperimentation and precision. A comprehensive evaluation of FRAME is conducted\nagainst traditional methods such as SelectKBest and Lasso Regression, using\nhigh-dimensional, noisy, and heterogeneous datasets. The results demonstrate\nthat FRAME consistently delivers superior predictive performance based on\ndownstream machine learning evaluation metrics. It efficiently performs\ndimensionality reduction with strong model performance, thus being especially\nuseful for applications that need interpretable and accurate predictions, e.g.,\nbiomedical diagnostics.\n  This research emphasizes the need to evaluate feature selection techniques on\ndiverse datasets to test their robustness and generalizability. The results\nindicate that FRAME has great potential for further development, especially by\nincorporating deep learning frameworks for adaptive and real-time feature\nselection in dynamic settings. By advancing feature selection methodologies,\nFRAME offers a practical and effective solution to improve machine learning\napplications across multiple domains.\n","authors":["Nachiket Kapure","Harsh Joshi","Parul Kumari","Rajeshwari Mistri","Manasi Mali"],"pdf_url":"https://arxiv.org/pdf/2501.11972v2.pdf","comment":"Updated version with refinements before JMLR submission. Improved\n  clarity, expanded literature review, refined methodology, updated\n  experimental results, and enhanced conclusion. FRAME's scalability, deep\n  learning integration, and real-world applications are further highlighted"},{"id":"http://arxiv.org/abs/2412.14663v2","updated":"2025-03-03T15:32:17Z","published":"2024-12-19T09:14:24Z","title":"IOHunter: Graph Foundation Model to Uncover Online Information\n  Operations","summary":"  Social media platforms have become vital spaces for public discourse, serving\nas modern agor\\`as where a wide range of voices influence societal narratives.\nHowever, their open nature also makes them vulnerable to exploitation by\nmalicious actors, including state-sponsored entities, who can conduct\ninformation operations (IOs) to manipulate public opinion. The spread of\nmisinformation, false news, and misleading claims threatens democratic\nprocesses and societal cohesion, making it crucial to develop methods for the\ntimely detection of inauthentic activity to protect the integrity of online\ndiscourse. In this work, we introduce a methodology designed to identify users\norchestrating information operations, a.k.a. IO drivers, across various\ninfluence campaigns. Our framework, named IOHunter, leverages the combined\nstrengths of Language Models and Graph Neural Networks to improve\ngeneralization in supervised, scarcely-supervised, and cross-IO contexts. Our\napproach achieves state-of-the-art performance across multiple sets of IOs\noriginating from six countries, significantly surpassing existing approaches.\nThis research marks a step toward developing Graph Foundation Models\nspecifically tailored for the task of IO detection on social media platforms.\n","authors":["Marco Minici","Luca Luceri","Francesco Fabbri","Emilio Ferrara"],"pdf_url":"https://arxiv.org/pdf/2412.14663v2.pdf","comment":"Accepted at AAAI 2025"},{"id":"http://arxiv.org/abs/2408.11561v2","updated":"2025-03-03T15:04:03Z","published":"2024-08-21T12:15:20Z","title":"Self-Supervised Iterative Refinement for Anomaly Detection in Industrial\n  Quality Control","summary":"  This study introduces the Iterative Refinement Process (IRP), a robust\nanomaly detection methodology designed for high-stakes industrial quality\ncontrol. The IRP enhances defect detection accuracy through a cyclic data\nrefinement strategy, iteratively removing misleading data points to improve\nmodel performance and robustness. We validate the IRP's effectiveness using two\nbenchmark datasets, Kolektor SDD2 (KSDD2) and MVTec AD, covering a wide range\nof industrial products and defect types. Our experimental results demonstrate\nthat the IRP consistently outperforms traditional anomaly detection models,\nparticularly in environments with high noise levels. This study highlights the\nIRP's potential to significantly enhance anomaly detection processes in\nindustrial settings, effectively managing the challenges of sparse and noisy\ndata.\n","authors":["Muhammad Aqeel","Shakiba Sharifi","Marco Cristani","Francesco Setti"],"pdf_url":"https://arxiv.org/pdf/2408.11561v2.pdf","comment":"Accepted to VISAPP 2025"},{"id":"http://arxiv.org/abs/2411.07180v4","updated":"2025-03-03T14:56:17Z","published":"2024-11-11T17:57:30Z","title":"Gumbel Counterfactual Generation From Language Models","summary":"  Understanding and manipulating the causal generation mechanisms in language\nmodels is essential for controlling their behavior. Previous work has primarily\nrelied on techniques such as representation surgery -- e.g., model ablations or\nmanipulation of linear subspaces tied to specific concepts -- to\n\\emph{intervene} on these models. To understand the impact of interventions\nprecisely, it is useful to examine \\emph{counterfactuals} -- e.g., how a given\nsentence would have appeared had it been generated by the model following a\nspecific intervention. We highlight that counterfactual reasoning is\nconceptually distinct from interventions, as articulated in Pearl's causal\nhierarchy. Based on this observation, we propose a framework for generating\ntrue string counterfactuals by reformulating language models as a structural\nequation model using the Gumbel-max trick, which we called Gumbel\ncounterfactual generation. This reformulation allows us to model the joint\ndistribution over original strings and their counterfactuals resulting from the\nsame instantiation of the sampling noise. We develop an algorithm based on\nhindsight Gumbel sampling that allows us to infer the latent noise variables\nand generate counterfactuals of observed strings. Our experiments demonstrate\nthat the approach produces meaningful counterfactuals while at the same time\nshowing that commonly used intervention techniques have considerable undesired\nside effects.\n","authors":["Shauli Ravfogel","Anej Svete","Vsteinn Snbjarnarson","Ryan Cotterell"],"pdf_url":"https://arxiv.org/pdf/2411.07180v4.pdf","comment":"Accepted in ICLR 2025"},{"id":"http://arxiv.org/abs/2409.13533v2","updated":"2025-03-03T14:40:34Z","published":"2024-09-20T14:23:05Z","title":"Using High-Level Patterns to Estimate How Humans Predict a Robot will\n  Behave","summary":"  Humans interacting with robots often form predictions of what the robot will\ndo next. For instance, based on the recent behavior of an autonomous car, a\nnearby human driver might predict that the car is going to remain in the same\nlane. It is important for the robot to understand the human's prediction for\nsafe and seamless interaction: e.g., if the autonomous car knows the human\nthinks it is not merging -- but the autonomous car actually intends to merge --\nthen the car can adjust its behavior to prevent an accident. Prior works\ntypically assume that humans make precise predictions of robot behavior.\nHowever, recent research on human-human prediction suggests the opposite:\nhumans tend to approximate other agents by predicting their high-level\nbehaviors. We apply this finding to develop a second-order theory of mind\napproach that enables robots to estimate how humans predict they will behave.\nTo extract these high-level predictions directly from data, we embed the recent\nhuman and robot trajectories into a discrete latent space. Each element of this\nlatent space captures a different type of behavior (e.g., merging in front of\nthe human, remaining in the same lane) and decodes into a vector field across\nthe state space that is consistent with the underlying behavior type. We\nhypothesize that our resulting high-level and course predictions of robot\nbehavior will correspond to actual human predictions. We provide initial\nevidence in support of this hypothesis through proof-of-concept simulations,\ntesting our method's predictions against those of real users, and experiments\non a real-world interactive driving dataset.\n","authors":["Sagar Parekh","Lauren Bramblett","Nicola Bezzo","Dylan P. Losey"],"pdf_url":"https://arxiv.org/pdf/2409.13533v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2407.11734v2","updated":"2025-03-03T14:24:06Z","published":"2024-07-16T14:05:03Z","title":"Multi-Modal and Multi-Attribute Generation of Single Cells with CFGen","summary":"  Generative modeling of single-cell RNA-seq data is crucial for tasks like\ntrajectory inference, batch effect removal, and simulation of realistic\ncellular data. However, recent deep generative models simulating synthetic\nsingle cells from noise operate on pre-processed continuous gene expression\napproximations, overlooking the discrete nature of single-cell data, which\nlimits their effectiveness and hinders the incorporation of robust noise\nmodels. Additionally, aspects like controllable multi-modal and multi-label\ngeneration of cellular data remain underexplored. This work introduces CellFlow\nfor Generation (CFGen), a flow-based conditional generative model that\npreserves the inherent discreteness of single-cell data. CFGen generates\nwhole-genome multi-modal single-cell data reliably, improving the recovery of\ncrucial biological data characteristics while tackling relevant generative\ntasks such as rare cell type augmentation and batch correction. We also\nintroduce a novel framework for compositional data generation using Flow\nMatching. By showcasing CFGen on a diverse set of biological datasets and\nsettings, we provide evidence of its value to the fields of computational\nbiology and deep generative models.\n","authors":["Alessandro Palma","Till Richter","Hanyi Zhang","Manuel Lubetzki","Alexander Tong","Andrea Dittadi","Fabian Theis"],"pdf_url":"https://arxiv.org/pdf/2407.11734v2.pdf","comment":"41 pages, 22 figures"},{"id":"http://arxiv.org/abs/2406.00987v2","updated":"2025-03-03T14:14:00Z","published":"2024-06-03T04:48:45Z","title":"Enhancing Fairness in Unsupervised Graph Anomaly Detection through\n  Disentanglement","summary":"  Graph anomaly detection (GAD) is increasingly crucial in various\napplications, ranging from financial fraud detection to fake news detection.\nHowever, current GAD methods largely overlook the fairness problem, which might\nresult in discriminatory decisions skewed toward certain demographic groups\ndefined on sensitive attributes (e.g., gender, religion, ethnicity, etc.). This\ngreatly limits the applicability of these methods in real-world scenarios in\nlight of societal and ethical restrictions. To address this critical gap, we\nmake the first attempt to integrate fairness with utility in GAD\ndecision-making. Specifically, we devise a novel DisEntangle-based\nFairnEss-aware aNomaly Detection framework on the attributed graph, named\nDEFEND. DEFEND first introduces disentanglement in GNNs to capture informative\nyet sensitive-irrelevant node representations, effectively reducing societal\nbias inherent in graph representation learning. Besides, to alleviate\ndiscriminatory bias in evaluating anomalous nodes, DEFEND adopts a\nreconstruction-based anomaly detection, which concentrates solely on node\nattributes without incorporating any graph structure. Additionally, given the\ninherent association between input and sensitive attributes, DEFEND constrains\nthe correlation between the reconstruction error and the predicted sensitive\nattributes. Our empirical evaluations on real-world datasets reveal that DEFEND\nperforms effectively in GAD and significantly enhances fairness compared to\nstate-of-the-art baselines. To foster reproducibility, our code is available at\nhttps://github.com/AhaChang/DEFEND.\n","authors":["Wenjing Chang","Kay Liu","Philip S. Yu","Jianjun Yu"],"pdf_url":"https://arxiv.org/pdf/2406.00987v2.pdf","comment":"Accepted to TMLR. Code available at\n  https://github.com/AhaChang/DEFEND"},{"id":"http://arxiv.org/abs/2405.15273v4","updated":"2025-03-03T12:40:28Z","published":"2024-05-24T06:59:43Z","title":"Towards a General Time Series Anomaly Detector with Adaptive Bottlenecks\n  and Dual Adversarial Decoders","summary":"  Time series anomaly detection plays a vital role in a wide range of\napplications. Existing methods require training one specific model for each\ndataset, which exhibits limited generalization capability across different\ntarget datasets, hindering anomaly detection performance in various scenarios\nwith scarce training data. Aiming at this problem, we propose constructing a\ngeneral time series anomaly detection model, which is pre-trained on extensive\nmulti-domain datasets and can subsequently apply to a multitude of downstream\nscenarios. The significant divergence of time series data across different\ndomains presents two primary challenges in building such a general model: (1)\nmeeting the diverse requirements of appropriate information bottlenecks\ntailored to different datasets in one unified model, and (2) enabling\ndistinguishment between multiple normal and abnormal patterns, both are crucial\nfor effective anomaly detection in various target scenarios. To tackle these\ntwo challenges, we propose a General time series anomaly Detector with Adaptive\nBottlenecks and Dual Adversarial Decoders (DADA), which enables flexible\nselection of bottlenecks based on different data and explicitly enhances clear\ndifferentiation between normal and abnormal series. We conduct extensive\nexperiments on nine target datasets from different domains. After pre-training\non multi-domain data, DADA, serving as a zero-shot anomaly detector for these\ndatasets, still achieves competitive or even superior results compared to those\nmodels tailored to each specific dataset. The code is made available at\nhttps://github.com/decisionintelligence/DADA.\n","authors":["Qichao Shentu","Beibu Li","Kai Zhao","Yang Shu","Zhongwen Rao","Lujia Pan","Bin Yang","Chenjuan Guo"],"pdf_url":"https://arxiv.org/pdf/2405.15273v4.pdf","comment":"Accepted by the 13th International Conference on Learning\n  Representations (ICLR 2025)"},{"id":"http://arxiv.org/abs/2403.19243v4","updated":"2025-03-03T12:32:47Z","published":"2024-03-28T08:58:20Z","title":"Efficient Learning With Sine-Activated Low-rank Matrices","summary":"  Low-rank decomposition has emerged as a vital tool for enhancing parameter\nefficiency in neural network architectures, gaining traction across diverse\napplications in machine learning. These techniques significantly lower the\nnumber of parameters, striking a balance between compactness and performance.\nHowever, a common challenge has been the compromise between parameter\nefficiency and the accuracy of the model, where reduced parameters often lead\nto diminished accuracy compared to their full-rank counterparts. In this work,\nwe propose a novel theoretical framework that integrates a sinusoidal function\nwithin the low-rank decomposition process. This approach not only preserves the\nbenefits of the parameter efficiency characteristic of low-rank methods but\nalso increases the decomposition's rank, thereby enhancing model performance.\nOur method proves to be a plug in enhancement for existing low-rank models, as\nevidenced by its successful application in Vision Transformers (ViT), Large\nLanguage Models (LLMs), Neural Radiance Fields (NeRF) and 3D shape modelling.\n","authors":["Yiping Ji","Hemanth Saratchandran","Cameron Gordon","Zeyu Zhang","Simon Lucey"],"pdf_url":"https://arxiv.org/pdf/2403.19243v4.pdf","comment":"The first two authors contributed equally. Paper accepted at ICLR\n  2025"},{"id":"http://arxiv.org/abs/2403.08632v2","updated":"2025-03-03T12:01:27Z","published":"2024-03-13T15:46:37Z","title":"A Decade's Battle on Dataset Bias: Are We There Yet?","summary":"  We revisit the \"dataset classification\" experiment suggested by Torralba &\nEfros (2011) a decade ago, in the new era with large-scale, diverse, and\nhopefully less biased datasets as well as more capable neural network\narchitectures. Surprisingly, we observe that modern neural networks can achieve\nexcellent accuracy in classifying which dataset an image is from: e.g., we\nreport 84.7% accuracy on held-out validation data for the three-way\nclassification problem consisting of the YFCC, CC, and DataComp datasets. Our\nfurther experiments show that such a dataset classifier could learn semantic\nfeatures that are generalizable and transferable, which cannot be explained by\nmemorization. We hope our discovery will inspire the community to rethink\nissues involving dataset bias.\n","authors":["Zhuang Liu","Kaiming He"],"pdf_url":"https://arxiv.org/pdf/2403.08632v2.pdf","comment":"Published in ICLR 2025 (Oral Presentation)"},{"id":"http://arxiv.org/abs/2403.02107v5","updated":"2025-03-03T11:48:55Z","published":"2024-03-04T15:07:33Z","title":"Iterated $Q$-Network: Beyond One-Step Bellman Updates in Deep\n  Reinforcement Learning","summary":"  The vast majority of Reinforcement Learning methods is largely impacted by\nthe computation effort and data requirements needed to obtain effective\nestimates of action-value functions, which in turn determine the quality of the\noverall performance and the sample-efficiency of the learning procedure.\nTypically, action-value functions are estimated through an iterative scheme\nthat alternates the application of an empirical approximation of the Bellman\noperator and a subsequent projection step onto a considered function space. It\nhas been observed that this scheme can be potentially generalized to carry out\nmultiple iterations of the Bellman operator at once, benefiting the underlying\nlearning algorithm. However, till now, it has been challenging to effectively\nimplement this idea, especially in high-dimensional problems. In this paper, we\nintroduce iterated $Q$-Network (i-QN), a novel principled approach that enables\nmultiple consecutive Bellman updates by learning a tailored sequence of\naction-value functions where each serves as the target for the next. We show\nthat i-QN is theoretically grounded and that it can be seamlessly used in\nvalue-based and actor-critic methods. We empirically demonstrate the advantages\nof i-QN in Atari $2600$ games and MuJoCo continuous control problems.\n","authors":["Tho Vincent","Daniel Palenicek","Boris Belousov","Jan Peters","Carlo D'Eramo"],"pdf_url":"https://arxiv.org/pdf/2403.02107v5.pdf","comment":"Published at TMLR: https://openreview.net/forum?id=Lt2H8Bd8jF"},{"id":"http://arxiv.org/abs/2402.06287v2","updated":"2025-03-03T11:28:57Z","published":"2024-02-09T09:54:01Z","title":"AI, Meet Human: Learning Paradigms for Hybrid Decision Making Systems","summary":"  Everyday we increasingly rely on machine learning models to automate and\nsupport high-stake tasks and decisions. This growing presence means that humans\nare now constantly interacting with machine learning-based systems, training\nand using models everyday. Several different techniques in computer science\nliterature account for the human interaction with machine learning systems, but\ntheir classification is sparse and the goals varied. This survey proposes a\ntaxonomy of Hybrid Decision Making Systems, providing both a conceptual and\ntechnical framework for understanding how current computer science literature\nmodels interaction between humans and machines.\n","authors":["Clara Punzi","Roberto Pellungrini","Mattia Setzu","Fosca Giannotti","Dino Pedreschi"],"pdf_url":"https://arxiv.org/pdf/2402.06287v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2402.18477v4","updated":"2025-03-03T11:25:26Z","published":"2024-02-28T16:58:31Z","title":"Signature Kernel Conditional Independence Tests in Causal Discovery for\n  Stochastic Processes","summary":"  Inferring the causal structure underlying stochastic dynamical systems from\nobservational data holds great promise in domains ranging from science and\nhealth to finance. Such processes can often be accurately modeled via\nstochastic differential equations (SDEs), which naturally imply causal\nrelationships via \"which variables enter the differential of which other\nvariables\". In this paper, we develop conditional independence (CI) constraints\non coordinate processes over selected intervals that are Markov with respect to\nthe acyclic dependence graph (allowing self-loops) induced by a general SDE\nmodel. We then provide a sound and complete causal discovery algorithm, capable\nof handling both fully and partially observed data, and uniquely recovering the\nunderlying or induced ancestral graph by exploiting time directionality\nassuming a CI oracle. Finally, to make our algorithm practically usable, we\nalso propose a flexible, consistent signature kernel-based CI test to infer\nthese constraints from data. We extensively benchmark the CI test in isolation\nand as part of our causal discovery algorithms, outperforming existing\napproaches in SDE models and beyond.\n","authors":["Georg Manten","Cecilia Casolo","Emilio Ferrucci","Sren Wengel Mogensen","Cristopher Salvi","Niki Kilbertus"],"pdf_url":"https://arxiv.org/pdf/2402.18477v4.pdf","comment":null},{"id":"http://arxiv.org/abs/2306.14872v4","updated":"2025-03-03T06:05:48Z","published":"2023-06-26T17:38:45Z","title":"Geometry-Aware Approaches for Balancing Performance and Theoretical\n  Guarantees in Linear Bandits","summary":"  This paper is motivated by recent research in the $d$-dimensional stochastic\nlinear bandit literature, which has revealed an unsettling discrepancy:\nalgorithms like Thompson sampling and Greedy demonstrate promising empirical\nperformance, yet this contrasts with their pessimistic theoretical regret\nbounds. The challenge arises from the fact that while these algorithms may\nperform poorly in certain problem instances, they generally excel in typical\ninstances. To address this, we propose a new data-driven technique that tracks\nthe geometric properties of the uncertainty ellipsoid around the main problem\nparameter. This methodology enables us to formulate a data-driven frequentist\nregret bound, which incorporates the geometric information, for a broad class\nof base algorithms, including Greedy, OFUL, and Thompson sampling. This result\nallows us to identify and ``course-correct\" problem instances in which the base\nalgorithms perform poorly. The course-corrected algorithms achieve the minimax\noptimal regret of order $\\tilde{\\mathcal{O}}(d\\sqrt{T})$ for a $T$-period\ndecision-making scenario, effectively maintaining the desirable attributes of\nthe base algorithms, including their empirical efficacy. We present simulation\nresults to validate our findings using synthetic and real data.\n","authors":["Yuwei Luo","Mohsen Bayati"],"pdf_url":"https://arxiv.org/pdf/2306.14872v4.pdf","comment":null}]},"2025-03-02T00:00:00Z":{"Computation and Language":[{"id":"http://arxiv.org/abs/2502.12361v3","updated":"2025-03-02T22:19:39Z","published":"2025-02-17T22:56:42Z","title":"ConFit v2: Improving Resume-Job Matching using Hypothetical Resume\n  Embedding and Runner-Up Hard-Negative Mining","summary":"  A reliable resume-job matching system helps a company recommend suitable\ncandidates from a pool of resumes and helps a job seeker find relevant jobs\nfrom a list of job posts. However, since job seekers apply only to a few jobs,\ninteraction labels in resume-job datasets are sparse. We introduce ConFit v2,\nan improvement over ConFit to tackle this sparsity problem. We propose two\ntechniques to enhance the encoder's contrastive training process: augmenting\njob data with hypothetical reference resume generated by a large language\nmodel; and creating high-quality hard negatives from unlabeled resume/job pairs\nusing a novel hard-negative mining strategy. We evaluate ConFit v2 on two\nreal-world datasets and demonstrate that it outperforms ConFit and prior\nmethods (including BM25 and OpenAI text-embedding-003), achieving an average\nabsolute improvement of 13.8% in recall and 17.5% in nDCG across job-ranking\nand resume-ranking tasks.\n","authors":["Xiao Yu","Ruize Xu","Chengyuan Xue","Jinzhong Zhang","Xu Ma","Zhou Yu"],"pdf_url":"https://arxiv.org/pdf/2502.12361v3.pdf","comment":"arXiv admin note: text overlap with arXiv:2401.16349"},{"id":"http://arxiv.org/abs/2402.10767v2","updated":"2025-03-02T20:33:20Z","published":"2024-02-16T15:41:23Z","title":"Inference to the Best Explanation in Large Language Models","summary":"  While Large Language Models (LLMs) have found success in real-world\napplications, their underlying explanatory process is still poorly understood.\nThis paper proposes IBE-Eval, a framework inspired by philosophical accounts on\nInference to the Best Explanation (IBE) to advance the interpretation and\nevaluation of LLMs' explanations. IBE-Eval estimates the plausibility of\nnatural language explanations through a combination of explicit logical and\nlinguistic features including: consistency, parsimony, coherence, and\nuncertainty. Extensive experiments are conducted on Causal Question Answering\n(CQA), where \\textit{IBE-Eval} is tasked to select the most plausible causal\nexplanation amongst competing ones generated by LLMs (i.e., GPT 3.5 and Llama\n2). The experiments reveal that IBE-Eval can successfully identify the best\nexplanation with up to 77\\% accuracy ($\\approx 27\\%$ above random), improving\nupon a GPT 3.5-as-a-Judge baseline ($\\approx+17\\%$) while being intrinsically\nmore efficient and interpretable. Additional analyses suggest that, despite\nmodel-specific variances, LLM-generated explanations tend to conform to IBE\ncriteria and that IBE-Eval is significantly correlated with human judgment,\nopening up opportunities for future development of automated explanation\nverification tools.\n","authors":["Dhairya Dalal","Marco Valentino","Andr Freitas","Paul Buitelaar"],"pdf_url":"https://arxiv.org/pdf/2402.10767v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.04343v2","updated":"2025-03-02T19:44:37Z","published":"2024-10-06T03:42:15Z","title":"Inference Scaling for Long-Context Retrieval Augmented Generation","summary":"  The scaling of inference computation has unlocked the potential of\nlong-context large language models (LLMs) across diverse settings. For\nknowledge-intensive tasks, the increased compute is often allocated to\nincorporate more external knowledge. However, without effectively utilizing\nsuch knowledge, solely expanding context does not always enhance performance.\nIn this work, we investigate inference scaling for retrieval augmented\ngeneration (RAG), exploring the combination of multiple strategies beyond\nsimply increasing the quantity of knowledge, including in-context learning and\niterative prompting. These strategies provide additional flexibility to scale\ntest-time computation (e.g., by increasing retrieved documents or generation\nsteps), thereby enhancing LLMs' ability to effectively acquire and utilize\ncontextual information. We address two key questions: (1) How does RAG\nperformance benefit from the scaling of inference computation when optimally\nconfigured? (2) Can we predict the optimal test-time compute allocation for a\ngiven budget by modeling the relationship between RAG performance and inference\nparameters? Our observations reveal that increasing inference computation leads\nto nearly linear gains in RAG performance when optimally allocated, a\nrelationship we describe as the inference scaling laws for RAG. Building on\nthis, we further develop the computation allocation model to estimate RAG\nperformance across different inference configurations. The model predicts\noptimal inference parameters under various computation constraints, which align\nclosely with the experimental results. By applying these optimal\nconfigurations, we demonstrate that scaling inference compute on long-context\nLLMs achieves up to 58.9% gains on benchmark datasets compared to standard RAG.\n","authors":["Zhenrui Yue","Honglei Zhuang","Aijun Bai","Kai Hui","Rolf Jagerman","Hansi Zeng","Zhen Qin","Dong Wang","Xuanhui Wang","Michael Bendersky"],"pdf_url":"https://arxiv.org/pdf/2410.04343v2.pdf","comment":"ICLR 2025"},{"id":"http://arxiv.org/abs/2405.14105v4","updated":"2025-03-02T18:24:29Z","published":"2024-05-23T02:14:17Z","title":"Distributed Speculative Inference (DSI): Speculation Parallelism for\n  Provably Faster Lossless Language Model Inference","summary":"  This paper introduces distributed speculative inference (DSI), a novel\ninference algorithm that is provably faster than speculative inference (SI)\n[leviathan2023, chen2023, miao2024, sun2025, timor2025] and standard\nautoregressive inference (non-SI). Like other SI algorithms, DSI operates on\nfrozen language models (LMs), requiring no training or architectural\nmodifications, and it preserves the target distribution. Prior studies on SI\nhave demonstrated empirical speedups over non-SI--but rely on sufficiently fast\nand accurate drafters, which are often unavailable in practice. We identify a\ngap where SI can be slower than non-SI if drafters are too slow or inaccurate.\nWe close this gap by proving that DSI is faster than both SI and non-SI--given\nany drafters. DSI is therefore not only faster than SI, but also unlocks the\nacceleration of LMs for which SI fails. DSI leverages speculation parallelism\n(SP), a novel type of task parallelism, to orchestrate target and drafter\ninstances that overlap in time, establishing a new foundational tradeoff\nbetween computational resources and latency. Our simulations show that DSI is\n1.29-1.92x faster than SI in single-node setups for various off-the-shelf LMs\nand tasks. We open-source all our code.\n","authors":["Nadav Timor","Jonathan Mamou","Daniel Korat","Moshe Berchansky","Oren Pereg","Moshe Wasserblat","Tomer Galanti","Michal Gordon","David Harel"],"pdf_url":"https://arxiv.org/pdf/2405.14105v4.pdf","comment":"Published at ICLR 2025. (Link:\n  https://openreview.net/forum?id=cJd1BgZ9CS)"},{"id":"http://arxiv.org/abs/2403.08743v2","updated":"2025-03-02T17:33:03Z","published":"2024-03-13T17:46:28Z","title":"Prompting Fairness: Integrating Causality to Debias Large Language\n  Models","summary":"  Large language models (LLMs), despite their remarkable capabilities, are\nsusceptible to generating biased and discriminatory responses. As LLMs\nincreasingly influence high-stakes decision-making (e.g., hiring and\nhealthcare), mitigating these biases becomes critical. In this work, we propose\na causality-guided debiasing framework to tackle social biases, aiming to\nreduce the objectionable dependence between LLMs' decisions and the social\ninformation in the input. Our framework introduces a novel perspective to\nidentify how social information can affect an LLM's decision through different\ncausal pathways. Leveraging these causal insights, we outline principled\nprompting strategies that regulate these pathways through selection mechanisms.\nThis framework not only unifies existing prompting-based debiasing techniques,\nbut also opens up new directions for reducing bias by encouraging the model to\nprioritize fact-based reasoning over reliance on biased social cues. We\nvalidate our framework through extensive experiments on real-world datasets\nacross multiple domains, demonstrating its effectiveness in debiasing LLM\ndecisions, even with only black-box access to the model.\n","authors":["Jingling Li","Zeyu Tang","Xiaoyu Liu","Peter Spirtes","Kun Zhang","Liu Leqi","Yang Liu"],"pdf_url":"https://arxiv.org/pdf/2403.08743v2.pdf","comment":"24 pages, 10 figures"},{"id":"http://arxiv.org/abs/2502.11882v3","updated":"2025-03-02T17:15:11Z","published":"2025-02-17T15:09:45Z","title":"Leveraging Dual Process Theory in Language Agent Framework for Real-time\n  Simultaneous Human-AI Collaboration","summary":"  Agents built on large language models (LLMs) have excelled in turn-by-turn\nhuman-AI collaboration but struggle with simultaneous tasks requiring real-time\ninteraction. Latency issues and the challenge of inferring variable human\nstrategies hinder their ability to make autonomous decisions without explicit\ninstructions. Through experiments with current independent System 1 and System\n2 methods, we validate the necessity of using Dual Process Theory (DPT) in\nreal-time tasks. We propose DPT-Agent, a novel language agent framework that\nintegrates System 1 and System 2 for efficient real-time simultaneous human-AI\ncollaboration. DPT-Agent's System 1 uses a Finite-state Machine (FSM) and\ncode-as-policy for fast, intuitive, and controllable decision-making.\nDPT-Agent's System 2 integrates Theory of Mind (ToM) and asynchronous\nreflection to infer human intentions and perform reasoning-based autonomous\ndecisions. We demonstrate the effectiveness of DPT-Agent through further\nexperiments with rule-based agents and human collaborators, showing significant\nimprovements over mainstream LLM-based frameworks. DPT-Agent can effectively\nhelp LLMs convert correct slow thinking and reasoning into executable actions,\nthereby improving performance. To the best of our knowledge, DPT-Agent is the\nfirst language agent framework that achieves successful real-time simultaneous\nhuman-AI collaboration autonomously. Code of DPT-Agent can be found in\nhttps://github.com/sjtu-marl/DPT-Agent.\n","authors":["Shao Zhang","Xihuai Wang","Wenhao Zhang","Chaoran Li","Junru Song","Tingyu Li","Lin Qiu","Xuezhi Cao","Xunliang Cai","Wen Yao","Weinan Zhang","Xinbing Wang","Ying Wen"],"pdf_url":"https://arxiv.org/pdf/2502.11882v3.pdf","comment":"Preprint under review. Update the experimental results of the\n  DeepSeek-R1 series models, o3-mini-high and o3-mini-medium"},{"id":"http://arxiv.org/abs/2502.18036v2","updated":"2025-03-02T16:56:04Z","published":"2025-02-25T09:48:53Z","title":"Harnessing Multiple Large Language Models: A Survey on LLM Ensemble","summary":"  LLM Ensemble -- which involves the comprehensive use of multiple large\nlanguage models (LLMs), each aimed at handling user queries during downstream\ninference, to benefit from their individual strengths -- has gained substantial\nattention recently. The widespread availability of LLMs, coupled with their\nvarying strengths and out-of-the-box usability, has profoundly advanced the\nfield of LLM Ensemble. This paper presents the first systematic review of\nrecent developments in LLM Ensemble. First, we introduce our taxonomy of LLM\nEnsemble and discuss several related research problems. Then, we provide a more\nin-depth classification of the methods under the broad categories of\n\"ensemble-before-inference, ensemble-during-inference,\nensemble-after-inference'', and review all relevant methods. Finally, we\nintroduce related benchmarks and applications, summarize existing studies, and\nsuggest several future research directions. A curated list of papers on LLM\nEnsemble is available at https://github.com/junchenzhi/Awesome-LLM-Ensemble.\n","authors":["Zhijun Chen","Jingzheng Li","Pengpeng Chen","Zhuoran Li","Kai Sun","Yuankai Luo","Qianren Mao","Dingqi Yang","Hailong Sun","Philip S. Yu"],"pdf_url":"https://arxiv.org/pdf/2502.18036v2.pdf","comment":"9 pages, 2 figures, codebase:\n  https://github.com/junchenzhi/Awesome-LLM-Ensemble"},{"id":"http://arxiv.org/abs/2502.06563v2","updated":"2025-03-02T16:38:28Z","published":"2025-02-10T15:31:54Z","title":"Large Language Models Meet Symbolic Provers for Logical Reasoning\n  Evaluation","summary":"  First-order logic (FOL) reasoning, which involves sequential deduction, is\npivotal for intelligent systems and serves as a valuable task for evaluating\nreasoning capabilities, particularly in chain-of-thought (CoT) contexts.\nExisting benchmarks often rely on extensive human annotation or handcrafted\ntemplates, making it difficult to achieve the necessary complexity,\nscalability, and diversity for robust evaluation. To address these limitations,\nwe propose a novel framework called ProverGen that synergizes the generative\nstrengths of Large Language Models (LLMs) with the rigor and precision of\nsymbolic provers, enabling the creation of a scalable, diverse, and\nhigh-quality FOL reasoning dataset, ProverQA. ProverQA is also distinguished by\nits inclusion of accessible and logically coherent intermediate reasoning steps\nfor each problem. Our evaluation shows that state-of-the-art LLMs struggle to\nsolve ProverQA problems, even with CoT prompting, highlighting the dataset's\nchallenging nature. We also finetune Llama3.1-8B-Instruct on a separate\ntraining set generated by our framework. The finetuned model demonstrates\nconsistent improvements on both in-distribution and out-of-distribution test\nsets, suggesting the value of our proposed data generation framework. Code\navailable at: https://github.com/opendatalab/ProverGen\n","authors":["Chengwen Qi","Ren Ma","Bowen Li","He Du","Binyuan Hui","Jinwang Wu","Yuanjun Laili","Conghui He"],"pdf_url":"https://arxiv.org/pdf/2502.06563v2.pdf","comment":"Accepted by ICLR 2025"},{"id":"http://arxiv.org/abs/2410.00812v2","updated":"2025-03-02T16:32:24Z","published":"2024-10-01T15:57:48Z","title":"Generative causal testing to bridge data-driven models and scientific\n  theories in language neuroscience","summary":"  Representations from large language models are highly effective at predicting\nBOLD fMRI responses to language stimuli. However, these representations are\nlargely opaque: it is unclear what features of the language stimulus drive the\nresponse in each brain area. We present generative causal testing (GCT), a\nframework for generating concise explanations of language selectivity in the\nbrain from predictive models and then testing those explanations in follow-up\nexperiments using LLM-generated stimuli.This approach is successful at\nexplaining selectivity both in individual voxels and cortical regions of\ninterest (ROIs), including newly identified microROIs in prefrontal cortex. We\nshow that explanatory accuracy is closely related to the predictive power and\nstability of the underlying predictive models. Finally, we show that GCT can\ndissect fine-grained differences between brain areas with similar functional\nselectivity. These results demonstrate that LLMs can be used to bridge the\nwidening gap between data-driven models and formal scientific theories.\n","authors":["Richard Antonello","Chandan Singh","Shailee Jain","Aliyah Hsu","Sihang Guo","Jianfeng Gao","Bin Yu","Alexander Huth"],"pdf_url":"https://arxiv.org/pdf/2410.00812v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2502.19412v2","updated":"2025-03-02T16:16:39Z","published":"2025-02-26T18:56:38Z","title":"The Mighty ToRR: A Benchmark for Table Reasoning and Robustness","summary":"  Despite its real-world significance, model performance on tabular data\nremains underexplored, leaving uncertainty about which model to rely on and\nwhich prompt configuration to adopt. To address this gap, we create ToRR, a\nbenchmark for Table Reasoning and Robustness, measuring model performance and\nrobustness on table-related tasks. The benchmark includes 10 datasets that\ncover different types of table reasoning capabilities across varied domains.\nToRR goes beyond model performance rankings, and is designed to reflect whether\nmodels can handle tabular data consistently and robustly, across a variety of\ncommon table representation formats. We present a leaderboard as well as\ncomprehensive analyses of the results of leading models over ToRR. Our results\nreveal a striking pattern of brittle model behavior, where even strong models\nare unable to perform robustly on tabular data tasks. Although no specific\ntable format leads to consistently better performance, we show that testing\nover multiple formats is crucial for reliably estimating model capabilities.\nMoreover, we show that the reliability boost from testing multiple prompts can\nbe equivalent to adding more test examples. Overall, our findings show that\ntable understanding and reasoning tasks remain a significant challenge.\n","authors":["Shir Ashury-Tahan","Yifan Mai","Rajmohan C","Ariel Gera","Yotam Perlitz","Asaf Yehudai","Elron Bandel","Leshem Choshen","Eyal Shnarch","Percy Liang","Michal Shmueli-Scheuer"],"pdf_url":"https://arxiv.org/pdf/2502.19412v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2501.03895v2","updated":"2025-03-02T15:55:07Z","published":"2025-01-07T16:03:14Z","title":"LLaVA-Mini: Efficient Image and Video Large Multimodal Models with One\n  Vision Token","summary":"  The advent of real-time large multimodal models (LMMs) like GPT-4o has\nsparked considerable interest in efficient LMMs. LMM frameworks typically\nencode visual inputs into vision tokens (continuous representations) and\nintegrate them and textual instructions into the context of large language\nmodels (LLMs), where large-scale parameters and numerous context tokens\n(predominantly vision tokens) result in substantial computational overhead.\nPrevious efforts towards efficient LMMs always focus on replacing the LLM\nbackbone with smaller models, while neglecting the crucial issue of token\nquantity. In this paper, we introduce LLaVA-Mini, an efficient LMM with minimal\nvision tokens. To achieve a high compression ratio of vision tokens while\npreserving visual information, we first analyze how LMMs understand vision\ntokens and find that most vision tokens only play a crucial role in the early\nlayers of LLM backbone, where they mainly fuse visual information into text\ntokens. Building on this finding, LLaVA-Mini introduces modality pre-fusion to\nfuse visual information into text tokens in advance, thereby facilitating the\nextreme compression of vision tokens fed to LLM backbone into one token.\nLLaVA-Mini is a unified large multimodal model that can support the\nunderstanding of images, high-resolution images, and videos in an efficient\nmanner. Experiments across 11 image-based and 7 video-based benchmarks\ndemonstrate that LLaVA-Mini outperforms LLaVA-v1.5 with just 1 vision token\ninstead of 576. Efficiency analyses reveal that LLaVA-Mini can reduce FLOPs by\n77%, deliver low-latency responses within 40 milliseconds, and process over\n10,000 frames of video on the GPU hardware with 24GB of memory.\n","authors":["Shaolei Zhang","Qingkai Fang","Zhe Yang","Yang Feng"],"pdf_url":"https://arxiv.org/pdf/2501.03895v2.pdf","comment":"Accepted to ICLR 2025. Code: https://github.com/ictnlp/LLaVA-Mini\n  Model: https://huggingface.co/ICTNLP/llava-mini-llama-3.1-8b"},{"id":"http://arxiv.org/abs/2410.03524v2","updated":"2025-03-02T15:54:11Z","published":"2024-10-04T15:44:47Z","title":"Steering Large Language Models between Code Execution and Textual\n  Reasoning","summary":"  While a lot of recent research focuses on enhancing the textual reasoning\ncapabilities of Large Language Models (LLMs) by optimizing the multi-agent\nframework or reasoning chains, several benchmark tasks can be solved with 100\\%\nsuccess through direct coding, which is more scalable and avoids the\ncomputational overhead associated with textual iterating and searching. Textual\nreasoning has inherent limitations in solving tasks with challenges in math,\nlogics, optimization, and searching, which is unlikely to be solved by simply\nscaling up the model and data size. The recently released OpenAI GPT Code\nInterpreter and multi-agent frameworks such as AutoGen have demonstrated\nremarkable proficiency of integrating code generation and execution to solve\ncomplex tasks using LLMs. However, based on our experiments on 7 existing\npopular methods for steering code/text generation in both single- and\nmulti-turn settings with 14 tasks and 6 types of LLMs (including the new\nO1-preview), currently there is no optimal method to correctly steer LLMs to\nwrite code when needed. We discover some interesting patterns on when models\nuse code vs. textual reasoning with the evolution to task complexity and model\nsizes, which even result in an astonishingly inverse scaling behavior. We also\ndiscover that results from LLM written code are not always better than using\ntextual reasoning, even if the task could be solved through code. To mitigate\nthe above issues, we propose three methods to better steer LLM code/text\ngeneration and achieve a notable improvement. The costs of token lengths and\nruntime are thoroughly discussed for all the methods. We believe the problem of\nsteering LLM code/text generation is critical for future research and has much\nspace for further improvement. Project Page, Datasets, and Codes are available\nat https://yongchao98.github.io/CodeSteer/.\n","authors":["Yongchao Chen","Harsh Jhamtani","Srinagesh Sharma","Chuchu Fan","Chi Wang"],"pdf_url":"https://arxiv.org/pdf/2410.03524v2.pdf","comment":"32 pages, 12 figures, 12 tables"},{"id":"http://arxiv.org/abs/2410.10781v2","updated":"2025-03-02T14:37:53Z","published":"2024-10-14T17:50:28Z","title":"When Attention Sink Emerges in Language Models: An Empirical View","summary":"  Language Models (LMs) assign significant attention to the first token, even\nif it is not semantically important, which is known as attention sink. This\nphenomenon has been widely adopted in applications such as streaming/long\ncontext generation, KV cache optimization, inference acceleration, model\nquantization, and others. Despite its widespread use, a deep understanding of\nattention sink in LMs is still lacking. In this work, we first demonstrate that\nattention sinks exist universally in LMs with various inputs, even in small\nmodels. Furthermore, attention sink is observed to emerge during the LM\npre-training, motivating us to investigate how optimization, data distribution,\nloss function, and model architecture in LM pre-training influence its\nemergence. We highlight that attention sink emerges after effective\noptimization on sufficient training data. The sink position is highly\ncorrelated with the loss function and data distribution. Most importantly, we\nfind that attention sink acts more like key biases, storing extra attention\nscores, which could be non-informative and not contribute to the value\ncomputation. We also observe that this phenomenon (at least partially) stems\nfrom tokens' inner dependence on attention scores as a result of softmax\nnormalization. After relaxing such dependence by replacing softmax attention\nwith other attention operations, such as sigmoid attention without\nnormalization, attention sinks do not emerge in LMs up to 1B parameters. The\ncode is available at https://github.com/sail-sg/Attention-Sink.\n","authors":["Xiangming Gu","Tianyu Pang","Chao Du","Qian Liu","Fengzhuo Zhang","Cunxiao Du","Ye Wang","Min Lin"],"pdf_url":"https://arxiv.org/pdf/2410.10781v2.pdf","comment":"ICLR 2025 (Spotlight)"},{"id":"http://arxiv.org/abs/2409.13555v2","updated":"2025-03-02T14:36:29Z","published":"2024-09-20T14:56:33Z","title":"Generating Visual Stories with Grounded and Coreferent Characters","summary":"  Characters are important in narratives. They move the plot forward, create\nemotional connections, and embody the story's themes. Visual storytelling\nmethods focus more on the plot and events relating to it, without building the\nnarrative around specific characters. As a result, the generated stories feel\ngeneric, with character mentions being absent, vague, or incorrect. To mitigate\nthese issues, we introduce the new task of character-centric story generation\nand present the first model capable of predicting visual stories with\nconsistently grounded and coreferent character mentions. Our model is finetuned\non a new dataset which we build on top of the widely used VIST benchmark.\nSpecifically, we develop an automated pipeline to enrich VIST with visual and\ntextual character coreference chains. We also propose new evaluation metrics to\nmeasure the richness of characters and coreference in stories. Experimental\nresults show that our model generates stories with recurring characters which\nare consistent and coreferent to larger extent compared to baselines and\nstate-of-the-art systems.\n","authors":["Danyang Liu","Mirella Lapata","Frank Keller"],"pdf_url":"https://arxiv.org/pdf/2409.13555v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.07137v2","updated":"2025-03-02T14:28:33Z","published":"2024-10-09T17:53:06Z","title":"Cheating Automatic LLM Benchmarks: Null Models Achieve High Win Rates","summary":"  Automatic LLM benchmarks, such as AlpacaEval 2.0, Arena-Hard-Auto, and\nMT-Bench, have become popular for evaluating language models due to their\ncost-effectiveness and scalability compared to human evaluation. Achieving high\nwin rates on these benchmarks can significantly boost the promotional impact of\nnewly released language models. This promotional benefit may motivate tricks,\nsuch as manipulating model output length or style to game win rates, even\nthough several mechanisms have been developed to control length and disentangle\nstyle to reduce gameability. Nonetheless, we show that even a \"null model\" that\nalways outputs a constant response (irrelevant to input instructions) can cheat\nautomatic benchmarks and achieve top-ranked win rates: an 86.5% LC win rate on\nAlpacaEval 2.0; an 83.0 score on Arena-Hard-Auto; and a 9.55 score on MT-Bench.\nMoreover, the crafted cheating outputs are transferable because we assume that\nthe instructions of these benchmarks (e.g., 805 samples of AlpacaEval 2.0) are\nprivate and cannot be accessed. While our experiments are primarily\nproof-of-concept, an adversary could use LLMs to generate more imperceptible\ncheating responses, unethically benefiting from high win rates and promotional\nimpact. Our findings call for the development of anti-cheating mechanisms for\nreliable automatic benchmarks. The code is available at\nhttps://github.com/sail-sg/Cheating-LLM-Benchmarks.\n","authors":["Xiaosen Zheng","Tianyu Pang","Chao Du","Qian Liu","Jing Jiang","Min Lin"],"pdf_url":"https://arxiv.org/pdf/2410.07137v2.pdf","comment":"ICLR 2025 (Oral)"},{"id":"http://arxiv.org/abs/2411.03962v4","updated":"2025-03-02T13:52:25Z","published":"2024-11-06T14:51:02Z","title":"How Does A Text Preprocessing Pipeline Affect Ontology Syntactic\n  Matching?","summary":"  The generic text preprocessing pipeline, comprising Tokenisation,\nNormalisation, Stop Words Removal, and Stemming/Lemmatisation, has been\nimplemented in many systems for syntactic ontology matching (OM). However, the\nlack of standardisation in text preprocessing creates diversity in mapping\nresults. In this paper, we investigate the effect of the text preprocessing\npipeline on syntactic OM in 8 Ontology Alignment Evaluation Initiative (OAEI)\ntracks with 49 distinct alignments. We find that Phase 1 text preprocessing\n(Tokenisation and Normalisation) is currently more effective than Phase 2 text\npreprocessing (Stop Words Removal and Stemming/Lemmatisation). To repair the\nless effective Phase 2 text preprocessing caused by unwanted false mappings, we\npropose a novel context-based pipeline repair approach that employs an ad hoc\ncheck to find common words that cause false mappings. These words are stored in\na reserved word set and applied in text preprocessing. The experimental results\nshow that our approach improves the matching correctness and the overall\nmatching performance. We also discuss the integration of the classical text\npreprocessing pipeline with modern large language models (LLMs). We recommend\nthat LLMs inject the text preprocessing pipeline via function calling to avoid\nthe tendency towards unstable true mappings produced by prompt-based LLM\napproaches, and use LLMs to repair false mappings generated by the text\npreprocessing pipeline.\n","authors":["Zhangcheng Qiang","Kerry Taylor","Weiqing Wang"],"pdf_url":"https://arxiv.org/pdf/2411.03962v4.pdf","comment":"13 pages, 11 figures, 4 tables"},{"id":"http://arxiv.org/abs/2406.15812v2","updated":"2025-03-02T12:28:24Z","published":"2024-06-22T10:36:04Z","title":"Intrinsic Dimension Correlation: uncovering nonlinear connections in\n  multimodal representations","summary":"  To gain insight into the mechanisms behind machine learning methods, it is\ncrucial to establish connections among the features describing data points.\nHowever, these correlations often exhibit a high-dimensional and strongly\nnonlinear nature, which makes them challenging to detect using standard\nmethods. This paper exploits the entanglement between intrinsic dimensionality\nand correlation to propose a metric that quantifies the (potentially nonlinear)\ncorrelation between high-dimensional manifolds. We first validate our method on\nsynthetic data in controlled environments, showcasing its advantages and\ndrawbacks compared to existing techniques. Subsequently, we extend our analysis\nto large-scale applications in neural network representations. Specifically, we\nfocus on latent representations of multimodal data, uncovering clear\ncorrelations between paired visual and textual embeddings, whereas existing\nmethods struggle significantly in detecting similarity. Our results indicate\nthe presence of highly nonlinear correlation patterns between latent manifolds.\n","authors":["Lorenzo Basile","Santiago Acevedo","Luca Bortolussi","Fabio Anselmi","Alex Rodriguez"],"pdf_url":"https://arxiv.org/pdf/2406.15812v2.pdf","comment":"Accepted at ICLR 2025"},{"id":"http://arxiv.org/abs/2405.01229v2","updated":"2025-03-02T12:27:07Z","published":"2024-05-02T12:18:14Z","title":"Boosting Jailbreak Attack with Momentum","summary":"  Large Language Models (LLMs) have achieved remarkable success across diverse\ntasks, yet they remain vulnerable to adversarial attacks, notably the\nwell-known jailbreak attack. In particular, the Greedy Coordinate Gradient\n(GCG) attack has demonstrated efficacy in exploiting this vulnerability by\noptimizing adversarial prompts through a combination of gradient heuristics and\ngreedy search. However, the efficiency of this attack has become a bottleneck\nin the attacking process. To mitigate this limitation, in this paper we rethink\nthe generation of the adversarial prompts through an optimization lens, aiming\nto stabilize the optimization process and harness more heuristic insights from\nprevious optimization iterations. Specifically, we propose the\n\\textbf{M}omentum \\textbf{A}ccelerated G\\textbf{C}G (\\textbf{MAC}) attack,\nwhich integrates a momentum term into the gradient heuristic to boost and\nstabilize the random search for tokens in adversarial prompts. Experimental\nresults showcase the notable enhancement achieved by MAC over baselines in\nterms of attack success rate and optimization efficiency. Moreover, we\ndemonstrate that MAC can still exhibit superior performance for transfer\nattacks and models under defense mechanisms. Our code is available at\nhttps://github.com/weizeming/momentum-attack-llm.\n","authors":["Yihao Zhang","Zeming Wei"],"pdf_url":"https://arxiv.org/pdf/2405.01229v2.pdf","comment":"Accepted by ICASSP 2025"},{"id":"http://arxiv.org/abs/2310.17953v4","updated":"2025-03-02T12:17:06Z","published":"2023-10-27T08:01:55Z","title":"Developing a Multilingual Dataset and Evaluation Metrics for\n  Code-Switching: A Focus on Hong Kong's Polylingual Dynamics","summary":"  The existing audio datasets are predominantly tailored towards single\nlanguages, overlooking the complex linguistic behaviors of multilingual\ncommunities that engage in code-switching. This practice, where individuals\nfrequently mix two or more languages in their daily interactions, is\nparticularly prevalent in multilingual regions such as Hong Kong, China. To\nbridge this gap, we have developed a 34.8-hour dataset of Mixed Cantonese and\nEnglish (MCE) audio using our Multi-Agent Data Generation Framework (MADGF). We\nfine-tuned the open-source multilingual Automatic Speech Recognition (ASR)\nmodel, Whisper, with the MCE dataset, leading to impressive zero-shot\nperformance. The traditional metrics overlook important factors such as latency\nin real-world applications and code-switching scenarios. We have introduced a\nnovel evaluation metric called Fidelity to the Original Audio, Accuracy, and\nLatency (FAL). This metric aims to overcome the limitations of traditional\nmetrics used to assess ASR systems.\n","authors":["Peng Xie","Kani Chen"],"pdf_url":"https://arxiv.org/pdf/2310.17953v4.pdf","comment":null},{"id":"http://arxiv.org/abs/2408.13940v3","updated":"2025-03-02T12:11:13Z","published":"2024-08-25T21:20:17Z","title":"Derailer-Rerailer: Adaptive Verification for Efficient and Reliable\n  Language Model Reasoning","summary":"  Large Language Models (LLMs) have shown impressive reasoning capabilities,\nyet existing prompting methods face a critical trade-off: simple approaches\noften struggle with complex tasks and reasoning stability, while more\nsophisticated methods require multiple inferences and substantial computational\nresources, limiting their practical deployment. To address this challenge, we\npropose Derailer-Rerailer, a novel framework that adaptively balances reasoning\naccuracy and computational efficiency. At its core, our framework employs a\nlightweight Derailer mechanism to assess reasoning stability and selectively\ntriggers an advanced Rerailer verification process only when necessary, thereby\noptimizing computational resource usage. Extensive evaluation across both open\nand closed-source models on more than 20 categories of mathematical, symbolic,\nand commonsense reasoning tasks demonstrates our framework's effectiveness:\nDerailer-Rerailer achieves significant accuracy improvements (8-11\\% across\nvarious reasoning tasks) while maintaining 2-3 times better efficiency than\nexisting verification methods, with particularly strong performance in\nmathematical and symbolic reasoning, offering a practical solution for\nenhancing LLM reasoning reliability while significantly reducing computational\noverhead.\n","authors":["Guangya Wan","Yuqi Wu","Hao Wang","Shengming Zhao","Jie Chen","Sheng Li"],"pdf_url":"https://arxiv.org/pdf/2408.13940v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2502.19649v2","updated":"2025-03-02T11:23:58Z","published":"2025-02-27T00:40:01Z","title":"Taxonomy, Opportunities, and Challenges of Representation Engineering\n  for Large Language Models","summary":"  Representation Engineering (RepE) is a novel paradigm for controlling the\nbehavior of LLMs. Unlike traditional approaches that modify inputs or fine-tune\nthe model, RepE directly manipulates the model's internal representations. As a\nresult, it may offer more effective, interpretable, data-efficient, and\nflexible control over models' behavior. We present the first comprehensive\nsurvey of RepE for LLMs, reviewing the rapidly growing literature to address\nkey questions: What RepE methods exist and how do they differ? For what\nconcepts and problems has RepE been applied? What are the strengths and\nweaknesses of RepE compared to other methods? To answer these, we propose a\nunified framework describing RepE as a pipeline comprising representation\nidentification, operationalization, and control. We posit that while RepE\nmethods offer significant potential, challenges remain, including managing\nmultiple concepts, ensuring reliability, and preserving models' performance.\nTowards improving RepE, we identify opportunities for experimental and\nmethodological improvements and construct a guide for best practices.\n","authors":["Jan Wehner","Sahar Abdelnabi","Daniel Tan","David Krueger","Mario Fritz"],"pdf_url":"https://arxiv.org/pdf/2502.19649v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.14666v2","updated":"2025-03-02T10:38:32Z","published":"2024-10-18T17:56:11Z","title":"DiscoGraMS: Enhancing Movie Screen-Play Summarization using Movie\n  Character-Aware Discourse Graph","summary":"  Summarizing movie screenplays presents a unique set of challenges compared to\nstandard document summarization. Screenplays are not only lengthy, but also\nfeature a complex interplay of characters, dialogues, and scenes, with numerous\ndirect and subtle relationships and contextual nuances that are difficult for\nmachine learning models to accurately capture and comprehend. Recent attempts\nat screenplay summarization focus on fine-tuning transformer-based pre-trained\nmodels, but these models often fall short in capturing long-term dependencies\nand latent relationships, and frequently encounter the \"lost in the middle\"\nissue. To address these challenges, we introduce DiscoGraMS, a novel resource\nthat represents movie scripts as a movie character-aware discourse graph (CaD\nGraph). This approach is well-suited for various downstream tasks, such as\nsummarization, question-answering, and salience detection. The model aims to\npreserve all salient information, offering a more comprehensive and faithful\nrepresentation of the screenplay's content. We further explore a baseline\nmethod that combines the CaD Graph with the corresponding movie script through\na late fusion of graph and text modalities, and we present very initial\npromising results.\n","authors":["Maitreya Prafulla Chitale","Uday Bindal","Rajakrishnan Rajkumar","Rahul Mishra"],"pdf_url":"https://arxiv.org/pdf/2410.14666v2.pdf","comment":"Accepted at NAACL 2025 (Main)"},{"id":"http://arxiv.org/abs/2502.14897v2","updated":"2025-03-02T10:18:09Z","published":"2025-02-17T21:35:18Z","title":"Market-Derived Financial Sentiment Analysis: Context-Aware Language\n  Models for Crypto Forecasting","summary":"  Financial Sentiment Analysis (FSA) traditionally relies on human-annotated\nsentiment labels to infer investor sentiment and forecast market movements.\nHowever, inferring the potential market impact of words based on their\nhuman-perceived intentions is inherently challenging. We hypothesize that the\nhistorical market reactions to words, offer a more reliable indicator of their\npotential impact on markets than subjective sentiment interpretations by human\nannotators. To test this hypothesis, a market-derived labeling approach is\nproposed to assign tweet labels based on ensuing short-term price trends,\nenabling the language model to capture the relationship between textual signals\nand market dynamics directly. A domain-specific language model was fine-tuned\non these labels, achieving up to an 11% improvement in short-term trend\nprediction accuracy over traditional sentiment-based benchmarks. Moreover, by\nincorporating market and temporal context through prompt-tuning, the proposed\ncontext-aware language model demonstrated an accuracy of 89.6% on a curated\ndataset of 227 impactful Bitcoin-related news events with significant market\nimpacts. Aggregating daily tweet predictions into trading signals, our method\noutperformed traditional fusion models (which combine sentiment-based and\nprice-based predictions). It challenged the assumption that sentiment-based\nsignals are inferior to price-based predictions in forecasting market\nmovements. Backtesting these signals across three distinct market regimes\nyielded robust Sharpe ratios of up to 5.07 in trending markets and 3.73 in\nneutral markets. Our findings demonstrate that language models can serve as\neffective short-term market predictors. This paradigm shift underscores the\nuntapped capabilities of language models in financial decision-making and opens\nnew avenues for market prediction applications.\n","authors":["Hamid Moradi-Kamali","Mohammad-Hossein Rajabi-Ghozlou","Mahdi Ghazavi","Ali Soltani","Amirreza Sattarzadeh","Reza Entezari-Maleki"],"pdf_url":"https://arxiv.org/pdf/2502.14897v2.pdf","comment":"13 pages, 6 figures"},{"id":"http://arxiv.org/abs/2408.10557v2","updated":"2025-03-02T09:59:36Z","published":"2024-08-20T05:45:04Z","title":"Speech Representation Learning Revisited: The Necessity of Separate\n  Learnable Parameters and Robust Data Augmentation","summary":"  Speech modeling methods learn one embedding for a fixed segment of speech,\ntypically in between 10-25 ms. The information present in speech can be divided\ninto two categories: \"what is being said\" (content) and \"how it is expressed\"\n(other) and these two are orthogonal in nature causing the optimization\nalgorithm to find a sub-optimal solution if forced to optimize together. This\nleads to sub-optimal performance in one or all downstream tasks as shown by\nprevious studies. Current self-supervised learning (SSL) methods such as HuBERT\nare very good at modeling the content information present in speech. Data\naugmentation improves the performance on tasks which require effective modeling\nof other information but this leads to a divided capacity of the model. In this\nwork, we conduct a preliminary study to understand the importance of modeling\nother information using separate learnable parameters. We propose a modified\nversion of HuBERT, termed Other HuBERT (O-HuBERT), to test our hypothesis. Our\nfindings are twofold: first, the O-HuBERT method is able to utilize all layers\nto build complex features to encode other information; second, a robust data\naugmentation strategy is essential for learning the information required by\ntasks that depend on other information and to achieve state-of-the-art (SOTA)\nperformance on the SUPERB benchmark with a similarly sized model (100 million\nparameters) and pre-training data (960 hours).\n","authors":["Hemant Yadav","Sunayana Sitaram","Rajiv Ratn Shah"],"pdf_url":"https://arxiv.org/pdf/2408.10557v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2402.04236v3","updated":"2025-03-02T09:39:57Z","published":"2024-02-06T18:43:48Z","title":"CogCoM: A Visual Language Model with Chain-of-Manipulations Reasoning","summary":"  Vision-Language Models (VLMs) have demonstrated their broad effectiveness\nthanks to extensive training in aligning visual instructions to responses.\nHowever, such training of conclusive alignment leads models to ignore essential\nvisual reasoning, further resulting in failures in meticulous visual problems\nand unfaithful responses. Drawing inspiration from human cognition in solving\nvisual problems (e.g., marking, zoom in), this paper introduces Chain of\nManipulations, a mechanism that enables VLMs to solve problems step-by-step\nwith evidence. After training, models can solve various visual problems by\neliciting intrinsic manipulations (e.g., grounding, zoom in) with results\n(e.g., boxes, image) actively without involving external tools, while also\nallowing users to trace error causes. We study the roadmap to implement this\nmechanism, including (1) a flexible design of manipulations upon extensive\nanalysis, (2) an efficient automated data generation pipeline, (3) a compatible\nVLM architecture capable of multi-turn multi-image, and (4) a model training\nprocess for versatile capabilities. With the design, we also manually annotate\n6K high-quality samples for the challenging graphical mathematical problems.\nOur trained model, \\textbf{CogCoM}, equipped with this mechanism with 17B\nparameters achieves state-of-the-art performance across 9 benchmarks from 4\ncategories, demonstrating the effectiveness while preserving the\ninterpretability. Our code, model weights, and collected data are publicly\navailable at https://github.com/THUDM/CogCoM.\n","authors":["Ji Qi","Ming Ding","Weihan Wang","Yushi Bai","Qingsong Lv","Wenyi Hong","Bin Xu","Lei Hou","Juanzi Li","Yuxiao Dong","Jie Tang"],"pdf_url":"https://arxiv.org/pdf/2402.04236v3.pdf","comment":"21 pages, 10 figures"},{"id":"http://arxiv.org/abs/2412.02956v2","updated":"2025-03-02T09:35:28Z","published":"2024-12-04T02:05:21Z","title":"Curriculum-style Data Augmentation for LLM-based Metaphor Detection","summary":"  Recently, utilizing large language models (LLMs) for metaphor detection has\nachieved promising results. However, these methods heavily rely on the\ncapabilities of closed-source LLMs, which come with relatively high inference\ncosts and latency. To address this, we propose a method for metaphor detection\nby fine-tuning open-source LLMs, effectively reducing inference costs and\nlatency with a single inference step. Furthermore, metaphor detection suffers\nfrom a severe data scarcity problem, which hinders effective fine-tuning of\nLLMs. To tackle this, we introduce Curriculum-style Data Augmentation (CDA).\nSpecifically, before fine-tuning, we evaluate the training data to identify\ncorrectly predicted instances for fine-tuning, while incorrectly predicted\ninstances are used as seed data for data augmentation. This approach enables\nthe model to quickly learn simpler knowledge and progressively acquire more\ncomplex knowledge, thereby improving performance incrementally. Experimental\nresults demonstrate that our method achieves state-of-the-art performance\nacross all baselines. Additionally, we provide detailed ablation studies to\nvalidate the effectiveness of CDA.\n","authors":["Kaidi Jia","Yanxia Wu","Ming Liu","Rongsheng Li"],"pdf_url":"https://arxiv.org/pdf/2412.02956v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.23771v2","updated":"2025-03-02T09:23:18Z","published":"2024-10-31T09:39:28Z","title":"What is Wrong with Perplexity for Long-context Language Modeling?","summary":"  Handling long-context inputs is crucial for large language models (LLMs) in\ntasks such as extended conversations, document summarization, and many-shot\nin-context learning. While recent approaches have extended the context windows\nof LLMs and employed perplexity (PPL) as a standard evaluation metric, PPL has\nproven unreliable for assessing long-context capabilities. The underlying cause\nof this limitation has remained unclear. In this work, we provide a\ncomprehensive explanation for this issue. We find that PPL overlooks key\ntokens, which are essential for long-context understanding, by averaging across\nall tokens and thereby obscuring the true performance of models in long-context\nscenarios. To address this, we propose \\textbf{LongPPL}, a novel metric that\nfocuses on key tokens by employing a long-short context contrastive method to\nidentify them. Our experiments demonstrate that LongPPL strongly correlates\nwith performance on various long-context benchmarks (e.g., Pearson correlation\nof -0.96), significantly outperforming traditional PPL in predictive accuracy.\nAdditionally, we introduce \\textbf{LongCE} (Long-context Cross-Entropy) loss, a\nre-weighting strategy for fine-tuning that prioritizes key tokens, leading to\nconsistent improvements across diverse benchmarks. In summary, these\ncontributions offer deeper insights into the limitations of PPL and present\neffective solutions for accurately evaluating and enhancing the long-context\ncapabilities of LLMs. Code is available at https://github.com/PKU-ML/LongPPL.\n","authors":["Lizhe Fang","Yifei Wang","Zhaoyang Liu","Chenheng Zhang","Stefanie Jegelka","Jinyang Gao","Bolin Ding","Yisen Wang"],"pdf_url":"https://arxiv.org/pdf/2410.23771v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.07168v2","updated":"2025-03-02T09:16:05Z","published":"2024-10-09T17:59:04Z","title":"Sylber: Syllabic Embedding Representation of Speech from Raw Audio","summary":"  Syllables are compositional units of spoken language that efficiently\nstructure human speech perception and production. However, current neural\nspeech representations lack such structure, resulting in dense token sequences\nthat are costly to process. To bridge this gap, we propose a new model, Sylber,\nthat produces speech representations with clean and robust syllabic structure.\nSpecifically, we propose a self-supervised learning (SSL) framework that\nbootstraps syllabic embeddings by distilling from its own initial unsupervised\nsyllabic segmentation. This results in a highly structured representation of\nspeech features, offering three key benefits: 1) a fast, linear-time syllable\nsegmentation algorithm, 2) efficient syllabic tokenization with an average of\n4.27 tokens per second, and 3) novel phonological units suited for efficient\nspoken language modeling. Our proposed segmentation method is highly robust and\ngeneralizes to out-of-domain data and unseen languages without any tuning. By\ntraining token-to-speech generative models, fully intelligible speech can be\nreconstructed from Sylber tokens with a significantly lower bitrate than\nbaseline SSL tokens. This suggests that our model effectively compresses speech\ninto a compact sequence of tokens with minimal information loss. Lastly, we\ndemonstrate that categorical perception-a linguistic phenomenon in speech\nperception-emerges naturally in Sylber, making the embedding space more\ncategorical and sparse than previous speech features and thus supporting the\nhigh efficiency of our tokenization. Together, we present a novel SSL approach\nfor representing speech as syllables, with significant potential for efficient\nspeech tokenization and spoken language modeling.\n","authors":["Cheol Jun Cho","Nicholas Lee","Akshat Gupta","Dhruv Agarwal","Ethan Chen","Alan W Black","Gopala K. Anumanchipalli"],"pdf_url":"https://arxiv.org/pdf/2410.07168v2.pdf","comment":"Accepted at ICLR 2025"},{"id":"http://arxiv.org/abs/2409.01281v2","updated":"2025-03-02T09:13:56Z","published":"2024-08-25T01:45:53Z","title":"Path-Consistency: Prefix Enhancement for Efficient Inference in LLM","summary":"  To enhance the reasoning capabilities of large language models (LLMs),\nself-consistency has gained significant popularity by combining multiple\nsampling with majority voting. However, the state-of-the-art self-consistency\napproaches consume substantial computational resources and lead to significant\nadditional time costs due to the multiple sampling. This prevents its full\npotential from being realized in scenarios where computational resources are\ncritical. To improve the inference efficiency, this paper introduces\n\\textit{path-consistency}, a method that leverages the confidence of answers\ngenerated in earlier branches to identify the prefix of the most promising\npath. By dynamically guiding the generation of subsequent branches based on\nthis prefix, the \\textit{path-consistency} mitigates both the errors and\nredundancies from random or less useful sampling in self-consistency. As a\nresult, it can significantly accelerate the inference process by reducing the\nnumber of tokens generated. Our extensive empirical evaluation shows that the\n\\textit{path-consistency} achieves significant acceleration in inference\nlatency ranging from $7.8\\%$ to $40.5\\%$, while maintaining or even improving\ntask accuracy across different datasets, including mathematical reasoning,\ncommon sense reasoning, symbolic reasoning, and code generation.\n","authors":["Jiace Zhu","Yingtao Shen","Jie Zhao","An Zou"],"pdf_url":"https://arxiv.org/pdf/2409.01281v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2501.06751v2","updated":"2025-03-02T09:10:13Z","published":"2025-01-12T08:36:38Z","title":"Padding Tone: A Mechanistic Analysis of Padding Tokens in T2I Models","summary":"  Text-to-image (T2I) diffusion models rely on encoded prompts to guide the\nimage generation process. Typically, these prompts are extended to a fixed\nlength by adding padding tokens before text encoding. Despite being a default\npractice, the influence of padding tokens on the image generation process has\nnot been investigated. In this work, we conduct the first in-depth analysis of\nthe role padding tokens play in T2I models. We develop two causal techniques to\nanalyze how information is encoded in the representation of tokens across\ndifferent components of the T2I pipeline. Using these techniques, we\ninvestigate when and how padding tokens impact the image generation process.\nOur findings reveal three distinct scenarios: padding tokens may affect the\nmodel's output during text encoding, during the diffusion process, or be\neffectively ignored. Moreover, we identify key relationships between these\nscenarios and the model's architecture (cross or self-attention) and its\ntraining process (frozen or trained text encoder). These insights contribute to\na deeper understanding of the mechanisms of padding tokens, potentially\ninforming future model design and training practices in T2I systems.\n","authors":["Michael Toker","Ido Galil","Hadas Orgad","Rinon Gal","Yoad Tewel","Gal Chechik","Yonatan Belinkov"],"pdf_url":"https://arxiv.org/pdf/2501.06751v2.pdf","comment":"Published in: NAACL 2025. Project webpage:\n  https://padding-tone.github.io/"},{"id":"http://arxiv.org/abs/2408.02976v3","updated":"2025-03-02T08:30:58Z","published":"2024-08-06T06:16:00Z","title":"Empathy Level Alignment via Reinforcement Learning for Empathetic\n  Response Generation","summary":"  Empathetic response generation, aiming to understand the user's situation and\nfeelings and respond empathically, is crucial in building human-like dialogue\nsystems. Traditional approaches typically employ maximum likelihood estimation\nas the optimization objective during training, yet fail to align the empathy\nlevels between generated and target responses. To this end, we propose an\nempathetic response generation framework using reinforcement learning (EmpRL).\nThe framework develops an effective empathy reward function and generates\nempathetic responses by maximizing the expected reward through reinforcement\nlearning. EmpRL utilizes the pre-trained T5 model as the generator and further\nfine-tunes it to initialize the policy. To align the empathy levels between\ngenerated and target responses within a given context, an empathy reward\nfunction containing three empathy communication mechanisms -- emotional\nreaction, interpretation, and exploration -- is constructed using pre-designed\nand pre-trained empathy identifiers. During reinforcement learning training,\nthe proximal policy optimization algorithm is used to fine-tune the policy,\nenabling the generation of empathetic responses. Both automatic and human\nevaluations demonstrate that the proposed EmpRL framework significantly\nimproves the quality of generated responses, enhances the similarity in empathy\nlevels between generated and target responses, and produces empathetic\nresponses covering both affective and cognitive aspects.\n","authors":["Hui Ma","Bo Zhang","Bo Xu","Jian Wang","Hongfei Lin","Xiao Sun"],"pdf_url":"https://arxiv.org/pdf/2408.02976v3.pdf","comment":"Accepted by IEEE Transactions on Affective Computing"},{"id":"http://arxiv.org/abs/2407.00886v3","updated":"2025-03-02T08:26:23Z","published":"2024-07-01T01:12:20Z","title":"Efficient Automated Circuit Discovery in Transformers using Contextual\n  Decomposition","summary":"  Automated mechanistic interpretation research has attracted great interest\ndue to its potential to scale explanations of neural network internals to large\nmodels. Existing automated circuit discovery work relies on activation patching\nor its approximations to identify subgraphs in models for specific tasks\n(circuits). They often suffer from slow runtime, approximation errors, and\nspecific requirements of metrics, such as non-zero gradients. In this work, we\nintroduce contextual decomposition for transformers (CD-T) to build\ninterpretable circuits in large language models. CD-T can produce circuits of\narbitrary level of abstraction, and is the first able to produce circuits as\nfine-grained as attention heads at specific sequence positions efficiently.\nCD-T consists of a set of mathematical equations to isolate contribution of\nmodel features. Through recursively computing contribution of all nodes in a\ncomputational graph of a model using CD-T followed by pruning, we are able to\nreduce circuit discovery runtime from hours to seconds compared to\nstate-of-the-art baselines. On three standard circuit evaluation datasets\n(indirect object identification, greater-than comparisons, and docstring\ncompletion), we demonstrate that CD-T outperforms ACDC and EAP by better\nrecovering the manual circuits with an average of 97% ROC AUC under low\nruntimes. In addition, we provide evidence that faithfulness of CD-T circuits\nis not due to random chance by showing our circuits are 80% more faithful than\nrandom circuits of up to 60% of the original model size. Finally, we show CD-T\ncircuits are able to perfectly replicate original models' behavior\n(faithfulness $ = 1$) using fewer nodes than the baselines for all tasks. Our\nresults underscore the great promise of CD-T for efficient automated\nmechanistic interpretability, paving the way for new insights into the workings\nof large language models.\n","authors":["Aliyah R. Hsu","Georgia Zhou","Yeshwanth Cherapanamjeri","Yaxuan Huang","Anobel Y. Odisho","Peter R. Carroll","Bin Yu"],"pdf_url":"https://arxiv.org/pdf/2407.00886v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2502.09097v2","updated":"2025-03-02T07:58:08Z","published":"2025-02-13T09:13:23Z","title":"A Hybrid Transformer Model for Fake News Detection: Leveraging Bayesian\n  Optimization and Bidirectional Recurrent Unit","summary":"  In this paper, we propose an optimized Transformer model that integrates\nBayesian algorithms with a Bidirectional Gated Recurrent Unit (BiGRU), and\napply it to fake news classification for the first time. First, we employ the\nTF-IDF method to extract features from news texts and transform them into\nnumeric representations to facilitate subsequent machine learning tasks. Two\nsets of experiments are then conducted for fake news detection and\nclassification: one using a Transformer model optimized only with BiGRU, and\nthe other incorporating Bayesian algorithms into the BiGRU-based Transformer.\nExperimental results show that the BiGRU-optimized Transformer achieves 100%\naccuracy on the training set and 99.67% on the test set, while the addition of\nthe Bayesian algorithm maintains 100% accuracy on the training set and slightly\nimproves test-set accuracy to 99.73%. This indicates that the Bayesian\nalgorithm boosts model accuracy by 0.06%, further enhancing the detection\ncapability for fake news. Moreover, the proposed algorithm converges rapidly at\naround the 10th training epoch with accuracy nearing 100%, demonstrating both\nits effectiveness and its fast classification ability. Overall, the optimized\nTransformer model, enhanced by the Bayesian algorithm and BiGRU, exhibits\nexcellent continuous learning and detection performance, offering a robust\ntechnical means to combat the spread of fake news in the current era of\ninformation overload.\n","authors":["Tianyi Huang","Zeqiu Xu","Peiyang Yu","Jingyuan Yi","Xiaochuan Xu"],"pdf_url":"https://arxiv.org/pdf/2502.09097v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.13757v2","updated":"2025-03-02T07:34:35Z","published":"2024-10-17T16:53:50Z","title":"MobA: Multifaceted Memory-Enhanced Adaptive Planning for Efficient\n  Mobile Task Automation","summary":"  Existing Multimodal Large Language Model (MLLM)-based agents face significant\nchallenges in handling complex GUI (Graphical User Interface) interactions on\ndevices. These challenges arise from the dynamic and structured nature of GUI\nenvironments, which integrate text, images, and spatial relationships, as well\nas the variability in action spaces across different pages and tasks. To\naddress these limitations, we propose MobA, a novel MLLM-based mobile assistant\nsystem. MobA introduces an adaptive planning module that incorporates a\nreflection mechanism for error recovery and dynamically adjusts plans to align\nwith the real environment contexts and action module's execution capacity.\nAdditionally, a multifaceted memory module provides comprehensive memory\nsupport to enhance adaptability and efficiency. We also present MobBench, a\ndataset designed for complex mobile interactions. Experimental results on\nMobBench and AndroidArena demonstrate MobA's ability to handle dynamic GUI\nenvironments and perform complex mobile task.\n","authors":["Zichen Zhu","Hao Tang","Yansi Li","Dingye Liu","Hongshen Xu","Kunyao Lan","Danyang Zhang","Yixuan Jiang","Hao Zhou","Chenrun Wang","Situo Zhang","Liangtai Sun","Yixiao Wang","Yuheng Sun","Lu Chen","Kai Yu"],"pdf_url":"https://arxiv.org/pdf/2410.13757v2.pdf","comment":"NAACL 2025 Demo Track"},{"id":"http://arxiv.org/abs/2501.14294v3","updated":"2025-03-02T06:49:21Z","published":"2025-01-24T07:24:23Z","title":"Examining Alignment of Large Language Models through Representative\n  Heuristics: The Case of Political Stereotypes","summary":"  Examining the alignment of large language models (LLMs) has become\nincreasingly important, e.g., when LLMs fail to operate as intended. This study\nexamines the alignment of LLMs with human values for the domain of politics.\nPrior research has shown that LLM-generated outputs can include political\nleanings and mimic the stances of political parties on various issues. However,\nthe extent and conditions under which LLMs deviate from empirical positions are\ninsufficiently examined. To address this gap, we analyze the factors that\ncontribute to LLMs' deviations from empirical positions on political issues,\naiming to quantify these deviations and identify the conditions that cause\nthem.\n  Drawing on findings from cognitive science about representativeness\nheuristics, i.e., situations where humans lean on representative attributes of\na target group in a way that leads to exaggerated beliefs, we scrutinize LLM\nresponses through this heuristics' lens. We conduct experiments to determine\nhow LLMs inflate predictions about political parties, which results in\nstereotyping. We find that while LLMs can mimic certain political parties'\npositions, they often exaggerate these positions more than human survey\nrespondents do. Also, LLMs tend to overemphasize representativeness more than\nhumans. This study highlights the susceptibility of LLMs to representativeness\nheuristics, suggesting a potential vulnerability of LLMs that facilitates\npolitical stereotyping. We also test prompt-based mitigation strategies,\nfinding that strategies that can mitigate representative heuristics in humans\nare also effective in reducing the influence of representativeness on\nLLM-generated responses.\n","authors":["Sullam Jeoung","Yubin Ge","Haohan Wang","Jana Diesner"],"pdf_url":"https://arxiv.org/pdf/2501.14294v3.pdf","comment":"ICLR 2025"},{"id":"http://arxiv.org/abs/2502.17924v2","updated":"2025-03-02T06:46:48Z","published":"2025-02-25T07:44:22Z","title":"FACT-AUDIT: An Adaptive Multi-Agent Framework for Dynamic Fact-Checking\n  Evaluation of Large Language Models","summary":"  Large Language Models (LLMs) have significantly advanced the fact-checking\nstudies. However, existing automated fact-checking evaluation methods rely on\nstatic datasets and classification metrics, which fail to automatically\nevaluate the justification production and uncover the nuanced limitations of\nLLMs in fact-checking. In this work, we introduce FACT-AUDIT, an agent-driven\nframework that adaptively and dynamically assesses LLMs' fact-checking\ncapabilities. Leveraging importance sampling principles and multi-agent\ncollaboration, FACT-AUDIT generates adaptive and scalable datasets, performs\niterative model-centric evaluations, and updates assessments based on\nmodel-specific responses. By incorporating justification production alongside\nverdict prediction, this framework provides a comprehensive and evolving audit\nof LLMs' factual reasoning capabilities, to investigate their trustworthiness.\nExtensive experiments demonstrate that FACT-AUDIT effectively differentiates\namong state-of-the-art LLMs, providing valuable insights into model strengths\nand limitations in model-centric fact-checking analysis.\n","authors":["Hongzhan Lin","Yang Deng","Yuxuan Gu","Wenxuan Zhang","Jing Ma","See-Kiong Ng","Tat-Seng Chua"],"pdf_url":"https://arxiv.org/pdf/2502.17924v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2405.19425v3","updated":"2025-03-02T06:36:57Z","published":"2024-05-29T18:08:37Z","title":"Adaptive In-conversation Team Building for Language Model Agents","summary":"  Leveraging multiple large language model (LLM) agents has shown to be a\npromising approach for tackling complex tasks, while the effective design of\nmultiple agents for a particular application remains an art. It is thus\nintriguing to answer a critical question: Given a task, how can we build a team\nof LLM agents to solve it effectively? Our new adaptive team-building paradigm\noffers a flexible solution, realized through a novel agent design named Captain\nAgent. It dynamically forms and manages teams for each step of a task-solving\nprocess, utilizing nested group conversations and reflection to ensure diverse\nexpertise and prevent stereotypical outputs, allowing for a flexible yet\nstructured approach to problem-solving. A comprehensive evaluation across six\nreal-world scenarios demonstrates that Captain Agent significantly outperforms\nexisting multi-agent methods with 21.94% improvement in average accuracy,\nproviding outstanding performance without requiring task-specific prompt\nengineering. Our exploration of different backbone LLM and cost analysis\nfurther shows that Captain Agent can improve the conversation quality of weak\nLLM and achieve competitive performance with extremely low cost, which\nilluminates the application of multi-agent systems.\n","authors":["Linxin Song","Jiale Liu","Jieyu Zhang","Shaokun Zhang","Ao Luo","Shijian Wang","Qingyun Wu","Chi Wang"],"pdf_url":"https://arxiv.org/pdf/2405.19425v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2407.01902v2","updated":"2025-03-02T06:28:59Z","published":"2024-07-02T02:58:29Z","title":"SeqAR: Jailbreak LLMs with Sequential Auto-Generated Characters","summary":"  The widespread applications of large language models (LLMs) have brought\nabout concerns regarding their potential misuse. Although aligned with human\npreference data before release, LLMs remain vulnerable to various malicious\nattacks. In this paper, we adopt a red-teaming strategy to enhance LLM safety\nand introduce SeqAR, a simple yet effective framework to design jailbreak\nprompts automatically. The SeqAR framework generates and optimizes multiple\njailbreak characters and then applies sequential jailbreak characters in a\nsingle query to bypass the guardrails of the target LLM. Different from\nprevious work which relies on proprietary LLMs or seed jailbreak templates\ncrafted by human expertise, SeqAR can generate and optimize the jailbreak\nprompt in a cold-start scenario using open-sourced LLMs without any seed\njailbreak templates. Experimental results show that SeqAR achieves attack\nsuccess rates of 88% and 60% in bypassing the safety alignment of GPT-3.5-1106\nand GPT-4, respectively. Furthermore, we extensively evaluate the\ntransferability of the generated templates across different LLMs and held-out\nmalicious requests, while also exploring defense strategies against the\njailbreak attack designed by SeqAR.\n","authors":["Yan Yang","Zeguan Xiao","Xin Lu","Hongru Wang","Xuetao Wei","Hailiang Huang","Guanhua Chen","Yun Chen"],"pdf_url":"https://arxiv.org/pdf/2407.01902v2.pdf","comment":"Accepted by NAACL 2025"},{"id":"http://arxiv.org/abs/2410.07672v2","updated":"2025-03-02T06:25:14Z","published":"2024-10-10T07:29:35Z","title":"MACPO: Weak-to-Strong Alignment via Multi-Agent Contrastive Preference\n  Optimization","summary":"  As large language models (LLMs) are rapidly advancing and achieving\nnear-human capabilities on specific tasks, aligning them with human values is\nbecoming more urgent. In scenarios where LLMs outperform humans, we face a\nweak-to-strong alignment problem where we need to effectively align strong\nstudent LLMs through weak supervision generated by weak teachers. Existing\nalignment methods mainly focus on strong-to-weak alignment and self-alignment\nsettings, and it is impractical to adapt them to the much harder weak-to-strong\nalignment setting. To fill this gap, we propose a multi-agent contrastive\npreference optimization (MACPO) framework. MACPO facilitates weak teachers and\nstrong students to learn from each other by iteratively reinforcing unfamiliar\npositive behaviors while penalizing familiar negative ones. To get this, we\ndevise a mutual positive behavior augmentation strategy to encourage weak\nteachers and strong students to learn from each other's positive behavior and\nfurther provide higher quality positive behavior for the next iteration.\nAdditionally, we propose a hard negative behavior construction strategy to\ninduce weak teachers and strong students to generate familiar negative behavior\nby fine-tuning on negative behavioral data. Experimental results on the HH-RLHF\nand PKU-SafeRLHF datasets, evaluated using both automatic metrics and human\njudgments, demonstrate that MACPO simultaneously improves the alignment\nperformance of strong students and weak teachers. Moreover, as the number of\nweak teachers increases, MACPO achieves better weak-to-strong alignment\nperformance through more iteration optimization rounds.\n","authors":["Yougang Lyu","Lingyong Yan","Zihan Wang","Dawei Yin","Pengjie Ren","Maarten de Rijke","Zhaochun Ren"],"pdf_url":"https://arxiv.org/pdf/2410.07672v2.pdf","comment":"ICLR 2025"},{"id":"http://arxiv.org/abs/2410.03115v2","updated":"2025-03-02T05:16:38Z","published":"2024-10-04T03:17:27Z","title":"X-ALMA: Plug & Play Modules and Adaptive Rejection for Quality\n  Translation at Scale","summary":"  Large language models (LLMs) have achieved remarkable success across various\nNLP tasks with a focus on English due to English-centric pre-training and\nlimited multilingual data. In this work, we focus on the problem of\ntranslation, and while some multilingual LLMs claim to support for hundreds of\nlanguages, models often fail to provide high-quality responses for mid- and\nlow-resource languages, leading to imbalanced performance heavily skewed in\nfavor of high-resource languages. We introduce **X-ALMA**, a model designed to\nensure top-tier performance across 50 diverse languages, regardless of their\nresource levels. X-ALMA surpasses state-of-the-art open-source multilingual\nLLMs, such as Aya-101 and Aya-23, in every single translation direction on the\nFLORES-200 and WMT'23 test datasets according to COMET-22. This is achieved by\nplug-and-play language-specific module architecture to prevent language\nconflicts during training and a carefully designed training regimen with novel\noptimization methods to maximize the translation performance. After the final\nstage of training regimen, our proposed **A**daptive **R**ejection\n**P**reference **O**ptimization (**ARPO**) surpasses existing preference\noptimization methods in translation tasks.\n","authors":["Haoran Xu","Kenton Murray","Philipp Koehn","Hieu Hoang","Akiko Eriguchi","Huda Khayrallah"],"pdf_url":"https://arxiv.org/pdf/2410.03115v2.pdf","comment":"Published as a conference paper at ICLR 2025 (spotlight)"},{"id":"http://arxiv.org/abs/2406.09044v3","updated":"2025-03-02T04:45:56Z","published":"2024-06-13T12:30:02Z","title":"MiLoRA: Harnessing Minor Singular Components for Parameter-Efficient LLM\n  Finetuning","summary":"  Efficient finetuning of large language models (LLMs) aims to adapt the LLMs\nwith reduced computational and memory cost. Previous LoRA-based approaches\ninitialize the low-rank matrices with Gaussian distribution and zero values\nwhile keeping the original weight matrices frozen. However, the trainable model\nparameters optimized in an unguided subspace might interfere with the\nwell-learned subspace of the pretrained weight matrices. In this paper, we\npropose MiLoRA, a simple yet effective LLM finetuning approach that only\nupdates the minor singular components of the weight matrix while keeping the\nprincipal singular components frozen. It is observed that the minor matrix\ncorresponds to the noisy or long-tail information, while the principal matrix\ncontains important knowledge. The MiLoRA initializes the low-rank matrices\nwithin a subspace that is orthogonal to the principal matrix, thus the\npretrained knowledge is expected to be well preserved. During finetuning,\nMiLoRA makes the most use of the less-optimized subspace for learning the\nlabeled dataset. Extensive experiments on commonsense reasoning, math\nreasoning, instruction following and visual instruction following benchmarks\npresent the superior performance of our method.\n","authors":["Hanqing Wang","Yixia Li","Shuo Wang","Guanhua Chen","Yun Chen"],"pdf_url":"https://arxiv.org/pdf/2406.09044v3.pdf","comment":"This paper has been accepted at NAACL 2025. Code is available at:\n  https://github.com/sufenlp/MiLoRA"},{"id":"http://arxiv.org/abs/2410.21533v2","updated":"2025-03-02T04:39:42Z","published":"2024-10-28T21:02:13Z","title":"L3Ms -- Lagrange Large Language Models","summary":"  Supervised fine-tuning (SFT) and alignment of large language models (LLMs)\nare key steps in providing a good user experience. However, the concept of an\nappropriate alignment is inherently application-dependent, and current methods\noften rely on heuristic choices to drive optimization. In this work, we\nformulate SFT and alignment as a constrained optimization problem: the LLM is\nfine-tuned on a task while being required to meet application-specific\nrequirements, without resorting to heuristics. To solve this, we propose\nLagrange Large Language Models (L3Ms), which employ logarithmic barriers to\nenforce the constraints. This approach allows for the customization of L3Ms\nacross diverse applications while avoiding heuristic-driven processes. We\nexperimentally demonstrate the versatility and efficacy of L3Ms in achieving\ntailored alignments for various applications.\n","authors":["Guneet S. Dhillon","Xingjian Shi","Yee Whye Teh","Alex Smola"],"pdf_url":"https://arxiv.org/pdf/2410.21533v2.pdf","comment":"International Conference on Learning Representations (ICLR), 2025"},{"id":"http://arxiv.org/abs/2502.10709v2","updated":"2025-03-02T04:37:08Z","published":"2025-02-15T07:45:20Z","title":"An Empirical Analysis of Uncertainty in Large Language Model Evaluations","summary":"  As LLM-as-a-Judge emerges as a new paradigm for assessing large language\nmodels (LLMs), concerns have been raised regarding the alignment, bias, and\nstability of LLM evaluators. While substantial work has focused on alignment\nand bias, little research has concentrated on the stability of LLM evaluators.\nIn this paper, we conduct extensive experiments involving 9 widely used LLM\nevaluators across 2 different evaluation settings to investigate the\nuncertainty in model-based LLM evaluations. We pinpoint that LLM evaluators\nexhibit varying uncertainty based on model families and sizes. With careful\ncomparative analyses, we find that employing special prompting strategies,\nwhether during inference or post-training, can alleviate evaluation uncertainty\nto some extent. By utilizing uncertainty to enhance LLM's reliability and\ndetection capability in Out-Of-Distribution (OOD) data, we further fine-tune an\nuncertainty-aware LLM evaluator named ConfiLM using a human-annotated\nfine-tuning set and assess ConfiLM's OOD evaluation ability on a manually\ndesigned test set sourced from the 2024 Olympics. Experimental results\ndemonstrate that incorporating uncertainty as additional information during the\nfine-tuning phase can largely improve the model's evaluation performance in OOD\nscenarios. The code and data are released at:\nhttps://github.com/hasakiXie123/LLM-Evaluator-Uncertainty.\n","authors":["Qiujie Xie","Qingqiu Li","Zhuohao Yu","Yuejie Zhang","Yue Zhang","Linyi Yang"],"pdf_url":"https://arxiv.org/pdf/2502.10709v2.pdf","comment":"ICLR 2025"},{"id":"http://arxiv.org/abs/2308.11432v7","updated":"2025-03-02T04:04:03Z","published":"2023-08-22T13:30:37Z","title":"A Survey on Large Language Model based Autonomous Agents","summary":"  Autonomous agents have long been a prominent research focus in both academic\nand industry communities. Previous research in this field often focuses on\ntraining agents with limited knowledge within isolated environments, which\ndiverges significantly from human learning processes, and thus makes the agents\nhard to achieve human-like decisions. Recently, through the acquisition of vast\namounts of web knowledge, large language models (LLMs) have demonstrated\nremarkable potential in achieving human-level intelligence. This has sparked an\nupsurge in studies investigating LLM-based autonomous agents. In this paper, we\npresent a comprehensive survey of these studies, delivering a systematic review\nof the field of LLM-based autonomous agents from a holistic perspective. More\nspecifically, we first discuss the construction of LLM-based autonomous agents,\nfor which we propose a unified framework that encompasses a majority of the\nprevious work. Then, we present a comprehensive overview of the diverse\napplications of LLM-based autonomous agents in the fields of social science,\nnatural science, and engineering. Finally, we delve into the evaluation\nstrategies commonly used for LLM-based autonomous agents. Based on the previous\nstudies, we also present several challenges and future directions in this\nfield. To keep track of this field and continuously update our survey, we\nmaintain a repository of relevant references at\nhttps://github.com/Paitesanshi/LLM-Agent-Survey.\n","authors":["Lei Wang","Chen Ma","Xueyang Feng","Zeyu Zhang","Hao Yang","Jingsen Zhang","Zhiyuan Chen","Jiakai Tang","Xu Chen","Yankai Lin","Wayne Xin Zhao","Zhewei Wei","Ji-Rong Wen"],"pdf_url":"https://arxiv.org/pdf/2308.11432v7.pdf","comment":"Correcting several typos, 35 pages, 5 figures, 3 tables"},{"id":"http://arxiv.org/abs/2407.14985v5","updated":"2025-03-02T03:27:58Z","published":"2024-07-20T21:24:40Z","title":"Generalization v.s. Memorization: Tracing Language Models' Capabilities\n  Back to Pretraining Data","summary":"  The impressive capabilities of large language models (LLMs) have sparked\ndebate over whether these models genuinely generalize to unseen tasks or\npredominantly rely on memorizing vast amounts of pretraining data. To explore\nthis issue, we introduce an extended concept of memorization, distributional\nmemorization, which measures the correlation between the LLM output\nprobabilities and the pretraining data frequency. To effectively capture\ntask-specific pretraining data frequency, we propose a novel task-gram language\nmodel, which is built by counting the co-occurrence of semantically related\n$n$-gram pairs from task inputs and outputs in the pretraining corpus. Using\nthe Pythia models trained on the Pile dataset, we evaluate four distinct tasks:\nmachine translation, factual question answering, world knowledge understanding,\nand math reasoning. Our findings reveal varying levels of memorization, with\nthe strongest effect observed in factual question answering. Furthermore, while\nmodel performance improves across all tasks as LLM size increases, only factual\nquestion answering shows an increase in memorization, whereas machine\ntranslation and reasoning tasks exhibit greater generalization, producing more\nnovel outputs. This study demonstrates that memorization plays a larger role in\nsimpler, knowledge-intensive tasks, while generalization is the key for harder,\nreasoning-based tasks, providing a scalable method for analyzing large\npretraining corpora in greater depth.\n","authors":["Xinyi Wang","Antonis Antoniades","Yanai Elazar","Alfonso Amayuelas","Alon Albalak","Kexun Zhang","William Yang Wang"],"pdf_url":"https://arxiv.org/pdf/2407.14985v5.pdf","comment":"Accepted to ICLR 2025"},{"id":"http://arxiv.org/abs/2401.06603v2","updated":"2025-03-02T01:46:57Z","published":"2024-01-12T14:35:57Z","title":"Mutual Enhancement of Large Language and Reinforcement Learning Models\n  through Bi-Directional Feedback Mechanisms: A Planning Case Study","summary":"  Large Language Models (LLMs) have demonstrated remarkable capabilities for\nreinforcement learning (RL) models, such as planning and reasoning\ncapabilities. However, the problems of LLMs and RL model collaboration still\nneed to be solved. In this study, we employ a teacher-student learning\nframework to tackle these problems, specifically by offering feedback for LLMs\nusing RL models and providing high-level information for RL models with LLMs in\na cooperative multi-agent setting. Within this framework, the LLM acts as a\nteacher, while the RL model acts as a student. The two agents cooperatively\nassist each other through a process of recursive help, such as \"I help you help\nI help.\" The LLM agent supplies abstract information to the RL agent, enabling\nefficient exploration and policy improvement. In turn, the RL agent offers\nfeedback to the LLM agent, providing valuable, real-time information that helps\ngenerate more useful tokens. This bi-directional feedback loop promotes\noptimization, exploration, and mutual improvement for both agents, enabling\nthem to accomplish increasingly challenging tasks. Remarkably, we propose a\npractical algorithm to address the problem and conduct empirical experiments to\nevaluate the effectiveness of our method.\n","authors":["Shangding Gu"],"pdf_url":"https://arxiv.org/pdf/2401.06603v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.10594v2","updated":"2025-03-02T01:19:51Z","published":"2024-10-14T15:04:18Z","title":"VisRAG: Vision-based Retrieval-augmented Generation on Multi-modality\n  Documents","summary":"  Retrieval-augmented generation (RAG) is an effective technique that enables\nlarge language models (LLMs) to utilize external knowledge sources for\ngeneration. However, current RAG systems are solely based on text, rendering it\nimpossible to utilize vision information like layout and images that play\ncrucial roles in real-world multi-modality documents. In this paper, we\nintroduce VisRAG, which tackles this issue by establishing a vision-language\nmodel (VLM)-based RAG pipeline. In this pipeline, instead of first parsing the\ndocument to obtain text, the document is directly embedded using a VLM as an\nimage and then retrieved to enhance the generation of a VLM. Compared to\ntraditional text-based RAG, VisRAG maximizes the retention and utilization of\nthe data information in the original documents, eliminating the information\nloss introduced during the parsing process. We collect both open-source and\nsynthetic data to train the retriever in VisRAG and explore a variety of\ngeneration methods. Experiments demonstrate that VisRAG outperforms traditional\nRAG in both the retrieval and generation stages, achieving a 20--40% end-to-end\nperformance gain over traditional text-based RAG pipeline. Further analysis\nreveals that VisRAG is efficient in utilizing training data and demonstrates\nstrong generalization capability, positioning it as a promising solution for\nRAG on multi-modality documents. Our code and data are available at\nhttps://github.com/openbmb/visrag.\n","authors":["Shi Yu","Chaoyue Tang","Bokai Xu","Junbo Cui","Junhao Ran","Yukun Yan","Zhenghao Liu","Shuo Wang","Xu Han","Zhiyuan Liu","Maosong Sun"],"pdf_url":"https://arxiv.org/pdf/2410.10594v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2406.13629v3","updated":"2025-03-02T00:46:31Z","published":"2024-06-19T15:25:29Z","title":"InstructRAG: Instructing Retrieval-Augmented Generation via\n  Self-Synthesized Rationales","summary":"  Retrieval-augmented generation (RAG) has shown promising potential to enhance\nthe accuracy and factuality of language models (LMs). However, imperfect\nretrievers or noisy corpora can introduce misleading or even erroneous\ninformation to the retrieved contents, posing a significant challenge to the\ngeneration quality. Existing RAG methods typically address this challenge by\ndirectly predicting final answers despite potentially noisy inputs, resulting\nin an implicit denoising process that is difficult to interpret and verify. On\nthe other hand, the acquisition of explicit denoising supervision is often\ncostly, involving significant human efforts. In this work, we propose\nInstructRAG, where LMs explicitly learn the denoising process through\nself-synthesized rationales -- First, we instruct the LM to explain how the\nground-truth answer is derived from retrieved documents. Then, these rationales\ncan be used either as demonstrations for in-context learning of explicit\ndenoising or as supervised fine-tuning data to train the model. Compared to\nstandard RAG approaches, InstructRAG requires no additional supervision, allows\nfor easier verification of the predicted answers, and effectively improves\ngeneration accuracy. Experiments show InstructRAG consistently outperforms\nexisting RAG methods in both training-free and trainable scenarios, achieving a\nrelative improvement of 8.3% over the best baseline method on average across\nfive knowledge-intensive benchmarks. Extensive analysis indicates that\nInstructRAG scales well with increased numbers of retrieved documents and\nconsistently exhibits robust denoising ability even in out-of-domain datasets,\ndemonstrating strong generalizability.\n","authors":["Zhepei Wei","Wei-Lin Chen","Yu Meng"],"pdf_url":"https://arxiv.org/pdf/2406.13629v3.pdf","comment":"ICLR 2025. Code: https://github.com/weizhepei/InstructRAG"},{"id":"http://arxiv.org/abs/2410.21533v2","updated":"2025-03-02T04:39:42Z","published":"2024-10-28T21:02:13Z","title":"L3Ms - Lagrange Large Language Models","summary":"  Supervised fine-tuning (SFT) and alignment of large language models (LLMs)\nare key steps in providing a good user experience. However, the concept of an\nappropriate alignment is inherently application-dependent, and current methods\noften rely on heuristic choices to drive optimization. In this work, we\nformulate SFT and alignment as a constrained optimization problem: the LLM is\nfine-tuned on a task while being required to meet application-specific\nrequirements, without resorting to heuristics. To solve this, we propose\nLagrange Large Language Models (L3Ms), which employ logarithmic barriers to\nenforce the constraints. This approach allows for the customization of L3Ms\nacross diverse applications while avoiding heuristic-driven processes. We\nexperimentally demonstrate the versatility and efficacy of L3Ms in achieving\ntailored alignments for various applications.\n","authors":["Guneet S. Dhillon","Xingjian Shi","Yee Whye Teh","Alex Smola"],"pdf_url":"https://arxiv.org/pdf/2410.21533v2.pdf","comment":"International Conference on Learning Representations (ICLR), 2025"}],"Computer Vision and Pattern Recognition":[{"id":"http://arxiv.org/abs/2310.07887v4","updated":"2025-03-02T23:48:32Z","published":"2023-10-11T20:48:20Z","title":"Unsupervised Denoising for Signal-Dependent and Row-Correlated Imaging\n  Noise","summary":"  Accurate analysis of microscopy images is hindered by the presence of noise.\nThis noise is usually signal-dependent and often additionally correlated along\nrows or columns of pixels. Current self- and unsupervised denoisers can address\nsignal-dependent noise, but none can reliably remove noise that is also row- or\ncolumn-correlated. Here, we present the first fully unsupervised deep\nlearning-based denoiser capable of handling imaging noise that is\nrow-correlated as well as signal-dependent. Our approach uses a Variational\nAutoencoder (VAE) with a specially designed autoregressive decoder. This\ndecoder is capable of modeling row-correlated and signal-dependent noise but is\nincapable of independently modeling underlying clean signal. The VAE therefore\nproduces latent variables containing only clean signal information, and these\nare mapped back into image space using a proposed second decoder network. Our\nmethod does not require a pre-trained noise model and can be trained from\nscratch using unpaired noisy data. We benchmark our approach on microscopy\ndatatsets from a range of imaging modalities and sensor types, each with row-\nor column-correlated, signal-dependent noise, and show that it outperforms\nexisting self- and unsupervised denoisers.\n","authors":["Benjamin Salmon","Alexander Krull"],"pdf_url":"https://arxiv.org/pdf/2310.07887v4.pdf","comment":null},{"id":"http://arxiv.org/abs/2408.15998v2","updated":"2025-03-02T23:41:37Z","published":"2024-08-28T17:59:31Z","title":"Eagle: Exploring The Design Space for Multimodal LLMs with Mixture of\n  Encoders","summary":"  The ability to accurately interpret complex visual information is a crucial\ntopic of multimodal large language models (MLLMs). Recent work indicates that\nenhanced visual perception significantly reduces hallucinations and improves\nperformance on resolution-sensitive tasks, such as optical character\nrecognition and document analysis. A number of recent MLLMs achieve this goal\nusing a mixture of vision encoders. Despite their success, there is a lack of\nsystematic comparisons and detailed ablation studies addressing critical\naspects, such as expert selection and the integration of multiple vision\nexperts. This study provides an extensive exploration of the design space for\nMLLMs using a mixture of vision encoders and resolutions. Our findings reveal\nseveral underlying principles common to various existing strategies, leading to\na streamlined yet effective design approach. We discover that simply\nconcatenating visual tokens from a set of complementary vision encoders is as\neffective as more complex mixing architectures or strategies. We additionally\nintroduce Pre-Alignment to bridge the gap between vision-focused encoders and\nlanguage tokens, enhancing model coherence. The resulting family of MLLMs,\nEagle, surpasses other leading open-source models on major MLLM benchmarks.\n","authors":["Min Shi","Fuxiao Liu","Shihao Wang","Shijia Liao","Subhashree Radhakrishnan","Yilin Zhao","De-An Huang","Hongxu Yin","Karan Sapra","Yaser Yacoob","Humphrey Shi","Bryan Catanzaro","Andrew Tao","Jan Kautz","Zhiding Yu","Guilin Liu"],"pdf_url":"https://arxiv.org/pdf/2408.15998v2.pdf","comment":"Github: https://github.com/NVlabs/Eagle, HuggingFace:\n  https://huggingface.co/NVEagle"},{"id":"http://arxiv.org/abs/2411.01106v2","updated":"2025-03-02T22:41:37Z","published":"2024-11-02T02:09:01Z","title":"SV-RAG: LoRA-Contextualizing Adaptation of MLLMs for Long Document\n  Understanding","summary":"  Multimodal large language models (MLLMs) have recently shown great progress\nin text-rich image understanding, yet they still struggle with complex,\nmulti-page visually-rich documents. Traditional methods using document parsers\nfor retrieval-augmented generation suffer from performance and efficiency\nlimitations, while directly presenting all pages to MLLMs leads to\ninefficiencies, especially with lengthy ones. In this work, we present a novel\nframework named **S**elf-**V**isual **R**etrieval-**A**ugmented **G**eneration\n(SV-RAG), which can broaden horizons of any MLLM to support long-document\nunderstanding. We demonstrate that **MLLMs themselves can be an effective\nmultimodal retriever** to fetch relevant pages and then answer user questions\nbased on these pages. SV-RAG is implemented with two specific MLLM adapters,\none for evidence page retrieval and the other for question answering. Empirical\nresults show state-of-the-art performance on public benchmarks, demonstrating\nthe effectiveness of SV-RAG.\n","authors":["Jian Chen","Ruiyi Zhang","Yufan Zhou","Tong Yu","Franck Dernoncourt","Jiuxiang Gu","Ryan A. Rossi","Changyou Chen","Tong Sun"],"pdf_url":"https://arxiv.org/pdf/2411.01106v2.pdf","comment":"Accepted to ICLR 2025"},{"id":"http://arxiv.org/abs/2502.00156v2","updated":"2025-03-02T20:53:26Z","published":"2025-01-31T20:47:06Z","title":"ALBAR: Adversarial Learning approach to mitigate Biases in Action\n  Recognition","summary":"  Bias in machine learning models can lead to unfair decision making, and while\nit has been well-studied in the image and text domains, it remains\nunderexplored in action recognition. Action recognition models often suffer\nfrom background bias (i.e., inferring actions based on background cues) and\nforeground bias (i.e., relying on subject appearance), which can be detrimental\nto real-life applications such as autonomous vehicles or assisted living\nmonitoring. While prior approaches have mainly focused on mitigating background\nbias using specialized augmentations, we thoroughly study both foreground and\nbackground bias. We propose ALBAR, a novel adversarial training method that\nmitigates foreground and background biases without requiring specialized\nknowledge of the bias attributes. Our framework applies an adversarial\ncross-entropy loss to the sampled static clip (where all the frames are the\nsame) and aims to make its class probabilities uniform using a proposed entropy\nmaximization loss. Additionally, we introduce a gradient penalty loss for\nregularization against the debiasing process. We evaluate our method on\nestablished background and foreground bias protocols, setting a new\nstate-of-the-art and strongly improving combined debiasing performance by over\n12% absolute on HMDB51. Furthermore, we identify an issue of background leakage\nin the existing UCF101 protocol for bias evaluation which provides a shortcut\nto predict actions and does not provide an accurate measure of the debiasing\ncapability of a model. We address this issue by proposing more fine-grained\nsegmentation boundaries for the actor, where our method also outperforms\nexisting approaches. Project Page:\nhttps://joefioresi718.github.io/ALBAR_webpage/\n","authors":["Joseph Fioresi","Ishan Rajendrakumar Dave","Mubarak Shah"],"pdf_url":"https://arxiv.org/pdf/2502.00156v2.pdf","comment":"Accepted to ICLR 2025"},{"id":"http://arxiv.org/abs/2312.15289v3","updated":"2025-03-02T18:36:56Z","published":"2023-12-23T16:10:53Z","title":"Frchet Wavelet Distance: A Domain-Agnostic Metric for Image\n  Generation","summary":"  Modern metrics for generative learning like Fr\\'echet Inception Distance\n(FID) and DINOv2-Fr\\'echet Distance (FD-DINOv2) demonstrate impressive\nperformance. However, they suffer from various shortcomings, like a bias\ntowards specific generators and datasets. To address this problem, we propose\nthe Fr\\'echet Wavelet Distance (FWD) as a domain-agnostic metric based on the\nWavelet Packet Transform ($W_p$). FWD provides a sight across a broad spectrum\nof frequencies in images with a high resolution, preserving both spatial and\ntextural aspects. Specifically, we use $W_p$ to project generated and real\nimages to the packet coefficient space. We then compute the Fr\\'echet distance\nwith the resultant coefficients to evaluate the quality of a generator. This\nmetric is general-purpose and dataset-domain agnostic, as it does not rely on\nany pre-trained network, while being more interpretable due to its ability to\ncompute Fr\\'echet distance per packet, enhancing transparency. We conclude with\nan extensive evaluation of a wide variety of generators across various datasets\nthat the proposed FWD can generalize and improve robustness to domain shifts\nand various corruptions compared to other metrics.\n","authors":["Lokesh Veeramacheneni","Moritz Wolter","Hildegard Kuehne","Juergen Gall"],"pdf_url":"https://arxiv.org/pdf/2312.15289v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.10509v2","updated":"2025-03-02T18:17:14Z","published":"2024-11-15T15:39:04Z","title":"TESGNN: Temporal Equivariant Scene Graph Neural Networks for Efficient\n  and Robust Multi-View 3D Scene Understanding","summary":"  Scene graphs have proven to be highly effective for various scene\nunderstanding tasks due to their compact and explicit representation of\nrelational information. However, current methods often overlook the critical\nimportance of preserving symmetry when generating scene graphs from 3D point\nclouds, which can lead to reduced accuracy and robustness, particularly when\ndealing with noisy, multi-view data. Furthermore, a major limitation of prior\napproaches is the lack of temporal modeling to capture time-dependent\nrelationships among dynamically evolving entities in a scene. To address these\nchallenges, we propose Temporal Equivariant Scene Graph Neural Network\n(TESGNN), consisting of two key components: (1) an Equivariant Scene Graph\nNeural Network (ESGNN), which extracts information from 3D point clouds to\ngenerate scene graph while preserving crucial symmetry properties, and (2) a\nTemporal Graph Matching Network, which fuses scene graphs generated by ESGNN\nacross multiple time sequences into a unified global representation using an\napproximate graph-matching algorithm. Our combined architecture TESGNN\noutperforms current state-of-the-art methods in scene graph generation,\nachieving higher accuracy and faster training convergence. Moreover, we show\nthat leveraging the symmetry-preserving property produces a more stable and\naccurate global scene representation compared to existing approaches. Last but\nnot least, it is computationally efficient and easily implementable using\nexisting frameworks, making it well-suited for real-time applications in\nrobotics and computer vision. This approach paves the way for more robust and\nscalable solutions to complex multi-view scene understanding challenges. Our\nsource code is publicly available at: https://github.com/HySonLab/TESGraph\n","authors":["Quang P. M. Pham","Khoi T. N. Nguyen","Lan C. Ngo","Truong Do","Dezhen Song","Truong-Son Hy"],"pdf_url":"https://arxiv.org/pdf/2411.10509v2.pdf","comment":"arXiv admin note: text overlap with arXiv:2407.00609"},{"id":"http://arxiv.org/abs/2411.02372v2","updated":"2025-03-02T17:34:53Z","published":"2024-11-04T18:40:46Z","title":"Learning General-Purpose Biomedical Volume Representations using\n  Randomized Synthesis","summary":"  Current volumetric biomedical foundation models struggle to generalize as\npublic 3D datasets are small and do not cover the broad diversity of medical\nprocedures, conditions, anatomical regions, and imaging protocols. We address\nthis by creating a representation learning method that instead anticipates\nstrong domain shifts at training time itself. We first propose a data engine\nthat synthesizes highly variable training samples that would enable\ngeneralization to new biomedical contexts. To then train a single 3D network\nfor any voxel-level task, we develop a contrastive learning method that\npretrains the network to be stable against nuisance imaging variation simulated\nby the data engine, a key inductive bias for generalization. This network's\nfeatures can be used as robust representations of input images for downstream\ntasks and its weights provide a strong, dataset-agnostic initialization for\nfinetuning on new datasets. As a result, we set new standards across both\nmultimodality registration and few-shot segmentation, a first for any 3D\nbiomedical vision model, all without (pre-)training on any existing dataset of\nreal images.\n","authors":["Neel Dey","Benjamin Billot","Hallee E. Wong","Clinton J. Wang","Mengwei Ren","P. Ellen Grant","Adrian V. Dalca","Polina Golland"],"pdf_url":"https://arxiv.org/pdf/2411.02372v2.pdf","comment":"ICLR 2025: International Conference on Learning Representations. Code\n  and model weights available at https://github.com/neel-dey/anatomix.\n  Keywords: synthetic data, representation learning, medical image analysis,\n  image registration, image segmentation"},{"id":"http://arxiv.org/abs/2409.14876v3","updated":"2025-03-02T17:27:04Z","published":"2024-09-23T10:17:13Z","title":"Tri-Clustering: A Multi-views Tri-level Information Fusion Context\n  Clustering Framework for Localization and Classification in Mammography","summary":"  Breast cancer is a significant global health issue, and the diagnosis of\nbreast imaging has always been challenging. Mammography images typically have\nextremely high resolution, with lesions occupying only a very small area.\nDown-sampling in neural networks can easily lead to the loss of\nmicrocalcifications or subtle structures, making it difficult for traditional\nneural network architectures to address these issues. To tackle these\nchallenges, we propose a Context Clustering Network with triple information\nfusion. Firstly, compared to CNNs or transformers, we find that Context\nclustering methods (1) are more computationally efficient and (2) can more\neasily associate structural or pathological features, making them suitable for\nthe clinical tasks of mammography. Secondly, we propose a triple information\nfusion mechanism that integrates global information, feature-based local\ninformation, and patch-based local information. The proposed approach is\nrigorously evaluated on two public datasets, Vindr-Mammo and CBIS-DDSM, using\nfive independent splits to ensure statistical robustness. Our method achieves\nan AUC of 0.828 on Vindr-Mammo and 0.805 on CBIS-DDSM, outperforming the next\nbest method by 3.1% and 2.4%, respectively. These improvements are\nstatistically significant (p<0.05), underscoring the benefits of Context\nClustering Network with triple information fusion. Overall, our Context\nClustering framework demonstrates strong potential as a scalable and\ncost-effective solution for large-scale mammography screening, enabling more\nefficient and accurate breast cancer detection. Access to our method is\navailable at https://github.com/Sohyu1/Mammo_Clustering.\n","authors":["Shilong Yang","Chulong Zhang","Qi Zang","Juan Yu","Liang Zeng","Xiao Luo","Yexuan Xing","Xin Pan","Qi Li","Xiaokun Liang","Yaoqin Xie"],"pdf_url":"https://arxiv.org/pdf/2409.14876v3.pdf","comment":"10 pages, 6 figures"},{"id":"http://arxiv.org/abs/2410.04810v2","updated":"2025-03-02T17:18:04Z","published":"2024-10-07T07:45:18Z","title":"FedBiP: Heterogeneous One-Shot Federated Learning with Personalized\n  Latent Diffusion Models","summary":"  One-Shot Federated Learning (OSFL), a special decentralized machine learning\nparadigm, has recently gained significant attention. OSFL requires only a\nsingle round of client data or model upload, which reduces communication costs\nand mitigates privacy threats compared to traditional FL. Despite these\npromising prospects, existing methods face challenges due to client data\nheterogeneity and limited data quantity when applied to real-world OSFL\nsystems. Recently, Latent Diffusion Models (LDM) have shown remarkable\nadvancements in synthesizing high-quality images through pretraining on\nlarge-scale datasets, thereby presenting a potential solution to overcome these\nissues. However, directly applying pretrained LDM to heterogeneous OSFL results\nin significant distribution shifts in synthetic data, leading to performance\ndegradation in classification models trained on such data. This issue is\nparticularly pronounced in rare domains, such as medical imaging, which are\nunderrepresented in LDM's pretraining data. To address this challenge, we\npropose Federated Bi-Level Personalization (FedBiP), which personalizes the\npretrained LDM at both instance-level and concept-level. Hereby, FedBiP\nsynthesizes images following the client's local data distribution without\ncompromising the privacy regulations. FedBiP is also the first approach to\nsimultaneously address feature space heterogeneity and client data scarcity in\nOSFL. Our method is validated through extensive experiments on three OSFL\nbenchmarks with feature space heterogeneity, as well as on challenging medical\nand satellite image datasets with label heterogeneity. The results demonstrate\nthe effectiveness of FedBiP, which substantially outperforms other OSFL\nmethods.\n","authors":["Haokun Chen","Hang Li","Yao Zhang","Jinhe Bi","Gengyuan Zhang","Yueqi Zhang","Philip Torr","Jindong Gu","Denis Krompass","Volker Tresp"],"pdf_url":"https://arxiv.org/pdf/2410.04810v2.pdf","comment":"CVPR 2025"},{"id":"http://arxiv.org/abs/2308.09036v2","updated":"2025-03-02T17:15:30Z","published":"2023-08-17T15:17:49Z","title":"Synthesizing Physically Plausible Human Motions in 3D Scenes","summary":"  We present a physics-based character control framework for synthesizing\nhuman-scene interactions. Recent advances adopt physics simulation to mitigate\nartifacts produced by data-driven kinematic approaches. However, existing\nphysics-based methods mainly focus on single-object environments, resulting in\nlimited applicability in realistic 3D scenes with multi-objects. To address\nsuch challenges, we propose a framework that enables physically simulated\ncharacters to perform long-term interaction tasks in diverse, cluttered, and\nunseen 3D scenes. The key idea is to decouple human-scene interactions into two\nfundamental processes, Interacting and Navigating, which motivates us to\nconstruct two reusable Controllers, namely InterCon and NavCon. Specifically,\nInterCon uses two complementary policies to enable characters to enter or leave\nthe interacting state with a particular object (e.g., sitting on a chair or\ngetting up). To realize navigation in cluttered environments, we introduce\nNavCon, where a trajectory following policy enables characters to track\npre-planned collision-free paths. Benefiting from the divide and conquer\nstrategy, we can train all policies in simple environments and directly apply\nthem in complex multi-object scenes through coordination from a rule-based\nscheduler. Video and code are available at\nhttps://github.com/liangpan99/InterScene.\n","authors":["Liang Pan","Jingbo Wang","Buzhen Huang","Junyu Zhang","Haofan Wang","Xu Tang","Yangang Wang"],"pdf_url":"https://arxiv.org/pdf/2308.09036v2.pdf","comment":"3DV 2024 version"},{"id":"http://arxiv.org/abs/2410.15744v2","updated":"2025-03-02T16:58:17Z","published":"2024-10-21T08:01:58Z","title":"Unleashing the Potential of Vision-Language Pre-Training for 3D\n  Zero-Shot Lesion Segmentation via Mask-Attribute Alignment","summary":"  Recent advancements in medical vision-language pre-training models have\ndriven significant progress in zero-shot disease recognition. However,\ntransferring image-level knowledge to pixel-level tasks, such as lesion\nsegmentation in 3D CT scans, remains a critical challenge. Due to the\ncomplexity and variability of pathological visual characteristics, existing\nmethods struggle to align fine-grained lesion features not encountered during\ntraining with disease-related textual representations. In this paper, we\npresent Malenia, a novel multi-scale lesion-level mask-attribute alignment\nframework, specifically designed for 3D zero-shot lesion segmentation. Malenia\nimproves the compatibility between mask representations and their associated\nelemental attributes, explicitly linking the visual features of unseen lesions\nwith the extensible knowledge learned from previously seen ones. Furthermore,\nwe design a Cross-Modal Knowledge Injection module to enhance both visual and\ntextual features with mutually beneficial information, effectively guiding the\ngeneration of segmentation results. Comprehensive experiments across three\ndatasets and 12 lesion categories validate the superior performance of Malenia.\n","authors":["Yankai Jiang","Wenhui Lei","Xiaofan Zhang","Shaoting Zhang"],"pdf_url":"https://arxiv.org/pdf/2410.15744v2.pdf","comment":"Accepted as ICLR 2025 conference paper"},{"id":"http://arxiv.org/abs/2403.18035v4","updated":"2025-03-02T16:41:49Z","published":"2024-03-26T18:40:36Z","title":"Bidirectional Consistency Models","summary":"  Diffusion models (DMs) are capable of generating remarkably high-quality\nsamples by iteratively denoising a random vector, a process that corresponds to\nmoving along the probability flow ordinary differential equation (PF ODE).\nInterestingly, DMs can also invert an input image to noise by moving backward\nalong the PF ODE, a key operation for downstream tasks such as interpolation\nand image editing. However, the iterative nature of this process restricts its\nspeed, hindering its broader application. Recently, Consistency Models (CMs)\nhave emerged to address this challenge by approximating the integral of the PF\nODE, largely reducing the number of iterations. Yet, the absence of an explicit\nODE solver complicates the inversion process. To resolve this, we introduce\nBidirectional Consistency Model (BCM), which learns a single neural network\nthat enables both forward and backward traversal along the PF ODE, efficiently\nunifying generation and inversion tasks within one framework. We can train BCM\nfrom scratch or tune it using a pretrained consistency model, which reduces the\ntraining cost and increases scalability. We demonstrate that BCM enables\none-step generation and inversion while also allowing the use of additional\nsteps to enhance generation quality or reduce reconstruction error. We further\nshowcase BCM's capability in downstream tasks, such as interpolation and\ninpainting. Our code and weights are available at\nhttps://github.com/Mosasaur5526/BCM-iCT-torch.\n","authors":["Liangchen Li","Jiajun He"],"pdf_url":"https://arxiv.org/pdf/2403.18035v4.pdf","comment":"39 pages, 27 figures; a shorter version of this paper was acceppted\n  at the ICML 2024 Workshop on Structured Probabilistic Inference & Generative\n  Modeling"},{"id":"http://arxiv.org/abs/2408.11915v2","updated":"2025-03-02T15:55:14Z","published":"2024-08-21T18:06:15Z","title":"Video-Foley: Two-Stage Video-To-Sound Generation via Temporal Event\n  Condition For Foley Sound","summary":"  Foley sound synthesis is crucial for multimedia production, enhancing user\nexperience by synchronizing audio and video both temporally and semantically.\nRecent studies on automating this labor-intensive process through\nvideo-to-sound generation face significant challenges. Systems lacking explicit\ntemporal features suffer from poor alignment and controllability, while\ntimestamp-based models require costly and subjective human annotation. We\npropose Video-Foley, a video-to-sound system using Root Mean Square (RMS) as an\nintuitive condition with semantic timbre prompts (audio or text). RMS, a\nframe-level intensity envelope closely related to audio semantics, acts as a\ntemporal event feature to guide audio generation from video. The\nannotation-free self-supervised learning framework consists of two stages,\nVideo2RMS and RMS2Sound, incorporating novel ideas including RMS discretization\nand RMS-ControlNet with a pretrained text-to-audio model. Our extensive\nevaluation shows that Video-Foley achieves state-of-the-art performance in\naudio-visual alignment and controllability for sound timing, intensity, timbre,\nand nuance. Source code, model weights and demos are available on our companion\nwebsite. (https://jnwnlee.github.io/video-foley-demo)\n","authors":["Junwon Lee","Jaekwon Im","Dabin Kim","Juhan Nam"],"pdf_url":"https://arxiv.org/pdf/2408.11915v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2501.03895v2","updated":"2025-03-02T15:55:07Z","published":"2025-01-07T16:03:14Z","title":"LLaVA-Mini: Efficient Image and Video Large Multimodal Models with One\n  Vision Token","summary":"  The advent of real-time large multimodal models (LMMs) like GPT-4o has\nsparked considerable interest in efficient LMMs. LMM frameworks typically\nencode visual inputs into vision tokens (continuous representations) and\nintegrate them and textual instructions into the context of large language\nmodels (LLMs), where large-scale parameters and numerous context tokens\n(predominantly vision tokens) result in substantial computational overhead.\nPrevious efforts towards efficient LMMs always focus on replacing the LLM\nbackbone with smaller models, while neglecting the crucial issue of token\nquantity. In this paper, we introduce LLaVA-Mini, an efficient LMM with minimal\nvision tokens. To achieve a high compression ratio of vision tokens while\npreserving visual information, we first analyze how LMMs understand vision\ntokens and find that most vision tokens only play a crucial role in the early\nlayers of LLM backbone, where they mainly fuse visual information into text\ntokens. Building on this finding, LLaVA-Mini introduces modality pre-fusion to\nfuse visual information into text tokens in advance, thereby facilitating the\nextreme compression of vision tokens fed to LLM backbone into one token.\nLLaVA-Mini is a unified large multimodal model that can support the\nunderstanding of images, high-resolution images, and videos in an efficient\nmanner. Experiments across 11 image-based and 7 video-based benchmarks\ndemonstrate that LLaVA-Mini outperforms LLaVA-v1.5 with just 1 vision token\ninstead of 576. Efficiency analyses reveal that LLaVA-Mini can reduce FLOPs by\n77%, deliver low-latency responses within 40 milliseconds, and process over\n10,000 frames of video on the GPU hardware with 24GB of memory.\n","authors":["Shaolei Zhang","Qingkai Fang","Zhe Yang","Yang Feng"],"pdf_url":"https://arxiv.org/pdf/2501.03895v2.pdf","comment":"Accepted to ICLR 2025. Code: https://github.com/ictnlp/LLaVA-Mini\n  Model: https://huggingface.co/ICTNLP/llava-mini-llama-3.1-8b"},{"id":"http://arxiv.org/abs/2501.18672v3","updated":"2025-03-02T15:43:39Z","published":"2025-01-30T18:51:54Z","title":"Drag Your Gaussian: Effective Drag-Based Editing with Score Distillation\n  for 3D Gaussian Splatting","summary":"  Recent advancements in 3D scene editing have been propelled by the rapid\ndevelopment of generative models. Existing methods typically utilize generative\nmodels to perform text-guided editing on 3D representations, such as 3D\nGaussian Splatting (3DGS). However, these methods are often limited to texture\nmodifications and fail when addressing geometric changes, such as editing a\ncharacter's head to turn around. Moreover, such methods lack accurate control\nover the spatial position of editing results, as language struggles to\nprecisely describe the extent of edits. To overcome these limitations, we\nintroduce DYG, an effective 3D drag-based editing method for 3D Gaussian\nSplatting. It enables users to conveniently specify the desired editing region\nand the desired dragging direction through the input of 3D masks and pairs of\ncontrol points, thereby enabling precise control over the extent of editing.\nDYG integrates the strengths of the implicit triplane representation to\nestablish the geometric scaffold of the editing results, effectively overcoming\nsuboptimal editing outcomes caused by the sparsity of 3DGS in the desired\nediting regions. Additionally, we incorporate a drag-based Latent Diffusion\nModel into our method through the proposed Drag-SDS loss function, enabling\nflexible, multi-view consistent, and fine-grained editing. Extensive\nexperiments demonstrate that DYG conducts effective drag-based editing guided\nby control point prompts, surpassing other baselines in terms of editing effect\nand quality, both qualitatively and quantitatively. Visit our project page at\nhttps://quyans.github.io/Drag-Your-Gaussian.\n","authors":["Yansong Qu","Dian Chen","Xinyang Li","Xiaofan Li","Shengchuan Zhang","Liujuan Cao","Rongrong Ji"],"pdf_url":"https://arxiv.org/pdf/2501.18672v3.pdf","comment":"Visit our project page at https://quyans.github.io/Drag-Your-Gaussian"},{"id":"http://arxiv.org/abs/2310.18709v4","updated":"2025-03-02T15:37:39Z","published":"2023-10-28T13:37:52Z","title":"Audio-Visual Instance Segmentation","summary":"  In this paper, we propose a new multi-modal task, termed audio-visual\ninstance segmentation (AVIS), which aims to simultaneously identify, segment\nand track individual sounding object instances in audible videos. To facilitate\nthis research, we introduce a high-quality benchmark named AVISeg, containing\nover 90K instance masks from 26 semantic categories in 926 long videos.\nAdditionally, we propose a strong baseline model for this task. Our model first\nlocalizes sound source within each frame, and condenses object-specific\ncontexts into concise tokens. Then it builds long-range audio-visual\ndependencies between these tokens using window-based attention, and tracks\nsounding objects among the entire video sequences. Extensive experiments reveal\nthat our method performs best on AVISeg, surpassing the existing methods from\nrelated tasks. We further conduct the evaluation on several multi-modal large\nmodels. Unfortunately, they exhibits subpar performance on instance-level sound\nsource localization and temporal perception. We expect that AVIS will inspire\nthe community towards a more comprehensive multi-modal understanding. Dataset\nand code is available at https://github.com/ruohaoguo/avis.\n","authors":["Ruohao Guo","Xianghua Ying","Yaru Chen","Dantong Niu","Guangyao Li","Liao Qu","Yanyu Qi","Jinxing Zhou","Bowei Xing","Wenzhen Yue","Ji Shi","Qixun Wang","Peiliang Zhang","Buwen Liang"],"pdf_url":"https://arxiv.org/pdf/2310.18709v4.pdf","comment":"Accepted by CVPR 2025"},{"id":"http://arxiv.org/abs/2409.03114v2","updated":"2025-03-02T15:30:06Z","published":"2024-09-04T22:39:02Z","title":"Evaluating Low-Resource Lane Following Algorithms for\n  Compute-Constrained Automated Vehicles","summary":"  Reliable lane-following is essential for automated and assisted driving, yet\nexisting solutions often rely on models that require extensive computational\nresources, limiting their deployment in compute-constrained vehicles. We\nevaluate five low-resource lane-following algorithms designed for real-time\noperation on vehicles with limited computing resources. Performance was\nassessed through simulation and deployment on real drive-by-wire electric\nvehicles, with evaluation metrics including reliability, comfort, speed, and\nadaptability. The top-performing methods used unsupervised learning to detect\nand separate lane lines with processing time under 10 ms per frame,\noutperforming compute-intensive and poor generalizing deep learning approaches.\nThese approaches demonstrated robustness across lighting conditions, road\ntextures, and lane geometries. The findings highlight the potential for\nefficient lane detection approaches to enhance the accessibility and\nreliability of autonomous vehicle technologies. Reducing computing requirements\nenables lane keeping to be widely deployed in vehicles as part of lower-level\nautomation, including active safety systems.\n","authors":["Beat Froemming-Aldanondo","Tatiana Rastoskueva","Michael Evans","Marcial Machado","Anna Vadella","Rickey Johnson","Luis Escamilla","Milan Jostes","Devson Butani","Ryan Kaddis","Chan-Jin Chung","Joshua Siegel"],"pdf_url":"https://arxiv.org/pdf/2409.03114v2.pdf","comment":"Supported by the National Science Foundation under Grants No. 2150292\n  and 2150096"},{"id":"http://arxiv.org/abs/2410.03878v2","updated":"2025-03-02T15:22:12Z","published":"2024-10-04T19:22:20Z","title":"SPARTUN3D: Situated Spatial Understanding of 3D World in Large Language\n  Models","summary":"  Integrating the 3D world into large language models (3D-based LLMs) has been\na promising research direction for 3D scene understanding. However, current\n3D-based LLMs fall short in situated understanding due to two key limitations:\n1) existing 3D datasets are constructed from a global perspective of the 3D\nscenes and lack situated context. 2) the architectures of existing 3D-based\nLLMs lack explicit alignment between the spatial representations of 3D scenes\nand natural language, limiting their performance in tasks requiring precise\nspatial reasoning. We address these issues by introducing a scalable situated\n3D dataset, named Spartun3D, that incorporates various situated spatial\nreasoning tasks. Furthermore, we propose Spartun3D-LLM, built on an existing\n3D-based LLM but integrated with a novel situated spatial alignment module,\naiming to enhance the alignment between 3D visual representations and their\ncorresponding textual descriptions. Experimental results demonstrate that both\nour proposed dataset and alignment module significantly enhance the situated\nspatial understanding of 3D-based LLMs.\n","authors":["Yue Zhang","Zhiyang Xu","Ying Shen","Parisa Kordjamshidi","Lifu Huang"],"pdf_url":"https://arxiv.org/pdf/2410.03878v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2409.13426v2","updated":"2025-03-02T15:06:51Z","published":"2024-09-20T11:46:48Z","title":"HMD^2: Environment-aware Motion Generation from Single Egocentric\n  Head-Mounted Device","summary":"  This paper investigates the generation of realistic full-body human motion\nusing a single head-mounted device with an outward-facing color camera and the\nability to perform visual SLAM. To address the ambiguity of this setup, we\npresent HMD^2, a novel system that balances motion reconstruction and\ngeneration. From a reconstruction standpoint, it aims to maximally utilize the\ncamera streams to produce both analytical and learned features, including head\nmotion, SLAM point cloud, and image embeddings. On the generative front, HMD^2\nemploys a multi-modal conditional motion diffusion model with a Transformer\nbackbone to maintain temporal coherence of generated motions, and utilizes\nautoregressive inpainting to facilitate online motion inference with minimal\nlatency (0.17 seconds). We show that our system provides an effective and\nrobust solution that scales to a diverse dataset of over 200 hours of motion in\ncomplex indoor and outdoor environments.\n","authors":["Vladimir Guzov","Yifeng Jiang","Fangzhou Hong","Gerard Pons-Moll","Richard Newcombe","C. Karen Liu","Yuting Ye","Lingni Ma"],"pdf_url":"https://arxiv.org/pdf/2409.13426v2.pdf","comment":"International Conference on 3D Vision 2025 (3DV 2025)"},{"id":"http://arxiv.org/abs/2502.11858v3","updated":"2025-03-02T14:14:07Z","published":"2025-02-17T14:50:34Z","title":"Rethinking Audio-Visual Adversarial Vulnerability from Temporal and\n  Modality Perspectives","summary":"  While audio-visual learning equips models with a richer understanding of the\nreal world by leveraging multiple sensory modalities, this integration also\nintroduces new vulnerabilities to adversarial attacks.\n  In this paper, we present a comprehensive study of the adversarial robustness\nof audio-visual models, considering both temporal and modality-specific\nvulnerabilities. We propose two powerful adversarial attacks: 1) a temporal\ninvariance attack that exploits the inherent temporal redundancy across\nconsecutive time segments and 2) a modality misalignment attack that introduces\nincongruence between the audio and visual modalities. These attacks are\ndesigned to thoroughly assess the robustness of audio-visual models against\ndiverse threats. Furthermore, to defend against such attacks, we introduce a\nnovel audio-visual adversarial training framework. This framework addresses key\nchallenges in vanilla adversarial training by incorporating efficient\nadversarial perturbation crafting tailored to multi-modal data and an\nadversarial curriculum strategy. Extensive experiments in the Kinetics-Sounds\ndataset demonstrate that our proposed temporal and modality-based attacks in\ndegrading model performance can achieve state-of-the-art performance, while our\nadversarial training defense largely improves the adversarial robustness as\nwell as the adversarial training efficiency.\n","authors":["Zeliang Zhang","Susan Liang","Daiki Shimada","Chenliang Xu"],"pdf_url":"https://arxiv.org/pdf/2502.11858v3.pdf","comment":"Accepted by ICLR 2025"},{"id":"http://arxiv.org/abs/2410.02094v3","updated":"2025-03-02T14:04:22Z","published":"2024-10-02T23:30:05Z","title":"Tracking objects that change in appearance with phase synchrony","summary":"  Objects we encounter often change appearance as we interact with them.\nChanges in illumination (shadows), object pose, or the movement of non-rigid\nobjects can drastically alter available image features. How do biological\nvisual systems track objects as they change? One plausible mechanism involves\nattentional mechanisms for reasoning about the locations of objects\nindependently of their appearances -- a capability that prominent neuroscience\ntheories have associated with computing through neural synchrony. Here, we\ndescribe a novel deep learning circuit that can learn to precisely control\nattention to features separately from their location in the world through\nneural synchrony: the complex-valued recurrent neural network (CV-RNN). Next,\nwe compare object tracking in humans, the CV-RNN, and other deep neural\nnetworks (DNNs), using FeatureTracker: a large-scale challenge that asks\nobservers to track objects as their locations and appearances change in\nprecisely controlled ways. While humans effortlessly solved FeatureTracker,\nstate-of-the-art DNNs did not. In contrast, our CV-RNN behaved similarly to\nhumans on the challenge, providing a computational proof-of-concept for the\nrole of phase synchronization as a neural substrate for tracking\nappearance-morphing objects as they move about.\n","authors":["Sabine Muzellec","Drew Linsley","Alekh K. Ashok","Ennio Mingolla","Girik Malik","Rufin VanRullen","Thomas Serre"],"pdf_url":"https://arxiv.org/pdf/2410.02094v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2502.19047v2","updated":"2025-03-02T13:52:23Z","published":"2025-02-26T11:01:43Z","title":"A Dual-Purpose Framework for Backdoor Defense and Backdoor Amplification\n  in Diffusion Models","summary":"  Diffusion models have emerged as state-of-the-art generative frameworks,\nexcelling in producing high-quality multi-modal samples. However, recent\nstudies have revealed their vulnerability to backdoor attacks, where backdoored\nmodels generate specific, undesirable outputs called backdoor target (e.g.,\nharmful images) when a pre-defined trigger is embedded to their inputs. In this\npaper, we propose PureDiffusion, a dual-purpose framework that simultaneously\nserves two contrasting roles: backdoor defense and backdoor attack\namplification. For defense, we introduce two novel loss functions to invert\nbackdoor triggers embedded in diffusion models. The first leverages\ntrigger-induced distribution shifts across multiple timesteps of the diffusion\nprocess, while the second exploits the denoising consistency effect when a\nbackdoor is activated. Once an accurate trigger inversion is achieved, we\ndevelop a backdoor detection method that analyzes both the inverted trigger and\nthe generated backdoor targets to identify backdoor attacks. In terms of attack\namplification with the role of an attacker, we describe how our trigger\ninversion algorithm can be used to reinforce the original trigger embedded in\nthe backdoored diffusion model. This significantly boosts attack performance\nwhile reducing the required backdoor training time. Experimental results\ndemonstrate that PureDiffusion achieves near-perfect detection accuracy,\noutperforming existing defenses by a large margin, particularly against complex\ntrigger patterns. Additionally, in an attack scenario, our attack amplification\napproach elevates the attack success rate (ASR) of existing backdoor attacks to\nnearly 100\\% while reducing training time by up to 20x.\n","authors":["Vu Tuan Truong","Long Bao Le"],"pdf_url":"https://arxiv.org/pdf/2502.19047v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2404.15161v2","updated":"2025-03-02T13:49:21Z","published":"2024-04-23T16:01:33Z","title":"Test-Time Adaptation for Combating Missing Modalities in Egocentric\n  Videos","summary":"  Understanding videos that contain multiple modalities is crucial, especially\nin egocentric videos, where combining various sensory inputs significantly\nimproves tasks like action recognition and moment localization. However,\nreal-world applications often face challenges with incomplete modalities due to\nprivacy concerns, efficiency needs, or hardware issues. Current methods, while\neffective, often necessitate retraining the model entirely to handle missing\nmodalities, making them computationally intensive, particularly with large\ntraining datasets. In this study, we propose a novel approach to address this\nissue at test time without requiring retraining. We frame the problem as a\ntest-time adaptation task, where the model adjusts to the available unlabeled\ndata at test time. Our method, MiDl~(Mutual information with\nself-Distillation), encourages the model to be insensitive to the specific\nmodality source present during testing by minimizing the mutual information\nbetween the prediction and the available modality. Additionally, we incorporate\nself-distillation to maintain the model's original performance when both\nmodalities are available. MiDl represents the first self-supervised, online\nsolution for handling missing modalities exclusively at test time. Through\nexperiments with various pretrained models and datasets, MiDl demonstrates\nsubstantial performance improvement without the need for retraining.\n","authors":["Merey Ramazanova","Alejandro Pardo","Bernard Ghanem","Motasem Alfarra"],"pdf_url":"https://arxiv.org/pdf/2404.15161v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2502.20209v2","updated":"2025-03-02T13:36:57Z","published":"2025-02-27T15:50:21Z","title":"DIPSER: A Dataset for In-Person Student Engagement Recognition in the\n  Wild","summary":"  In this paper, a novel dataset is introduced, designed to assess student\nattention within in-person classroom settings. This dataset encompasses RGB\ncamera data, featuring multiple cameras per student to capture both posture and\nfacial expressions, in addition to smartwatch sensor data for each individual.\nThis dataset allows machine learning algorithms to be trained to predict\nattention and correlate it with emotion. A comprehensive suite of attention and\nemotion labels for each student is provided, generated through self-reporting\nas well as evaluations by four different experts. Our dataset uniquely combines\nfacial and environmental camera data, smartwatch metrics, and includes\nunderrepresented ethnicities in similar datasets, all within in-the-wild,\nin-person settings, making it the most comprehensive dataset of its kind\ncurrently available.\n  The dataset presented offers an extensive and diverse collection of data\npertaining to student interactions across different educational contexts,\naugmented with additional metadata from other tools. This initiative addresses\nexisting deficiencies by offering a valuable resource for the analysis of\nstudent attention and emotion in face-to-face lessons.\n","authors":["Luis Marquez-Carpintero","Sergio Suescun-Ferrandiz","Carolina Lorenzo lvarez","Jorge Fernandez-Herrero","Diego Viejo","Rosabel Roig-Vila","Miguel Cazorla"],"pdf_url":"https://arxiv.org/pdf/2502.20209v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2208.02820v2","updated":"2025-03-02T13:14:11Z","published":"2022-08-04T02:22:29Z","title":"MOVE: Effective and Harmless Ownership Verification via Embedded\n  External Features","summary":"  Currently, deep neural networks (DNNs) are widely adopted in different\napplications. Despite its commercial values, training a well-performing DNN is\nresource-consuming. Accordingly, the well-trained model is valuable\nintellectual property for its owner. However, recent studies revealed the\nthreats of model stealing, where the adversaries can obtain a function-similar\ncopy of the victim model, even when they can only query the model. In this\npaper, we propose an effective and harmless model ownership verification (MOVE)\nto defend against different types of model stealing simultaneously, without\nintroducing new security risks. In general, we conduct the ownership\nverification by verifying whether a suspicious model contains the knowledge of\ndefender-specified external features. Specifically, we embed the external\nfeatures by modifying a few training samples with style transfer. We then train\na meta-classifier to determine whether a model is stolen from the victim. This\napproach is inspired by the understanding that the stolen models should contain\nthe knowledge of features learned by the victim model. In particular,\n\\revision{we develop our MOVE method under both white-box and black-box\nsettings and analyze its theoretical foundation to provide comprehensive model\nprotection.} Extensive experiments on benchmark datasets verify the\neffectiveness of our method and its resistance to potential adaptive attacks.\nThe codes for reproducing the main experiments of our method are available at\nhttps://github.com/THUYimingLi/MOVE.\n","authors":["Yiming Li","Linghui Zhu","Xiaojun Jia","Yang Bai","Yong Jiang","Shu-Tao Xia","Xiaochun Cao","Kui Ren"],"pdf_url":"https://arxiv.org/pdf/2208.02820v2.pdf","comment":"This paper has been accepted by IEEE TPAMI 2025. It is the journal\n  extension of our conference paper in AAAI 2022\n  (https://ojs.aaai.org/index.php/AAAI/article/view/20036). 18 pages"},{"id":"http://arxiv.org/abs/2502.18461v2","updated":"2025-03-02T12:44:06Z","published":"2025-02-25T18:59:12Z","title":"K-LoRA: Unlocking Training-Free Fusion of Any Subject and Style LoRAs","summary":"  Recent studies have explored combining different LoRAs to jointly generate\nlearned style and content. However, existing methods either fail to effectively\npreserve both the original subject and style simultaneously or require\nadditional training. In this paper, we argue that the intrinsic properties of\nLoRA can effectively guide diffusion models in merging learned subject and\nstyle. Building on this insight, we propose K-LoRA, a simple yet effective\ntraining-free LoRA fusion approach. In each attention layer, K-LoRA compares\nthe Top-K elements in each LoRA to be fused, determining which LoRA to select\nfor optimal fusion. This selection mechanism ensures that the most\nrepresentative features of both subject and style are retained during the\nfusion process, effectively balancing their contributions. Experimental results\ndemonstrate that the proposed method effectively integrates the subject and\nstyle information learned by the original LoRAs, outperforming state-of-the-art\ntraining-based approaches in both qualitative and quantitative results.\n","authors":["Ziheng Ouyang","Zhen Li","Qibin Hou"],"pdf_url":"https://arxiv.org/pdf/2502.18461v2.pdf","comment":"CVPR 2025, Project page: https://k-lora.github.io/K-LoRA.io/"},{"id":"http://arxiv.org/abs/2406.15812v2","updated":"2025-03-02T12:28:24Z","published":"2024-06-22T10:36:04Z","title":"Intrinsic Dimension Correlation: uncovering nonlinear connections in\n  multimodal representations","summary":"  To gain insight into the mechanisms behind machine learning methods, it is\ncrucial to establish connections among the features describing data points.\nHowever, these correlations often exhibit a high-dimensional and strongly\nnonlinear nature, which makes them challenging to detect using standard\nmethods. This paper exploits the entanglement between intrinsic dimensionality\nand correlation to propose a metric that quantifies the (potentially nonlinear)\ncorrelation between high-dimensional manifolds. We first validate our method on\nsynthetic data in controlled environments, showcasing its advantages and\ndrawbacks compared to existing techniques. Subsequently, we extend our analysis\nto large-scale applications in neural network representations. Specifically, we\nfocus on latent representations of multimodal data, uncovering clear\ncorrelations between paired visual and textual embeddings, whereas existing\nmethods struggle significantly in detecting similarity. Our results indicate\nthe presence of highly nonlinear correlation patterns between latent manifolds.\n","authors":["Lorenzo Basile","Santiago Acevedo","Luca Bortolussi","Fabio Anselmi","Alex Rodriguez"],"pdf_url":"https://arxiv.org/pdf/2406.15812v2.pdf","comment":"Accepted at ICLR 2025"},{"id":"http://arxiv.org/abs/2409.20063v2","updated":"2025-03-02T12:17:51Z","published":"2024-09-30T08:05:00Z","title":"Q-Bench-Video: Benchmarking the Video Quality Understanding of LMMs","summary":"  With the rising interest in research on Large Multi-modal Models (LMMs) for\nvideo understanding, many studies have emphasized general video comprehension\ncapabilities, neglecting the systematic exploration into video quality\nunderstanding. To address this oversight, we introduce Q-Bench-Video in this\npaper, a new benchmark specifically designed to evaluate LMMs' proficiency in\ndiscerning video quality. a) To ensure video source diversity, Q-Bench-Video\nencompasses videos from natural scenes, AI-generated Content (AIGC), and\nComputer Graphics (CG). b) Building on the traditional multiple-choice\nquestions format with the Yes-or-No and What-How categories, we include\nOpen-ended questions to better evaluate complex scenarios. Additionally, we\nincorporate the video pair quality comparison question to enhance\ncomprehensiveness. c) Beyond the traditional Technical, Aesthetic, and Temporal\ndistortions, we have expanded our evaluation aspects to include the dimension\nof AIGC distortions, which addresses the increasing demand for video\ngeneration. Finally, we collect a total of 2,378 question-answer pairs and test\nthem on 12 open-source & 5 proprietary LMMs. Our findings indicate that while\nLMMs have a foundational understanding of video quality, their performance\nremains incomplete and imprecise, with a notable discrepancy compared to human\nperformance. Through Q-Bench-Video, we seek to catalyze community interest,\nstimulate further research, and unlock the untapped potential of LMMs to close\nthe gap in video quality understanding.\n","authors":["Zicheng Zhang","Ziheng Jia","Haoning Wu","Chunyi Li","Zijian Chen","Yingjie Zhou","Wei Sun","Xiaohong Liu","Xiongkuo Min","Weisi Lin","Guangtao Zhai"],"pdf_url":"https://arxiv.org/pdf/2409.20063v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.08470v2","updated":"2025-03-02T11:52:31Z","published":"2024-11-13T09:42:12Z","title":"HyperFace: Generating Synthetic Face Recognition Datasets by Exploring\n  Face Embedding Hypersphere","summary":"  Face recognition datasets are often collected by crawling Internet and\nwithout individuals' consents, raising ethical and privacy concerns. Generating\nsynthetic datasets for training face recognition models has emerged as a\npromising alternative. However, the generation of synthetic datasets remains\nchallenging as it entails adequate inter-class and intra-class variations.\nWhile advances in generative models have made it easier to increase intra-class\nvariations in face datasets (such as pose, illumination, etc.), generating\nsufficient inter-class variation is still a difficult task. In this paper, we\nformulate the dataset generation as a packing problem on the embedding space\n(represented on a hypersphere) of a face recognition model and propose a new\nsynthetic dataset generation approach, called HyperFace. We formalize our\npacking problem as an optimization problem and solve it with a gradient\ndescent-based approach. Then, we use a conditional face generator model to\nsynthesize face images from the optimized embeddings. We use our generated\ndatasets to train face recognition models and evaluate the trained models on\nseveral benchmarking real datasets. Our experimental results show that models\ntrained with HyperFace achieve state-of-the-art performance in training face\nrecognition using synthetic datasets.\n","authors":["Hatef Otroshi Shahreza","Sbastien Marcel"],"pdf_url":"https://arxiv.org/pdf/2411.08470v2.pdf","comment":"Accepted in ICLR 2025"},{"id":"http://arxiv.org/abs/2408.09886v3","updated":"2025-03-02T11:32:04Z","published":"2024-08-19T11:01:00Z","title":"Improved Baselines with Synchronized Encoding for Universal Medical\n  Image Segmentation","summary":"  Large foundation models, known for their strong zero-shot generalization\ncapabilities, can be applied to a wide range of downstream tasks. However,\ndeveloping foundation models for medical image segmentation poses a significant\nchallenge due to the domain gap between natural and medical images. While\nfine-tuning techniques based on the Segment Anything Model (SAM) have been\nexplored, they primarily focus on scaling up data or refining inference\nstrategies without incorporating domain-specific architectural designs,\nlimiting their zero-shot performance. To optimize segmentation performance\nunder standard inference settings and provide a strong baseline for future\nresearch, we introduce SyncSAM, which employs a synchronized dual-branch\nencoder that integrates convolution and Transformer features in a synchronized\nmanner to enhance medical image encoding, and a multi-scale dual-branch decoder\nto preserve image details. SyncSAM is trained on two of the largest medical\nimage segmentation datasets, SA-Med2D-20M and IMed-361M, resulting in a series\nof pre-trained models for universal medical image segmentation. Experimental\nresults demonstrate that SyncSAM not only achieves state-of-the-art performance\non test sets but also exhibits strong zero-shot capabilities on unseen\ndatasets. The code and model weights are available at\nhttps://github.com/Hhankyangg/SyncSAM.\n","authors":["Sihan Yang","Xuande Mi","Jiadong Feng","Haixia Bi","Hai Zhang","Jian Sun"],"pdf_url":"https://arxiv.org/pdf/2408.09886v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2501.15445v2","updated":"2025-03-02T11:16:08Z","published":"2025-01-26T08:22:44Z","title":"StochSync: Stochastic Diffusion Synchronization for Image Generation in\n  Arbitrary Spaces","summary":"  We propose a zero-shot method for generating images in arbitrary spaces\n(e.g., a sphere for 360{\\deg} panoramas and a mesh surface for texture) using a\npretrained image diffusion model. The zero-shot generation of various visual\ncontent using a pretrained image diffusion model has been explored mainly in\ntwo directions. First, Diffusion Synchronization-performing reverse diffusion\nprocesses jointly across different projected spaces while synchronizing them in\nthe target space-generates high-quality outputs when enough conditioning is\nprovided, but it struggles in its absence. Second, Score Distillation\nSampling-gradually updating the target space data through gradient\ndescent-results in better coherence but often lacks detail. In this paper, we\nreveal for the first time the interconnection between these two methods while\nhighlighting their differences. To this end, we propose StochSync, a novel\napproach that combines the strengths of both, enabling effective performance\nwith weak conditioning. Our experiments demonstrate that StochSync provides the\nbest performance in 360{\\deg} panorama generation (where image conditioning is\nnot given), outperforming previous finetuning-based methods, and also delivers\ncomparable results in 3D mesh texturing (where depth conditioning is provided)\nwith previous methods.\n","authors":["Kyeongmin Yeo","Jaihoon Kim","Minhyuk Sung"],"pdf_url":"https://arxiv.org/pdf/2501.15445v2.pdf","comment":"Project page: https://stochsync.github.io/ (ICLR 2025)"},{"id":"http://arxiv.org/abs/2410.05260v2","updated":"2025-03-02T10:58:06Z","published":"2024-10-07T17:58:22Z","title":"DartControl: A Diffusion-Based Autoregressive Motion Model for Real-Time\n  Text-Driven Motion Control","summary":"  Text-conditioned human motion generation, which allows for user interaction\nthrough natural language, has become increasingly popular. Existing methods\ntypically generate short, isolated motions based on a single input sentence.\nHowever, human motions are continuous and can extend over long periods,\ncarrying rich semantics. Creating long, complex motions that precisely respond\nto streams of text descriptions, particularly in an online and real-time\nsetting, remains a significant challenge. Furthermore, incorporating spatial\nconstraints into text-conditioned motion generation presents additional\nchallenges, as it requires aligning the motion semantics specified by text\ndescriptions with geometric information, such as goal locations and 3D scene\ngeometry. To address these limitations, we propose DartControl, in short DART,\na Diffusion-based Autoregressive motion primitive model for Real-time\nText-driven motion control. Our model effectively learns a compact motion\nprimitive space jointly conditioned on motion history and text inputs using\nlatent diffusion models. By autoregressively generating motion primitives based\non the preceding history and current text input, DART enables real-time,\nsequential motion generation driven by natural language descriptions.\nAdditionally, the learned motion primitive space allows for precise spatial\nmotion control, which we formulate either as a latent noise optimization\nproblem or as a Markov decision process addressed through reinforcement\nlearning. We present effective algorithms for both approaches, demonstrating\nour model's versatility and superior performance in various motion synthesis\ntasks. Experiments show our method outperforms existing baselines in motion\nrealism, efficiency, and controllability. Video results are available on the\nproject page: https://zkf1997.github.io/DART/.\n","authors":["Kaifeng Zhao","Gen Li","Siyu Tang"],"pdf_url":"https://arxiv.org/pdf/2410.05260v2.pdf","comment":"Updated ICLR camera ready version"},{"id":"http://arxiv.org/abs/2402.04236v3","updated":"2025-03-02T09:39:57Z","published":"2024-02-06T18:43:48Z","title":"CogCoM: A Visual Language Model with Chain-of-Manipulations Reasoning","summary":"  Vision-Language Models (VLMs) have demonstrated their broad effectiveness\nthanks to extensive training in aligning visual instructions to responses.\nHowever, such training of conclusive alignment leads models to ignore essential\nvisual reasoning, further resulting in failures in meticulous visual problems\nand unfaithful responses. Drawing inspiration from human cognition in solving\nvisual problems (e.g., marking, zoom in), this paper introduces Chain of\nManipulations, a mechanism that enables VLMs to solve problems step-by-step\nwith evidence. After training, models can solve various visual problems by\neliciting intrinsic manipulations (e.g., grounding, zoom in) with results\n(e.g., boxes, image) actively without involving external tools, while also\nallowing users to trace error causes. We study the roadmap to implement this\nmechanism, including (1) a flexible design of manipulations upon extensive\nanalysis, (2) an efficient automated data generation pipeline, (3) a compatible\nVLM architecture capable of multi-turn multi-image, and (4) a model training\nprocess for versatile capabilities. With the design, we also manually annotate\n6K high-quality samples for the challenging graphical mathematical problems.\nOur trained model, \\textbf{CogCoM}, equipped with this mechanism with 17B\nparameters achieves state-of-the-art performance across 9 benchmarks from 4\ncategories, demonstrating the effectiveness while preserving the\ninterpretability. Our code, model weights, and collected data are publicly\navailable at https://github.com/THUDM/CogCoM.\n","authors":["Ji Qi","Ming Ding","Weihan Wang","Yushi Bai","Qingsong Lv","Wenyi Hong","Bin Xu","Lei Hou","Juanzi Li","Yuxiao Dong","Jie Tang"],"pdf_url":"https://arxiv.org/pdf/2402.04236v3.pdf","comment":"21 pages, 10 figures"},{"id":"http://arxiv.org/abs/2502.18176v2","updated":"2025-03-02T09:22:47Z","published":"2025-02-25T13:09:34Z","title":"CLIPure: Purification in Latent Space via CLIP for Adversarially Robust\n  Zero-Shot Classification","summary":"  In this paper, we aim to build an adversarially robust zero-shot image\nclassifier. We ground our work on CLIP, a vision-language pre-trained encoder\nmodel that can perform zero-shot classification by matching an image with text\nprompts ``a photo of a <class-name>.''. Purification is the path we choose\nsince it does not require adversarial training on specific attack types and\nthus can cope with any foreseen attacks. We then formulate purification risk as\nthe KL divergence between the joint distributions of the purification process\nof denoising the adversarial samples and the attack process of adding\nperturbations to benign samples, through bidirectional Stochastic Differential\nEquations (SDEs). The final derived results inspire us to explore purification\nin the multi-modal latent space of CLIP. We propose two variants for our\nCLIPure approach: CLIPure-Diff which models the likelihood of images' latent\nvectors with the DiffusionPrior module in DaLLE-2 (modeling the generation\nprocess of CLIP's latent vectors), and CLIPure-Cos which models the likelihood\nwith the cosine similarity between the embeddings of an image and ``a photo of\na.''. As far as we know, CLIPure is the first purification method in\nmulti-modal latent space and CLIPure-Cos is the first purification method that\nis not based on generative models, which substantially improves defense\nefficiency. We conducted extensive experiments on CIFAR-10, ImageNet, and 13\ndatasets that previous CLIP-based defense methods used for evaluating zero-shot\nclassification robustness. Results show that CLIPure boosts the SOTA robustness\nby a large margin, e.g., from 71.7% to 91.1% on CIFAR10, from 59.6% to 72.6% on\nImageNet, and 108% relative improvements of average robustness on the 13\ndatasets over previous SOTA. The code is available at\nhttps://github.com/TMLResearchGroup-CAS/CLIPure.\n","authors":["Mingkun Zhang","Keping Bi","Wei Chen","Jiafeng Guo","Xueqi Cheng"],"pdf_url":"https://arxiv.org/pdf/2502.18176v2.pdf","comment":"accepted by ICLR 2025"},{"id":"http://arxiv.org/abs/2412.09765v2","updated":"2025-03-02T09:21:27Z","published":"2024-12-12T23:57:01Z","title":"L-WISE: Boosting Human Visual Category Learning Through Model-Based\n  Image Selection And Enhancement","summary":"  The currently leading artificial neural network models of the visual ventral\nstream - which are derived from a combination of performance optimization and\nrobustification methods - have demonstrated a remarkable degree of behavioral\nalignment with humans on visual categorization tasks. We show that image\nperturbations generated by these models can enhance the ability of humans to\naccurately report the ground truth class. Furthermore, we find that the same\nmodels can also be used out-of-the-box to predict the proportion of correct\nhuman responses to individual images, providing a simple, human-aligned\nestimator of the relative difficulty of each image. Motivated by these\nobservations, we propose to augment visual learning in humans in a way that\nimproves human categorization accuracy at test time. Our learning augmentation\napproach consists of (i) selecting images based on their model-estimated\nrecognition difficulty, and (ii) applying image perturbations that aid\nrecognition for novice learners. We find that combining these model-based\nstrategies leads to categorization accuracy gains of 33-72% relative to control\nsubjects without these interventions, on unmodified, randomly selected held-out\ntest images. Beyond the accuracy gain, the training time for the augmented\nlearning group was also shortened by 20-23%, despite both groups completing the\nsame number of training trials. We demonstrate the efficacy of our approach in\na fine-grained categorization task with natural images, as well as two tasks in\nclinically relevant image domains - histology and dermoscopy - where visual\nlearning is notoriously challenging. To the best of our knowledge, our work is\nthe first application of artificial neural networks to increase visual learning\nperformance in humans by enhancing category-specific image features.\n","authors":["Morgan B. Talbot","Gabriel Kreiman","James J. DiCarlo","Guy Gaziv"],"pdf_url":"https://arxiv.org/pdf/2412.09765v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2501.06751v2","updated":"2025-03-02T09:10:13Z","published":"2025-01-12T08:36:38Z","title":"Padding Tone: A Mechanistic Analysis of Padding Tokens in T2I Models","summary":"  Text-to-image (T2I) diffusion models rely on encoded prompts to guide the\nimage generation process. Typically, these prompts are extended to a fixed\nlength by adding padding tokens before text encoding. Despite being a default\npractice, the influence of padding tokens on the image generation process has\nnot been investigated. In this work, we conduct the first in-depth analysis of\nthe role padding tokens play in T2I models. We develop two causal techniques to\nanalyze how information is encoded in the representation of tokens across\ndifferent components of the T2I pipeline. Using these techniques, we\ninvestigate when and how padding tokens impact the image generation process.\nOur findings reveal three distinct scenarios: padding tokens may affect the\nmodel's output during text encoding, during the diffusion process, or be\neffectively ignored. Moreover, we identify key relationships between these\nscenarios and the model's architecture (cross or self-attention) and its\ntraining process (frozen or trained text encoder). These insights contribute to\na deeper understanding of the mechanisms of padding tokens, potentially\ninforming future model design and training practices in T2I systems.\n","authors":["Michael Toker","Ido Galil","Hadas Orgad","Rinon Gal","Yoad Tewel","Gal Chechik","Yonatan Belinkov"],"pdf_url":"https://arxiv.org/pdf/2501.06751v2.pdf","comment":"Published in: NAACL 2025. Project webpage:\n  https://padding-tone.github.io/"},{"id":"http://arxiv.org/abs/2410.06614v2","updated":"2025-03-02T08:59:29Z","published":"2024-10-09T07:09:46Z","title":"Pair-VPR: Place-Aware Pre-training and Contrastive Pair Classification\n  for Visual Place Recognition with Vision Transformers","summary":"  In this work we propose a novel joint training method for Visual Place\nRecognition (VPR), which simultaneously learns a global descriptor and a pair\nclassifier for re-ranking. The pair classifier can predict whether a given pair\nof images are from the same place or not. The network only comprises Vision\nTransformer components for both the encoder and the pair classifier, and both\ncomponents are trained using their respective class tokens. In existing VPR\nmethods, typically the network is initialized using pre-trained weights from a\ngeneric image dataset such as ImageNet. In this work we propose an alternative\npre-training strategy, by using Siamese Masked Image Modelling as a\npre-training task. We propose a Place-aware image sampling procedure from a\ncollection of large VPR datasets for pre-training our model, to learn visual\nfeatures tuned specifically for VPR. By re-using the Mask Image Modelling\nencoder and decoder weights in the second stage of training, Pair-VPR can\nachieve state-of-the-art VPR performance across five benchmark datasets with a\nViT-B encoder, along with further improvements in localization recall with\nlarger encoders. The Pair-VPR website is:\nhttps://csiro-robotics.github.io/Pair-VPR.\n","authors":["Stephen Hausler","Peyman Moghadam"],"pdf_url":"https://arxiv.org/pdf/2410.06614v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2502.20092v2","updated":"2025-03-02T08:56:15Z","published":"2025-02-27T13:51:56Z","title":"WalnutData: A UAV Remote Sensing Dataset of Green Walnuts and Model\n  Evaluation","summary":"  The UAV technology is gradually maturing and can provide extremely powerful\nsupport for smart agriculture and precise monitoring. Currently, there is no\ndataset related to green walnuts in the field of agricultural computer vision.\nThus, in order to promote the algorithm design in the field of agricultural\ncomputer vision, we used UAV to collect remote-sensing data from 8 walnut\nsample plots. Considering that green walnuts are subject to various lighting\nconditions and occlusion, we constructed a large-scale dataset with a\nhigher-granularity of target features - WalnutData. This dataset contains a\ntotal of 30,240 images and 706,208 instances, and there are 4 target\ncategories: being illuminated by frontal light and unoccluded (A1), being\nbacklit and unoccluded (A2), being illuminated by frontal light and occluded\n(B1), and being backlit and occluded (B2). Subsequently, we evaluated many\nmainstream algorithms on WalnutData and used these evaluation results as the\nbaseline standard. The dataset and all evaluation results can be obtained at\nhttps://github.com/1wuming/WalnutData.\n","authors":["Mingjie Wu","Chenggui Yang","Huihua Wang","Chen Xue","Yibo Wang","Haoyu Wang","Yansong Wang","Can Peng","Yuqi Han","Ruoyu Li","Lijun Yun","Zaiqing Chen","Songfan Shi","Luhao Fang","Shuyi Wan","Tingfeng Li","Shuangyao Liu","Haotian Feng"],"pdf_url":"https://arxiv.org/pdf/2502.20092v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.14808v2","updated":"2025-03-02T08:53:47Z","published":"2024-11-22T09:08:58Z","title":"High-Resolution Image Synthesis via Next-Token Prediction","summary":"  Recently, autoregressive models have demonstrated remarkable performance in\nclass-conditional image generation. However, the application of next-token\nprediction to high-resolution text-to-image generation remains largely\nunexplored. In this paper, we introduce \\textbf{D-JEPA$\\cdot$T2I}, an\nautoregressive model based on continuous tokens that incorporates innovations\nin both architecture and training strategy to generate high-quality,\nphotorealistic images at arbitrary resolutions, up to 4K. Architecturally, we\nadopt the denoising joint embedding predictive architecture (D-JEPA) while\nleveraging a multimodal visual transformer to effectively integrate textual and\nvisual features. Additionally, we introduce flow matching loss alongside the\nproposed Visual Rotary Positional Embedding (VoPE) to enable continuous\nresolution learning. In terms of training strategy, we propose a data feedback\nmechanism that dynamically adjusts the sampling procedure based on statistical\nanalysis and an online learning critic model. This encourages the model to move\nbeyond its comfort zone, reducing redundant training on well-mastered scenarios\nand compelling it to address more challenging cases with suboptimal generation\nquality. For the first time, we achieve state-of-the-art high-resolution image\nsynthesis via next-token prediction.\n","authors":["Dengsheng Chen","Jie Hu","Tiezhu Yue","Xiaoming Wei","Enhua Wu"],"pdf_url":"https://arxiv.org/pdf/2411.14808v2.pdf","comment":"31 pages"},{"id":"http://arxiv.org/abs/2411.03990v2","updated":"2025-03-02T08:11:34Z","published":"2024-11-06T15:30:42Z","title":"ET-SEED: Efficient Trajectory-Level SE(3) Equivariant Diffusion Policy","summary":"  Imitation learning, e.g., diffusion policy, has been proven effective in\nvarious robotic manipulation tasks. However, extensive demonstrations are\nrequired for policy robustness and generalization. To reduce the demonstration\nreliance, we leverage spatial symmetry and propose ET-SEED, an efficient\ntrajectory-level SE(3) equivariant diffusion model for generating action\nsequences in complex robot manipulation tasks. Further, previous equivariant\ndiffusion models require the per-step equivariance in the Markov process,\nmaking it difficult to learn policy under such strong constraints. We\ntheoretically extend equivariant Markov kernels and simplify the condition of\nequivariant diffusion process, thereby significantly improving training\nefficiency for trajectory-level SE(3) equivariant diffusion policy in an\nend-to-end manner. We evaluate ET-SEED on representative robotic manipulation\ntasks, involving rigid body, articulated and deformable object. Experiments\ndemonstrate superior data efficiency and manipulation proficiency of our\nproposed method, as well as its ability to generalize to unseen configurations\nwith only a few demonstrations. Website: https://et-seed.github.io/\n","authors":["Chenrui Tie","Yue Chen","Ruihai Wu","Boxuan Dong","Zeyi Li","Chongkai Gao","Hao Dong"],"pdf_url":"https://arxiv.org/pdf/2411.03990v2.pdf","comment":"Accept to ICLR 2025"},{"id":"http://arxiv.org/abs/2412.14169v2","updated":"2025-03-02T08:09:39Z","published":"2024-12-18T18:59:53Z","title":"Autoregressive Video Generation without Vector Quantization","summary":"  This paper presents a novel approach that enables autoregressive video\ngeneration with high efficiency. We propose to reformulate the video generation\nproblem as a non-quantized autoregressive modeling of temporal frame-by-frame\nprediction and spatial set-by-set prediction. Unlike raster-scan prediction in\nprior autoregressive models or joint distribution modeling of fixed-length\ntokens in diffusion models, our approach maintains the causal property of\nGPT-style models for flexible in-context capabilities, while leveraging\nbidirectional modeling within individual frames for efficiency. With the\nproposed approach, we train a novel video autoregressive model without vector\nquantization, termed NOVA. Our results demonstrate that NOVA surpasses prior\nautoregressive video models in data efficiency, inference speed, visual\nfidelity, and video fluency, even with a much smaller model capacity, i.e.,\n0.6B parameters. NOVA also outperforms state-of-the-art image diffusion models\nin text-to-image generation tasks, with a significantly lower training cost.\nAdditionally, NOVA generalizes well across extended video durations and enables\ndiverse zero-shot applications in one unified model. Code and models are\npublicly available at https://github.com/baaivision/NOVA.\n","authors":["Haoge Deng","Ting Pan","Haiwen Diao","Zhengxiong Luo","Yufeng Cui","Huchuan Lu","Shiguang Shan","Yonggang Qi","Xinlong Wang"],"pdf_url":"https://arxiv.org/pdf/2412.14169v2.pdf","comment":"Accepted to ICLR 2025. Project page at\n  https://github.com/baaivision/NOVA"},{"id":"http://arxiv.org/abs/2404.14396v2","updated":"2025-03-02T07:53:44Z","published":"2024-04-22T17:56:09Z","title":"SEED-X: Multimodal Models with Unified Multi-granularity Comprehension\n  and Generation","summary":"  The rapid evolution of multimodal foundation model has demonstrated\nsignificant progresses in vision-language understanding and generation, e.g.,\nour previous work SEED-LLaMA. However, there remains a gap between its\ncapability and the real-world applicability, primarily due to the model's\nlimited capacity to effectively respond to various user instructions and\ninteract with diverse visual data. In this work, we focus on bridging this gap\nthrough integrating two enhanced features: (1) comprehending images of\narbitrary sizes and ratios, and (2) enabling multi-granularity image\ngeneration. We present a unified and versatile foundation model, namely,\nSEED-X, which is able to model multi-granularity visual semantics for\ncomprehension and generation tasks. Besides the competitive results on public\nbenchmarks, SEED-X demonstrates its effectiveness in handling real-world\napplications across various domains after instruction tuning. We hope that our\nwork will inspire future research into what can be achieved by versatile\nmultimodal foundation models in real-world applications. The models, codes, and\ndatasets are released in https://github.com/AILab-CVC/SEED-X.\n","authors":["Yuying Ge","Sijie Zhao","Jinguo Zhu","Yixiao Ge","Kun Yi","Lin Song","Chen Li","Xiaohan Ding","Ying Shan"],"pdf_url":"https://arxiv.org/pdf/2404.14396v2.pdf","comment":"We added benchmark results (without updating models) and ablation\n  study in this version. Project released at:\n  https://github.com/AILab-CVC/SEED-X"},{"id":"http://arxiv.org/abs/2405.20986v2","updated":"2025-03-02T07:46:05Z","published":"2024-05-31T16:32:46Z","title":"Predictive Uncertainty Quantification for Bird's Eye View Segmentation:\n  A Benchmark and Novel Loss Function","summary":"  The fusion of raw sensor data to create a Bird's Eye View (BEV)\nrepresentation is critical for autonomous vehicle planning and control. Despite\nthe growing interest in using deep learning models for BEV semantic\nsegmentation, anticipating segmentation errors and enhancing the explainability\nof these models remain underexplored. This paper introduces a comprehensive\nbenchmark for predictive uncertainty quantification in BEV segmentation,\nevaluating multiple uncertainty quantification methods across three popular\ndatasets with three representative network architectures. Our study focuses on\nthe effectiveness of quantified uncertainty in detecting misclassified and\nout-of-distribution (OOD) pixels while also improving model calibration.\nThrough empirical analysis, we uncover challenges in existing uncertainty\nquantification methods and demonstrate the potential of evidential deep\nlearning techniques, which capture both aleatoric and epistemic uncertainty. To\naddress these challenges, we propose a novel loss function,\nUncertainty-Focal-Cross-Entropy (UFCE), specifically designed for highly\nimbalanced data, along with a simple uncertainty-scaling regularization term\nthat improves both uncertainty quantification and model calibration for BEV\nsegmentation.\n","authors":["Linlin Yu","Bowen Yang","Tianhao Wang","Kangshuo Li","Feng Chen"],"pdf_url":"https://arxiv.org/pdf/2405.20986v2.pdf","comment":"ICLR 2025"},{"id":"http://arxiv.org/abs/2410.03355v3","updated":"2025-03-02T07:45:09Z","published":"2024-10-04T12:21:03Z","title":"LANTERN: Accelerating Visual Autoregressive Models with Relaxed\n  Speculative Decoding","summary":"  Auto-Regressive (AR) models have recently gained prominence in image\ngeneration, often matching or even surpassing the performance of diffusion\nmodels. However, one major limitation of AR models is their sequential nature,\nwhich processes tokens one at a time, slowing down generation compared to\nmodels like GANs or diffusion-based methods that operate more efficiently.\nWhile speculative decoding has proven effective for accelerating LLMs by\ngenerating multiple tokens in a single forward, its application in visual AR\nmodels remains largely unexplored. In this work, we identify a challenge in\nthis setting, which we term \\textit{token selection ambiguity}, wherein visual\nAR models frequently assign uniformly low probabilities to tokens, hampering\nthe performance of speculative decoding. To overcome this challenge, we propose\na relaxed acceptance condition referred to as LANTERN that leverages the\ninterchangeability of tokens in latent space. This relaxation restores the\neffectiveness of speculative decoding in visual AR models by enabling more\nflexible use of candidate tokens that would otherwise be prematurely rejected.\nFurthermore, by incorporating a total variation distance bound, we ensure that\nthese speed gains are achieved without significantly compromising image quality\nor semantic coherence. Experimental results demonstrate the efficacy of our\nmethod in providing a substantial speed-up over speculative decoding. In\nspecific, compared to a na\\\"ive application of the state-of-the-art speculative\ndecoding, LANTERN increases speed-ups by $\\mathbf{1.75}\\times$ and\n$\\mathbf{1.82}\\times$, as compared to greedy decoding and random sampling,\nrespectively, when applied to LlamaGen, a contemporary visual AR model. The\ncode is publicly available at https://github.com/jadohu/LANTERN.\n","authors":["Doohyuk Jang","Sihwan Park","June Yong Yang","Yeonsung Jung","Jihun Yun","Souvik Kundu","Sung-Yub Kim","Eunho Yang"],"pdf_url":"https://arxiv.org/pdf/2410.03355v3.pdf","comment":"30 pages, 13 figures, Accepted to ICLR 2025 (poster)"},{"id":"http://arxiv.org/abs/2410.10010v3","updated":"2025-03-02T07:42:20Z","published":"2024-10-13T21:11:04Z","title":"InterMask: 3D Human Interaction Generation via Collaborative Masked\n  Modeling","summary":"  Generating realistic 3D human-human interactions from textual descriptions\nremains a challenging task. Existing approaches, typically based on diffusion\nmodels, often produce results lacking realism and fidelity. In this work, we\nintroduce InterMask, a novel framework for generating human interactions using\ncollaborative masked modeling in discrete space. InterMask first employs a\nVQ-VAE to transform each motion sequence into a 2D discrete motion token map.\nUnlike traditional 1D VQ token maps, it better preserves fine-grained\nspatio-temporal details and promotes spatial awareness within each token.\nBuilding on this representation, InterMask utilizes a generative masked\nmodeling framework to collaboratively model the tokens of two interacting\nindividuals. This is achieved by employing a transformer architecture\nspecifically designed to capture complex spatio-temporal inter-dependencies.\nDuring training, it randomly masks the motion tokens of both individuals and\nlearns to predict them. For inference, starting from fully masked sequences, it\nprogressively fills in the tokens for both individuals. With its enhanced\nmotion representation, dedicated architecture, and effective learning strategy,\nInterMask achieves state-of-the-art results, producing high-fidelity and\ndiverse human interactions. It outperforms previous methods, achieving an FID\nof $5.154$ (vs $5.535$ of in2IN) on the InterHuman dataset and $0.399$ (vs\n$5.207$ of InterGen) on the InterX dataset. Additionally, InterMask seamlessly\nsupports reaction generation without the need for model redesign or\nfine-tuning.\n","authors":["Muhammad Gohar Javed","Chuan Guo","Li Cheng","Xingyu Li"],"pdf_url":"https://arxiv.org/pdf/2410.10010v3.pdf","comment":"Project webpage: https://gohar-malik.github.io/intermask"},{"id":"http://arxiv.org/abs/2409.19835v2","updated":"2025-03-02T07:32:50Z","published":"2024-09-30T00:17:00Z","title":"MoCoLSK: Modality Conditioned High-Resolution Downscaling for Land\n  Surface Temperature","summary":"  Land Surface Temperature (LST) is a critical parameter for environmental\nstudies, but directly obtaining high spatial resolution LST data remains\nchallenging due to the spatio-temporal trade-off in satellite remote sensing.\nGuided LST downscaling has emerged as an alternative solution to overcome these\nlimitations, but current methods often neglect spatial non-stationarity, and\nthere is a lack of an open-source ecosystem for deep learning methods. In this\npaper, we propose the Modality-Conditional Large Selective Kernel (MoCoLSK)\nNetwork, a novel architecture that dynamically fuses multi-modal data through\nmodality-conditioned projections. MoCoLSK achieves a confluence of dynamic\nreceptive field adjustment and multi-modal feature fusion, leading to enhanced\nLST prediction accuracy. Furthermore, we establish the GrokLST project, a\ncomprehensive open-source ecosystem featuring the GrokLST dataset, a\nhigh-resolution benchmark, and the GrokLST toolkit, an open-source\nPyTorch-based toolkit encapsulating MoCoLSK alongside 40+ state-of-the-art\napproaches. Extensive experimental results validate MoCoLSK's effectiveness in\ncapturing complex dependencies and subtle variations within multispectral data,\noutperforming existing methods in LST downscaling. Our code, dataset, and\ntoolkit are available at https://github.com/GrokCV/GrokLST.\n","authors":["Qun Dai","Chunyang Yuan","Yimian Dai","Yuxuan Li","Xiang Li","Kang Ni","Jianhui Xu","Xiangbo Shu","Jian Yang"],"pdf_url":"https://arxiv.org/pdf/2409.19835v2.pdf","comment":"Accepted by IEEE TGRS"},{"id":"http://arxiv.org/abs/2502.10982v3","updated":"2025-03-02T07:31:57Z","published":"2025-02-16T04:00:06Z","title":"TEASER: Token Enhanced Spatial Modeling for Expressions Reconstruction","summary":"  3D facial reconstruction from a single in-the-wild image is a crucial task in\nhuman-centered computer vision tasks. While existing methods can recover\naccurate facial shapes, there remains significant space for improvement in\nfine-grained expression capture. Current approaches struggle with irregular\nmouth shapes, exaggerated expressions, and asymmetrical facial movements. We\npresent TEASER (Token EnhAnced Spatial modeling for Expressions\nReconstruction), which addresses these challenges and enhances 3D facial\ngeometry performance. TEASER tackles two main limitations of existing methods:\ninsufficient photometric loss for self-reconstruction and inaccurate\nlocalization of subtle expressions. We introduce a multi-scale tokenizer to\nextract facial appearance information. Combined with a neural renderer, these\ntokens provide precise geometric guidance for expression reconstruction.\nFurthermore, TEASER incorporates a pose-dependent landmark loss to further\nimprove geometric performances. Our approach not only significantly enhances\nexpression reconstruction quality but also offers interpretable tokens suitable\nfor various downstream applications, such as photorealistic facial video\ndriving, expression transfer, and identity swapping. Quantitative and\nqualitative experimental results across multiple datasets demonstrate that\nTEASER achieves state-of-the-art performance in precise expression\nreconstruction.\n","authors":["Yunfei Liu","Lei Zhu","Lijian Lin","Ye Zhu","Ailing Zhang","Yu Li"],"pdf_url":"https://arxiv.org/pdf/2502.10982v3.pdf","comment":"Accepted by ICLR 2025, code and demos are available at\n  https://tinyurl.com/TEASER-project"},{"id":"http://arxiv.org/abs/2501.19069v2","updated":"2025-03-02T07:22:57Z","published":"2025-01-31T11:55:17Z","title":"Improving vision-language alignment with graph spiking hybrid Networks","summary":"  To bridge the semantic gap between vision and language (VL), it is necessary\nto develop a good alignment strategy, which includes handling semantic\ndiversity, abstract representation of visual information, and generalization\nability of models. Recent works use detector-based bounding boxes or patches\nwith regular partitions to represent visual semantics. While current paradigms\nhave made strides, they are still insufficient for fully capturing the nuanced\ncontextual relations among various objects. This paper proposes a comprehensive\nvisual semantic representation module, necessitating the utilization of\npanoptic segmentation to generate coherent fine-grained semantic features.\nFurthermore, we propose a novel Graph Spiking Hybrid Network (GSHN) that\nintegrates the complementary advantages of Spiking Neural Networks (SNNs) and\nGraph Attention Networks (GATs) to encode visual semantic information.\nIntriguingly, the model not only encodes the discrete and continuous latent\nvariables of instances but also adeptly captures both local and global\ncontextual features, thereby significantly enhancing the richness and diversity\nof semantic representations. Leveraging the spatiotemporal properties inherent\nin SNNs, we employ contrastive learning (CL) to enhance the similarity-based\nrepresentation of embeddings. This strategy alleviates the computational\noverhead of the model and enriches meaningful visual representations by\nconstructing positive and negative sample pairs. We design an innovative\npre-training method, Spiked Text Learning (STL), which uses text features to\nimprove the encoding ability of discrete semantics. Experiments show that the\nproposed GSHN exhibits promising results on multiple VL downstream tasks.\n","authors":["Siyu Zhang","Wenzhe Liu","Yeming Chen","Yiming Wu","Heming Zheng","Cheng Cheng"],"pdf_url":"https://arxiv.org/pdf/2501.19069v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.11817v2","updated":"2025-03-02T07:05:19Z","published":"2024-10-15T17:46:31Z","title":"Improving Long-Text Alignment for Text-to-Image Diffusion Models","summary":"  The rapid advancement of text-to-image (T2I) diffusion models has enabled\nthem to generate unprecedented results from given texts. However, as text\ninputs become longer, existing encoding methods like CLIP face limitations, and\naligning the generated images with long texts becomes challenging. To tackle\nthese issues, we propose LongAlign, which includes a segment-level encoding\nmethod for processing long texts and a decomposed preference optimization\nmethod for effective alignment training. For segment-level encoding, long texts\nare divided into multiple segments and processed separately. This method\novercomes the maximum input length limits of pretrained encoding models. For\npreference optimization, we provide decomposed CLIP-based preference models to\nfine-tune diffusion models. Specifically, to utilize CLIP-based preference\nmodels for T2I alignment, we delve into their scoring mechanisms and find that\nthe preference scores can be decomposed into two components: a text-relevant\npart that measures T2I alignment and a text-irrelevant part that assesses other\nvisual aspects of human preference. Additionally, we find that the\ntext-irrelevant part contributes to a common overfitting problem during\nfine-tuning. To address this, we propose a reweighting strategy that assigns\ndifferent weights to these two components, thereby reducing overfitting and\nenhancing alignment. After fine-tuning $512 \\times 512$ Stable Diffusion (SD)\nv1.5 for about 20 hours using our method, the fine-tuned SD outperforms\nstronger foundation models in T2I alignment, such as PixArt-$\\alpha$ and\nKandinsky v2.2. The code is available at\nhttps://github.com/luping-liu/LongAlign.\n","authors":["Luping Liu","Chao Du","Tianyu Pang","Zehan Wang","Chongxuan Li","Dong Xu"],"pdf_url":"https://arxiv.org/pdf/2410.11817v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2501.03836v3","updated":"2025-03-02T06:41:56Z","published":"2025-01-07T14:45:39Z","title":"SCC-YOLO: An Improved Object Detector for Assisting in Brain Tumor\n  Diagnosis","summary":"  Brain tumors can lead to neurological dysfunction, cognitive and\npsychological changes, increased intracranial pressure, and seizures, posing\nsignificant risks to health. The You Only Look Once (YOLO) series has shown\nsuperior accuracy in medical imaging object detection. This paper presents a\nnovel SCC-YOLO architecture that integrates the SCConv module into YOLOv9. The\nSCConv module optimizes convolutional efficiency by reducing spatial and\nchannel redundancy, enhancing image feature learning. We examine the effects of\ndifferent attention mechanisms with YOLOv9 for brain tumor detection using the\nBr35H dataset and our custom dataset (Brain_Tumor_Dataset). Results indicate\nthat SCC-YOLO improved mAP50 by 0.3% on the Br35H dataset and by 0.5% on our\ncustom dataset compared to YOLOv9. SCC-YOLO achieves state-of-the-art\nperformance in brain tumor detection.\n","authors":["Runci Bai","Guibao Xu","Yanze Shi"],"pdf_url":"https://arxiv.org/pdf/2501.03836v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2412.03173v2","updated":"2025-03-02T06:24:05Z","published":"2024-12-04T09:53:09Z","title":"IRisPath: Enhancing Costmap for Off-Road Navigation with Robust IR-RGB\n  Fusion for Improved Day and Night Traversability","summary":"  Autonomous off-road navigation is required for applications in agriculture,\nconstruction, search and rescue and defence. Traditional on-road autonomous\nmethods struggle with dynamic terrains, leading to poor vehicle control in\noff-road conditions. Recent deep-learning models have used perception sensors\nalong with kinesthetic feedback for navigation on such terrains. However, this\napproach has out-of-domain uncertainty. Factors like change in time of day and\nweather impacts the performance of the model. We propose a multi modal fusion\nnetwork \"IRisPath\" capable of using Thermal and RGB images to provide\nrobustness against dynamic weather and light conditions. To aid further works\nin this domain, we also open-source a day-night dataset with Thermal and RGB\nimages along with pseudo-labels for traversability. In order to co-register for\nfusion model we also develop a novel method for targetless extrinsic\ncalibration of Thermal, LiDAR and RGB cameras with translation accuracy of\n+/-1.7cm and rotation accuracy of +/-0.827degrees.\n","authors":["Saksham Sharma","Akshit Raizada","Suresh Sundaram"],"pdf_url":"https://arxiv.org/pdf/2412.03173v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2306.12033v2","updated":"2025-03-02T06:19:58Z","published":"2023-06-21T05:48:51Z","title":"End-to-End Augmentation Hyperparameter Tuning for Self-Supervised\n  Anomaly Detection","summary":"  Self-supervised learning (SSL) has emerged as a promising paradigm that\npresents supervisory signals to real-world problems, bypassing the extensive\ncost of manual labeling. Consequently, self-supervised anomaly detection (SSAD)\nhas seen a recent surge of interest, since SSL is especially attractive for\nunsupervised tasks. However, recent works have reported that the choice of a\ndata augmentation function has significant impact on the accuracy of SSAD,\nposing augmentation search as an essential but nontrivial problem with the lack\nof labeled validation data. In this paper, we introduce ST-SSAD, the first\nsystematic approach for rigorous augmentation tuning on SSAD. To this end, our\nwork presents two key contributions. The first is a new unsupervised validation\nloss that quantifies the alignment between augmented training data and\nunlabeled validation data. The second is new differentiable augmentation\nfunctions, allowing data augmentation hyperparameter(s) to be tuned in an\nend-to-end manner. Experiments on two testbeds with semantic class anomalies\nand subtle industrial defects show that ST-SSAD gives significant performance\ngains over existing works.\n","authors":["Jaemin Yoo","Lingxiao Zhao","Leman Akoglu"],"pdf_url":"https://arxiv.org/pdf/2306.12033v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.03051v3","updated":"2025-03-02T06:17:12Z","published":"2024-10-04T00:13:54Z","title":"AuroraCap: Efficient, Performant Video Detailed Captioning and a New\n  Benchmark","summary":"  Video detailed captioning is a key task which aims to generate comprehensive\nand coherent textual descriptions of video content, benefiting both video\nunderstanding and generation. In this paper, we propose AuroraCap, a video\ncaptioner based on a large multimodal model. We follow the simplest\narchitecture design without additional parameters for temporal modeling. To\naddress the overhead caused by lengthy video sequences, we implement the token\nmerging strategy, reducing the number of input visual tokens. Surprisingly, we\nfound that this strategy results in little performance loss. AuroraCap shows\nsuperior performance on various video and image captioning benchmarks, for\nexample, obtaining a CIDEr of 88.9 on Flickr30k, beating GPT-4V (55.3) and\nGemini-1.5 Pro (82.2). However, existing video caption benchmarks only include\nsimple descriptions, consisting of a few dozen words, which limits research in\nthis field. Therefore, we develop VDC, a video detailed captioning benchmark\nwith over one thousand carefully annotated structured captions. In addition, we\npropose a new LLM-assisted metric VDCscore for bettering evaluation, which\nadopts a divide-and-conquer strategy to transform long caption evaluation into\nmultiple short question-answer pairs. With the help of human Elo ranking, our\nexperiments show that this benchmark better correlates with human judgments of\nvideo detailed captioning quality.\n","authors":["Wenhao Chai","Enxin Song","Yilun Du","Chenlin Meng","Vashisht Madhavan","Omer Bar-Tal","Jenq-Neng Hwang","Saining Xie","Christopher D. Manning"],"pdf_url":"https://arxiv.org/pdf/2410.03051v3.pdf","comment":"Accepted to ICLR 2025. Code, docs, weight, benchmark and training\n  data are all avaliable at https://rese1f.github.io/aurora-web/"},{"id":"http://arxiv.org/abs/2502.19260v2","updated":"2025-03-02T06:08:34Z","published":"2025-02-26T16:06:35Z","title":"EMT: A Visual Multi-Task Benchmark Dataset for Autonomous Driving in the\n  Arab Gulf Region","summary":"  This paper introduces the Emirates Multi-Task (EMT) dataset - the first\npublicly available dataset for autonomous driving collected in the Arab Gulf\nregion. The EMT dataset captures the unique road topology, high traffic\ncongestion, and distinctive characteristics of the Gulf region, including\nvariations in pedestrian clothing and weather conditions. It contains over\n30,000 frames from a dash-camera perspective, along with 570,000 annotated\nbounding boxes, covering approximately 150 kilometers of driving routes. The\nEMT dataset supports three primary tasks: tracking, trajectory forecasting and\nintention prediction. Each benchmark dataset is complemented with corresponding\nevaluations: (1) multi-agent tracking experiments, focusing on multi-class\nscenarios and occlusion handling; (2) trajectory forecasting evaluation using\ndeep sequential and interaction-aware models; and (3) intention benchmark\nexperiments conducted for predicting agents intentions from observed\ntrajectories. The dataset is publicly available at avlab.io/emt-dataset, and\npre-processing scripts along with evaluation models can be accessed at\ngithub.com/AV-Lab/emt-dataset.\n","authors":["Nadya Abdel Madjid","Murad Mebrahtu","Abdelmoamen Nasser","Bilal Hassan","Naoufel Werghi","Jorge Dias","Majid Khonji"],"pdf_url":"https://arxiv.org/pdf/2502.19260v2.pdf","comment":"19 pages, 6 figures"},{"id":"http://arxiv.org/abs/2502.08813v2","updated":"2025-03-02T05:50:08Z","published":"2025-02-12T21:55:26Z","title":"Measuring Anxiety Levels with Head Motion Patterns in Severe Depression\n  Population","summary":"  Depression and anxiety are prevalent mental health disorders that frequently\ncooccur, with anxiety significantly influencing both the manifestation and\ntreatment of depression. An accurate assessment of anxiety levels in\nindividuals with depression is crucial to develop effective and personalized\ntreatment plans. This study proposes a new noninvasive method for quantifying\nanxiety severity by analyzing head movements -- specifically speed,\nacceleration, and angular displacement -- during video-recorded interviews with\npatients suffering from severe depression. Using data from a new CALYPSO\nDepression Dataset, we extracted head motion characteristics and applied\nregression analysis to predict clinically evaluated anxiety levels. Our results\ndemonstrate a high level of precision, achieving a mean absolute error (MAE) of\n0.35 in predicting the severity of psychological anxiety based on head movement\npatterns. This indicates that our approach can enhance the understanding of\nanxiety's role in depression and assist psychiatrists in refining treatment\nstrategies for individuals.\n","authors":["Fouad Boutaleb","Emery Pierson","Nicolas Doudeau","Clmence Nineuil","Ali Amad","Mohamed Daoudi"],"pdf_url":"https://arxiv.org/pdf/2502.08813v2.pdf","comment":"19th IEEE International Conference on Automatic Face and Gesture\n  Recognition (FG), 2025"},{"id":"http://arxiv.org/abs/2411.01099v2","updated":"2025-03-02T05:33:33Z","published":"2024-11-02T01:31:47Z","title":"Few-Class Arena: A Benchmark for Efficient Selection of Vision Models\n  and Dataset Difficulty Measurement","summary":"  We propose Few-Class Arena (FCA), as a unified benchmark with focus on\ntesting efficient image classification models for few classes. A wide variety\nof benchmark datasets with many classes (80-1000) have been created to assist\nComputer Vision architectural evolution. An increasing number of vision models\nare evaluated with these many-class datasets. However, real-world applications\noften involve substantially fewer classes of interest (2-10). This gap between\nmany and few classes makes it difficult to predict performance of the few-class\napplications using models trained on the available many-class datasets. To\ndate, little has been offered to evaluate models in this Few-Class Regime. We\nconduct a systematic evaluation of the ResNet family trained on ImageNet\nsubsets from 2 to 1000 classes, and test a wide spectrum of Convolutional\nNeural Networks and Transformer architectures over ten datasets by using our\nnewly proposed FCA tool. Furthermore, to aid an up-front assessment of dataset\ndifficulty and a more efficient selection of models, we incorporate a\ndifficulty measure as a function of class similarity. FCA offers a new tool for\nefficient machine learning in the Few-Class Regime, with goals ranging from a\nnew efficient class similarity proposal, to lightweight model architecture\ndesign, to a new scaling law. FCA is user-friendly and can be easily extended\nto new models and datasets, facilitating future research work. Our benchmark is\navailable at https://github.com/bryanbocao/fca.\n","authors":["Bryan Bo Cao","Lawrence O'Gorman","Michael Coss","Shubham Jain"],"pdf_url":"https://arxiv.org/pdf/2411.01099v2.pdf","comment":"10 pages, 32 pages including References and Appendix, 19 figures, 8\n  tables"},{"id":"http://arxiv.org/abs/2410.03816v2","updated":"2025-03-02T05:29:42Z","published":"2024-10-04T18:47:49Z","title":"Modeling and Analysis of Spatial and Temporal Land Clutter Statistics in\n  SAR Imaging Based on MSTAR Data","summary":"  The statistical analysis of land clutter for Synthetic Aperture Radar (SAR)\nimaging has become an increasingly important subject for research and\ninvestigation. It is also absolutely necessary for designing robust algorithms\ncapable of performing the task of target detection in the background clutter.\nAny attempt to extract the energy of the desired targets from the land clutter\nrequires complete knowledge of the statistical properties of the background\nclutter. In this paper, the spatial as well as the temporal characteristics of\nthe land clutter are studied. Since the data for each image has been collected\nbased on a different aspect angle; therefore, the temporal analysis contains\nvariation in the aspect angle. Consequently, the temporal analysis includes the\ncharacteristics of the radar cross section with respect to the aspect angle\nbased on which the data has been collected. In order to perform the statistical\nanalysis, several well-known and relevant distributions, namely, Weibull,\nLog-normal, Gamma, and Rayleigh are considered as prime candidates to model the\nland clutter. The goodness-of-fit test is based on the Kullback-Leibler (KL)\nDivergence metric. The detailed analysis presented in this paper demonstrates\nthat the Weibull distribution is a more accurate fit for the\ntemporal-aspect-angle statistical analysis while the Rayleigh distribution\nmodels the spatial characteristics of the background clutter with higher\naccuracy. Finally, based on the aforementioned statistical analyses and by\nutilizing the Constant False Alarm Rate (CFAR) algorithm, we perform target\ndetection in land clutter. The overall verification of the analysis is\nperformed by exploiting the Moving and Stationary Target Acquisition and\nRecognition (MSTAR) data-set, which has been collected in spotlight mode at\nX-band, and the results are presented.\n","authors":["Shahrokh Hamidi"],"pdf_url":"https://arxiv.org/pdf/2410.03816v2.pdf","comment":"arXiv admin note: substantial text overlap with arXiv:2409.02155"},{"id":"http://arxiv.org/abs/2408.08258v3","updated":"2025-03-02T04:25:12Z","published":"2024-08-15T16:59:15Z","title":"Snuffy: Efficient Whole Slide Image Classifier","summary":"  Whole Slide Image (WSI) classification with multiple instance learning (MIL)\nin digital pathology faces significant computational challenges. Current\nmethods mostly rely on extensive self-supervised learning (SSL) for\nsatisfactory performance, requiring long training periods and considerable\ncomputational resources. At the same time, no pre-training affects performance\ndue to domain shifts from natural images to WSIs. We introduce Snuffy\narchitecture, a novel MIL-pooling method based on sparse transformers that\nmitigates performance loss with limited pre-training and enables continual\nfew-shot pre-training as a competitive option. Our sparsity pattern is tailored\nfor pathology and is theoretically proven to be a universal approximator with\nthe tightest probabilistic sharp bound on the number of layers for sparse\ntransformers, to date. We demonstrate Snuffy's effectiveness on CAMELYON16 and\nTCGA Lung cancer datasets, achieving superior WSI and patch-level accuracies.\nThe code is available on https://github.com/jafarinia/snuffy.\n","authors":["Hossein Jafarinia","Alireza Alipanah","Danial Hamdi","Saeed Razavi","Nahal Mirzaie","Mohammad Hossein Rohban"],"pdf_url":"https://arxiv.org/pdf/2408.08258v3.pdf","comment":"Accepted for ECCV 2024"},{"id":"http://arxiv.org/abs/2405.16071v2","updated":"2025-03-02T04:18:55Z","published":"2024-05-25T05:44:55Z","title":"DynRefer: Delving into Region-level Multimodal Tasks via Dynamic\n  Resolution","summary":"  One fundamental task of multimodal models is to translate referred image\nregions to human preferred language descriptions. Existing methods, however,\nignore the resolution adaptability needs of different tasks, which hinders them\nto find out precise language descriptions. In this study, we propose a DynRefer\napproach, to pursue high-accuracy region-level referring through mimicking the\nresolution adaptability of human visual cognition. During training, DynRefer\nstochastically aligns language descriptions of multimodal tasks with images of\nmultiple resolutions, which are constructed by nesting a set of random views\naround the referred region. During inference, DynRefer performs selectively\nmultimodal referring by sampling proper region representations for tasks from\nthe nested views based on image and task priors. This allows the visual\ninformation for referring to better match human preferences, thereby improving\nthe representational adaptability of region-level multimodal models.\nExperiments show that DynRefer brings mutual improvement upon broad tasks\nincluding region-level captioning, open-vocabulary region recognition and\nattribute detection. Furthermore, DynRefer achieves state-of-the-art results on\nmultiple region-level multimodal tasks using a single model. Code is available\nat https://github.com/callsys/DynRefer.\n","authors":["Yuzhong Zhao","Feng Liu","Yue Liu","Mingxiang Liao","Chen Gong","Qixiang Ye","Fang Wan"],"pdf_url":"https://arxiv.org/pdf/2405.16071v2.pdf","comment":"Accepted in CVPR 2025. Code is available at\n  https://github.com/callsys/DynRefer"},{"id":"http://arxiv.org/abs/2411.18018v2","updated":"2025-03-02T04:05:24Z","published":"2024-11-27T03:21:57Z","title":"Neural Finite-State Machines for Surgical Phase Recognition","summary":"  Surgical phase recognition (SPR) is crucial for applications in workflow\noptimization, performance evaluation, and real-time intervention guidance.\nHowever, current deep learning models often struggle with fragmented\npredictions, failing to capture the sequential nature of surgical workflows. We\npropose the Neural Finite-State Machine (NFSM), a novel approach that enforces\ntemporal coherence by integrating classical state-transition priors with modern\nneural networks. NFSM leverages learnable global state embeddings as unique\nphase identifiers and dynamic transition tables to model phase-to-phase\nprogressions. Additionally, a future phase forecasting mechanism employs\nrepeated frame padding to anticipate upcoming transitions. Implemented as a\nplug-and-play module, NFSM can be integrated into existing SPR pipelines\nwithout changing their core architectures. We demonstrate state-of-the-art\nperformance across multiple benchmarks, including a significant improvement on\nthe BernBypass70 dataset - raising video-level accuracy by 0.9 points and\nphase-level precision, recall, F1-score, and mAP by 3.8, 3.1, 3.3, and 4.1,\nrespectively. Ablation studies confirm each component's effectiveness and the\nmodule's adaptability to various architectures. By unifying finite-state\nprinciples with deep learning, NFSM offers a robust path toward consistent,\nlong-term surgical video analysis.\n","authors":["Hao Ding","Zhongpai Gao","Benjamin Planche","Tianyu Luan","Abhishek Sharma","Meng Zheng","Ange Lou","Terrence Chen","Mathias Unberath","Ziyan Wu"],"pdf_url":"https://arxiv.org/pdf/2411.18018v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2501.11069v3","updated":"2025-03-02T03:01:19Z","published":"2025-01-19T15:05:15Z","title":"Refinement Module based on Parse Graph of Feature Map for Human Pose\n  Estimation","summary":"  Parse graphs of the human body can be obtained in the human brain to help\nhumans complete the human Pose Estimation better (HPE). It contains a\nhierarchical structure, like a tree structure, and context relations among\nnodes. To equip models with such capabilities, many researchers predefine the\nparse graph of body structure to design HPE frameworks. However, these\nframeworks struggle to adapt to instances that deviate from the predefined\nparse graph and are often parameter-heavy. Unlike them, we view the feature map\nholistically, much like the human body. It can be optimized using parse graphs,\nwhere each node's feature is an implicit expression rather than a fixed one.\nThis allows it to adapt to more instances, unconstrained by rigid structural\nfeatures. In this paper, we design the Refinement Module based on the Parse\nGraph of feature map (RMPG), which includes two stages: top-down decomposition\nand bottom-up combination. In the first stage, the feature map is decomposed\ninto multiple sub-feature maps along the channel. In the second stage, the\ncontext relations of sub-feature maps are calculated to obtain their respective\ncontext information and the sub-feature maps with context information are\nconcatenated along channels to obtain the refined feature map. Additionally, we\ndesign a hierarchical network with fewer parameters using multiple RMPG modules\nto model the context relations and hierarchies in the parse graph of body\nstructure for HPE, some of which are supervised to obtain context relations\namong body parts. Our network achieves excellent results on multiple mainstream\nhuman pose datasets. More importantly, the effectiveness of RMPG is proven on\ndifferent methods. The code of RMPG will be open.\n","authors":["Shibang Liu","Xuemei Xie","Guangming Shi"],"pdf_url":"https://arxiv.org/pdf/2501.11069v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.20026v2","updated":"2025-03-02T02:45:56Z","published":"2024-10-26T00:49:06Z","title":"Towards Robust Algorithms for Surgical Phase Recognition via Digital\n  Twin Representation","summary":"  Surgical phase recognition (SPR) is an integral component of surgical data\nscience, enabling high-level surgical analysis. End-to-end trained neural\nnetworks that predict surgical phase directly from videos have shown excellent\nperformance on benchmarks. However, these models struggle with robustness due\nto non-causal associations in the training set. Our goal is to improve model\nrobustness to variations in the surgical videos by leveraging the digital twin\n(DT) paradigm -- an intermediary layer to separate high-level analysis (SPR)\nfrom low-level processing. As a proof of concept, we present a DT\nrepresentation-based framework for SPR from videos. The framework employs\nvision foundation models with reliable low-level scene understanding to craft\nDT representation. We embed the DT representation in place of raw video inputs\nin the state-of-the-art SPR model. The framework is trained on the Cholec80\ndataset and evaluated on out-of-distribution (OOD) and corrupted test samples.\nContrary to the vulnerability of the baseline model, our framework demonstrates\nstrong robustness on both OOD and corrupted samples, with a video-level\naccuracy of 80.3 on a highly corrupted Cholec80 test set, 67.9 on the\nchallenging CRCD dataset, and 99.8 on an internal robotic surgery dataset,\noutperforming the baseline by 3.9, 16.8, and 90.9 respectively. We also find\nthat using DT representation as an augmentation to the raw input can\nsignificantly improve model robustness. Our findings lend support to the thesis\nthat DT representations are effective in enhancing model robustness. Future\nwork will seek to improve the feature informativeness and incorporate\ninterpretability for a more comprehensive framework.\n","authors":["Hao Ding","Yuqian Zhang","Wenzheng Cheng","Xinyu Wang","Xu Lian","Chenhao Yu","Hongchao Shu","Ji Woong Kim","Axel Krieger","Mathias Unberath"],"pdf_url":"https://arxiv.org/pdf/2410.20026v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2401.04364v4","updated":"2025-03-02T02:32:25Z","published":"2024-01-09T05:32:22Z","title":"SoK: Systematization and Benchmarking of Deepfake Detectors in a Unified\n  Framework","summary":"  Deepfakes have rapidly emerged as a serious threat to society due to their\nease of creation and dissemination, triggering the accelerated development of\ndetection technologies. However, many existing detectors rely on labgenerated\ndatasets for validation, which may not prepare them for novel, real-world\ndeepfakes. This paper extensively reviews and analyzes state-of-the-art\ndeepfake detectors, evaluating them against several critical criteria. These\ncriteria categorize detectors into 4 high-level groups and 13 finegrained\nsub-groups, aligned with a unified conceptual framework we propose. This\nclassification offers practical insights into the factors affecting detector\nefficacy. We evaluate the generalizability of 16 leading detectors across\ncomprehensive attack scenarios, including black-box, white-box, and graybox\nsettings. Our systematized analysis and experiments provide a deeper\nunderstanding of deepfake detectors and their generalizability, paving the way\nfor future research and the development of more proactive defenses against\ndeepfakes.\n","authors":["Binh M. Le","Jiwon Kim","Simon S. Woo","Kristen Moore","Alsharif Abuadbba","Shahroz Tariq"],"pdf_url":"https://arxiv.org/pdf/2401.04364v4.pdf","comment":"20 pages, 6 figures, 7 table, Accepted at IEEE European Symposium on\n  security and privacy 2025 (EuroS&P '25)"},{"id":"http://arxiv.org/abs/2410.05470v2","updated":"2025-03-02T02:07:21Z","published":"2024-10-07T20:04:29Z","title":"Image Watermarks are Removable Using Controllable Regeneration from\n  Clean Noise","summary":"  Image watermark techniques provide an effective way to assert ownership,\ndeter misuse, and trace content sources, which has become increasingly\nessential in the era of large generative models. A critical attribute of\nwatermark techniques is their robustness against various manipulations. In this\npaper, we introduce a watermark removal approach capable of effectively\nnullifying state-of-the-art watermarking techniques. Our primary insight\ninvolves regenerating the watermarked image starting from a clean Gaussian\nnoise via a controllable diffusion model, utilizing the extracted semantic and\nspatial features from the watermarked image. The semantic control adapter and\nthe spatial control network are specifically trained to control the denoising\nprocess towards ensuring image quality and enhancing consistency between the\ncleaned image and the original watermarked image. To achieve a smooth trade-off\nbetween watermark removal performance and image consistency, we further propose\nan adjustable and controllable regeneration scheme. This scheme adds varying\nnumbers of noise steps to the latent representation of the watermarked image,\nfollowed by a controlled denoising process starting from this noisy latent\nrepresentation. As the number of noise steps increases, the latent\nrepresentation progressively approaches clean Gaussian noise, facilitating the\ndesired trade-off. We apply our watermark removal methods across various\nwatermarking techniques, and the results demonstrate that our methods offer\nsuperior visual consistency/quality and enhanced watermark removal performance\ncompared to existing regeneration approaches. Our code is available at\nhttps://github.com/yepengliu/CtrlRegen.\n","authors":["Yepeng Liu","Yiren Song","Hai Ci","Yu Zhang","Haofan Wang","Mike Zheng Shou","Yuheng Bu"],"pdf_url":"https://arxiv.org/pdf/2410.05470v2.pdf","comment":"ICLR2025"},{"id":"http://arxiv.org/abs/2502.10603v2","updated":"2025-03-02T01:50:22Z","published":"2025-02-14T23:18:54Z","title":"Adaptive Neural Networks for Intelligent Data-Driven Development","summary":"  Advances in machine learning methods for computer vision tasks have led to\ntheir consideration for safety-critical applications like autonomous driving.\nHowever, effectively integrating these methods into the automotive development\nlifecycle remains challenging. Since the performance of machine learning\nalgorithms relies heavily on the training data provided, the data and model\ndevelopment lifecycle play a key role in successfully integrating these\ncomponents into the product development lifecycle. Existing models frequently\nencounter difficulties recognizing or adapting to novel instances not present\nin the original training dataset. This poses a significant risk for reliable\ndeployment in dynamic environments. To address this challenge, we propose an\nadaptive neural network architecture and an iterative development framework\nthat enables users to efficiently incorporate previously unknown objects into\nthe current perception system. Our approach builds on continuous learning,\nemphasizing the necessity of dynamic updates to reflect real-world deployment\nconditions. Specifically, we introduce a pipeline with three key components:\n(1) a scalable network extension strategy to integrate new classes while\npreserving existing performance, (2) a dynamic OoD detection component that\nrequires no additional retraining for newly added classes, and (3) a\nretrieval-based data augmentation process tailored for safety-critical\ndeployments. The integration of these components establishes a pragmatic and\nadaptive pipeline for the continuous evolution of perception systems in the\ncontext of autonomous driving.\n","authors":["Youssef Shoeb","Azarm Nowzad","Hanno Gottschalk"],"pdf_url":"https://arxiv.org/pdf/2502.10603v2.pdf","comment":"8 pages, 3 figures, and 3 tables"},{"id":"http://arxiv.org/abs/2412.05707v3","updated":"2025-03-02T01:46:15Z","published":"2024-12-07T17:40:20Z","title":"Segment-Level Road Obstacle Detection Using Visual Foundation Model\n  Priors and Likelihood Ratios","summary":"  Detecting road obstacles is essential for autonomous vehicles to navigate\ndynamic and complex traffic environments safely. Current road obstacle\ndetection methods typically assign a score to each pixel and apply a threshold\nto generate final predictions. However, selecting an appropriate threshold is\nchallenging, and the per-pixel classification approach often leads to\nfragmented predictions with numerous false positives. In this work, we propose\na novel method that leverages segment-level features from visual foundation\nmodels and likelihood ratios to predict road obstacles directly. By focusing on\nsegments rather than individual pixels, our approach enhances detection\naccuracy, reduces false positives, and offers increased robustness to scene\nvariability. We benchmark our approach against existing methods on the\nRoadObstacle and LostAndFound datasets, achieving state-of-the-art performance\nwithout needing a predefined threshold.\n","authors":["Youssef Shoeb","Nazir Nayal","Azarm Nowzad","Fatma Gney","Hanno Gottschalk"],"pdf_url":"https://arxiv.org/pdf/2412.05707v3.pdf","comment":"10 pages, 4 figures, and 1 table, to be published in VISAPP 2025"},{"id":"http://arxiv.org/abs/2410.10594v2","updated":"2025-03-02T01:19:51Z","published":"2024-10-14T15:04:18Z","title":"VisRAG: Vision-based Retrieval-augmented Generation on Multi-modality\n  Documents","summary":"  Retrieval-augmented generation (RAG) is an effective technique that enables\nlarge language models (LLMs) to utilize external knowledge sources for\ngeneration. However, current RAG systems are solely based on text, rendering it\nimpossible to utilize vision information like layout and images that play\ncrucial roles in real-world multi-modality documents. In this paper, we\nintroduce VisRAG, which tackles this issue by establishing a vision-language\nmodel (VLM)-based RAG pipeline. In this pipeline, instead of first parsing the\ndocument to obtain text, the document is directly embedded using a VLM as an\nimage and then retrieved to enhance the generation of a VLM. Compared to\ntraditional text-based RAG, VisRAG maximizes the retention and utilization of\nthe data information in the original documents, eliminating the information\nloss introduced during the parsing process. We collect both open-source and\nsynthetic data to train the retriever in VisRAG and explore a variety of\ngeneration methods. Experiments demonstrate that VisRAG outperforms traditional\nRAG in both the retrieval and generation stages, achieving a 20--40% end-to-end\nperformance gain over traditional text-based RAG pipeline. Further analysis\nreveals that VisRAG is efficient in utilizing training data and demonstrates\nstrong generalization capability, positioning it as a promising solution for\nRAG on multi-modality documents. Our code and data are available at\nhttps://github.com/openbmb/visrag.\n","authors":["Shi Yu","Chaoyue Tang","Bokai Xu","Junbo Cui","Junhao Ran","Yukun Yan","Zhenghao Liu","Shuo Wang","Xu Han","Zhiyuan Liu","Maosong Sun"],"pdf_url":"https://arxiv.org/pdf/2410.10594v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2409.11219v3","updated":"2025-03-02T01:07:41Z","published":"2024-09-17T14:12:50Z","title":"Score Forgetting Distillation: A Swift, Data-Free Method for Machine\n  Unlearning in Diffusion Models","summary":"  The machine learning community is increasingly recognizing the importance of\nfostering trust and safety in modern generative AI (GenAI) models. We posit\nmachine unlearning (MU) as a crucial foundation for developing safe, secure,\nand trustworthy GenAI models. Traditional MU methods often rely on stringent\nassumptions and require access to real data. This paper introduces Score\nForgetting Distillation (SFD), an innovative MU approach that promotes the\nforgetting of undesirable information in diffusion models by aligning the\nconditional scores of \"unsafe\" classes or concepts with those of \"safe\" ones.\nTo eliminate the need for real data, our SFD framework incorporates a\nscore-based MU loss into the score distillation objective of a pretrained\ndiffusion model. This serves as a regularization term that preserves desired\ngeneration capabilities while enabling the production of synthetic data through\na one-step generator. Our experiments on pretrained label-conditional and\ntext-to-image diffusion models demonstrate that our method effectively\naccelerates the forgetting of target classes or concepts during generation,\nwhile preserving the quality of other classes or concepts. This unlearned and\ndistilled diffusion not only pioneers a novel concept in MU but also\naccelerates the generation speed of diffusion models. Our experiments and\nstudies on a range of diffusion models and datasets confirm that our approach\nis generalizable, effective, and advantageous for MU in diffusion models. Code\nis available at https://github.com/tqch/score-forgetting-distillation.\n($\\textbf{Warning:}$ This paper contains sexually explicit imagery, discussions\nof pornography, racially-charged terminology, and other content that some\nreaders may find disturbing, distressing, and/or offensive.)\n","authors":["Tianqi Chen","Shujian Zhang","Mingyuan Zhou"],"pdf_url":"https://arxiv.org/pdf/2409.11219v3.pdf","comment":"ICLR 2025"},{"id":"http://arxiv.org/abs/2502.02283v3","updated":"2025-03-02T00:25:45Z","published":"2025-02-04T12:50:16Z","title":"GP-GS: Gaussian Processes for Enhanced Gaussian Splatting","summary":"  3D Gaussian Splatting has emerged as an efficient photorealistic novel view\nsynthesis method. However, its reliance on sparse Structure-from-Motion (SfM)\npoint clouds consistently compromises the scene reconstruction quality. To\naddress these limitations, this paper proposes a novel 3D reconstruction\nframework Gaussian Processes Gaussian Splatting (GP-GS), where a multi-output\nGaussian Process model is developed to achieve adaptive and uncertainty-guided\ndensification of sparse SfM point clouds. Specifically, we propose a dynamic\nsampling and filtering pipeline that adaptively expands the SfM point clouds by\nleveraging GP-based predictions to infer new candidate points from the input 2D\npixels and depth maps. The pipeline utilizes uncertainty estimates to guide the\npruning of high-variance predictions, ensuring geometric consistency and\nenabling the generation of dense point clouds. The densified point clouds\nprovide high-quality initial 3D Gaussians to enhance reconstruction\nperformance. Extensive experiments conducted on synthetic and real-world\ndatasets across various scales validate the effectiveness and practicality of\nthe proposed framework.\n","authors":["Zhihao Guo","Jingxuan Su","Shenglin Wang","Jinlong Fan","Jing Zhang","Liangxiu Han","Peng Wang"],"pdf_url":"https://arxiv.org/pdf/2502.02283v3.pdf","comment":"14 pages,11 figures"},{"id":"http://arxiv.org/abs/2411.18810v4","updated":"2025-03-02T00:15:11Z","published":"2024-11-27T23:32:54Z","title":"All Seeds Are Not Equal: Enhancing Compositional Text-to-Image\n  Generation with Reliable Random Seeds","summary":"  Text-to-image diffusion models have demonstrated remarkable capability in\ngenerating realistic images from arbitrary text prompts. However, they often\nproduce inconsistent results for compositional prompts such as \"two dogs\" or \"a\npenguin on the right of a bowl\". Understanding these inconsistencies is crucial\nfor reliable image generation. In this paper, we highlight the significant role\nof initial noise in these inconsistencies, where certain noise patterns are\nmore reliable for compositional prompts than others. Our analyses reveal that\ndifferent initial random seeds tend to guide the model to place objects in\ndistinct image areas, potentially adhering to specific patterns of camera\nangles and image composition associated with the seed. To improve the model's\ncompositional ability, we propose a method for mining these reliable cases,\nresulting in a curated training set of generated images without requiring any\nmanual annotation. By fine-tuning text-to-image models on these generated\nimages, we significantly enhance their compositional capabilities. For\nnumerical composition, we observe relative increases of 29.3% and 19.5% for\nStable Diffusion and PixArt-{\\alpha}, respectively. Spatial composition sees\neven larger gains, with 60.7% for Stable Diffusion and 21.1% for\nPixArt-{\\alpha}.\n","authors":["Shuangqi Li","Hieu Le","Jingyi Xu","Mathieu Salzmann"],"pdf_url":"https://arxiv.org/pdf/2411.18810v4.pdf","comment":null}],"Information Retrieval":[{"id":"http://arxiv.org/abs/2410.10594v2","updated":"2025-03-02T01:19:51Z","published":"2024-10-14T15:04:18Z","title":"VisRAG: Vision-based Retrieval-augmented Generation on Multi-modality\n  Documents","summary":"  Retrieval-augmented generation (RAG) is an effective technique that enables\nlarge language models (LLMs) to utilize external knowledge sources for\ngeneration. However, current RAG systems are solely based on text, rendering it\nimpossible to utilize vision information like layout and images that play\ncrucial roles in real-world multi-modality documents. In this paper, we\nintroduce VisRAG, which tackles this issue by establishing a vision-language\nmodel (VLM)-based RAG pipeline. In this pipeline, instead of first parsing the\ndocument to obtain text, the document is directly embedded using a VLM as an\nimage and then retrieved to enhance the generation of a VLM. Compared to\ntraditional text-based RAG, VisRAG maximizes the retention and utilization of\nthe data information in the original documents, eliminating the information\nloss introduced during the parsing process. We collect both open-source and\nsynthetic data to train the retriever in VisRAG and explore a variety of\ngeneration methods. Experiments demonstrate that VisRAG outperforms traditional\nRAG in both the retrieval and generation stages, achieving a 20--40% end-to-end\nperformance gain over traditional text-based RAG pipeline. Further analysis\nreveals that VisRAG is efficient in utilizing training data and demonstrates\nstrong generalization capability, positioning it as a promising solution for\nRAG on multi-modality documents. Our code and data are available at\nhttps://github.com/openbmb/visrag.\n","authors":["Shi Yu","Chaoyue Tang","Bokai Xu","Junbo Cui","Junhao Ran","Yukun Yan","Zhenghao Liu","Shuo Wang","Xu Han","Zhiyuan Liu","Maosong Sun"],"pdf_url":"https://arxiv.org/pdf/2410.10594v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.01031v1","updated":"2025-03-02T21:33:49Z","published":"2025-03-02T21:33:49Z","title":"Can We Find the Code? An Empirical Study of Google Scholar's Code\n  Retrieval","summary":"  Academic codes associated with research papers are valuable resources for\nscholars. In specialized fields outside computer science, code availability is\noften limited, making effective code retrieval essential. Google Scholar is a\ncrucial academic search tool. If a code published in the paper is not\nretrievable via Google Scholar, its accessibility and impact are significantly\nreduced. This study takes the term \"accelerated degradation\" combined with\n\"reliability\" as an example, and finds that, for papers published by Elsevier,\nonly GitHub links included in abstracts are comprehensively retrieved by Google\nScholar. When such links appear within the main body of a paper, even in the\n\"Data Availability\" section, they may be ignored and become unsearchable. These\nfindings highlight the importance of strategically placing GitHub links in\nabstracts to enhance code discoverability on Google Scholar.\n","authors":["Shi-Shun Chen"],"pdf_url":"https://arxiv.org/pdf/2503.01031v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.01003v1","updated":"2025-03-02T19:59:41Z","published":"2025-03-02T19:59:41Z","title":"A Semantic Search Pipeline for Causality-driven Adhoc Information\n  Retrieval","summary":"  We present a unsupervised semantic search pipeline for the Causality-driven\nAdhoc Information Retrieval (CAIR-2021) shared task. The CAIR shared task\nexpands traditional information retrieval to support the retrieval of documents\ncontaining the likely causes of a query event. A successful system must be able\nto distinguish between topical documents and documents containing causal\ndescriptions of events that are causally related to the query event. Our\napproach involves aggregating results from multiple query strategies over a\nsemantic and lexical index. The proposed approach leads the CAIR-2021\nleaderboard and outperformed both traditional IR and pure semantic\nembedding-based approaches.\n","authors":["Dhairya Dalal","Sharmi Dev Gupta","Bentolhoda Binaei"],"pdf_url":"https://arxiv.org/pdf/2503.01003v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.01001v1","updated":"2025-03-02T19:43:35Z","published":"2025-03-02T19:43:35Z","title":"Towards An Efficient LLM Training Paradigm for CTR Prediction","summary":"  Large Language Models (LLMs) have demonstrated tremendous potential as the\nnext-generation ranking-based recommendation system. Many recent works have\nshown that LLMs can significantly outperform conventional click-through-rate\n(CTR) prediction approaches. Despite such promising results, the computational\ninefficiency inherent in the current training paradigm makes it particularly\nchallenging to train LLMs for ranking-based recommendation tasks on large\ndatasets. To train LLMs for CTR prediction, most existing studies adopt the\nprevalent ''sliding-window'' paradigm. Given a sequence of $m$ user\ninteractions, a unique training prompt is constructed for each interaction by\ndesignating it as the prediction target along with its preceding $n$\ninteractions serving as context. In turn, the sliding-window paradigm results\nin an overall complexity of $O(mn^2)$ that scales linearly with the length of\nuser interactions. Consequently, a direct adoption to train LLMs with such\nstrategy can result in prohibitively high training costs as the length of\ninteractions grows. To alleviate the computational inefficiency, we propose a\nnovel training paradigm, namely Dynamic Target Isolation (DTI), that\nstructurally parallelizes the training of $k$ (where $k >> 1$) target\ninteractions. Furthermore, we identify two major bottlenecks - hidden-state\nleakage and positional bias overfitting - that limit DTI to only scale up to a\nsmall value of $k$ (e.g., 5) then propose a computationally light solution to\neffectively tackle each. Through extensive experiments on three widely adopted\npublic CTR datasets, we empirically show that DTI reduces training time by an\naverage of $\\textbf{92%}$ (e.g., from $70.5$ hrs to $5.31$ hrs), without\ncompromising CTR prediction performance.\n","authors":["Allen Lin","Renqin Cai","Yun He","Hanchao Yu","Jing Qian","Rui Li","Qifan Wang","James Caverlee"],"pdf_url":"https://arxiv.org/pdf/2503.01001v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.00999v1","updated":"2025-03-02T19:39:29Z","published":"2025-03-02T19:39:29Z","title":"Federated Conversational Recommender System","summary":"  Conversational Recommender Systems (CRSs) have become increasingly popular as\na powerful tool for providing personalized recommendation experiences. By\ndirectly engaging with users in a conversational manner to learn their current\nand fine-grained preferences, a CRS can quickly derive recommendations that are\nrelevant and justifiable. However, existing conversational recommendation\nsystems (CRSs) typically rely on a centralized training and deployment process,\nwhich involves collecting and storing explicitly-communicated user preferences\nin a centralized repository. These fine-grained user preferences are completely\nhuman-interpretable and can easily be used to infer sensitive information\n(e.g., financial status, political stands, and health information) about the\nuser, if leaked or breached. To address the user privacy concerns in CRS, we\nfirst define a set of privacy protection guidelines for preserving user privacy\nunder the conversational recommendation setting. Based on these guidelines, we\npropose a novel federated conversational recommendation framework that\neffectively reduces the risk of exposing user privacy by (i) de-centralizing\nboth the historical interests estimation stage and the interactive preference\nelicitation stage and (ii) strictly bounding privacy leakage by enforcing\nuser-level differential privacy with meticulously selected privacy budgets.\nThrough extensive experiments, we show that the proposed framework not only\nsatisfies these user privacy protection guidelines, but also enables the system\nto achieve competitive recommendation performance even when compared to the\nstate-of-the-art non-private conversational recommendation approach.\n","authors":["Allen Lin","Jianling Wang","Ziwei Zhu","James Caverlee"],"pdf_url":"https://arxiv.org/pdf/2503.00999v1.pdf","comment":"ECIR 2024"},{"id":"http://arxiv.org/abs/2503.00863v1","updated":"2025-03-02T11:45:50Z","published":"2025-03-02T11:45:50Z","title":"Systematic Literature Review on Clinical Trial Eligibility Matching","summary":"  Clinical trial eligibility matching is a critical yet often labor-intensive\nand error-prone step in medical research, as it ensures that participants meet\nprecise criteria for safe and reliable study outcomes. Recent advances in\nNatural Language Processing (NLP) have shown promise in automating and\nimproving this process by rapidly analyzing large volumes of unstructured\nclinical text and structured electronic health record (EHR) data. In this\npaper, we present a systematic overview of current NLP methodologies applied to\nclinical trial eligibility screening, focusing on data sources, annotation\npractices, machine learning approaches, and real-world implementation\nchallenges. A comprehensive literature search (spanning Google Scholar,\nMendeley, and PubMed from 2015 to 2024) yielded high-quality studies, each\ndemonstrating the potential of techniques such as rule-based systems, named\nentity recognition, contextual embeddings, and ontology-based normalization to\nenhance patient matching accuracy. While results indicate substantial\nimprovements in screening efficiency and precision, limitations persist\nregarding data completeness, annotation consistency, and model scalability\nacross diverse clinical domains. The review highlights how explainable AI and\nstandardized ontologies can bolster clinician trust and broaden adoption.\nLooking ahead, further research into advanced semantic and temporal\nrepresentations, expanded data integration, and rigorous prospective\nevaluations is necessary to fully realize the transformative potential of NLP\nin clinical trial recruitment.\n","authors":["Muhammad Talha Sharif","Abdul Rehman"],"pdf_url":"https://arxiv.org/pdf/2503.00863v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.00781v1","updated":"2025-03-02T08:11:07Z","published":"2025-03-02T08:11:07Z","title":"Towards Efficient Educational Chatbots: Benchmarking RAG Frameworks","summary":"  Large Language Models (LLMs) have proven immensely beneficial in education by\ncapturing vast amounts of literature-based information, allowing them to\ngenerate context without relying on external sources. In this paper, we propose\na generative AI-powered GATE question-answering framework (GATE stands for\nGraduate Aptitude Test in Engineering) that leverages LLMs to explain GATE\nsolutions and support students in their exam preparation. We conducted\nextensive benchmarking to select the optimal embedding model and LLM,\nevaluating our framework based on criteria such as latency, faithfulness, and\nrelevance, with additional validation through human evaluation. Our chatbot\nintegrates state-of-the-art embedding models and LLMs to deliver accurate,\ncontext-aware responses. Through rigorous experimentation, we identified\nconfigurations that balance performance and computational efficiency, ensuring\na reliable chatbot to serve students' needs. Additionally, we discuss the\nchallenges faced in data processing and modeling and implemented solutions. Our\nwork explores the application of Retrieval-Augmented Generation (RAG) for GATE\nQ/A explanation tasks, and our findings demonstrate significant improvements in\nretrieval accuracy and response quality. This research offers practical\ninsights for developing effective AI-driven educational tools while\nhighlighting areas for future enhancement in usability and scalability.\n","authors":["Umar Ali Khan","Ekram Khan","Fiza Khan","Athar Ali Moinuddin"],"pdf_url":"https://arxiv.org/pdf/2503.00781v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.00674v1","updated":"2025-03-02T00:28:55Z","published":"2025-03-02T00:28:55Z","title":"OrdRankBen: A Novel Ranking Benchmark for Ordinal Relevance in NLP","summary":"  The evaluation of ranking tasks remains a significant challenge in natural\nlanguage processing (NLP), particularly due to the lack of direct labels for\nresults in real-world scenarios. Benchmark datasets play a crucial role in\nproviding standardized testbeds that ensure fair comparisons, enhance\nreproducibility, and enable progress tracking, facilitating rigorous assessment\nand continuous improvement of ranking models. Existing NLP ranking benchmarks\ntypically use binary relevance labels or continuous relevance scores,\nneglecting ordinal relevance scores. However, binary labels oversimplify\nrelevance distinctions, while continuous scores lack a clear ordinal structure,\nmaking it challenging to capture nuanced ranking differences effectively. To\naddress these challenges, we introduce OrdRankBen, a novel benchmark designed\nto capture multi-granularity relevance distinctions. Unlike conventional\nbenchmarks, OrdRankBen incorporates structured ordinal labels, enabling more\nprecise ranking evaluations. Given the absence of suitable datasets for ordinal\nrelevance ranking in NLP, we constructed two datasets with distinct ordinal\nlabel distributions. We further evaluate various models for three model types,\nranking-based language models, general large language models, and\nranking-focused large language models on these datasets. Experimental results\nshow that ordinal relevance modeling provides a more precise evaluation of\nranking models, improving their ability to distinguish multi-granularity\ndifferences among ranked items-crucial for tasks that demand fine-grained\nrelevance differentiation.\n","authors":["Yan Wang","Lingfei Qian","Xueqing Peng","Jimin Huang","Dongji Feng"],"pdf_url":"https://arxiv.org/pdf/2503.00674v1.pdf","comment":"6 pages"},{"id":"http://arxiv.org/abs/2503.04796v1","updated":"2025-03-02T11:33:22Z","published":"2025-03-02T11:33:22Z","title":"Optimizing Multi-Hop Document Retrieval Through Intermediate\n  Representations","summary":"  Retrieval-augmented generation (RAG) encounters challenges when addressing\ncomplex queries, particularly multi-hop questions. While several methods tackle\nmulti-hop queries by iteratively generating internal queries and retrieving\nexternal documents, these approaches are computationally expensive. In this\npaper, we identify a three-stage information processing pattern in LLMs during\nlayer-by-layer reasoning, consisting of extraction, processing, and subsequent\nextraction steps. This observation suggests that the representations in\nintermediate layers contain richer information compared to those in other\nlayers. Building on this insight, we propose Layer-wise RAG (L-RAG). Unlike\nprior methods that focus on generating new internal queries, L-RAG leverages\nintermediate representations from the middle layers, which capture next-hop\ninformation, to retrieve external knowledge. L-RAG achieves performance\ncomparable to multi-step approaches while maintaining inference overhead\nsimilar to that of standard RAG. Experimental results show that L-RAG\noutperforms existing RAG methods on open-domain multi-hop question-answering\ndatasets, including MuSiQue, HotpotQA, and 2WikiMultiHopQA. The code is\navailable in https://anonymous.4open.science/r/L-RAG-ADD5/\n","authors":["Jiaen Lin","Jingyu Liu"],"pdf_url":"https://arxiv.org/pdf/2503.04796v1.pdf","comment":null}],"Machine Learning":[{"id":"http://arxiv.org/abs/2408.15998v2","updated":"2025-03-02T23:41:37Z","published":"2024-08-28T17:59:31Z","title":"Eagle: Exploring The Design Space for Multimodal LLMs with Mixture of\n  Encoders","summary":"  The ability to accurately interpret complex visual information is a crucial\ntopic of multimodal large language models (MLLMs). Recent work indicates that\nenhanced visual perception significantly reduces hallucinations and improves\nperformance on resolution-sensitive tasks, such as optical character\nrecognition and document analysis. A number of recent MLLMs achieve this goal\nusing a mixture of vision encoders. Despite their success, there is a lack of\nsystematic comparisons and detailed ablation studies addressing critical\naspects, such as expert selection and the integration of multiple vision\nexperts. This study provides an extensive exploration of the design space for\nMLLMs using a mixture of vision encoders and resolutions. Our findings reveal\nseveral underlying principles common to various existing strategies, leading to\na streamlined yet effective design approach. We discover that simply\nconcatenating visual tokens from a set of complementary vision encoders is as\neffective as more complex mixing architectures or strategies. We additionally\nintroduce Pre-Alignment to bridge the gap between vision-focused encoders and\nlanguage tokens, enhancing model coherence. The resulting family of MLLMs,\nEagle, surpasses other leading open-source models on major MLLM benchmarks.\n","authors":["Min Shi","Fuxiao Liu","Shihao Wang","Shijia Liao","Subhashree Radhakrishnan","Yilin Zhao","De-An Huang","Hongxu Yin","Karan Sapra","Yaser Yacoob","Humphrey Shi","Bryan Catanzaro","Andrew Tao","Jan Kautz","Zhiding Yu","Guilin Liu"],"pdf_url":"https://arxiv.org/pdf/2408.15998v2.pdf","comment":"Github: https://github.com/NVlabs/Eagle, HuggingFace:\n  https://huggingface.co/NVEagle"},{"id":"http://arxiv.org/abs/2411.09851v3","updated":"2025-03-02T23:29:50Z","published":"2024-11-15T00:09:37Z","title":"SymbolFit: Automatic Parametric Modeling with Symbolic Regression","summary":"  We introduce SymbolFit, a framework that automates parametric modeling by\nusing symbolic regression to perform a machine-search for functions that fit\nthe data while simultaneously providing uncertainty estimates in a single run.\nTraditionally, constructing a parametric model to accurately describe binned\ndata has been a manual and iterative process, requiring an adequate functional\nform to be determined before the fit can be performed. The main challenge\narises when the appropriate functional forms cannot be derived from first\nprinciples, especially when there is no underlying true closed-form function\nfor the distribution. In this work, we develop a framework that automates and\nstreamlines the process by utilizing symbolic regression, a machine learning\ntechnique that explores a vast space of candidate functions without requiring a\npredefined functional form because the functional form itself is treated as a\ntrainable parameter, making the process far more efficient and effortless than\ntraditional regression methods. We demonstrate the framework in high-energy\nphysics experiments at the CERN Large Hadron Collider (LHC) using five real\nproton-proton collision datasets from new physics searches, including\nbackground modeling in resonance searches for high-mass dijet, trijet,\npaired-dijet, diphoton, and dimuon events. We show that our framework can\nflexibly and efficiently generate a wide range of candidate functions that fit\na nontrivial distribution well using a simple fit configuration that varies\nonly by random seed, and that the same fit configuration, which defines a vast\nfunction space, can also be applied to distributions of different shapes,\nwhereas achieving a comparable result with traditional methods would have\nrequired extensive manual effort.\n","authors":["Ho Fung Tsoi","Dylan Rankin","Cecile Caillol","Miles Cranmer","Sridhara Dasu","Javier Duarte","Philip Harris","Elliot Lipeles","Vladimir Loncar"],"pdf_url":"https://arxiv.org/pdf/2411.09851v3.pdf","comment":"50 pages, 35 figures. Under review. The API can be used\n  out-of-the-box and is available at https://github.com/hftsoi/symbolfit"},{"id":"http://arxiv.org/abs/2401.17116v2","updated":"2025-03-02T23:04:57Z","published":"2024-01-30T15:50:06Z","title":"Quantum time dynamics mediated by the Yang-Baxter equation and\n  artificial neural networks","summary":"  Quantum computing shows great potential, but errors pose a significant\nchallenge. This study explores new strategies for mitigating quantum errors\nusing artificial neural networks (ANN) and the Yang-Baxter equation (YBE).\nUnlike traditional error mitigation methods, which are computationally\nintensive, we investigate artificial error mitigation. We developed a novel\nmethod that combines ANN for noise mitigation combined with the YBE to generate\nnoisy data. This approach effectively reduces noise in quantum simulations,\nenhancing the accuracy of the results. The YBE rigorously preserves quantum\ncorrelations and symmetries in spin chain simulations in certain classes of\nintegrable lattice models, enabling effective compression of quantum circuits\nwhile retaining linear scalability with the number of qubits. This compression\nfacilitates both full and partial implementations, allowing the generation of\nnoisy quantum data on hardware alongside noiseless simulations using classical\nplatforms. By introducing controlled noise through the YBE, we enhance the\ndataset for error mitigation. We train an ANN model on partial data from\nquantum simulations, demonstrating its effectiveness in mitigating errors in\ntime-evolving quantum states, providing a scalable framework to enhance quantum\ncomputation fidelity, particularly in noisy intermediate-scale quantum (NISQ)\nsystems. We demonstrate the efficacy of this approach by performing quantum\ntime dynamics simulations using the Heisenberg XY Hamiltonian on real quantum\ndevices.\n","authors":["Sahil Gulania","Yuri Alexeev","Stephen K. Gray","Bo Peng","Niranjan Govind"],"pdf_url":"https://arxiv.org/pdf/2401.17116v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2402.13496v2","updated":"2025-03-02T22:34:01Z","published":"2024-02-21T03:14:45Z","title":"Heterogeneous Graph Neural Network on Semantic Tree","summary":"  The recent past has seen an increasing interest in Heterogeneous Graph Neural\nNetworks (HGNNs), since many real-world graphs are heterogeneous in nature,\nfrom citation graphs to email graphs. However, existing methods ignore a tree\nhierarchy among metapaths, naturally constituted by different node types and\nrelation types. In this paper, we present HetTree, a novel HGNN that models\nboth the graph structure and heterogeneous aspects in a scalable and effective\nmanner. Specifically, HetTree builds a semantic tree data structure to capture\nthe hierarchy among metapaths. To effectively encode the semantic tree, HetTree\nuses a novel subtree attention mechanism to emphasize metapaths that are more\nhelpful in encoding parent-child relationships. Moreover, HetTree proposes\ncarefully matching pre-computed features and labels correspondingly,\nconstituting a complete metapath representation. Our evaluation of HetTree on a\nvariety of real-world datasets demonstrates that it outperforms all existing\nbaselines on open benchmarks and efficiently scales to large real-world graphs\nwith millions of nodes and edges.\n","authors":["Mingyu Guan","Jack W. Stokes","Qinlong Luo","Fuchen Liu","Purvanshi Mehta","Elnaz Nouri","Taesoo Kim"],"pdf_url":"https://arxiv.org/pdf/2402.13496v2.pdf","comment":"Accepted at AAAI 2025"},{"id":"http://arxiv.org/abs/2407.11249v3","updated":"2025-03-02T22:12:01Z","published":"2024-07-15T21:32:58Z","title":"Disentangling Representations through Multi-task Learning","summary":"  Intelligent perception and interaction with the world hinges on internal\nrepresentations that capture its underlying structure (''disentangled'' or\n''abstract'' representations). Disentangled representations serve as world\nmodels, isolating latent factors of variation in the world along approximately\northogonal directions, thus facilitating feature-based generalization. We\nprovide experimental and theoretical results guaranteeing the emergence of\ndisentangled representations in agents that optimally solve multi-task evidence\naccumulation classification tasks, canonical in the neuroscience literature.\nThe key conceptual finding is that, by producing accurate multi-task\nclassification estimates, a system implicitly represents a set of coordinates\nspecifying a disentangled representation of the underlying latent state of the\ndata it receives. The theory provides conditions for the emergence of these\nrepresentations in terms of noise, number of tasks, and evidence accumulation\ntime. We experimentally validate these predictions in RNNs trained to\nmulti-task, which learn disentangled representations in the form of continuous\nattractors, leading to zero-shot out-of-distribution (OOD) generalization in\npredicting latent factors. We demonstrate the robustness of our framework\nacross autoregressive architectures, decision boundary geometries and in tasks\nrequiring classification confidence estimation. We find that transformers are\nparticularly suited for disentangling representations, which might explain\ntheir unique world understanding abilities. Overall, our framework establishes\na formal link between competence at multiple tasks and the formation of\ndisentangled, interpretable world models in both biological and artificial\nsystems, and helps explain why ANNs often arrive at human-interpretable\nconcepts, and how they both may acquire exceptional zero-shot generalization\ncapabilities.\n","authors":["Pantelis Vafidis","Aman Bhargava","Antonio Rangel"],"pdf_url":"https://arxiv.org/pdf/2407.11249v3.pdf","comment":"43 pages, 17 figures"},{"id":"http://arxiv.org/abs/2406.10279v3","updated":"2025-03-02T21:03:52Z","published":"2024-06-12T03:29:06Z","title":"We Have a Package for You! A Comprehensive Analysis of Package\n  Hallucinations by Code Generating LLMs","summary":"  The reliance of popular programming languages such as Python and JavaScript\non centralized package repositories and open-source software, combined with the\nemergence of code-generating Large Language Models (LLMs), has created a new\ntype of threat to the software supply chain: package hallucinations. These\nhallucinations, which arise from fact-conflicting errors when generating code\nusing LLMs, represent a novel form of package confusion attack that poses a\ncritical threat to the integrity of the software supply chain. This paper\nconducts a rigorous and comprehensive evaluation of package hallucinations\nacross different programming languages, settings, and parameters, exploring how\na diverse set of models and configurations affect the likelihood of generating\nerroneous package recommendations and identifying the root causes of this\nphenomenon. Using 16 popular LLMs for code generation and two unique prompt\ndatasets, we generate 576,000 code samples in two programming languages that we\nanalyze for package hallucinations. Our findings reveal that that the average\npercentage of hallucinated packages is at least 5.2% for commercial models and\n21.7% for open-source models, including a staggering 205,474 unique examples of\nhallucinated package names, further underscoring the severity and pervasiveness\nof this threat. To overcome this problem, we implement several hallucination\nmitigation strategies and show that they are able to significantly reduce the\nnumber of package hallucinations while maintaining code quality. Our\nexperiments and findings highlight package hallucinations as a persistent and\nsystemic phenomenon while using state-of-the-art LLMs for code generation, and\na significant challenge which deserves the research community's urgent\nattention.\n","authors":["Joseph Spracklen","Raveen Wijewickrama","A H M Nazmus Sakib","Anindya Maiti","Bimal Viswanath","Murtuza Jadliwala"],"pdf_url":"https://arxiv.org/pdf/2406.10279v3.pdf","comment":"To appear in the 2025 USENIX Security Symposium. 22 pages, 14\n  figures, 8 tables. Edited from original version for submission to a different\n  conference. No change to original results or findings"},{"id":"http://arxiv.org/abs/2410.06232v3","updated":"2025-03-02T20:40:21Z","published":"2024-10-08T17:41:37Z","title":"Range, not Independence, Drives Modularity in Biologically Inspired\n  Representations","summary":"  Why do biological and artificial neurons sometimes modularise, each encoding\na single meaningful variable, and sometimes entangle their representation of\nmany variables? In this work, we develop a theory of when biologically inspired\nnetworks -- those that are nonnegative and energy efficient -- modularise their\nrepresentation of source variables (sources). We derive necessary and\nsufficient conditions on a sample of sources that determine whether the neurons\nin an optimal biologically-inspired linear autoencoder modularise. Our theory\napplies to any dataset, extending far beyond the case of statistical\nindependence studied in previous work. Rather we show that sources modularise\nif their support is ``sufficiently spread''. From this theory, we extract and\nvalidate predictions in a variety of empirical studies on how data distribution\naffects modularisation in nonlinear feedforward and recurrent neural networks\ntrained on supervised and unsupervised tasks. Furthermore, we apply these ideas\nto neuroscience data, showing that range independence can be used to understand\nthe mixing or modularising of spatial and reward information in entorhinal\nrecordings in seemingly conflicting experiments. Further, we use these results\nto suggest alternate origins of mixed-selectivity, beyond the predominant\ntheory of flexible nonlinear classification. In sum, our theory prescribes\nprecise conditions on when neural activities modularise, providing tools for\ninducing and elucidating modular representations in brains and machines.\n","authors":["Will Dorrell","Kyle Hsu","Luke Hollingsworth","Jin Hwa Lee","Jiajun Wu","Chelsea Finn","Peter E Latham","Tim EJ Behrens","James CR Whittington"],"pdf_url":"https://arxiv.org/pdf/2410.06232v3.pdf","comment":"47 pages, 17 figures. WD and KH contributed equally; LH and JHL\n  contributed equally"},{"id":"http://arxiv.org/abs/2408.15905v2","updated":"2025-03-02T20:30:28Z","published":"2024-08-28T16:19:35Z","title":"MetaGFN: Exploring Distant Modes with Adapted Metadynamics for\n  Continuous GFlowNets","summary":"  Generative Flow Networks (GFlowNets) are a class of generative models that\nsample objects in proportion to a specified reward function through a learned\npolicy. They can be trained either on-policy or off-policy, needing a balance\nbetween exploration and exploitation for fast convergence to a target\ndistribution. While exploration strategies for discrete GFlowNets have been\nstudied, exploration in the continuous case remains to be investigated, despite\nthe potential for novel exploration algorithms due to the local connectedness\nof continuous domains. Here, we introduce Adapted Metadynamics, a variant of\nmetadynamics that can be applied to arbitrary black-box reward functions on\ncontinuous domains. We use Adapted Metadynamics as an exploration strategy for\ncontinuous GFlowNets. We show several continuous domains where the resulting\nalgorithm, MetaGFN, accelerates convergence to the target distribution and\ndiscovers more distant reward modes than previous off-policy exploration\nstrategies used for GFlowNets.\n","authors":["Dominic Phillips","Flaviu Cipcigan"],"pdf_url":"https://arxiv.org/pdf/2408.15905v2.pdf","comment":"22 pages"},{"id":"http://arxiv.org/abs/2502.12381v3","updated":"2025-03-02T20:17:56Z","published":"2025-02-17T23:40:27Z","title":"Linear Diffusion Networks","summary":"  Diffusion kernels capture global dependencies. We present Linear Diffusion\nNetworks (LDNs), a novel architecture that reinterprets sequential data\nprocessing as a unified diffusion process. Our model integrates adaptive\ndiffusion modules with localized nonlinear updates and a diffusion-inspired\nattention mechanism. This design enables efficient global information\npropagation while preserving fine-grained temporal details. LDN overcomes the\nlimitations of conventional recurrent and transformer models by allowing full\nparallelization across time steps and supporting robust multi-scale temporal\nrepresentations. Experiments on benchmark sequence modeling tasks demonstrate\nthat LDN delivers competitive performance across ImageNet and GLUE tasks.\n","authors":["Jacob Fein-Ashley"],"pdf_url":"https://arxiv.org/pdf/2502.12381v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2502.05967v2","updated":"2025-03-02T20:16:43Z","published":"2025-02-09T17:31:09Z","title":"$$nit Scaling: Simple and Scalable FP8 LLM Training","summary":"  Large Language Model training with 8-bit floating point (FP8) formats\npromises significant efficiency improvements, but reduced numerical precision\nmakes training challenging. It is currently possible to train in FP8 only if\none is willing to tune various hyperparameters, reduce model scale, or accept\nthe overhead of computing dynamic scale factors. We demonstrate simple,\nscalable FP8 training that requires no dynamic scaling factors or special\nhyperparameters, even at large model sizes. Our method, $\\mu$nit Scaling\n($\\mu$S), also enables simple hyperparameter transfer across model widths,\nmatched numerics across training and inference, and other desirable properties.\n$\\mu$nit Scaling is straightforward to implement, consisting of a set of\nminimal interventions based on a first-principles analysis of common\ntransformer operations. We validate our method by training models from 1B to\n13B parameters, performing all hidden linear layer computations in FP8. We\nachieve quality equal to higher precision baselines while also training up to\n33% faster.\n","authors":["Saaketh Narayan","Abhay Gupta","Mansheej Paul","Davis Blalock"],"pdf_url":"https://arxiv.org/pdf/2502.05967v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2404.12534v2","updated":"2025-03-02T20:13:11Z","published":"2024-04-18T22:54:08Z","title":"Lean Copilot: Large Language Models as Copilots for Theorem Proving in\n  Lean","summary":"  Neural theorem proving combines large language models (LLMs) with proof\nassistants such as Lean, where the correctness of formal proofs can be\nrigorously verified, leaving no room for hallucination. With existing neural\ntheorem provers pretrained on a fixed collection of data and offering valuable\nsuggestions at times, it is challenging for them to continually prove novel\ntheorems in a fully autonomous mode, where human insights may be critical. In\nthis paper, we explore LLMs as copilots that assist humans in proving theorems.\nWe introduce Lean Copilot, an general framework for running LLM inference\nnatively in Lean. It enables programmers to build various LLM-based proof\nautomation tools that integrate seamlessly into the workflow of Lean users.\nLean users can use our pretrained models or bring their own ones that run\neither locally (with or without GPUs) or on the cloud. Using Lean Copilot, we\nbuild LLM-based tools that suggest proof steps, complete proof goals, and\nselect relevant premises. Experimental results on the Mathematics in Lean\ntextbook demonstrate the effectiveness of our method compared to existing\nrule-based proof automation in Lean (aesop). When assisting humans, Lean\nCopilot requires only 2.08 manually-entered proof steps on average (3.86\nrequired by aesop); when automating the theorem proving process, Lean Copilot\nautomates 74.2% proof steps on average, 85% better than aesop (40.1%). We open\nsource all code and artifacts under a permissive MIT license to facilitate\nfurther research.\n","authors":["Peiyang Song","Kaiyu Yang","Anima Anandkumar"],"pdf_url":"https://arxiv.org/pdf/2404.12534v2.pdf","comment":"All code and artifacts open-sourced at\n  https://github.com/lean-dojo/LeanCopilot"},{"id":"http://arxiv.org/abs/2405.09660v3","updated":"2025-03-02T19:51:43Z","published":"2024-05-15T19:03:08Z","title":"Fast Two-Time-Scale Stochastic Gradient Method with Applications in\n  Reinforcement Learning","summary":"  Two-time-scale optimization is a framework introduced in Zeng et al. (2024)\nthat abstracts a range of policy evaluation and policy optimization problems in\nreinforcement learning (RL). Akin to bi-level optimization under a particular\ntype of stochastic oracle, the two-time-scale optimization framework has an\nupper level objective whose gradient evaluation depends on the solution of a\nlower level problem, which is to find the root of a strongly monotone operator.\nIn this work, we propose a new method for solving two-time-scale optimization\nthat achieves significantly faster convergence than the prior arts. The key\nidea of our approach is to leverage an averaging step to improve the estimates\nof the operators in both lower and upper levels before using them to update the\ndecision variables. These additional averaging steps eliminate the direct\ncoupling between the main variables, enabling the accelerated performance of\nour algorithm. We characterize the finite-time convergence rates of the\nproposed algorithm under various conditions of the underlying objective\nfunction, including strong convexity, Polyak-Lojasiewicz condition, and general\nnon-convexity. These rates significantly improve over the best-known complexity\nof the standard two-time-scale stochastic approximation algorithm. When applied\nto RL, we show how the proposed algorithm specializes to novel online\nsample-based methods that surpass or match the performance of the existing\nstate of the art. Finally, we support our theoretical results with numerical\nsimulations in RL.\n","authors":["Sihan Zeng","Thinh T. Doan"],"pdf_url":"https://arxiv.org/pdf/2405.09660v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.16103v4","updated":"2025-03-02T18:38:37Z","published":"2024-10-21T15:31:06Z","title":"LDAdam: Adaptive Optimization from Low-Dimensional Gradient Statistics","summary":"  We introduce LDAdam, a memory-efficient optimizer for training large models,\nthat performs adaptive optimization steps within lower dimensional subspaces,\nwhile consistently exploring the full parameter space during training. This\nstrategy keeps the optimizer's memory footprint to a fraction of the model\nsize. LDAdam relies on a new projection-aware update rule for the optimizer\nstates that allows for transitioning between subspaces, i.e., estimation of the\nstatistics of the projected gradients. To mitigate the errors due to low-rank\nprojection, LDAdam integrates a new generalized error feedback mechanism, which\nexplicitly accounts for both gradient and optimizer state compression. We prove\nthe convergence of LDAdam under standard assumptions, and show that LDAdam\nallows for accurate and efficient fine-tuning and pre-training of language\nmodels. Code is available at https://github.com/IST-DASLab/LDAdam\n","authors":["Thomas Robert","Mher Safaryan","Ionut-Vlad Modoranu","Dan Alistarh"],"pdf_url":"https://arxiv.org/pdf/2410.16103v4.pdf","comment":"39 pages, ICLR 2025"},{"id":"http://arxiv.org/abs/2312.15289v3","updated":"2025-03-02T18:36:56Z","published":"2023-12-23T16:10:53Z","title":"Frchet Wavelet Distance: A Domain-Agnostic Metric for Image\n  Generation","summary":"  Modern metrics for generative learning like Fr\\'echet Inception Distance\n(FID) and DINOv2-Fr\\'echet Distance (FD-DINOv2) demonstrate impressive\nperformance. However, they suffer from various shortcomings, like a bias\ntowards specific generators and datasets. To address this problem, we propose\nthe Fr\\'echet Wavelet Distance (FWD) as a domain-agnostic metric based on the\nWavelet Packet Transform ($W_p$). FWD provides a sight across a broad spectrum\nof frequencies in images with a high resolution, preserving both spatial and\ntextural aspects. Specifically, we use $W_p$ to project generated and real\nimages to the packet coefficient space. We then compute the Fr\\'echet distance\nwith the resultant coefficients to evaluate the quality of a generator. This\nmetric is general-purpose and dataset-domain agnostic, as it does not rely on\nany pre-trained network, while being more interpretable due to its ability to\ncompute Fr\\'echet distance per packet, enhancing transparency. We conclude with\nan extensive evaluation of a wide variety of generators across various datasets\nthat the proposed FWD can generalize and improve robustness to domain shifts\nand various corruptions compared to other metrics.\n","authors":["Lokesh Veeramacheneni","Moritz Wolter","Hildegard Kuehne","Juergen Gall"],"pdf_url":"https://arxiv.org/pdf/2312.15289v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2408.02950v2","updated":"2025-03-02T18:31:59Z","published":"2024-08-06T04:28:16Z","title":"Kolmogorov-Arnold PointNet: Deep learning for prediction of fluid fields\n  on irregular geometries","summary":"  Kolmogorov-Arnold Networks (KANs) have emerged as a promising alternative to\ntraditional Multilayer Perceptrons (MLPs) in deep learning. KANs have already\nbeen integrated into various architectures, such as convolutional neural\nnetworks, graph neural networks, and transformers, and their potential has been\nassessed for predicting physical quantities. However, the combination of KANs\nwith point-cloud-based neural networks (e.g., PointNet) for computational\nphysics has not yet been explored. To address this, we present\nKolmogorov-Arnold PointNet (KA-PointNet) as a novel supervised deep learning\nframework for the prediction of incompressible steady-state fluid flow fields\nin irregular domains, where the predicted fields are a function of the geometry\nof the domains. In KA-PointNet, we implement shared KANs in the segmentation\nbranch of the PointNet architecture. We utilize Jacobi polynomials to construct\nshared KANs. As a benchmark test case, we consider incompressible laminar\nsteady-state flow over a cylinder, where the geometry of its cross-section\nvaries over the data set. We investigate the performance of Jacobi polynomials\nwith different degrees as well as special cases of Jacobi polynomials such as\nLegendre polynomials, Chebyshev polynomials of the first and second kinds, and\nGegenbauer polynomials, in terms of the computational cost of training and\naccuracy of prediction of the test set. Additionally, we compare the\nperformance of PointNet with shared KANs (i.e., KA-PointNet) and PointNet with\nshared MLPs. It is observed that when the number of trainable parameters is\napproximately equal, PointNet with shared KANs (i.e., KA-PointNet) outperforms\nPointNet with shared MLPs. Moreover, KA-PointNet predicts the pressure and\nvelocity distributions along the surface of cylinders more accurately,\nresulting in more precise computations of lift and drag.\n","authors":["Ali Kashefi"],"pdf_url":"https://arxiv.org/pdf/2408.02950v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2405.14105v4","updated":"2025-03-02T18:24:29Z","published":"2024-05-23T02:14:17Z","title":"Distributed Speculative Inference (DSI): Speculation Parallelism for\n  Provably Faster Lossless Language Model Inference","summary":"  This paper introduces distributed speculative inference (DSI), a novel\ninference algorithm that is provably faster than speculative inference (SI)\n[leviathan2023, chen2023, miao2024, sun2025, timor2025] and standard\nautoregressive inference (non-SI). Like other SI algorithms, DSI operates on\nfrozen language models (LMs), requiring no training or architectural\nmodifications, and it preserves the target distribution. Prior studies on SI\nhave demonstrated empirical speedups over non-SI--but rely on sufficiently fast\nand accurate drafters, which are often unavailable in practice. We identify a\ngap where SI can be slower than non-SI if drafters are too slow or inaccurate.\nWe close this gap by proving that DSI is faster than both SI and non-SI--given\nany drafters. DSI is therefore not only faster than SI, but also unlocks the\nacceleration of LMs for which SI fails. DSI leverages speculation parallelism\n(SP), a novel type of task parallelism, to orchestrate target and drafter\ninstances that overlap in time, establishing a new foundational tradeoff\nbetween computational resources and latency. Our simulations show that DSI is\n1.29-1.92x faster than SI in single-node setups for various off-the-shelf LMs\nand tasks. We open-source all our code.\n","authors":["Nadav Timor","Jonathan Mamou","Daniel Korat","Moshe Berchansky","Oren Pereg","Moshe Wasserblat","Tomer Galanti","Michal Gordon","David Harel"],"pdf_url":"https://arxiv.org/pdf/2405.14105v4.pdf","comment":"Published at ICLR 2025. (Link:\n  https://openreview.net/forum?id=cJd1BgZ9CS)"},{"id":"http://arxiv.org/abs/2411.10509v2","updated":"2025-03-02T18:17:14Z","published":"2024-11-15T15:39:04Z","title":"TESGNN: Temporal Equivariant Scene Graph Neural Networks for Efficient\n  and Robust Multi-View 3D Scene Understanding","summary":"  Scene graphs have proven to be highly effective for various scene\nunderstanding tasks due to their compact and explicit representation of\nrelational information. However, current methods often overlook the critical\nimportance of preserving symmetry when generating scene graphs from 3D point\nclouds, which can lead to reduced accuracy and robustness, particularly when\ndealing with noisy, multi-view data. Furthermore, a major limitation of prior\napproaches is the lack of temporal modeling to capture time-dependent\nrelationships among dynamically evolving entities in a scene. To address these\nchallenges, we propose Temporal Equivariant Scene Graph Neural Network\n(TESGNN), consisting of two key components: (1) an Equivariant Scene Graph\nNeural Network (ESGNN), which extracts information from 3D point clouds to\ngenerate scene graph while preserving crucial symmetry properties, and (2) a\nTemporal Graph Matching Network, which fuses scene graphs generated by ESGNN\nacross multiple time sequences into a unified global representation using an\napproximate graph-matching algorithm. Our combined architecture TESGNN\noutperforms current state-of-the-art methods in scene graph generation,\nachieving higher accuracy and faster training convergence. Moreover, we show\nthat leveraging the symmetry-preserving property produces a more stable and\naccurate global scene representation compared to existing approaches. Last but\nnot least, it is computationally efficient and easily implementable using\nexisting frameworks, making it well-suited for real-time applications in\nrobotics and computer vision. This approach paves the way for more robust and\nscalable solutions to complex multi-view scene understanding challenges. Our\nsource code is publicly available at: https://github.com/HySonLab/TESGraph\n","authors":["Quang P. M. Pham","Khoi T. N. Nguyen","Lan C. Ngo","Truong Do","Dezhen Song","Truong-Son Hy"],"pdf_url":"https://arxiv.org/pdf/2411.10509v2.pdf","comment":"arXiv admin note: text overlap with arXiv:2407.00609"},{"id":"http://arxiv.org/abs/2407.13929v2","updated":"2025-03-02T18:17:11Z","published":"2024-07-18T22:33:52Z","title":"Unmasking Social Bots: How Confident Are We?","summary":"  Social bots remain a major vector for spreading disinformation on social\nmedia and a menace to the public. Despite the progress made in developing\nmultiple sophisticated social bot detection algorithms and tools, bot detection\nremains a challenging, unsolved problem that is fraught with uncertainty due to\nthe heterogeneity of bot behaviors, training data, and detection algorithms.\nDetection models often disagree on whether to label the same account as bot or\nhuman-controlled. However, they do not provide any measure of uncertainty to\nindicate how much we should trust their results. We propose to address both bot\ndetection and the quantification of uncertainty at the account level - a novel\nfeature of this research. This dual focus is crucial as it allows us to\nleverage additional information related to the quantified uncertainty of each\nprediction, thereby enhancing decision-making and improving the reliability of\nbot classifications. Specifically, our approach facilitates targeted\ninterventions for bots when predictions are made with high confidence and\nsuggests caution (e.g., gathering more data) when predictions are uncertain.\n","authors":["James Giroux","Ariyarathne Gangani","Alexander C. Nwala","Cristiano Fanelli"],"pdf_url":"https://arxiv.org/pdf/2407.13929v2.pdf","comment":"15 pages, 6 figures, 6 tables"},{"id":"http://arxiv.org/abs/2410.04642v3","updated":"2025-03-02T18:16:48Z","published":"2024-10-06T22:30:14Z","title":"The Optimization Landscape of SGD Across the Feature Learning Strength","summary":"  We consider neural networks (NNs) where the final layer is down-scaled by a\nfixed hyperparameter $\\gamma$. Recent work has identified $\\gamma$ as\ncontrolling the strength of feature learning. As $\\gamma$ increases, network\nevolution changes from \"lazy\" kernel dynamics to \"rich\" feature-learning\ndynamics, with a host of associated benefits including improved performance on\ncommon tasks. In this work, we conduct a thorough empirical investigation of\nthe effect of scaling $\\gamma$ across a variety of models and datasets in the\nonline training setting. We first examine the interaction of $\\gamma$ with the\nlearning rate $\\eta$, identifying several scaling regimes in the\n$\\gamma$-$\\eta$ plane which we explain theoretically using a simple model. We\nfind that the optimal learning rate $\\eta^*$ scales non-trivially with\n$\\gamma$. In particular, $\\eta^* \\propto \\gamma^2$ when $\\gamma \\ll 1$ and\n$\\eta^* \\propto \\gamma^{2/L}$ when $\\gamma \\gg 1$ for a feed-forward network of\ndepth $L$. Using this optimal learning rate scaling, we proceed with an\nempirical study of the under-explored \"ultra-rich\" $\\gamma \\gg 1$ regime. We\nfind that networks in this regime display characteristic loss curves, starting\nwith a long plateau followed by a drop-off, sometimes followed by one or more\nadditional staircase steps. We find networks of different large $\\gamma$ values\noptimize along similar trajectories up to a reparameterization of time. We\nfurther find that optimal online performance is often found at large $\\gamma$\nand could be missed if this hyperparameter is not tuned. Our findings indicate\nthat analytical study of the large-$\\gamma$ limit may yield useful insights\ninto the dynamics of representation learning in performant models.\n","authors":["Alexander Atanasov","Alexandru Meterez","James B. Simon","Cengiz Pehlevan"],"pdf_url":"https://arxiv.org/pdf/2410.04642v3.pdf","comment":"ICLR 2025 Final Copy, 40 Pages, 45 figures"},{"id":"http://arxiv.org/abs/2408.08531v2","updated":"2025-03-02T18:15:48Z","published":"2024-08-16T04:57:54Z","title":"Detecting Unsuccessful Students in Cybersecurity Exercises in Two\n  Different Learning Environments","summary":"  This full paper in the research track evaluates the usage of data logged from\ncybersecurity exercises in order to predict students who are potentially at\nrisk of performing poorly. Hands-on exercises are essential for learning since\nthey enable students to practice their skills. In cybersecurity, hands-on\nexercises are often complex and require knowledge of many topics. Therefore,\nstudents may miss solutions due to gaps in their knowledge and become\nfrustrated, which impedes their learning. Targeted aid by the instructor helps,\nbut since the instructor's time is limited, efficient ways to detect struggling\nstudents are needed. This paper develops automated tools to predict when a\nstudent is having difficulty. We formed a dataset with the actions of 313\nstudents from two countries and two learning environments: KYPO CRP and\nEDURange. These data are used in machine learning algorithms to predict the\nsuccess of students in exercises deployed in these environments. After\nextracting features from the data, we trained and cross-validated eight\nclassifiers for predicting the exercise outcome and evaluated their predictive\npower. The contribution of this paper is comparing two approaches to feature\nengineering, modeling, and classification performance on data from two learning\nenvironments. Using the features from either learning environment, we were able\nto detect and distinguish between successful and struggling students. A\ndecision tree classifier achieved the highest balanced accuracy and sensitivity\nwith data from both learning environments. The results show that activity data\nfrom cybersecurity exercises are suitable for predicting student success. In a\npotential application, such models can aid instructors in detecting struggling\nstudents and providing targeted help. We publish data and code for building\nthese models so that others can adopt or adapt them.\n","authors":["Valdemar vbensk","Kristin Tkik","Aubrey Birdwell","Richard Weiss","Ryan S. Baker","Pavel eleda","Jan Vykopal","Jens Mache","Ankur Chattopadhyay"],"pdf_url":"https://arxiv.org/pdf/2408.08531v2.pdf","comment":"Published in the FIE 2024 conference proceedings, see\n  https://doi.org/10.1109/FIE61694.2024.10893135"},{"id":"http://arxiv.org/abs/2410.11112v5","updated":"2025-03-02T17:48:06Z","published":"2024-10-14T21:43:48Z","title":"Differentiable Weightless Neural Networks","summary":"  We introduce the Differentiable Weightless Neural Network (DWN), a model\nbased on interconnected lookup tables. Training of DWNs is enabled by a novel\nExtended Finite Difference technique for approximate differentiation of binary\nvalues. We propose Learnable Mapping, Learnable Reduction, and Spectral\nRegularization to further improve the accuracy and efficiency of these models.\nWe evaluate DWNs in three edge computing contexts: (1) an FPGA-based hardware\naccelerator, where they demonstrate superior latency, throughput, energy\nefficiency, and model area compared to state-of-the-art solutions, (2) a\nlow-power microcontroller, where they achieve preferable accuracy to XGBoost\nwhile subject to stringent memory constraints, and (3) ultra-low-cost chips,\nwhere they consistently outperform small models in both accuracy and projected\nhardware area. DWNs also compare favorably against leading approaches for\ntabular datasets, with higher average rank. Overall, our work positions DWNs as\na pioneering solution for edge-compatible high-throughput neural networks.\n","authors":["Alan T. L. Bacellar","Zachary Susskind","Mauricio Breternitz Jr.","Eugene John","Lizy K. John","Priscila M. V. Lima","Felipe M. G. Frana"],"pdf_url":"https://arxiv.org/pdf/2410.11112v5.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.02372v2","updated":"2025-03-02T17:34:53Z","published":"2024-11-04T18:40:46Z","title":"Learning General-Purpose Biomedical Volume Representations using\n  Randomized Synthesis","summary":"  Current volumetric biomedical foundation models struggle to generalize as\npublic 3D datasets are small and do not cover the broad diversity of medical\nprocedures, conditions, anatomical regions, and imaging protocols. We address\nthis by creating a representation learning method that instead anticipates\nstrong domain shifts at training time itself. We first propose a data engine\nthat synthesizes highly variable training samples that would enable\ngeneralization to new biomedical contexts. To then train a single 3D network\nfor any voxel-level task, we develop a contrastive learning method that\npretrains the network to be stable against nuisance imaging variation simulated\nby the data engine, a key inductive bias for generalization. This network's\nfeatures can be used as robust representations of input images for downstream\ntasks and its weights provide a strong, dataset-agnostic initialization for\nfinetuning on new datasets. As a result, we set new standards across both\nmultimodality registration and few-shot segmentation, a first for any 3D\nbiomedical vision model, all without (pre-)training on any existing dataset of\nreal images.\n","authors":["Neel Dey","Benjamin Billot","Hallee E. Wong","Clinton J. Wang","Mengwei Ren","P. Ellen Grant","Adrian V. Dalca","Polina Golland"],"pdf_url":"https://arxiv.org/pdf/2411.02372v2.pdf","comment":"ICLR 2025: International Conference on Learning Representations. Code\n  and model weights available at https://github.com/neel-dey/anatomix.\n  Keywords: synthetic data, representation learning, medical image analysis,\n  image registration, image segmentation"},{"id":"http://arxiv.org/abs/2403.08743v2","updated":"2025-03-02T17:33:03Z","published":"2024-03-13T17:46:28Z","title":"Prompting Fairness: Integrating Causality to Debias Large Language\n  Models","summary":"  Large language models (LLMs), despite their remarkable capabilities, are\nsusceptible to generating biased and discriminatory responses. As LLMs\nincreasingly influence high-stakes decision-making (e.g., hiring and\nhealthcare), mitigating these biases becomes critical. In this work, we propose\na causality-guided debiasing framework to tackle social biases, aiming to\nreduce the objectionable dependence between LLMs' decisions and the social\ninformation in the input. Our framework introduces a novel perspective to\nidentify how social information can affect an LLM's decision through different\ncausal pathways. Leveraging these causal insights, we outline principled\nprompting strategies that regulate these pathways through selection mechanisms.\nThis framework not only unifies existing prompting-based debiasing techniques,\nbut also opens up new directions for reducing bias by encouraging the model to\nprioritize fact-based reasoning over reliance on biased social cues. We\nvalidate our framework through extensive experiments on real-world datasets\nacross multiple domains, demonstrating its effectiveness in debiasing LLM\ndecisions, even with only black-box access to the model.\n","authors":["Jingling Li","Zeyu Tang","Xiaoyu Liu","Peter Spirtes","Kun Zhang","Liu Leqi","Yang Liu"],"pdf_url":"https://arxiv.org/pdf/2403.08743v2.pdf","comment":"24 pages, 10 figures"},{"id":"http://arxiv.org/abs/2502.03391v3","updated":"2025-03-02T17:32:48Z","published":"2025-02-05T17:29:12Z","title":"Explain Yourself, Briefly! Self-Explaining Neural Networks with Concise\n  Sufficient Reasons","summary":"  *Minimal sufficient reasons* represent a prevalent form of explanation - the\nsmallest subset of input features which, when held constant at their\ncorresponding values, ensure that the prediction remains unchanged. Previous\n*post-hoc* methods attempt to obtain such explanations but face two main\nlimitations: (1) Obtaining these subsets poses a computational challenge,\nleading most scalable methods to converge towards suboptimal, less meaningful\nsubsets; (2) These methods heavily rely on sampling out-of-distribution input\nassignments, potentially resulting in counterintuitive behaviors. To tackle\nthese limitations, we propose in this work a self-supervised training approach,\nwhich we term *sufficient subset training* (SST). Using SST, we train models to\ngenerate concise sufficient reasons for their predictions as an integral part\nof their output. Our results indicate that our framework produces succinct and\nfaithful subsets substantially more efficiently than competing post-hoc\nmethods, while maintaining comparable predictive performance.\n","authors":["Shahaf Bassan","Ron Eliav","Shlomit Gur"],"pdf_url":"https://arxiv.org/pdf/2502.03391v3.pdf","comment":"To appear in ICLR 2025"},{"id":"http://arxiv.org/abs/2410.06262v2","updated":"2025-03-02T17:20:26Z","published":"2024-10-08T18:02:29Z","title":"SymDiff: Equivariant Diffusion via Stochastic Symmetrisation","summary":"  We propose SymDiff, a method for constructing equivariant diffusion models\nusing the framework of stochastic symmetrisation. SymDiff resembles a learned\ndata augmentation that is deployed at sampling time, and is lightweight,\ncomputationally efficient, and easy to implement on top of arbitrary\noff-the-shelf models. In contrast to previous work, SymDiff typically does not\nrequire any neural network components that are intrinsically equivariant,\navoiding the need for complex parameterisations or the use of higher-order\ngeometric features. Instead, our method can leverage highly scalable modern\narchitectures as drop-in replacements for these more constrained alternatives.\nWe show that this additional flexibility yields significant empirical benefit\nfor $\\mathrm{E}(3)$-equivariant molecular generation. To the best of our\nknowledge, this is the first application of symmetrisation to generative\nmodelling, suggesting its potential in this domain more generally.\n","authors":["Leo Zhang","Kianoosh Ashouritaklimi","Yee Whye Teh","Rob Cornish"],"pdf_url":"https://arxiv.org/pdf/2410.06262v2.pdf","comment":"Camera-ready version for ICLR 2025"},{"id":"http://arxiv.org/abs/2410.04810v2","updated":"2025-03-02T17:18:04Z","published":"2024-10-07T07:45:18Z","title":"FedBiP: Heterogeneous One-Shot Federated Learning with Personalized\n  Latent Diffusion Models","summary":"  One-Shot Federated Learning (OSFL), a special decentralized machine learning\nparadigm, has recently gained significant attention. OSFL requires only a\nsingle round of client data or model upload, which reduces communication costs\nand mitigates privacy threats compared to traditional FL. Despite these\npromising prospects, existing methods face challenges due to client data\nheterogeneity and limited data quantity when applied to real-world OSFL\nsystems. Recently, Latent Diffusion Models (LDM) have shown remarkable\nadvancements in synthesizing high-quality images through pretraining on\nlarge-scale datasets, thereby presenting a potential solution to overcome these\nissues. However, directly applying pretrained LDM to heterogeneous OSFL results\nin significant distribution shifts in synthetic data, leading to performance\ndegradation in classification models trained on such data. This issue is\nparticularly pronounced in rare domains, such as medical imaging, which are\nunderrepresented in LDM's pretraining data. To address this challenge, we\npropose Federated Bi-Level Personalization (FedBiP), which personalizes the\npretrained LDM at both instance-level and concept-level. Hereby, FedBiP\nsynthesizes images following the client's local data distribution without\ncompromising the privacy regulations. FedBiP is also the first approach to\nsimultaneously address feature space heterogeneity and client data scarcity in\nOSFL. Our method is validated through extensive experiments on three OSFL\nbenchmarks with feature space heterogeneity, as well as on challenging medical\nand satellite image datasets with label heterogeneity. The results demonstrate\nthe effectiveness of FedBiP, which substantially outperforms other OSFL\nmethods.\n","authors":["Haokun Chen","Hang Li","Yao Zhang","Jinhe Bi","Gengyuan Zhang","Yueqi Zhang","Philip Torr","Jindong Gu","Denis Krompass","Volker Tresp"],"pdf_url":"https://arxiv.org/pdf/2410.04810v2.pdf","comment":"CVPR 2025"},{"id":"http://arxiv.org/abs/2410.03011v2","updated":"2025-03-02T17:17:22Z","published":"2024-10-03T21:42:21Z","title":"Towards Understanding the Universality of Transformers for Next-Token\n  Prediction","summary":"  Causal Transformers are trained to predict the next token for a given\ncontext. While it is widely accepted that self-attention is crucial for\nencoding the causal structure of sequences, the precise underlying mechanism\nbehind this in-context autoregressive learning ability remains unclear. In this\npaper, we take a step towards understanding this phenomenon by studying the\napproximation ability of Transformers for next-token prediction. Specifically,\nwe explore the capacity of causal Transformers to predict the next token\n$x_{t+1}$ given an autoregressive sequence $(x_1, \\dots, x_t)$ as a prompt,\nwhere $ x_{t+1} = f(x_t) $, and $ f $ is a context-dependent function that\nvaries with each sequence. On the theoretical side, we focus on specific\ninstances, namely when $ f $ is linear or when $ (x_t)_{t \\geq 1} $ is\nperiodic. We explicitly construct a Transformer (with linear, exponential, or\nsoftmax attention) that learns the mapping $f$ in-context through a causal\nkernel descent method. The causal kernel descent method we propose provably\nestimates $x_{t+1} $ based solely on past and current observations $ (x_1,\n\\dots, x_t) $, with connections to the Kaczmarz algorithm in Hilbert spaces. We\npresent experimental results that validate our theoretical findings and suggest\ntheir applicability to more general mappings $f$.\n","authors":["Michael E. Sander","Gabriel Peyr"],"pdf_url":"https://arxiv.org/pdf/2410.03011v2.pdf","comment":"ICLR 2025, 20 pages"},{"id":"http://arxiv.org/abs/2502.11882v3","updated":"2025-03-02T17:15:11Z","published":"2025-02-17T15:09:45Z","title":"Leveraging Dual Process Theory in Language Agent Framework for Real-time\n  Simultaneous Human-AI Collaboration","summary":"  Agents built on large language models (LLMs) have excelled in turn-by-turn\nhuman-AI collaboration but struggle with simultaneous tasks requiring real-time\ninteraction. Latency issues and the challenge of inferring variable human\nstrategies hinder their ability to make autonomous decisions without explicit\ninstructions. Through experiments with current independent System 1 and System\n2 methods, we validate the necessity of using Dual Process Theory (DPT) in\nreal-time tasks. We propose DPT-Agent, a novel language agent framework that\nintegrates System 1 and System 2 for efficient real-time simultaneous human-AI\ncollaboration. DPT-Agent's System 1 uses a Finite-state Machine (FSM) and\ncode-as-policy for fast, intuitive, and controllable decision-making.\nDPT-Agent's System 2 integrates Theory of Mind (ToM) and asynchronous\nreflection to infer human intentions and perform reasoning-based autonomous\ndecisions. We demonstrate the effectiveness of DPT-Agent through further\nexperiments with rule-based agents and human collaborators, showing significant\nimprovements over mainstream LLM-based frameworks. DPT-Agent can effectively\nhelp LLMs convert correct slow thinking and reasoning into executable actions,\nthereby improving performance. To the best of our knowledge, DPT-Agent is the\nfirst language agent framework that achieves successful real-time simultaneous\nhuman-AI collaboration autonomously. Code of DPT-Agent can be found in\nhttps://github.com/sjtu-marl/DPT-Agent.\n","authors":["Shao Zhang","Xihuai Wang","Wenhao Zhang","Chaoran Li","Junru Song","Tingyu Li","Lin Qiu","Xuezhi Cao","Xunliang Cai","Wen Yao","Weinan Zhang","Xinbing Wang","Ying Wen"],"pdf_url":"https://arxiv.org/pdf/2502.11882v3.pdf","comment":"Preprint under review. Update the experimental results of the\n  DeepSeek-R1 series models, o3-mini-high and o3-mini-medium"},{"id":"http://arxiv.org/abs/2403.18035v4","updated":"2025-03-02T16:41:49Z","published":"2024-03-26T18:40:36Z","title":"Bidirectional Consistency Models","summary":"  Diffusion models (DMs) are capable of generating remarkably high-quality\nsamples by iteratively denoising a random vector, a process that corresponds to\nmoving along the probability flow ordinary differential equation (PF ODE).\nInterestingly, DMs can also invert an input image to noise by moving backward\nalong the PF ODE, a key operation for downstream tasks such as interpolation\nand image editing. However, the iterative nature of this process restricts its\nspeed, hindering its broader application. Recently, Consistency Models (CMs)\nhave emerged to address this challenge by approximating the integral of the PF\nODE, largely reducing the number of iterations. Yet, the absence of an explicit\nODE solver complicates the inversion process. To resolve this, we introduce\nBidirectional Consistency Model (BCM), which learns a single neural network\nthat enables both forward and backward traversal along the PF ODE, efficiently\nunifying generation and inversion tasks within one framework. We can train BCM\nfrom scratch or tune it using a pretrained consistency model, which reduces the\ntraining cost and increases scalability. We demonstrate that BCM enables\none-step generation and inversion while also allowing the use of additional\nsteps to enhance generation quality or reduce reconstruction error. We further\nshowcase BCM's capability in downstream tasks, such as interpolation and\ninpainting. Our code and weights are available at\nhttps://github.com/Mosasaur5526/BCM-iCT-torch.\n","authors":["Liangchen Li","Jiajun He"],"pdf_url":"https://arxiv.org/pdf/2403.18035v4.pdf","comment":"39 pages, 27 figures; a shorter version of this paper was acceppted\n  at the ICML 2024 Workshop on Structured Probabilistic Inference & Generative\n  Modeling"},{"id":"http://arxiv.org/abs/2412.07067v3","updated":"2025-03-02T16:40:03Z","published":"2024-12-10T00:19:28Z","title":"MoE-CAP: Benchmarking Cost, Accuracy and Performance of Sparse\n  Mixture-of-Experts Systems","summary":"  The Mixture-of-Experts (MoE) architecture is increasingly favored for scaling\nLarge Language Models (LLMs). Its key feature, sparse activation, selectively\nactivates only a subset of parameters (experts) per token, reducing memory\nbandwidth and compute FLOPs compared to dense models. To capitalize on this,\nMoE designers leverage heterogeneous compute and memory hardware to lower\nsystem costs. However, the interaction between model sparsity and hardware\nheterogeneity introduces trade-offs in Cost, Accuracy, and Performance (CAP).\nTo address this, we introduce MoE-CAP, a benchmarking method for evaluating\nsparse MoE systems across these three dimensions. Its key innovation is a\nsparsity-aware CAP analysis model, the first to integrate cost, performance,\nand accuracy metrics into a single diagram while estimating the impact of\nsparsity on system performance. MoE-CAP helps practitioners optimize hardware\nprovisioning for an MoE model-or vice versa. MoE-CAP supports various MoE\nmodels and provides more accurate metrics than existing methods.\n","authors":["Yao Fu","Yinsicheng Jiang","Yeqi Huang","Ping Nie","Zhan Lu","Leyang Xue","Congjie He","Man-Kit Sit","Jilong Xue","Li Dong","Ziming Miao","Kai Zou","Edoardo Ponti","Luo Mai"],"pdf_url":"https://arxiv.org/pdf/2412.07067v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2308.16471v4","updated":"2025-03-02T16:36:29Z","published":"2023-08-31T05:26:14Z","title":"Foundational Policy Acquisition via Multitask Learning for Motor Skill\n  Generation","summary":"  In this study, we propose a multitask reinforcement learning algorithm for\nfoundational policy acquisition to generate novel motor skills.\n\\textcolor{\\hcolor}{Learning the rich representation of the multitask policy is\na challenge in dynamic movement generation tasks because the policy needs to\ncope with changes in goals or environments with different reward functions or\nphysical parameters. Inspired by human sensorimotor adaptation mechanisms, we\ndeveloped the learning pipeline to construct the encoder-decoder networks and\nnetwork selection to facilitate foundational policy acquisition under multiple\nsituations. First, we compared the proposed method with previous multitask\nreinforcement learning methods in the standard multi-locomotion tasks. The\nresults showed that the proposed approach outperformed the baseline methods.\nThen, we applied the proposed method to the ball heading task using a monopod\nrobot model to evaluate skill generation performance. The results showed that\nthe proposed method was able to adapt to novel target positions or\ninexperienced ball restitution coefficients but to acquire a foundational\npolicy network, originally learned for heading motion, which can generate an\nentirely new overhead kicking skill.\n","authors":["Satoshi Yamamori","Jun Morimoto"],"pdf_url":"https://arxiv.org/pdf/2308.16471v4.pdf","comment":"11 pages, 9 figures"},{"id":"http://arxiv.org/abs/2406.03735v2","updated":"2025-03-02T16:21:37Z","published":"2024-06-06T04:19:55Z","title":"Phase-Amplitude Reduction-Based Imitation Learning","summary":"  In this study, we propose the use of the phase-amplitude reduction method to\nconstruct an imitation learning framework. Imitating human movement\ntrajectories is recognized as a promising strategy for generating a range of\nhuman-like robot movements. Unlike previous dynamical system-based imitation\nlearning approaches, our proposed method allows the robot not only to imitate a\nlimit cycle trajectory but also to replicate the transient movement from the\ninitial or disturbed state to the limit cycle. Consequently, our method offers\na safer imitation learning approach that avoids generating unpredictable\nmotions immediately after disturbances or from a specified initial state. We\nfirst validated our proposed method by reconstructing a simple limit-cycle\nattractor. We then compared the proposed approach with a conventional method on\na lemniscate trajectory tracking task with a simulated robot arm. Our findings\nconfirm that our proposed method can more accurately generate transient\nmovements to converge on a target periodic attractor compared to the previous\nstandard approach. Subsequently, we applied our method to a real robot arm to\nimitate periodic human movements.\n","authors":["Satoshi Yamamori","Jun Morimoto"],"pdf_url":"https://arxiv.org/pdf/2406.03735v2.pdf","comment":"21 pages, 8 figures"},{"id":"http://arxiv.org/abs/2502.18960v2","updated":"2025-03-02T16:14:51Z","published":"2025-02-26T09:17:04Z","title":"Nonparametric Heterogeneous Long-term Causal Effect Estimation via Data\n  Combination","summary":"  Long-term causal inference has drawn increasing attention in many scientific\ndomains. Existing methods mainly focus on estimating average long-term causal\neffects by combining long-term observational data and short-term experimental\ndata. However, it is still understudied how to robustly and effectively\nestimate heterogeneous long-term causal effects, significantly limiting\npractical applications. In this paper, we propose several two-stage style\nnonparametric estimators for heterogeneous long-term causal effect estimation,\nincluding propensity-based, regression-based, and multiple robust estimators.\nWe conduct a comprehensive theoretical analysis of their asymptotic properties\nunder mild assumptions, with the ultimate goal of building a better\nunderstanding of the conditions under which some estimators can be expected to\nperform better. Extensive experiments across several semi-synthetic and\nreal-world datasets validate the theoretical results and demonstrate the\neffectiveness of the proposed estimators.\n","authors":["Weilin Chen","Ruichu Cai","Junjie Wan","Zeqin Yang","Jos Miguel Hernndez-Lobato"],"pdf_url":"https://arxiv.org/pdf/2502.18960v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2412.20138v5","updated":"2025-03-02T15:57:39Z","published":"2024-12-28T12:54:06Z","title":"TradingAgents: Multi-Agents LLM Financial Trading Framework","summary":"  Significant progress has been made in automated problem-solving using\nsocieties of agents powered by large language models (LLMs). In finance,\nefforts have largely focused on single-agent systems handling specific tasks or\nmulti-agent frameworks independently gathering data. However, multi-agent\nsystems' potential to replicate real-world trading firms' collaborative\ndynamics remains underexplored. TradingAgents proposes a novel stock trading\nframework inspired by trading firms, featuring LLM-powered agents in\nspecialized roles such as fundamental analysts, sentiment analysts, technical\nanalysts, and traders with varied risk profiles. The framework includes Bull\nand Bear researcher agents assessing market conditions, a risk management team\nmonitoring exposure, and traders synthesizing insights from debates and\nhistorical data to make informed decisions. By simulating a dynamic,\ncollaborative trading environment, this framework aims to improve trading\nperformance. Detailed architecture and extensive experiments reveal its\nsuperiority over baseline models, with notable improvements in cumulative\nreturns, Sharpe ratio, and maximum drawdown, highlighting the potential of\nmulti-agent LLM frameworks in financial trading. TradingAgents is available at\nhttps://github.com/PioneerFintech.\n","authors":["Yijia Xiao","Edward Sun","Di Luo","Wei Wang"],"pdf_url":"https://arxiv.org/pdf/2412.20138v5.pdf","comment":"Multi-Agent AI in the Real World @ AAAI 2025"},{"id":"http://arxiv.org/abs/2408.11915v2","updated":"2025-03-02T15:55:14Z","published":"2024-08-21T18:06:15Z","title":"Video-Foley: Two-Stage Video-To-Sound Generation via Temporal Event\n  Condition For Foley Sound","summary":"  Foley sound synthesis is crucial for multimedia production, enhancing user\nexperience by synchronizing audio and video both temporally and semantically.\nRecent studies on automating this labor-intensive process through\nvideo-to-sound generation face significant challenges. Systems lacking explicit\ntemporal features suffer from poor alignment and controllability, while\ntimestamp-based models require costly and subjective human annotation. We\npropose Video-Foley, a video-to-sound system using Root Mean Square (RMS) as an\nintuitive condition with semantic timbre prompts (audio or text). RMS, a\nframe-level intensity envelope closely related to audio semantics, acts as a\ntemporal event feature to guide audio generation from video. The\nannotation-free self-supervised learning framework consists of two stages,\nVideo2RMS and RMS2Sound, incorporating novel ideas including RMS discretization\nand RMS-ControlNet with a pretrained text-to-audio model. Our extensive\nevaluation shows that Video-Foley achieves state-of-the-art performance in\naudio-visual alignment and controllability for sound timing, intensity, timbre,\nand nuance. Source code, model weights and demos are available on our companion\nwebsite. (https://jnwnlee.github.io/video-foley-demo)\n","authors":["Junwon Lee","Jaekwon Im","Dabin Kim","Juhan Nam"],"pdf_url":"https://arxiv.org/pdf/2408.11915v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2310.18709v4","updated":"2025-03-02T15:37:39Z","published":"2023-10-28T13:37:52Z","title":"Audio-Visual Instance Segmentation","summary":"  In this paper, we propose a new multi-modal task, termed audio-visual\ninstance segmentation (AVIS), which aims to simultaneously identify, segment\nand track individual sounding object instances in audible videos. To facilitate\nthis research, we introduce a high-quality benchmark named AVISeg, containing\nover 90K instance masks from 26 semantic categories in 926 long videos.\nAdditionally, we propose a strong baseline model for this task. Our model first\nlocalizes sound source within each frame, and condenses object-specific\ncontexts into concise tokens. Then it builds long-range audio-visual\ndependencies between these tokens using window-based attention, and tracks\nsounding objects among the entire video sequences. Extensive experiments reveal\nthat our method performs best on AVISeg, surpassing the existing methods from\nrelated tasks. We further conduct the evaluation on several multi-modal large\nmodels. Unfortunately, they exhibits subpar performance on instance-level sound\nsource localization and temporal perception. We expect that AVIS will inspire\nthe community towards a more comprehensive multi-modal understanding. Dataset\nand code is available at https://github.com/ruohaoguo/avis.\n","authors":["Ruohao Guo","Xianghua Ying","Yaru Chen","Dantong Niu","Guangyao Li","Liao Qu","Yanyu Qi","Jinxing Zhou","Bowei Xing","Wenzhen Yue","Ji Shi","Qixun Wang","Peiliang Zhang","Buwen Liang"],"pdf_url":"https://arxiv.org/pdf/2310.18709v4.pdf","comment":"Accepted by CVPR 2025"},{"id":"http://arxiv.org/abs/2412.12164v2","updated":"2025-03-02T15:12:38Z","published":"2024-12-11T19:12:22Z","title":"GAMED: Knowledge Adaptive Multi-Experts Decoupling for Multimodal Fake\n  News Detection","summary":"  Multimodal fake news detection often involves modelling heterogeneous data\nsources, such as vision and language. Existing detection methods typically rely\non fusion effectiveness and cross-modal consistency to model the content,\ncomplicating understanding how each modality affects prediction accuracy.\nAdditionally, these methods are primarily based on static feature modelling,\nmaking it difficult to adapt to the dynamic changes and relationships between\ndifferent data modalities. This paper develops a significantly novel approach,\nGAMED, for multimodal modelling, which focuses on generating distinctive and\ndiscriminative features through modal decoupling to enhance cross-modal\nsynergies, thereby optimizing overall performance in the detection process.\nGAMED leverages multiple parallel expert networks to refine features and\npre-embed semantic knowledge to improve the experts' ability in information\nselection and viewpoint sharing. Subsequently, the feature distribution of each\nmodality is adaptively adjusted based on the respective experts' opinions.\nGAMED also introduces a novel classification technique to dynamically manage\ncontributions from different modalities, while improving the explainability of\ndecisions. Experimental results on the Fakeddit and Yang datasets demonstrate\nthat GAMED performs better than recently developed state-of-the-art models. The\nsource code can be accessed at https://github.com/slz0925/GAMED.\n","authors":["Lingzhi Shen","Yunfei Long","Xiaohao Cai","Imran Razzak","Guanming Chen","Kang Liu","Shoaib Jameel"],"pdf_url":"https://arxiv.org/pdf/2412.12164v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2402.07189v2","updated":"2025-03-02T15:05:58Z","published":"2024-02-11T12:54:07Z","title":"Improving LSH via Tensorized Random Projection","summary":"  Locality sensitive hashing (LSH) is a fundamental algorithmic toolkit used by\ndata scientists for approximate nearest neighbour search problems that have\nbeen used extensively in many large scale data processing applications such as\nnear duplicate detection, nearest neighbour search, clustering, etc. In this\nwork, we aim to propose faster and space efficient locality sensitive hash\nfunctions for Euclidean distance and cosine similarity for tensor data.\nTypically, the naive approach for obtaining LSH for tensor data involves first\nreshaping the tensor into vectors, followed by applying existing LSH methods\nfor vector data $E2LSH$ and $SRP$. However, this approach becomes impractical\nfor higher order tensors because the size of the reshaped vector becomes\nexponential in the order of the tensor. Consequently, the size of LSH\nparameters increases exponentially. To address this problem, we suggest two\nmethods for LSH for Euclidean distance and cosine similarity, namely\n$CP-E2LSH$, $TT-E2LSH$, and $CP-SRP$, $TT-SRP$, respectively, building on $CP$\nand tensor train $(TT)$ decompositions techniques. Our approaches are space\nefficient and can be efficiently applied to low rank $CP$ or $TT$ tensors. We\nprovide a rigorous theoretical analysis of our proposal on their correctness\nand efficacy.\n","authors":["Bhisham Dev Verma","Rameshwar Pratap"],"pdf_url":"https://arxiv.org/pdf/2402.07189v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2407.14154v2","updated":"2025-03-02T14:41:12Z","published":"2024-07-19T09:34:04Z","title":"Where is the Testbed for my Federated Learning Research?","summary":"  Progressing beyond centralized AI is of paramount importance, yet,\ndistributed AI solutions, in particular various federated learning (FL)\nalgorithms, are often not comprehensively assessed, which prevents the research\ncommunity from identifying the most promising approaches and practitioners from\nbeing convinced that a certain solution is deployment-ready. The largest hurdle\ntowards FL algorithm evaluation is the difficulty of conducting real-world\nexperiments over a variety of FL client devices and different platforms, with\ndifferent datasets and data distribution, all while assessing various\ndimensions of algorithm performance, such as inference accuracy, energy\nconsumption, and time to convergence, to name a few. In this paper, we present\nCoLExT, a real-world testbed for FL research. CoLExT is designed to streamline\nexperimentation with custom FL algorithms in a rich testbed configuration\nspace, with a large number of heterogeneous edge devices, ranging from\nsingle-board computers to smartphones, and provides real-time collection and\nvisualization of a variety of metrics through automatic instrumentation.\nAccording to our evaluation, porting FL algorithms to CoLExT requires minimal\ninvolvement from the developer, and the instrumentation introduces minimal\nresource usage overhead. Furthermore, through an initial investigation\ninvolving popular FL algorithms running on CoLExT, we reveal previously unknown\ntrade-offs, inefficiencies, and programming bugs.\n","authors":["Janez Boi","Amndio R. Faustino","Boris Radovi","Marco Canini","Veljko Pejovi"],"pdf_url":"https://arxiv.org/pdf/2407.14154v2.pdf","comment":"SEC 2024"},{"id":"http://arxiv.org/abs/2410.10781v2","updated":"2025-03-02T14:37:53Z","published":"2024-10-14T17:50:28Z","title":"When Attention Sink Emerges in Language Models: An Empirical View","summary":"  Language Models (LMs) assign significant attention to the first token, even\nif it is not semantically important, which is known as attention sink. This\nphenomenon has been widely adopted in applications such as streaming/long\ncontext generation, KV cache optimization, inference acceleration, model\nquantization, and others. Despite its widespread use, a deep understanding of\nattention sink in LMs is still lacking. In this work, we first demonstrate that\nattention sinks exist universally in LMs with various inputs, even in small\nmodels. Furthermore, attention sink is observed to emerge during the LM\npre-training, motivating us to investigate how optimization, data distribution,\nloss function, and model architecture in LM pre-training influence its\nemergence. We highlight that attention sink emerges after effective\noptimization on sufficient training data. The sink position is highly\ncorrelated with the loss function and data distribution. Most importantly, we\nfind that attention sink acts more like key biases, storing extra attention\nscores, which could be non-informative and not contribute to the value\ncomputation. We also observe that this phenomenon (at least partially) stems\nfrom tokens' inner dependence on attention scores as a result of softmax\nnormalization. After relaxing such dependence by replacing softmax attention\nwith other attention operations, such as sigmoid attention without\nnormalization, attention sinks do not emerge in LMs up to 1B parameters. The\ncode is available at https://github.com/sail-sg/Attention-Sink.\n","authors":["Xiangming Gu","Tianyu Pang","Chao Du","Qian Liu","Fengzhuo Zhang","Cunxiao Du","Ye Wang","Min Lin"],"pdf_url":"https://arxiv.org/pdf/2410.10781v2.pdf","comment":"ICLR 2025 (Spotlight)"},{"id":"http://arxiv.org/abs/2410.07137v2","updated":"2025-03-02T14:28:33Z","published":"2024-10-09T17:53:06Z","title":"Cheating Automatic LLM Benchmarks: Null Models Achieve High Win Rates","summary":"  Automatic LLM benchmarks, such as AlpacaEval 2.0, Arena-Hard-Auto, and\nMT-Bench, have become popular for evaluating language models due to their\ncost-effectiveness and scalability compared to human evaluation. Achieving high\nwin rates on these benchmarks can significantly boost the promotional impact of\nnewly released language models. This promotional benefit may motivate tricks,\nsuch as manipulating model output length or style to game win rates, even\nthough several mechanisms have been developed to control length and disentangle\nstyle to reduce gameability. Nonetheless, we show that even a \"null model\" that\nalways outputs a constant response (irrelevant to input instructions) can cheat\nautomatic benchmarks and achieve top-ranked win rates: an 86.5% LC win rate on\nAlpacaEval 2.0; an 83.0 score on Arena-Hard-Auto; and a 9.55 score on MT-Bench.\nMoreover, the crafted cheating outputs are transferable because we assume that\nthe instructions of these benchmarks (e.g., 805 samples of AlpacaEval 2.0) are\nprivate and cannot be accessed. While our experiments are primarily\nproof-of-concept, an adversary could use LLMs to generate more imperceptible\ncheating responses, unethically benefiting from high win rates and promotional\nimpact. Our findings call for the development of anti-cheating mechanisms for\nreliable automatic benchmarks. The code is available at\nhttps://github.com/sail-sg/Cheating-LLM-Benchmarks.\n","authors":["Xiaosen Zheng","Tianyu Pang","Chao Du","Qian Liu","Jing Jiang","Min Lin"],"pdf_url":"https://arxiv.org/pdf/2410.07137v2.pdf","comment":"ICLR 2025 (Oral)"},{"id":"http://arxiv.org/abs/2410.16699v2","updated":"2025-03-02T14:18:13Z","published":"2024-10-22T05:11:45Z","title":"Graph Transformers Dream of Electric Flow","summary":"  We show theoretically and empirically that the linear Transformer, when\napplied to graph data, can implement algorithms that solve canonical problems\nsuch as electric flow and eigenvector decomposition. The Transformer has access\nto information on the input graph only via the graph's incidence matrix. We\npresent explicit weight configurations for implementing each algorithm, and we\nbound the constructed Transformers' errors by the errors of the underlying\nalgorithms. Our theoretical findings are corroborated by experiments on\nsynthetic data. Additionally, on a real-world molecular regression task, we\nobserve that the linear Transformer is capable of learning a more effective\npositional encoding than the default one based on Laplacian eigenvectors. Our\nwork is an initial step towards elucidating the inner-workings of the\nTransformer for graph data. Code is available at\nhttps://github.com/chengxiang/LinearGraphTransformer\n","authors":["Xiang Cheng","Lawrence Carin","Suvrit Sra"],"pdf_url":"https://arxiv.org/pdf/2410.16699v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2405.15252v2","updated":"2025-03-02T14:10:09Z","published":"2024-05-24T06:22:01Z","title":"Accelerating 3D Molecule Generation via Jointly Geometric Optimal\n  Transport","summary":"  This paper proposes a new 3D molecule generation framework, called GOAT, for\nfast and effective 3D molecule generation based on the flow-matching optimal\ntransport objective. Specifically, we formulate a geometric transport formula\nfor measuring the cost of mapping multi-modal features (e.g., continuous atom\ncoordinates and categorical atom types) between a base distribution and a\ntarget data distribution. Our formula is solved within a joint, equivariant,\nand smooth representation space. This is achieved by transforming the\nmulti-modal features into a continuous latent space with equivariant networks.\nIn addition, we find that identifying optimal distributional coupling is\nnecessary for fast and effective transport between any two distributions. We\nfurther propose a mechanism for estimating and purifying optimal coupling to\ntrain the flow model with optimal transport. By doing so, GOAT can turn\narbitrary distribution couplings into new deterministic couplings, leading to\nan estimated optimal transport plan for fast 3D molecule generation. The\npurification filters out the subpar molecules to ensure the ultimate generation\nquality. We theoretically and empirically prove that the proposed optimal\ncoupling estimation and purification yield transport plan with non-increasing\ncost. Finally, extensive experiments show that GOAT enjoys the efficiency of\nsolving geometric optimal transport, leading to a double speedup compared to\nthe sub-optimal method while achieving the best generation quality regarding\nvalidity, uniqueness, and novelty. The code is available at\nhttps://github.com/WanyuGroup/ICLR2025-GOAT.\n","authors":["Haokai Hong","Wanyu Lin","Kay Chen Tan"],"pdf_url":"https://arxiv.org/pdf/2405.15252v2.pdf","comment":"Published as a conference paper at ICLR 2025"},{"id":"http://arxiv.org/abs/2302.01310v3","updated":"2025-03-02T13:29:19Z","published":"2023-02-02T18:33:34Z","title":"Knowledge Gradient for Multi-Objective Bayesian Optimization with\n  Decoupled Evaluations","summary":"  Multi-objective Bayesian optimization aims to find the Pareto front of\ntrade-offs between a set of expensive objectives while collecting as few\nsamples as possible. In some cases, it is possible to evaluate the objectives\nseparately, and a different latency or evaluation cost can be associated with\neach objective. This decoupling of the objectives presents an opportunity to\nlearn the Pareto front faster by avoiding unnecessary, expensive evaluations.\nWe propose a scalarization based knowledge gradient acquisition function which\naccounts for the different evaluation costs of the objectives. We prove\nasymptotic consistency of the estimator of the optimum for an arbitrary,\nD-dimensional, real compact search space and show empirically that the\nalgorithm performs comparably with the state of the art and significantly\noutperforms versions which always evaluate both objectives.\n","authors":["Jack M. Buckingham","Sebastian Rojas Gonzalez","Juergen Branke"],"pdf_url":"https://arxiv.org/pdf/2302.01310v3.pdf","comment":"36 pages. This preprint has not undergone peer review (when\n  applicable) or any post-submission improvements or corrections. The Version\n  of Record of this contribution is published in 'Evolutionary Multi-Criterion\n  Optimization', LNCS 15513, and is available online at\n  https://doi.org/10.1007/978-981-96-3538-2_9"},{"id":"http://arxiv.org/abs/2411.12556v2","updated":"2025-03-02T13:29:03Z","published":"2024-11-19T15:15:45Z","title":"UMGAD: Unsupervised Multiplex Graph Anomaly Detection","summary":"  Graph anomaly detection (GAD) is a critical task in graph machine learning,\nwith the primary objective of identifying anomalous nodes that deviate\nsignificantly from the majority. This task is widely applied in various\nreal-world scenarios, including fraud detection and social network analysis.\nHowever, existing GAD methods still face two major challenges: (1) They are\noften limited to detecting anomalies in single-type interaction graphs and\nstruggle with multiple interaction types in multiplex heterogeneous graphs. (2)\nIn unsupervised scenarios, selecting appropriate anomaly score thresholds\nremains a significant challenge for accurate anomaly detection. To address the\nabove challenges, we propose a novel Unsupervised Multiplex Graph Anomaly\nDetection method, named UMGAD. We first learn multi-relational correlations\namong nodes in multiplex heterogeneous graphs and capture anomaly information\nduring node attribute and structure reconstruction through graph-masked\nautoencoder (GMAE). Then, to further extract abnormal information, we generate\nattribute-level and subgraph-level augmented-view graphs respectively, and\nperform attribute and structure reconstruction through GMAE. Finally, we learn\nto optimize node attributes and structural features through contrastive\nlearning between original-view and augmented-view graphs to improve the model's\nability to capture anomalies. Meanwhile, we also propose a new anomaly score\nthreshold selection strategy, which allows the model to be independent of\nground truth information in real unsupervised scenarios. Extensive experiments\non four datasets show that our UMGAD significantly outperforms state-of-the-art\nmethods, achieving average improvements of 13.48% in AUC and 11.68% in Macro-F1\nacross all datasets.\n","authors":["Xiang Li","Jianpeng Qi","Zhongying Zhao","Guanjie Zheng","Lei Cao","Junyu Dong","Yanwei Yu"],"pdf_url":"https://arxiv.org/pdf/2411.12556v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2208.02820v2","updated":"2025-03-02T13:14:11Z","published":"2022-08-04T02:22:29Z","title":"MOVE: Effective and Harmless Ownership Verification via Embedded\n  External Features","summary":"  Currently, deep neural networks (DNNs) are widely adopted in different\napplications. Despite its commercial values, training a well-performing DNN is\nresource-consuming. Accordingly, the well-trained model is valuable\nintellectual property for its owner. However, recent studies revealed the\nthreats of model stealing, where the adversaries can obtain a function-similar\ncopy of the victim model, even when they can only query the model. In this\npaper, we propose an effective and harmless model ownership verification (MOVE)\nto defend against different types of model stealing simultaneously, without\nintroducing new security risks. In general, we conduct the ownership\nverification by verifying whether a suspicious model contains the knowledge of\ndefender-specified external features. Specifically, we embed the external\nfeatures by modifying a few training samples with style transfer. We then train\na meta-classifier to determine whether a model is stolen from the victim. This\napproach is inspired by the understanding that the stolen models should contain\nthe knowledge of features learned by the victim model. In particular,\n\\revision{we develop our MOVE method under both white-box and black-box\nsettings and analyze its theoretical foundation to provide comprehensive model\nprotection.} Extensive experiments on benchmark datasets verify the\neffectiveness of our method and its resistance to potential adaptive attacks.\nThe codes for reproducing the main experiments of our method are available at\nhttps://github.com/THUYimingLi/MOVE.\n","authors":["Yiming Li","Linghui Zhu","Xiaojun Jia","Yang Bai","Yong Jiang","Shu-Tao Xia","Xiaochun Cao","Kui Ren"],"pdf_url":"https://arxiv.org/pdf/2208.02820v2.pdf","comment":"This paper has been accepted by IEEE TPAMI 2025. It is the journal\n  extension of our conference paper in AAAI 2022\n  (https://ojs.aaai.org/index.php/AAAI/article/view/20036). 18 pages"},{"id":"http://arxiv.org/abs/2312.08671v2","updated":"2025-03-02T13:13:42Z","published":"2023-12-14T06:08:35Z","title":"Permutation-Invariant Graph Partitioning:How Graph Neural Networks\n  Capture Structural Interactions?","summary":"  Graph Neural Networks (GNNs) have paved the way for being a cornerstone in\ngraph-related learning tasks. Yet, the ability of GNNs to capture structural\ninteractions within graphs remains under-explored. In this work, we address\nthis gap by drawing on the insight that permutation invariant graph\npartitioning enables a powerful way of exploring structural interactions. We\nestablish theoretical connections between permutation invariant graph\npartitioning and graph isomorphism, and then propose Graph Partitioning Neural\nNetworks (GPNNs), a novel architecture that efficiently enhances the expressive\npower of GNNs in learning structural interactions. We analyze how partitioning\nschemes and structural interactions contribute to GNN expressivity and their\ntrade-offs with complexity. Empirically, we demonstrate that GPNNs outperform\nexisting GNN models in capturing structural interactions across diverse graph\nbenchmark tasks.\n","authors":["Asela Hevapathige","Qing Wang"],"pdf_url":"https://arxiv.org/pdf/2312.08671v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2406.15812v2","updated":"2025-03-02T12:28:24Z","published":"2024-06-22T10:36:04Z","title":"Intrinsic Dimension Correlation: uncovering nonlinear connections in\n  multimodal representations","summary":"  To gain insight into the mechanisms behind machine learning methods, it is\ncrucial to establish connections among the features describing data points.\nHowever, these correlations often exhibit a high-dimensional and strongly\nnonlinear nature, which makes them challenging to detect using standard\nmethods. This paper exploits the entanglement between intrinsic dimensionality\nand correlation to propose a metric that quantifies the (potentially nonlinear)\ncorrelation between high-dimensional manifolds. We first validate our method on\nsynthetic data in controlled environments, showcasing its advantages and\ndrawbacks compared to existing techniques. Subsequently, we extend our analysis\nto large-scale applications in neural network representations. Specifically, we\nfocus on latent representations of multimodal data, uncovering clear\ncorrelations between paired visual and textual embeddings, whereas existing\nmethods struggle significantly in detecting similarity. Our results indicate\nthe presence of highly nonlinear correlation patterns between latent manifolds.\n","authors":["Lorenzo Basile","Santiago Acevedo","Luca Bortolussi","Fabio Anselmi","Alex Rodriguez"],"pdf_url":"https://arxiv.org/pdf/2406.15812v2.pdf","comment":"Accepted at ICLR 2025"},{"id":"http://arxiv.org/abs/2405.01229v2","updated":"2025-03-02T12:27:07Z","published":"2024-05-02T12:18:14Z","title":"Boosting Jailbreak Attack with Momentum","summary":"  Large Language Models (LLMs) have achieved remarkable success across diverse\ntasks, yet they remain vulnerable to adversarial attacks, notably the\nwell-known jailbreak attack. In particular, the Greedy Coordinate Gradient\n(GCG) attack has demonstrated efficacy in exploiting this vulnerability by\noptimizing adversarial prompts through a combination of gradient heuristics and\ngreedy search. However, the efficiency of this attack has become a bottleneck\nin the attacking process. To mitigate this limitation, in this paper we rethink\nthe generation of the adversarial prompts through an optimization lens, aiming\nto stabilize the optimization process and harness more heuristic insights from\nprevious optimization iterations. Specifically, we propose the\n\\textbf{M}omentum \\textbf{A}ccelerated G\\textbf{C}G (\\textbf{MAC}) attack,\nwhich integrates a momentum term into the gradient heuristic to boost and\nstabilize the random search for tokens in adversarial prompts. Experimental\nresults showcase the notable enhancement achieved by MAC over baselines in\nterms of attack success rate and optimization efficiency. Moreover, we\ndemonstrate that MAC can still exhibit superior performance for transfer\nattacks and models under defense mechanisms. Our code is available at\nhttps://github.com/weizeming/momentum-attack-llm.\n","authors":["Yihao Zhang","Zeming Wei"],"pdf_url":"https://arxiv.org/pdf/2405.01229v2.pdf","comment":"Accepted by ICASSP 2025"},{"id":"http://arxiv.org/abs/2412.05994v2","updated":"2025-03-02T12:21:49Z","published":"2024-12-08T16:58:29Z","title":"PIG: Physics-Informed Gaussians as Adaptive Parametric Mesh\n  Representations","summary":"  The numerical approximation of partial differential equations (PDEs) using\nneural networks has seen significant advancements through Physics-Informed\nNeural Networks (PINNs). Despite their straightforward optimization framework\nand flexibility in implementing various PDEs, PINNs often suffer from limited\naccuracy due to the spectral bias of Multi-Layer Perceptrons (MLPs), which\nstruggle to effectively learn high-frequency and nonlinear components.\nRecently, parametric mesh representations in combination with neural networks\nhave been investigated as a promising approach to eliminate the inductive bias\nof MLPs. However, they usually require high-resolution grids and a large number\nof collocation points to achieve high accuracy while avoiding overfitting. In\naddition, the fixed positions of the mesh parameters restrict their\nflexibility, making accurate approximation of complex PDEs challenging. To\novercome these limitations, we propose Physics-Informed Gaussians (PIGs), which\ncombine feature embeddings using Gaussian functions with a lightweight neural\nnetwork. Our approach uses trainable parameters for the mean and variance of\neach Gaussian, allowing for dynamic adjustment of their positions and shapes\nduring training. This adaptability enables our model to optimally approximate\nPDE solutions, unlike models with fixed parameter positions. Furthermore, the\nproposed approach maintains the same optimization framework used in PINNs,\nallowing us to benefit from their excellent properties. Experimental results\nshow the competitive performance of our model across various PDEs,\ndemonstrating its potential as a robust tool for solving complex PDEs. Our\nproject page is available at\nhttps://namgyukang.github.io/Physics-Informed-Gaussians/\n","authors":["Namgyu Kang","Jaemin Oh","Youngjoon Hong","Eunbyung Park"],"pdf_url":"https://arxiv.org/pdf/2412.05994v2.pdf","comment":"Project page:\n  https://namgyukang.github.io/Physics-Informed-Gaussians/"},{"id":"http://arxiv.org/abs/2410.12025v2","updated":"2025-03-02T12:20:56Z","published":"2024-10-15T19:46:09Z","title":"Geometric Inductive Biases of Deep Networks: The Role of Data and\n  Architecture","summary":"  In this paper, we propose the $\\textit{geometric invariance hypothesis\n(GIH)}$, which argues that the input space curvature of a neural network\nremains invariant under transformation in certain architecture-dependent\ndirections during training. We investigate a simple, non-linear binary\nclassification problem residing on a plane in a high dimensional space and\nobserve that$\\unicode{x2014}$unlike MPLs$\\unicode{x2014}$ResNets fail to\ngeneralize depending on the orientation of the plane. Motivated by this\nexample, we define a neural network's $\\textbf{average geometry}$ and\n$\\textbf{average geometry evolution}$ as compact\n$\\textit{architecture-dependent}$ summaries of the model's input-output\ngeometry and its evolution during training. By investigating the average\ngeometry evolution at initialization, we discover that the geometry of a neural\nnetwork evolves according to the data covariance projected onto its average\ngeometry. This means that the geometry only changes in a subset of the input\nspace when the average geometry is low-rank, such as in ResNets. This causes an\narchitecture-dependent invariance property in the input space curvature, which\nwe dub GIH. Finally, we present extensive experimental results to observe the\nconsequences of GIH and how it relates to generalization in neural networks.\n","authors":["Sajad Movahedi","Antonio Orvieto","Seyed-Mohsen Moosavi-Dezfooli"],"pdf_url":"https://arxiv.org/pdf/2410.12025v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2502.14309v2","updated":"2025-03-02T12:04:35Z","published":"2025-02-20T06:51:42Z","title":"On Theoretical Limits of Learning with Label Differential Privacy","summary":"  Label differential privacy (DP) is designed for learning problems involving\nprivate labels and public features. While various methods have been proposed\nfor learning under label DP, the theoretical limits remain largely unexplored.\nIn this paper, we investigate the fundamental limits of learning with label DP\nin both local and central models for both classification and regression tasks,\ncharacterized by minimax convergence rates. We establish lower bounds by\nconverting each task into a multiple hypothesis testing problem and bounding\nthe test error. Additionally, we develop algorithms that yield matching upper\nbounds. Our results demonstrate that under label local DP (LDP), the risk has a\nsignificantly faster convergence rate than that under full LDP, i.e. protecting\nboth features and labels, indicating the advantages of relaxing the DP\ndefinition to focus solely on labels. In contrast, under the label central DP\n(CDP), the risk is only reduced by a constant factor compared to full DP,\nindicating that the relaxation of CDP only has limited benefits on the\nperformance.\n","authors":["Puning Zhao","Chuan Ma","Li Shen","Shaowei Wang","Rongfei Fan"],"pdf_url":"https://arxiv.org/pdf/2502.14309v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2407.04942v2","updated":"2025-03-02T11:55:15Z","published":"2024-07-06T03:22:57Z","title":"FOSP: Fine-tuning Offline Safe Policy through World Models","summary":"  Offline Safe Reinforcement Learning (RL) seeks to address safety constraints\nby learning from static datasets and restricting exploration. However, these\napproaches heavily rely on the dataset and struggle to generalize to unseen\nscenarios safely. In this paper, we aim to improve safety during the deployment\nof vision-based robotic tasks through online fine-tuning an offline pretrained\npolicy. To facilitate effective fine-tuning, we introduce model-based RL, which\nis known for its data efficiency. Specifically, our method employs in-sample\noptimization to improve offline training efficiency while incorporating\nreachability guidance to ensure safety. After obtaining an offline safe policy,\na safe policy expansion approach is leveraged for online fine-tuning. The\nperformance of our method is validated on simulation benchmarks with five\nvision-only tasks and through real-world robot deployment using limited data.\nIt demonstrates that our approach significantly improves the generalization of\noffline policies to unseen safety-constrained scenarios. To the best of our\nknowledge, this is the first work to explore offline-to-online RL for safe\ngeneralization tasks.\n","authors":["Chenyang Cao","Yucheng Xin","Silang Wu","Longxiang He","Zichen Yan","Junbo Tan","Xueqian Wang"],"pdf_url":"https://arxiv.org/pdf/2407.04942v2.pdf","comment":"32 pages, ICLR2025"},{"id":"http://arxiv.org/abs/2411.02275v2","updated":"2025-03-02T11:48:40Z","published":"2024-11-04T17:05:37Z","title":"Breaking the Reclustering Barrier in Centroid-based Deep Clustering","summary":"  This work investigates an important phenomenon in centroid-based deep\nclustering (DC) algorithms: Performance quickly saturates after a period of\nrapid early gains. Practitioners commonly address early saturation with\nperiodic reclustering, which we demonstrate to be insufficient to address\nperformance plateaus. We call this phenomenon the \"reclustering barrier\" and\nempirically show when the reclustering barrier occurs, what its underlying\nmechanisms are, and how it is possible to Break the Reclustering Barrier with\nour algorithm BRB. BRB avoids early over-commitment to initial clusterings and\nenables continuous adaptation to reinitialized clustering targets while\nremaining conceptually simple. Applying our algorithm to widely-used\ncentroid-based DC algorithms, we show that (1) BRB consistently improves\nperformance across a wide range of clustering benchmarks, (2) BRB enables\ntraining from scratch, and (3) BRB performs competitively against\nstate-of-the-art DC algorithms when combined with a contrastive loss. We\nrelease our code and pre-trained models at\nhttps://github.com/Probabilistic-and-Interactive-ML/breaking-the-reclustering-barrier .\n","authors":["Lukas Miklautz","Timo Klein","Kevin Sidak","Collin Leiber","Thomas Lang","Andrii Shkabrii","Sebastian Tschiatschek","Claudia Plant"],"pdf_url":"https://arxiv.org/pdf/2411.02275v2.pdf","comment":"Accepted at ICLR 2025 (Camera-ready version)"},{"id":"http://arxiv.org/abs/2407.05649v4","updated":"2025-03-02T11:37:49Z","published":"2024-07-08T06:21:56Z","title":"Greener GRASS: Enhancing GNNs with Encoding, Rewiring, and Attention","summary":"  Graph Neural Networks (GNNs) have become important tools for machine learning\non graph-structured data. In this paper, we explore the synergistic combination\nof graph encoding, graph rewiring, and graph attention, by introducing Graph\nAttention with Stochastic Structures (GRASS), a novel GNN architecture. GRASS\nutilizes relative random walk probabilities (RRWP) encoding and a novel\ndecomposed variant (D-RRWP) to efficiently capture structural information. It\nrewires the input graph by superimposing a random regular graph to enhance\nlong-range information propagation. It also employs a novel additive attention\nmechanism tailored for graph-structured data. Our empirical evaluations\ndemonstrate that GRASS achieves state-of-the-art performance on multiple\nbenchmark datasets, including a 20.3% reduction in mean absolute error on the\nZINC dataset.\n","authors":["Tongzhou Liao","Barnabs Pczos"],"pdf_url":"https://arxiv.org/pdf/2407.05649v4.pdf","comment":"Published as a conference paper at ICLR 2025"},{"id":"http://arxiv.org/abs/2410.02242v2","updated":"2025-03-02T11:32:27Z","published":"2024-10-03T06:30:27Z","title":"Robust Weight Initialization for Tanh Neural Networks with Fixed Point\n  Analysis","summary":"  As a neural network's depth increases, it can improve generalization\nperformance. However, training deep networks is challenging due to gradient and\nsignal propagation issues. To address these challenges, extensive theoretical\nresearch and various methods have been introduced. Despite these advances,\neffective weight initialization methods for tanh neural networks remain\ninsufficiently investigated. This paper presents a novel weight initialization\nmethod for neural networks with tanh activation function. Based on an analysis\nof the fixed points of the function $\\tanh(ax)$, the proposed method aims to\ndetermine values of $a$ that mitigate activation saturation. A series of\nexperiments on various classification datasets and physics-informed neural\nnetworks demonstrates that the proposed method outperforms Xavier\ninitialization methods~(with or without normalization) in terms of robustness\nacross different network sizes, data efficiency, and convergence speed. Code is\navailable at https://github.com/1HyunwooLee/Tanh-Init\n","authors":["Hyunwoo Lee","Hayoung Choi","Hyunju Kim"],"pdf_url":"https://arxiv.org/pdf/2410.02242v2.pdf","comment":"ICLR 2025"},{"id":"http://arxiv.org/abs/2502.19649v2","updated":"2025-03-02T11:23:58Z","published":"2025-02-27T00:40:01Z","title":"Taxonomy, Opportunities, and Challenges of Representation Engineering\n  for Large Language Models","summary":"  Representation Engineering (RepE) is a novel paradigm for controlling the\nbehavior of LLMs. Unlike traditional approaches that modify inputs or fine-tune\nthe model, RepE directly manipulates the model's internal representations. As a\nresult, it may offer more effective, interpretable, data-efficient, and\nflexible control over models' behavior. We present the first comprehensive\nsurvey of RepE for LLMs, reviewing the rapidly growing literature to address\nkey questions: What RepE methods exist and how do they differ? For what\nconcepts and problems has RepE been applied? What are the strengths and\nweaknesses of RepE compared to other methods? To answer these, we propose a\nunified framework describing RepE as a pipeline comprising representation\nidentification, operationalization, and control. We posit that while RepE\nmethods offer significant potential, challenges remain, including managing\nmultiple concepts, ensuring reliability, and preserving models' performance.\nTowards improving RepE, we identify opportunities for experimental and\nmethodological improvements and construct a guide for best practices.\n","authors":["Jan Wehner","Sahar Abdelnabi","Daniel Tan","David Krueger","Mario Fritz"],"pdf_url":"https://arxiv.org/pdf/2502.19649v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.04803v4","updated":"2025-03-02T11:22:35Z","published":"2024-10-07T07:27:39Z","title":"Timer-XL: Long-Context Transformers for Unified Time Series Forecasting","summary":"  We present Timer-XL, a causal Transformer for unified time series\nforecasting. To uniformly predict multidimensional time series, we generalize\nnext token prediction, predominantly adopted for 1D token sequences, to\nmultivariate next token prediction. The paradigm formulates various forecasting\ntasks as a long-context prediction problem. We opt for decoder-only\nTransformers that capture causal dependencies from varying-length contexts for\nunified forecasting, making predictions on non-stationary univariate time\nseries, multivariate series with complicated dynamics and correlations, as well\nas covariate-informed contexts that include exogenous variables. Technically,\nwe propose a universal TimeAttention to capture fine-grained intra- and\ninter-series dependencies of flattened time series tokens (patches), which is\nfurther enhanced by deft position embedding for temporal causality and variable\nequivalence. Timer-XL achieves state-of-the-art performance across\ntask-specific forecasting benchmarks through a unified approach. Based on\nlarge-scale pre-training, Timer-XL achieves state-of-the-art zero-shot\nperformance, making it a promising architecture for pre-trained time series\nmodels. Code is available at this repository:\nhttps://github.com/thuml/Timer-XL.\n","authors":["Yong Liu","Guo Qin","Xiangdong Huang","Jianmin Wang","Mingsheng Long"],"pdf_url":"https://arxiv.org/pdf/2410.04803v4.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.02957v4","updated":"2025-03-02T10:59:52Z","published":"2024-03-05T13:25:44Z","title":"On the Asymptotic Mean Square Error Optimality of Diffusion Models","summary":"  Diffusion models (DMs) as generative priors have recently shown great\npotential for denoising tasks but lack theoretical understanding with respect\nto their mean square error (MSE) optimality. This paper proposes a novel\ndenoising strategy inspired by the structure of the MSE-optimal conditional\nmean estimator (CME). The resulting DM-based denoiser can be conveniently\nemployed using a pre-trained DM, being particularly fast by truncating reverse\ndiffusion steps and not requiring stochastic re-sampling. We present a\ncomprehensive (non-)asymptotic optimality analysis of the proposed\ndiffusion-based denoiser, demonstrating polynomial-time convergence to the CME\nunder mild conditions. Our analysis also derives a novel Lipschitz constant\nthat depends solely on the DM's hyperparameters. Further, we offer a new\nperspective on DMs, showing that they inherently combine an asymptotically\noptimal denoiser with a powerful generator, modifiable by switching re-sampling\nin the reverse process on or off. The theoretical findings are thoroughly\nvalidated with experiments based on various benchmark datasets\n","authors":["Benedikt Fesl","Benedikt Bck","Florian Strasser","Michael Baur","Michael Joham","Wolfgang Utschick"],"pdf_url":"https://arxiv.org/pdf/2403.02957v4.pdf","comment":null},{"id":"http://arxiv.org/abs/2212.13706v3","updated":"2025-03-02T10:52:11Z","published":"2022-12-28T05:43:57Z","title":"End-to-End Modeling Hierarchical Time Series Using Autoregressive\n  Transformer and Conditional Normalizing Flow based Reconciliation","summary":"  Multivariate time series forecasting with hierarchical structure is pervasive\nin real-world applications, demanding not only predicting each level of the\nhierarchy, but also reconciling all forecasts to ensure coherency, i.e., the\nforecasts should satisfy the hierarchical aggregation constraints. Moreover,\nthe disparities of statistical characteristics between levels can be huge,\nworsened by non-Gaussian distributions and non-linear correlations. To this\nextent, we propose a novel end-to-end hierarchical time series forecasting\nmodel, based on conditioned normalizing flow-based autoregressive transformer\nreconciliation, to represent complex data distribution while simultaneously\nreconciling the forecasts to ensure coherency. Unlike other state-of-the-art\nmethods, we achieve the forecasting and reconciliation simultaneously without\nrequiring any explicit post-processing step. In addition, by harnessing the\npower of deep model, we do not rely on any assumption such as unbiased\nestimates or Gaussian distribution. Our evaluation experiments are conducted on\nfour real-world hierarchical datasets from different industrial domains (three\npublic ones and a dataset from the application servers of Alipay's data center)\nand the preliminary results demonstrate efficacy of our proposed method.\n","authors":["Shiyu Wang","Fan Zhou","Yinbo Sun","Lintao Ma","James Zhang","Yangfei Zheng"],"pdf_url":"https://arxiv.org/pdf/2212.13706v3.pdf","comment":"Accepted by the 22nd IEEE International Conference on Data Mining\n  (ICDM2022)"},{"id":"http://arxiv.org/abs/2402.05569v5","updated":"2025-03-02T10:48:32Z","published":"2024-02-08T11:10:39Z","title":"Training-Free Message Passing for Learning on Hypergraphs","summary":"  Hypergraphs are crucial for modelling higher-order interactions in real-world\ndata. Hypergraph neural networks (HNNs) effectively utilise these structures by\nmessage passing to generate informative node features for various downstream\ntasks like node classification. However, the message passing module in existing\nHNNs typically requires a computationally intensive training process, which\nlimits their practical use. To tackle this challenge, we propose an alternative\napproach by decoupling the usage of hypergraph structural information from the\nmodel learning stage. This leads to a novel training-free message passing\nmodule, named TF-MP-Module, which can be precomputed in the data preprocessing\nstage, thereby reducing the computational burden. We refer to the hypergraph\nneural network equipped with our TF-MP-Module as TF-HNN. We theoretically\nsupport the efficiency and effectiveness of TF-HNN by showing that: 1) It is\nmore training-efficient compared to existing HNNs; 2) It utilises as much\ninformation as existing HNNs for node feature generation; and 3) It is robust\nagainst the oversmoothing issue while using long-range interactions.\nExperiments based on seven real-world hypergraph benchmarks in node\nclassification and hyperlink prediction show that, compared to state-of-the-art\nHNNs, TF-HNN exhibits both competitive performance and superior training\nefficiency. Specifically, on the large-scale benchmark, Trivago, TF-HNN\noutperforms the node classification accuracy of the best baseline by 10% with\njust 1% of the training time of that baseline.\n","authors":["Bohan Tang","Zexi Liu","Keyue Jiang","Siheng Chen","Xiaowen Dong"],"pdf_url":"https://arxiv.org/pdf/2402.05569v5.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.14666v2","updated":"2025-03-02T10:38:32Z","published":"2024-10-18T17:56:11Z","title":"DiscoGraMS: Enhancing Movie Screen-Play Summarization using Movie\n  Character-Aware Discourse Graph","summary":"  Summarizing movie screenplays presents a unique set of challenges compared to\nstandard document summarization. Screenplays are not only lengthy, but also\nfeature a complex interplay of characters, dialogues, and scenes, with numerous\ndirect and subtle relationships and contextual nuances that are difficult for\nmachine learning models to accurately capture and comprehend. Recent attempts\nat screenplay summarization focus on fine-tuning transformer-based pre-trained\nmodels, but these models often fall short in capturing long-term dependencies\nand latent relationships, and frequently encounter the \"lost in the middle\"\nissue. To address these challenges, we introduce DiscoGraMS, a novel resource\nthat represents movie scripts as a movie character-aware discourse graph (CaD\nGraph). This approach is well-suited for various downstream tasks, such as\nsummarization, question-answering, and salience detection. The model aims to\npreserve all salient information, offering a more comprehensive and faithful\nrepresentation of the screenplay's content. We further explore a baseline\nmethod that combines the CaD Graph with the corresponding movie script through\na late fusion of graph and text modalities, and we present very initial\npromising results.\n","authors":["Maitreya Prafulla Chitale","Uday Bindal","Rajakrishnan Rajkumar","Rahul Mishra"],"pdf_url":"https://arxiv.org/pdf/2410.14666v2.pdf","comment":"Accepted at NAACL 2025 (Main)"},{"id":"http://arxiv.org/abs/2411.15216v2","updated":"2025-03-02T10:23:51Z","published":"2024-11-20T16:17:40Z","title":"Dist Loss: Enhancing Regression in Few-Shot Region through Distribution\n  Distance Constraint","summary":"  Imbalanced data distributions are prevalent in real-world scenarios, posing\nsignificant challenges in both imbalanced classification and imbalanced\nregression tasks. They often cause deep learning models to overfit in areas of\nhigh sample density (many-shot regions) while underperforming in areas of low\nsample density (few-shot regions). This characteristic restricts the utility of\ndeep learning models in various sectors, notably healthcare, where areas with\nfew-shot data hold greater clinical relevance. While recent studies have shown\nthe benefits of incorporating distribution information in imbalanced\nclassification tasks, such strategies are rarely explored in imbalanced\nregression. In this paper, we address this issue by introducing a novel loss\nfunction, termed Dist Loss, designed to minimize the distribution distance\nbetween the model's predictions and the target labels in a differentiable\nmanner, effectively integrating distribution information into model training.\nDist Loss enables deep learning models to regularize their output distribution\nduring training, effectively enhancing their focus on few-shot regions. We have\nconducted extensive experiments across three datasets spanning computer vision\nand healthcare: IMDB-WIKI-DIR, AgeDB-DIR, and ECG-Ka-DIR. The results\ndemonstrate that Dist Loss effectively mitigates the negative impact of\nimbalanced data distribution on model performance, achieving state-of-the-art\nresults in sparse data regions. Furthermore, Dist Loss is easy to integrate,\ncomplementing existing methods.\n","authors":["Guangkun Nie","Gongzheng Tang","Shenda Hong"],"pdf_url":"https://arxiv.org/pdf/2411.15216v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2502.14897v2","updated":"2025-03-02T10:18:09Z","published":"2025-02-17T21:35:18Z","title":"Market-Derived Financial Sentiment Analysis: Context-Aware Language\n  Models for Crypto Forecasting","summary":"  Financial Sentiment Analysis (FSA) traditionally relies on human-annotated\nsentiment labels to infer investor sentiment and forecast market movements.\nHowever, inferring the potential market impact of words based on their\nhuman-perceived intentions is inherently challenging. We hypothesize that the\nhistorical market reactions to words, offer a more reliable indicator of their\npotential impact on markets than subjective sentiment interpretations by human\nannotators. To test this hypothesis, a market-derived labeling approach is\nproposed to assign tweet labels based on ensuing short-term price trends,\nenabling the language model to capture the relationship between textual signals\nand market dynamics directly. A domain-specific language model was fine-tuned\non these labels, achieving up to an 11% improvement in short-term trend\nprediction accuracy over traditional sentiment-based benchmarks. Moreover, by\nincorporating market and temporal context through prompt-tuning, the proposed\ncontext-aware language model demonstrated an accuracy of 89.6% on a curated\ndataset of 227 impactful Bitcoin-related news events with significant market\nimpacts. Aggregating daily tweet predictions into trading signals, our method\noutperformed traditional fusion models (which combine sentiment-based and\nprice-based predictions). It challenged the assumption that sentiment-based\nsignals are inferior to price-based predictions in forecasting market\nmovements. Backtesting these signals across three distinct market regimes\nyielded robust Sharpe ratios of up to 5.07 in trending markets and 3.73 in\nneutral markets. Our findings demonstrate that language models can serve as\neffective short-term market predictors. This paradigm shift underscores the\nuntapped capabilities of language models in financial decision-making and opens\nnew avenues for market prediction applications.\n","authors":["Hamid Moradi-Kamali","Mohammad-Hossein Rajabi-Ghozlou","Mahdi Ghazavi","Ali Soltani","Amirreza Sattarzadeh","Reza Entezari-Maleki"],"pdf_url":"https://arxiv.org/pdf/2502.14897v2.pdf","comment":"13 pages, 6 figures"}]},"2025-03-04T00:00:00Z":{"Computation and Language":[{"id":"http://arxiv.org/abs/2502.19732v3","updated":"2025-03-04T03:46:23Z","published":"2025-02-27T03:53:45Z","title":"Speculative Decoding and Beyond: An In-Depth Survey of Techniques","summary":"  Sequential dependencies present a fundamental bottleneck in deploying\nlarge-scale autoregressive models, particularly for real-time applications.\nWhile traditional optimization approaches like pruning and quantization often\ncompromise model quality, recent advances in generation-refinement frameworks\ndemonstrate that this trade-off can be significantly mitigated.\n  This survey presents a comprehensive taxonomy of generation-refinement\nframeworks, analyzing methods across autoregressive sequence tasks. We\ncategorize methods based on their generation strategies (from simple n-gram\nprediction to sophisticated draft models) and refinement mechanisms (including\nsingle-pass verification and iterative approaches). Through systematic analysis\nof both algorithmic innovations and system-level implementations, we examine\ndeployment strategies across computing environments and explore applications\nspanning text, images, and speech generation. This systematic examination of\nboth theoretical frameworks and practical implementations provides a foundation\nfor future research in efficient autoregressive decoding.\n","authors":["Yunhai Hu","Zining Liu","Zhenyuan Dong","Tianfan Peng","Bradley McDanel","Sai Qian Zhang"],"pdf_url":"https://arxiv.org/pdf/2502.19732v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.23771v3","updated":"2025-03-04T04:07:01Z","published":"2024-10-31T09:39:28Z","title":"What is Wrong with Perplexity for Long-context Language Modeling?","summary":"  Handling long-context inputs is crucial for large language models (LLMs) in\ntasks such as extended conversations, document summarization, and many-shot\nin-context learning. While recent approaches have extended the context windows\nof LLMs and employed perplexity (PPL) as a standard evaluation metric, PPL has\nproven unreliable for assessing long-context capabilities. The underlying cause\nof this limitation has remained unclear. In this work, we provide a\ncomprehensive explanation for this issue. We find that PPL overlooks key\ntokens, which are essential for long-context understanding, by averaging across\nall tokens and thereby obscuring the true performance of models in long-context\nscenarios. To address this, we propose \\textbf{LongPPL}, a novel metric that\nfocuses on key tokens by employing a long-short context contrastive method to\nidentify them. Our experiments demonstrate that LongPPL strongly correlates\nwith performance on various long-context benchmarks (e.g., Pearson correlation\nof -0.96), significantly outperforming traditional PPL in predictive accuracy.\nAdditionally, we introduce \\textbf{LongCE} (Long-context Cross-Entropy) loss, a\nre-weighting strategy for fine-tuning that prioritizes key tokens, leading to\nconsistent improvements across diverse benchmarks. In summary, these\ncontributions offer deeper insights into the limitations of PPL and present\neffective solutions for accurately evaluating and enhancing the long-context\ncapabilities of LLMs. Code is available at https://github.com/PKU-ML/LongPPL.\n","authors":["Lizhe Fang","Yifei Wang","Zhaoyang Liu","Chenheng Zhang","Stefanie Jegelka","Jinyang Gao","Bolin Ding","Yisen Wang"],"pdf_url":"https://arxiv.org/pdf/2410.23771v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2407.06057v3","updated":"2025-03-04T14:33:50Z","published":"2024-07-08T15:59:44Z","title":"Variational Best-of-N Alignment","summary":"  Best-of-N (BoN) is a popular and effective algorithm for aligning language\nmodels to human preferences. The algorithm works as follows: at inference time,\nN samples are drawn from the language model, and the sample with the highest\nreward, as judged by a reward model, is returned as the output. Despite its\neffectiveness, BoN is computationally expensive; it reduces sampling throughput\nby a factor of N. To make BoN more efficient at inference time, one strategy is\nto fine-tune the language model to mimic what BoN does during inference. To\nachieve this, we derive the distribution induced by the BoN algorithm. We then\npropose to fine-tune the language model to minimize backward KL divergence to\nthe BoN distribution. Our approach is analogous to mean-field variational\ninference and, thus, we term it variational BoN (vBoN). To the extent this\nfine-tuning is successful and we end up with a good approximation, we have\nreduced the inference cost by a factor of N. Our experiments on controlled\ngeneration and summarization tasks show that BoN is the most effective\nalignment method, and our variational approximation to BoN achieves the closest\nperformance to BoN and surpasses models fine-tuned using the standard\nKL-constrained RL objective. In the controlled generation task, vBoN appears\nmore frequently on the Pareto frontier of reward and KL divergence compared to\nother alignment methods. In the summarization task, vBoN achieves high reward\nvalues across various sampling temperatures.\n","authors":["Afra Amini","Tim Vieira","Elliott Ash","Ryan Cotterell"],"pdf_url":"https://arxiv.org/pdf/2407.06057v3.pdf","comment":"Accepted at ICLR 2025"},{"id":"http://arxiv.org/abs/2502.12110v3","updated":"2025-03-04T15:09:10Z","published":"2025-02-17T18:36:14Z","title":"A-MEM: Agentic Memory for LLM Agents","summary":"  While large language model (LLM) agents can effectively use external tools\nfor complex real-world tasks, they require memory systems to leverage\nhistorical experiences. Current memory systems enable basic storage and\nretrieval but lack sophisticated memory organization, despite recent attempts\nto incorporate graph databases. Moreover, these systems' fixed operations and\nstructures limit their adaptability across diverse tasks. To address this\nlimitation, this paper proposes a novel agentic memory system for LLM agents\nthat can dynamically organize memories in an agentic way. Following the basic\nprinciples of the Zettelkasten method, we designed our memory system to create\ninterconnected knowledge networks through dynamic indexing and linking. When a\nnew memory is added, we generate a comprehensive note containing multiple\nstructured attributes, including contextual descriptions, keywords, and tags.\nThe system then analyzes historical memories to identify relevant connections,\nestablishing links where meaningful similarities exist. Additionally, this\nprocess enables memory evolution - as new memories are integrated, they can\ntrigger updates to the contextual representations and attributes of existing\nhistorical memories, allowing the memory network to continuously refine its\nunderstanding. Our approach combines the structured organization principles of\nZettelkasten with the flexibility of agent-driven decision making, allowing for\nmore adaptive and context-aware memory management. Empirical experiments on six\nfoundation models show superior improvement against existing SOTA baselines.\nThe source code for evaluating performance is available at\nhttps://github.com/WujiangXu/AgenticMemory, while the source code of agentic\nmemory system is available at https://github.com/agiresearch/A-mem.\n","authors":["Wujiang Xu","Zujie Liang","Kai Mei","Hang Gao","Juntao Tan","Yongfeng Zhang"],"pdf_url":"https://arxiv.org/pdf/2502.12110v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2405.14093v4","updated":"2025-03-04T08:24:20Z","published":"2024-05-23T01:43:54Z","title":"A Survey on Vision-Language-Action Models for Embodied AI","summary":"  Embodied AI is widely recognized as a key element of artificial general\nintelligence because it involves controlling embodied agents to perform tasks\nin the physical world. Building on the success of large language models and\nvision-language models, a new category of multimodal models -- referred to as\nvision-language-action models (VLAs) -- has emerged to address\nlanguage-conditioned robotic tasks in embodied AI by leveraging their distinct\nability to generate actions. In recent years, a myriad of VLAs have been\ndeveloped, making it imperative to capture the rapidly evolving landscape\nthrough a comprehensive survey. To this end, we present the first survey on\nVLAs for embodied AI. This work provides a detailed taxonomy of VLAs, organized\ninto three major lines of research. The first line focuses on individual\ncomponents of VLAs. The second line is dedicated to developing control policies\nadept at predicting low-level actions. The third line comprises high-level task\nplanners capable of decomposing long-horizon tasks into a sequence of subtasks,\nthereby guiding VLAs to follow more general user instructions. Furthermore, we\nprovide an extensive summary of relevant resources, including datasets,\nsimulators, and benchmarks. Finally, we discuss the challenges faced by VLAs\nand outline promising future directions in embodied AI. We have created a\nproject associated with this survey, which is available at\nhttps://github.com/yueen-ma/Awesome-VLA.\n","authors":["Yueen Ma","Zixing Song","Yuzheng Zhuang","Jianye Hao","Irwin King"],"pdf_url":"https://arxiv.org/pdf/2405.14093v4.pdf","comment":"Project page: https://github.com/yueen-ma/Awesome-VLA"},{"id":"http://arxiv.org/abs/2503.02879v1","updated":"2025-03-04T18:58:13Z","published":"2025-03-04T18:58:13Z","title":"Wikipedia in the Era of LLMs: Evolution and Risks","summary":"  In this paper, we present a thorough analysis of the impact of Large Language\nModels (LLMs) on Wikipedia, examining the evolution of Wikipedia through\nexisting data and using simulations to explore potential risks. We begin by\nanalyzing page views and article content to study Wikipedia's recent changes\nand assess the impact of LLMs. Subsequently, we evaluate how LLMs affect\nvarious Natural Language Processing (NLP) tasks related to Wikipedia, including\nmachine translation and retrieval-augmented generation (RAG). Our findings and\nsimulation results reveal that Wikipedia articles have been influenced by LLMs,\nwith an impact of approximately 1%-2% in certain categories. If the machine\ntranslation benchmark based on Wikipedia is influenced by LLMs, the scores of\nthe models may become inflated, and the comparative results among models might\nshift as well. Moreover, the effectiveness of RAG might decrease if the\nknowledge base becomes polluted by LLM-generated content. While LLMs have not\nyet fully changed Wikipedia's language and knowledge structures, we believe\nthat our empirical findings signal the need for careful consideration of\npotential future risks.\n","authors":["Siming Huang","Yuliang Xu","Mingmeng Geng","Yao Wan","Dongping Chen"],"pdf_url":"https://arxiv.org/pdf/2503.02879v1.pdf","comment":"We release all the experimental dataset and source code at:\n  https://github.com/HSM316/LLM_Wikipedia"},{"id":"http://arxiv.org/abs/2503.02878v1","updated":"2025-03-04T18:58:11Z","published":"2025-03-04T18:58:11Z","title":"Language Models can Self-Improve at State-Value Estimation for Better\n  Search","summary":"  Collecting ground truth task completion rewards or human demonstrations for\nmulti-step reasoning tasks is often cost-prohibitive and time-consuming,\nespecially in interactive domains like web tasks. To address this bottleneck,\nwe present self-taught lookahead, a self-supervised method that leverages\nstate-transition dynamics to train a value model capable of effectively guiding\nlanguage model-controlled search. We find that moderately sized (8 billion\nparameters) open-weight value models improved with self-taught lookahead can\nmatch the performance of using a frontier LLM such as gpt-4o as the value\nmodel. Furthermore, we find that self-taught lookahead improves performance by\n20% while reducing costs 37x compared to previous LLM-based tree search,\nwithout relying on ground truth rewards.\n","authors":["Ethan Mendes","Alan Ritter"],"pdf_url":"https://arxiv.org/pdf/2503.02878v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.02875v1","updated":"2025-03-04T18:56:03Z","published":"2025-03-04T18:56:03Z","title":"The First Few Tokens Are All You Need: An Efficient and Effective\n  Unsupervised Prefix Fine-Tuning Method for Reasoning Models","summary":"  Improving the reasoning capabilities of large language models (LLMs)\ntypically requires supervised fine-tuning with labeled data or computationally\nexpensive sampling. We introduce Unsupervised Prefix Fine-Tuning (UPFT), which\nleverages the observation of Prefix Self-Consistency -- the shared initial\nreasoning steps across diverse solution trajectories -- to enhance LLM\nreasoning efficiency. By training exclusively on the initial prefix substrings\n(as few as 8 tokens), UPFT removes the need for labeled data or exhaustive\nsampling. Experiments on reasoning benchmarks show that UPFT matches the\nperformance of supervised methods such as Rejection Sampling Fine-Tuning, while\nreducing training time by 75% and sampling cost by 99%. Further analysis\nreveals that errors tend to appear in later stages of the reasoning process and\nthat prefix-based training preserves the model's structural knowledge. This\nwork demonstrates how minimal unsupervised fine-tuning can unlock substantial\nreasoning gains in LLMs, offering a scalable and resource-efficient alternative\nto conventional approaches.\n","authors":["Ke Ji","Jiahao Xu","Tian Liang","Qiuzhi Liu","Zhiwei He","Xingyu Chen","Xiaoyuan Liu","Zhijie Wang","Junying Chen","Benyou Wang","Zhaopeng Tu","Haitao Mi","Dong Yu"],"pdf_url":"https://arxiv.org/pdf/2503.02875v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2409.14509v5","updated":"2025-03-04T18:55:27Z","published":"2024-09-22T16:13:00Z","title":"Can AI writing be salvaged? Mitigating Idiosyncrasies and Improving\n  Human-AI Alignment in the Writing Process through Edits","summary":"  LLM-based applications are helping people write, and LLM-generated text is\nmaking its way into social media, journalism, and our classrooms. However, the\ndifferences between LLM-generated and human written text remain unclear. To\nexplore this, we hired professional writers to edit paragraphs in several\ncreative domains. We first found these writers agree on undesirable\nidiosyncrasies in LLM generated text, formalizing it into a seven-category\ntaxonomy (e.g. clich\\'es, unnecessary exposition). Second, we curated the LAMP\ncorpus: 1,057 LLM-generated paragraphs edited by professional writers according\nto our taxonomy. Analysis of LAMP reveals that none of the LLMs used in our\nstudy (GPT4o, Claude-3.5-Sonnet, Llama-3.1-70b) outperform each other in terms\nof writing quality, revealing common limitations across model families. Third,\nbuilding on existing work in automatic editing we evaluated methods to improve\nLLM-generated text. A large-scale preference annotation confirms that although\nexperts largely prefer text edited by other experts, automatic editing methods\nshow promise in improving alignment between LLM-generated and human-written\ntext.\n","authors":["Tuhin Chakrabarty","Philippe Laban","Chien-Sheng Wu"],"pdf_url":"https://arxiv.org/pdf/2409.14509v5.pdf","comment":"ACM CHI 2025"},{"id":"http://arxiv.org/abs/2503.00043v2","updated":"2025-03-04T18:47:38Z","published":"2025-02-25T23:36:19Z","title":"VOILA: Evaluation of MLLMs For Perceptual Understanding and Analogical\n  Reasoning","summary":"  Multimodal Large Language Models (MLLMs) have become a powerful tool for\nintegrating visual and textual information. Despite their exceptional\nperformance on visual understanding benchmarks, measuring their ability to\nreason abstractly across multiple images remains a significant challenge. To\naddress this, we introduce VOILA, a large-scale, open-ended, dynamic benchmark\ndesigned to evaluate MLLMs' perceptual understanding and abstract relational\nreasoning. VOILA employs an analogical mapping approach in the visual domain,\nrequiring models to generate an image that completes an analogy between two\ngiven image pairs, reference and application, without relying on predefined\nchoices. Our experiments demonstrate that the analogical reasoning tasks in\nVOILA present a challenge to MLLMs. Through multi-step analysis, we reveal that\ncurrent MLLMs struggle to comprehend inter-image relationships and exhibit\nlimited capabilities in high-level relational reasoning. Notably, we observe\nthat performance improves when following a multi-step strategy of least-to-most\nprompting. Comprehensive evaluations on open-source models and GPT-4o show that\non text-based answers, the best accuracy for challenging scenarios is 13%\n(LLaMa 3.2) and even for simpler tasks is only 29% (GPT-4o), while human\nperformance is significantly higher at 70% across both difficulty levels.\n","authors":["Nilay Yilmaz","Maitreya Patel","Yiran Lawrence Luo","Tejas Gokhale","Chitta Baral","Suren Jayasuriya","Yezhou Yang"],"pdf_url":"https://arxiv.org/pdf/2503.00043v2.pdf","comment":"Accepted at ICLR 2025. Code and data: https://github.com/nlylmz/Voila"},{"id":"http://arxiv.org/abs/2503.02865v1","updated":"2025-03-04T18:43:57Z","published":"2025-03-04T18:43:57Z","title":"FairSense-AI: Responsible AI Meets Sustainability","summary":"  In this paper, we introduce FairSense-AI: a multimodal framework designed to\ndetect and mitigate bias in both text and images. By leveraging Large Language\nModels (LLMs) and Vision-Language Models (VLMs), FairSense-AI uncovers subtle\nforms of prejudice or stereotyping that can appear in content, providing users\nwith bias scores, explanatory highlights, and automated recommendations for\nfairness enhancements. In addition, FairSense-AI integrates an AI risk\nassessment component that aligns with frameworks like the MIT AI Risk\nRepository and NIST AI Risk Management Framework, enabling structured\nidentification of ethical and safety concerns. The platform is optimized for\nenergy efficiency via techniques such as model pruning and mixed-precision\ncomputation, thereby reducing its environmental footprint. Through a series of\ncase studies and applications, we demonstrate how FairSense-AI promotes\nresponsible AI use by addressing both the social dimension of fairness and the\npressing need for sustainability in large-scale AI deployments.\nhttps://vectorinstitute.github.io/FairSense-AI,\nhttps://pypi.org/project/fair-sense-ai/\n","authors":["Shaina Raza","Mukund Sayeeganesh Chettiar","Matin Yousefabadi","Tahniat Khan","Marcelo Lotif"],"pdf_url":"https://arxiv.org/pdf/2503.02865v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.02863v1","updated":"2025-03-04T18:40:49Z","published":"2025-03-04T18:40:49Z","title":"Calibrating LLM Confidence with Semantic Steering: A Multi-Prompt\n  Aggregation Framework","summary":"  Large Language Models (LLMs) often exhibit misaligned confidence scores,\nusually overestimating the reliability of their predictions. While verbalized\nconfidence in Large Language Models (LLMs) has gained attention, prior work\nremains divided on whether confidence scores can be systematically steered\nthrough prompting. Recent studies even argue that such prompt-induced\nconfidence shifts are negligible, suggesting LLMs' confidence calibration is\nrigid to linguistic interventions. Contrary to these claims, we first\nrigorously confirm the existence of directional confidence shifts by probing\nthree models (including GPT3.5, LLAMA3-70b, GPT4) across 7 benchmarks,\ndemonstrating that explicit instructions can inflate or deflate confidence\nscores in a regulated manner. Based on this observation, we propose a novel\nframework containing three components: confidence steering, steered confidence\naggregation and steered answers selection, named SteeringConf. Our method,\nSteeringConf, leverages a confidence manipulation mechanism to steer the\nconfidence scores of LLMs in several desired directions, followed by a\nsummarization module that aggregates the steered confidence scores to produce a\nfinal prediction. We evaluate our method on 7 benchmarks and it consistently\noutperforms the baselines in terms of calibration metrics in task of confidence\ncalibration and failure detection.\n","authors":["Ziang Zhou","Tianyuan Jin","Jieming Shi","Qing Li"],"pdf_url":"https://arxiv.org/pdf/2503.02863v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.02854v1","updated":"2025-03-04T18:31:02Z","published":"2025-03-04T18:31:02Z","title":"(How) Do Language Models Track State?","summary":"  Transformer language models (LMs) exhibit behaviors -- from storytelling to\ncode generation -- that appear to require tracking the unobserved state of an\nevolving world. How do they do so? We study state tracking in LMs trained or\nfine-tuned to compose permutations (i.e., to compute the order of a set of\nobjects after a sequence of swaps). Despite the simple algebraic structure of\nthis problem, many other tasks (e.g., simulation of finite automata and\nevaluation of boolean expressions) can be reduced to permutation composition,\nmaking it a natural model for state tracking in general. We show that LMs\nconsistently learn one of two state tracking mechanisms for this task. The\nfirst closely resembles the \"associative scan\" construction used in recent\ntheoretical work by Liu et al. (2023) and Merrill et al. (2024). The second\nuses an easy-to-compute feature (permutation parity) to partially prune the\nspace of outputs, then refines this with an associative scan. The two\nmechanisms exhibit markedly different robustness properties, and we show how to\nsteer LMs toward one or the other with intermediate training tasks that\nencourage or suppress the heuristics. Our results demonstrate that transformer\nLMs, whether pretrained or fine-tuned, can learn to implement efficient and\ninterpretable state tracking mechanisms, and the emergence of these mechanisms\ncan be predicted and controlled.\n","authors":["Belinda Z. Li","Zifan Carl Guo","Jacob Andreas"],"pdf_url":"https://arxiv.org/pdf/2503.02854v1.pdf","comment":"21 pages, 17 figures, 1 table"},{"id":"http://arxiv.org/abs/2503.02851v1","updated":"2025-03-04T18:27:00Z","published":"2025-03-04T18:27:00Z","title":"Shakespearean Sparks: The Dance of Hallucination and Creativity in LLMs'\n  Decoding Layers","summary":"  Large language models (LLMs) are known to hallucinate, a phenomenon often\nlinked to creativity. While previous research has primarily explored this\nconnection through theoretical or qualitative lenses, our work takes a\nquantitative approach to systematically examine the relationship between\nhallucination and creativity in LLMs. Given the complex nature of creativity,\nwe propose a narrow definition tailored to LLMs and introduce an evaluation\nframework, HCL, which quantifies Hallucination and Creativity across different\nLayers of LLMs during decoding. Our empirical analysis reveals a tradeoff\nbetween hallucination and creativity that is consistent across layer depth,\nmodel type, and model size. Notably, across different model architectures, we\nidentify a specific layer at each model size that optimally balances this\ntradeoff. Additionally, the optimal layer tends to appear in the early layers\nof larger models, and the confidence of the model is also significantly higher\nat this layer. These findings provide a quantitative perspective that offers\nnew insights into the interplay between LLM creativity and hallucination. The\ncode and data for our experiments are available at\nhttps://github.com/ZicongHe2002/HCL-Spark.\n","authors":["Zicong He","Boxuan Zhang","Lu Cheng"],"pdf_url":"https://arxiv.org/pdf/2503.02851v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.02846v1","updated":"2025-03-04T18:20:24Z","published":"2025-03-04T18:20:24Z","title":"Mask-DPO: Generalizable Fine-grained Factuality Alignment of LLMs","summary":"  Large language models (LLMs) exhibit hallucinations (i.e., unfaithful or\nnonsensical information) when serving as AI assistants in various domains.\nSince hallucinations always come with truthful content in the LLM responses,\nprevious factuality alignment methods that conduct response-level preference\nlearning inevitably introduced noises during training. Therefore, this paper\nproposes a fine-grained factuality alignment method based on Direct Preference\nOptimization (DPO), called Mask-DPO. Incorporating sentence-level factuality as\nmask signals, Mask-DPO only learns from factually correct sentences in the\npreferred samples and prevents the penalty on factual contents in the not\npreferred samples, which resolves the ambiguity in the preference learning.\nExtensive experimental results demonstrate that Mask-DPO can significantly\nimprove the factuality of LLMs responses to questions from both in-domain and\nout-of-domain datasets, although these questions and their corresponding topics\nare unseen during training. Only trained on the ANAH train set, the score of\nLlama3.1-8B-Instruct on the ANAH test set is improved from 49.19% to 77.53%,\neven surpassing the score of Llama3.1-70B-Instruct (53.44%), while its\nFactScore on the out-of-domain Biography dataset is also improved from 30.29%\nto 39.39%. We further study the generalization property of Mask-DPO using\ndifferent training sample scaling strategies and find that scaling the number\nof topics in the dataset is more effective than the number of questions. We\nprovide a hypothesis of what factual alignment is doing with LLMs, on the\nimplication of this phenomenon, and conduct proof-of-concept experiments to\nverify it. We hope the method and the findings pave the way for future research\non scaling factuality alignment.\n","authors":["Yuzhe Gu","Wenwei Zhang","Chengqi Lyu","Dahua Lin","Kai Chen"],"pdf_url":"https://arxiv.org/pdf/2503.02846v1.pdf","comment":"Accepted by ICLR 2025. Code is available at\n  https://github.com/open-compass/ANAH"},{"id":"http://arxiv.org/abs/2412.16172v2","updated":"2025-03-04T18:15:36Z","published":"2024-12-07T00:15:24Z","title":"LABIIUM: AI-Enhanced Zero-configuration Measurement Automation System","summary":"  The complexity of laboratory environments requires solutions that simplify\ninstrument interaction and enhance measurement automation. Traditional tools\noften require configuration, software, and programming skills, creating\nbarriers to productivity. Previous approaches, including dedicated software\nsuites and custom scripts, frequently fall short in providing user-friendly\nsolutions that align with programming practices. We present LABIIUM, an\nAI-enhanced, zero-configuration measurement automation system designed to\nstreamline experimental workflows and improve user productivity. LABIIUM\nintegrates an AI assistant powered by Large Language Models (LLMs) to generate\ncode. LABIIUM's Lab-Automation-Measurement Bridges (LAMBs) enable seamless\ninstrument connectivity using standard tools such as VSCode and Python,\neliminating setup overhead. To demonstrate its capabilities, we conducted\nexperiments involving the measurement of the parametric transfer curve of a\nsimple two-transistor inverting amplifier with a current source load. The AI\nassistant was evaluated using different prompt scenarios and compared with\nmultiple models, including Claude Sonnet 3.5, Gemini Pro 1.5, and GPT-4o. An\nexpert solution implementing the Gradient-Weighted Adaptive Stochastic Sampling\n(GWASS) method was used as a baseline. The solutions generated by the AI\nassistant were compared with the expert solution and a uniform linear sweep\nbaseline with 10,000 points. The graph results show that the LLMs were able to\nsuccessfully complete the most basic uniform sweep, but LLMs were unable to\ndevelop adaptive sweeping algorithms to compete with GWASS. The evaluation\nunderscores LABIIUM's ability to enhance laboratory productivity and support\ndigital transformation in research and industry, and emphasizes the future work\nrequired to improve LLM performance in Electronic Measurement Science Tasks.\n","authors":["Emmanuel A. Olowe","Danial Chitnis"],"pdf_url":"https://arxiv.org/pdf/2412.16172v2.pdf","comment":"accepted for IEEE I2MTC 2025"},{"id":"http://arxiv.org/abs/2410.01335v2","updated":"2025-03-04T18:15:16Z","published":"2024-10-02T08:53:07Z","title":"Layer Swapping for Zero-Shot Cross-Lingual Transfer in Large Language\n  Models","summary":"  Model merging, such as model souping, is the practice of combining different\nmodels with the same architecture together without further training. In this\nwork, we present a model merging methodology that addresses the difficulty of\nfine-tuning Large Language Models (LLMs) for target tasks in non-English\nlanguages, where task-specific data is often unavailable. We focus on\nmathematical reasoning and without in-language math data, facilitate\ncross-lingual transfer by composing language and math capabilities. Starting\nfrom the same pretrained model, we fine-tune separate \"experts\" on math\ninstruction data in English and on generic instruction data in the target\nlanguage. We then replace the top and bottom transformer layers of the math\nexpert directly with layers from the language expert, which consequently\nenhances math performance in the target language. The resulting merged models\noutperform the individual experts and other merging methods on the math\nbenchmark, MGSM, by 10% across four major languages where math instruction data\nis scarce. In addition, this layer swapping is simple, inexpensive, and\nintuitive, as it is based on an interpretative analysis of the most important\nparameter changes during the fine-tuning of each expert. The ability to\nsuccessfully re-compose LLMs for cross-lingual transfer in this manner opens up\nfuture possibilities to combine model expertise, create modular solutions, and\ntransfer reasoning capabilities across languages all post hoc.\n","authors":["Lucas Bandarkar","Benjamin Muller","Pritish Yuvraj","Rui Hou","Nayan Singhal","Hongjiang Lv","Bing Liu"],"pdf_url":"https://arxiv.org/pdf/2410.01335v2.pdf","comment":"ICLR 2025, Spotlight Paper, In The Thirteenth International\n  Conference on Learning Representations, 2025"},{"id":"http://arxiv.org/abs/2406.05516v3","updated":"2025-03-04T18:07:34Z","published":"2024-06-08T16:35:31Z","title":"Verbalized Probabilistic Graphical Modeling","summary":"  Human cognition excels at transcending sensory input and forming latent\nrepresentations that structure our understanding of the world. Although Large\nLanguage Models (LLMs) can produce chain-of-thought reasoning, they lack a\nprincipled framework to capture latent structures and model uncertainty,\nespecially in compositional reasoning tasks. We propose Verbalized\nProbabilistic Graphical Modeling (vPGM), a Bayesian prompting framework that\nguides LLMs to simulate key principles of Probabilistic Graphical Models (PGMs)\nin natural language. Unlike many traditional probabilistic methods requiring\nsubstantial domain expertise or specialized training, vPGM bypasses\nexpert-driven model design, making it well-suited for scenarios with limited\nassumptions or scarce data. We evaluated our model on several compositional\nreasoning tasks, both close-ended and open-ended. Our results indicate that the\nmodel effectively enhances confidence calibration and text generation quality.\n","authors":["Hengguan Huang","Xing Shen","Songtao Wang","Lingfa Meng","Dianbo Liu","Hao Wang","Samir Bhatt"],"pdf_url":"https://arxiv.org/pdf/2406.05516v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.01773v2","updated":"2025-03-04T18:01:19Z","published":"2025-03-03T17:57:03Z","title":"Why Is Spatial Reasoning Hard for VLMs? An Attention Mechanism\n  Perspective on Focus Areas","summary":"  Large Vision Language Models (VLMs) have long struggled with spatial\nreasoning tasks. Surprisingly, even simple spatial reasoning tasks, such as\nrecognizing \"under\" or \"behind\" relationships between only two objects, pose\nsignificant challenges for current VLMs. In this work, we study the spatial\nreasoning challenge from the lens of mechanistic interpretability, diving into\nthe model's internal states to examine the interactions between image and text\ntokens. By tracing attention distribution over the image through out\nintermediate layers, we observe that successful spatial reasoning correlates\nstrongly with the model's ability to align its attention distribution with\nactual object locations, particularly differing between familiar and unfamiliar\nspatial relationships. Motivated by these findings, we propose ADAPTVIS based\non inference-time confidence scores to sharpen the attention on highly relevant\nregions when confident, while smoothing and broadening the attention window to\nconsider a wider context when confidence is lower. This training-free decoding\nmethod shows significant improvement (e.g., up to a 50 absolute point\nimprovement) on spatial reasoning benchmarks such as WhatsUp and VSR with\nnegligible cost. We make code and data publicly available for research purposes\nat https://github.com/shiqichen17/AdaptVis.\n","authors":["Shiqi Chen","Tongyao Zhu","Ruochen Zhou","Jinghan Zhang","Siyang Gao","Juan Carlos Niebles","Mor Geva","Junxian He","Jiajun Wu","Manling Li"],"pdf_url":"https://arxiv.org/pdf/2503.01773v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.02832v1","updated":"2025-03-04T17:57:09Z","published":"2025-03-04T17:57:09Z","title":"AlignDistil: Token-Level Language Model Alignment as Adaptive Policy\n  Distillation","summary":"  In modern large language models (LLMs), LLM alignment is of crucial\nimportance and is typically achieved through methods such as reinforcement\nlearning from human feedback (RLHF) and direct preference optimization (DPO).\nHowever, in most existing methods for LLM alignment, all tokens in the response\nare optimized using a sparse, response-level reward or preference annotation.\nThe ignorance of token-level rewards may erroneously punish high-quality tokens\nor encourage low-quality tokens, resulting in suboptimal performance and slow\nconvergence speed. To address this issue, we propose AlignDistil, an\nRLHF-equivalent distillation method for token-level reward optimization.\nSpecifically, we introduce the reward learned by DPO into the RLHF objective\nand theoretically prove the equivalence between this objective and a\ntoken-level distillation process, where the teacher distribution linearly\ncombines the logits from the DPO model and a reference model. On this basis, we\nfurther bridge the accuracy gap between the reward from the DPO model and the\npure reward model, by building a contrastive DPO reward with a normal and a\nreverse DPO model. Moreover, to avoid under- and over-optimization on different\ntokens, we design a token adaptive logit extrapolation mechanism to construct\nan appropriate teacher distribution for each token. Experimental results\ndemonstrate the superiority of our AlignDistil over existing methods and\nshowcase fast convergence due to its token-level distributional reward\noptimization.\n","authors":["Songming Zhang","Xue Zhang","Tong Zhang","Bojie Hu","Yufeng Chen","Jinan Xu"],"pdf_url":"https://arxiv.org/pdf/2503.02832v1.pdf","comment":"15 pages, 2 figures"},{"id":"http://arxiv.org/abs/2503.02812v1","updated":"2025-03-04T17:37:49Z","published":"2025-03-04T17:37:49Z","title":"Q-Filters: Leveraging QK Geometry for Efficient KV Cache Compression","summary":"  Autoregressive language models rely on a Key-Value (KV) Cache, which avoids\nre-computing past hidden states during generation, making it faster. As model\nsizes and context lengths grow, the KV Cache becomes a significant memory\nbottleneck, which calls for compression methods that limit its size during\ngeneration. In this paper, we discover surprising properties of Query (Q) and\nKey (K) vectors that allow us to efficiently approximate attention scores\nwithout computing the attention maps. We propose Q-Filters, a training-free KV\nCache compression method that filters out less crucial Key-Value pairs based on\na single context-agnostic projection. Contrarily to many alternatives,\nQ-Filters is compatible with FlashAttention, as it does not require direct\naccess to attention weights. Experimental results in long-context settings\ndemonstrate that Q-Filters is competitive with attention-based compression\nmethods such as SnapKV in retrieval tasks while consistently outperforming\nefficient compression schemes such as Streaming-LLM in generation setups.\nNotably, Q-Filters achieves a 99% accuracy in the needle-in-a-haystack task\nwith a x32 compression level while reducing the generation perplexity drop by\nup to 65% in text generation compared to Streaming-LLM.\n","authors":["Nathan Godey","Alessio Devoto","Yu Zhao","Simone Scardapane","Pasquale Minervini","ric de la Clergerie","Benot Sagot"],"pdf_url":"https://arxiv.org/pdf/2503.02812v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2502.21239v2","updated":"2025-03-04T17:31:25Z","published":"2025-02-28T17:09:08Z","title":"Semantic Volume: Quantifying and Detecting both External and Internal\n  Uncertainty in LLMs","summary":"  Large language models (LLMs) have demonstrated remarkable performance across\ndiverse tasks by encoding vast amounts of factual knowledge. However, they are\nstill prone to hallucinations, generating incorrect or misleading information,\noften accompanied by high uncertainty. Existing methods for hallucination\ndetection primarily focus on quantifying internal uncertainty, which arises\nfrom missing or conflicting knowledge within the model. However, hallucinations\ncan also stem from external uncertainty, where ambiguous user queries lead to\nmultiple possible interpretations. In this work, we introduce Semantic Volume,\na novel mathematical measure for quantifying both external and internal\nuncertainty in LLMs. Our approach perturbs queries and responses, embeds them\nin a semantic space, and computes the determinant of the Gram matrix of the\nembedding vectors, capturing their dispersion as a measure of uncertainty. Our\nframework provides a generalizable and unsupervised uncertainty detection\nmethod without requiring white-box access to LLMs. We conduct extensive\nexperiments on both external and internal uncertainty detection, demonstrating\nthat our Semantic Volume method consistently outperforms existing baselines in\nboth tasks. Additionally, we provide theoretical insights linking our measure\nto differential entropy, unifying and extending previous sampling-based\nuncertainty measures such as the semantic entropy. Semantic Volume is shown to\nbe a robust and interpretable approach to improving the reliability of LLMs by\nsystematically detecting uncertainty in both user queries and model responses.\n","authors":["Xiaomin Li","Zhou Yu","Ziji Zhang","Yingying Zhuang","Swair Shah","Anurag Beniwal"],"pdf_url":"https://arxiv.org/pdf/2502.21239v2.pdf","comment":"This paper needs approval from Amazon for open resource release"},{"id":"http://arxiv.org/abs/2502.16600v3","updated":"2025-03-04T17:23:23Z","published":"2025-02-23T15:00:53Z","title":"Revealing the Pragmatic Dilemma for Moral Reasoning Acquisition in\n  Language Models","summary":"  Ensuring that Large Language Models (LLMs) return just responses which adhere\nto societal values is crucial for their broader application. Prior research has\nshown that LLMs often fail to perform satisfactorily on tasks requiring moral\ncognizance, such as ethics-based judgments. While current approaches have\nfocused on fine-tuning LLMs with curated datasets to improve their capabilities\non such tasks, choosing the optimal learning paradigm to enhance the ethical\nresponses of LLMs remains an open research debate. In this work, we aim to\naddress this fundamental question: can current learning paradigms enable LLMs\nto acquire sufficient moral reasoning capabilities? Drawing from distributional\nsemantics theory and the pragmatic nature of moral discourse, our analysis\nindicates that performance improvements follow a mechanism similar to that of\nsemantic-level tasks, and therefore remain affected by the pragmatic nature of\nmorals latent in discourse, a phenomenon we name the pragmatic dilemma. We\nconclude that this pragmatic dilemma imposes significant limitations on the\ngeneralization ability of current learning paradigms, making it the primary\nbottleneck for moral reasoning acquisition in LLMs.\n","authors":["Guangliang Liu","Lei Jiang","Xitong Zhang","Kristen Marie Johnson"],"pdf_url":"https://arxiv.org/pdf/2502.16600v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.01711v2","updated":"2025-03-04T17:02:27Z","published":"2025-03-03T16:24:36Z","title":"MAPS: Motivation-Aware Personalized Search via LLM-Driven Consultation\n  Alignment","summary":"  Personalized product search aims to retrieve and rank items that match users'\npreferences and search intent. Despite their effectiveness, existing approaches\ntypically assume that users' query fully captures their real motivation.\nHowever, our analysis of a real-world e-commerce platform reveals that users\noften engage in relevant consultations before searching, indicating they refine\nintents through consultations based on motivation and need. The implied\nmotivation in consultations is a key enhancing factor for personalized search.\nThis unexplored area comes with new challenges including aligning contextual\nmotivations with concise queries, bridging the category-text gap, and filtering\nnoise within sequence history. To address these, we propose a Motivation-Aware\nPersonalized Search (MAPS) method. It embeds queries and consultations into a\nunified semantic space via LLMs, utilizes a Mixture of Attention Experts (MoAE)\nto prioritize critical semantics, and introduces dual alignment: (1)\ncontrastive learning aligns consultations, reviews, and product features; (2)\nbidirectional attention integrates motivation-aware embeddings with user\npreferences. Extensive experiments on real and synthetic data show MAPS\noutperforms existing methods in both retrieval and ranking tasks.\n","authors":["Weicong Qin","Yi Xu","Weijie Yu","Chenglei Shen","Ming He","Jianping Fan","Xiao Zhang","Jun Xu"],"pdf_url":"https://arxiv.org/pdf/2503.01711v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.02783v1","updated":"2025-03-04T16:56:34Z","published":"2025-03-04T16:56:34Z","title":"IterPref: Focal Preference Learning for Code Generation via Iterative\n  Debugging","summary":"  Preference learning enhances Code LLMs beyond supervised fine-tuning by\nleveraging relative quality comparisons. Existing methods construct preference\npairs from\n  candidates based on test case success, treating the higher pass rate sample\nas positive and the lower as negative. However, this approach does not pinpoint\nspecific errors in the code, which prevents the model from learning more\ninformative error correction patterns, as aligning failing code as a whole\nlacks the granularity needed to capture meaningful error-resolution\nrelationships. To address these issues, we propose IterPref, a new preference\nalignment framework that mimics human iterative debugging to refine Code LLMs.\nIterPref explicitly locates error regions and aligns the corresponding tokens\nvia a tailored DPO algorithm. To generate informative pairs, we introduce the\nCodeFlow dataset, where samples are iteratively refined until passing tests,\nwith modifications capturing error corrections. Extensive experiments show that\na diverse suite of Code LLMs equipped with IterPref achieves significant\nperformance gains in code generation and improves on challenging tasks like\nBigCodeBench. In-depth analysis reveals that IterPref yields fewer errors. Our\ncode and data will be made publicaly available.\n","authors":["Jie Wu","Haoling Li","Xin Zhang","Jianwen Luo","Yangyu Huang","Ruihang Chu","Yujiu Yang","Scarlett Li"],"pdf_url":"https://arxiv.org/pdf/2503.02783v1.pdf","comment":"The code and data will be released soon"},{"id":"http://arxiv.org/abs/2503.02776v1","updated":"2025-03-04T16:49:37Z","published":"2025-03-04T16:49:37Z","title":"Implicit Bias in LLMs: A Survey","summary":"  Due to the implement of guardrails by developers, Large language models\n(LLMs) have demonstrated exceptional performance in explicit bias tests.\nHowever, bias in LLMs may occur not only explicitly, but also implicitly, much\nlike humans who consciously strive for impartiality yet still harbor implicit\nbias. The unconscious and automatic nature of implicit bias makes it\nparticularly challenging to study. This paper provides a comprehensive review\nof the existing literature on implicit bias in LLMs. We begin by introducing\nkey concepts, theories and methods related to implicit bias in psychology,\nextending them from humans to LLMs. Drawing on the Implicit Association Test\n(IAT) and other psychological frameworks, we categorize detection methods into\nthree primary approaches: word association, task-oriented text generation and\ndecision-making. We divide our taxonomy of evaluation metrics for implicit bias\ninto two categories: single-value-based metrics and comparison-value-based\nmetrics. We classify datasets into two types: sentences with masked tokens and\ncomplete sentences, incorporating datasets from various domains to reflect the\nbroad application of LLMs. Although research on mitigating implicit bias in\nLLMs is still limited, we summarize existing efforts and offer insights on\nfuture challenges. We aim for this work to serve as a clear guide for\nresearchers and inspire innovative ideas to advance exploration in this task.\n","authors":["Xinru Lin","Luyang Li"],"pdf_url":"https://arxiv.org/pdf/2503.02776v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2502.17403v2","updated":"2025-03-04T16:36:52Z","published":"2025-02-24T18:30:36Z","title":"Large Language Models are Powerful EHR Encoders","summary":"  Electronic Health Records (EHRs) offer rich potential for clinical\nprediction, yet their inherent complexity and heterogeneity pose significant\nchallenges for traditional machine learning approaches. Domain-specific EHR\nfoundation models trained on large collections of unlabeled EHR data have\ndemonstrated promising improvements in predictive accuracy and generalization;\nhowever, their training is constrained by limited access to diverse,\nhigh-quality datasets and inconsistencies in coding standards and healthcare\npractices. In this study, we explore the possibility of using general-purpose\nLarge Language Models (LLMs) based embedding methods as EHR encoders. By\nserializing patient records into structured Markdown text, transforming codes\ninto human-readable descriptors, we leverage the extensive generalization\ncapabilities of LLMs pretrained on vast public corpora, thereby bypassing the\nneed for proprietary medical datasets. We systematically evaluate two\nstate-of-the-art LLM-embedding models, GTE-Qwen2-7B-Instruct and\nLLM2Vec-Llama3.1-8B-Instruct, across 15 diverse clinical prediction tasks from\nthe EHRSHOT benchmark, comparing their performance to an EHRspecific foundation\nmodel, CLIMBR-T-Base, and traditional machine learning baselines. Our results\ndemonstrate that LLM-based embeddings frequently match or exceed the\nperformance of specialized models, even in few-shot settings, and that their\neffectiveness scales with the size of the underlying LLM and the available\ncontext window. Overall, our findings demonstrate that repurposing LLMs for EHR\nencoding offers a scalable and effective approach for clinical prediction,\ncapable of overcoming the limitations of traditional EHR modeling and\nfacilitating more interoperable and generalizable healthcare applications.\n","authors":["Stefan Hegselmann","Georg von Arnim","Tillmann Rheude","Noel Kronenberg","David Sontag","Gerhard Hindricks","Roland Eils","Benjamin Wild"],"pdf_url":"https://arxiv.org/pdf/2502.17403v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.02769v1","updated":"2025-03-04T16:34:14Z","published":"2025-03-04T16:34:14Z","title":"InSerter: Speech Instruction Following with Unsupervised Interleaved\n  Pre-training","summary":"  Recent advancements in speech large language models (SpeechLLMs) have\nattracted considerable attention. Nonetheless, current methods exhibit\nsuboptimal performance in adhering to speech instructions. Notably, the\nintelligence of models significantly diminishes when processing speech-form\ninput as compared to direct text-form input. Prior work has attempted to\nmitigate this semantic inconsistency between speech and text representations\nthrough techniques such as representation and behavior alignment, which involve\nthe meticulous design of data pairs during the post-training phase. In this\npaper, we introduce a simple and scalable training method called InSerter,\nwhich stands for Interleaved Speech-Text Representation Pre-training. InSerter\nis designed to pre-train large-scale unsupervised speech-text sequences, where\nthe speech is synthesized from randomly selected segments of an extensive text\ncorpus using text-to-speech conversion. Consequently, the model acquires the\nability to generate textual continuations corresponding to the provided speech\nsegments, obviating the need for intensive data design endeavors. To\nsystematically evaluate speech instruction-following capabilities, we introduce\nSpeechInstructBench, the first comprehensive benchmark specifically designed\nfor speech-oriented instruction-following tasks. Our proposed InSerter achieves\nSOTA performance in SpeechInstructBench and demonstrates superior or\ncompetitive results across diverse speech processing tasks.\n","authors":["Dingdong Wang","Jin Xu","Ruihang Chu","Zhifang Guo","Xiong Wang","Jincenzi Wu","Dongchao Yang","Shengpeng Ji","Junyang Lin"],"pdf_url":"https://arxiv.org/pdf/2503.02769v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.02760v1","updated":"2025-03-04T16:22:49Z","published":"2025-03-04T16:22:49Z","title":"From Metaphor to Mechanism: How LLMs Decode Traditional Chinese Medicine\n  Symbolic Language for Modern Clinical Relevance","summary":"  Metaphorical expressions are abundant in Traditional Chinese Medicine (TCM),\nconveying complex disease mechanisms and holistic health concepts through\nculturally rich and often abstract terminology. Bridging these metaphors to\nanatomically driven Western medical (WM) concepts poses significant challenges\nfor both automated language processing and real-world clinical practice. To\naddress this gap, we propose a novel multi-agent and chain-of-thought (CoT)\nframework designed to interpret TCM metaphors accurately and map them to WM\npathophysiology. Specifically, our approach combines domain-specialized agents\n(TCM Expert, WM Expert) with a Coordinator Agent, leveraging stepwise\nchain-of-thought prompts to ensure transparent reasoning and conflict\nresolution. We detail a methodology for building a metaphor-rich TCM dataset,\ndiscuss strategies for effectively integrating multi-agent collaboration and\nCoT reasoning, and articulate the theoretical underpinnings that guide metaphor\ninterpretation across distinct medical paradigms. We present a comprehensive\nsystem design and highlight both the potential benefits and limitations of our\napproach, while leaving placeholders for future experimental validation. Our\nwork aims to support clinical decision-making, cross-system educational\ninitiatives, and integrated healthcare research, ultimately offering a robust\nscaffold for reconciling TCM's symbolic language with the mechanistic focus of\nWestern medicine.\n","authors":["Jiacheng Tang","Nankai Wu","Fan Gao","Chengxiao Dai","Mengyao Zhao","Xinjie Zhao"],"pdf_url":"https://arxiv.org/pdf/2503.02760v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.05821v2","updated":"2025-03-04T16:21:26Z","published":"2024-10-08T08:51:44Z","title":"Towards Zero-Shot, Controllable Dialog Planning with LLMs","summary":"  Recently, Large Language Models (LLMs) have emerged as an alternative to\ntraining task-specific dialog agents, due to their broad reasoning capabilities\nand performance in zero-shot learning scenarios. However, many LLM-based dialog\nsystems fall short in planning towards an overarching dialog goal and therefore\ncannot steer the conversation appropriately. Furthermore, these models struggle\nwith hallucination, making them unsuitable for information access in sensitive\ndomains, such as legal or medical domains, where correctness of information\ngiven to users is critical. The recently introduced task Conversational Tree\nSearch (CTS) proposes the use of dialog graphs to avoid hallucination in\nsensitive domains, however, state-of-the-art agents are Reinforcement Learning\n(RL) based and require long training times, despite excelling at dialog\nstrategy. This paper introduces a novel zero-shot method for controllable CTS\nagents, where LLMs guide the dialog planning through domain graphs by searching\nand pruning relevant graph nodes based on user interaction preferences. We show\nthat these agents significantly outperform state-of-the-art CTS agents\n($p<0.0001$; Barnard Exact test) in simulation. This generalizes to all\navailable CTS domains. Finally, we perform user evaluation to test the agent's\nperformance in the wild, showing that our policy significantly ($p<0.05$;\nBarnard Exact) improves task-success compared to the state-of-the-art RL-based\nCTS agent.\n","authors":["Dirk Vth","Ngoc Thang Vu"],"pdf_url":"https://arxiv.org/pdf/2410.05821v2.pdf","comment":"This paper has been accepted for publication at the AAAI 2022\n  Workshop on Planning in the Era of LLMs"},{"id":"http://arxiv.org/abs/2501.18632v2","updated":"2025-03-04T16:20:59Z","published":"2025-01-27T22:07:52Z","title":"Towards Safe AI Clinicians: A Comprehensive Study on Large Language\n  Model Jailbreaking in Healthcare","summary":"  Large language models (LLMs) are increasingly utilized in healthcare\napplications. However, their deployment in clinical practice raises significant\nsafety concerns, including the potential spread of harmful information. This\nstudy systematically assesses the vulnerabilities of seven LLMs to three\nadvanced black-box jailbreaking techniques within medical contexts. To quantify\nthe effectiveness of these techniques, we propose an automated and\ndomain-adapted agentic evaluation pipeline. Experiment results indicate that\nleading commercial and open-source LLMs are highly vulnerable to medical\njailbreaking attacks. To bolster model safety and reliability, we further\ninvestigate the effectiveness of Continual Fine-Tuning (CFT) in defending\nagainst medical adversarial attacks. Our findings underscore the necessity for\nevolving attack methods evaluation, domain-specific safety alignment, and LLM\nsafety-utility balancing. This research offers actionable insights for\nadvancing the safety and reliability of AI clinicians, contributing to ethical\nand effective AI deployment in healthcare.\n","authors":["Hang Zhang","Qian Lou","Yanshan Wang"],"pdf_url":"https://arxiv.org/pdf/2501.18632v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.02756v1","updated":"2025-03-04T16:20:52Z","published":"2025-03-04T16:20:52Z","title":"BatchGEMBA: Token-Efficient Machine Translation Evaluation with Batched\n  Prompting and Prompt Compression","summary":"  Recent advancements in Large Language Model (LLM)-based Natural Language\nGeneration evaluation have largely focused on single-example prompting,\nresulting in significant token overhead and computational inefficiencies. In\nthis work, we introduce BatchGEMBA-MQM, a framework that integrates batched\nprompting with the GEMBA-MQM metric for machine translation evaluation. Our\napproach aggregates multiple translation examples into a single prompt,\nreducing token usage by 2-4 times (depending on the batch size) relative to\nsingle-example prompting. Furthermore, we propose a batching-aware prompt\ncompression model that achieves an additional token reduction of 13-15% on\naverage while also showing ability to help mitigate batching-induced quality\ndegradation. Evaluations across several LLMs (GPT-4o, GPT-4o-mini, Mistral\nSmall, Phi4, and CommandR7B) and varying batch sizes reveal that while batching\ngenerally negatively affects quality (but sometimes not substantially), prompt\ncompression does not degrade further, and in some cases, recovers quality loss.\nFor instance, GPT-4o retains over 90% of its baseline performance at a batch\nsize of 4 when compression is applied, compared to a 44.6% drop without\ncompression. We plan to release our code and trained models at\nhttps://github.com/NL2G/batchgemba to support future research in this domain.\n","authors":["Daniil Larionov","Steffen Eger"],"pdf_url":"https://arxiv.org/pdf/2503.02756v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.02741v1","updated":"2025-03-04T16:05:13Z","published":"2025-03-04T16:05:13Z","title":"Seeded Poisson Factorization: Leveraging domain knowledge to fit topic\n  models","summary":"  Topic models are widely used for discovering latent thematic structures in\nlarge text corpora, yet traditional unsupervised methods often struggle to\nalign with predefined conceptual domains. This paper introduces Seeded Poisson\nFactorization (SPF), a novel approach that extends the Poisson Factorization\nframework by incorporating domain knowledge through seed words. SPF enables a\nmore interpretable and structured topic discovery by modifying the prior\ndistribution of topic-specific term intensities, assigning higher initial rates\nto predefined seed words. The model is estimated using variational inference\nwith stochastic gradient optimization, ensuring scalability to large datasets.\n  We apply SPF to an Amazon customer feedback dataset, leveraging predefined\nproduct categories as guiding structures. Our evaluation demonstrates that SPF\nachieves superior classification performance compared to alternative guided\ntopic models, particularly in terms of computational efficiency and predictive\nperformance. Furthermore, robustness checks highlight SPF's ability to\nadaptively balance domain knowledge and data-driven topic discovery, even in\ncases of imperfect seed word selection. These results establish SPF as a\npowerful and scalable alternative for integrating expert knowledge into topic\nmodeling, enhancing both interpretability and efficiency in real-world\napplications.\n","authors":["Bernd Prostmaier","Jan Vvra","Bettina Grn","Paul Hofmarcher"],"pdf_url":"https://arxiv.org/pdf/2503.02741v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.02737v1","updated":"2025-03-04T15:56:43Z","published":"2025-03-04T15:56:43Z","title":"Large Language Models for Multilingual Previously Fact-Checked Claim\n  Detection","summary":"  In our era of widespread false information, human fact-checkers often face\nthe challenge of duplicating efforts when verifying claims that may have\nalready been addressed in other countries or languages. As false information\ntranscends linguistic boundaries, the ability to automatically detect\npreviously fact-checked claims across languages has become an increasingly\nimportant task. This paper presents the first comprehensive evaluation of large\nlanguage models (LLMs) for multilingual previously fact-checked claim\ndetection. We assess seven LLMs across 20 languages in both monolingual and\ncross-lingual settings. Our results show that while LLMs perform well for\nhigh-resource languages, they struggle with low-resource languages. Moreover,\ntranslating original texts into English proved to be beneficial for\nlow-resource languages. These findings highlight the potential of LLMs for\nmultilingual previously fact-checked claim detection and provide a foundation\nfor further research on this promising application of LLMs.\n","authors":["Ivan Vykopal","Mat Pikuliak","Simon Ostermann","Tatiana Anikina","Michal Gregor","Marin imko"],"pdf_url":"https://arxiv.org/pdf/2503.02737v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.01625v2","updated":"2025-03-04T15:33:16Z","published":"2025-03-03T15:00:36Z","title":"Annotating and Inferring Compositional Structures in Numeral Systems\n  Across Languages","summary":"  Numeral systems across the world's languages vary in fascinating ways, both\nregarding their synchronic structure and the diachronic processes that\ndetermined how they evolved in their current shape. For a proper comparison of\nnumeral systems across different languages, however, it is important to code\nthem in a standardized form that allows for the comparison of basic properties.\nHere, we present a simple but effective coding scheme for numeral annotation,\nalong with a workflow that helps to code numeral systems in a computer-assisted\nmanner, providing sample data for numerals from 1 to 40 in 25 typologically\ndiverse languages. We perform a thorough analysis of the sample, focusing on\nthe systematic comparison between the underlying and the surface morphological\nstructure. We further experiment with automated models for morpheme\nsegmentation, where we find allomorphy as the major reason for segmentation\nerrors. Finally, we show that subword tokenization algorithms are not viable\nfor discovering morphemes in low-resource scenarios.\n","authors":["Arne Rubehn","Christoph Rzymski","Luca Ciucci","Kellen Parker van Dam","Albta Kuerov","Katja Bocklage","David Snee","Abishek Stephen","Johann-Mattis List"],"pdf_url":"https://arxiv.org/pdf/2503.01625v2.pdf","comment":"Submitted to the 7th Workshop on Research in Computational Linguistic\n  Typology and Multilingual NLP (SIGTYP)"},{"id":"http://arxiv.org/abs/2503.02718v1","updated":"2025-03-04T15:32:59Z","published":"2025-03-04T15:32:59Z","title":"Evaluating Knowledge Generation and Self-Refinement Strategies for\n  LLM-based Column Type Annotation","summary":"  Understanding the semantics of columns in relational tables is an important\npre-processing step for indexing data lakes in order to provide rich data\nsearch. An approach to establishing such understanding is column type\nannotation (CTA) where the goal is to annotate table columns with terms from a\ngiven vocabulary. This paper experimentally compares different knowledge\ngeneration and self-refinement strategies for LLM-based column type annotation.\nThe strategies include using LLMs to generate term definitions, error-based\nrefinement of term definitions, self-correction, and fine-tuning using examples\nand term definitions. We evaluate these strategies along two dimensions:\neffectiveness measured as F1 performance and efficiency measured in terms of\ntoken usage and cost. Our experiments show that the best performing strategy\ndepends on the model/dataset combination. We find that using training data to\ngenerate label definitions outperforms using the same data as demonstrations\nfor in-context learning for two out of three datasets using OpenAI models. The\nexperiments further show that using the LLMs to refine label definitions brings\nan average increase of 3.9% F1 in 10 out of 12 setups compared to the\nperformance of the non-refined definitions. Combining fine-tuned models with\nself-refined term definitions results in the overall highest performance,\noutperforming zero-shot prompting fine-tuned models by at least 3% in F1 score.\nThe costs analysis shows that while reaching similar F1 score, self-refinement\nvia prompting is more cost efficient for use cases requiring smaller amounts of\ntables to be annotated while fine-tuning is more efficient for large amounts of\ntables.\n","authors":["Keti Korini","Christian Bizer"],"pdf_url":"https://arxiv.org/pdf/2503.02718v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.09230v3","updated":"2025-03-04T15:26:30Z","published":"2024-10-11T20:06:21Z","title":"Improving Semantic Understanding in Speech Language Models via\n  Brain-tuning","summary":"  Speech language models align with human brain responses to natural language\nto an impressive degree. However, current models rely heavily on low-level\nspeech features, indicating they lack brain-relevant semantics which limits\ntheir utility as model organisms of semantic processing in the brain. In this\nwork, we address this limitation by inducing brain-relevant bias directly into\nthe models via fine-tuning with fMRI recordings of people listening to natural\nstories, a process we name brain-tuning. After testing it on 3 different\npretrained model families, we show that brain-tuning not only improves overall\nalignment with new brain recordings in semantic language regions, but also\nreduces the reliance on low-level speech features for this alignment.\nExcitingly, we further show that brain-tuning leads to 1) consistent\nimprovements in performance on a range of downstream tasks and 2) a\nrepresentational space with increased semantic preference. Our results provide\nconverging evidence, for the first time, that incorporating brain signals into\nthe training of language models improves the models' semantic understanding.\n","authors":["Omer Moussa","Dietrich Klakow","Mariya Toneva"],"pdf_url":"https://arxiv.org/pdf/2410.09230v3.pdf","comment":"Published as a conference paper at ICLR 2025"},{"id":"http://arxiv.org/abs/2503.02707v1","updated":"2025-03-04T15:21:22Z","published":"2025-03-04T15:21:22Z","title":"Multilingualism, Transnationality, and K-pop in the Online\n  #StopAsianHate Movement","summary":"  The #StopAsianHate (SAH) movement is a broad social movement against violence\ntargeting Asians and Asian Americans, beginning in 2021 in response to racial\ndiscrimination related to COVID-19 and sparking worldwide conversation about\nanti-Asian hate. However, research on the online SAH movement has focused on\nEnglish-speaking participants so the spread of the movement outside of the\nUnited States is largely unknown. In addition, there have been no long-term\nstudies of SAH so the extent to which it has been successfully sustained over\ntime is not well understood. We present an analysis of 6.5 million\n\"#StopAsianHate\" tweets from 2.2 million users all over the globe and spanning\n60 different languages, constituting the first study of the non-English and\ntransnational component of the online SAH movement. Using a combination of\ntopic modeling, user modeling, and hand annotation, we identify and\ncharacterize the dominant discussions and users participating in the movement\nand draw comparisons of English versus non-English topics and users. We\ndiscover clear differences in events driving topics, where spikes in English\ntweets are driven by violent crimes in the US but spikes in non-English tweets\nare driven by transnational incidents of anti-Asian sentiment towards symbolic\nrepresentatives of Asian nations. We also find that global K-pop fans were\nquick to adopt the SAH movement and, in fact, sustained it for longer than any\nother user group. Our work contributes to understanding the transnationality\nand evolution of the SAH movement, and more generally to exploring upward scale\nshift and public attention in large-scale multilingual online activism.\n","authors":["Tessa Masis","Zhangqi Duan","Weiai Wayne Xu","Ethan Zuckerman","Jane Yeahin Pyo","Brendan O'Connor"],"pdf_url":"https://arxiv.org/pdf/2503.02707v1.pdf","comment":"WebSci'25"},{"id":"http://arxiv.org/abs/2501.03291v2","updated":"2025-03-04T15:03:06Z","published":"2025-01-06T08:20:04Z","title":"ADePT: Adaptive Decomposed Prompt Tuning for Parameter-Efficient\n  Fine-tuning","summary":"  Prompt Tuning (PT) enables the adaptation of Pre-trained Large Language\nModels (PLMs) to downstream tasks by optimizing a small amount of soft virtual\ntokens, which are prepended to the input token embeddings. Recently, Decomposed\nPrompt Tuning (DePT) has demonstrated superior adaptation capabilities by\ndecomposing the soft prompt into a shorter soft prompt and a pair of low-rank\nmatrices. The product of the pair of low-rank matrices is added to the input\ntoken embeddings to offset them. Additionally, DePT achieves faster inference\ncompared to PT due to the shorter soft prompt. However, in this paper, we find\nthat the position-based token embedding offsets of DePT restrict its ability to\ngeneralize across diverse model inputs, and that the shared embedding offsets\nacross many token embeddings result in sub-optimization. To tackle these\nissues, we introduce Adaptive Decomposed Prompt Tuning (ADePT), which is\ncomposed of a short soft prompt and a shallow token-shared feed-forward neural\nnetwork. ADePT utilizes the token-shared feed-forward neural network to learn\nthe embedding offsets for each token, enabling adaptive embedding offsets that\nvary according to the model input and better optimization of token embedding\noffsets. This enables ADePT to achieve superior adaptation performance without\nrequiring more inference time or additional trainable parameters compared to\nvanilla PT and its variants. In comprehensive experiments across 23 natural\nlanguage processing tasks and 4 typical PLMs of different scales, ADePT\nconsistently surpasses the other leading parameter-efficient fine-tuning\nmethods, and even outperforms the full fine-tuning in certain scenarios. We\nalso provide a theoretical analysis towards ADePT. Code is available at\nhttps://github.com/HungerPWAY/ADePT.\n","authors":["Pengwei Tang","Xiaolin Hu","Yong Liu"],"pdf_url":"https://arxiv.org/pdf/2501.03291v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.02682v1","updated":"2025-03-04T14:54:45Z","published":"2025-03-04T14:54:45Z","title":"MPO: Boosting LLM Agents with Meta Plan Optimization","summary":"  Recent advancements in large language models (LLMs) have enabled LLM-based\nagents to successfully tackle interactive planning tasks. However, despite\ntheir successes, existing approaches often suffer from planning hallucinations\nand require retraining for each new agent. To address these challenges, we\npropose the Meta Plan Optimization (MPO) framework, which enhances agent\nplanning capabilities by directly incorporating explicit guidance. Unlike\nprevious methods that rely on complex knowledge, which either require\nsignificant human effort or lack quality assurance, MPO leverages high-level\ngeneral guidance through meta plans to assist agent planning and enables\ncontinuous optimization of the meta plans based on feedback from the agent's\ntask execution. Our experiments conducted on two representative tasks\ndemonstrate that MPO significantly outperforms existing baselines. Moreover,\nour analysis indicates that MPO provides a plug-and-play solution that enhances\nboth task completion efficiency and generalization capabilities in previous\nunseen scenarios.\n","authors":["Weimin Xiong","Yifan Song","Qingxiu Dong","Bingchan Zhao","Feifan Song","Xun Wang","Sujian Li"],"pdf_url":"https://arxiv.org/pdf/2503.02682v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.02671v1","updated":"2025-03-04T14:43:43Z","published":"2025-03-04T14:43:43Z","title":"Are some books better than others?","summary":"  Scholars, awards committees, and laypeople frequently discuss the merit of\nwritten works. Literary professionals and journalists differ in how much\nperspectivism they concede in their book reviews. Here, we quantify how\nstrongly book reviews are determined by the actual book contents vs.\nidiosyncratic reader tendencies. In our analysis of 624,320 numerical and\ntextual book reviews, we find that the contents of professionally published\nbooks are not predictive of a random reader's reading enjoyment. Online reviews\nof popular fiction and non-fiction books carry up to ten times more information\nabout the reviewer than about the book. For books of a preferred genre, readers\nmight be less likely to give low ratings, but still struggle to converge in\ntheir relative assessments. We find that book evaluations generalize more\nacross experienced review writers than casual readers. When discussing specific\nissues with a book, one review text had poor predictability of issues brought\nup in another review of the same book. We conclude that extreme perspectivism\nis a justifiable position when researching literary quality, bestowing literary\nawards, and designing recommendation systems.\n","authors":["Hannes Rosenbusch","Luke Korthals"],"pdf_url":"https://arxiv.org/pdf/2503.02671v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.02670v1","updated":"2025-03-04T14:41:05Z","published":"2025-03-04T14:41:05Z","title":"Multidimensional Consistency Improves Reasoning in Language Models","summary":"  While Large language models (LLMs) have proved able to address some complex\nreasoning tasks, we also know that they are highly sensitive to input\nvariation, which can lead to different solution paths and final answers. Answer\nconsistency across input variations can thus be taken as a sign of stronger\nconfidence. Leveraging this insight, we introduce a framework, {\\em\nMultidimensional Reasoning Consistency} where, focusing on math problems,\nmodels are systematically pushed to diversify solution paths towards a final\nanswer, thereby testing them for answer consistency across multiple input\nvariations. We induce variations in (i) order of shots in prompt, (ii) problem\nphrasing, and (iii) languages used. Extensive experiments on a large range of\nopen-source state-of-the-art LLMs of various sizes show that reasoning\nconsistency differs by variation dimension, and that by aggregating consistency\nacross dimensions, our framework consistently enhances mathematical reasoning\nperformance on both monolingual dataset GSM8K and multilingual dataset MGSM,\nespecially for smaller models.\n","authors":["Huiyuan Lai","Xiao Zhang","Malvina Nissim"],"pdf_url":"https://arxiv.org/pdf/2503.02670v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.02659v1","updated":"2025-03-04T14:21:08Z","published":"2025-03-04T14:21:08Z","title":"LoRA-Null: Low-Rank Adaptation via Null Space for Large Language Models","summary":"  Low-Rank Adaptation (LoRA) is the leading parameter-efficient fine-tuning\nmethod for Large Language Models (LLMs). However, the fine-tuned LLMs encounter\nthe issue of catastrophic forgetting of the pre-trained world knowledge. To\naddress this issue, inspired by theoretical insights of null space, we propose\nLoRA-Null, i.e., Low-Rank Adaptation via null space, which builds adapters\ninitialized from the null space of the pre-trained knowledge activation.\nConcretely, we randomly collect a few data samples and capture their\nactivations after passing through the LLM layer. We perform Singular Value\nDecomposition on the input activations to obtain their null space. We use the\nprojection of the pre-trained weights onto the null space as the initialization\nfor adapters. Experimental results demonstrate that this initialization\napproach can effectively preserve the original pre-trained world knowledge of\nthe LLMs during fine-tuning. Additionally, if we freeze the values of the\ndown-projection matrices during fine-tuning, it achieves even better\npreservation of the pre-trained world knowledge. LoRA-Null effectively\npreserves pre-trained world knowledge while maintaining strong fine-tuning\nperformance, as validated by extensive experiments on LLaMA series (LLaMA2,\nLLaMA3, LLaMA3.1, and LLaMA3.2) across Code, Math, and Instruction Following\ntasks. We also provide a theoretical guarantee for the capacity of LoRA-Null to\nretain pre-trained knowledge. Code is in\nhttps://github.com/HungerPWAY/LoRA-Null.\n","authors":["Pengwei Tang","Yong Liu","Dongjie Zhang","Xing Wu","Debing Zhang"],"pdf_url":"https://arxiv.org/pdf/2503.02659v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.02656v1","updated":"2025-03-04T14:17:00Z","published":"2025-03-04T14:17:00Z","title":"Adapting Decoder-Based Language Models for Diverse Encoder Downstream\n  Tasks","summary":"  Decoder-based transformers, while revolutionizing language modeling and\nscaling to immense sizes, have not completely overtaken encoder-heavy\narchitectures in natural language processing. Specifically, encoder-only models\nremain dominant in tasks like classification, regression, and ranking. This is\nprimarily due to the inherent structure of decoder-based models, which limits\ntheir direct applicability to these tasks. In this paper, we introduce Gemma\nEncoder, adapting the powerful Gemma decoder model to an encoder architecture,\nthereby unlocking its potential for a wider range of non-generative\napplications. To optimize the adaptation from decoder to encoder, we\nsystematically analyze various pooling strategies, attention mechanisms, and\nhyperparameters (e.g., dropout rate). Furthermore, we benchmark Gemma Encoder\nagainst established approaches on the GLUE benchmarks, and MS MARCO ranking\nbenchmark, demonstrating its effectiveness and versatility.\n","authors":["Paul Suganthan","Fedor Moiseev","Le Yan","Junru Wu","Jianmo Ni","Jay Han","Imed Zitouni","Enrique Alfonseca","Xuanhui Wang","Zhe Dong"],"pdf_url":"https://arxiv.org/pdf/2503.02656v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.02650v1","updated":"2025-03-04T14:14:28Z","published":"2025-03-04T14:14:28Z","title":"The Effectiveness of Large Language Models in Transforming Unstructured\n  Text to Standardized Formats","summary":"  The exponential growth of unstructured text data presents a fundamental\nchallenge in modern data management and information retrieval. While Large\nLanguage Models (LLMs) have shown remarkable capabilities in natural language\nprocessing, their potential to transform unstructured text into standardized,\nstructured formats remains largely unexplored - a capability that could\nrevolutionize data processing workflows across industries. This study breaks\nnew ground by systematically evaluating LLMs' ability to convert unstructured\nrecipe text into the structured Cooklang format. Through comprehensive testing\nof four models (GPT-4o, GPT-4o-mini, Llama3.1:70b, and Llama3.1:8b), an\ninnovative evaluation approach is introduced that combines traditional metrics\n(WER, ROUGE-L, TER) with specialized metrics for semantic element\nidentification. Our experiments reveal that GPT-4o with few-shot prompting\nachieves breakthrough performance (ROUGE-L: 0.9722, WER: 0.0730), demonstrating\nfor the first time that LLMs can reliably transform domain-specific\nunstructured text into structured formats without extensive training. Although\nmodel performance generally scales with size, we uncover surprising potential\nin smaller models like Llama3.1:8b for optimization through targeted\nfine-tuning. These findings open new possibilities for automated structured\ndata generation across various domains, from medical records to technical\ndocumentation, potentially transforming the way organizations process and\nutilize unstructured information.\n","authors":["William Brach","Kristin Kol","Michal Ries"],"pdf_url":"https://arxiv.org/pdf/2503.02650v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2401.15077v3","updated":"2025-03-04T13:58:39Z","published":"2024-01-26T18:59:01Z","title":"EAGLE: Speculative Sampling Requires Rethinking Feature Uncertainty","summary":"  Autoregressive decoding makes the inference of Large Language Models (LLMs)\ntime-consuming. In this paper, we reconsider speculative sampling and derive\ntwo key observations. Firstly, autoregression at the feature\n(second-to-top-layer) level is more straightforward than at the token level.\nSecondly, the inherent uncertainty in feature (second-to-top-layer) level\nautoregression constrains its performance. Based on these insights, we\nintroduce EAGLE (Extrapolation Algorithm for Greater Language-model\nEfficiency), a simple yet highly efficient speculative sampling framework. By\nincorporating a token sequence advanced by one time step, EAGLE effectively\nresolves the uncertainty, enabling precise second-to-top-layer feature\nprediction with minimal overhead. We conducted comprehensive evaluations of\nEAGLE, including all models from the Vicuna and LLaMA2-Chat series, the MoE\nmodel Mixtral 8x7B Instruct, and tasks in dialogue, code generation,\nmathematical reasoning, and instruction following. For LLaMA2-Chat 70B, EAGLE\nachieved a latency speedup ratio of 2.7x-3.5x, doubled throughput, while\nmaintaining the distribution of the generated text.\n","authors":["Yuhui Li","Fangyun Wei","Chao Zhang","Hongyang Zhang"],"pdf_url":"https://arxiv.org/pdf/2401.15077v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.02628v1","updated":"2025-03-04T13:53:43Z","published":"2025-03-04T13:53:43Z","title":"Towards Event Extraction with Massive Types: LLM-based Collaborative\n  Annotation and Partitioning Extraction","summary":"  Developing a general-purpose extraction system that can extract events with\nmassive types is a long-standing target in Event Extraction (EE). In doing so,\nthe challenge comes from two aspects: 1) The absence of an efficient and\neffective annotation method. 2) The absence of a powerful extraction method can\nhandle massive types. For the first challenge, we propose a collaborative\nannotation method based on Large Language Models (LLMs). Through collaboration\namong multiple LLMs, it first refines annotations of trigger words from distant\nsupervision and then carries out argument annotation. Next, a voting phase\nconsolidates the annotation preferences across different LLMs. Finally, we\ncreate the EEMT dataset, the largest EE dataset to date, featuring over 200,000\nsamples, 3,465 event types, and 6,297 role types. For the second challenge, we\npropose an LLM-based Partitioning EE method called LLM-PEE. To overcome the\nlimited context length of LLMs, LLM-PEE first recalls candidate event types and\nthen splits them into multiple partitions for LLMs to extract events. The\nresults in the supervised setting show that LLM-PEE outperforms the\nstate-of-the-art methods by 5.4 in event detection and 6.1 in argument\nextraction. In the zero-shot setting, LLM-PEE achieves up to 12.9 improvement\ncompared to mainstream LLMs, demonstrating its strong generalization\ncapabilities.\n","authors":["Wenxuan Liu","Zixuan Li","Long Bai","Yuxin Zuo","Daozhu Xu","Xiaolong Jin","Jiafeng Guo","Xueqi Cheng"],"pdf_url":"https://arxiv.org/pdf/2503.02628v1.pdf","comment":"Work in progress"},{"id":"http://arxiv.org/abs/2502.13044v2","updated":"2025-03-04T13:51:34Z","published":"2025-02-18T16:56:15Z","title":"Do we still need Human Annotators? Prompting Large Language Models for\n  Aspect Sentiment Quad Prediction","summary":"  Aspect sentiment quadruple prediction (ASQP) facilitates a detailed\nunderstanding of opinions expressed in a text by identifying the opinion term,\naspect term, aspect category and sentiment polarity for each opinion. However,\nannotating a full set of training examples to fine-tune models for ASQP is a\nresource-intensive process. In this study, we explore the capabilities of large\nlanguage models (LLMs) for zero- and few-shot learning on the ASQP task across\nfive diverse datasets. We report F1 scores slightly below those obtained with\nstate-of-the-art fine-tuned models but exceeding previously reported zero- and\nfew-shot performance. In the 40-shot setting on the Rest16 restaurant domain\ndataset, LLMs achieved an F1 score of 52.46, compared to 60.39 by the\nbest-performing fine-tuned method MVP. Additionally, we report the performance\nof LLMs in target aspect sentiment detection (TASD), where the F1 scores were\nalso close to fine-tuned models, achieving 66.03 on Rest16 in the 40-shot\nsetting, compared to 72.76 with MVP. While human annotators remain essential\nfor achieving optimal performance, LLMs can reduce the need for extensive\nmanual annotation in ASQP tasks.\n","authors":["Nils Constantin Hellwig","Jakob Fehle","Udo Kruschwitz","Christian Wolff"],"pdf_url":"https://arxiv.org/pdf/2502.13044v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.04070v6","updated":"2025-03-04T13:51:14Z","published":"2024-10-05T08:00:55Z","title":"PAD: Personalized Alignment of LLMs at Decoding-Time","summary":"  Aligning with personalized preferences, which vary significantly across\ncultural, educational, and political differences, poses a significant challenge\ndue to the computational costs and data demands of traditional alignment\nmethods. In response, this paper presents Personalized Alignment at\nDecoding-time (PAD), a novel framework designed to align LLM outputs with\ndiverse personalized preferences during the inference phase, eliminating the\nneed for additional training. By introducing a unique personalized reward\nmodeling strategy, this framework decouples the text generation process from\npersonalized preferences, facilitating the generation of generalizable\ntoken-level personalized rewards. The PAD algorithm leverages these rewards to\nguide the decoding process, dynamically tailoring the base model's predictions\nto personalized preferences. Extensive experimental results demonstrate that\nPAD not only outperforms existing training-based alignment methods in terms of\naligning with diverse preferences but also shows significant generalizability\nto preferences unseen during training and scalability across different base\nmodels. This work advances the capability of LLMs to meet user needs in\nreal-time applications, presenting a substantial step forward in personalized\nLLM alignment.\n","authors":["Ruizhe Chen","Xiaotian Zhang","Meng Luo","Wenhao Chai","Zuozhu Liu"],"pdf_url":"https://arxiv.org/pdf/2410.04070v6.pdf","comment":"ICLR 2025"},{"id":"http://arxiv.org/abs/2503.02625v1","updated":"2025-03-04T13:50:21Z","published":"2025-03-04T13:50:21Z","title":"ttta: Tools for Temporal Text Analysis","summary":"  Text data is inherently temporal. The meaning of words and phrases changes\nover time, and the context in which they are used is constantly evolving. This\nis not just true for social media data, where the language used is rapidly\ninfluenced by current events, memes and trends, but also for journalistic,\neconomic or political text data. Most NLP techniques however consider the\ncorpus at hand to be homogenous in regard to time. This is a simplification\nthat can lead to biased results, as the meaning of words and phrases can change\nover time. For instance, running a classic Latent Dirichlet Allocation on a\ncorpus that spans several years is not enough to capture changes in the topics\nover time, but only portraits an \"average\" topic distribution over the whole\ntime span. Researchers have developed a number of tools for analyzing text data\nover time. However, these tools are often scattered across different packages\nand libraries, making it difficult for researchers to use them in a consistent\nand reproducible way. The ttta package is supposed to serve as a collection of\ntools for analyzing text data over time.\n","authors":["Kai-Robin Lange","Niklas Benner","Lars Grnberg","Aymane Hachcham","Imene Kolli","Jonas Rieger","Carsten Jentsch"],"pdf_url":"https://arxiv.org/pdf/2503.02625v1.pdf","comment":"4 pages, 2 figures"},{"id":"http://arxiv.org/abs/2503.02623v1","updated":"2025-03-04T13:48:50Z","published":"2025-03-04T13:48:50Z","title":"Rewarding Doubt: A Reinforcement Learning Approach to Confidence\n  Calibration of Large Language Models","summary":"  A safe and trustworthy use of Large Language Models (LLMs) requires an\naccurate expression of confidence in their answers. We introduce a novel\nReinforcement Learning (RL) approach for LLM calibration that fine-tunes LLMs\nto elicit calibrated confidence estimations in their answers to factual\nquestions. We model the problem as a betting game where the model predicts a\nconfidence score together with every answer, and design a reward function that\npenalizes both over and under-confidence. We prove that under our reward design\nan optimal policy would result in a perfectly calibrated confidence estimation.\nOur experiments demonstrate significantly improved confidence calibration and\ngeneralization to new tasks without re-training, indicating that our approach\nteaches a general confidence awareness. This approach enables the training of\ninherently calibrated LLMs.\n","authors":["Paul Stangel","David Bani-Harouni","Chantal Pellegrini","Ege zsoy","Kamilia Zaripova","Matthias Keicher","Nassir Navab"],"pdf_url":"https://arxiv.org/pdf/2503.02623v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.02603v1","updated":"2025-03-04T13:21:47Z","published":"2025-03-04T13:21:47Z","title":"OkraLong: A Flexible Retrieval-Augmented Framework for Long-Text Query\n  Processing","summary":"  Large Language Models (LLMs) encounter challenges in efficiently processing\nlong-text queries, as seen in applications like enterprise document analysis\nand financial report comprehension. While conventional solutions employ\nlong-context processing or Retrieval-Augmented Generation (RAG), they suffer\nfrom prohibitive input expenses or incomplete information. Recent advancements\nadopt context compression and dynamic retrieval loops, but still sacrifice\ncritical details or incur iterative costs.To address these limitations, we\npropose OkraLong, a novel framework that flexibly optimizes the entire\nprocessing workflow. Unlike prior static or coarse-grained adaptive strategies,\nOkraLong adopts fine-grained orchestration through three synergistic\ncomponents: analyzer, organizer and executor. The analyzer characterizes the\ntask states, which guide the organizer in dynamically scheduling the workflow.\nThe executor carries out the execution and generates the final answer.\nExperimental results demonstrate that OkraLong not only enhances answer\naccuracy but also achieves cost-effectiveness across a variety of datasets.\n","authors":["Yulong Hui","Yihao Liu","Yao Lu","Huanchen Zhang"],"pdf_url":"https://arxiv.org/pdf/2503.02603v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.02589v1","updated":"2025-03-04T13:12:39Z","published":"2025-03-04T13:12:39Z","title":"MciteBench: A Benchmark for Multimodal Citation Text Generation in MLLMs","summary":"  Multimodal Large Language Models (MLLMs) have advanced in integrating diverse\nmodalities but frequently suffer from hallucination. A promising solution to\nmitigate this issue is to generate text with citations, providing a transparent\nchain for verification. However, existing work primarily focuses on generating\ncitations for text-only content, overlooking the challenges and opportunities\nof multimodal contexts. To address this gap, we introduce MCiteBench, the first\nbenchmark designed to evaluate and analyze the multimodal citation text\ngeneration ability of MLLMs. Our benchmark comprises data derived from academic\npapers and review-rebuttal interactions, featuring diverse information sources\nand multimodal content. We comprehensively evaluate models from multiple\ndimensions, including citation quality, source reliability, and answer\naccuracy. Through extensive experiments, we observe that MLLMs struggle with\nmultimodal citation text generation. We also conduct deep analyses of models'\nperformance, revealing that the bottleneck lies in attributing the correct\nsources rather than understanding the multimodal content.\n","authors":["Caiyu Hu","Yikai Zhang","Tinghui Zhu","Yiwei Ye","Yanghua Xiao"],"pdf_url":"https://arxiv.org/pdf/2503.02589v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2404.09299v2","updated":"2025-03-04T13:10:27Z","published":"2024-04-14T16:47:38Z","title":"Reap the Wild Wind: Detecting Media Storms in Large-Scale News Corpora","summary":"  Media Storms, dramatic outbursts of attention to a story, are central\ncomponents of media dynamics and the attention landscape. Despite their\nsignificance, there has been little systematic and empirical research on this\nconcept due to issues of measurement and operationalization. We introduce an\niterative human-in-the-loop method to identify media storms in a large-scale\ncorpus of news articles. The text is first transformed into signals of\ndispersion based on several textual characteristics. In each iteration, we\napply unsupervised anomaly detection to these signals; each anomaly is then\nvalidated by an expert to confirm the presence of a storm, and those results\nare then used to tune the anomaly detection in the next iteration. We\ndemonstrate the applicability of this method in two scenarios: first,\nsupplementing an initial list of media storms within a specific time frame; and\nsecond, detecting media storms in new time periods. We make available a media\nstorm dataset compiled using both scenarios. Both the method and dataset offer\nthe basis for comprehensive empirical research into the concept of media\nstorms, including characterizing them and predicting their outbursts and\ndurations, in mainstream media or social media platforms.\n","authors":["Dror K. Markus","Effi Levi","Tamir Sheafer","Shaul R. Shenhav"],"pdf_url":"https://arxiv.org/pdf/2404.09299v2.pdf","comment":"This paper was accepted and published in Findings of EMNLP 2024. The\n  final version is available at:\n  https://aclanthology.org/2024.findings-emnlp.275/"},{"id":"http://arxiv.org/abs/2407.03157v2","updated":"2025-03-04T13:01:07Z","published":"2024-07-03T14:34:03Z","title":"Let the Code LLM Edit Itself When You Edit the Code","summary":"  In this work, we investigate a typical scenario in code generation where a\ndeveloper edits existing code in real time and requests a code assistant, e.g.,\na large language model, to re-predict the next token or next line on the fly.\nNaively, the LLM needs to re-encode the entire KV cache to provide an accurate\nprediction. However, this process is computationally expensive, especially when\nthe sequence length is long. Simply encoding the edited subsequence and\nintegrating it to the original KV cache meets the temporal confusion problem,\nleading to significantly worse performance. We address this efficiency and\naccuracy trade-off by introducing \\underline{\\textbf{Positional\n\\textbf{I}ntegrity \\textbf{E}ncoding} (PIE). Building upon the rotary\npositional encoding, PIE first removes the rotary matrices in the Key cache\nthat introduce temporal confusion and then reapplies the correct rotary\nmatrices. This process ensures that positional relationships between tokens are\ncorrect and requires only a single round of matrix multiplication. We validate\nthe effectiveness of PIE through extensive experiments on the RepoBench-C-8k\ndataset, utilizing DeepSeek-Coder models with 1.3B, 6.7B, and 33B parameters.\nOur evaluation includes three real-world coding tasks: code insertion, code\ndeletion, and multi-place code editing. Results demonstrate that PIE reduces\ncomputational overhead by over 85% compared to the standard full recomputation\napproach across all model sizes and tasks while well approximating the model\nperformance.\n","authors":["Zhenyu He","Jun Zhang","Shengjie Luo","Jingjing Xu","Zhi Zhang","Di He"],"pdf_url":"https://arxiv.org/pdf/2407.03157v2.pdf","comment":"ICLR 2025 Camera Ready"},{"id":"http://arxiv.org/abs/2503.01622v2","updated":"2025-03-04T13:00:55Z","published":"2025-03-03T14:55:41Z","title":"DOVE: A Large-Scale Multi-Dimensional Predictions Dataset Towards\n  Meaningful LLM Evaluation","summary":"  Recent work found that LLMs are sensitive to a wide range of arbitrary prompt\ndimensions, including the type of delimiters, answer enumerators, instruction\nwording, and more. This throws into question popular single-prompt evaluation\npractices. We present DOVE (Dataset Of Variation Evaluation) a large-scale\ndataset containing prompt perturbations of various evaluation benchmarks. In\ncontrast to previous work, we examine LLM sensitivity from an holistic\nperspective, and assess the joint effects of perturbations along various\ndimensions, resulting in thousands of perturbations per instance. We evaluate\nseveral model families against DOVE, leading to several findings, including\nefficient methods for choosing well-performing prompts, observing that few-shot\nexamples reduce sensitivity, and identifying instances which are inherently\nhard across all perturbations. DOVE consists of more than 250M prompt\nperturbations and model outputs, which we make publicly available to spur a\ncommunity-wide effort toward meaningful, robust, and efficient evaluation.\n  Browse the data, contribute, and more: https://slab-nlp.github.io/DOVE/\n","authors":["Eliya Habba","Ofir Arviv","Itay Itzhak","Yotam Perlitz","Elron Bandel","Leshem Choshen","Michal Shmueli-Scheuer","Gabriel Stanovsky"],"pdf_url":"https://arxiv.org/pdf/2503.01622v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2502.00196v2","updated":"2025-03-04T12:36:10Z","published":"2025-01-31T22:26:33Z","title":"DermaSynth: Rich Synthetic Image-Text Pairs Using Open Access\n  Dermatology Datasets","summary":"  A major barrier to developing vision large language models (LLMs) in\ndermatology is the lack of large image--text pairs dataset. We introduce\nDermaSynth, a dataset comprising of 92,020 synthetic image--text pairs curated\nfrom 45,205 images (13,568 clinical and 35,561 dermatoscopic) for\ndermatology-related clinical tasks. Leveraging state-of-the-art LLMs, using\nGemini 2.0, we used clinically related prompts and self-instruct method to\ngenerate diverse and rich synthetic texts. Metadata of the datasets were\nincorporated into the input prompts by targeting to reduce potential\nhallucinations. The resulting dataset builds upon open access dermatological\nimage repositories (DERM12345, BCN20000, PAD-UFES-20, SCIN, and HIBA) that have\npermissive CC-BY-4.0 licenses. We also fine-tuned a preliminary\nLlama-3.2-11B-Vision-Instruct model, DermatoLlama 1.0, on 5,000 samples. We\nanticipate this dataset to support and accelerate AI research in dermatology.\nData and code underlying this work are accessible at\nhttps://github.com/abdurrahimyilmaz/DermaSynth.\n","authors":["Abdurrahim Yilmaz","Furkan Yuceyalcin","Ece Gokyayla","Donghee Choi","Ozan Erdem","Ali Anil Demircali","Rahmetullah Varol","Ufuk Gorkem Kirabali","Gulsum Gencoglan","Joram M. Posma","Burak Temelkuran"],"pdf_url":"https://arxiv.org/pdf/2502.00196v2.pdf","comment":"12 pages, 4 figures"},{"id":"http://arxiv.org/abs/2503.00493v2","updated":"2025-03-04T12:32:13Z","published":"2025-03-01T13:44:50Z","title":"LLaSE-G1: Incentivizing Generalization Capability for LLaMA-based Speech\n  Enhancement","summary":"  Recent advancements in language models (LMs) have demonstrated strong\ncapabilities in semantic understanding and contextual modeling, which have\nflourished in generative speech enhancement (SE). However, many LM-based SE\napproaches primarily focus on semantic information, often neglecting the\ncritical role of acoustic information, which leads to acoustic inconsistency\nafter enhancement and limited generalization across diverse SE tasks. In this\npaper, we introduce LLaSE-G1, a LLaMA-based language model that incentivizes\ngeneralization capabilities for speech enhancement. LLaSE-G1 offers the\nfollowing key contributions: First, to mitigate acoustic inconsistency,\nLLaSE-G1 employs continuous representations from WavLM as input and predicts\nspeech tokens from X-Codec2, maximizing acoustic preservation. Second, to\npromote generalization capability, LLaSE-G1 introduces dual-channel inputs and\noutputs, unifying multiple SE tasks without requiring task-specific IDs. Third,\nLLaSE-G1 outperforms prior task-specific discriminative and generative SE\nmodels, demonstrating scaling effects at test time and emerging capabilities\nfor unseen SE tasks. Additionally, we release our code and models to support\nfurther research in this area.\n","authors":["Boyi Kang","Xinfa Zhu","Zihan Zhang","Zhen Ye","Mingshuai Liu","Ziqian Wang","Yike Zhu","Guobin Ma","Jun Chen","Longshuai Xiao","Chao Weng","Wei Xue","Lei Xie"],"pdf_url":"https://arxiv.org/pdf/2503.00493v2.pdf","comment":"13 pages, 2 figures, 8 tables"},{"id":"http://arxiv.org/abs/2503.00401v2","updated":"2025-03-04T12:04:26Z","published":"2025-03-01T08:29:59Z","title":"Smoothing Grounding and Reasoning for MLLM-Powered GUI Agents with\n  Query-Oriented Pivot Tasks","summary":"  Perception-enhanced pre-training, particularly through grounding techniques,\nis widely adopted to enhance the performance of graphical user interface (GUI)\nagents. However, in resource-constrained scenarios, the format discrepancy\nbetween coordinate-oriented grounding and action-oriented reasoning limits the\neffectiveness of grounding for reasoning tasks. To address this challenge, we\npropose a query-oriented pivot approach called query inference, which serves as\na bridge between GUI grounding and reasoning. By inferring potential user\nqueries from a screenshot and its associated element coordinates, query\ninference improves the understanding of coordinates while aligning more closely\nwith reasoning tasks. Experimental results show that query inference\noutperforms previous grounding techniques under the same training data scale.\nNotably, query inference achieves comparable or even better performance to\nlarge-scale grounding-enhanced OS-Atlas with less than 0.1% of training data.\nFurthermore, we explore the impact of reasoning formats and demonstrate that\nintegrating additional semantic information into the input further boosts\nreasoning performance. The code is publicly available at\nhttps://github.com/ZrW00/GUIPivot.\n","authors":["Zongru Wu","Pengzhou Cheng","Zheng Wu","Tianjie Ju","Zhuosheng Zhang","Gongshen Liu"],"pdf_url":"https://arxiv.org/pdf/2503.00401v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.02532v1","updated":"2025-03-04T11:56:33Z","published":"2025-03-04T11:56:33Z","title":"Use Me Wisely: AI-Driven Assessment for LLM Prompting Skills Development","summary":"  The use of large language model (LLM)-powered chatbots, such as ChatGPT, has\nbecome popular across various domains, supporting a range of tasks and\nprocesses. However, due to the intrinsic complexity of LLMs, effective\nprompting is more challenging than it may seem. This highlights the need for\ninnovative educational and support strategies that are both widely accessible\nand seamlessly integrated into task workflows. Yet, LLM prompting is highly\ntask- and domain-dependent, limiting the effectiveness of generic approaches.\nIn this study, we explore whether LLM-based methods can facilitate learning\nassessments by using ad-hoc guidelines and a minimal number of annotated prompt\nsamples. Our framework transforms these guidelines into features that can be\nidentified within learners' prompts. Using these feature descriptions and\nannotated examples, we create few-shot learning detectors. We then evaluate\ndifferent configurations of these detectors, testing three state-of-the-art\nLLMs and ensembles. We run experiments with cross-validation on a sample of\noriginal prompts, as well as tests on prompts collected from task-naive\nlearners. Our results show how LLMs perform on feature detection. Notably, GPT-\n4 demonstrates strong performance on most features, while closely related\nmodels, such as GPT-3 and GPT-3.5 Turbo (Instruct), show inconsistent behaviors\nin feature classification. These differences highlight the need for further\nresearch into how design choices impact feature selection and prompt detection.\nOur findings contribute to the fields of generative AI literacy and\ncomputer-supported learning assessment, offering valuable insights for both\nresearchers and practitioners.\n","authors":["Dimitri Ognibene","Gregor Donabauer","Emily Theophilou","Cansu Koyuturk","Mona Yavari","Sathya Bursic","Alessia Telari","Alessia Testa","Raffaele Boiano","Davide Taibi","Davinia Hernandez-Leo","Udo Kruschwitz","Martin Ruskov"],"pdf_url":"https://arxiv.org/pdf/2503.02532v1.pdf","comment":"Preprint accepted for Publication in Educational Technology & Society\n  (ET&S)"},{"id":"http://arxiv.org/abs/2405.16533v2","updated":"2025-03-04T11:33:50Z","published":"2024-05-26T11:40:58Z","title":"Tool Learning in the Wild: Empowering Language Models as Automatic Tool\n  Agents","summary":"  Augmenting large language models (LLMs) with external tools has emerged as a\npromising approach to extend their utility, enabling them to solve practical\ntasks. Previous methods manually parse tool documentation and create in-context\ndemonstrations, transforming tools into structured formats for LLMs to use in\ntheir step-by-step reasoning. However, this manual process requires domain\nexpertise and struggles to scale to large toolsets. Additionally, these methods\nrely heavily on ad-hoc inference techniques or special tokens to integrate\nfree-form LLM generation with tool-calling actions, limiting the LLM's\nflexibility in handling diverse tool specifications and integrating multiple\ntools.\n  In this work, we propose AutoTools, a framework that enables LLMs to automate\nthe tool-use workflow. Specifically, the LLM automatically transforms tool\ndocumentation into callable functions, verifying syntax and runtime\ncorrectness. Then, the LLM integrates these functions into executable programs\nto solve practical tasks, flexibly grounding tool-use actions into its\nreasoning processes. Extensive experiments on existing and newly collected,\nmore challenging benchmarks illustrate the superiority of our framework.\nInspired by these promising results, we further investigate how to improve the\nexpertise of LLMs, especially open-source LLMs with fewer parameters, within\nAutoTools. Thus, we propose the AutoTools-learning approach, training the LLMs\nwith three learning tasks on 34k instances of high-quality synthetic data,\nincluding documentation understanding, relevance learning, and function\nprogramming. Fine-grained results validate the effectiveness of our overall\ntraining approach and each individual task. Our methods are an important step\ntowards the use of LLMs for solving real-world tasks with external tools.\n","authors":["Zhengliang Shi","Shen Gao","Lingyong Yan","Yue Feng","Xiuyi Chen","Zhumin Chen","Dawei Yin","Suzan Verberne","Zhaochun Ren"],"pdf_url":"https://arxiv.org/pdf/2405.16533v2.pdf","comment":"Accepted by WWW 2025"},{"id":"http://arxiv.org/abs/2503.02519v1","updated":"2025-03-04T11:31:05Z","published":"2025-03-04T11:31:05Z","title":"Generator-Assistant Stepwise Rollback Framework for Large Language Model\n  Agent","summary":"  Large language model (LLM) agents typically adopt a step-by-step reasoning\nframework, in which they interleave the processes of thinking and acting to\naccomplish the given task. However, this paradigm faces a deep-rooted one-pass\nissue whereby each generated intermediate thought is plugged into the\ntrajectory regardless of its correctness, which can cause irreversible error\npropagation. To address the issue, this paper proposes a novel framework called\nGenerator-Assistant Stepwise Rollback (GA-Rollback) to induce better\ndecision-making for LLM agents. Particularly, GA-Rollback utilizes a generator\nto interact with the environment and an assistant to examine each action\nproduced by the generator, where the assistant triggers a rollback operation\nupon detection of incorrect actions. Moreover, we introduce two additional\nstrategies tailored for the rollback scenario to further improve its\neffectiveness. Extensive experiments show that GA-Rollback achieves significant\nimprovements over several strong baselines on three widely used benchmarks. Our\nanalysis further reveals that GA-Rollback can function as a robust\nplug-and-play module, integrating seamlessly with other methods.\n","authors":["Xingzuo Li","Kehai Chen","Yunfei Long","Xuefeng Bai","Yong Xu","Min Zhang"],"pdf_url":"https://arxiv.org/pdf/2503.02519v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2402.14337v3","updated":"2025-03-04T11:22:10Z","published":"2024-02-22T07:12:34Z","title":"How Ambiguous Are the Rationales for Natural Language Reasoning? A\n  Simple Approach to Handling Rationale Uncertainty","summary":"  The quality of rationales is essential in the reasoning capabilities of\nlanguage models. Rationales not only enhance reasoning performance in complex\nnatural language tasks but also justify model decisions. However, obtaining\nimpeccable rationales is often impossible. Our study aims to investigate how\nambiguous rationales play in model performances of natural language reasoning.\nWe first assess the ambiguity of rationales through the lens of entropy and\nuncertainty in model prior beliefs, exploring its impact on task performance.\nWe then propose a simple way to guide models to choose between two different\nreasoning paths depending on the ambiguity of the rationales. Our empirical\nresults demonstrate that this approach leads to robust performance,\nparticularly in adversarial scenarios where rationale quality is inconsistent.\n","authors":["Hazel H. Kim"],"pdf_url":"https://arxiv.org/pdf/2402.14337v3.pdf","comment":"Accepted to COLING2025"},{"id":"http://arxiv.org/abs/2503.02502v1","updated":"2025-03-04T11:10:13Z","published":"2025-03-04T11:10:13Z","title":"LADM: Long-context Training Data Selection with Attention-based\n  Dependency Measurement for LLMs","summary":"  Long-context modeling has drawn more and more attention in the area of Large\nLanguage Models (LLMs). Continual training with long-context data becomes the\nde-facto method to equip LLMs with the ability to process long inputs. However,\nit still remains an open challenge to measure the quality of long-context\ntraining data. To address this issue, we propose a Long-context data selection\nframework with Attention-based Dependency Measurement (LADM), which can\nefficiently identify high-quality long-context data from a large-scale,\nmulti-domain pre-training corpus. LADM leverages the retrieval capabilities of\nthe attention mechanism to capture contextual dependencies, ensuring a\ncomprehensive quality measurement of long-context data. Experimental results\nshow that our LADM framework significantly boosts the performance of LLMs on\nmultiple long-context tasks with only 1B tokens for continual training.\n","authors":["Jianghao Chen","Junhong Wu","Yangyifan Xu","Jiajun Zhang"],"pdf_url":"https://arxiv.org/pdf/2503.02502v1.pdf","comment":"Submitted to ACL ARR 2024 December"},{"id":"http://arxiv.org/abs/2503.02495v1","updated":"2025-03-04T11:01:25Z","published":"2025-03-04T11:01:25Z","title":"Union of Experts: Adapting Hierarchical Routing to Equivalently\n  Decomposed Transformer","summary":"  Mixture-of-Experts (MoE) enhances model performance while maintaining\ncomputational efficiency, making it well-suited for large-scale applications.\nHowever, expert in exist MoE paradigm works as an individual, thereby lacking\nhigh-quality expert interactions. Moreover, they have not been effectively\nextended to attention block, which constrains further efficiency improvements.\nTo tackle these issues, we propose Union-of-Experts (UoE), which decomposes\ntransformer into an equitant group of experts, and then implement dynamic\nrouting on input data and experts. Our approach advances MoE design with three\nkey innovations: (1) We conducted equitant expert decomposition on both MLP\nblocks and attention blocks based on matrix partition in tensor parallelism.\n(2) We developed two routing paradigms: patch wise data selection and expert\nselection, to apply routing across different levels. (3) We design the\narchitecture of UoE model, including Selective Multi-Head Attention (SMHA) and\nUnion-of-MLP-Experts (UoME). (4) We develop parallel implementation of UoE's\nrouting and computation operation, and optimize efficiency based on the\nhardware processing analysis. The experiments demonstrate that the model\nemployed with UoE surpass Full Attention, state-of-art MoEs and efficient\ntransformers in several tasks across image and natural language domains. The\nsource codes are available at https://github.com/YujiaoYang-work/UoE.\n","authors":["Yujiao Yang","Jing Lian","Linhui Li"],"pdf_url":"https://arxiv.org/pdf/2503.02495v1.pdf","comment":"17 pages, 6 figures, 5 tables"},{"id":"http://arxiv.org/abs/2503.02463v1","updated":"2025-03-04T10:17:29Z","published":"2025-03-04T10:17:29Z","title":"It Helps to Take a Second Opinion: Teaching Smaller LLMs to Deliberate\n  Mutually via Selective Rationale Optimisation","summary":"  Very large language models (LLMs) such as GPT-4 have shown the ability to\nhandle complex tasks by generating and self-refining step-by-step rationales.\nSmaller language models (SLMs), typically with < 13B parameters, have been\nimproved by using the data generated from very-large LMs through knowledge\ndistillation. However, various practical constraints such as API costs,\ncopyright, legal and ethical policies restrict using large (often opaque)\nmodels to train smaller models for commercial use. Limited success has been\nachieved at improving the ability of an SLM to explore the space of possible\nrationales and evaluate them by itself through self-deliberation. To address\nthis, we propose COALITION, a trainable framework that facilitates interaction\nbetween two variants of the same SLM and trains them to generate and refine\nrationales optimized for the end-task. The variants exhibit different behaviors\nto produce a set of diverse candidate rationales during the generation and\nrefinement steps. The model is then trained via Selective Rationale\nOptimization (SRO) to prefer generating rationale candidates that maximize the\nlikelihood of producing the ground-truth answer. During inference, COALITION\nemploys a controller to select the suitable variant for generating and refining\nthe rationales. On five different datasets covering mathematical problems,\ncommonsense reasoning, and natural language inference, COALITION outperforms\nseveral baselines by up to 5%. Our ablation studies reveal that\ncross-communication between the two variants performs better than using the\nsingle model to self-refine the rationales. We also demonstrate the\napplicability of COALITION for LMs of varying scales (4B to 14B parameters) and\nmodel families (Mistral, Llama, Qwen, Phi). We release the code for this work\nat https://github.com/Sohanpatnaik106/coalition.\n","authors":["Sohan Patnaik","Milan Aggarwal","Sumit Bhatia","Balaji Krishnamurthy"],"pdf_url":"https://arxiv.org/pdf/2503.02463v1.pdf","comment":"Accepted at ICLR 2025"},{"id":"http://arxiv.org/abs/2503.02450v1","updated":"2025-03-04T09:53:26Z","published":"2025-03-04T09:53:26Z","title":"Measuring What Makes You Unique: Difference-Aware User Modeling for\n  Enhancing LLM Personalization","summary":"  Personalizing Large Language Models (LLMs) has become a critical step in\nfacilitating their widespread application to enhance individual life\nexperiences. In pursuit of personalization, distilling key preference\ninformation from an individual's historical data as instructional preference\ncontext to customize LLM generation has emerged as a promising direction.\nHowever, these methods face a fundamental limitation by overlooking the\ninter-user comparative analysis, which is essential for identifying the\ninter-user differences that truly shape preferences. To address this\nlimitation, we propose Difference-aware Personalization Learning (DPL), a novel\napproach that emphasizes extracting inter-user differences to enhance LLM\npersonalization. DPL strategically selects representative users for comparison\nand establishes a structured standard to extract meaningful, task-relevant\ndifferences for customizing LLM generation. Extensive experiments on real-world\ndatasets demonstrate that DPL significantly enhances LLM personalization. We\nrelease our code at https://github.com/SnowCharmQ/DPL.\n","authors":["Yilun Qiu","Xiaoyan Zhao","Yang Zhang","Yimeng Bai","Wenjie Wang","Hong Cheng","Fuli Feng","Tat-Seng Chua"],"pdf_url":"https://arxiv.org/pdf/2503.02450v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.02445v1","updated":"2025-03-04T09:40:00Z","published":"2025-03-04T09:40:00Z","title":"BRIDGE: Bootstrapping Text to Control Time-Series Generation via\n  Multi-Agent Iterative Optimization and Diffusion Modelling","summary":"  Time-series Generation (TSG) is a prominent research area with broad\napplications in simulations, data augmentation, and counterfactual analysis.\nWhile existing methods have shown promise in unconditional single-domain TSG,\nreal-world applications demand for cross-domain approaches capable of\ncontrolled generation tailored to domain-specific constraints and\ninstance-level requirements. In this paper, we argue that text can provide\nsemantic insights, domain information and instance-specific temporal patterns,\nto guide and improve TSG. We introduce ``Text-Controlled TSG'', a task focused\non generating realistic time series by incorporating textual descriptions. To\naddress data scarcity in this setting, we propose a novel LLM-based Multi-Agent\nframework that synthesizes diverse, realistic text-to-TS datasets. Furthermore,\nwe introduce BRIDGE, a hybrid text-controlled TSG framework that integrates\nsemantic prototypes with text description for supporting domain-level guidance.\nThis approach achieves state-of-the-art generation fidelity on 11 of 12\ndatasets, and improves controllability by 12.52% on MSE and 6.34% MAE compared\nto no text input generation, highlighting its potential for generating tailored\ntime-series data.\n","authors":["Hao Li","Yu-Hao Huang","Chang Xu","Viktor Schlegel","Ren-He Jiang","Riza Batista-Navarro","Goran Nenadic","Jiang Bian"],"pdf_url":"https://arxiv.org/pdf/2503.02445v1.pdf","comment":"Preprint. Work in progress"},{"id":"http://arxiv.org/abs/2503.02443v1","updated":"2025-03-04T09:39:09Z","published":"2025-03-04T09:39:09Z","title":"AILS-NTUA at SemEval-2025 Task 4: Parameter-Efficient Unlearning for\n  Large Language Models using Data Chunking","summary":"  The Unlearning Sensitive Content from Large Language Models task aims to\nremove targeted datapoints from trained models while minimally affecting their\ngeneral knowledge. In our work, we leverage parameter-efficient, gradient-based\nunlearning using low-rank (LoRA) adaptation and layer-focused fine-tuning. To\nfurther enhance unlearning effectiveness, we employ data chunking, splitting\nforget data into disjoint partitions and merging them with cyclically sampled\nretain samples at a pre-defined ratio. Our task-agnostic method achieves an\noutstanding forget-retain balance, ranking first on leaderboards and\nsignificantly outperforming baselines and competing systems.\n","authors":["Iraklis Premptis","Maria Lymperaiou","Giorgos Filandrianos","Orfeas Menis Mastromichalakis","Athanasios Voulodimos","Giorgos Stamou"],"pdf_url":"https://arxiv.org/pdf/2503.02443v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.02442v1","updated":"2025-03-04T09:38:57Z","published":"2025-03-04T09:38:57Z","title":"AILS-NTUA at SemEval-2025 Task 3: Leveraging Large Language Models and\n  Translation Strategies for Multilingual Hallucination Detection","summary":"  Multilingual hallucination detection stands as an underexplored challenge,\nwhich the Mu-SHROOM shared task seeks to address. In this work, we propose an\nefficient, training-free LLM prompting strategy that enhances detection by\ntranslating multilingual text spans into English. Our approach achieves\ncompetitive rankings across multiple languages, securing two first positions in\nlow-resource languages. The consistency of our results highlights the\neffectiveness of our translation strategy for hallucination detection,\ndemonstrating its applicability regardless of the source language.\n","authors":["Dimitra Karkani","Maria Lymperaiou","Giorgos Filandrianos","Nikolaos Spanos","Athanasios Voulodimos","Giorgos Stamou"],"pdf_url":"https://arxiv.org/pdf/2503.02442v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.02316v4","updated":"2025-03-04T09:10:59Z","published":"2024-11-04T17:40:39Z","title":"Evaluating Creative Short Story Generation in Humans and Large Language\n  Models","summary":"  Story-writing is a fundamental aspect of human imagination, relying heavily\non creativity to produce narratives that are novel, effective, and surprising.\nWhile large language models (LLMs) have demonstrated the ability to generate\nhigh-quality stories, their creative story-writing capabilities remain\nunder-explored. In this work, we conduct a systematic analysis of creativity in\nshort story generation across 60 LLMs and 60 people using a five-sentence\ncreative story-writing task. We use measures to automatically evaluate model-\nand human-generated stories across several dimensions of creativity, including\nnovelty, surprise, diversity, and linguistic complexity. We also collect\ncreativity ratings and Turing Test classifications from non-expert and expert\nhuman raters and LLMs. Automated metrics show that LLMs generate stylistically\ncomplex stories, but tend to fall short in terms of novelty, surprise and\ndiversity when compared to average human writers. Expert ratings generally\ncoincide with automated metrics. However, LLMs and non-experts rate LLM stories\nto be more creative than human-generated stories. We discuss why and how these\ndifferences in ratings occur, and their implications for both human and\nartificial creativity.\n","authors":["Mete Ismayilzada","Claire Stevenson","Lonneke van der Plas"],"pdf_url":"https://arxiv.org/pdf/2411.02316v4.pdf","comment":"Submitted to ICCC 2025"},{"id":"http://arxiv.org/abs/2503.02401v1","updated":"2025-03-04T08:43:19Z","published":"2025-03-04T08:43:19Z","title":"Hierarchical Re-ranker Retriever (HRR)","summary":"  Retrieving the right level of context for a given query is a perennial\nchallenge in information retrieval - too large a chunk dilutes semantic\nspecificity, while chunks that are too small lack broader context. This paper\nintroduces the Hierarchical Re-ranker Retriever (HRR), a framework designed to\nachieve both fine-grained and high-level context retrieval for large language\nmodel (LLM) applications. In HRR, documents are split into sentence-level and\nintermediate-level (512 tokens) chunks to maximize vector-search quality for\nboth short and broad queries. We then employ a reranker that operates on these\n512-token chunks, ensuring an optimal balance neither too coarse nor too fine\nfor robust relevance scoring. Finally, top-ranked intermediate chunks are\nmapped to parent chunks (2048 tokens) to provide an LLM with sufficiently large\ncontext.\n","authors":["Ashish Singh","Priti Mohapatra"],"pdf_url":"https://arxiv.org/pdf/2503.02401v1.pdf","comment":"14 pages"},{"id":"http://arxiv.org/abs/2404.14851v4","updated":"2025-03-04T08:38:34Z","published":"2024-04-23T09:05:37Z","title":"From Matching to Generation: A Survey on Generative Information\n  Retrieval","summary":"  Information Retrieval (IR) systems are crucial tools for users to access\ninformation, which have long been dominated by traditional methods relying on\nsimilarity matching. With the advancement of pre-trained language models,\ngenerative information retrieval (GenIR) emerges as a novel paradigm,\nattracting increasing attention. Based on the form of information provided to\nusers, current research in GenIR can be categorized into two aspects:\n\\textbf{(1) Generative Document Retrieval} (GR) leverages the generative\nmodel's parameters for memorizing documents, enabling retrieval by directly\ngenerating relevant document identifiers without explicit indexing. \\textbf{(2)\nReliable Response Generation} employs language models to directly generate\ninformation users seek, breaking the limitations of traditional IR in terms of\ndocument granularity and relevance matching while offering flexibility,\nefficiency, and creativity to meet practical needs. This paper aims to\nsystematically review the latest research progress in GenIR. We will summarize\nthe advancements in GR regarding model training and structure, document\nidentifier, incremental learning, etc., as well as progress in reliable\nresponse generation in aspects of internal knowledge memorization, external\nknowledge augmentation, etc. We also review the evaluation, challenges and\nfuture developments in GenIR systems. This review aims to offer a comprehensive\nreference for researchers, encouraging further development in the GenIR field.\nGithub Repository: https://github.com/RUC-NLPIR/GenIR-Survey\n","authors":["Xiaoxi Li","Jiajie Jin","Yujia Zhou","Yuyao Zhang","Peitian Zhang","Yutao Zhu","Zhicheng Dou"],"pdf_url":"https://arxiv.org/pdf/2404.14851v4.pdf","comment":null},{"id":"http://arxiv.org/abs/2502.16033v2","updated":"2025-03-04T08:23:58Z","published":"2025-02-22T01:52:37Z","title":"Multimodal Inconsistency Reasoning (MMIR): A New Benchmark for\n  Multimodal Reasoning Models","summary":"  Existing Multimodal Large Language Models (MLLMs) are predominantly trained\nand tested on consistent visual-textual inputs, leaving open the question of\nwhether they can handle inconsistencies in real-world, layout-rich content. To\nbridge this gap, we propose the Multimodal Inconsistency Reasoning (MMIR)\nbenchmark to assess MLLMs' ability to detect and reason about semantic\nmismatches in artifacts such as webpages, presentation slides, and posters.\nMMIR comprises 534 challenging samples, each containing synthetically injected\nerrors across five reasoning-heavy categories: Factual Contradiction, Identity\nMisattribution, Contextual Mismatch, Quantitative Discrepancy, and\nTemporal/Spatial Incoherence. We evaluate six state-of-the-art MLLMs, showing\nthat models with dedicated multimodal reasoning capabilities, such as o1,\nsubstantially outperform their counterparts while open-source models remain\nparticularly vulnerable to inconsistency errors. Detailed error analyses\nfurther show that models excel in detecting pairwise inconsistencies but\nstruggle with inconsistencies confined to single elements in complex layouts.\nProbing experiments reveal that single-modality prompting, including\nChain-of-Thought (CoT) and Set-of-Mark (SoM) methods, yields marginal gains,\nrevealing a key bottleneck in cross-modal reasoning. Our findings highlight the\nneed for advanced multimodal reasoning and point to future research on\nmultimodal inconsistency.\n","authors":["Qianqi Yan","Yue Fan","Hongquan Li","Shan Jiang","Yang Zhao","Xinze Guan","Ching-Chen Kuo","Xin Eric Wang"],"pdf_url":"https://arxiv.org/pdf/2502.16033v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.00203v2","updated":"2025-03-04T08:23:10Z","published":"2025-02-28T21:39:22Z","title":"Llamarine: Open-source Maritime Industry-specific Large Language Model","summary":"  Large Language Models (LLMs) have demonstrated substantial potential in\naddressing complex reasoning tasks, yet their general-purpose nature often\nlimits their effectiveness in specialized domains such as maritime navigation.\nTo bridge this gap, we introduce Llamarine, the first open-source LLM designed\nspecifically for maritime navigation. Llamarine 1.0 is developed through\ncontinued pretraining and fine-tuning on a high-quality corpus comprising\nmaritime textbooks, research publications, and web text from Wikipedia. This\ndomain-specific training enables the model to acquire expert-level knowledge in\nnavigational principles, collision avoidance, route optimization, and\nregulatory compliance. Our key contributions include (a) the curation of a\ncomprehensive maritime dataset from authoritative sources, ensuring depth and\nreliability in the model's knowledge base; (b) the development of a\nfoundational model capable of reasoning about complex navigational challenges\nwith greater accuracy than general-purpose LLMs; and (c) the establishment of a\nbenchmark to evaluate performance in maritime-specific decision-making tasks.\nExperimental results demonstrate that Llamarine outperforms both\ngeneral-purpose and commercial LLMs in critical navigation-related tasks, such\nas trajectory planning, risk assessment, and compliance with maritime\nregulations. By providing an open-source foundation model trained exclusively\non high-quality maritime literature, Llamarine paves the way for AI-driven\nadvancements in maritime safety, efficiency, and operational decision-making.\n","authors":["William Nguyen","An Phan","Konobu Kimura","Hitoshi Maeno","Mika Tanaka","Quynh Le","William Poucher","Christopher Nguyen"],"pdf_url":"https://arxiv.org/pdf/2503.00203v2.pdf","comment":"Work in progress"},{"id":"http://arxiv.org/abs/2503.02382v1","updated":"2025-03-04T08:18:46Z","published":"2025-03-04T08:18:46Z","title":"An Efficient and Precise Training Data Construction Framework for\n  Process-supervised Reward Model in Mathematical Reasoning","summary":"  Enhancing the mathematical reasoning capabilities of Large Language Models\n(LLMs) is of great scientific and practical significance. Researchers typically\nemploy process-supervised reward models (PRMs) to guide the reasoning process,\neffectively improving the models' reasoning abilities. However, existing\nmethods for constructing process supervision training data, such as manual\nannotation and per-step Monte Carlo estimation, are often costly or suffer from\npoor quality. To address these challenges, this paper introduces a framework\ncalled EpicPRM, which annotates each intermediate reasoning step based on its\nquantified contribution and uses an adaptive binary search algorithm to enhance\nboth annotation precision and efficiency. Using this approach, we efficiently\nconstruct a high-quality process supervision training dataset named Epic50k,\nconsisting of 50k annotated intermediate steps. Compared to other publicly\navailable datasets, the PRM trained on Epic50k demonstrates significantly\nsuperior performance. Getting Epic50k at https://github.com/xiaolizh1/EpicPRM.\n","authors":["Wei Sun","Qianlong Du","Fuwei Cui","Jiajun Zhang"],"pdf_url":"https://arxiv.org/pdf/2503.02382v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.02374v1","updated":"2025-03-04T08:01:34Z","published":"2025-03-04T08:01:34Z","title":"MedEthicEval: Evaluating Large Language Models Based on Chinese Medical\n  Ethics","summary":"  Large language models (LLMs) demonstrate significant potential in advancing\nmedical applications, yet their capabilities in addressing medical ethics\nchallenges remain underexplored. This paper introduces MedEthicEval, a novel\nbenchmark designed to systematically evaluate LLMs in the domain of medical\nethics. Our framework encompasses two key components: knowledge, assessing the\nmodels' grasp of medical ethics principles, and application, focusing on their\nability to apply these principles across diverse scenarios. To support this\nbenchmark, we consulted with medical ethics researchers and developed three\ndatasets addressing distinct ethical challenges: blatant violations of medical\nethics, priority dilemmas with clear inclinations, and equilibrium dilemmas\nwithout obvious resolutions. MedEthicEval serves as a critical tool for\nunderstanding LLMs' ethical reasoning in healthcare, paving the way for their\nresponsible and effective use in medical contexts.\n","authors":["Haoan Jin","Jiacheng Shi","Hanhui Xu","Kenny Q. Zhu","Mengyue Wu"],"pdf_url":"https://arxiv.org/pdf/2503.02374v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2406.16783v3","updated":"2025-03-04T07:56:00Z","published":"2024-06-24T16:45:13Z","title":"M2Lingual: Enhancing Multilingual, Multi-Turn Instruction Alignment in\n  Large Language Models","summary":"  Instruction finetuning (IFT) is critical for aligning Large Language Models\n(LLMs) to follow instructions. While many effective IFT datasets have been\nintroduced recently, they predominantly focus on high-resource languages like\nEnglish. To better align LLMs across a broad spectrum of languages and tasks,\nwe propose a fully synthetic, novel taxonomy (Evol) guided Multilingual,\nMulti-turn instruction finetuning dataset, called M2Lingual. It is constructed\nby first selecting a diverse set of seed examples and then utilizing the\nproposed Evol taxonomy to convert these seeds into complex and challenging\nmulti-turn instructions. We demonstrate the effectiveness of M2Lingual by\ntraining LLMs of varying sizes and showcasing the enhanced performance across a\ndiverse set of languages. We contribute the 2 step Evol taxonomy with the\nguided generation code: https://github.com/ServiceNow/M2Lingual, as well as the\nfirst fully synthetic, general and task-oriented, multi-turn, multilingual\ndataset built with Evol - M2Lingual:\nhttps://huggingface.co/datasets/ServiceNow-AI/ M2Lingual - containing 182K\ntotal IFT pairs, covering 70 languages and 17+ NLP tasks.\n","authors":["Rishabh Maheshwary","Vikas Yadav","Hoang Nguyen","Khyati Mahajan","Sathwik Tejaswi Madhusudhan"],"pdf_url":"https://arxiv.org/pdf/2406.16783v3.pdf","comment":"39 pages"},{"id":"http://arxiv.org/abs/2503.01478v2","updated":"2025-03-04T07:51:56Z","published":"2025-03-03T12:37:34Z","title":"SePer: Measure Retrieval Utility Through The Lens Of Semantic Perplexity\n  Reduction","summary":"  Large Language Models (LLMs) have demonstrated improved generation\nperformance by incorporating externally retrieved knowledge, a process known as\nretrieval-augmented generation (RAG). Despite the potential of this approach,\nexisting studies evaluate RAG effectiveness by 1) assessing retrieval and\ngeneration components jointly, which obscures retrieval's distinct\ncontribution, or 2) examining retrievers using traditional metrics such as\nNDCG, which creates a gap in understanding retrieval's true utility in the\noverall generation process. To address the above limitations, in this work, we\nintroduce an automatic evaluation method that measures retrieval quality\nthrough the lens of information gain within the RAG framework. Specifically, we\npropose Semantic Perplexity (SePer), a metric that captures the LLM's internal\nbelief about the correctness of the retrieved information. We quantify the\nutility of retrieval by the extent to which it reduces semantic perplexity\npost-retrieval. Extensive experiments demonstrate that SePer not only aligns\nclosely with human preferences but also offers a more precise and efficient\nevaluation of retrieval utility across diverse RAG scenarios.\n","authors":["Lu Dai","Yijie Xu","Jinhui Ye","Hao Liu","Hui Xiong"],"pdf_url":"https://arxiv.org/pdf/2503.01478v2.pdf","comment":"ICLR 2025 Spotlight"},{"id":"http://arxiv.org/abs/2309.14362v2","updated":"2025-03-04T07:50:39Z","published":"2023-09-23T10:37:57Z","title":"Diversifying Question Generation over Knowledge Base via External\n  Natural Questions","summary":"  Previous methods on knowledge base question generation (KBQG) primarily focus\non enhancing the quality of a single generated question. Recognizing the\nremarkable paraphrasing ability of humans, we contend that diverse texts should\nconvey the same semantics through varied expressions. The above insights make\ndiversifying question generation an intriguing task, where the first challenge\nis evaluation metrics for diversity. Current metrics inadequately assess the\nabove diversity since they calculate the ratio of unique n-grams in the\ngenerated question itself, which leans more towards measuring duplication\nrather than true diversity. Accordingly, we devise a new diversity evaluation\nmetric, which measures the diversity among top-k generated questions for each\ninstance while ensuring their relevance to the ground truth. Clearly, the\nsecond challenge is how to enhance diversifying question generation. To address\nthis challenge, we introduce a dual model framework interwoven by two selection\nstrategies to generate diverse questions leveraging external natural questions.\nThe main idea of our dual framework is to extract more diverse expressions and\nintegrate them into the generation model to enhance diversifying question\ngeneration. Extensive experiments on widely used benchmarks for KBQG\ndemonstrate that our proposed approach generates highly diverse questions and\nimproves the performance of question answering tasks.\n","authors":["Shasha Guo","Jing Zhang","Xirui Ke","Cuiping Li","Hong Chen"],"pdf_url":"https://arxiv.org/pdf/2309.14362v2.pdf","comment":"13 pages, 2 figures"},{"id":"http://arxiv.org/abs/2503.02368v1","updated":"2025-03-04T07:49:10Z","published":"2025-03-04T07:49:10Z","title":"Iterative Value Function Optimization for Guided Decoding","summary":"  While Reinforcement Learning from Human Feedback (RLHF) has become the\npredominant method for controlling language model outputs, it suffers from high\ncomputational costs and training instability. Guided decoding, especially\nvalue-guided methods, offers a cost-effective alternative by controlling\noutputs without re-training models. However, the accuracy of the value function\nis crucial for value-guided decoding, as inaccuracies can lead to suboptimal\ndecision-making and degraded performance. Existing methods struggle with\naccurately estimating the optimal value function, leading to less effective\ncontrol. We propose Iterative Value Function Optimization, a novel framework\nthat addresses these limitations through two key components: Monte Carlo Value\nEstimation, which reduces estimation variance by exploring diverse\ntrajectories, and Iterative On-Policy Optimization, which progressively\nimproves value estimation through collecting trajectories from value-guided\npolicies. Extensive experiments on text summarization, multi-turn dialogue, and\ninstruction following demonstrate the effectiveness of value-guided decoding\napproaches in aligning language models. These approaches not only achieve\nalignment but also significantly reduce computational costs by leveraging\nprincipled value function optimization for efficient and effective control.\n","authors":["Zhenhua Liu","Lijun Li","Ruizhe Chen","Yuxian Jiang","Tong Zhu","Wenliang Chen","Jing Shao"],"pdf_url":"https://arxiv.org/pdf/2503.02368v1.pdf","comment":"20 pages, 10 figures"},{"id":"http://arxiv.org/abs/2503.02365v1","updated":"2025-03-04T07:45:45Z","published":"2025-03-04T07:45:45Z","title":"EchoQA: A Large Collection of Instruction Tuning Data for Echocardiogram\n  Reports","summary":"  We introduce a novel question-answering (QA) dataset using echocardiogram\nreports sourced from the Medical Information Mart for Intensive Care database.\nThis dataset is specifically designed to enhance QA systems in cardiology,\nconsisting of 771,244 QA pairs addressing a wide array of cardiac abnormalities\nand their severity. We compare large language models (LLMs), including\nopen-source and biomedical-specific models for zero-shot evaluation, and\nclosed-source models for zero-shot and three-shot evaluation. Our results show\nthat fine-tuning LLMs improves performance across various QA metrics,\nvalidating the value of our dataset. Clinicians also qualitatively evaluate the\nbest-performing model to assess the LLM responses for correctness. Further, we\nconduct fine-grained fairness audits to assess the bias-performance trade-off\nof LLMs across various social determinants of health. Our objective is to\npropel the field forward by establishing a benchmark for LLM AI agents aimed at\nsupporting clinicians with cardiac differential diagnoses, thereby reducing the\ndocumentation burden that contributes to clinician burnout and enabling\nhealthcare professionals to focus more on patient care.\n","authors":["Lama Moukheiber","Mira Moukheiber","Dana Moukheiiber","Hyung-Chul Lee"],"pdf_url":"https://arxiv.org/pdf/2503.02365v1.pdf","comment":"NeurIPS SafeGenAI 2024"},{"id":"http://arxiv.org/abs/2503.02359v1","updated":"2025-03-04T07:32:41Z","published":"2025-03-04T07:32:41Z","title":"Add-One-In: Incremental Sample Selection for Large Language Models via a\n  Choice-Based Greedy Paradigm","summary":"  Selecting high-quality and diverse training samples from extensive datasets\nplays a crucial role in reducing training overhead and enhancing the\nperformance of Large Language Models (LLMs). However, existing studies fall\nshort in assessing the overall value of selected data, focusing primarily on\nindividual quality, and struggle to strike an effective balance between\nensuring diversity and minimizing data point traversals. Therefore, this paper\nintroduces a novel choice-based sample selection framework that shifts the\nfocus from evaluating individual sample quality to comparing the contribution\nvalue of different samples when incorporated into the subset. Thanks to the\nadvanced language understanding capabilities of LLMs, we utilize LLMs to\nevaluate the value of each option during the selection process. Furthermore, we\ndesign a greedy sampling process where samples are incrementally added to the\nsubset, thereby improving efficiency by eliminating the need for exhaustive\ntraversal of the entire dataset with the limited budget. Extensive experiments\ndemonstrate that selected data from our method not only surpass the performance\nof the full dataset but also achieves competitive results with state-of-the-art\n(SOTA) studies, while requiring fewer selections. Moreover, we validate our\napproach on a larger medical dataset, highlighting its practical applicability\nin real-world applications.\n","authors":["Zhuo Li","Yuhao Du","Xiaoqi Jiao","Yiwen Guo","Yuege Feng","Xiang Wan","Anningzhe Gao","Jinpeng Hu"],"pdf_url":"https://arxiv.org/pdf/2503.02359v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2501.05874v2","updated":"2025-03-04T07:29:52Z","published":"2025-01-10T11:17:15Z","title":"VideoRAG: Retrieval-Augmented Generation over Video Corpus","summary":"  Retrieval-Augmented Generation (RAG) is a powerful strategy for improving the\nfactual accuracy of models by retrieving external knowledge relevant to queries\nand incorporating it into the generation process. However, existing approaches\nprimarily focus on text, with some recent advancements considering images, and\nthey largely overlook videos, a rich source of multimodal knowledge capable of\nrepresenting contextual details more effectively than any other modality. While\nvery recent studies explore the use of videos in response generation, they\neither predefine query-associated videos without retrieval or convert videos\ninto textual descriptions losing multimodal richness. To tackle these, we\nintroduce VideoRAG, a framework that not only dynamically retrieves videos\nbased on their relevance with queries but also utilizes both visual and textual\ninformation. The operation of VideoRAG is powered by recent Large Video\nLanguage Models (LVLMs), which enable the direct processing of video content to\nrepresent it for retrieval and the seamless integration of retrieved videos\njointly with queries for response generation. Also, inspired by that the\ncontext size of LVLMs may not be sufficient to process all frames in extremely\nlong videos and not all frames are equally important, we introduce a video\nframe selection mechanism to extract the most informative subset of frames,\nalong with a strategy to extract textual information from videos (as it can aid\nthe understanding of video content) when their subtitles are not available. We\nexperimentally validate the effectiveness of VideoRAG, showcasing that it is\nsuperior to relevant baselines. Code is available at\nhttps://github.com/starsuzi/VideoRAG.\n","authors":["Soyeong Jeong","Kangsan Kim","Jinheon Baek","Sung Ju Hwang"],"pdf_url":"https://arxiv.org/pdf/2501.05874v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.02358v1","updated":"2025-03-04T07:29:03Z","published":"2025-03-04T07:29:03Z","title":"Are Large Vision Language Models Good Game Players?","summary":"  Large Vision Language Models (LVLMs) have demonstrated remarkable abilities\nin understanding and reasoning about both visual and textual information.\nHowever, existing evaluation methods for LVLMs, primarily based on benchmarks\nlike Visual Question Answering and image captioning, often fail to capture the\nfull scope of LVLMs' capabilities. These benchmarks are limited by issues such\nas inadequate assessment of detailed visual perception, data contamination, and\na lack of focus on multi-turn reasoning. To address these challenges, we\npropose \\method{}, a game-based evaluation framework designed to provide a\ncomprehensive assessment of LVLMs' cognitive and reasoning skills in structured\nenvironments. \\method{} uses a set of games to evaluate LVLMs on four core\ntasks: Perceiving, Question Answering, Rule Following, and End-to-End Playing,\nwith each target task designed to assess specific abilities, including visual\nperception, reasoning, decision-making, etc. Based on this framework, we\nconduct extensive experiments that explore the limitations of current LVLMs,\nsuch as handling long structured outputs and perceiving detailed and dense\nelements. Code and data are publicly available at\nhttps://github.com/xinke-wang/LVLM-Playground.\n","authors":["Xinyu Wang","Bohan Zhuang","Qi Wu"],"pdf_url":"https://arxiv.org/pdf/2503.02358v1.pdf","comment":"ICLR2025"},{"id":"http://arxiv.org/abs/2410.22839v2","updated":"2025-03-04T07:13:20Z","published":"2024-10-30T09:18:31Z","title":"Danoliteracy of Generative Large Language Models","summary":"  The language technology moonshot moment of Generative Large Language Models\n(GLLMs) was not limited to English: These models brought a surge of\ntechnological applications, investments, and hype to low-resource languages as\nwell. However, the capabilities of these models in languages such as Danish\nwere, until recently, difficult to verify beyond qualitative demonstrations due\nto a lack of applicable evaluation corpora. We present a GLLM benchmark to\nevaluate \\emph{Danoliteracy}, a measure of Danish language and cultural\ncompetency across eight diverse scenarios such as Danish citizenship tests and\nabstractive social media question answering. This limited-size benchmark was\nfound to produce a robust ranking that correlates to human feedback at $\\rho\n\\sim 0.8$ with GPT-4 and Claude Opus models achieving the highest rankings.\nAnalyzing these model results across scenarios, we find one strong underlying\nfactor explaining $95\\%$ of scenario performance variance for GLLMs in Danish,\nsuggesting a $g$ factor of model consistency in language adaptation.\n","authors":["Sren Vejlgaard Holm","Lars Kai Hansen","Martin Carsten Nielsen"],"pdf_url":"https://arxiv.org/pdf/2410.22839v2.pdf","comment":"16 pages, 13 figures, Accepted to NoDaLiDa/Baltic-HLT 2025"},{"id":"http://arxiv.org/abs/2503.02343v1","updated":"2025-03-04T07:07:17Z","published":"2025-03-04T07:07:17Z","title":"DeLTa: A Decoding Strategy based on Logit Trajectory Prediction Improves\n  Factuality and Reasoning Ability","summary":"  Large Language Models (LLMs) are increasingly being used in real-world\napplications. However, concerns about the reliability of the content they\ngenerate persist, as it frequently deviates from factual correctness or\nexhibits deficiencies in logical reasoning. This paper proposes a novel\ndecoding strategy aimed at enhancing both factual accuracy and inferential\nreasoning without requiring any modifications to the architecture or\npre-trained parameters of LLMs. Our approach adjusts next-token probabilities\nby analyzing the trajectory of logits from lower to higher layers in\nTransformers and applying linear regression. We find that this Decoding by\nLogit Trajectory-based approach (DeLTa) effectively reinforces factuality and\nreasoning while mitigating incorrect generation. Experiments on TruthfulQA\ndemonstrate that DeLTa attains up to a 4.9% improvement over the baseline.\nFurthermore, it enhances performance by up to 8.1% on StrategyQA and 7.3% on\nGSM8K, both of which demand strong reasoning capabilities.\n","authors":["Yunzhen He","Yusuke Takase","Yoichi Ishibashi","Hidetoshi Shimodaira"],"pdf_url":"https://arxiv.org/pdf/2503.02343v1.pdf","comment":"Source code is available at https://github.com/githubhyz/DeLTa"},{"id":"http://arxiv.org/abs/2410.09418v2","updated":"2025-03-04T07:06:43Z","published":"2024-10-12T07:54:01Z","title":"Beyond Exact Match: Semantically Reassessing Event Extraction by Large\n  Language Models","summary":"  Event extraction has gained extensive research attention due to its broad\nrange of applications. However, the current mainstream evaluation method for\nevent extraction relies on token-level exact match, which misjudges numerous\nsemantic-level correct cases. This reliance leads to a significant discrepancy\nbetween the evaluated performance of models under exact match criteria and\ntheir real performance. To address this problem, we propose a reliable and\nsemantic evaluation framework for event extraction, named RAEE, which\naccurately assesses extraction results at semantic-level instead of\ntoken-level. Specifically, RAEE leverages large language models (LLMs) as\nevaluation agents, incorporating an adaptive mechanism to achieve adaptive\nevaluations for precision and recall of triggers and arguments. Extensive\nexperiments demonstrate that: (1) RAEE achieves a very strong correlation with\nhuman judgments; (2) after reassessing 14 models, including advanced LLMs, on\n10 datasets, there is a significant performance gap between exact match and\nRAEE. The exact match evaluation significantly underestimates the performance\nof existing event extraction models, and in particular underestimates the\ncapabilities of LLMs; (3) fine-grained analysis under RAEE evaluation reveals\ninsightful phenomena worth further exploration. The evaluation toolkit of our\nproposed RAEE is publicly released.\n","authors":["Yi-Fan Lu","Xian-Ling Mao","Tian Lan","Heyan Huang","Chen Xu","Xiaoyan Gao"],"pdf_url":"https://arxiv.org/pdf/2410.09418v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2406.16135v2","updated":"2025-03-04T07:00:10Z","published":"2024-06-23T15:15:17Z","title":"Crosslingual Capabilities and Knowledge Barriers in Multilingual Large\n  Language Models","summary":"  Large language models (LLMs) are typically multilingual due to pretraining on\ndiverse multilingual corpora. But can these models relate corresponding\nconcepts across languages, i.e., be crosslingual? This study evaluates\nstate-of-the-art LLMs on inherently crosslingual tasks. We observe that while\nthese models show promising surface-level crosslingual abilities on machine\ntranslation and embedding space analyses, they struggle with deeper\ncrosslingual knowledge transfer, revealing a crosslingual knowledge barrier in\nboth general (MMLU benchmark) and domain-specific (Harry Potter quiz and TOFU\nbenchmark) contexts. Since simple inference-time mitigation methods offer only\nlimited improvement, we propose fine-tuning of LLMs on mixed-language data,\nwhich effectively reduces these gaps, even when using out-of-domain datasets\nlike WikiText. Our findings suggest the need for explicit optimization to\nunlock the full crosslingual potential of LLMs. Our code is publicly available\nat https://github.com/google-research/crosslingual-knowledge-barriers.\n","authors":["Lynn Chua","Badih Ghazi","Yangsibo Huang","Pritish Kamath","Ravi Kumar","Pasin Manurangsi","Amer Sinha","Chulin Xie","Chiyuan Zhang"],"pdf_url":"https://arxiv.org/pdf/2406.16135v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2502.18168v4","updated":"2025-03-04T06:59:18Z","published":"2025-02-25T13:00:05Z","title":"SECURA: Sigmoid-Enhanced CUR Decomposition with Uninterrupted Retention\n  and Low-Rank Adaptation in Large Language Models","summary":"  With the rapid development of large language models (LLMs), fully fine-tuning\n(FT) these models is becoming increasingly infeasible due to high computational\ndemands. Moreover, FT also increases the risk of catastrophic forgetting. As an\nalternative, Low-Rank Adaptation (LoRA) has been proposed. By fine-tuning only\na small subset of parameters, LoRA achieves performance similar to FT while\nsignificantly reducing resource requirements. However, since LoRA inherits FT's\ndesign, the issue of catastrophic forgetting still remains. To address these\nlimitations, we propose SECURA: Sigmoid-Enhanced CUR Decomposition LoRA, a\nnovel PEFT variant designed to mitigate catastrophic forgetting while improving\nfine-tuning performance. Our method introduces a novel normalization technique,\nSigmoid-based Magnitude Norm (S-MagNorm), which enhances parameter retention\nand fine-tuning efficiency. SECURA has been evaluated on a diverse range of\ntasks, including mathematical problem-solving (GSM8K), complex\nquestion-answering (CNNDM), translation (NewsDE), and complex multiple-choice\nreasoning (LogiQA). Experimental results demonstrate that it achieves an\naverage fine-tuning improvement of 3.59% across four MCQ tasks and 2.51% across\nfive QA tasks on Gemma2 2B, Qwen2 1.5B, Qwen2 7B, Llama3 8B, and Llama3.1 8B,\noutperforming DoRA. Additionally, SECURA demonstrates superior knowledge\nretention capabilities, achieving state-of-the-art performance in 16 continual\nlearning tests and maintaining more than 70% accuracy on LLMs' basic knowledge\ncompared to Experience Replay (ER), sequential learning (SEQ), EWC, I-LoRA, and\nCUR-LoRA.\n","authors":["Yuxuan Zhang"],"pdf_url":"https://arxiv.org/pdf/2502.18168v4.pdf","comment":"New work on PEFT for LLMs, introducing S-MagNorm and CABR-LoRA to\n  enhance fine-tuning performance and knowledge retention. In v4, we renamed\n  Sigmoid-based Magnitude Normalization to S-MagNorm for clarity and added a\n  gradient comparison between SECURA and CABR-LoRA to highlight their\n  contributions"},{"id":"http://arxiv.org/abs/2503.02335v1","updated":"2025-03-04T06:48:45Z","published":"2025-03-04T06:48:45Z","title":"Unlocking a New Rust Programming Experience: Fast and Slow Thinking with\n  LLMs to Conquer Undefined Behaviors","summary":"  To provide flexibility and low-level interaction capabilities, the unsafe tag\nin Rust is essential in many projects, but undermines memory safety and\nintroduces Undefined Behaviors (UBs) that reduce safety. Eliminating these UBs\nrequires a deep understanding of Rust's safety rules and strong typing.\nTraditional methods require depth analysis of code, which is laborious and\ndepends on knowledge design. The powerful semantic understanding capabilities\nof LLM offer new opportunities to solve this problem. Although existing large\nmodel debugging frameworks excel in semantic tasks, limited by fixed processes\nand lack adaptive and dynamic adjustment capabilities. Inspired by the dual\nprocess theory of decision-making (Fast and Slow Thinking), we present a\nLLM-based framework called RustBrain that automatically and flexibly minimizes\nUBs in Rust projects. Fast thinking extracts features to generate solutions,\nwhile slow thinking decomposes, verifies, and generalizes them abstractly. To\napply verification and generalization results to solution generation, enabling\ndynamic adjustments and precise outputs, RustBrain integrates two thinking\nthrough a feedback mechanism. Experimental results on Miri dataset show a 94.3%\npass rate and 80.4% execution rate, improving flexibility and Rust projects\nsafety.\n","authors":["Renshuang Jiang","Pan Dong","Zhenling Duan","Yu Shi","Xiaoxiang Fang","Yan Ding","Jun Ma","Shuai Zhao","Zhe Jiang"],"pdf_url":"https://arxiv.org/pdf/2503.02335v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2502.10868v2","updated":"2025-03-04T06:45:23Z","published":"2025-02-15T17:52:14Z","title":"NitiBench: A Comprehensive Studies of LLM Frameworks Capabilities for\n  Thai Legal Question Answering","summary":"  The application of large language models (LLMs) in the legal domain holds\nsignificant potential for information retrieval and question answering, yet\nThai legal QA systems face challenges due to a lack of standardized evaluation\nbenchmarks and the complexity of Thai legal structures. This paper introduces\nNitiBench, a benchmark comprising two datasets: the NitiBench-CCL, covering\ngeneral Thai financial law, and the NitiBench-Tax, which includes real-world\ntax law cases requiring advanced legal reasoning. We evaluate\nretrieval-augmented generation (RAG) and long-context LLM-based approaches to\naddress three key research questions: the impact of domain-specific components\nlike section-based chunking and cross-referencing, the comparative performance\nof different retrievers and LLMs, and the viability of long-context LLMs as an\nalternative to RAG. Our results show that section-based chunking significantly\nimproves retrieval and end-to-end performance, current retrievers struggle with\ncomplex queries, and long-context LLMs still underperform RAG-based systems in\nThai legal QA. To support fair evaluation, we propose tailored multi-label\nretrieval metrics and the use of an LLM-as-judge for coverage and contradiction\ndetection method. These findings highlight the limitations of current Thai\nlegal NLP solutions and provide a foundation for future research in the field.\nWe also open-sourced our codes and dataset to available publicly.\n","authors":["Pawitsapak Akarajaradwong","Pirat Pothavorn","Chompakorn Chaksangchaichot","Panuthep Tasawong","Thitiwat Nopparatbundit","Sarana Nutanong"],"pdf_url":"https://arxiv.org/pdf/2502.10868v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.02333v1","updated":"2025-03-04T06:45:17Z","published":"2025-03-04T06:45:17Z","title":"Examining the Mental Health Impact of Misinformation on Social Media\n  Using a Hybrid Transformer-Based Approach","summary":"  Social media has significantly reshaped interpersonal communication,\nfostering connectivity while also enabling the proliferation of misinformation.\nThe unchecked spread of false narratives has profound effects on mental health,\ncontributing to increased stress, anxiety, and misinformation-driven paranoia.\nThis study presents a hybrid transformer-based approach using a RoBERTa-LSTM\nclassifier to detect misinformation, assess its impact on mental health, and\nclassify disorders linked to misinformation exposure. The proposed models\ndemonstrate accuracy rates of 98.4, 87.8, and 77.3 in detecting misinformation,\nmental health implications, and disorder classification, respectively.\nFurthermore, Pearson's Chi-Squared Test for Independence (p-value = 0.003871)\nvalidates the direct correlation between misinformation and deteriorating\nmental well-being. This study underscores the urgent need for better\nmisinformation management strategies to mitigate its psychological\nrepercussions. Future research could explore broader datasets incorporating\nlinguistic, demographic, and cultural variables to deepen the understanding of\nmisinformation-induced mental health distress.\n","authors":["Sarvesh Arora","Sarthak Arora","Deepika Kumar","Vallari Agrawal","Vedika Gupta","Dipit Vasdev"],"pdf_url":"https://arxiv.org/pdf/2503.02333v1.pdf","comment":"20 pages"},{"id":"http://arxiv.org/abs/2503.02328v1","updated":"2025-03-04T06:38:29Z","published":"2025-03-04T06:38:29Z","title":"Limited Effectiveness of LLM-based Data Augmentation for COVID-19\n  Misinformation Stance Detection","summary":"  Misinformation surrounding emerging outbreaks poses a serious societal\nthreat, making robust countermeasures essential. One promising approach is\nstance detection (SD), which identifies whether social media posts support or\noppose misleading claims. In this work, we finetune classifiers on COVID-19\nmisinformation SD datasets consisting of claims and corresponding tweets.\nSpecifically, we test controllable misinformation generation (CMG) using large\nlanguage models (LLMs) as a method for data augmentation. While CMG\ndemonstrates the potential for expanding training datasets, our experiments\nreveal that performance gains over traditional augmentation methods are often\nminimal and inconsistent, primarily due to built-in safeguards within LLMs. We\nrelease our code and datasets to facilitate further research on misinformation\ndetection and generation.\n","authors":["Eun Cheol Choi","Ashwin Balasubramanian","Jinhu Qi","Emilio Ferrara"],"pdf_url":"https://arxiv.org/pdf/2503.02328v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.02324v1","updated":"2025-03-04T06:32:30Z","published":"2025-03-04T06:32:30Z","title":"PromptCoT: Synthesizing Olympiad-level Problems for Mathematical\n  Reasoning in Large Language Models","summary":"  The ability of large language models to solve complex mathematical problems\nhas progressed significantly, particularly for tasks requiring advanced\nreasoning. However, the scarcity of sufficiently challenging problems,\nparticularly at the Olympiad level, hinders further advancements. In this work,\nwe introduce PromptCoT, a novel approach for automatically generating\nhigh-quality Olympiad-level math problems. The proposed method synthesizes\ncomplex problems based on mathematical concepts and the rationale behind\nproblem construction, emulating the thought processes of experienced problem\ndesigners. We provide a theoretical analysis demonstrating that an optimal\nrationale should maximize both the likelihood of rationale generation given the\nassociated concepts and the likelihood of problem generation conditioned on\nboth the rationale and the concepts. Our method is evaluated on standard\nbenchmarks including GSM8K, MATH-500, and AIME2024, where it consistently\noutperforms existing problem generation methods. Furthermore, we demonstrate\nthat PromptCoT exhibits superior data scalability, consistently maintaining\nhigh performance as the dataset size increases, outperforming the baselines.\nThe implementation is available at https://github.com/zhaoxlpku/PromptCoT.\n","authors":["Xueliang Zhao","Wei Wu","Jian Guan","Lingpeng Kong"],"pdf_url":"https://arxiv.org/pdf/2503.02324v1.pdf","comment":"Preprint"},{"id":"http://arxiv.org/abs/2412.17256v2","updated":"2025-03-04T06:29:50Z","published":"2024-12-23T03:58:34Z","title":"B-STaR: Monitoring and Balancing Exploration and Exploitation in\n  Self-Taught Reasoners","summary":"  In the absence of extensive human-annotated data for complex reasoning tasks,\nself-improvement -- where models are trained on their own outputs -- has\nemerged as a primary method for enhancing performance. However, the critical\nfactors underlying the mechanism of these iterative self-improving methods\nremain poorly understood, such as under what conditions self-improvement is\neffective, and what are the bottlenecks in the current iterations. In this\nwork, we identify and propose methods to monitor two pivotal factors in this\niterative process: (1) the model's ability to generate sufficiently diverse\nresponses (exploration); and (2) the effectiveness of external rewards in\ndistinguishing high-quality candidates from lower-quality ones (exploitation).\nUsing mathematical reasoning as a case study, we begin with a quantitative\nanalysis to track the dynamics of exploration and exploitation, discovering\nthat a model's exploratory capabilities rapidly deteriorate over iterations,\nand the effectiveness of exploiting external rewards diminishes as well.\nMotivated by these findings, we introduce B-STaR, a Self-Taught Reasoning\nframework that autonomously adjusts configurations across iterations to Balance\nexploration and exploitation, thereby optimizing the self-improving\neffectiveness based on the current policy model and available rewards. Our\nexperiments on mathematical reasoning, coding, and commonsense reasoning\ndemonstrate that B-STaR not only enhances the model's exploratory capabilities\nthroughout training but also achieves a more effective balance between\nexploration and exploitation, leading to superior performance.\n","authors":["Weihao Zeng","Yuzhen Huang","Lulu Zhao","Yijun Wang","Zifei Shan","Junxian He"],"pdf_url":"https://arxiv.org/pdf/2412.17256v2.pdf","comment":"Published as a conference paper at ICLR 2025"},{"id":"http://arxiv.org/abs/2410.03226v3","updated":"2025-03-04T06:28:21Z","published":"2024-10-04T08:26:06Z","title":"Frame-Voyager: Learning to Query Frames for Video Large Language Models","summary":"  Video Large Language Models (Video-LLMs) have made remarkable progress in\nvideo understanding tasks. However, they are constrained by the maximum length\nof input tokens, making it impractical to input entire videos. Existing frame\nselection approaches, such as uniform frame sampling and text-frame retrieval,\nfail to account for the information density variations in the videos or the\ncomplex instructions in the tasks, leading to sub-optimal performance. In this\npaper, we propose Frame-Voyager that learns to query informative frame\ncombinations, based on the given textual queries in the task. To train\nFrame-Voyager, we introduce a new data collection and labeling pipeline, by\nranking frame combinations using a pre-trained Video-LLM. Given a video of M\nframes, we traverse its T-frame combinations, feed them into a Video-LLM, and\nrank them based on Video-LLM's prediction losses. Using this ranking as\nsupervision, we train Frame-Voyager to query the frame combinations with lower\nlosses. In experiments, we evaluate Frame-Voyager on four Video Question\nAnswering benchmarks by plugging it into two different Video-LLMs. The\nexperimental results demonstrate that Frame-Voyager achieves impressive results\nin all settings, highlighting its potential as a plug-and-play solution for\nVideo-LLMs.\n","authors":["Sicheng Yu","Chengkai Jin","Huanyu Wang","Zhenghao Chen","Sheng Jin","Zhongrong Zuo","Xiaolei Xu","Zhenbang Sun","Bingni Zhang","Jiawei Wu","Hao Zhang","Qianru Sun"],"pdf_url":"https://arxiv.org/pdf/2410.03226v3.pdf","comment":"ICLR 2025, Camera-ready Version"},{"id":"http://arxiv.org/abs/2503.00032v2","updated":"2025-03-04T06:26:41Z","published":"2025-02-25T00:59:27Z","title":"Detecting LLM-Generated Korean Text through Linguistic Feature Analysis","summary":"  The rapid advancement of large language models (LLMs) increases the\ndifficulty of distinguishing between human-written and LLM-generated text.\nDetecting LLM-generated text is crucial for upholding academic integrity,\npreventing plagiarism, protecting copyrights, and ensuring ethical research\npractices. Most prior studies on detecting LLM-generated text focus primarily\non English text. However, languages with distinct morphological and syntactic\ncharacteristics require specialized detection approaches. Their unique\nstructures and usage patterns can hinder the direct application of methods\nprimarily designed for English. Among such languages, we focus on Korean, which\nhas relatively flexible spacing rules, a rich morphological system, and less\nfrequent comma usage compared to English. We introduce KatFish, the first\nbenchmark dataset for detecting LLM-generated Korean text. The dataset consists\nof text written by humans and generated by four LLMs across three genres.\n  By examining spacing patterns, part-of-speech diversity, and comma usage, we\nilluminate the linguistic differences between human-written and LLM-generated\nKorean text. Building on these observations, we propose KatFishNet, a detection\nmethod specifically designed for the Korean language. KatFishNet achieves an\naverage of 19.78% higher AUROC compared to the best-performing existing\ndetection method. Our code and data are available at\nhttps://github.com/Shinwoo-Park/detecting_llm_generated_korean_text_through_linguistic_analysis.\n","authors":["Shinwoo Park","Shubin Kim","Do-Kyung Kim","Yo-Sub Han"],"pdf_url":"https://arxiv.org/pdf/2503.00032v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.23123v2","updated":"2025-03-04T06:22:40Z","published":"2024-10-30T15:31:54Z","title":"On Memorization of Large Language Models in Logical Reasoning","summary":"  Large language models (LLMs) achieve good performance on challenging\nreasoning benchmarks, yet could also make basic reasoning mistakes. This\ncontrasting behavior is puzzling when it comes to understanding the mechanisms\nbehind LLMs' reasoning capabilities. One hypothesis is that the increasingly\nhigh and nearly saturated performance on common reasoning benchmarks could be\ndue to the memorization of similar problems. In this paper, we systematically\ninvestigate this hypothesis with a quantitative measurement of memorization in\nreasoning tasks, using a dynamically generated logical reasoning benchmark\nbased on Knights and Knaves (K&K) puzzles. We find that LLMs could interpolate\nand memorize the training puzzles (achieving near-perfect accuracy) after\nfine-tuning, yet they struggle with slight variations of these puzzles. On the\nother hand, we show that while fine-tuning leads to heavy memorization, it also\nconsistently improves generalization performance. Through in-depth analyses\nwith perturbation tests, cross difficulty-level transferability, probing model\ninternals, and fine-tuning with wrong answers, we establish that LLMs develop\nreasoning skills on K&K puzzles alongside memorization. Finally, our analysis\nbased on a per-sample memorization score sheds light on how LLMs switch between\nreasoning and memorization when solving logical puzzles. Our code and data are\navailable at https://memkklogic.github.io.\n","authors":["Chulin Xie","Yangsibo Huang","Chiyuan Zhang","Da Yu","Xinyun Chen","Bill Yuchen Lin","Bo Li","Badih Ghazi","Ravi Kumar"],"pdf_url":"https://arxiv.org/pdf/2410.23123v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.02318v1","updated":"2025-03-04T06:18:34Z","published":"2025-03-04T06:18:34Z","title":"Audio-Reasoner: Improving Reasoning Capability in Large Audio Language\n  Models","summary":"  Recent advancements in multimodal reasoning have largely overlooked the audio\nmodality. We introduce Audio-Reasoner, a large-scale audio language model for\ndeep reasoning in audio tasks. We meticulously curated a large-scale and\ndiverse multi-task audio dataset with simple annotations. Then, we leverage\nclosed-source models to conduct secondary labeling, QA generation, along with\nstructured COT process. These datasets together form a high-quality reasoning\ndataset with 1.2 million reasoning-rich samples, which we name CoTA. Following\ninference scaling principles, we train Audio-Reasoner on CoTA, enabling it to\nachieve great logical capabilities in audio reasoning. Experiments show\nstate-of-the-art performance across key benchmarks, including MMAU-mini\n(+25.42%), AIR-Bench chat/foundation(+14.57%/+10.13%), and MELD (+8.01%). Our\nfindings stress the core of structured CoT training in advancing audio\nreasoning.\n","authors":["Zhifei Xie","Mingbao Lin","Zihang Liu","Pengcheng Wu","Shuicheng Yan","Chunyan Miao"],"pdf_url":"https://arxiv.org/pdf/2503.02318v1.pdf","comment":"Technical report, in process"},{"id":"http://arxiv.org/abs/2503.00808v2","updated":"2025-03-04T06:15:27Z","published":"2025-03-02T09:21:28Z","title":"Predictive Data Selection: The Data That Predicts Is the Data That\n  Teaches","summary":"  Language model pretraining involves training on extensive corpora, where data\nquality plays a pivotal role. In this work, we aim to directly estimate the\ncontribution of data during pretraining and select pretraining data in an\nefficient manner. Specifically, we draw inspiration from recent findings\nshowing that compression efficiency (i.e., the normalized loss) of diverse\nmodels on certain text correlates strongly with their downstream performance,\nwhen the text domain aligns with the downstream benchmarks(Huang et al., 2024).\nBuilding on this observation, we hypothesize that data on which model losses\nare predictive of downstream abilities also contribute effectively to learning.\nTo leverage this insight, we introduce predictive data selection (PreSelect), a\nlightweight and efficient data selection method that requires training and\ndeploying only a fastText-based scorer. Through comprehensive experiments with\n1B and 3B parameter models, we demonstrate that models trained on 30B tokens\nselected with PreSelect surpass the performance of the vanilla baseline trained\non 300B tokens, achieving a 10x reduction in compute requirements. Furthermore,\nPreSelect significantly outperforms other competitive data selection baselines,\nsuch as DCLM and FineWeb-Edu on a scale of 3B models trained on 100B tokens. We\nopen-source our trained data selection scorer along with the curated datasets\nat https://github.com/hkust-nlp/PreSelect.\n","authors":["Kashun Shum","Yuzhen Huang","Hongjian Zou","Qi Ding","Yixuan Liao","Xiaoxin Chen","Qian Liu","Junxian He"],"pdf_url":"https://arxiv.org/pdf/2503.00808v2.pdf","comment":"21 pages"},{"id":"http://arxiv.org/abs/2410.13509v2","updated":"2025-03-04T06:12:01Z","published":"2024-10-17T12:53:29Z","title":"RAG-DDR: Optimizing Retrieval-Augmented Generation Using Differentiable\n  Data Rewards","summary":"  Retrieval-Augmented Generation (RAG) has proven its effectiveness in\nmitigating hallucinations in Large Language Models (LLMs) by retrieving\nknowledge from external resources. To adapt LLMs for the RAG systems, current\napproaches use instruction tuning to optimize LLMs, improving their ability to\nutilize retrieved knowledge. This supervised fine-tuning (SFT) approach focuses\non equipping LLMs to handle diverse RAG tasks using different instructions.\nHowever, it trains RAG modules to overfit training signals and overlooks the\nvarying data preferences among agents within the RAG system. In this paper, we\npropose a Differentiable Data Rewards (DDR) method, which end-to-end trains RAG\nsystems by aligning data preferences between different RAG modules. DDR works\nby collecting the rewards to optimize each agent in the RAG system with the\nrollout method, which prompts agents to sample some potential responses as\nperturbations, evaluates the impact of these perturbations on the whole RAG\nsystem, and subsequently optimizes the agent to produce outputs that improve\nthe performance of the RAG system. Our experiments on various\nknowledge-intensive tasks demonstrate that DDR significantly outperforms the\nSFT method, particularly for LLMs with smaller-scale parameters that depend\nmore on the retrieved knowledge. Additionally, DDR exhibits a stronger\ncapability to align the data preference between RAG modules. The DDR method\nmakes the generation module more effective in extracting key information from\ndocuments and mitigating conflicts between parametric memory and external\nknowledge. All codes are available at https://github.com/OpenMatch/RAG-DDR.\n","authors":["Xinze Li","Sen Mei","Zhenghao Liu","Yukun Yan","Shuo Wang","Shi Yu","Zheni Zeng","Hao Chen","Ge Yu","Zhiyuan Liu","Maosong Sun","Chenyan Xiong"],"pdf_url":"https://arxiv.org/pdf/2410.13509v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2407.17773v2","updated":"2025-03-04T05:20:59Z","published":"2024-07-25T05:02:39Z","title":"KiVA: Kid-inspired Visual Analogies for Testing Large Multimodal Models","summary":"  This paper investigates visual analogical reasoning in large multimodal\nmodels (LMMs) compared to human adults and children. A \"visual analogy\" is an\nabstract rule inferred from one image and applied to another. While benchmarks\nexist for testing visual reasoning in LMMs, they require advanced skills and\nomit basic visual analogies that even young children can make. Inspired by\ndevelopmental psychology, we propose a new benchmark of 4,300 visual\ntransformations of everyday objects to test LMMs on visual analogical reasoning\nand compare them to children (ages three to five) and to adults. We structure\nthe evaluation into three stages: identifying what changed (e.g., color,\nnumber, etc.), how it changed (e.g., added one object), and applying the rule\nto new scenarios. Our findings show that while GPT-o1, GPT-4V, LLaVA-1.5, and\nMANTIS identify the \"what\" effectively, they struggle with quantifying the\n\"how\" and extrapolating this rule to new objects. In contrast, children and\nadults exhibit much stronger analogical reasoning at all three stages.\nAdditionally, the strongest tested model, GPT-o1, performs better in tasks\ninvolving simple surface-level visual attributes like color and size,\ncorrelating with quicker human adult response times. Conversely, more complex\ntasks such as number, rotation, and reflection, which necessitate extensive\ncognitive processing and understanding of extrinsic spatial properties in the\nphysical world, present more significant challenges. Altogether, these findings\nhighlight the limitations of training models on data that primarily consists of\n2D images and text.\n","authors":["Eunice Yiu","Maan Qraitem","Charlie Wong","Anisa Noor Majhi","Yutong Bai","Shiry Ginosar","Alison Gopnik","Kate Saenko"],"pdf_url":"https://arxiv.org/pdf/2407.17773v2.pdf","comment":"10 pages. For the KiVA benchmark, see https://github.com/ey242/KiVA"},{"id":"http://arxiv.org/abs/2502.04342v2","updated":"2025-03-04T05:13:07Z","published":"2025-02-03T06:43:12Z","title":"Tutorial on Using Machine Learning and Deep Learning Models for Mental\n  Illness Detection","summary":"  Social media has become an important source for understanding mental health,\nproviding researchers with a way to detect conditions like depression from\nuser-generated posts. This tutorial provides practical guidance to address\ncommon challenges in applying machine learning and deep learning methods for\nmental health detection on these platforms. It focuses on strategies for\nworking with diverse datasets, improving text preprocessing, and addressing\nissues such as imbalanced data and model evaluation. Real-world examples and\nstep-by-step instructions demonstrate how to apply these techniques\neffectively, with an emphasis on transparency, reproducibility, and ethical\nconsiderations. By sharing these approaches, this tutorial aims to help\nresearchers build more reliable and widely applicable models for mental health\nresearch, contributing to better tools for early detection and intervention.\n","authors":["Yeyubei Zhang","Zhongyan Wang","Zhanyi Ding","Yexin Tian","Jianglai Dai","Xiaorui Shen","Yunchong Liu","Yuchen Cao"],"pdf_url":"https://arxiv.org/pdf/2502.04342v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2412.15267v3","updated":"2025-03-04T04:49:58Z","published":"2024-12-17T05:04:57Z","title":"Toxicity Detection towards Adaptability to Changing Perturbations","summary":"  Toxicity detection is crucial for maintaining the peace of the society. While\nexisting methods perform well on normal toxic contents or those generated by\nspecific perturbation methods, they are vulnerable to evolving perturbation\npatterns. However, in real-world scenarios, malicious users tend to create new\nperturbation patterns for fooling the detectors. For example, some users may\ncircumvent the detector of large language models (LLMs) by adding `I am a\nscientist' at the beginning of the prompt. In this paper, we introduce a novel\nproblem, i.e., continual learning jailbreak perturbation patterns, into the\ntoxicity detection field. To tackle this problem, we first construct a new\ndataset generated by 9 types of perturbation patterns, 7 of them are summarized\nfrom prior work and 2 of them are developed by us. We then systematically\nvalidate the vulnerability of current methods on this new perturbation\npattern-aware dataset via both the zero-shot and fine tuned cross-pattern\ndetection. Upon this, we present the domain incremental learning paradigm and\nthe corresponding benchmark to ensure the detector's robustness to dynamically\nemerging types of perturbed toxic text. Our code and dataset are provided in\nthe appendix and will be publicly available at GitHub, by which we wish to\noffer new research opportunities for the security-relevant communities.\n","authors":["Hankun Kang","Jianhao Chen","Yongqi Li","Xin Miao","Mayi Xu","Ming Zhong","Yuanyuan Zhu","Tieyun Qian"],"pdf_url":"https://arxiv.org/pdf/2412.15267v3.pdf","comment":"There are still some flaws in the uploaded content, which may cause\n  confusion for readers. To be rigorous, we need to retract the paper for\n  optimization and improvement"},{"id":"http://arxiv.org/abs/2503.02255v1","updated":"2025-03-04T04:09:10Z","published":"2025-03-04T04:09:10Z","title":"AxBERT: An Interpretable Chinese Spelling Correction Method Driven by\n  Associative Knowledge Network","summary":"  Deep learning has shown promising performance on various machine learning\ntasks. Nevertheless, the uninterpretability of deep learning models severely\nrestricts the usage domains that require feature explanations, such as text\ncorrection. Therefore, a novel interpretable deep learning model (named AxBERT)\nis proposed for Chinese spelling correction by aligning with an associative\nknowledge network (AKN). Wherein AKN is constructed based on the co-occurrence\nrelations among Chinese characters, which denotes the interpretable statistic\nlogic contrasted with uninterpretable BERT logic. And a translator matrix\nbetween BERT and AKN is introduced for the alignment and regulation of the\nattention component in BERT. In addition, a weight regulator is designed to\nadjust the attention distributions in BERT to appropriately model the sentence\nsemantics. Experimental results on SIGHAN datasets demonstrate that AxBERT can\nachieve extraordinary performance, especially upon model precision compared to\nbaselines. Our interpretable analysis, together with qualitative reasoning, can\neffectively illustrate the interpretability of AxBERT.\n","authors":["Fanyu Wang","Hangyu Zhu","Zhenping Xie"],"pdf_url":"https://arxiv.org/pdf/2503.02255v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2406.18678v2","updated":"2025-03-04T03:45:47Z","published":"2024-06-26T18:29:12Z","title":"Few-shot Personalization of LLMs with Mis-aligned Responses","summary":"  As the diversity of users increases, the capability of providing personalized\nresponses by large language models (LLMs) has become increasingly important.\nExisting approaches have only limited successes in LLM personalization, due to\nthe absence of personalized learning or the reliance on shared personal data.\nThis paper proposes a new approach for a few-shot personalization of LLMs with\ntheir mis-aligned responses (Fermi). Our key idea is to learn a set of\npersonalized prompts for each user by progressively improving the prompts using\nLLMs, based on user profile (e.g., demographic information) and a few examples\nof previous opinions. During an iterative process of prompt improvement, we\nincorporate the contexts of mis-aligned responses by LLMs, which are especially\ncrucial for the effective personalization of LLMs. In addition, we develop an\neffective inference method to further leverage the context of the test query\nand the personalized prompts. Our experimental results demonstrate that Fermi\nsignificantly improves performance across various benchmarks, compared to\nbest-performing baselines.\n","authors":["Jaehyung Kim","Yiming Yang"],"pdf_url":"https://arxiv.org/pdf/2406.18678v2.pdf","comment":"NAACL 25 (main, long), 32 pages"},{"id":"http://arxiv.org/abs/2503.02240v1","updated":"2025-03-04T03:30:56Z","published":"2025-03-04T03:30:56Z","title":"OmniSQL: Synthesizing High-quality Text-to-SQL Data at Scale","summary":"  Text-to-SQL, the task of translating natural language questions into SQL\nqueries, plays a crucial role in enabling non-experts to interact with\ndatabases. While recent advancements in large language models (LLMs) have\nsignificantly enhanced text-to-SQL performance, existing approaches face\nnotable limitations in real-world text-to-SQL applications. Prompting-based\nmethods often depend on closed-source LLMs, which are expensive, raise privacy\nconcerns, and lack customization. Fine-tuning-based methods, on the other hand,\nsuffer from poor generalizability due to the limited coverage of publicly\navailable training data. To overcome these challenges, we propose a novel and\nscalable text-to-SQL data synthesis framework for automatically synthesizing\nlarge-scale, high-quality, and diverse datasets without extensive human\nintervention. Using this framework, we introduce SynSQL-2.5M, the first\nmillion-scale text-to-SQL dataset, containing 2.5 million samples spanning over\n16,000 synthetic databases. Each sample includes a database, SQL query, natural\nlanguage question, and chain-of-thought (CoT) solution. Leveraging SynSQL-2.5M,\nwe develop OmniSQL, a powerful open-source text-to-SQL model available in three\nsizes: 7B, 14B, and 32B. Extensive evaluations across nine datasets demonstrate\nthat OmniSQL achieves state-of-the-art performance, matching or surpassing\nleading closed-source and open-source LLMs, including GPT-4o and DeepSeek-V3,\ndespite its smaller size. We release all code, datasets, and models to support\nfurther research.\n","authors":["Haoyang Li","Shang Wu","Xiaokang Zhang","Xinmei Huang","Jing Zhang","Fuxin Jiang","Shuai Wang","Tieying Zhang","Jianjun Chen","Rui Shi","Hong Chen","Cuiping Li"],"pdf_url":"https://arxiv.org/pdf/2503.02240v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.02238v1","updated":"2025-03-04T03:27:02Z","published":"2025-03-04T03:27:02Z","title":"Haste Makes Waste: Evaluating Planning Abilities of LLMs for Efficient\n  and Feasible Multitasking with Time Constraints Between Actions","summary":"  While Large Language Model-based agents have demonstrated substantial\nprogress in task completion, existing evaluation benchmarks tend to\noveremphasize single-task performance, with insufficient attention given to the\ncrucial aspects of multitask planning and execution efficiency required in\nreal-world scenarios. To bridge this gap, we present Recipe2Plan, a novel\nbenchmark framework based on real-world cooking scenarios. Unlike conventional\nbenchmarks, Recipe2Plan challenges agents to optimize cooking time through\nparallel task execution while respecting temporal constraints i.e. specific\nactions need to be performed within a particular time intervals following the\npreceding steps. Overly aggressive local parallelization may disrupt this\nconstraint, potentially compromising the entire cooking process. This strict\ntime constraint between actions raises a unique challenge for agents to balance\nbetween maximizing concurrent operations and adhering to critical timing\nconstraints. Extensive experiments with state-of-the-art models reveal\nchallenges in maintaining this balance between efficiency and feasibility. The\nresults highlight the need for improved temporal awareness and global\nmultitasking capabilities in large language models. We open-source our\nbenchmark and code at https://github.com/WilliamZR/Recipe2Plan.\n","authors":["Zirui Wu","Xiao Liu","Jiayi Li","Lingpeng Kong","Yansong Feng"],"pdf_url":"https://arxiv.org/pdf/2503.02238v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.02233v1","updated":"2025-03-04T03:16:02Z","published":"2025-03-04T03:16:02Z","title":"Enhancing LLM Reliability via Explicit Knowledge Boundary Modeling","summary":"  Large language models (LLMs) frequently hallucinate due to misaligned\nself-awareness, generating erroneous outputs when addressing queries beyond\ntheir knowledge boundaries. While existing approaches mitigate hallucinations\nvia uncertainty estimation or query rejection, they suffer from computational\ninefficiency or sacrificed helpfulness. To address these issues, we propose the\nExplicit Knowledge Boundary Modeling (EKBM) framework, integrating fast and\nslow reasoning systems to harmonize reliability and usability. The framework\nfirst employs a fast-thinking model to generate confidence-labeled responses,\nenabling immediate use of high-confidence outputs. For uncertain predictions, a\nslow refinement model conducts targeted reasoning to improve accuracy. To align\nmodel behavior with our proposed object, we propose a hybrid training pipeline,\nenhancing self-awareness without degrading task performance. Evaluations on\ndialogue state tracking tasks demonstrate that EKBM achieves superior model\nreliability over uncertainty-based baselines. Further analysis reveals that\nrefinement substantially boosts accuracy while maintaining low computational\noverhead. Our work establishes a scalable paradigm for advancing LLM\nreliability and balancing accuracy and practical utility in error-sensitive\napplications.\n","authors":["Hang Zheng","Hongshen Xu","Yuncong Liu","Lu Chen","Pascale Fung","Kai Yu"],"pdf_url":"https://arxiv.org/pdf/2503.02233v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.19340v2","updated":"2025-03-04T03:06:30Z","published":"2024-03-28T11:57:08Z","title":"Dataverse: Open-Source ETL (Extract, Transform, Load) Pipeline for Large\n  Language Models","summary":"  To address the challenges associated with data processing at scale, we\npropose Dataverse, a unified open-source Extract-Transform-Load (ETL) pipeline\nfor large language models (LLMs) with a user-friendly design at its core. Easy\naddition of custom processors with block-based interface in Dataverse allows\nusers to readily and efficiently use Dataverse to build their own ETL pipeline.\nWe hope that Dataverse will serve as a vital tool for LLM development and open\nsource the entire library to welcome community contribution. Additionally, we\nprovide a concise, two-minute video demonstration of our system, illustrating\nits capabilities and implementation.\n","authors":["Hyunbyung Park","Sukyung Lee","Gyoungjin Gim","Yungi Kim","Dahyun Kim","Chanjun Park"],"pdf_url":"https://arxiv.org/pdf/2403.19340v2.pdf","comment":"Accepted to NAACL 2025 Demo"},{"id":"http://arxiv.org/abs/2411.18711v2","updated":"2025-03-04T03:01:25Z","published":"2024-11-27T19:32:03Z","title":"Evaluating Vision-Language Models as Evaluators in Path Planning","summary":"  Despite their promise to perform complex reasoning, large language models\n(LLMs) have been shown to have limited effectiveness in end-to-end planning.\nThis has inspired an intriguing question: if these models cannot plan well, can\nthey still contribute to the planning framework as a helpful plan evaluator? In\nthis work, we generalize this question to consider LLMs augmented with visual\nunderstanding, i.e., Vision-Language Models (VLMs). We introduce PathEval, a\nnovel benchmark evaluating VLMs as plan evaluators in complex path-planning\nscenarios. Succeeding in the benchmark requires a VLM to be able to abstract\ntraits of optimal paths from the scenario description, demonstrate precise\nlow-level perception on each path, and integrate this information to decide the\nbetter path. Our analysis of state-of-the-art VLMs reveals that these models\nface significant challenges on the benchmark. We observe that the VLMs can\nprecisely abstract given scenarios to identify the desired traits and exhibit\nmixed performance in integrating the provided information. Yet, their vision\ncomponent presents a critical bottleneck, with models struggling to perceive\nlow-level details about a path. Our experimental results show that this issue\ncannot be trivially addressed via end-to-end fine-tuning; rather, task-specific\ndiscriminative adaptation of these vision encoders is needed for these VLMs to\nbecome effective path evaluators.\n","authors":["Mohamed Aghzal","Xiang Yue","Erion Plaku","Ziyu Yao"],"pdf_url":"https://arxiv.org/pdf/2411.18711v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2502.19747v2","updated":"2025-03-04T02:42:56Z","published":"2025-02-27T04:20:47Z","title":"HaLoRA: Hardware-aware Low-Rank Adaptation for Large Language Models\n  Based on Hybrid Compute-in-Memory Architecture","summary":"  Low-rank adaptation (LoRA) is a predominant parameter-efficient finetuning\nmethod to adapt large language models (LLMs) for downstream tasks. In this\npaper, we first propose to deploy the LoRA-finetuned LLMs on the hybrid\ncompute-in-memory (CIM) architecture (i.e., pretrained weights onto RRAM and\nLoRA onto SRAM). To address performance degradation from RRAM's inherent noise,\nwe design a novel Hardware-aware Low-rank Adaption (HaLoRA) method, aiming to\ntrain a LoRA branch that is both robust and accurate by aligning the training\nobjectives under both ideal and noisy conditions. Experiments finetuning LLaMA\n3.2 1B and 3B demonstrate HaLoRA's effectiveness across multiple reasoning\ntasks, achieving up to 22.7 improvement in average score while maintaining\nrobustness at various noise levels.\n","authors":["Taiqiang Wu","Chenchen Ding","Wenyong Zhou","Yuxin Cheng","Xincheng Feng","Shuqi Wang","Chufan Shi","Zhengwu Liu","Ngai Wong"],"pdf_url":"https://arxiv.org/pdf/2502.19747v2.pdf","comment":"7 pages"},{"id":"http://arxiv.org/abs/2503.02199v1","updated":"2025-03-04T02:21:07Z","published":"2025-03-04T02:21:07Z","title":"Words or Vision: Do Vision-Language Models Have Blind Faith in Text?","summary":"  Vision-Language Models (VLMs) excel in integrating visual and textual\ninformation for vision-centric tasks, but their handling of inconsistencies\nbetween modalities is underexplored. We investigate VLMs' modality preferences\nwhen faced with visual data and varied textual inputs in vision-centered\nsettings. By introducing textual variations to four vision-centric tasks and\nevaluating ten Vision-Language Models (VLMs), we discover a \\emph{``blind faith\nin text''} phenomenon: VLMs disproportionately trust textual data over visual\ndata when inconsistencies arise, leading to significant performance drops under\ncorrupted text and raising safety concerns. We analyze factors influencing this\ntext bias, including instruction prompts, language model size, text relevance,\ntoken order, and the interplay between visual and textual certainty. While\ncertain factors, such as scaling up the language model size, slightly mitigate\ntext bias, others like token order can exacerbate it due to positional biases\ninherited from language models. To address this issue, we explore supervised\nfine-tuning with text augmentation and demonstrate its effectiveness in\nreducing text bias. Additionally, we provide a theoretical analysis suggesting\nthat the blind faith in text phenomenon may stem from an imbalance of pure text\nand multi-modal data during training. Our findings highlight the need for\nbalanced training and careful consideration of modality interactions in VLMs to\nenhance their robustness and reliability in handling multi-modal data\ninconsistencies.\n","authors":["Ailin Deng","Tri Cao","Zhirui Chen","Bryan Hooi"],"pdf_url":"https://arxiv.org/pdf/2503.02199v1.pdf","comment":"Accepted to CVPR 2025"},{"id":"http://arxiv.org/abs/2503.02197v1","updated":"2025-03-04T02:14:55Z","published":"2025-03-04T02:14:55Z","title":"ATLaS: Agent Tuning via Learning Critical Steps","summary":"  Large Language Model (LLM) agents have demonstrated remarkable generalization\ncapabilities across multi-domain tasks. Existing agent tuning approaches\ntypically employ supervised finetuning on entire expert trajectories. However,\nbehavior-cloning of full trajectories can introduce expert bias and weaken\ngeneralization to states not covered by the expert data. Additionally, critical\nsteps, such as planning, complex reasoning for intermediate subtasks, and\nstrategic decision-making, are essential to success in agent tasks, so learning\nthese steps is the key to improving LLM agents. For more effective and\nefficient agent tuning, we propose ATLaS that identifies the critical steps in\nexpert trajectories and finetunes LLMs solely on these steps with reduced\ncosts. By steering the training's focus to a few critical steps, our method\nmitigates the risk of overfitting entire trajectories and promotes\ngeneralization across different environments and tasks. In extensive\nexperiments, an LLM finetuned on only 30% critical steps selected by ATLaS\noutperforms the LLM finetuned on all steps and recent open-source LLM agents.\nATLaS maintains and improves base LLM skills as generalist agents interacting\nwith diverse environments.\n","authors":["Zhixun Chen","Ming Li","Yuxuan Huang","Yali Du","Meng Fang","Tianyi Zhou"],"pdf_url":"https://arxiv.org/pdf/2503.02197v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2412.17049v2","updated":"2025-03-04T02:14:35Z","published":"2024-12-22T15:00:16Z","title":"Modular Conversational Agents for Surveys and Interviews","summary":"  Surveys and interviews are widely used for collecting insights on emerging or\nhypothetical scenarios. Traditional human-led methods often face challenges\nrelated to cost, scalability, and consistency. Recently, various domains have\nbegun to explore the use of conversational agents (chatbots) powered by\ngenerative artificial intelligence (AI) technologies. However, considering\ndecisions in transportation investments and policies often carry significant\npublic and environmental stakes, surveys and interviews face unique challenges\nin integrating AI agents, underscoring the need for a rigorous,\nresource-efficient approach that enhances participant engagement and ensures\nprivacy. This paper addresses this gap by introducing a modular approach and\nits resulting parameterized process for designing AI agents. We detail the\nsystem architecture, integrating engineered prompts, specialized knowledge\nbases, and customizable, goal-oriented conversational logic. We demonstrate the\nadaptability, generalizability, and efficacy of our modular approach through\nthree empirical studies: (1) travel preference surveys, highlighting\nconditional logic and multimodal (voice, text, and image generation)\ncapabilities; (2) public opinion elicitation on a newly constructed, novel\ninfrastructure project, showcasing question customization and multilingual\n(English and French) capabilities; and (3) expert consultation about the impact\nof technologies on future transportation systems, highlighting real-time,\nclarification request capabilities for open-ended questions, resilience in\nhandling erratic inputs, and efficient transcript postprocessing. The results\nsuggest that the AI agent increases completion rates and response quality.\nFurthermore, the modular approach demonstrates controllability, flexibility,\nand robustness while addressing key ethical, privacy, security, and token\nconsumption concerns.\n","authors":["Jiangbo Yu","Jinhua Zhao","Luis Miranda-Moreno","Matthew Korp"],"pdf_url":"https://arxiv.org/pdf/2412.17049v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2409.19134v3","updated":"2025-03-04T01:58:42Z","published":"2024-09-27T20:32:42Z","title":"Confidential Prompting: Protecting User Prompts from Cloud LLM Providers","summary":"  Our work tackles the challenge of securing user inputs in cloud-hosted large\nlanguage model (LLM) serving while ensuring model confidentiality, output\ninvariance, and compute efficiency. We introduce Secure Partitioned Decoding\n(SPD), which uses confidential computing to confine user prompts to a trusted\nexecution environment (TEE), namely a confidential virtual machine (CVM), while\nallowing service providers to generate tokens efficiently. We also introduce a\nnovel cryptographic method, Prompt Obfuscation (PO), to ensure robustness\nagainst reconstruction attacks on SPD. We demonstrate our approach preserves\nboth prompt confidentiality and LLM serving efficiency. Our solution enables\nprivacy-preserving cloud LLM serving that handles sensitive prompts, such as\nclinical records, financial data, and personal information.\n","authors":["In Gim","Caihua Li","Lin Zhong"],"pdf_url":"https://arxiv.org/pdf/2409.19134v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2412.11694v3","updated":"2025-03-04T01:47:20Z","published":"2024-12-16T12:12:45Z","title":"From Specific-MLLMs to Omni-MLLMs: A Survey on MLLMs Aligned with\n  Multi-modalities","summary":"  To tackle complex tasks in real-world scenarios, more researchers are\nfocusing on Omni-MLLMs, which aim to achieve omni-modal understanding and\ngeneration. Beyond the constraints of any specific non-linguistic modality,\nOmni-MLLMs map various non-linguistic modalities into the embedding space of\nLLMs and enable the interaction and understanding of arbitrary combinations of\nmodalities within a single model. In this paper, we systematically investigate\nrelevant research and provide a comprehensive survey of Omni-MLLMs.\nSpecifically, we first explain the four core components of Omni-MLLMs for\nunified multi-modal modeling with a meticulous taxonomy that offers novel\nperspectives. Then, we introduce the effective integration achieved through\ntwo-stage training and discuss the corresponding datasets as well as\nevaluation. Furthermore, we summarize the main challenges of current Omni-MLLMs\nand outline future directions. We hope this paper serves as an introduction for\nbeginners and promotes the advancement of related research. Resources have been\nmade publicly available at https://github.com/threegold116/Awesome-Omni-MLLMs.\n","authors":["Shixin Jiang","Jiafeng Liang","Jiyuan Wang","Xuan Dong","Heng Chang","Weijiang Yu","Jinhua Du","Ming Liu","Bing Qin"],"pdf_url":"https://arxiv.org/pdf/2412.11694v3.pdf","comment":"35 pages"},{"id":"http://arxiv.org/abs/2503.02174v1","updated":"2025-03-04T01:31:17Z","published":"2025-03-04T01:31:17Z","title":"Adversarial Tokenization","summary":"  Current LLM pipelines account for only one possible tokenization for a given\nstring, ignoring exponentially many alternative tokenizations during training\nand inference. For example, the standard Llama3 tokenization of penguin is\n[p,enguin], yet [peng,uin] is another perfectly valid alternative. In this\npaper, we show that despite LLMs being trained solely on one tokenization, they\nstill retain semantic understanding of other tokenizations, raising questions\nabout their implications in LLM safety. Put succinctly, we answer the following\nquestion: can we adversarially tokenize an obviously malicious string to evade\nsafety and alignment restrictions? We show that not only is adversarial\ntokenization an effective yet previously neglected axis of attack, but it is\nalso competitive against existing state-of-the-art adversarial approaches\nwithout changing the text of the harmful request. We empirically validate this\nexploit across three state-of-the-art LLMs and adversarial datasets, revealing\na previously unknown vulnerability in subword models.\n","authors":["Renato Lui Geh","Zilei Shao","Guy Van den Broeck"],"pdf_url":"https://arxiv.org/pdf/2503.02174v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2409.03257v3","updated":"2025-03-04T01:21:18Z","published":"2024-09-05T05:31:29Z","title":"Understanding LLM Development Through Longitudinal Study: Insights from\n  the Open Ko-LLM Leaderboard","summary":"  This paper conducts a longitudinal study over eleven months to address the\nlimitations of prior research on the Open Ko-LLM Leaderboard, which have relied\non empirical studies with restricted observation periods of only five months.\nBy extending the analysis duration, we aim to provide a more comprehensive\nunderstanding of the progression in developing Korean large language models\n(LLMs). Our study is guided by three primary research questions: (1) What are\nthe specific challenges in improving LLM performance across diverse tasks on\nthe Open Ko-LLM Leaderboard over time? (2) How does model size impact task\nperformance correlations across various benchmarks? (3) How have the patterns\nin leaderboard rankings shifted over time on the Open Ko-LLM Leaderboard?. By\nanalyzing 1,769 models over this period, our research offers a comprehensive\nexamination of the ongoing advancements in LLMs and the evolving nature of\nevaluation frameworks.\n","authors":["Chanjun Park","Hyeonwoo Kim"],"pdf_url":"https://arxiv.org/pdf/2409.03257v3.pdf","comment":"Accepted to NAACL 2025 Industry"},{"id":"http://arxiv.org/abs/2410.12445v3","updated":"2025-03-04T01:18:34Z","published":"2024-10-16T10:49:22Z","title":"Open Ko-LLM Leaderboard2: Bridging Foundational and Practical Evaluation\n  for Korean LLMs","summary":"  The Open Ko-LLM Leaderboard has been instrumental in benchmarking Korean\nLarge Language Models (LLMs), yet it has certain limitations. Notably, the\ndisconnect between quantitative improvements on the overly academic leaderboard\nbenchmarks and the qualitative impact of the models should be addressed.\nFurthermore, the benchmark suite is largely composed of translated versions of\ntheir English counterparts, which may not fully capture the intricacies of the\nKorean language. To address these issues, we propose Open Ko-LLM Leaderboard2,\nan improved version of the earlier Open Ko-LLM Leaderboard. The original\nbenchmarks are entirely replaced with new tasks that are more closely aligned\nwith real-world capabilities. Additionally, four new native Korean benchmarks\nare introduced to better reflect the distinct characteristics of the Korean\nlanguage. Through these refinements, Open Ko-LLM Leaderboard2 seeks to provide\na more meaningful evaluation for advancing Korean LLMs.\n","authors":["Hyeonwoo Kim","Dahyun Kim","Jihoo Kim","Sukyung Lee","Yungi Kim","Chanjun Park"],"pdf_url":"https://arxiv.org/pdf/2410.12445v3.pdf","comment":"Accepted to NAACL 2025 Industry"},{"id":"http://arxiv.org/abs/2502.08168v5","updated":"2025-03-04T01:07:55Z","published":"2025-02-12T07:19:36Z","title":"SARChat-Bench-2M: A Multi-Task Vision-Language Benchmark for SAR Image\n  Interpretation","summary":"  As a powerful all-weather Earth observation tool, synthetic aperture radar\n(SAR) remote sensing enables critical military reconnaissance, maritime\nsurveillance, and infrastructure monitoring. Although Vision language models\n(VLMs) have made remarkable progress in natural language processing and image\nunderstanding, their applications remain limited in professional domains due to\ninsufficient domain expertise. This paper innovatively proposes the first\nlarge-scale multimodal dialogue dataset for SAR images, named SARChat-2M, which\ncontains approximately 2 million high-quality image-text pairs, encompasses\ndiverse scenarios with detailed target annotations. This dataset not only\nsupports several key tasks such as visual understanding and object detection\ntasks, but also has unique innovative aspects: this study develop a\nvisual-language dataset and benchmark for the SAR domain, enabling and\nevaluating VLMs' capabilities in SAR image interpretation, which provides a\nparadigmatic framework for constructing multimodal datasets across various\nremote sensing vertical domains. Through experiments on 16 mainstream VLMs, the\neffectiveness of the dataset has been fully verified. The project will be\nreleased at https://github.com/JimmyMa99/SARChat.\n","authors":["Zhiming Ma","Xiayang Xiao","Sihao Dong","Peidong Wang","HaiPeng Wang","Qingyun Pan"],"pdf_url":"https://arxiv.org/pdf/2502.08168v5.pdf","comment":null},{"id":"http://arxiv.org/abs/2502.19676v2","updated":"2025-03-04T00:59:53Z","published":"2025-02-27T01:36:00Z","title":"The Future Outcome Reasoning and Confidence Assessment Benchmark","summary":"  Forecasting is an important task in many domains, such as technology and\neconomics. However existing forecasting benchmarks largely lack comprehensive\nconfidence assessment, focus on limited question types, and often consist of\nartificial questions that do not align with real-world human forecasting needs.\nTo address these gaps, we introduce FOReCAst (Future Outcome Reasoning and\nConfidence Assessment), a benchmark that evaluates models' ability to make\npredictions and their confidence in them. FOReCAst spans diverse forecasting\nscenarios involving Boolean questions, timeframe prediction, and quantity\nestimation, enabling a comprehensive evaluation of both prediction accuracy and\nconfidence calibration for real-world applications.\n","authors":["Zhangdie Yuan","Zifeng Ding","Andreas Vlachos"],"pdf_url":"https://arxiv.org/pdf/2502.19676v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.02712v2","updated":"2025-03-04T00:49:07Z","published":"2024-10-03T17:36:33Z","title":"LLaVA-Critic: Learning to Evaluate Multimodal Models","summary":"  We introduce LLaVA-Critic, the first open-source large multimodal model (LMM)\ndesigned as a generalist evaluator to assess performance across a wide range of\nmultimodal tasks. LLaVA-Critic is trained using a high-quality critic\ninstruction-following dataset that incorporates diverse evaluation criteria and\nscenarios. Our experiments demonstrate the model's effectiveness in two key\nareas: (1) LMM-as-a-Judge, where LLaVA-Critic provides reliable evaluation\nscores, performing on par with or surpassing GPT models on multiple evaluation\nbenchmarks; and (2) Preference Learning, where it generates reward signals for\npreference learning, enhancing model alignment capabilities. This work\nunderscores the potential of open-source LMMs in self-critique and evaluation,\nsetting the stage for future research into scalable, superhuman alignment\nfeedback mechanisms for LMMs.\n","authors":["Tianyi Xiong","Xiyao Wang","Dong Guo","Qinghao Ye","Haoqi Fan","Quanquan Gu","Heng Huang","Chunyuan Li"],"pdf_url":"https://arxiv.org/pdf/2410.02712v2.pdf","comment":"Accepted by CVPR 2025; Project Page:\n  https://llava-vl.github.io/blog/2024-10-03-llava-critic"},{"id":"http://arxiv.org/abs/2412.01007v3","updated":"2025-03-04T00:36:44Z","published":"2024-12-01T23:54:12Z","title":"CoRNStack: High-Quality Contrastive Data for Better Code Retrieval and\n  Reranking","summary":"  Effective code retrieval plays a crucial role in advancing code generation,\nbug fixing, and software maintenance, particularly as software systems increase\nin complexity. While current code embedding models have demonstrated promise in\nretrieving code snippets for small-scale, well-defined tasks, they often\nunderperform in more demanding real-world applications such as bug localization\nwithin GitHub repositories. We hypothesize that a key issue is their reliance\non noisy and inconsistent datasets for training, which impedes their ability to\ngeneralize to more complex retrieval scenarios. To address these limitations,\nwe introduce CoRNStack, a large-scale, high-quality contrastive training\ndataset for code that spans multiple programming languages. This dataset is\ncurated using consistency filtering to eliminate noisy positives and is further\nenriched with mined hard negatives, thereby facilitating more effective\nlearning. We demonstrate that contrastive training of embedding models using\nCoRNStack leads to state-of-the-art performance across a variety of code\nretrieval tasks. Furthermore, the dataset can be leveraged for training code\nreranking models, a largely underexplored area compared to text reranking. Our\nfinetuned code reranking model significantly improves the ranking quality over\nthe retrieved results. Finally, by employing our code retriever and reranker\ntogether, we demonstrate significant improvements in function localization for\nGitHub issues, an important component of real-world software development.\n","authors":["Tarun Suresh","Revanth Gangi Reddy","Yifei Xu","Zach Nussbaum","Andriy Mulyar","Brandon Duderstadt","Heng Ji"],"pdf_url":"https://arxiv.org/pdf/2412.01007v3.pdf","comment":"Published as a conference paper at ICLR 2025. First and second author\n  had equal contribution"},{"id":"http://arxiv.org/abs/2503.02152v1","updated":"2025-03-04T00:32:15Z","published":"2025-03-04T00:32:15Z","title":"Tabby: Tabular Data Synthesis with Language Models","summary":"  While advances in large language models (LLMs) have greatly improved the\nquality of synthetic text data in recent years, synthesizing tabular data has\nreceived relatively less attention. We address this disparity with Tabby, a\nsimple but powerful post-training modification to the standard Transformer\nlanguage model architecture, enabling its use for tabular dataset synthesis.\nTabby enables the representation of differences across columns using Gated\nMixture-of-Experts, with column-specific sets of parameters. Empirically, Tabby\nresults in data quality near or equal to that of real data. By pairing our\nnovel LLM table training technique, Plain, with Tabby, we observe up to a 44%\nimprovement in quality over previous methods. We also show that Tabby extends\nbeyond tables to more general structured data, reaching parity with real data\non a nested JSON dataset as well.\n","authors":["Sonia Cromp","Satya Sai Srinath Namburi GNVV","Mohammed Alkhudhayri","Catherine Cao","Samuel Guo","Nicholas Roberts","Frederic Sala"],"pdf_url":"https://arxiv.org/pdf/2503.02152v1.pdf","comment":"21 pages, 8 figures"},{"id":"http://arxiv.org/abs/2409.11242v3","updated":"2025-03-04T00:25:09Z","published":"2024-09-17T14:47:33Z","title":"Measuring and Enhancing Trustworthiness of LLMs in RAG through Grounded\n  Attributions and Learning to Refuse","summary":"  LLMs are an integral component of retrieval-augmented generation (RAG)\nsystems. While many studies focus on evaluating the overall quality of\nend-to-end RAG systems, there is a gap in understanding the appropriateness of\nLLMs for the RAG task. To address this, we introduce Trust-Score, a holistic\nmetric that evaluates the trustworthiness of LLMs within the RAG framework. Our\nresults show that various prompting methods, such as in-context learning, fail\nto effectively adapt LLMs to the RAG task as measured by Trust-Score.\nConsequently, we propose Trust-Align, a method to align LLMs for improved\nTrust-Score performance. 26 out of 27 models aligned using Trust-Align\nsubstantially outperform competitive baselines on ASQA, QAMPARI, and ELI5.\nSpecifically, in LLaMA-3-8b, Trust-Align outperforms FRONT on ASQA (up 12.56),\nQAMPARI (up 36.04), and ELI5 (up 17.69). Trust-Align also significantly\nenhances models' ability to correctly refuse and provide quality citations. We\nalso demonstrate the effectiveness of Trust-Align across different open-weight\nmodels, including the LLaMA series (1b to 8b), Qwen-2.5 series (0.5b to 7b),\nand Phi3.5 (3.8b). We release our code at\nhttps://github.com/declare-lab/trust-align.\n","authors":["Maojia Song","Shang Hong Sim","Rishabh Bhardwaj","Hai Leong Chieu","Navonil Majumder","Soujanya Poria"],"pdf_url":"https://arxiv.org/pdf/2409.11242v3.pdf","comment":"Published at ICLR 2025 (Oral)"},{"id":"http://arxiv.org/abs/2503.02144v1","updated":"2025-03-04T00:24:21Z","published":"2025-03-04T00:24:21Z","title":"Malware Classification from Memory Dumps Using Machine Learning,\n  Transformers, and Large Language Models","summary":"  This study investigates the performance of various classification models for\na malware classification task using different feature sets and data\nconfigurations. Six models-Logistic Regression, K-Nearest Neighbors (KNN),\nSupport Vector Machines (SVM), Decision Trees, Random Forest (RF), and Extreme\nGradient Boosting (XGB)-were evaluated alongside two deep learning models,\nRecurrent Neural Networks (RNN) and Transformers, as well as the Gemini\nzero-shot and few-shot learning methods. Four feature sets were tested\nincluding All Features, Literature Review Features, the Top 45 Features from\nRF, and Down-Sampled with Top 45 Features. XGB achieved the highest accuracy of\n87.42% using the Top 45 Features, outperforming all other models. RF followed\nclosely with 87.23% accuracy on the same feature set. In contrast, deep\nlearning models underperformed, with RNN achieving 66.71% accuracy and\nTransformers reaching 71.59%. Down-sampling reduced performance across all\nmodels, with XGB dropping to 81.31%. Gemini zero-shot and few-shot learning\napproaches showed the lowest performance, with accuracies of 40.65% and 48.65%,\nrespectively. The results highlight the importance of feature selection in\nimproving model performance while reducing computational complexity.\nTraditional models like XGB and RF demonstrated superior performance, while\ndeep learning and few-shot methods struggled to match their accuracy. This\nstudy underscores the effectiveness of traditional machine learning models for\nstructured datasets and provides a foundation for future research into hybrid\napproaches and larger datasets.\n","authors":["Areej Dweib","Montaser Tanina","Shehab Alawi","Mohammad Dyab","Huthaifa I. Ashqar"],"pdf_url":"https://arxiv.org/pdf/2503.02144v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.02142v1","updated":"2025-03-04T00:19:01Z","published":"2025-03-04T00:19:01Z","title":"Measuring Intrinsic Dimension of Token Embeddings","summary":"  In this study, we measure the Intrinsic Dimension (ID) of token embedding to\nestimate the intrinsic dimensions of the manifolds spanned by the\nrepresentations, so as to evaluate their redundancy quantitatively compared to\ntheir extrinsic dimensionality. In detail, (1) we estimate the ID of token\nembeddings in small-scale language models and also modern large language\nmodels, finding that the embedding spaces often reside on lower-dimensional\nmanifolds compared to their extrinsic dimensionality; (2) we measure the ID\nacross various model sizes and observe an increase in redundancy rates as the\nmodel scale grows; (3) we measure the dynamics of IDs during the training\nprocess, and find a rapid ID drop in the early stages of training. Moreover,\n(4) when LoRA is applied to the embedding layers, we observe a sudden drop in\nperplexity around the estimated IDs, suggesting that the ID can serve as a\nuseful guideline for LoRA application.\n","authors":["Takuya Kataiwa","Cho Hakaze","Tetsushi Ohki"],"pdf_url":"https://arxiv.org/pdf/2503.02142v1.pdf","comment":"4 pages, 4 figures"},{"id":"http://arxiv.org/abs/2503.02141v1","updated":"2025-03-04T00:18:58Z","published":"2025-03-04T00:18:58Z","title":"Network Traffic Classification Using Machine Learning, Transformer, and\n  Large Language Models","summary":"  This study uses various models to address network traffic classification,\ncategorizing traffic into web, browsing, IPSec, backup, and email. We collected\na comprehensive dataset from Arbor Edge Defender (AED) devices, comprising of\n30,959 observations and 19 features. Multiple models were evaluated, including\nNaive Bayes, Decision Tree, Random Forest, Gradient Boosting, XGBoost, Deep\nNeural Networks (DNN), Transformer, and two Large Language Models (LLMs)\nincluding GPT-4o and Gemini with zero- and few-shot learning. Transformer and\nXGBoost showed the best performance, achieving the highest accuracy of 98.95\nand 97.56%, respectively. GPT-4o and Gemini showed promising results with\nfew-shot learning, improving accuracy significantly from initial zero-shot\nperformance. While Gemini Few-Shot and GPT-4o Few-Shot performed well in\ncategories like Web and Email, misclassifications occurred in more complex\ncategories like IPSec and Backup. The study highlights the importance of model\nselection, fine-tuning, and the balance between training data size and model\ncomplexity for achieving reliable classification results.\n","authors":["Ahmad Antari","Yazan Abo-Aisheh","Jehad Shamasneh","Huthaifa I. Ashqar"],"pdf_url":"https://arxiv.org/pdf/2503.02141v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2408.03350v3","updated":"2025-03-04T00:10:22Z","published":"2024-08-05T20:19:18Z","title":"miniCTX: Neural Theorem Proving with (Long-)Contexts","summary":"  Real-world formal theorem proving often depends on a wealth of context,\nincluding definitions, lemmas, comments, file structure, and other information.\nWe introduce miniCTX, which tests a model's ability to prove formal\nmathematical theorems that depend on new context that is not seen during\ntraining. miniCTX contains theorems sourced from real Lean projects and\ntextbooks, each associated with a context that can span tens of thousands of\ntokens. Models are tasked with proving a theorem given access to code from the\ntheorem's repository, which contains context that is needed for the proof. As a\nbaseline for miniCTX, we tested fine-tuning and prompting methods that\ncondition theorem proving on preceding context. Both approaches substantially\noutperform traditional methods that rely solely on state information. We found\nthat this ability to use context is not captured by previous benchmarks such as\nminiF2F. Alongside miniCTX, we offer ntp-toolkit for automatically extracting\nand annotating theorem proving data, making it easy to add new projects into\nminiCTX to ensure that contexts are not seen during training. miniCTX offers a\nchallenging and realistic evaluation of neural theorem provers.\n","authors":["Jiewen Hu","Thomas Zhu","Sean Welleck"],"pdf_url":"https://arxiv.org/pdf/2408.03350v3.pdf","comment":"Project page: https://cmu-l3.github.io/minictx"},{"id":"http://arxiv.org/abs/2406.04412v2","updated":"2025-03-04T00:04:24Z","published":"2024-06-06T18:01:02Z","title":"Spread Preference Annotation: Direct Preference Judgment for Efficient\n  LLM Alignment","summary":"  Aligning large language models (LLMs) with human preferences becomes a key\ncomponent to obtaining state-of-the-art performance, but it yields a huge cost\nto construct a large human-annotated preference dataset. To tackle this\nproblem, we propose a new framework, Spread Preference Annotation with direct\npreference judgment (SPA), that boosts the alignment of LLMs using only a very\nsmall amount of human-annotated preference data. Our key idea is leveraging the\nhuman prior knowledge within the small (seed) data and progressively improving\nthe alignment of LLM, by iteratively generating the responses and learning from\nthem with the self-annotated preference data. To be specific, we propose to\nderive the preference label from the logits of LLM to explicitly extract the\nmodel's inherent preference. Compared to the previous approaches using external\nreward models or implicit in-context learning, we observe that the proposed\napproach is significantly more effective. In addition, we introduce a\nnoise-aware preference learning algorithm to mitigate the risk of low quality\nwithin generated preference data. Our experimental results demonstrate that the\nproposed framework significantly boosts the alignment of LLMs. For example, we\nachieve superior alignment performance on AlpacaEval 2.0 with only 3.3% of the\nground-truth preference labels in the Ultrafeedback data compared to the cases\nusing the entire data or state-of-the-art baselines.\n","authors":["Dongyoung Kim","Kimin Lee","Jinwoo Shin","Jaehyung Kim"],"pdf_url":"https://arxiv.org/pdf/2406.04412v2.pdf","comment":"ICLR 2025 Oral Presentation, 22 pages"},{"id":"http://arxiv.org/abs/2503.03064v1","updated":"2025-03-04T23:59:08Z","published":"2025-03-04T23:59:08Z","title":"Improving LLM-as-a-Judge Inference with the Judgment Distribution","summary":"  Using language models to scalably approximate human preferences on text\nquality (LLM-as-a-judge) has become a standard practice applicable to many\ntasks. A judgment is often extracted from the judge's textual output alone,\ntypically with greedy decoding. However, LLM judges naturally provide\ndistributions over judgment tokens, inviting a breadth of inference methods for\nextracting fine-grained preferences. We find that taking the mean of the\njudgment distribution consistently outperforms taking the mode (i.e. greedy\ndecoding) in all evaluation settings (i.e. pointwise, pairwise, and listwise).\nWe further explore novel methods of deriving preferences from judgment\ndistributions, and find that methods incorporating risk aversion often improve\nperformance. Lastly, we analyze LLM-as-a-judge paired with chain-of-thought\n(CoT) prompting, showing that CoT can collapse the spread of the judgment\ndistribution, often harming performance. Our findings suggest leveraging\ndistributional output can improve LLM-as-a-judge, as opposed to using the text\ninterface alone.\n","authors":["Victor Wang","Michael J. Q. Zhang","Eunsol Choi"],"pdf_url":"https://arxiv.org/pdf/2503.03064v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.03062v1","updated":"2025-03-04T23:52:49Z","published":"2025-03-04T23:52:49Z","title":"Semi-Supervised In-Context Learning: A Baseline Study","summary":"  Most existing work in data selection for In-Context Learning (ICL) has\nfocused on constructing demonstrations from ground truth annotations, with\nlimited attention given to selecting reliable self-generated annotations. In\nthis work, we propose a three-step semi-supervised ICL framework: annotation\ngeneration, demonstration selection, and semi-supervised inference. Our\nbaseline, Naive-SemiICL, which prompts select high-confidence self-generated\ndemonstrations for ICL prompting, outperforms a 16-shot baseline by an average\nof 9.94% across 16 datasets. We further introduce IterPSD, an annotation\napproach that refines pseudo-demonstrations iteratively, achieving up to 6.8%\nadditional gains in classification tasks. Lastly, we reveal a scaling law for\nsemi-supervised ICL, where models achieve optimal performance with over 1,000\ndemonstrations.\n","authors":["Zhengyao Gu","Henry Peng Zou","Yankai Chen","Aiwei Liu","Weizhi Zhang","Philip S. Yu"],"pdf_url":"https://arxiv.org/pdf/2503.03062v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2502.14338v2","updated":"2025-03-04T23:24:09Z","published":"2025-02-20T07:47:03Z","title":"English Please: Evaluating Machine Translation for Multilingual Bug\n  Reports","summary":"  Accurate translation of bug reports is critical for efficient collaboration\nin global software development. In this study, we conduct the first\ncomprehensive evaluation of machine translation (MT) performance on bug\nreports, analyzing the capabilities of DeepL, AWS Translate, and ChatGPT using\ndata from the Visual Studio Code GitHub repository, specifically focusing on\nreports labeled with the english-please tag. To thoroughly assess the accuracy\nand effectiveness of each system, we employ multiple machine translation\nmetrics, including BLEU, BERTScore, COMET, METEOR, and ROUGE. Our findings\nindicate that DeepL consistently outperforms the other systems across most\nautomatic metrics, demonstrating strong lexical and semantic alignment. AWS\nTranslate performs competitively, particularly in METEOR, while ChatGPT lags in\nkey metrics. This study underscores the importance of domain adaptation for\ntranslating technical texts and offers guidance for integrating automated\ntranslation into bug-triaging workflows. Moreover, our results establish a\nfoundation for future research to refine machine translation solutions for\nspecialized engineering contexts. The code and dataset for this paper are\navailable at GitHub: https://github.com/av9ash/gitbugs/tree/main/multilingual.\n","authors":["Avinash Patil","Aryan Jadon"],"pdf_url":"https://arxiv.org/pdf/2502.14338v2.pdf","comment":"8 Pages, 4 Figures, 3 Tables"},{"id":"http://arxiv.org/abs/2503.03044v1","updated":"2025-03-04T22:50:17Z","published":"2025-03-04T22:50:17Z","title":"QE4PE: Word-level Quality Estimation for Human Post-Editing","summary":"  Word-level quality estimation (QE) detects erroneous spans in machine\ntranslations, which can direct and facilitate human post-editing. While the\naccuracy of word-level QE systems has been assessed extensively, their\nusability and downstream influence on the speed, quality and editing choices of\nhuman post-editing remain understudied. Our QE4PE study investigates the impact\nof word-level QE on machine translation (MT) post-editing in a realistic\nsetting involving 42 professional post-editors across two translation\ndirections. We compare four error-span highlight modalities, including\nsupervised and uncertainty-based word-level QE methods, for identifying\npotential errors in the outputs of a state-of-the-art neural MT model.\nPost-editing effort and productivity are estimated by behavioral logs, while\nquality improvements are assessed by word- and segment-level human annotation.\nWe find that domain, language and editors' speed are critical factors in\ndetermining highlights' effectiveness, with modest differences between\nhuman-made and automated QE highlights underlining a gap between accuracy and\nusability in professional workflows.\n","authors":["Gabriele Sarti","Vilm Zouhar","Grzegorz Chrupaa","Ana Guerberof-Arenas","Malvina Nissim","Arianna Bisazza"],"pdf_url":"https://arxiv.org/pdf/2503.03044v1.pdf","comment":"Code: https://github.com/gsarti/qe4pe. Dataset:\n  https://huggingface.co/datasets/gsarti/qe4pe"},{"id":"http://arxiv.org/abs/2503.03040v1","updated":"2025-03-04T22:45:24Z","published":"2025-03-04T22:45:24Z","title":"SAGE: Steering and Refining Dialog Generation with State-Action\n  Augmentation","summary":"  Recent advances in large language models have demonstrated impressive\ncapabilities in task-oriented applications, yet building emotionally\nintelligent chatbots that can engage in natural, strategic conversations\nremains a challenge. We present a novel approach called SAGE that uses latent\nvariables to control long-horizon behavior in dialogue generation. At the core\nof our method is the State-Action Chain (SAC), which augments standard language\nmodel fine-tuning by introducing latent variables that encapsulate emotional\nstates and conversational strategies between dialogue turns. During inference,\nthese variables are generated before each response, enabling coarse-grained\ncontrol over dialogue progression while maintaining natural interaction\npatterns. We also introduce a self-improvement pipeline that leverages dialogue\ntree search, LLM-based reward modeling, and targeted fine-tuning to optimize\nconversational trajectories. Our experimental results show that models trained\nwith this approach demonstrate improved performance in emotional intelligence\nmetrics while maintaining strong capabilities on LLM benchmarks. The discrete\nnature of our latent variables facilitates search-based strategies and provides\na foundation for future applications of reinforcement learning to dialogue\nsystems, where learning can occur at the state level rather than the token\nlevel.\n","authors":["Yizhe Zhang","Navdeep Jaitly"],"pdf_url":"https://arxiv.org/pdf/2503.03040v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.03032v1","updated":"2025-03-04T22:19:52Z","published":"2025-03-04T22:19:52Z","title":"SAFE: A Sparse Autoencoder-Based Framework for Robust Query Enrichment\n  and Hallucination Mitigation in LLMs","summary":"  Despite the state-of-the-art performance of Large Language Models (LLMs),\nthese models often suffer from hallucinations, which can undermine their\nperformance in critical applications. In this work, we propose SAFE, a novel\nmethod for detecting and mitigating hallucinations by leveraging Sparse\nAutoencoders (SAEs). While hallucination detection techniques and SAEs have\nbeen explored independently, their synergistic application in a comprehensive\nsystem, particularly for hallucination-aware query enrichment, has not been\nfully investigated. To validate the effectiveness of SAFE, we evaluate it on\ntwo models with available SAEs across three diverse cross-domain datasets\ndesigned to assess hallucination problems. Empirical results demonstrate that\nSAFE consistently improves query generation accuracy and mitigates\nhallucinations across all datasets, achieving accuracy improvements of up to\n29.45%.\n","authors":["Samir Abdaljalil","Filippo Pallucchini","Andrea Seveso","Hasan Kurban","Fabio Mercorio","Erchin Serpedin"],"pdf_url":"https://arxiv.org/pdf/2503.03032v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.10813v2","updated":"2025-03-04T22:19:41Z","published":"2024-10-14T17:59:44Z","title":"LongMemEval: Benchmarking Chat Assistants on Long-Term Interactive\n  Memory","summary":"  Recent large language model (LLM)-driven chat assistant systems have\nintegrated memory components to track user-assistant chat histories, enabling\nmore accurate and personalized responses. However, their long-term memory\ncapabilities in sustained interactions remain underexplored. We introduce\nLongMemEval, a comprehensive benchmark designed to evaluate five core long-term\nmemory abilities of chat assistants: information extraction, multi-session\nreasoning, temporal reasoning, knowledge updates, and abstention. With 500\nmeticulously curated questions embedded within freely scalable user-assistant\nchat histories, LongMemEval presents a significant challenge to existing\nlong-term memory systems, with commercial chat assistants and long-context LLMs\nshowing a 30% accuracy drop on memorizing information across sustained\ninteractions. We then present a unified framework that breaks down the\nlong-term memory design into three stages: indexing, retrieval, and reading.\nBuilt upon key experimental insights, we propose several memory design\noptimizations including session decomposition for value granularity,\nfact-augmented key expansion for indexing, and time-aware query expansion for\nrefining the search scope. Extensive experiments show that these optimizations\ngreatly improve both memory recall and downstream question answering on\nLongMemEval. Overall, our study provides valuable resources and guidance for\nadvancing the long-term memory capabilities of LLM-based chat assistants,\npaving the way toward more personalized and reliable conversational AI. Our\nbenchmark and code are publicly available at\nhttps://github.com/xiaowu0162/LongMemEval.\n","authors":["Di Wu","Hongwei Wang","Wenhao Yu","Yuwei Zhang","Kai-Wei Chang","Dong Yu"],"pdf_url":"https://arxiv.org/pdf/2410.10813v2.pdf","comment":"ICLR 2025"},{"id":"http://arxiv.org/abs/2503.03008v1","updated":"2025-03-04T21:08:17Z","published":"2025-03-04T21:08:17Z","title":"One Model to Train them All: Hierarchical Self-Distillation for Enhanced\n  Early Layer Embeddings","summary":"  Deploying language models often requires handling model size vs. performance\ntrade-offs to satisfy downstream latency constraints while preserving the\nmodel's usefulness. Model distillation is commonly employed to reduce model\nsize while maintaining acceptable performance. However, distillation can be\ninefficient since it involves multiple training steps. In this work, we\nintroduce MODULARSTARENCODER, a modular multi-exit encoder with 1B parameters,\nuseful for multiple tasks within the scope of code retrieval.\nMODULARSTARENCODER is trained with a novel self-distillation mechanism that\nsignificantly improves lower-layer representations-allowing different portions\nof the model to be used while still maintaining a good trade-off in terms of\nperformance. Our architecture focuses on enhancing text-to-code and\ncode-to-code search by systematically capturing syntactic and semantic\nstructures across multiple levels of representation. Specific encoder layers\nare targeted as exit heads, allowing higher layers to guide earlier layers\nduring training. This self-distillation effect improves intermediate\nrepresentations, increasing retrieval recall at no extra training cost. In\naddition to the multi-exit scheme, our approach integrates a repository-level\ncontextual loss that maximally utilizes the training context window, further\nenhancing the learned representations. We also release a new dataset\nconstructed via code translation, seamlessly expanding traditional text-to-code\nbenchmarks with code-to-code pairs across diverse programming languages.\nExperimental results highlight the benefits of self-distillation through\nmulti-exit supervision.\n","authors":["Andrea Gurioli","Federico Pennino","Joo Monteiro","Maurizio Gabbrielli"],"pdf_url":"https://arxiv.org/pdf/2503.03008v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.03005v1","updated":"2025-03-04T21:04:21Z","published":"2025-03-04T21:04:21Z","title":"Will I Get Hate Speech Predicting the Volume of Abusive Replies before\n  Posting in Social Media","summary":"  Despite the growing body of research tackling offensive language in social\nmedia, this research is predominantly reactive, determining if content already\nposted in social media is abusive. There is a gap in predictive approaches,\nwhich we address in our study by enabling to predict the volume of abusive\nreplies a tweet will receive after being posted. We formulate the problem from\nthe perspective of a social media user asking: ``if I post a certain message on\nsocial media, is it possible to predict the volume of abusive replies it might\nreceive?'' We look at four types of features, namely text, text metadata, tweet\nmetadata, and account features, which also help us understand the extent to\nwhich the user or the content helps predict the number of abusive replies.\nThis, in turn, helps us develop a model to support social media users in\nfinding the best way to post content. One of our objectives is also to\ndetermine the extent to which the volume of abusive replies that a tweet will\nget are motivated by the content of the tweet or by the identity of the user\nposting it. Our study finds that one can build a model that performs\ncompetitively by developing a comprehensive set of features derived from the\ncontent of the message that is going to be posted. In addition, our study\nsuggests that features derived from the user's identity do not impact model\nperformance, hence suggesting that it is especially the content of a post that\ntriggers abusive replies rather than who the user is.\n","authors":["Raneem Alharthia","Rajwa Alharthib","Ravi Shekharc","Aiqi Jiangd","Arkaitz Zubiagaa"],"pdf_url":"https://arxiv.org/pdf/2503.03005v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.02993v1","updated":"2025-03-04T20:39:07Z","published":"2025-03-04T20:39:07Z","title":"Zero-Shot Multi-Label Classification of Bangla Documents: Large Decoders\n  Vs. Classic Encoders","summary":"  Bangla, a language spoken by over 300 million native speakers and ranked as\nthe sixth most spoken language worldwide, presents unique challenges in natural\nlanguage processing (NLP) due to its complex morphological characteristics and\nlimited resources. While recent Large Decoder Based models (LLMs), such as GPT,\nLLaMA, and DeepSeek, have demonstrated excellent performance across many NLP\ntasks, their effectiveness in Bangla remains largely unexplored. In this paper,\nwe establish the first benchmark comparing decoder-based LLMs with classic\nencoder-based models for Zero-Shot Multi-Label Classification (Zero-Shot-MLC)\ntask in Bangla. Our evaluation of 32 state-of-the-art models reveals that,\nexisting so-called powerful encoders and decoders still struggle to achieve\nhigh accuracy on the Bangla Zero-Shot-MLC task, suggesting a need for more\nresearch and resources for Bangla NLP.\n","authors":["Souvika Sarkar","Md. Najib Hasan","Santu Karmaker"],"pdf_url":"https://arxiv.org/pdf/2503.02993v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.02989v1","updated":"2025-03-04T20:32:27Z","published":"2025-03-04T20:32:27Z","title":"Effectively Steer LLM To Follow Preference via Building Confident\n  Directions","summary":"  Having an LLM that aligns with human preferences is essential for\naccommodating individual needs, such as maintaining writing style or generating\nspecific topics of interest. The majority of current alignment methods rely on\nfine-tuning or prompting, which can be either costly or difficult to control.\nModel steering algorithms, which modify the model output by constructing\nspecific steering directions, are typically easy to implement and\noptimization-free. However, their capabilities are typically limited to\nsteering the model into one of the two directions (i.e., bidirectional\nsteering), and there has been no theoretical understanding to guarantee their\nperformance. In this work, we propose a theoretical framework to understand and\nquantify the model steering methods. Inspired by the framework, we propose a\nconfident direction steering method (CONFST) that steers LLMs via modifying\ntheir activations at inference time. More specifically, CONFST builds a\nconfident direction that is closely aligned with users' preferences, and this\ndirection is then added to the activations of the LLMs to effectively steer the\nmodel output. Our approach offers three key advantages over popular\nbidirectional model steering methods: 1) It is more powerful, since multiple\n(i.e. more than two) users' preferences can be aligned simultaneously; 2) It is\nsimple to implement, since there is no need to determine which layer to add the\nsteering vector to; 3) No explicit user instruction is required. We validate\nour method on GPT-2 XL (1.5B), Mistral (7B) and Gemma-it (9B) models for tasks\nthat require shifting the output of LLMs across various topics and styles,\nachieving superior performance over competing methods.\n","authors":["Bingqing Song","Boran Han","Shuai Zhang","Hao Wang","Haoyang Fang","Bonan Min","Yuyang Wang","Mingyi Hong"],"pdf_url":"https://arxiv.org/pdf/2503.02989v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.02972v1","updated":"2025-03-04T19:57:47Z","published":"2025-03-04T19:57:47Z","title":"LINGOLY-TOO: Disentangling Memorisation from Reasoning with Linguistic\n  Templatisation and Orthographic Obfuscation","summary":"  Effective evaluation of the reasoning capabilities of large language models\n(LLMs) are susceptible to overestimation due to data exposure of evaluation\nbenchmarks. We introduce a framework for producing linguistic reasoning\nproblems that reduces the effect of memorisation in model performance estimates\nand apply this framework to develop LINGOLY-TOO, a challenging evaluation\nbenchmark for linguistic reasoning. By developing orthographic templates, we\ndynamically obfuscate the writing systems of real languages to generate\nnumerous question variations. These variations preserve the reasoning steps\nrequired for each solution while reducing the likelihood of specific problem\ninstances appearing in model training data. Our experiments demonstrate that\nfrontier models, including OpenAI o1-preview and DeepSeem R1, struggle with\nadvanced reasoning. Our analysis also shows that LLMs exhibit noticeable\nvariance in accuracy across permutations of the same problem, and on average\nperform better on questions appearing in their original orthography. Our\nfindings highlight the opaque nature of response generation in LLMs and provide\nevidence that prior data exposure contributes to overestimating the reasoning\ncapabilities of frontier models.\n","authors":["Jude Khouja","Karolina Korgul","Simi Hellsten","Lingyi Yang","Vlad Neacs","Harry Mayne","Ryan Kearns","Andrew Bean","Adam Mahdi"],"pdf_url":"https://arxiv.org/pdf/2503.02972v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.02971v1","updated":"2025-03-04T19:56:56Z","published":"2025-03-04T19:56:56Z","title":"Multilingual Relative Clause Attachment Ambiguity Resolution in Large\n  Language Models","summary":"  This study examines how large language models (LLMs) resolve relative clause\n(RC) attachment ambiguities and compares their performance to human sentence\nprocessing. Focusing on two linguistic factors, namely the length of RCs and\nthe syntactic position of complex determiner phrases (DPs), we assess whether\nLLMs can achieve human-like interpretations amid the complexities of language.\nIn this study, we evaluated several LLMs, including Claude, Gemini and Llama,\nin multiple languages: English, Spanish, French, German, Japanese, and Korean.\nWhile these models performed well in Indo-European languages (English, Spanish,\nFrench, and German), they encountered difficulties in Asian languages (Japanese\nand Korean), often defaulting to incorrect English translations. The findings\nunderscore the variability in LLMs' handling of linguistic ambiguities and\nhighlight the need for model improvements, particularly for non-European\nlanguages. This research informs future enhancements in LLM design to improve\naccuracy and human-like processing in diverse linguistic environments.\n","authors":["So Young Lee","Russell Scheinberg","Amber Shore","Ameeta Agrawal"],"pdf_url":"https://arxiv.org/pdf/2503.02971v1.pdf","comment":"Accepted at PACLIC 2024"},{"id":"http://arxiv.org/abs/2503.02969v1","updated":"2025-03-04T19:51:29Z","published":"2025-03-04T19:51:29Z","title":"InfiniSST: Simultaneous Translation of Unbounded Speech with Large\n  Language Model","summary":"  Simultaneous translation of unbounded streaming speech remains a challenging\nproblem due to the need for effectively processing the history speech context\nand past translations so that quality and latency, including computation\noverhead, can be balanced. Most prior works assume pre-segmented speech,\nlimiting their real-world applicability. In this paper, we propose InfiniSST, a\nnovel approach that formulates SST as a multi-turn dialogue task, enabling\nseamless translation of unbounded speech. We construct translation trajectories\nand robust segments from MuST-C with multi-latency augmentation during training\nand develop a key-value (KV) cache management strategy to facilitate efficient\ninference. Experiments on MuST-C En-Es, En-De, and En-Zh demonstrate that\nInfiniSST reduces computation-aware latency by 0.5 to 1 second while\nmaintaining the same translation quality compared to baselines. Ablation\nstudies further validate the contributions of our data construction and cache\nmanagement strategy. We release the code at\nhttps://github.com/LeiLiLab/InfiniSST\n","authors":["Siqi Ouyang","Xi Xu","Lei Li"],"pdf_url":"https://arxiv.org/pdf/2503.02969v1.pdf","comment":"Under Review"},{"id":"http://arxiv.org/abs/2503.02951v1","updated":"2025-03-04T19:17:36Z","published":"2025-03-04T19:17:36Z","title":"KodCode: A Diverse, Challenging, and Verifiable Synthetic Dataset for\n  Coding","summary":"  We introduce KodCode, a synthetic dataset that addresses the persistent\nchallenge of acquiring high-quality, verifiable training data across diverse\ndifficulties and domains for training Large Language Models for coding.\nExisting code-focused resources typically fail to ensure either the breadth of\ncoverage (e.g., spanning simple coding tasks to advanced algorithmic problems)\nor verifiable correctness (e.g., unit tests). In contrast, KodCode comprises\nquestion-solution-test triplets that are systematically validated via a\nself-verification procedure. Our pipeline begins by synthesizing a broad range\nof coding questions, then generates solutions and test cases with additional\nattempts allocated to challenging problems. Finally, post-training data\nsynthesis is done by rewriting questions into diverse formats and generating\nresponses under a test-based reject sampling procedure from a reasoning model\n(DeepSeek R1). This pipeline yields a large-scale, robust and diverse coding\ndataset. KodCode is suitable for supervised fine-tuning and the paired unit\ntests also provide great potential for RL tuning. Fine-tuning experiments on\ncoding benchmarks (HumanEval(+), MBPP(+), BigCodeBench, and LiveCodeBench)\ndemonstrate that KodCode-tuned models achieve state-of-the-art performance,\nsurpassing models like Qwen2.5-Coder-32B-Instruct and\nDeepSeek-R1-Distill-Llama-70B.\n","authors":["Zhangchen Xu","Yang Liu","Yueqin Yin","Mingyuan Zhou","Radha Poovendran"],"pdf_url":"https://arxiv.org/pdf/2503.02951v1.pdf","comment":"Codes and Data: https://kodcode-ai.github.io/"},{"id":"http://arxiv.org/abs/2409.13744v2","updated":"2025-03-04T19:15:49Z","published":"2024-09-11T00:16:17Z","title":"A Simplified Retriever to Improve Accuracy of Phenotype Normalizations\n  by Large Language Models","summary":"  Large language models (LLMs) have shown improved accuracy in phenotype term\nnormalization tasks when augmented with retrievers that suggest candidate\nnormalizations based on term definitions. In this work, we introduce a\nsimplified retriever that enhances LLM accuracy by searching the Human\nPhenotype Ontology (HPO) for candidate matches using contextual word embeddings\nfrom BioBERT without the need for explicit term definitions. Testing this\nmethod on terms derived from the clinical synopses of Online Mendelian\nInheritance in Man (OMIM), we demonstrate that the normalization accuracy of a\nstate-of-the-art LLM increases from a baseline of 62.3% without augmentation to\n90.3% with retriever augmentation. This approach is potentially generalizable\nto other biomedical term normalization tasks and offers an efficient\nalternative to more complex retrieval methods.\n","authors":["Daniel B. Hier","Thanh Son Do","Tayo Obafemi-Ajayi"],"pdf_url":"https://arxiv.org/pdf/2409.13744v2.pdf","comment":"Published by Frontiers in Digital Health"},{"id":"http://arxiv.org/abs/2503.02950v1","updated":"2025-03-04T19:13:10Z","published":"2025-03-04T19:13:10Z","title":"LiteWebAgent: The Open-Source Suite for VLM-Based Web-Agent Applications","summary":"  We introduce LiteWebAgent, an open-source suite for VLM-based web agent\napplications. Our framework addresses a critical gap in the web agent ecosystem\nwith a production-ready solution that combines minimal serverless backend\nconfiguration, intuitive user and browser interfaces, and extensible research\ncapabilities in agent planning, memory, and tree search. For the core\nLiteWebAgent agent framework, we implemented a simple yet effective baseline\nusing recursive function calling, providing with decoupled action generation\nand action grounding. In addition, we integrate advanced research components\nsuch as agent planning, agent workflow memory, and tree search in a modular and\nextensible manner. We then integrate the LiteWebAgent agent framework with\nfrontend and backend as deployed systems in two formats: (1) a production\nVercel-based web application, which provides users with an agent-controlled\nremote browser, (2) a Chrome extension leveraging LiteWebAgent's API to control\nan existing Chrome browser via CDP (Chrome DevTools Protocol). The LiteWebAgent\nframework is available at https://github.com/PathOnAI/LiteWebAgent, with\ndeployed frontend at https://lite-web-agent.vercel.app/.\n","authors":["Danqing Zhang","Balaji Rama","Jingyi Ni","Shiying He","Fu Zhao","Kunyu Chen","Arnold Chen","Junyu Cao"],"pdf_url":"https://arxiv.org/pdf/2503.02950v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.02948v1","updated":"2025-03-04T19:09:48Z","published":"2025-03-04T19:09:48Z","title":"ExpertGenQA: Open-ended QA generation in Specialized Domains","summary":"  Generating high-quality question-answer pairs for specialized technical\ndomains remains challenging, with existing approaches facing a tradeoff between\nleveraging expert examples and achieving topical diversity. We present\nExpertGenQA, a protocol that combines few-shot learning with structured topic\nand style categorization to generate comprehensive domain-specific QA pairs.\nUsing U.S. Federal Railroad Administration documents as a test bed, we\ndemonstrate that ExpertGenQA achieves twice the efficiency of baseline few-shot\napproaches while maintaining $94.4\\%$ topic coverage. Through systematic\nevaluation, we show that current LLM-based judges and reward models exhibit\nstrong bias toward superficial writing styles rather than content quality. Our\nanalysis using Bloom's Taxonomy reveals that ExpertGenQA better preserves the\ncognitive complexity distribution of expert-written questions compared to\ntemplate-based approaches. When used to train retrieval models, our generated\nqueries improve top-1 accuracy by $13.02\\%$ over baseline performance,\ndemonstrating their effectiveness for downstream applications in technical\ndomains.\n","authors":["Haz Sameen Shahgir","Chansong Lim","Jia Chen","Evangelos E. Papalexakis","Yue Dong"],"pdf_url":"https://arxiv.org/pdf/2503.02948v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2502.18282v2","updated":"2025-03-04T19:06:06Z","published":"2025-02-25T15:16:17Z","title":"Better Aligned with Survey Respondents or Training Data? Unveiling\n  Political Leanings of LLMs on U.S. Supreme Court Cases","summary":"  The increased adoption of Large Language Models (LLMs) and their potential to\nshape public opinion have sparked interest in assessing these models' political\nleanings. Building on previous research that compared LLMs and human opinions\nand observed political bias in system responses, we take a step further to\ninvestigate the underlying causes of such biases by empirically examining how\nthe values and biases embedded in training corpora shape model outputs.\nSpecifically, we propose a method to quantitatively evaluate political leanings\nembedded in the large pretraining corpora. Subsequently we investigate to whom\nare the LLMs' political leanings more aligned with, their pretrainig corpora or\nthe surveyed human opinions. As a case study, we focus on probing the political\nleanings of LLMs in 32 U.S. Supreme Court cases, addressing contentious topics\nsuch as abortion and voting rights. Our findings reveal that LLMs strongly\nreflect the political leanings in their training data, and no strong\ncorrelation is observed with their alignment to human opinions as expressed in\nsurveys. These results underscore the importance of responsible curation of\ntraining data and the need for robust evaluation metrics to ensure LLMs'\nalignment with human-centered values.\n","authors":["Shanshan Xu","T. Y. S. S Santosh","Yanai Elazar","Quirin Vogel","Barbara Plank","Matthias Grabmair"],"pdf_url":"https://arxiv.org/pdf/2502.18282v2.pdf","comment":"under review"}],"Computer Vision and Pattern Recognition":[{"id":"http://arxiv.org/abs/2502.20041v3","updated":"2025-03-04T07:37:57Z","published":"2025-02-27T12:29:44Z","title":"3D-AffordanceLLM: Harnessing Large Language Models for Open-Vocabulary\n  Affordance Detection in 3D Worlds","summary":"  3D Affordance detection is a challenging problem with broad applications on\nvarious robotic tasks. Existing methods typically formulate the detection\nparadigm as a label-based semantic segmentation task. This paradigm relies on\npredefined labels and lacks the ability to comprehend complex natural language,\nresulting in limited generalization in open-world scene. To address these\nlimitations, we reformulate the traditional affordance detection paradigm into\n\\textit{Instruction Reasoning Affordance Segmentation} (IRAS) task. This task\nis designed to output a affordance mask region given a query reasoning text,\nwhich avoids fixed categories of input labels. We accordingly propose the\n\\textit{3D-AffordanceLLM} (3D-ADLLM), a framework designed for reasoning\naffordance detection in 3D open-scene. Specifically, 3D-ADLLM introduces large\nlanguage models (LLMs) to 3D affordance perception with a custom-designed\ndecoder for generating affordance masks, thus achieving open-world reasoning\naffordance detection. In addition, given the scarcity of 3D affordance datasets\nfor training large models, we seek to extract knowledge from general\nsegmentation data and transfer it to affordance detection. Thus, we propose a\nmulti-stage training strategy that begins with a novel pre-training task, i.e.,\n\\textit{Referring Object Part Segmentation}~(ROPS). This stage is designed to\nequip the model with general recognition and segmentation capabilities at the\nobject-part level. Then followed by fine-tuning with the IRAS task, 3D-ADLLM\nobtains the reasoning ability for affordance detection. In summary, 3D-ADLLM\nleverages the rich world knowledge and human-object interaction reasoning\nability of LLMs, achieving approximately an 8\\% improvement in mIoU on\nopen-vocabulary affordance detection tasks.\n","authors":["Hengshuo Chu","Xiang Deng","Qi Lv","Xiaoyang Chen","Yinchuan Li","Jianye Hao","Liqiang Nie"],"pdf_url":"https://arxiv.org/pdf/2502.20041v3.pdf","comment":"ICLR"},{"id":"http://arxiv.org/abs/2405.14093v4","updated":"2025-03-04T08:24:20Z","published":"2024-05-23T01:43:54Z","title":"A Survey on Vision-Language-Action Models for Embodied AI","summary":"  Embodied AI is widely recognized as a key element of artificial general\nintelligence because it involves controlling embodied agents to perform tasks\nin the physical world. Building on the success of large language models and\nvision-language models, a new category of multimodal models -- referred to as\nvision-language-action models (VLAs) -- has emerged to address\nlanguage-conditioned robotic tasks in embodied AI by leveraging their distinct\nability to generate actions. In recent years, a myriad of VLAs have been\ndeveloped, making it imperative to capture the rapidly evolving landscape\nthrough a comprehensive survey. To this end, we present the first survey on\nVLAs for embodied AI. This work provides a detailed taxonomy of VLAs, organized\ninto three major lines of research. The first line focuses on individual\ncomponents of VLAs. The second line is dedicated to developing control policies\nadept at predicting low-level actions. The third line comprises high-level task\nplanners capable of decomposing long-horizon tasks into a sequence of subtasks,\nthereby guiding VLAs to follow more general user instructions. Furthermore, we\nprovide an extensive summary of relevant resources, including datasets,\nsimulators, and benchmarks. Finally, we discuss the challenges faced by VLAs\nand outline promising future directions in embodied AI. We have created a\nproject associated with this survey, which is available at\nhttps://github.com/yueen-ma/Awesome-VLA.\n","authors":["Yueen Ma","Zixing Song","Yuzheng Zhuang","Jianye Hao","Irwin King"],"pdf_url":"https://arxiv.org/pdf/2405.14093v4.pdf","comment":"Project page: https://github.com/yueen-ma/Awesome-VLA"},{"id":"http://arxiv.org/abs/2502.20092v3","updated":"2025-03-04T14:00:03Z","published":"2025-02-27T13:51:56Z","title":"WalnutData: A UAV Remote Sensing Dataset of Green Walnuts and Model\n  Evaluation","summary":"  The UAV technology is gradually maturing and can provide extremely powerful\nsupport for smart agriculture and precise monitoring. Currently, there is no\ndataset related to green walnuts in the field of agricultural computer vision.\nThus, in order to promote the algorithm design in the field of agricultural\ncomputer vision, we used UAV to collect remote-sensing data from 8 walnut\nsample plots. Considering that green walnuts are subject to various lighting\nconditions and occlusion, we constructed a large-scale dataset with a\nhigher-granularity of target features - WalnutData. This dataset contains a\ntotal of 30,240 images and 706,208 instances, and there are 4 target\ncategories: being illuminated by frontal light and unoccluded (A1), being\nbacklit and unoccluded (A2), being illuminated by frontal light and occluded\n(B1), and being backlit and occluded (B2). Subsequently, we evaluated many\nmainstream algorithms on WalnutData and used these evaluation results as the\nbaseline standard. The dataset and all evaluation results can be obtained at\nhttps://github.com/1wuming/WalnutData.\n","authors":["Mingjie Wu","Chenggui Yang","Huihua Wang","Chen Xue","Yibo Wang","Haoyu Wang","Yansong Wang","Can Peng","Yuqi Han","Ruoyu Li","Lijun Yun","Zaiqing Chen","Yuelong Xia"],"pdf_url":"https://arxiv.org/pdf/2502.20092v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.02883v1","updated":"2025-03-04T18:59:56Z","published":"2025-03-04T18:59:56Z","title":"ARINAR: Bi-Level Autoregressive Feature-by-Feature Generative Models","summary":"  Existing autoregressive (AR) image generative models use a token-by-token\ngeneration schema. That is, they predict a per-token probability distribution\nand sample the next token from that distribution. The main challenge is how to\nmodel the complex distribution of high-dimensional tokens. Previous methods\neither are too simplistic to fit the distribution or result in slow generation\nspeed. Instead of fitting the distribution of the whole tokens, we explore\nusing a AR model to generate each token in a feature-by-feature way, i.e.,\ntaking the generated features as input and generating the next feature. Based\non that, we propose ARINAR (AR-in-AR), a bi-level AR model. The outer AR layer\ntake previous tokens as input, predicts a condition vector z for the next\ntoken. The inner layer, conditional on z, generates features of the next token\nautoregressively. In this way, the inner layer only needs to model the\ndistribution of a single feature, for example, using a simple Gaussian Mixture\nModel. On the ImageNet 256x256 image generation task, ARINAR-B with 213M\nparameters achieves an FID of 2.75, which is comparable to the state-of-the-art\nMAR-B model (FID=2.31), while five times faster than the latter.\n","authors":["Qinyu Zhao","Stephen Gould","Liang Zheng"],"pdf_url":"https://arxiv.org/pdf/2503.02883v1.pdf","comment":"Technical report. Our code is available at\n  https://github.com/Qinyu-Allen-Zhao/Arinar"},{"id":"http://arxiv.org/abs/2503.02876v1","updated":"2025-03-04T18:57:12Z","published":"2025-03-04T18:57:12Z","title":"SPIDER: A Comprehensive Multi-Organ Supervised Pathology Dataset and\n  Baseline Models","summary":"  Advancing AI in computational pathology requires large, high-quality, and\ndiverse datasets, yet existing public datasets are often limited in organ\ndiversity, class coverage, or annotation quality. To bridge this gap, we\nintroduce SPIDER (Supervised Pathology Image-DEscription Repository), the\nlargest publicly available patch-level dataset covering multiple organ types,\nincluding Skin, Colorectal, and Thorax, with comprehensive class coverage for\neach organ. SPIDER provides high-quality annotations verified by expert\npathologists and includes surrounding context patches, which enhance\nclassification performance by providing spatial context.\n  Alongside the dataset, we present baseline models trained on SPIDER using the\nHibou-L foundation model as a feature extractor combined with an\nattention-based classification head. The models achieve state-of-the-art\nperformance across multiple tissue categories and serve as strong benchmarks\nfor future digital pathology research. Beyond patch classification, the model\nenables rapid identification of significant areas, quantitative tissue metrics,\nand establishes a foundation for multimodal approaches.\n  Both the dataset and trained models are publicly available to advance\nresearch, reproducibility, and AI-driven pathology development. Access them at:\nhttps://github.com/HistAI/SPIDER\n","authors":["Dmitry Nechaev","Alexey Pchelnikov","Ekaterina Ivanova"],"pdf_url":"https://arxiv.org/pdf/2503.02876v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.12915v3","updated":"2025-03-04T18:51:48Z","published":"2024-11-19T22:59:14Z","title":"VILA-M3: Enhancing Vision-Language Models with Medical Expert Knowledge","summary":"  Generalist vision language models (VLMs) have made significant strides in\ncomputer vision, but they fall short in specialized fields like healthcare,\nwhere expert knowledge is essential. In traditional computer vision tasks,\ncreative or approximate answers may be acceptable, but in healthcare, precision\nis paramount.Current large multimodal models like Gemini and GPT-4o are\ninsufficient for medical tasks due to their reliance on memorized internet\nknowledge rather than the nuanced expertise required in healthcare. VLMs are\nusually trained in three stages: vision pre-training, vision-language\npre-training, and instruction fine-tuning (IFT). IFT has been typically applied\nusing a mixture of generic and healthcare data. In contrast, we propose that\nfor medical VLMs, a fourth stage of specialized IFT is necessary, which focuses\non medical data and includes information from domain expert models. Domain\nexpert models developed for medical use are crucial because they are\nspecifically trained for certain clinical tasks, e.g. to detect tumors and\nclassify abnormalities through segmentation and classification, which learn\nfine-grained features of medical data$-$features that are often too intricate\nfor a VLM to capture effectively especially in radiology. This paper introduces\na new framework, VILA-M3, for medical VLMs that utilizes domain knowledge via\nexpert models. Through our experiments, we show an improved state-of-the-art\n(SOTA) performance with an average improvement of ~9% over the prior SOTA model\nMed-Gemini and ~6% over models trained on the specific tasks. Our approach\nemphasizes the importance of domain expertise in creating precise, reliable\nVLMs for medical applications.\n","authors":["Vishwesh Nath","Wenqi Li","Dong Yang","Andriy Myronenko","Mingxin Zheng","Yao Lu","Zhijian Liu","Hongxu Yin","Yucheng Tang","Pengfei Guo","Can Zhao","Ziyue Xu","Yufan He","Greg Heinrich","Yee Man Law","Benjamin Simon","Stephanie Harmon","Stephen Aylward","Marc Edgar","Michael Zephyr","Song Han","Pavlo Molchanov","Baris Turkbey","Holger Roth","Daguang Xu"],"pdf_url":"https://arxiv.org/pdf/2411.12915v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.00043v2","updated":"2025-03-04T18:47:38Z","published":"2025-02-25T23:36:19Z","title":"VOILA: Evaluation of MLLMs For Perceptual Understanding and Analogical\n  Reasoning","summary":"  Multimodal Large Language Models (MLLMs) have become a powerful tool for\nintegrating visual and textual information. Despite their exceptional\nperformance on visual understanding benchmarks, measuring their ability to\nreason abstractly across multiple images remains a significant challenge. To\naddress this, we introduce VOILA, a large-scale, open-ended, dynamic benchmark\ndesigned to evaluate MLLMs' perceptual understanding and abstract relational\nreasoning. VOILA employs an analogical mapping approach in the visual domain,\nrequiring models to generate an image that completes an analogy between two\ngiven image pairs, reference and application, without relying on predefined\nchoices. Our experiments demonstrate that the analogical reasoning tasks in\nVOILA present a challenge to MLLMs. Through multi-step analysis, we reveal that\ncurrent MLLMs struggle to comprehend inter-image relationships and exhibit\nlimited capabilities in high-level relational reasoning. Notably, we observe\nthat performance improves when following a multi-step strategy of least-to-most\nprompting. Comprehensive evaluations on open-source models and GPT-4o show that\non text-based answers, the best accuracy for challenging scenarios is 13%\n(LLaMa 3.2) and even for simpler tasks is only 29% (GPT-4o), while human\nperformance is significantly higher at 70% across both difficulty levels.\n","authors":["Nilay Yilmaz","Maitreya Patel","Yiran Lawrence Luo","Tejas Gokhale","Chitta Baral","Suren Jayasuriya","Yezhou Yang"],"pdf_url":"https://arxiv.org/pdf/2503.00043v2.pdf","comment":"Accepted at ICLR 2025. Code and data: https://github.com/nlylmz/Voila"},{"id":"http://arxiv.org/abs/2503.02857v1","updated":"2025-03-04T18:33:22Z","published":"2025-03-04T18:33:22Z","title":"Deepfake-Eval-2024: A Multi-Modal In-the-Wild Benchmark of Deepfakes\n  Circulated in 2024","summary":"  In the age of increasingly realistic generative AI, robust deepfake detection\nis essential for mitigating fraud and disinformation. While many deepfake\ndetectors report high accuracy on academic datasets, we show that these\nacademic benchmarks are out of date and not representative of recent deepfakes.\nWe introduce Deepfake-Eval-2024, a new deepfake detection benchmark consisting\nof in-the-wild deepfakes collected from social media and deepfake detection\nplatform users in 2024. Deepfake-Eval-2024 consists of 44 hours of videos, 56.5\nhours of audio, and 1,975 images, encompassing the latest manipulation\ntechnologies. The benchmark contains diverse media content from 88 different\nwebsites in 52 different languages. We find that the performance of open-source\nstate-of-the-art deepfake detection models drops precipitously when evaluated\non Deepfake-Eval-2024, with AUC decreasing by 50% for video, 48% for audio, and\n45% for image models compared to previous benchmarks. We also evaluate\ncommercial deepfake detection models and models finetuned on\nDeepfake-Eval-2024, and find that they have superior performance to\noff-the-shelf open-source models, but they do not yet reach the accuracy of\nhuman deepfake forensic analysts. The dataset is available at\nhttps://github.com/nuriachandra/Deepfake-Eval-2024.\n","authors":["Nuria Alina Chandra","Ryan Murtfeldt","Lin Qiu","Arnab Karmakar","Hannah Lee","Emmanuel Tanumihardja","Kevin Farhat","Ben Caffee","Sejin Paik","Changyeon Lee","Jongwook Choi","Aerin Kim","Oren Etzioni"],"pdf_url":"https://arxiv.org/pdf/2503.02857v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.02853v1","updated":"2025-03-04T18:29:57Z","published":"2025-03-04T18:29:57Z","title":"CADDI: An in-Class Activity Detection Dataset using IMU data from\n  low-cost sensors","summary":"  The monitoring and prediction of in-class student activities is of paramount\nimportance for the comprehension of engagement and the enhancement of\npedagogical efficacy. The accurate detection of these activities enables\neducators to modify their lessons in real time, thereby reducing negative\nemotional states and enhancing the overall learning experience. To this end,\nthe use of non-intrusive devices, such as inertial measurement units (IMUs)\nembedded in smartwatches, represents a viable solution. The development of\nreliable predictive systems has been limited by the lack of large, labeled\ndatasets in education. To bridge this gap, we present a novel dataset for\nin-class activity detection using affordable IMU sensors. The dataset comprises\n19 diverse activities, both instantaneous and continuous, performed by 12\nparticipants in typical classroom scenarios. It includes accelerometer,\ngyroscope, rotation vector data, and synchronized stereo images, offering a\ncomprehensive resource for developing multimodal algorithms using sensor and\nvisual data. This dataset represents a key step toward scalable solutions for\nactivity recognition in educational settings.\n","authors":["Luis Marquez-Carpintero","Sergio Suescun-Ferrandiz","Monica Pina-Navarro","Miguel Cazorla","Francisco Gomez-Donoso"],"pdf_url":"https://arxiv.org/pdf/2503.02853v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.02849v1","updated":"2025-03-04T18:24:33Z","published":"2025-03-04T18:24:33Z","title":"Multimodal Deep Learning for Subtype Classification in Breast Cancer\n  Using Histopathological Images and Gene Expression Data","summary":"  Molecular subtyping of breast cancer is crucial for personalized treatment\nand prognosis. Traditional classification approaches rely on either\nhistopathological images or gene expression profiling, limiting their\npredictive power. In this study, we propose a deep multimodal learning\nframework that integrates histopathological images and gene expression data to\nclassify breast cancer into BRCA.Luminal and BRCA.Basal / Her2 subtypes. Our\napproach employs a ResNet-50 model for image feature extraction and fully\nconnected layers for gene expression processing, with a cross-attention fusion\nmechanism to enhance modality interaction. We conduct extensive experiments\nusing five-fold cross-validation, demonstrating that our multimodal integration\noutperforms unimodal approaches in terms of classification accuracy,\nprecision-recall AUC, and F1-score. Our findings highlight the potential of\ndeep learning for robust and interpretable breast cancer subtype\nclassification, paving the way for improved clinical decision-making.\n","authors":["Amin Honarmandi Shandiz"],"pdf_url":"https://arxiv.org/pdf/2503.02849v1.pdf","comment":"9 pages, 9 figures"},{"id":"http://arxiv.org/abs/2503.02841v1","updated":"2025-03-04T18:12:58Z","published":"2025-03-04T18:12:58Z","title":"Boltzmann Attention Sampling for Image Analysis with Small Objects","summary":"  Detecting and segmenting small objects, such as lung nodules and tumor\nlesions, remains a critical challenge in image analysis. These objects often\noccupy less than 0.1% of an image, making traditional transformer architectures\ninefficient and prone to performance degradation due to redundant attention\ncomputations on irrelevant regions. Existing sparse attention mechanisms rely\non rigid hierarchical structures, which are poorly suited for detecting small,\nvariable, and uncertain object locations. In this paper, we propose\nBoltzFormer, a novel transformer-based architecture designed to address these\nchallenges through dynamic sparse attention. BoltzFormer identifies and focuses\nattention on relevant areas by modeling uncertainty using a Boltzmann\ndistribution with an annealing schedule. Initially, a higher temperature allows\nbroader area sampling in early layers, when object location uncertainty is\ngreatest. As the temperature decreases in later layers, attention becomes more\nfocused, enhancing efficiency and accuracy. BoltzFormer seamlessly integrates\ninto existing transformer architectures via a modular Boltzmann attention\nsampling mechanism. Comprehensive evaluations on benchmark datasets demonstrate\nthat BoltzFormer significantly improves segmentation performance for small\nobjects while reducing attention computation by an order of magnitude compared\nto previous state-of-the-art methods.\n","authors":["Theodore Zhao","Sid Kiblawi","Naoto Usuyama","Ho Hin Lee","Sam Preston","Hoifung Poon","Mu Wei"],"pdf_url":"https://arxiv.org/pdf/2503.02841v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.02835v1","updated":"2025-03-04T17:58:44Z","published":"2025-03-04T17:58:44Z","title":"In-Depth Analysis of Automated Acne Disease Recognition and\n  Classification","summary":"  Facial acne is a common disease, especially among adolescents, negatively\naffecting both physically and psychologically. Classifying acne is vital to\nproviding the appropriate treatment. Traditional visual inspection or expert\nscanning is time-consuming and difficult to differentiate acne types. This\npaper introduces an automated expert system for acne recognition and\nclassification. The proposed method employs a machine learning-based technique\nto classify and evaluate six types of acne diseases to facilitate the diagnosis\nof dermatologists. The pre-processing phase includes contrast improvement,\nsmoothing filter, and RGB to L*a*b color conversion to eliminate noise and\nimprove the classification accuracy. Then, a clustering-based segmentation\nmethod, k-means clustering, is applied for segmenting the disease-affected\nregions that pass through the feature extraction step. Characteristics of these\ndisease-affected regions are extracted based on a combination of gray-level\nco-occurrence matrix (GLCM) and Statistical features. Finally, five different\nmachine learning classifiers are employed to classify acne diseases.\nExperimental results show that the Random Forest (RF) achieves the highest\naccuracy of 98.50%, which is promising compared to the state-of-the-art\nmethods.\n","authors":["Afsana Ahsan Jeny","Masum Shah Junayed","Md Robel Mia","Md Baharul Islam"],"pdf_url":"https://arxiv.org/pdf/2503.02835v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2502.17648v3","updated":"2025-03-04T17:54:37Z","published":"2025-02-24T20:53:42Z","title":"CalibRefine: Deep Learning-Based Online Automatic Targetless\n  LiDAR-Camera Calibration with Iterative and Attention-Driven Post-Refinement","summary":"  Accurate multi-sensor calibration is essential for deploying robust\nperception systems in applications such as autonomous driving, robotics, and\nintelligent transportation. Existing LiDAR-camera calibration methods often\nrely on manually placed targets, preliminary parameter estimates, or intensive\ndata preprocessing, limiting their scalability and adaptability in real-world\nsettings. In this work, we propose a fully automatic, targetless, and online\ncalibration framework, CalibRefine, which directly processes raw LiDAR point\nclouds and camera images. Our approach is divided into four stages: (1) a\nCommon Feature Discriminator that trains on automatically detected\nobjects--using relative positions, appearance embeddings, and semantic\nclasses--to generate reliable LiDAR-camera correspondences, (2) a coarse\nhomography-based calibration, (3) an iterative refinement to incrementally\nimprove alignment as additional data frames become available, and (4) an\nattention-based refinement that addresses non-planar distortions by leveraging\na Vision Transformer and cross-attention mechanisms. Through extensive\nexperiments on two urban traffic datasets, we show that CalibRefine delivers\nhigh-precision calibration results with minimal human involvement,\noutperforming state-of-the-art targetless methods and remaining competitive\nwith, or surpassing, manually tuned baselines. Our findings highlight how\nrobust object-level feature matching, together with iterative and\nself-supervised attention-based adjustments, enables consistent sensor fusion\nin complex, real-world conditions without requiring ground-truth calibration\nmatrices or elaborate data preprocessing.\n","authors":["Lei Cheng","Lihao Guo","Tianya Zhang","Tam Bang","Austin Harris","Mustafa Hajij","Mina Sartipi","Siyang Cao"],"pdf_url":"https://arxiv.org/pdf/2502.17648v3.pdf","comment":"Submitted to Transportation Research Part C: Emerging Technologies"},{"id":"http://arxiv.org/abs/2503.02824v1","updated":"2025-03-04T17:49:07Z","published":"2025-03-04T17:49:07Z","title":"Developing a PET/CT Foundation Model for Cross-Modal Anatomical and\n  Functional Imaging","summary":"  In oncology, Positron Emission Tomography-Computed Tomography (PET/CT) is\nwidely used in cancer diagnosis, staging, and treatment monitoring, as it\ncombines anatomical details from CT with functional metabolic activity and\nmolecular marker expression information from PET. However, existing artificial\nintelligence-driven PET/CT analyses rely predominantly on task-specific models\ntrained from scratch or on limited datasets, limiting their generalizability\nand robustness. To address this, we propose a foundation model approach\nspecifically designed for multimodal PET/CT imaging. We introduce the\nCross-Fraternal Twin Masked Autoencoder (FratMAE), a novel framework that\neffectively integrates whole-body anatomical and functional or molecular\ninformation. FratMAE employs separate Vision Transformer (ViT) encoders for PET\nand CT scans, along with cross-attention decoders that enable synergistic\ninteractions between modalities during masked autoencoder training.\nAdditionally, it incorporates textual metadata to enhance PET representation\nlearning. By pre-training on PET/CT datasets, FratMAE captures intricate\ncross-modal relationships and global uptake patterns, achieving superior\nperformance on downstream tasks and demonstrating its potential as a\ngeneralizable foundation model.\n","authors":["Yujin Oh","Robert Seifert","Yihan Cao","Christoph Clement","Justin Ferdinandus","Constantin Lapa","Alessandro Liebich","Michelle Amon","Johanna Enke","Sifan Song","Runqi Meng","Fang Zeng","Ning Guo","Xiang Li","Pedram Heidari","Axel Rominger","Kuangyu Shi","Quanzheng Li"],"pdf_url":"https://arxiv.org/pdf/2503.02824v1.pdf","comment":"11 pages, 2 figures, 3 tables"},{"id":"http://arxiv.org/abs/2311.12836v2","updated":"2025-03-04T17:24:53Z","published":"2023-10-03T16:09:07Z","title":"AI-based association analysis for medical imaging using latent-space\n  geometric confounder correction","summary":"  This study addresses the challenges of confounding effects and\ninterpretability in artificial-intelligence-based medical image analysis.\nWhereas existing literature often resolves confounding by removing\nconfounder-related information from latent representations, this strategy risks\naffecting image reconstruction quality in generative models, thus limiting\ntheir applicability in feature visualization. To tackle this, we propose a\ndifferent strategy that retains confounder-related information in latent\nrepresentations while finding an alternative confounder-free representation of\nthe image data.\n  Our approach views the latent space of an autoencoder as a vector space,\nwhere imaging-related variables, such as the learning target (t) and confounder\n(c), have a vector capturing their variability. The confounding problem is\naddressed by searching a confounder-free vector which is orthogonal to the\nconfounder-related vector but maximally collinear to the target-related vector.\nTo achieve this, we introduce a novel correlation-based loss that not only\nperforms vector searching in the latent space, but also encourages the encoder\nto generate latent representations linearly correlated with the variables.\nSubsequently, we interpret the confounder-free representation by sampling and\nreconstructing images along the confounder-free vector.\n  The efficacy and flexibility of our proposed method are demonstrated across\nthree applications, accommodating multiple confounders and utilizing diverse\nimage modalities. Results affirm the method's effectiveness in reducing\nconfounder influences, preventing wrong or misleading associations, and\noffering a unique visual interpretation for in-depth investigations by clinical\nand epidemiological researchers. The code is released in the following GitLab\nrepository:\nhttps://gitlab.com/radiology/compopbio/ai_based_association_analysis}\n","authors":["Xianjing Liu","Bo Li","Meike W. Vernooij","Eppo B. Wolvius","Gennady V. Roshchupkin","Esther E. Bron"],"pdf_url":"https://arxiv.org/pdf/2311.12836v2.pdf","comment":"Accepted by Medical Image Analysis"},{"id":"http://arxiv.org/abs/2410.02098v5","updated":"2025-03-04T17:23:51Z","published":"2024-10-02T23:39:10Z","title":"EC-DIT: Scaling Diffusion Transformers with Adaptive Expert-Choice\n  Routing","summary":"  Diffusion transformers have been widely adopted for text-to-image synthesis.\nWhile scaling these models up to billions of parameters shows promise, the\neffectiveness of scaling beyond current sizes remains underexplored and\nchallenging. By explicitly exploiting the computational heterogeneity of image\ngenerations, we develop a new family of Mixture-of-Experts (MoE) models\n(EC-DIT) for diffusion transformers with expert-choice routing. EC-DIT learns\nto adaptively optimize the compute allocated to understand the input texts and\ngenerate the respective image patches, enabling heterogeneous computation\naligned with varying text-image complexities. This heterogeneity provides an\nefficient way of scaling EC-DIT up to 97 billion parameters and achieving\nsignificant improvements in training convergence, text-to-image alignment, and\noverall generation quality over dense models and conventional MoE models.\nThrough extensive ablations, we show that EC-DIT demonstrates superior\nscalability and adaptive compute allocation by recognizing varying textual\nimportance through end-to-end training. Notably, in text-to-image alignment\nevaluation, our largest models achieve a state-of-the-art GenEval score of\n71.68% and still maintain competitive inference speed with intuitive\ninterpretability.\n","authors":["Haotian Sun","Tao Lei","Bowen Zhang","Yanghao Li","Haoshuo Huang","Ruoming Pang","Bo Dai","Nan Du"],"pdf_url":"https://arxiv.org/pdf/2410.02098v5.pdf","comment":null},{"id":"http://arxiv.org/abs/2408.11196v3","updated":"2025-03-04T17:23:27Z","published":"2024-08-20T21:06:05Z","title":"Robust Long-Range Perception Against Sensor Misalignment in Autonomous\n  Vehicles","summary":"  Advances in machine learning algorithms for sensor fusion have significantly\nimproved the detection and prediction of other road users, thereby enhancing\nsafety. However, even a small angular displacement in the sensor's placement\ncan cause significant degradation in output, especially at long range. In this\npaper, we demonstrate a simple yet generic and efficient multi-task learning\napproach that not only detects misalignment between different sensor modalities\nbut is also robust against them for long-range perception. Along with the\namount of misalignment, our method also predicts calibrated uncertainty, which\ncan be useful for filtering and fusing predicted misalignment values over time.\nIn addition, we show that the predicted misalignment parameters can be used for\nself-correcting input sensor data, further improving the perception performance\nunder sensor misalignment.\n","authors":["Zi-Xiang Xia","Sudeep Fadadu","Yi Shi","Louis Foucard"],"pdf_url":"https://arxiv.org/pdf/2408.11196v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.02799v1","updated":"2025-03-04T17:18:43Z","published":"2025-03-04T17:18:43Z","title":"MX-Font++: Mixture of Heterogeneous Aggregation Experts for Few-shot\n  Font Generation","summary":"  Few-shot Font Generation (FFG) aims to create new font libraries using\nlimited reference glyphs, with crucial applications in digital accessibility\nand equity for low-resource languages, especially in multilingual artificial\nintelligence systems. Although existing methods have shown promising\nperformance, transitioning to unseen characters in low-resource languages\nremains a significant challenge, especially when font glyphs vary considerably\nacross training sets. MX-Font considers the content of a character from the\nperspective of a local component, employing a Mixture of Experts (MoE) approach\nto adaptively extract the component for better transition. However, the lack of\na robust feature extractor prevents them from adequately decoupling content and\nstyle, leading to sub-optimal generation results. To alleviate these problems,\nwe propose Heterogeneous Aggregation Experts (HAE), a powerful feature\nextraction expert that helps decouple content and style downstream from being\nable to aggregate information in channel and spatial dimensions. Additionally,\nwe propose a novel content-style homogeneity loss to enhance the untangling.\nExtensive experiments on several datasets demonstrate that our MX-Font++ yields\nsuperior visual results in FFG and effectively outperforms state-of-the-art\nmethods. Code and data are available at\nhttps://github.com/stephensun11/MXFontpp.\n","authors":["Weihang Wang","Duolin Sun","Jielei Zhang","Longwen Gao"],"pdf_url":"https://arxiv.org/pdf/2503.02799v1.pdf","comment":"4 pages, 4 figures, accepted by ICASSP 2025"},{"id":"http://arxiv.org/abs/2503.02797v1","updated":"2025-03-04T17:15:31Z","published":"2025-03-04T17:15:31Z","title":"A Causal Framework for Aligning Image Quality Metrics and Deep Neural\n  Network Robustness","summary":"  Image quality plays an important role in the performance of deep neural\nnetworks (DNNs) and DNNs have been widely shown to exhibit sensitivity to\nchanges in imaging conditions. Large-scale datasets often contain images under\na wide range of conditions prompting a need to quantify and understand their\nunderlying quality distribution in order to better characterize DNN performance\nand robustness. Aligning the sensitivities of image quality metrics and DNNs\nensures that estimates of quality can act as proxies for image/dataset\ndifficulty independent of the task models trained/evaluated on the data.\nConventional image quality assessment (IQA) seeks to measure and align quality\nrelative to human perceptual judgments, but here we seek a quality measure that\nis not only sensitive to imaging conditions but also well-aligned with DNN\nsensitivities. We first ask whether conventional IQA metrics are also\ninformative of DNN performance. In order to answer this question, we reframe\nIQA from a causal perspective and examine conditions under which quality\nmetrics are predictive of DNN performance. We show theoretically and\nempirically that current IQA metrics are weak predictors of DNN performance in\nthe context of classification. We then use our causal framework to provide an\nalternative formulation and a new image quality metric that is more strongly\ncorrelated with DNN performance and can act as a prior on performance without\ntraining new task models. Our approach provides a means to directly estimate\nthe quality distribution of large-scale image datasets towards characterizing\nthe relationship between dataset composition and DNN performance.\n","authors":["Nathan Drenkow","Mathias Unberath"],"pdf_url":"https://arxiv.org/pdf/2503.02797v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2501.01022v3","updated":"2025-03-04T16:59:53Z","published":"2025-01-02T02:49:13Z","title":"Efficient Connectivity-Preserving Instance Segmentation with\n  Supervoxel-Based Loss Function","summary":"  Reconstructing the intricate local morphology of neurons and their long-range\nprojecting axons can address many connectivity related questions in\nneuroscience. The main bottleneck in connectomics pipelines is correcting\ntopological errors, as multiple entangled neuronal arbors is a challenging\ninstance segmentation problem. More broadly, segmentation of curvilinear,\nfilamentous structures continues to pose significant challenges. To address\nthis problem, we extend the notion of simple points from digital topology to\nconnected sets of voxels (i.e. supervoxels) and propose a topology-aware neural\nnetwork segmentation method with minimal computational overhead. We demonstrate\nits effectiveness on a new public dataset of 3-d light microscopy images of\nmouse brains, along with the benchmark datasets DRIVE, ISBI12, and CrackTree.\n","authors":["Anna Grim","Jayaram Chandrashekar","Uygar Sumbul"],"pdf_url":"https://arxiv.org/pdf/2501.01022v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2502.14827v2","updated":"2025-03-04T16:43:01Z","published":"2025-02-20T18:45:00Z","title":"Exploring Advanced Techniques for Visual Question Answering: A\n  Comprehensive Comparison","summary":"  Visual Question Answering (VQA) has emerged as a pivotal task in the\nintersection of computer vision and natural language processing, requiring\nmodels to understand and reason about visual content in response to natural\nlanguage questions. Analyzing VQA datasets is essential for developing robust\nmodels that can handle the complexities of multimodal reasoning. Several\napproaches have been developed to examine these datasets, each offering\ndistinct perspectives on question diversity, answer distribution, and\nvisual-textual correlations. Despite significant progress, existing VQA models\nface challenges related to dataset bias, limited model complexity, commonsense\nreasoning gaps, rigid evaluation methods, and generalization to real world\nscenarios. This paper offers a detailed study of the original VQA dataset,\nbaseline models and methods along with a comparative study of five advanced VQA\nmodels, ABC-CNN, KICNLE, Masked Vision and Language Modeling, BLIP-2, and OFA,\neach employing distinct methods to address these ongoing challenges.\n","authors":["Aiswarya Baby","Tintu Thankom Koshy"],"pdf_url":"https://arxiv.org/pdf/2502.14827v2.pdf","comment":"8 pages, No figures"},{"id":"http://arxiv.org/abs/2503.02767v1","updated":"2025-03-04T16:33:58Z","published":"2025-03-04T16:33:58Z","title":"Undertrained Image Reconstruction for Realistic Degradation in Blind\n  Image Super-Resolution","summary":"  Most super-resolution (SR) models struggle with real-world low-resolution\n(LR) images. This issue arises because the degradation characteristics in the\nsynthetic datasets differ from those in real-world LR images. Since SR models\nare trained on pairs of high-resolution (HR) and LR images generated by\ndownsampling, they are optimized for simple degradation. However, real-world LR\nimages contain complex degradation caused by factors such as the imaging\nprocess and JPEG compression. Due to these differences in degradation\ncharacteristics, most SR models perform poorly on real-world LR images. This\nstudy proposes a dataset generation method using undertrained image\nreconstruction models. These models have the property of reconstructing\nlow-quality images with diverse degradation from input images. By leveraging\nthis property, this study generates LR images with diverse degradation from HR\nimages to construct the datasets. Fine-tuning pre-trained SR models on our\ngenerated datasets improves noise removal and blur reduction, enhancing\nperformance on real-world LR images. Furthermore, an analysis of the datasets\nreveals that degradation diversity contributes to performance improvements,\nwhereas color differences between HR and LR images may degrade performance. 11\npages, (11 figures and 2 tables)\n","authors":["Ru Ito","Supatta Viriyavisuthisakul","Kazuhiko Kawamoto","Hiroshi Kera"],"pdf_url":"https://arxiv.org/pdf/2503.02767v1.pdf","comment":"11 pages, 11 figures, 2 tables"},{"id":"http://arxiv.org/abs/2409.04429v3","updated":"2025-03-04T16:31:57Z","published":"2024-09-06T17:49:56Z","title":"VILA-U: a Unified Foundation Model Integrating Visual Understanding and\n  Generation","summary":"  VILA-U is a Unified foundation model that integrates Video, Image, Language\nunderstanding and generation. Traditional visual language models (VLMs) use\nseparate modules for understanding and generating visual content, which can\nlead to misalignment and increased complexity. In contrast, VILA-U employs a\nsingle autoregressive next-token prediction framework for both tasks,\neliminating the need for additional components like diffusion models. This\napproach not only simplifies the model but also achieves near state-of-the-art\nperformance in visual language understanding and generation. The success of\nVILA-U is attributed to two main factors: the unified vision tower that aligns\ndiscrete visual tokens with textual inputs during pretraining, which enhances\nvisual perception, and autoregressive image generation can achieve similar\nquality as diffusion models with high-quality dataset. This allows VILA-U to\nperform comparably to more complex models using a fully token-based\nautoregressive framework.\n","authors":["Yecheng Wu","Zhuoyang Zhang","Junyu Chen","Haotian Tang","Dacheng Li","Yunhao Fang","Ligeng Zhu","Enze Xie","Hongxu Yin","Li Yi","Song Han","Yao Lu"],"pdf_url":"https://arxiv.org/pdf/2409.04429v3.pdf","comment":"Code: https://github.com/mit-han-lab/vila-u. The first two authors\n  contributed equally to this work"},{"id":"http://arxiv.org/abs/2501.17792v2","updated":"2025-03-04T16:25:51Z","published":"2025-01-29T17:31:46Z","title":"CrowdSplat: Exploring Gaussian Splatting For Crowd Rendering","summary":"  We present CrowdSplat, a novel approach that leverages 3D Gaussian Splatting\nfor real-time, high-quality crowd rendering. Our method utilizes 3D Gaussian\nfunctions to represent animated human characters in diverse poses and outfits,\nwhich are extracted from monocular videos. We integrate Level of Detail (LoD)\nrendering to optimize computational efficiency and quality. The CrowdSplat\nframework consists of two stages: (1) avatar reconstruction and (2) crowd\nsynthesis. The framework is also optimized for GPU memory usage to enhance\nscalability. Quantitative and qualitative evaluations show that CrowdSplat\nachieves good levels of rendering quality, memory efficiency, and computational\nperformance. Through these experiments, we demonstrate that CrowdSplat is a\nviable solution for dynamic, realistic crowd simulation in real-time\napplications.\n","authors":["Xiaohan Sun","Yinghan Xu","John Dingliana","Carol O'Sullivan"],"pdf_url":"https://arxiv.org/pdf/2501.17792v2.pdf","comment":"4 pages, 4 figures"},{"id":"http://arxiv.org/abs/2503.02752v1","updated":"2025-03-04T16:19:06Z","published":"2025-03-04T16:19:06Z","title":"Deep Learning-Enhanced Visual Monitoring in Hazardous Underwater\n  Environments with a Swarm of Micro-Robots","summary":"  Long-term monitoring and exploration of extreme environments, such as\nunderwater storage facilities, is costly, labor-intensive, and hazardous.\nAutomating this process with low-cost, collaborative robots can greatly improve\nefficiency. These robots capture images from different positions, which must be\nprocessed simultaneously to create a spatio-temporal model of the facility. In\nthis paper, we propose a novel approach that integrates data simulation, a\nmulti-modal deep learning network for coordinate prediction, and image\nreassembly to address the challenges posed by environmental disturbances\ncausing drift and rotation in the robots' positions and orientations. Our\napproach enhances the precision of alignment in noisy environments by\nintegrating visual information from snapshots, global positional context from\nmasks, and noisy coordinates. We validate our method through extensive\nexperiments using synthetic data that simulate real-world robotic operations in\nunderwater settings. The results demonstrate very high coordinate prediction\naccuracy and plausible image assembly, indicating the real-world applicability\nof our approach. The assembled images provide clear and coherent views of the\nunderwater environment for effective monitoring and inspection, showcasing the\npotential for broader use in extreme settings, further contributing to improved\nsafety, efficiency, and cost reduction in hazardous field monitoring. Code is\navailable on https://github.com/ChrisChen1023/Micro-Robot-Swarm.\n","authors":["Shuang Chen","Yifeng He","Barry Lennox","Farshad Arvin","Amir Atapour-Abarghouei"],"pdf_url":"https://arxiv.org/pdf/2503.02752v1.pdf","comment":"Accepted by ICRA 2025"},{"id":"http://arxiv.org/abs/2501.17085v2","updated":"2025-03-04T16:17:14Z","published":"2025-01-28T17:14:13Z","title":"Evaluating CrowdSplat: Perceived Level of Detail for Gaussian Crowds","summary":"  Efficient and realistic crowd rendering is an important element of many\nreal-time graphics applications such as Virtual Reality (VR) and games. To this\nend, Levels of Detail (LOD) avatar representations such as polygonal meshes,\nimage-based impostors, and point clouds have been proposed and evaluated. More\nrecently, 3D Gaussian Splatting has been explored as a potential method for\nreal-time crowd rendering. In this paper, we present a two-alternative forced\nchoice (2AFC) experiment that aims to determine the perceived quality of 3D\nGaussian avatars. Three factors were explored: Motion, LOD (i.e., #Gaussians),\nand the avatar height in Pixels (corresponding to the viewing distance).\nParticipants viewed pairs of animated 3D Gaussian avatars and were tasked with\nchoosing the most detailed one. Our findings can inform the optimization of LOD\nstrategies in Gaussian-based crowd rendering, thereby helping to achieve\nefficient rendering while maintaining visual quality in real-time applications.\n","authors":["Xiaohan Sun","Yinghan Xu","John Dingliana","Carol O'Sullivan"],"pdf_url":"https://arxiv.org/pdf/2501.17085v2.pdf","comment":"5 pages, 5 figures"},{"id":"http://arxiv.org/abs/2503.02745v1","updated":"2025-03-04T16:10:42Z","published":"2025-03-04T16:10:42Z","title":"ArcPro: Architectural Programs for Structured 3D Abstraction of Sparse\n  Points","summary":"  We introduce ArcPro, a novel learning framework built on architectural\nprograms to recover structured 3D abstractions from highly sparse and\nlow-quality point clouds. Specifically, we design a domain-specific language\n(DSL) to hierarchically represent building structures as a program, which can\nbe efficiently converted into a mesh. We bridge feedforward and inverse\nprocedural modeling by using a feedforward process for training data synthesis,\nallowing the network to make reverse predictions. We train an encoder-decoder\non the points-program pairs to establish a mapping from unstructured point\nclouds to architectural programs, where a 3D convolutional encoder extracts\npoint cloud features and a transformer decoder autoregressively predicts the\nprograms in a tokenized form. Inference by our method is highly efficient and\nproduces plausible and faithful 3D abstractions. Comprehensive experiments\ndemonstrate that ArcPro outperforms both traditional architectural proxy\nreconstruction and learning-based abstraction methods. We further explore its\npotential to work with multi-view image and natural language inputs.\n","authors":["Qirui Huang","Runze Zhang","Kangjun Liu","Minglun Gong","Hao Zhang","Hui Huang"],"pdf_url":"https://arxiv.org/pdf/2503.02745v1.pdf","comment":"CVPR 2025 (Patent Protected); Project page:\n  https://vcc.tech/research/2025/ArcPro"},{"id":"http://arxiv.org/abs/2503.01193v2","updated":"2025-03-04T16:08:27Z","published":"2025-03-03T05:38:57Z","title":"Near-infrared Image Deblurring and Event Denoising with Synergistic\n  Neuromorphic Imaging","summary":"  The fields of imaging in the nighttime dynamic and other extremely dark\nconditions have seen impressive and transformative advancements in recent\nyears, partly driven by the rise of novel sensing approaches, e.g.,\nnear-infrared (NIR) cameras with high sensitivity and event cameras with\nminimal blur. However, inappropriate exposure ratios of near-infrared cameras\nmake them susceptible to distortion and blur. Event cameras are also highly\nsensitive to weak signals at night yet prone to interference, often generating\nsubstantial noise and significantly degrading observations and analysis.\nHerein, we develop a new framework for low-light imaging combined with NIR\nimaging and event-based techniques, named synergistic neuromorphic imaging,\nwhich can jointly achieve NIR image deblurring and event denoising. Harnessing\ncross-modal features of NIR images and visible events via spectral consistency\nand higher-order interaction, the NIR images and events are simultaneously\nfused, enhanced, and bootstrapped. Experiments on real and realistically\nsimulated sequences demonstrate the effectiveness of our method and indicate\nbetter accuracy and robustness than other methods in practical scenarios. This\nstudy gives impetus to enhance both NIR images and events, which paves the way\nfor high-fidelity low-light imaging and neuromorphic reasoning.\n","authors":["Chao Qu","Shuo Zhu","Yuhang Wang","Zongze Wu","Xiaoyu Chen","Edmund Y. Lam","Jing Han"],"pdf_url":"https://arxiv.org/pdf/2503.01193v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.02733v1","updated":"2025-03-04T15:54:57Z","published":"2025-03-04T15:54:57Z","title":"UAR-NVC: A Unified AutoRegressive Framework for Memory-Efficient Neural\n  Video Compression","summary":"  Implicit Neural Representations (INRs) have demonstrated significant\npotential in video compression by representing videos as neural networks.\nHowever, as the number of frames increases, the memory consumption for training\nand inference increases substantially, posing challenges in\nresource-constrained scenarios. Inspired by the success of traditional video\ncompression frameworks, which process video frame by frame and can efficiently\ncompress long videos, we adopt this modeling strategy for INRs to decrease\nmemory consumption, while aiming to unify the frameworks from the perspective\nof timeline-based autoregressive modeling. In this work, we present a novel\nunderstanding of INR models from an autoregressive (AR) perspective and\nintroduce a Unified AutoRegressive Framework for memory-efficient Neural Video\nCompression (UAR-NVC). UAR-NVC integrates timeline-based and INR-based neural\nvideo compression under a unified autoregressive paradigm. It partitions videos\ninto several clips and processes each clip using a different INR model\ninstance, leveraging the advantages of both compression frameworks while\nallowing seamless adaptation to either in form. To further reduce temporal\nredundancy between clips, we design two modules to optimize the initialization,\ntraining, and compression of these model parameters. UAR-NVC supports\nadjustable latencies by varying the clip length. Extensive experimental results\ndemonstrate that UAR-NVC, with its flexible video clip setting, can adapt to\nresource-constrained environments and significantly improve performance\ncompared to different baseline models.\n","authors":["Jia Wang","Xinfeng Zhang","Gai Zhang","Jun Zhu","Lv Tang","Li Zhang"],"pdf_url":"https://arxiv.org/pdf/2503.02733v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.02730v1","updated":"2025-03-04T15:49:42Z","published":"2025-03-04T15:49:42Z","title":"Creating Sorted Grid Layouts with Gradient-based Optimization","summary":"  Visually sorted grid layouts provide an efficient method for organizing\nhigh-dimensional vectors in two-dimensional space by aligning spatial proximity\nwith similarity relationships. This approach facilitates the effective sorting\nof diverse elements ranging from data points to images, and enables the\nsimultaneous visualization of a significant number of elements. However,\nsorting data on two-dimensional grids is a challenge due to its high\ncomplexity. Even for a small 8-by-8 grid with 64 elements, the number of\npossible arrangements exceeds $1.3 \\cdot 10^{89}$ - more than the number of\natoms in the universe - making brute-force solutions impractical.\n  Although various methods have been proposed to address the challenge of\ndetermining sorted grid layouts, none have investigated the potential of\ngradient-based optimization. In this paper, we present a novel method for\ngrid-based sorting that exploits gradient optimization for the first time. We\nintroduce a novel loss function that balances two opposing goals: ensuring the\ngeneration of a \"valid\" permutation matrix, and optimizing the arrangement on\nthe grid to reflect the similarity between vectors, inspired by metrics that\nassess the quality of sorted grids. While learning-based approaches are\ninherently computationally complex, our method shows promising results in\ngenerating sorted grid layouts with superior sorting quality compared to\nexisting techniques.\n","authors":["Kai Uwe Barthel","Florian Tim Barthel","Peter Eisert","Nico Hezel","Konstantin Schall"],"pdf_url":"https://arxiv.org/pdf/2503.02730v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.02725v1","updated":"2025-03-04T15:44:33Z","published":"2025-03-04T15:44:33Z","title":"A Joint Visual Compression and Perception Framework for Neuralmorphic\n  Spiking Camera","summary":"  The advent of neuralmorphic spike cameras has garnered significant attention\nfor their ability to capture continuous motion with unparalleled temporal\nresolution.However, this imaging attribute necessitates considerable resources\nfor binary spike data storage and transmission.In light of compression and\nspike-driven intelligent applications, we present the notion of Spike Coding\nfor Intelligence (SCI), wherein spike sequences are compressed and optimized\nfor both bit-rate and task performance.Drawing inspiration from the mammalian\nvision system, we propose a dual-pathway architecture for separate processing\nof spatial semantics and motion information, which is then merged to produce\nfeatures for compression.A refinement scheme is also introduced to ensure\nconsistency between decoded features and motion vectors.We further propose a\ntemporal regression approach that integrates various motion dynamics,\ncapitalizing on the advancements in warping and deformation\nsimultaneously.Comprehensive experiments demonstrate our scheme achieves\nstate-of-the-art (SOTA) performance for spike compression and analysis.We\nachieve an average 17.25% BD-rate reduction compared to SOTA codecs and a 4.3%\naccuracy improvement over SpiReco for spike-based classification, with 88.26%\ncomplexity reduction and 42.41% inference time saving on the encoding side.\n","authors":["Kexiang Feng","Chuanmin Jia","Siwei Ma","Wen Gao"],"pdf_url":"https://arxiv.org/pdf/2503.02725v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.01342v2","updated":"2025-03-04T15:36:45Z","published":"2025-03-03T09:27:24Z","title":"UFO: A Unified Approach to Fine-grained Visual Perception via Open-ended\n  Language Interface","summary":"  Generalist models have achieved remarkable success in both language and\nvision-language tasks, showcasing the potential of unified modeling. However,\neffectively integrating fine-grained perception tasks like detection and\nsegmentation into these models remains a significant challenge. This is\nprimarily because these tasks often rely heavily on task-specific designs and\narchitectures that can complicate the modeling process. To address this\nchallenge, we present \\ours, a framework that \\textbf{U}nifies\n\\textbf{F}ine-grained visual perception tasks through an \\textbf{O}pen-ended\nlanguage interface. By transforming all perception targets into the language\nspace, \\ours unifies object-level detection, pixel-level segmentation, and\nimage-level vision-language tasks into a single model. Additionally, we\nintroduce a novel embedding retrieval approach that relies solely on the\nlanguage interface to support segmentation tasks. Our framework bridges the gap\nbetween fine-grained perception and vision-language tasks, significantly\nsimplifying architectural design and training strategies while achieving\ncomparable or superior performance to methods with intricate task-specific\ndesigns. After multi-task training on five standard visual perception datasets,\n\\ours outperforms the previous state-of-the-art generalist models by 12.3 mAP\non COCO instance segmentation and 3.3 mIoU on ADE20K semantic segmentation.\nFurthermore, our method seamlessly integrates with existing MLLMs, effectively\ncombining fine-grained perception capabilities with their advanced language\nabilities, thereby enabling more challenging tasks such as reasoning\nsegmentation. Code and models are available at https://github.com/nnnth/UFO.\n","authors":["Hao Tang","Chenwei Xie","Haiyang Wang","Xiaoyi Bao","Tingyu Weng","Pandeng Li","Yun Zheng","Liwei Wang"],"pdf_url":"https://arxiv.org/pdf/2503.01342v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.02717v1","updated":"2025-03-04T15:32:32Z","published":"2025-03-04T15:32:32Z","title":"Catheter Detection and Segmentation in X-ray Images via Multi-task\n  Learning","summary":"  Automated detection and segmentation of surgical devices, such as catheters\nor wires, in X-ray fluoroscopic images have the potential to enhance image\nguidance in minimally invasive heart surgeries. In this paper, we present a\nconvolutional neural network model that integrates a resnet architecture with\nmultiple prediction heads to achieve real-time, accurate localization of\nelectrodes on catheters and catheter segmentation in an end-to-end deep\nlearning framework. We also propose a multi-task learning strategy in which our\nmodel is trained to perform both accurate electrode detection and catheter\nsegmentation simultaneously. A key challenge with this approach is achieving\noptimal performance for both tasks. To address this, we introduce a novel\nmulti-level dynamic resource prioritization method. This method dynamically\nadjusts sample and task weights during training to effectively prioritize more\nchallenging tasks, where task difficulty is inversely proportional to\nperformance and evolves throughout the training process. Experiments on both\npublic and private datasets have demonstrated that the accuracy of our method\nsurpasses the existing state-of-the-art methods in both single segmentation\ntask and in the detection and segmentation multi-task. Our approach achieves a\ngood trade-off between accuracy and efficiency, making it well-suited for\nreal-time surgical guidance applications.\n","authors":["Lin Xi","Yingliang Ma","Ethan Koland","Sandra Howell","Aldo Rinaldi","Kawal S. Rhode"],"pdf_url":"https://arxiv.org/pdf/2503.02717v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.01725v2","updated":"2025-03-04T15:31:11Z","published":"2025-03-03T16:42:46Z","title":"HarmonySet: A Comprehensive Dataset for Understanding Video-Music\n  Semantic Alignment and Temporal Synchronization","summary":"  This paper introduces HarmonySet, a comprehensive dataset designed to advance\nvideo-music understanding. HarmonySet consists of 48,328 diverse video-music\npairs, annotated with detailed information on rhythmic synchronization,\nemotional alignment, thematic coherence, and cultural relevance. We propose a\nmulti-step human-machine collaborative framework for efficient annotation,\ncombining human insights with machine-generated descriptions to identify key\ntransitions and assess alignment across multiple dimensions. Additionally, we\nintroduce a novel evaluation framework with tasks and metrics to assess the\nmulti-dimensional alignment of video and music, including rhythm, emotion,\ntheme, and cultural context. Our extensive experiments demonstrate that\nHarmonySet, along with the proposed evaluation framework, significantly\nimproves the ability of multimodal models to capture and analyze the intricate\nrelationships between video and music.\n","authors":["Zitang Zhou","Ke Mei","Yu Lu","Tianyi Wang","Fengyun Rao"],"pdf_url":"https://arxiv.org/pdf/2503.01725v2.pdf","comment":"Accepted at CVPR 2025. Project page: https://harmonyset.github.io/"},{"id":"http://arxiv.org/abs/2502.18495v2","updated":"2025-03-04T15:16:52Z","published":"2025-02-19T01:37:24Z","title":"A Comprehensive Survey on Composed Image Retrieval","summary":"  Composed Image Retrieval (CIR) is an emerging yet challenging task that\nallows users to search for target images using a multimodal query, comprising a\nreference image and a modification text specifying the user's desired changes\nto the reference image. Given its significant academic and practical value, CIR\nhas become a rapidly growing area of interest in the computer vision and\nmachine learning communities, particularly with the advances in deep learning.\nTo the best of our knowledge, there is currently no comprehensive review of CIR\nto provide a timely overview of this field. Therefore, we synthesize insights\nfrom over 120 publications in top conferences and journals, including ACM TOIS,\nSIGIR, and CVPR In particular, we systematically categorize existing supervised\nCIR and zero-shot CIR models using a fine-grained taxonomy. For a comprehensive\nreview, we also briefly discuss approaches for tasks closely related to CIR,\nsuch as attribute-based CIR and dialog-based CIR. Additionally, we summarize\nbenchmark datasets for evaluation and analyze existing supervised and zero-shot\nCIR methods by comparing experimental results across multiple datasets.\nFurthermore, we present promising future directions in this field, offering\npractical insights for researchers interested in further exploration. The\ncurated collection of related works is maintained and continuously updated in\nhttps://github.com/haokunwen/Awesome-Composed-Image-Retrieval.\n","authors":["Xuemeng Song","Haoqiang Lin","Haokun Wen","Bohan Hou","Mingzhu Xu","Liqiang Nie"],"pdf_url":"https://arxiv.org/pdf/2502.18495v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2412.20903v4","updated":"2025-03-04T15:05:02Z","published":"2024-12-30T12:29:02Z","title":"WalkVLM:Aid Visually Impaired People Walking by Vision Language Model","summary":"  Approximately 200 million individuals around the world suffer from varying\ndegrees of visual impairment, making it crucial to leverage AI technology to\noffer walking assistance for these people. With the recent progress of\nvision-language models (VLMs), applying VLMs to offer walking guidance has\nbecome popular. However, the existing methods of walking guidance are mainly\nbased on self-curated question-answering datasets that are not publicly\naccessible, without a standardized benchmark for training or evaluation.\nMoreover, walking assistance often requires real-time streaming video analysis\nand the generation of concise yet informative reminders, making VLMs struggle\ndue to excessive responses and low efficiency in inferences. In this paper, we\nintroduce the first large-scale dataset dedicated to walking assistance,\ncomprising 12,000 video-annotation pairs, to provide a unified benchmark for\ntraining and evaluating systems to help visually-impaired individuals walk.\nFurthermore, a WalkVLM model is proposed, which employs chain of thought for\nhierarchical planning to generate concise but informative reminders and\nutilizes temporal-aware adaptive prediction to reduce the temporal redundancy\nof reminders. Finally, we have established a solid benchmark for blind walking\ntask and verified the advantages of WalkVLM in stream video processing for this\ntask compared to other VLMs. Our dataset and code are available at\nhttps://walkvlm2024.github.io.\n","authors":["Zhiqiang Yuan","Ting Zhang","Ying Deng","Jiapei Zhang","Yeshuang Zhu","Zexi Jia","Jie Zhou","Jinchao Zhang"],"pdf_url":"https://arxiv.org/pdf/2412.20903v4.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.02691v1","updated":"2025-03-04T15:03:47Z","published":"2025-03-04T15:03:47Z","title":"Memory Efficient Continual Learning for Edge-Based Visual Anomaly\n  Detection","summary":"  Visual Anomaly Detection (VAD) is a critical task in computer vision with\nnumerous real-world applications. However, deploying these models on edge\ndevices presents significant challenges, such as constrained computational and\nmemory resources. Additionally, dynamic data distributions in real-world\nsettings necessitate continuous model adaptation, further complicating\ndeployment under limited resources. To address these challenges, we present a\nnovel investigation into the problem of Continual Learning for Visual Anomaly\nDetection (CLAD) on edge devices. We evaluate the STFPM approach, given its low\nmemory footprint on edge devices, which demonstrates good performance when\ncombined with the Replay approach. Furthermore, we propose to study the\nbehavior of a recently proposed approach, PaSTe, specifically designed for the\nedge but not yet explored in the Continual Learning context. Our results show\nthat PaSTe is not only a lighter version of STPFM, but it also achieves\nsuperior anomaly detection performance, improving the f1 pixel performance by\n10% with the Replay technique. In particular, the structure of PaSTe allows us\nto test it using a series of Compressed Replay techniques, reducing memory\noverhead by a maximum of 91.5% compared to the traditional Replay for STFPM.\nOur study proves the feasibility of deploying VAD models that adapt and learn\nincrementally on CLAD scenarios on resource-constrained edge devices.\n","authors":["Manuel Barusco","Lorenzo D'Antoni","Davide Dalle Pezze","Francesco Borsatti","Gian Antonio Susto"],"pdf_url":"https://arxiv.org/pdf/2503.02691v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.02689v1","updated":"2025-03-04T15:02:32Z","published":"2025-03-04T15:02:32Z","title":"STAA-SNN: Spatial-Temporal Attention Aggregator for Spiking Neural\n  Networks","summary":"  Spiking Neural Networks (SNNs) have gained significant attention due to their\nbiological plausibility and energy efficiency, making them promising\nalternatives to Artificial Neural Networks (ANNs). However, the performance gap\nbetween SNNs and ANNs remains a substantial challenge hindering the widespread\nadoption of SNNs. In this paper, we propose a Spatial-Temporal Attention\nAggregator SNN (STAA-SNN) framework, which dynamically focuses on and captures\nboth spatial and temporal dependencies. First, we introduce a spike-driven\nself-attention mechanism specifically designed for SNNs. Additionally, we\npioneeringly incorporate position encoding to integrate latent temporal\nrelationships into the incoming features. For spatial-temporal information\naggregation, we employ step attention to selectively amplify relevant features\nat different steps. Finally, we implement a time-step random dropout strategy\nto avoid local optima. As a result, STAA-SNN effectively captures both spatial\nand temporal dependencies, enabling the model to analyze complex patterns and\nmake accurate predictions. The framework demonstrates exceptional performance\nacross diverse datasets and exhibits strong generalization capabilities.\nNotably, STAA-SNN achieves state-of-the-art results on neuromorphic datasets\nCIFAR10-DVS, with remarkable performances of 97.14%, 82.05% and 70.40% on the\nstatic datasets CIFAR-10, CIFAR-100 and ImageNet, respectively. Furthermore,\nour model exhibits improved performance ranging from 0.33\\% to 2.80\\% with\nfewer time steps. The code for the model is available on GitHub.\n","authors":["Tianqing Zhang","Kairong Yu","Xian Zhong","Hongwei Wang","Qi Xu","Qiang Zhang"],"pdf_url":"https://arxiv.org/pdf/2503.02689v1.pdf","comment":"Accepted by CVPR 2025"},{"id":"http://arxiv.org/abs/2503.02687v1","updated":"2025-03-04T15:02:07Z","published":"2025-03-04T15:02:07Z","title":"Class-Aware PillarMix: Can Mixed Sample Data Augmentation Enhance 3D\n  Object Detection with Radar Point Clouds?","summary":"  Due to the significant effort required for data collection and annotation in\n3D perception tasks, mixed sample data augmentation (MSDA) has been widely\nstudied to generate diverse training samples by mixing existing data. Recently,\nmany MSDA techniques have been developed for point clouds, but they mainly\ntarget LiDAR data, leaving their application to radar point clouds largely\nunexplored. In this paper, we examine the feasibility of applying existing MSDA\nmethods to radar point clouds and identify several challenges in adapting these\ntechniques. These obstacles stem from the radar's irregular angular\ndistribution, deviations from a single-sensor polar layout in multi-radar\nsetups, and point sparsity. To address these issues, we propose Class-Aware\nPillarMix (CAPMix), a novel MSDA approach that applies MixUp at the pillar\nlevel in 3D point clouds, guided by class labels. Unlike methods that rely a\nsingle mix ratio to the entire sample, CAPMix assigns an independent ratio to\neach pillar, boosting sample diversity. To account for the density of different\nclasses, we use class-specific distributions: for dense objects (e.g., large\nvehicles), we skew ratios to favor points from another sample, while for sparse\nobjects (e.g., pedestrians), we sample more points from the original. This\nclass-aware mixing retains critical details and enriches each sample with new\ninformation, ultimately generating more diverse training data. Experimental\nresults demonstrate that our method not only significantly boosts performance\nbut also outperforms existing MSDA approaches across two datasets (Bosch Street\nand K-Radar). We believe that this straightforward yet effective approach will\nspark further investigation into MSDA techniques for radar data.\n","authors":["Miao Zhang","Sherif Abdulatif","Benedikt Loesch","Marco Altmann","Bin Yang"],"pdf_url":"https://arxiv.org/pdf/2503.02687v1.pdf","comment":"8 pages, 6 figures, 4 tables, submitted to 2025 IEEE/RSJ\n  International Conference on Intelligent Robots and Systems (IROS 2025)"},{"id":"http://arxiv.org/abs/2503.02685v1","updated":"2025-03-04T14:57:59Z","published":"2025-03-04T14:57:59Z","title":"TReND: Transformer derived features and Regularized NMF for neonatal\n  functional network Delineation","summary":"  Precise parcellation of functional networks (FNs) of early developing human\nbrain is the fundamental basis for identifying biomarker of developmental\ndisorders and understanding functional development. Resting-state fMRI\n(rs-fMRI) enables in vivo exploration of functional changes, but adult FN\nparcellations cannot be directly applied to the neonates due to incomplete\nnetwork maturation. No standardized neonatal functional atlas is currently\navailable. To solve this fundamental issue, we propose TReND, a novel and fully\nautomated self-supervised transformer-autoencoder framework that integrates\nregularized nonnegative matrix factorization (RNMF) to unveil the FNs in\nneonates. TReND effectively disentangles spatiotemporal features in voxel-wise\nrs-fMRI data. The framework integrates confidence-adaptive masks into\ntransformer self-attention layers to mitigate noise influence. A self\nsupervised decoder acts as a regulator to refine the encoder's latent\nembeddings, which serve as reliable temporal features. For spatial coherence,\nwe incorporate brain surface-based geodesic distances as spatial encodings\nalong with functional connectivity from temporal features. The TReND clustering\napproach processes these features under sparsity and smoothness constraints,\nproducing robust and biologically plausible parcellations. We extensively\nvalidated our TReND framework on three different rs-fMRI datasets: simulated,\ndHCP and HCP-YA against comparable traditional feature extraction and\nclustering techniques. Our results demonstrated the superiority of the TReND\nframework in the delineation of neonate FNs with significantly better spatial\ncontiguity and functional homogeneity. Collectively, we established TReND, a\nnovel and robust framework, for neonatal FN delineation. TReND-derived neonatal\nFNs could serve as a neonatal functional atlas for perinatal populations in\nhealth and disease.\n","authors":["Sovesh Mohapatra","Minhui Ouyang","Shufang Tan","Jianlin Guo","Lianglong Sun","Yong He","Hao Huang"],"pdf_url":"https://arxiv.org/pdf/2503.02685v1.pdf","comment":"10 Pages, 5 figures"},{"id":"http://arxiv.org/abs/2501.04477v2","updated":"2025-03-04T14:53:28Z","published":"2025-01-08T13:00:17Z","title":"Rethinking High-speed Image Reconstruction Framework with Spike Camera","summary":"  Spike cameras, as innovative neuromorphic devices, generate continuous spike\nstreams to capture high-speed scenes with lower bandwidth and higher dynamic\nrange than traditional RGB cameras. However, reconstructing high-quality images\nfrom the spike input under low-light conditions remains challenging.\nConventional learning-based methods often rely on the synthetic dataset as the\nsupervision for training. Still, these approaches falter when dealing with\nnoisy spikes fired under the low-light environment, leading to further\nperformance degradation in the real-world dataset. This phenomenon is primarily\ndue to inadequate noise modelling and the domain gap between synthetic and real\ndatasets, resulting in recovered images with unclear textures, excessive noise,\nand diminished brightness. To address these challenges, we introduce a novel\nspike-to-image reconstruction framework SpikeCLIP that goes beyond traditional\ntraining paradigms. Leveraging the CLIP model's powerful capability to align\ntext and images, we incorporate the textual description of the captured scene\nand unpaired high-quality datasets as the supervision. Our experiments on\nreal-world low-light datasets U-CALTECH and U-CIFAR demonstrate that SpikeCLIP\nsignificantly enhances texture details and the luminance balance of recovered\nimages. Furthermore, the reconstructed images are well-aligned with the broader\nvisual features needed for downstream tasks, ensuring more robust and versatile\nperformance in challenging environments.\n","authors":["Kang Chen","Yajing Zheng","Tiejun Huang","Zhaofei Yu"],"pdf_url":"https://arxiv.org/pdf/2501.04477v2.pdf","comment":"Accepted by AAAI2025"},{"id":"http://arxiv.org/abs/2503.02675v1","updated":"2025-03-04T14:46:34Z","published":"2025-03-04T14:46:34Z","title":"State of play and future directions in industrial computer vision AI\n  standards","summary":"  The recent tremendous advancements in the areas of Artificial Intelligence\n(AI) and Deep Learning (DL) have also resulted into corresponding remarkable\nprogress in the field of Computer Vision (CV), showcasing robust technological\nsolutions in a wide range of application sectors of high industrial interest\n(e.g., healthcare, autonomous driving, automation, etc.). Despite the\noutstanding performance of CV systems in specific domains, their development\nand exploitation at industrial-scale necessitates, among other, the addressing\nof requirements related to the reliability, transparency, trustworthiness,\nsecurity, safety, and robustness of the developed AI models. The latter raises\nthe imperative need for the development of efficient, comprehensive and\nwidely-adopted industrial standards. In this context, this study investigates\nthe current state of play regarding the development of industrial computer\nvision AI standards, emphasizing on critical aspects, like model\ninterpretability, data quality, and regulatory compliance. In particular, a\nsystematic analysis of launched and currently developing CV standards, proposed\nby the main international standardization bodies (e.g. ISO/IEC, IEEE, DIN,\netc.) is performed. The latter is complemented by a comprehensive discussion on\nthe current challenges and future directions observed in this regularization\nendeavor.\n","authors":["Artemis Stefanidou","Panagiotis Radoglou-Grammatikis","Vasileios Argyriou","Panagiotis Sarigiannidis","Iraklis Varlamis","Georgios Th. Papadopoulos"],"pdf_url":"https://arxiv.org/pdf/2503.02675v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.02662v1","updated":"2025-03-04T14:25:51Z","published":"2025-03-04T14:25:51Z","title":"10K is Enough: An Ultra-Lightweight Binarized Network for Infrared\n  Small-Target Detection","summary":"  The widespread deployment of InfRared Small-Target Detection(IRSTD)\nalgorithms on edge devices necessitates the exploration of model compression\ntechniques. Binary neural networks (BNNs) are distinguished by their\nexceptional efficiency in model compression. However, the small size of\ninfrared targets introduces stringent precision requirements for the IRSTD\ntask, while the inherent precision loss during binarization presents a\nsignificant challenge. To address this, we propose the Binarized Infrared\nSmall-Target Detection Network (BiisNet), which preserves the core operations\nof binarized convolutions while integrating full-precision features into the\nnetwork's information flow. Specifically, we propose the Dot-Binary\nConvolution, which retains fine-grained semantic information in feature maps\nwhile still leveraging the binarized convolution operations. In addition, we\nintroduce a smooth and adaptive Dynamic Softsign function, which provides more\ncomprehensive and progressively finer gradient during back-propagation,\nenhancing model stability and promoting an optimal weight\ndistribution.Experimental results demonstrate that BiisNet not only\nsignificantly outperforms other binary architectures but also demonstrates\nstrong competitiveness among state-of-the-art full-precision models.\n","authors":["Biqiao Xin","Qianchen Mao","Bingshu Wang","Jiangbin Zheng","Yong Zhao","C. L. Philip Chen"],"pdf_url":"https://arxiv.org/pdf/2503.02662v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.02660v1","updated":"2025-03-04T14:22:08Z","published":"2025-03-04T14:22:08Z","title":"A dataset-free approach for self-supervised learning of 3D reflectional\n  symmetries","summary":"  In this paper, we explore a self-supervised model that learns to detect the\nsymmetry of a single object without requiring a dataset-relying solely on the\ninput object itself. We hypothesize that the symmetry of an object can be\ndetermined by its intrinsic features, eliminating the need for large datasets\nduring training. Additionally, we design a self-supervised learning strategy\nthat removes the necessity of ground truth labels. These two key elements make\nour approach both effective and efficient, addressing the prohibitive costs\nassociated with constructing large, labeled datasets for this task. The novelty\nof our method lies in computing features for each point on the object based on\nthe idea that symmetric points should exhibit similar visual appearances. To\nachieve this, we leverage features extracted from a foundational image model to\ncompute a visual descriptor for the points. This approach equips the point\ncloud with visual features that facilitate the optimization of our\nself-supervised model. Experimental results demonstrate that our method\nsurpasses the state-of-the-art models trained on large datasets. Furthermore,\nour model is more efficient, effective, and operates with minimal computational\nand data resources.\n","authors":["Issac Aguirre","Ivan Sipiran","Gabriel Montaana"],"pdf_url":"https://arxiv.org/pdf/2503.02660v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2408.11760v3","updated":"2025-03-04T14:04:07Z","published":"2024-08-21T16:32:03Z","title":"R2Det: Exploring Relaxed Rotation Equivariance in 2D object detection","summary":"  Group Equivariant Convolution (GConv) empowers models to explore underlying\nsymmetry in data, improving performance. However, real-world scenarios often\ndeviate from ideal symmetric systems caused by physical permutation,\ncharacterized by non-trivial actions of a symmetry group, resulting in\nasymmetries that affect the outputs, a phenomenon known as Symmetry Breaking.\nTraditional GConv-based methods are constrained by rigid operational rules\nwithin group space, assuming data remains strictly symmetry after limited group\ntransformations. This limitation makes it difficult to adapt to\nSymmetry-Breaking and non-rigid transformations. Motivated by this, we mainly\nfocus on a common scenario: Rotational Symmetry-Breaking. By relaxing strict\ngroup transformations within Strict Rotation-Equivariant group $\\mathbf{C}_n$,\nwe redefine a Relaxed Rotation-Equivariant group $\\mathbf{R}_n$ and introduce a\nnovel Relaxed Rotation-Equivariant GConv (R2GConv) with only a minimal increase\nof $4n$ parameters compared to GConv. Based on R2GConv, we propose a Relaxed\nRotation-Equivariant Network (R2Net) as the backbone and develop a Relaxed\nRotation-Equivariant Object Detector (R2Det) for 2D object detection.\nExperimental results demonstrate the effectiveness of the proposed R2GConv in\nnatural image classification, and R2Det achieves excellent performance in 2D\nobject detection with improved generalization capabilities and robustness. The\ncode is available in \\texttt{https://github.com/wuer5/r2det}.\n","authors":["Zhiqiang Wu","Yingjie Liu","Hanlin Dong","Xuan Tang","Jian Yang","Bo Jin","Mingsong Chen","Xian Wei"],"pdf_url":"https://arxiv.org/pdf/2408.11760v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.02619v1","updated":"2025-03-04T13:38:58Z","published":"2025-03-04T13:38:58Z","title":"XFMamba: Cross-Fusion Mamba for Multi-View Medical Image Classification","summary":"  Compared to single view medical image classification, using multiple views\ncan significantly enhance predictive accuracy as it can account for the\ncomplementarity of each view while leveraging correlations between views.\nExisting multi-view approaches typically employ separate convolutional or\ntransformer branches combined with simplistic feature fusion strategies.\nHowever, these approaches inadvertently disregard essential cross-view\ncorrelations, leading to suboptimal classification performance, and suffer from\nchallenges with limited receptive field (CNNs) or quadratic computational\ncomplexity (transformers). Inspired by state space sequence models, we propose\nXFMamba, a pure Mamba-based cross-fusion architecture to address the challenge\nof multi-view medical image classification. XFMamba introduces a novel\ntwo-stage fusion strategy, facilitating the learning of single-view features\nand their cross-view disparity. This mechanism captures spatially long-range\ndependencies in each view while enhancing seamless information transfer between\nviews. Results on three public datasets, MURA, CheXpert and DDSM, illustrate\nthe effectiveness of our approach across diverse multi-view medical image\nclassification tasks, showing that it outperforms existing convolution-based\nand transformer-based multi-view methods. Code is available at\nhttps://github.com/XZheng0427/XFMamba.\n","authors":["Xiaoyu Zheng","Xu Chen","Shaogang Gong","Xavier Griffin","Greg Slabaugh"],"pdf_url":"https://arxiv.org/pdf/2503.02619v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.02618v1","updated":"2025-03-04T13:38:41Z","published":"2025-03-04T13:38:41Z","title":"ZAPBench: A Benchmark for Whole-Brain Activity Prediction in Zebrafish","summary":"  Data-driven benchmarks have led to significant progress in key scientific\nmodeling domains including weather and structural biology. Here, we introduce\nthe Zebrafish Activity Prediction Benchmark (ZAPBench) to measure progress on\nthe problem of predicting cellular-resolution neural activity throughout an\nentire vertebrate brain. The benchmark is based on a novel dataset containing\n4d light-sheet microscopy recordings of over 70,000 neurons in a larval\nzebrafish brain, along with motion stabilized and voxel-level cell\nsegmentations of these data that facilitate development of a variety of\nforecasting methods. Initial results from a selection of time series and\nvolumetric video modeling approaches achieve better performance than naive\nbaseline methods, but also show room for further improvement. The specific\nbrain used in the activity recording is also undergoing synaptic-level\nanatomical mapping, which will enable future integration of detailed structural\ninformation into forecasting methods.\n","authors":["Jan-Matthis Lueckmann","Alexander Immer","Alex Bo-Yuan Chen","Peter H. Li","Mariela D. Petkova","Nirmala A. Iyer","Luuk Willem Hesselink","Aparna Dev","Gudrun Ihrke","Woohyun Park","Alyson Petruncio","Aubrey Weigel","Wyatt Korff","Florian Engert","Jeff W. Lichtman","Misha B. Ahrens","Micha Januszewski","Viren Jain"],"pdf_url":"https://arxiv.org/pdf/2503.02618v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.02616v1","updated":"2025-03-04T13:36:16Z","published":"2025-03-04T13:36:16Z","title":"Smoothing the Shift: Towards Stable Test-Time Adaptation under Complex\n  Multimodal Noises","summary":"  Test-Time Adaptation (TTA) aims to tackle distribution shifts using unlabeled\ntest data without access to the source data. In the context of multimodal data,\nthere are more complex noise patterns than unimodal data such as simultaneous\ncorruptions for multiple modalities and missing modalities. Besides, in\nreal-world applications, corruptions from different distribution shifts are\nalways mixed. Existing TTA methods always fail in such multimodal scenario\nbecause the abrupt distribution shifts will destroy the prior knowledge from\nthe source model, thus leading to performance degradation. To this end, we\nreveal a new challenge named multimodal wild TTA. To address this challenging\nproblem, we propose two novel strategies: sample identification with\ninterquartile range Smoothing and unimodal assistance, and Mutual information\nsharing (SuMi). SuMi smooths the adaptation process by interquartile range\nwhich avoids the abrupt distribution shifts. Then, SuMi fully utilizes the\nunimodal features to select low-entropy samples with rich multimodal\ninformation for optimization. Furthermore, mutual information sharing is\nintroduced to align the information, reduce the discrepancies and enhance the\ninformation utilization across different modalities. Extensive experiments on\ntwo public datasets show the effectiveness and superiority over existing\nmethods under the complex noise patterns in multimodal data. Code is available\nat https://github.com/zrguo/SuMi.\n","authors":["Zirun Guo","Tao Jin"],"pdf_url":"https://arxiv.org/pdf/2503.02616v1.pdf","comment":"Accepted at ICLR 2025"},{"id":"http://arxiv.org/abs/2503.02606v1","updated":"2025-03-04T13:28:05Z","published":"2025-03-04T13:28:05Z","title":"ARC-Flow : Articulated, Resolution-Agnostic, Correspondence-Free\n  Matching and Interpolation of 3D Shapes Under Flow Fields","summary":"  This work presents a unified framework for the unsupervised prediction of\nphysically plausible interpolations between two 3D articulated shapes and the\nautomatic estimation of dense correspondence between them. Interpolation is\nmodelled as a diffeomorphic transformation using a smooth, time-varying flow\nfield governed by Neural Ordinary Differential Equations (ODEs). This ensures\ntopological consistency and non-intersecting trajectories while accommodating\nhard constraints, such as volume preservation, and soft constraints, \\eg\nphysical priors.\n  Correspondence is recovered using an efficient Varifold formulation, that is\neffective on high-fidelity surfaces with differing parameterisations. By\nproviding a simple skeleton for the source shape only, we impose physically\nmotivated constraints on the deformation field and resolve symmetric\nambiguities. This is achieved without relying on skinning weights or any prior\nknowledge of the skeleton's target pose configuration.\n  Qualitative and quantitative results demonstrate competitive or superior\nperformance over existing state-of-the-art approaches in both shape\ncorrespondence and interpolation tasks across standard datasets.\n","authors":["Adam Hartshorne","Allen Paul","Tony Shardlow","Neill D. F. Campbell"],"pdf_url":"https://arxiv.org/pdf/2503.02606v1.pdf","comment":"11 pages, 6 figures"},{"id":"http://arxiv.org/abs/2503.02600v1","updated":"2025-03-04T13:20:42Z","published":"2025-03-04T13:20:42Z","title":"Resource-Efficient Affordance Grounding with Complementary Depth and\n  Semantic Prompts","summary":"  Affordance refers to the functional properties that an agent perceives and\nutilizes from its environment, and is key perceptual information required for\nrobots to perform actions. This information is rich and multimodal in nature.\nExisting multimodal affordance methods face limitations in extracting useful\ninformation, mainly due to simple structural designs, basic fusion methods, and\nlarge model parameters, making it difficult to meet the performance\nrequirements for practical deployment. To address these issues, this paper\nproposes the BiT-Align image-depth-text affordance mapping framework. The\nframework includes a Bypass Prompt Module (BPM) and a Text Feature Guidance\n(TFG) attention selection mechanism. BPM integrates the auxiliary modality\ndepth image directly as a prompt to the primary modality RGB image, embedding\nit into the primary modality encoder without introducing additional encoders.\nThis reduces the model's parameter count and effectively improves functional\nregion localization accuracy. The TFG mechanism guides the selection and\nenhancement of attention heads in the image encoder using textual features,\nimproving the understanding of affordance characteristics. Experimental results\ndemonstrate that the proposed method achieves significant performance\nimprovements on public AGD20K and HICO-IIF datasets. On the AGD20K dataset,\ncompared with the current state-of-the-art method, we achieve a 6.0%\nimprovement in the KLD metric, while reducing model parameters by 88.8%,\ndemonstrating practical application values. The source code will be made\npublicly available at https://github.com/DAWDSE/BiT-Align.\n","authors":["Yizhou Huang","Fan Yang","Guoliang Zhu","Gen Li","Hao Shi","Yukun Zuo","Wenrui Chen","Zhiyong Li","Kailun Yang"],"pdf_url":"https://arxiv.org/pdf/2503.02600v1.pdf","comment":"The source code will be made publicly available at\n  https://github.com/DAWDSE/BiT-Align"},{"id":"http://arxiv.org/abs/2503.02597v1","updated":"2025-03-04T13:18:33Z","published":"2025-03-04T13:18:33Z","title":"Seeing is Understanding: Unlocking Causal Attention into Modality-Mutual\n  Attention for Multimodal LLMs","summary":"  Recent Multimodal Large Language Models (MLLMs) have demonstrated significant\nprogress in perceiving and reasoning over multimodal inquiries, ushering in a\nnew research era for foundation models. However, vision-language misalignment\nin MLLMs has emerged as a critical challenge, where the textual responses\ngenerated by these models are not factually aligned with the given text-image\ninputs. Existing efforts to address vision-language misalignment have focused\non developing specialized vision-language connectors or leveraging visual\ninstruction tuning from diverse domains. In this paper, we tackle this issue\nfrom a fundamental yet unexplored perspective by revisiting the core\narchitecture of MLLMs. Most MLLMs are typically built on decoder-only LLMs\nconsisting of a causal attention mechanism, which limits the ability of earlier\nmodalities (e.g., images) to incorporate information from later modalities\n(e.g., text). To address this problem, we propose AKI, a novel MLLM that\nunlocks causal attention into modality-mutual attention (MMA) to enable image\ntokens to attend to text tokens. This simple yet effective design allows AKI to\nachieve superior performance in 12 multimodal understanding benchmarks (+7.2%\non average) without introducing additional parameters and increasing training\ntime. Our MMA design is intended to be generic, allowing for application across\nvarious modalities, and scalable to accommodate diverse multimodal scenarios.\nThe code is publicly available at https://github.com/sony/aki, and we will\nrelease our AKI-4B model to encourage further advancements in MLLMs across\nvarious directions.\n","authors":["Wei-Yao Wang","Zhao Wang","Helen Suzuki","Yoshiyuki Kobayashi"],"pdf_url":"https://arxiv.org/pdf/2503.02597v1.pdf","comment":"Preprint"},{"id":"http://arxiv.org/abs/2503.02595v1","updated":"2025-03-04T13:17:50Z","published":"2025-03-04T13:17:50Z","title":"StageDesigner: Artistic Stage Generation for Scenography via Theater\n  Scripts","summary":"  In this work, we introduce StageDesigner, the first comprehensive framework\nfor artistic stage generation using large language models combined with\nlayout-controlled diffusion models. Given the professional requirements of\nstage scenography, StageDesigner simulates the workflows of seasoned artists to\ngenerate immersive 3D stage scenes. Specifically, our approach is divided into\nthree primary modules: Script Analysis, which extracts thematic and spatial\ncues from input scripts; Foreground Generation, which constructs and arranges\nessential 3D objects; and Background Generation, which produces a harmonious\nbackground aligned with the narrative atmosphere and maintains spatial\ncoherence by managing occlusions between foreground and background elements.\nFurthermore, we introduce the StagePro-V1 dataset, a dedicated dataset with 276\nunique stage scenes spanning different historical styles and annotated with\nscripts, images, and detailed 3D layouts, specifically tailored for this task.\nFinally, evaluations using both standard and newly proposed metrics, along with\nextensive user studies, demonstrate the effectiveness of StageDesigner. Project\ncan be found at: https://deadsmither5.github.io/2025/01/03/StageDesigner/\n","authors":["Zhaoxing Gan","Mengtian Li","Ruhua Chen","Zhongxia Ji","Sichen Guo","Huanling Hu","Guangnan Ye","Zuo Hu"],"pdf_url":"https://arxiv.org/pdf/2503.02595v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.02593v1","updated":"2025-03-04T13:17:17Z","published":"2025-03-04T13:17:17Z","title":"CMMLoc: Advancing Text-to-PointCloud Localization with\n  Cauchy-Mixture-Model Based Framework","summary":"  The goal of point cloud localization based on linguistic description is to\nidentify a 3D position using textual description in large urban environments,\nwhich has potential applications in various fields, such as determining the\nlocation for vehicle pickup or goods delivery. Ideally, for a textual\ndescription and its corresponding 3D location, the objects around the 3D\nlocation should be fully described in the text description. However, in\npractical scenarios, e.g., vehicle pickup, passengers usually describe only the\npart of the most significant and nearby surroundings instead of the entire\nenvironment. In response to this $\\textbf{partially relevant}$ challenge, we\npropose $\\textbf{CMMLoc}$, an uncertainty-aware\n$\\textbf{C}$auchy-$\\textbf{M}$ixture-$\\textbf{M}$odel ($\\textbf{CMM}$) based\nframework for text-to-point-cloud $\\textbf{Loc}$alization. To model the\nuncertain semantic relations between text and point cloud, we integrate CMM\nconstraints as a prior during the interaction between the two modalities. We\nfurther design a spatial consolidation scheme to enable adaptive aggregation of\ndifferent 3D objects with varying receptive fields. To achieve precise\nlocalization, we propose a cardinal direction integration module alongside a\nmodality pre-alignment strategy, helping capture the spatial relationships\namong objects and bringing the 3D objects closer to the text modality.\nComprehensive experiments validate that CMMLoc outperforms existing methods,\nachieving state-of-the-art results on the KITTI360Pose dataset. Codes are\navailable in this GitHub repository https://github.com/kevin301342/CMMLoc.\n","authors":["Yanlong Xu","Haoxuan Qu","Jun Liu","Wenxiao Zhang","Xun Yang"],"pdf_url":"https://arxiv.org/pdf/2503.02593v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2409.11635v2","updated":"2025-03-04T13:11:49Z","published":"2024-09-18T01:55:00Z","title":"PainDiffusion: Learning to Express Pain","summary":"  Accurate pain expression synthesis is essential for improving clinical\ntraining and human-robot interaction. Current Robotic Patient Simulators (RPSs)\nlack realistic pain facial expressions, limiting their effectiveness in medical\ntraining. In this work, we introduce PainDiffusion, a generative model that\nsynthesizes naturalistic facial pain expressions. Unlike traditional heuristic\nor autoregressive methods, PainDiffusion operates in a continuous latent space,\nensuring smoother and more natural facial motion while supporting\nindefinite-length generation via diffusion forcing. Our approach incorporates\nintrinsic characteristics such as pain expressiveness and emotion, allowing for\npersonalized and controllable pain expression synthesis. We train and evaluate\nour model using the BioVid HeatPain Database. Additionally, we integrate\nPainDiffusion into a robotic system to assess its applicability in real-time\nrehabilitation exercises. Qualitative studies with clinicians reveal that\nPainDiffusion produces realistic pain expressions, with a 31.2% (std 4.8%)\npreference rate against ground-truth recordings. Our results suggest that\nPainDiffusion can serve as a viable alternative to real patients in clinical\ntraining and simulation, bridging the gap between synthetic and naturalistic\npain expression. Code and videos are available at:\nhttps://damtien444.github.io/paindf/\n","authors":["Quang Tien Dam","Tri Tung Nguyen Nguyen","Yuki Endo","Dinh Tuan Tran","Joo-Ho Lee"],"pdf_url":"https://arxiv.org/pdf/2409.11635v2.pdf","comment":"8 pages, 9 figures"},{"id":"http://arxiv.org/abs/2503.02585v1","updated":"2025-03-04T13:08:45Z","published":"2025-03-04T13:08:45Z","title":"A Hypernetwork-Based Approach to KAN Representation of Audio Signals","summary":"  Implicit neural representations (INR) have gained prominence for efficiently\nencoding multimedia data, yet their applications in audio signals remain\nlimited. This study introduces the Kolmogorov-Arnold Network (KAN), a novel\narchitecture using learnable activation functions, as an effective INR model\nfor audio representation. KAN demonstrates superior perceptual performance over\nprevious INRs, achieving the lowest Log-SpectralDistance of 1.29 and the\nhighest Perceptual Evaluation of Speech Quality of 3.57 for 1.5 s audio. To\nextend KAN's utility, we propose FewSound, a hypernetwork-based architecture\nthat enhances INR parameter updates. FewSound outperforms the state-of-the-art\nHyperSound, with a 33.3% improvement in MSE and 60.87% in SI-SNR. These results\nshow KAN as a robust and adaptable audio representation with the potential for\nscalability and integration into various hypernetwork frameworks. The source\ncode can be accessed at https://github.com/gmum/fewsound.git.\n","authors":["Patryk Marszaek","Maciej Rut","Piotr Kawa","Piotr Syga"],"pdf_url":"https://arxiv.org/pdf/2503.02585v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2502.14401v2","updated":"2025-03-04T13:08:22Z","published":"2025-02-20T09:38:13Z","title":"MedFuncta: Modality-Agnostic Representations Based on Efficient Neural\n  Fields","summary":"  Recent research in medical image analysis with deep learning almost\nexclusively focuses on grid- or voxel-based data representations. We challenge\nthis common choice by introducing MedFuncta, a modality-agnostic continuous\ndata representation based on neural fields. We demonstrate how to scale neural\nfields from single instances to large datasets by exploiting redundancy in\nmedical signals and by applying an efficient meta-learning approach with a\ncontext reduction scheme. We further address the spectral bias in commonly used\nSIREN activations, by introducing an $\\omega_0$-schedule, improving\nreconstruction quality and convergence speed. We validate our proposed approach\non a large variety of medical signals of different dimensions and modalities\n(1D: ECG; 2D: Chest X-ray, Retinal OCT, Fundus Camera, Dermatoscope, Colon\nHistopathology, Cell Microscopy; 3D: Brain MRI, Lung CT) and successfully\ndemonstrate that we can solve relevant downstream tasks on these\nrepresentations. We additionally release a large-scale dataset of > 550k\nannotated neural fields to promote research in this direction.\n","authors":["Paul Friedrich","Florentin Bieder","Philippe C. Cattin"],"pdf_url":"https://arxiv.org/pdf/2502.14401v2.pdf","comment":"Project page: https://pfriedri.github.io/medfuncta-io/ Code and\n  Dataset: https://github.com/pfriedri/medfuncta/"},{"id":"http://arxiv.org/abs/2405.13152v4","updated":"2025-03-04T13:07:09Z","published":"2024-05-21T18:45:18Z","title":"Interpretable Interaction Modeling for Trajectory Prediction via Agent\n  Selection and Physical Coefficient","summary":"  A thorough understanding of the interaction between the target agent and\nsurrounding agents is a prerequisite for accurate trajectory prediction.\nAlthough many methods have been explored, they assign correlation coefficients\nto surrounding agents in a purely learning-based manner. In this study, we\npresent ASPILin, which manually selects interacting agents and replaces the\nattention scores in Transformer with a newly computed physical correlation\ncoefficient, enhancing the interpretability of interaction modeling.\nSurprisingly, these simple modifications can significantly improve prediction\nperformance and substantially reduce computational costs. We intentionally\nsimplified our model in other aspects, such as map encoding. Remarkably,\nexperiments conducted on the INTERACTION, highD, and CitySim datasets\ndemonstrate that our method is efficient and straightforward, outperforming\nother state-of-the-art methods.\n","authors":["Shiji Huang","Lei Ye","Min Chen","Wenhai Luo","Dihong Wang","Chenqi Xu","Deyuan Liang"],"pdf_url":"https://arxiv.org/pdf/2405.13152v4.pdf","comment":"code:https://github.com/kkk00714/ASPILin"},{"id":"http://arxiv.org/abs/2503.02581v1","updated":"2025-03-04T13:04:46Z","published":"2025-03-04T13:04:46Z","title":"Unveiling the Potential of Segment Anything Model 2 for RGB-Thermal\n  Semantic Segmentation with Language Guidance","summary":"  The perception capability of robotic systems relies on the richness of the\ndataset. Although Segment Anything Model 2 (SAM2), trained on large datasets,\ndemonstrates strong perception potential in perception tasks, its inherent\ntraining paradigm prevents it from being suitable for RGB-T tasks. To address\nthese challenges, we propose SHIFNet, a novel SAM2-driven Hybrid Interaction\nParadigm that unlocks the potential of SAM2 with linguistic guidance for\nefficient RGB-Thermal perception. Our framework consists of two key components:\n(1) Semantic-Aware Cross-modal Fusion (SACF) module that dynamically balances\nmodality contributions through text-guided affinity learning, overcoming SAM2's\ninherent RGB bias; (2) Heterogeneous Prompting Decoder (HPD) that enhances\nglobal semantic information through a semantic enhancement module and then\ncombined with category embeddings to amplify cross-modal semantic consistency.\nWith 32.27M trainable parameters, SHIFNet achieves state-of-the-art\nsegmentation performance on public benchmarks, reaching 89.8% on PST900 and\n67.8% on FMB, respectively. The framework facilitates the adaptation of\npre-trained large models to RGB-T segmentation tasks, effectively mitigating\nthe high costs associated with data collection while endowing robotic systems\nwith comprehensive perception capabilities. The source code will be made\npublicly available at https://github.com/iAsakiT3T/SHIFNet.\n","authors":["Jiayi Zhao","Fei Teng","Kai Luo","Guoqiang Zhao","Zhiyong Li","Xu Zheng","Kailun Yang"],"pdf_url":"https://arxiv.org/pdf/2503.02581v1.pdf","comment":"The source code will be made publicly available at\n  https://github.com/iAsakiT3T/SHIFNet"},{"id":"http://arxiv.org/abs/2309.02244v2","updated":"2025-03-04T13:04:45Z","published":"2023-09-05T13:52:43Z","title":"Augmenting Chest X-ray Datasets with Non-Expert Annotations","summary":"  The advancement of machine learning algorithms in medical image analysis\nrequires the expansion of training datasets. A popular and cost-effective\napproach is automated annotation extraction from free-text medical reports,\nprimarily due to the high costs associated with expert clinicians annotating\nmedical images, such as chest X-rays. However, it has been shown that the\nresulting datasets are susceptible to biases and shortcuts. Another strategy to\nincrease the size of a dataset is crowdsourcing, a widely adopted practice in\ngeneral computer vision with some success in medical image analysis. In a\nsimilar vein to crowdsourcing, we enhance two publicly available chest X-ray\ndatasets by incorporating non-expert annotations. However, instead of using\ndiagnostic labels, we annotate shortcuts in the form of tubes. We collect 3.5k\nchest drain annotations for NIH-CXR14, and 1k annotations for four different\ntube types in PadChest, and create the Non-Expert Annotations of Tubes in\nX-rays (NEATX) dataset. We train a chest drain detector with the non-expert\nannotations that generalizes well to expert labels. Moreover, we compare our\nannotations to those provided by experts and show \"moderate\" to \"almost\nperfect\" agreement. Finally, we present a pathology agreement study to raise\nawareness about the quality of ground truth annotations. We make our dataset\navailable at https://zenodo.org/records/14944064 and our code available at\nhttps://github.com/purrlab/chestxr-label-reliability.\n","authors":["Veronika Cheplygina","Cathrine Damgaard","Trine Naja Eriksen","Dovile Juodelyte","Amelia Jimnez-Snchez"],"pdf_url":"https://arxiv.org/pdf/2309.02244v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.02579v1","updated":"2025-03-04T13:00:52Z","published":"2025-03-04T13:00:52Z","title":"MM-OR: A Large Multimodal Operating Room Dataset for Semantic\n  Understanding of High-Intensity Surgical Environments","summary":"  Operating rooms (ORs) are complex, high-stakes environments requiring precise\nunderstanding of interactions among medical staff, tools, and equipment for\nenhancing surgical assistance, situational awareness, and patient safety.\nCurrent datasets fall short in scale, realism and do not capture the multimodal\nnature of OR scenes, limiting progress in OR modeling. To this end, we\nintroduce MM-OR, a realistic and large-scale multimodal spatiotemporal OR\ndataset, and the first dataset to enable multimodal scene graph generation.\nMM-OR captures comprehensive OR scenes containing RGB-D data, detail views,\naudio, speech transcripts, robotic logs, and tracking data and is annotated\nwith panoptic segmentations, semantic scene graphs, and downstream task labels.\nFurther, we propose MM2SG, the first multimodal large vision-language model for\nscene graph generation, and through extensive experiments, demonstrate its\nability to effectively leverage multimodal inputs. Together, MM-OR and MM2SG\nestablish a new benchmark for holistic OR understanding, and open the path\ntowards multimodal scene analysis in complex, high-stakes environments. Our\ncode, and data is available at https://github.com/egeozsoy/MM-OR.\n","authors":["Ege zsoy","Chantal Pellegrini","Tobias Czempiel","Felix Tristram","Kun Yuan","David Bani-Harouni","Ulrich Eck","Benjamin Busam","Matthias Keicher","Nassir Navab"],"pdf_url":"https://arxiv.org/pdf/2503.02579v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.02578v1","updated":"2025-03-04T13:00:30Z","published":"2025-03-04T13:00:30Z","title":"TS-CGNet: Temporal-Spatial Fusion Meets Centerline-Guided Diffusion for\n  BEV Mapping","summary":"  Bird's Eye View (BEV) perception technology is crucial for autonomous\ndriving, as it generates top-down 2D maps for environment perception,\nnavigation, and decision-making. Nevertheless, the majority of current BEV map\ngeneration studies focusing on visual map generation lack depth-aware reasoning\ncapabilities. They exhibit limited efficacy in managing occlusions and handling\ncomplex environments, with a notable decline in perceptual performance under\nadverse weather conditions or low-light scenarios. Therefore, this paper\nproposes TS-CGNet, which leverages Temporal-Spatial fusion with\nCenterline-Guided diffusion. This visual framework, grounded in prior\nknowledge, is designed for integration into any existing network for building\nBEV maps. Specifically, this framework is decoupled into three parts: Local\nmapping system involves the initial generation of semantic maps using purely\nvisual information; The Temporal-Spatial Aligner Module (TSAM) integrates\nhistorical information into mapping generation by applying transformation\nmatrices; The Centerline-Guided Diffusion Model (CGDM) is a prediction module\nbased on the diffusion model. CGDM incorporates centerline information through\nspatial-attention mechanisms to enhance semantic segmentation reconstruction.\nWe construct BEV semantic segmentation maps by our methods on the public\nnuScenes and the robustness benchmarks under various corruptions. Our method\nimproves 1.90%, 1.73%, and 2.87% for perceived ranges of 60x30m, 120x60m, and\n240x60m in the task of BEV HD mapping. TS-CGNet attains an improvement of 1.92%\nfor perceived ranges of 100x100m in the task of BEV semantic mapping. Moreover,\nTS-CGNet achieves an average improvement of 2.92% in detection accuracy under\nvarying weather conditions and sensor interferences in the perception range of\n240x60m. The source code will be publicly available at\nhttps://github.com/krabs-H/TS-CGNet.\n","authors":["Xinying Hong","Siyu Li","Kang Zeng","Hao Shi","Bomin Peng","Kailun Yang","Zhiyong Li"],"pdf_url":"https://arxiv.org/pdf/2503.02578v1.pdf","comment":"The source code will be publicly available at\n  https://github.com/krabs-H/TS-CGNet"},{"id":"http://arxiv.org/abs/2503.02577v1","updated":"2025-03-04T13:00:05Z","published":"2025-03-04T13:00:05Z","title":"SPG: Improving Motion Diffusion by Smooth Perturbation Guidance","summary":"  This paper presents a test-time guidance method to improve the output quality\nof the human motion diffusion models without requiring additional training. To\nhave negative guidance, Smooth Perturbation Guidance (SPG) builds a weak model\nby temporally smoothing the motion in the denoising steps. Compared to\nmodel-agnostic methods originating from the image generation field, SPG\neffectively mitigates out-of-distribution issues when perturbing motion\ndiffusion models. In SPG guidance, the nature of motion structure remains\nintact. This work conducts a comprehensive analysis across distinct model\narchitectures and tasks. Despite its extremely simple implementation and no\nneed for additional training requirements, SPG consistently enhances motion\nfidelity. Project page can be found at https://spg-blind.vercel.app/\n","authors":["Boseong Jeon"],"pdf_url":"https://arxiv.org/pdf/2503.02577v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2312.03790v2","updated":"2025-03-04T12:54:46Z","published":"2023-12-06T12:43:11Z","title":"Memory-Efficient Optical Flow via Radius-Distribution Orthogonal Cost\n  Volume","summary":"  The full 4D cost volume in Recurrent All-Pairs Field Transforms (RAFT) or\nglobal matching by Transformer achieves impressive performance for optical flow\nestimation. However, their memory consumption increases quadratically with\ninput resolution, rendering them impractical for high-resolution images. In\nthis paper, we present MeFlow, a novel memory-efficient method for\nhigh-resolution optical flow estimation. The key of MeFlow is a recurrent local\northogonal cost volume representation, which decomposes the 2D search space\ndynamically into two 1D orthogonal spaces, enabling our method to scale\neffectively to very high-resolution inputs. To preserve essential information\nin the orthogonal space, we utilize self attention to propagate feature\ninformation from the 2D space to the orthogonal space. We further propose a\nradius-distribution multi-scale lookup strategy to model the correspondences of\nlarge displacements at a negligible cost. We verify the efficiency and\neffectiveness of our method on the challenging Sintel and KITTI benchmarks, and\nreal-world 4K ($2160\\!\\times\\!3840$) images. Our method achieves competitive\nperformance on both Sintel and KITTI benchmarks, while maintaining the highest\nmemory efficiency on high-resolution inputs.\n","authors":["Gangwei Xu","Shujun Chen","Hao Jia","Miaojie Feng","Xin Yang"],"pdf_url":"https://arxiv.org/pdf/2312.03790v2.pdf","comment":"10 pages, 9 figures"},{"id":"http://arxiv.org/abs/2409.07972v4","updated":"2025-03-04T12:53:32Z","published":"2024-09-12T12:12:19Z","title":"Deep Height Decoupling for Precise Vision-based 3D Occupancy Prediction","summary":"  The task of vision-based 3D occupancy prediction aims to reconstruct 3D\ngeometry and estimate its semantic classes from 2D color images, where the\n2D-to-3D view transformation is an indispensable step. Most previous methods\nconduct forward projection, such as BEVPooling and VoxelPooling, both of which\nmap the 2D image features into 3D grids. However, the current grid representing\nfeatures within a certain height range usually introduces many confusing\nfeatures that belong to other height ranges. To address this challenge, we\npresent Deep Height Decoupling (DHD), a novel framework that incorporates\nexplicit height prior to filter out the confusing features. Specifically, DHD\nfirst predicts height maps via explicit supervision. Based on the height\ndistribution statistics, DHD designs Mask Guided Height Sampling (MGHS) to\nadaptively decouple the height map into multiple binary masks. MGHS projects\nthe 2D image features into multiple subspaces, where each grid contains\nfeatures within reasonable height ranges. Finally, a Synergistic Feature\nAggregation (SFA) module is deployed to enhance the feature representation\nthrough channel and spatial affinities, enabling further occupancy refinement.\nOn the popular Occ3D-nuScenes benchmark, our method achieves state-of-the-art\nperformance even with minimal input frames. Source code is released at\nhttps://github.com/yanzq95/DHD.\n","authors":["Yuan Wu","Zhiqiang Yan","Zhengxue Wang","Xiang Li","Le Hui","Jian Yang"],"pdf_url":"https://arxiv.org/pdf/2409.07972v4.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.00911v2","updated":"2025-03-04T12:45:15Z","published":"2024-10-01T17:58:06Z","title":"Dual Consolidation for Pre-Trained Model-Based Domain-Incremental\n  Learning","summary":"  Domain-Incremental Learning (DIL) involves the progressive adaptation of a\nmodel to new concepts across different domains. While recent advances in\npre-trained models provide a solid foundation for DIL, learning new concepts\noften results in the catastrophic forgetting of pre-trained knowledge.\nSpecifically, sequential model updates can overwrite both the representation\nand the classifier with knowledge from the latest domain. Thus, it is crucial\nto develop a representation and corresponding classifier that accommodate all\nseen domains throughout the learning process. To this end, we propose DUal\nConsolidaTion (Duct) to unify and consolidate historical knowledge at both the\nrepresentation and classifier levels. By merging the backbone of different\nstages, we create a representation space suitable for multiple domains\nincrementally. The merged representation serves as a balanced intermediary that\ncaptures task-specific features from all seen domains. Additionally, to address\nthe mismatch between consolidated embeddings and the classifier, we introduce\nan extra classifier consolidation process. Leveraging class-wise semantic\ninformation, we estimate the classifier weights of old domains within the\nlatest embedding space. By merging historical and estimated classifiers, we\nalign them with the consolidated embedding space, facilitating incremental\nclassification. Extensive experimental results on four benchmark datasets\ndemonstrate Duct's state-of-the-art performance. Code is available at\nhttps://github.com/Estrella-fugaz/CVPR25-Duct\n","authors":["Da-Wei Zhou","Zi-Wen Cai","Han-Jia Ye","Lijun Zhang","De-Chuan Zhan"],"pdf_url":"https://arxiv.org/pdf/2410.00911v2.pdf","comment":"Accepted to CVPR 2025. Code is available at\n  https://github.com/Estrella-fugaz/CVPR25-Duct"},{"id":"http://arxiv.org/abs/2502.00196v2","updated":"2025-03-04T12:36:10Z","published":"2025-01-31T22:26:33Z","title":"DermaSynth: Rich Synthetic Image-Text Pairs Using Open Access\n  Dermatology Datasets","summary":"  A major barrier to developing vision large language models (LLMs) in\ndermatology is the lack of large image--text pairs dataset. We introduce\nDermaSynth, a dataset comprising of 92,020 synthetic image--text pairs curated\nfrom 45,205 images (13,568 clinical and 35,561 dermatoscopic) for\ndermatology-related clinical tasks. Leveraging state-of-the-art LLMs, using\nGemini 2.0, we used clinically related prompts and self-instruct method to\ngenerate diverse and rich synthetic texts. Metadata of the datasets were\nincorporated into the input prompts by targeting to reduce potential\nhallucinations. The resulting dataset builds upon open access dermatological\nimage repositories (DERM12345, BCN20000, PAD-UFES-20, SCIN, and HIBA) that have\npermissive CC-BY-4.0 licenses. We also fine-tuned a preliminary\nLlama-3.2-11B-Vision-Instruct model, DermatoLlama 1.0, on 5,000 samples. We\nanticipate this dataset to support and accelerate AI research in dermatology.\nData and code underlying this work are accessible at\nhttps://github.com/abdurrahimyilmaz/DermaSynth.\n","authors":["Abdurrahim Yilmaz","Furkan Yuceyalcin","Ece Gokyayla","Donghee Choi","Ozan Erdem","Ali Anil Demircali","Rahmetullah Varol","Ufuk Gorkem Kirabali","Gulsum Gencoglan","Joram M. Posma","Burak Temelkuran"],"pdf_url":"https://arxiv.org/pdf/2502.00196v2.pdf","comment":"12 pages, 4 figures"},{"id":"http://arxiv.org/abs/2503.02558v1","updated":"2025-03-04T12:33:17Z","published":"2025-03-04T12:33:17Z","title":"Tracking-Aware Deformation Field Estimation for Non-rigid 3D\n  Reconstruction in Robotic Surgeries","summary":"  Minimally invasive procedures have been advanced rapidly by the robotic\nlaparoscopic surgery. The latter greatly assists surgeons in sophisticated and\nprecise operations with reduced invasiveness. Nevertheless, it is still safety\ncritical to be aware of even the least tissue deformation during\ninstrument-tissue interactions, especially in 3D space. To address this, recent\nworks rely on NeRF to render 2D videos from different perspectives and\neliminate occlusions. However, most of the methods fail to predict the accurate\n3D shapes and associated deformation estimates robustly. Differently, we\npropose Tracking-Aware Deformation Field (TADF), a novel framework which\nreconstructs the 3D mesh along with the 3D tissue deformation simultaneously.\nIt first tracks the key points of soft tissue by a foundation vision model,\nproviding an accurate 2D deformation field. Then, the 2D deformation field is\nsmoothly incorporated with a neural implicit reconstruction network to obtain\ntissue deformation in the 3D space. Finally, we experimentally demonstrate that\nthe proposed method provides more accurate deformation estimation compared with\nother 3D neural reconstruction methods in two public datasets.\n","authors":["Zeqing Wang","Han Fang","Yihong Xu","Yutong Ban"],"pdf_url":"https://arxiv.org/pdf/2503.02558v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2412.06097v2","updated":"2025-03-04T12:32:31Z","published":"2024-12-08T22:57:41Z","title":"Order Theory in the Context of Machine Learning","summary":"  The paper ``Tropical Geometry of Deep Neural Networks'' by L. Zhang et al.\nintroduces an equivalence between integer-valued neural networks (IVNN) with\n$\\text{ReLU}_{t}$ and tropical rational functions, which come with a map to\npolytopes. Here, IVNN refers to a network with integer weights but real biases,\nand $\\text{ReLU}_{t}$ is defined as $\\text{ReLU}_{t}(x)=\\max(x,t)$ for\n$t\\in\\mathbb{R}\\cup\\{-\\infty\\}$.\n  For every poset with $n$ points, there exists a corresponding order polytope,\ni.e., a convex polytope in the unit cube $[0,1]^n$ whose coordinates obey the\ninequalities of the poset. We study neural networks whose associated polytope\nis an order polytope. We then explain how posets with four points induce neural\nnetworks that can be interpreted as $2\\times 2$ convolutional filters. These\nposet filters can be added to any neural network, not only IVNN.\n  Similarly to maxout, poset pooling filters update the weights of the neural\nnetwork during backpropagation with more precision than average pooling, max\npooling, or mixed pooling, without the need to train extra parameters. We\nreport experiments that support our statements.\n  We also define the structure of algebra over the operad of posets on poset\nneural networks and tropical polynomials. This formalism allows us to study the\ncomposition of poset neural network arquitectures and the effect on their\ncorresponding Newton polytopes, via the introduction of the generalization of\ntwo operations on polytopes: the Minkowski sum and the convex envelope.\n","authors":["Eric Dolores-Cuenca","Aldo Guzman-Saenz","Sangil Kim","Susana Lopez-Moreno","Jose Mendoza-Cortes"],"pdf_url":"https://arxiv.org/pdf/2412.06097v2.pdf","comment":"We added experiments with ImageNet 100, and improved the exposition\n  of the theory developed. Added examples. Poster presentation in NeurIPS WIML\n  2024, Talk in JMM 2025 section: Applied category theory II"},{"id":"http://arxiv.org/abs/2503.02554v1","updated":"2025-03-04T12:26:45Z","published":"2025-03-04T12:26:45Z","title":"Towards a robust R2D2 paradigm for radio-interferometric imaging:\n  revisiting DNN training and architecture","summary":"  The R2D2 Deep Neural Network (DNN) series was recently introduced for image\nformation in radio interferometry. It can be understood as a learned version of\nCLEAN, whose minor cycles are substituted with DNNs. We revisit R2D2 on the\ngrounds of series convergence, training methodology, and DNN architecture,\nimproving its robustness in terms of generalisability beyond training\nconditions, capability to deliver high data fidelity, and epistemic\nuncertainty. Firstly, while still focusing on telescope-specific training, we\nenhance the learning process by randomising Fourier sampling integration times,\nincorporating multi-scan multi-noise configurations, and varying imaging\nsettings, including pixel resolution and visibility-weighting scheme. Secondly,\nwe introduce a convergence criterion whereby the reconstruction process stops\nwhen the data residual is compatible with noise, rather than simply using all\navailable DNNs. This not only increases the reconstruction efficiency by\nreducing its computational cost, but also refines training by pruning out the\ndata/image pairs for which optimal data fidelity is reached before training the\nnext DNN. Thirdly, we substitute R2D2's early U-Net DNN with a novel\narchitecture (U-WDSR) combining U-Net and WDSR, which leverages wide\nactivation, dense connections, weight normalisation, and low-rank convolution\nto improve feature reuse and reconstruction precision. As previously, R2D2 was\ntrained for monochromatic intensity imaging with the Very Large Array (VLA) at\nfixed $512 \\times 512$ image size. Simulations on a wide range of inverse\nproblems and a case study on real data reveal that the new R2D2 model\nconsistently outperforms its earlier version in image reconstruction quality,\ndata fidelity, and epistemic uncertainty.\n","authors":["Amir Aghabiglou","Chung San Chu","Chao Tang","Arwa Dabbech","Yves Wiaux"],"pdf_url":"https://arxiv.org/pdf/2503.02554v1.pdf","comment":"17 pages, 6 figures"},{"id":"http://arxiv.org/abs/2503.02549v1","updated":"2025-03-04T12:20:06Z","published":"2025-03-04T12:20:06Z","title":"Federated nnU-Net for Privacy-Preserving Medical Image Segmentation","summary":"  The nnU-Net framework has played a crucial role in medical image segmentation\nand has become the gold standard in multitudes of applications targeting\ndifferent diseases, organs, and modalities. However, so far it has been used\nprimarily in a centralized approach where the data collected from hospitals are\nstored in one center and used to train the nnU-Net. This centralized approach\nhas various limitations, such as leakage of sensitive patient information and\nviolation of patient privacy. Federated learning is one of the approaches to\ntrain a segmentation model in a decentralized manner that helps preserve\npatient privacy. In this paper, we propose FednnU-Net, a federated learning\nextension of nnU-Net. We introduce two novel federated learning methods to the\nnnU-Net framework - Federated Fingerprint Extraction (FFE) and Asymmetric\nFederated Averaging (AsymFedAvg) - and experimentally show their consistent\nperformance for breast, cardiac and fetal segmentation using 6 datasets\nrepresenting samples from 18 institutions. Additionally, to further promote\nresearch and deployment of decentralized training in privacy constrained\ninstitutions, we make our plug-n-play framework public. The source-code is\navailable at https://github.com/faildeny/FednnUNet .\n","authors":["Grzegorz Skorupko","Fotios Avgoustidis","Carlos Martn-Isla","Lidia Garrucho","Dimitri A. Kessler","Esmeralda Ruiz Pujadas","Oliver Daz","Maciej Bobowicz","Katarzyna Gwodziewicz","Xavier Bargall","Paulius Jarueviius","Kaisar Kushibar","Karim Lekadir"],"pdf_url":"https://arxiv.org/pdf/2503.02549v1.pdf","comment":"In review"},{"id":"http://arxiv.org/abs/2503.02547v1","updated":"2025-03-04T12:15:33Z","published":"2025-03-04T12:15:33Z","title":"PVTree: Realistic and Controllable Palm Vein Generation for Recognition\n  Tasks","summary":"  Palm vein recognition is an emerging biometric technology that offers\nenhanced security and privacy. However, acquiring sufficient palm vein data for\ntraining deep learning-based recognition models is challenging due to the high\ncosts of data collection and privacy protection constraints. This has led to a\ngrowing interest in generating pseudo-palm vein data using generative models.\nExisting methods, however, often produce unrealistic palm vein patterns or\nstruggle with controlling identity and style attributes. To address these\nissues, we propose a novel palm vein generation framework named PVTree. First,\nthe palm vein identity is defined by a complex and authentic 3D palm vascular\ntree, created using an improved Constrained Constructive Optimization (CCO)\nalgorithm. Second, palm vein patterns of the same identity are generated by\nprojecting the same 3D vascular tree into 2D images from different views and\nconverting them into realistic images using a generative model. As a result,\nPVTree satisfies the need for both identity consistency and intra-class\ndiversity. Extensive experiments conducted on several publicly available\ndatasets demonstrate that our proposed palm vein generation method surpasses\nexisting methods and achieves a higher TAR@FAR=1e-4 under the 1:1 Open-set\nprotocol. To the best of our knowledge, this is the first time that the\nperformance of a recognition model trained on synthetic palm vein data exceeds\nthat of the recognition model trained on real data, which indicates that palm\nvein image generation research has a promising future.\n","authors":["Sheng Shang","Chenglong Zhao","Ruixin Zhang","Jianlong Jin","Jingyun Zhang","Rizen Guo","Shouhong Ding","Yunsheng Wu","Yang Zhao","Wei Jia"],"pdf_url":"https://arxiv.org/pdf/2503.02547v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.00401v2","updated":"2025-03-04T12:04:26Z","published":"2025-03-01T08:29:59Z","title":"Smoothing Grounding and Reasoning for MLLM-Powered GUI Agents with\n  Query-Oriented Pivot Tasks","summary":"  Perception-enhanced pre-training, particularly through grounding techniques,\nis widely adopted to enhance the performance of graphical user interface (GUI)\nagents. However, in resource-constrained scenarios, the format discrepancy\nbetween coordinate-oriented grounding and action-oriented reasoning limits the\neffectiveness of grounding for reasoning tasks. To address this challenge, we\npropose a query-oriented pivot approach called query inference, which serves as\na bridge between GUI grounding and reasoning. By inferring potential user\nqueries from a screenshot and its associated element coordinates, query\ninference improves the understanding of coordinates while aligning more closely\nwith reasoning tasks. Experimental results show that query inference\noutperforms previous grounding techniques under the same training data scale.\nNotably, query inference achieves comparable or even better performance to\nlarge-scale grounding-enhanced OS-Atlas with less than 0.1% of training data.\nFurthermore, we explore the impact of reasoning formats and demonstrate that\nintegrating additional semantic information into the input further boosts\nreasoning performance. The code is publicly available at\nhttps://github.com/ZrW00/GUIPivot.\n","authors":["Zongru Wu","Pengzhou Cheng","Zheng Wu","Tianjie Ju","Zhuosheng Zhang","Gongshen Liu"],"pdf_url":"https://arxiv.org/pdf/2503.00401v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.02537v1","updated":"2025-03-04T12:03:26Z","published":"2025-03-04T12:03:26Z","title":"RectifiedHR: Enable Efficient High-Resolution Image Generation via\n  Energy Rectification","summary":"  Diffusion models have achieved remarkable advances in various image\ngeneration tasks. However, their performance notably declines when generating\nimages at resolutions higher than those used during the training period.\nDespite the existence of numerous methods for producing high-resolution images,\nthey either suffer from inefficiency or are hindered by complex operations. In\nthis paper, we propose RectifiedHR, an efficient and straightforward solution\nfor training-free high-resolution image generation. Specifically, we introduce\nthe noise refresh strategy, which theoretically only requires a few lines of\ncode to unlock the model's high-resolution generation ability and improve\nefficiency. Additionally, we first observe the phenomenon of energy decay that\nmay cause image blurriness during the high-resolution image generation process.\nTo address this issue, we propose an Energy Rectification strategy, where\nmodifying the hyperparameters of the classifier-free guidance effectively\nimproves the generation performance. Our method is entirely training-free and\nboasts a simple implementation logic. Through extensive comparisons with\nnumerous baseline methods, our RectifiedHR demonstrates superior effectiveness\nand efficiency.\n","authors":["Zhen Yang","Guibao Shen","Liang Hou","Mushui Liu","Luozhou Wang","Xin Tao","Pengfei Wan","Di Zhang","Ying-Cong Chen"],"pdf_url":"https://arxiv.org/pdf/2503.02537v1.pdf","comment":"Project Page: https://zhenyangcs.github.io/RectifiedHR-Diffusion/"},{"id":"http://arxiv.org/abs/2503.01202v2","updated":"2025-03-04T11:59:54Z","published":"2025-03-03T05:55:30Z","title":"A Multi-Sensor Fusion Approach for Rapid Orthoimage Generation in\n  Large-Scale UAV Mapping","summary":"  Rapid generation of large-scale orthoimages from Unmanned Aerial Vehicles\n(UAVs) has been a long-standing focus of research in the field of aerial\nmapping. A multi-sensor UAV system, integrating the Global Positioning System\n(GPS), Inertial Measurement Unit (IMU), 4D millimeter-wave radar and camera,\ncan provide an effective solution to this problem. In this paper, we utilize\nmulti-sensor data to overcome the limitations of conventional orthoimage\ngeneration methods in terms of temporal performance, system robustness, and\ngeographic reference accuracy. A prior-pose-optimized feature matching method\nis introduced to enhance matching speed and accuracy, reducing the number of\nrequired features and providing precise references for the Structure from\nMotion (SfM) process. The proposed method exhibits robustness in low-texture\nscenes like farmlands, where feature matching is difficult. Experiments show\nthat our approach achieves accurate feature matching orthoimage generation in a\nshort time. The proposed drone system effectively aids in farmland detection\nand management.\n","authors":["Jialei He","Zhihao Zhan","Zhituo Tu","Xiang Zhu","Jie Yuan"],"pdf_url":"https://arxiv.org/pdf/2503.01202v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.02511v1","updated":"2025-03-04T11:20:10Z","published":"2025-03-04T11:20:10Z","title":"TeTRA-VPR: A Ternary Transformer Approach for Compact Visual Place\n  Recognition","summary":"  Visual Place Recognition (VPR) localizes a query image by matching it against\na database of geo-tagged reference images, making it essential for navigation\nand mapping in robotics. Although Vision Transformer (ViT) solutions deliver\nhigh accuracy, their large models often exceed the memory and compute budgets\nof resource-constrained platforms such as drones and mobile robots. To address\nthis issue, we propose TeTRA, a ternary transformer approach that progressively\nquantizes the ViT backbone to 2-bit precision and binarizes its final embedding\nlayer, offering substantial reductions in model size and latency. A carefully\ndesigned progressive distillation strategy preserves the representational power\nof a full-precision teacher, allowing TeTRA to retain or even surpass the\naccuracy of uncompressed convolutional counterparts, despite using fewer\nresources. Experiments on standard VPR benchmarks demonstrate that TeTRA\nreduces memory consumption by up to 69% compared to efficient baselines, while\nlowering inference latency by 35%, with either no loss or a slight improvement\nin recall@1. These gains enable high-accuracy VPR on power-constrained,\nmemory-limited robotic platforms, making TeTRA an appealing solution for\nreal-world deployment.\n","authors":["Oliver Grainge","Michael Milford","Indu Bodala","Sarvapali D. Ramchurn","Shoaib Ehsan"],"pdf_url":"https://arxiv.org/pdf/2503.02511v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.02510v1","updated":"2025-03-04T11:19:18Z","published":"2025-03-04T11:19:18Z","title":"Remote Sensing Image Classification Using Convolutional Neural Network\n  (CNN) and Transfer Learning Techniques","summary":"  This study investigates the classification of aerial images depicting\ntransmission towers, forests, farmland, and mountains. To complete the\nclassification job, features are extracted from input photos using a\nConvolutional Neural Network (CNN) architecture. Then, the images are\nclassified using Softmax. To test the model, we ran it for ten epochs using a\nbatch size of 90, the Adam optimizer, and a learning rate of 0.001. Both\ntraining and assessment are conducted using a dataset that blends\nself-collected pictures from Google satellite imagery with the MLRNet dataset.\nThe comprehensive dataset comprises 10,400 images. Our study shows that\ntransfer learning models and MobileNetV2 in particular, work well for landscape\ncategorization. These models are good options for practical use because they\nstrike a good mix between precision and efficiency; our approach achieves\nresults with an overall accuracy of 87% on the built CNN model. Furthermore, we\nreach even higher accuracies by utilizing the pretrained VGG16 and MobileNetV2\nmodels as a starting point for transfer learning. Specifically, VGG16 achieves\nan accuracy of 90% and a test loss of 0.298, while MobileNetV2 outperforms both\nmodels with an accuracy of 96% and a test loss of 0.119; the results\ndemonstrate the effectiveness of employing transfer learning with MobileNetV2\nfor classifying transmission towers, forests, farmland, and mountains.\n","authors":["Mustafa Majeed Abd Zaid","Ahmed Abed Mohammed","Putra Sumari"],"pdf_url":"https://arxiv.org/pdf/2503.02510v1.pdf","comment":"This paper is published in Journal of Computer Science, Volume 21 No.\n  3, 2025. It contains 635-645 pages"},{"id":"http://arxiv.org/abs/2503.02508v1","updated":"2025-03-04T11:19:02Z","published":"2025-03-04T11:19:02Z","title":"Q&C: When Quantization Meets Cache in Efficient Image Generation","summary":"  Quantization and cache mechanisms are typically applied individually for\nefficient Diffusion Transformers (DiTs), each demonstrating notable potential\nfor acceleration. However, the promoting effect of combining the two mechanisms\non efficient generation remains under-explored. Through empirical\ninvestigation, we find that the combination of quantization and cache\nmechanisms for DiT is not straightforward, and two key challenges lead to\nsevere catastrophic performance degradation: (i) the sample efficacy of\ncalibration datasets in post-training quantization (PTQ) is significantly\neliminated by cache operation; (ii) the combination of the above mechanisms\nintroduces more severe exposure bias within sampling distribution, resulting in\namplified error accumulation in the image generation process. In this work, we\ntake advantage of these two acceleration mechanisms and propose a hybrid\nacceleration method by tackling the above challenges, aiming to further improve\nthe efficiency of DiTs while maintaining excellent generation capability.\nConcretely, a temporal-aware parallel clustering (TAP) is designed to\ndynamically improve the sample selection efficacy for the calibration within\nPTQ for different diffusion steps. A variance compensation (VC) strategy is\nderived to correct the sampling distribution. It mitigates exposure bias\nthrough an adaptive correction factor generation. Extensive experiments have\nshown that our method has accelerated DiTs by 12.7x while preserving\ncompetitive generation capability. The code will be available at\nhttps://github.com/xinding-sys/Quant-Cache.\n","authors":["Xin Ding","Xin Li","Haotong Qin","Zhibo Chen"],"pdf_url":"https://arxiv.org/pdf/2503.02508v1.pdf","comment":"11 pages"},{"id":"http://arxiv.org/abs/2503.02505v1","updated":"2025-03-04T11:16:46Z","published":"2025-03-04T11:16:46Z","title":"ROCKET-2: Steering Visuomotor Policy via Cross-View Goal Alignment","summary":"  We aim to develop a goal specification method that is semantically clear,\nspatially sensitive, and intuitive for human users to guide agent interactions\nin embodied environments. Specifically, we propose a novel cross-view goal\nalignment framework that allows users to specify target objects using\nsegmentation masks from their own camera views rather than the agent's\nobservations. We highlight that behavior cloning alone fails to align the\nagent's behavior with human intent when the human and agent camera views differ\nsignificantly. To address this, we introduce two auxiliary objectives:\ncross-view consistency loss and target visibility loss, which explicitly\nenhance the agent's spatial reasoning ability. According to this, we develop\nROCKET-2, a state-of-the-art agent trained in Minecraft, achieving an\nimprovement in the efficiency of inference 3x to 6x. We show ROCKET-2 can\ndirectly interpret goals from human camera views for the first time, paving the\nway for better human-agent interaction.\n","authors":["Shaofei Cai","Zhancun Mu","Anji Liu","Yitao Liang"],"pdf_url":"https://arxiv.org/pdf/2503.02505v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.02503v1","updated":"2025-03-04T11:11:14Z","published":"2025-03-04T11:11:14Z","title":"Deepfake Detection via Knowledge Injection","summary":"  Deepfake detection technologies become vital because current generative AI\nmodels can generate realistic deepfakes, which may be utilized in malicious\npurposes. Existing deepfake detection methods either rely on developing\nclassification methods to better fit the distributions of the training data, or\nexploiting forgery synthesis mechanisms to learn a more comprehensive forgery\ndistribution. Unfortunately, these methods tend to overlook the essential role\nof real data knowledge, which limits their generalization ability in processing\nthe unseen real and fake data. To tackle these challenges, in this paper, we\npropose a simple and novel approach, named Knowledge Injection based deepfake\nDetection (KID), by constructing a multi-task learning based knowledge\ninjection framework, which can be easily plugged into existing ViT-based\nbackbone models, including foundation models. Specifically, a knowledge\ninjection module is proposed to learn and inject necessary knowledge into the\nbackbone model, to achieve a more accurate modeling of the distributions of\nreal and fake data. A coarse-grained forgery localization branch is constructed\nto learn the forgery locations in a multi-task learning manner, to enrich the\nlearned forgery knowledge for the knowledge injection module. Two layer-wise\nsuppression and contrast losses are proposed to emphasize the knowledge of real\ndata in the knowledge injection module, to further balance the portions of the\nreal and fake knowledge. Extensive experiments have demonstrated that our KID\npossesses excellent compatibility with different scales of Vit-based backbone\nmodels, and achieves state-of-the-art generalization performance while\nenhancing the training convergence speed.\n","authors":["Tonghui Li","Yuanfang Guo","Zeming Liu","Heqi Peng","Yunhong Wang"],"pdf_url":"https://arxiv.org/pdf/2503.02503v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2501.08180v2","updated":"2025-03-04T10:58:45Z","published":"2025-01-14T15:03:53Z","title":"D$^2$-DPM: Dual Denoising for Quantized Diffusion Probabilistic Models","summary":"  Diffusion models have achieved cutting-edge performance in image generation.\nHowever, their lengthy denoising process and computationally intensive score\nestimation network impede their scalability in low-latency and\nresource-constrained scenarios. Post-training quantization (PTQ) compresses and\naccelerates diffusion models without retraining, but it inevitably introduces\nadditional quantization noise, resulting in mean and variance deviations. In\nthis work, we propose D2-DPM, a dual denoising mechanism aimed at precisely\nmitigating the adverse effects of quantization noise on the noise estimation\nnetwork. Specifically, we first unravel the impact of quantization noise on the\nsampling equation into two components: the mean deviation and the variance\ndeviation. The mean deviation alters the drift coefficient of the sampling\nequation, influencing the trajectory trend, while the variance deviation\nmagnifies the diffusion coefficient, impacting the convergence of the sampling\ntrajectory. The proposed D2-DPM is thus devised to denoise the quantization\nnoise at each time step, and then denoise the noisy sample through the inverse\ndiffusion iterations. Experimental results demonstrate that D2-DPM achieves\nsuperior generation quality, yielding a 1.42 lower FID than the full-precision\nmodel while achieving 3.99x compression and 11.67x bit-operation acceleration.\n","authors":["Qian Zeng","Jie Song","Han Zheng","Hao Jiang","Mingli Song"],"pdf_url":"https://arxiv.org/pdf/2501.08180v2.pdf","comment":"9 pages, 4 figures, acceptted by AAAI2025, the code is available at\n  https://github.com/taylorjocelyn/d2-dpm"},{"id":"http://arxiv.org/abs/2503.02491v1","updated":"2025-03-04T10:57:24Z","published":"2025-03-04T10:57:24Z","title":"Joint Out-of-Distribution Filtering and Data Discovery Active Learning","summary":"  As the data demand for deep learning models increases, active learning (AL)\nbecomes essential to strategically select samples for labeling, which maximizes\ndata efficiency and reduces training costs. Real-world scenarios necessitate\nthe consideration of incomplete data knowledge within AL. Prior works address\nhandling out-of-distribution (OOD) data, while another research direction has\nfocused on category discovery. However, a combined analysis of real-world\nconsiderations combining AL with out-of-distribution data and category\ndiscovery remains unexplored. To address this gap, we propose Joint\nOut-of-distribution filtering and data Discovery Active learning (Joda) , to\nuniquely address both challenges simultaneously by filtering out OOD data\nbefore selecting candidates for labeling. In contrast to previous methods, we\ndeeply entangle the training procedure with filter and selection to construct a\ncommon feature space that aligns known and novel categories while separating\nOOD samples. Unlike previous works, Joda is highly efficient and completely\nomits auxiliary models and training access to the unlabeled pool for filtering\nor selection. In extensive experiments on 18 configurations and 3 metrics,\n\\ours{} consistently achieves the highest accuracy with the best class\ndiscovery to OOD filtering balance compared to state-of-the-art competitor\napproaches.\n","authors":["Sebastian Schmidt","Leonard Schenk","Leo Schwinn","Stephan Gnnemann"],"pdf_url":"https://arxiv.org/pdf/2503.02491v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.02490v1","updated":"2025-03-04T10:56:08Z","published":"2025-03-04T10:56:08Z","title":"Deep Robust Reversible Watermarking","summary":"  Robust Reversible Watermarking (RRW) enables perfect recovery of cover images\nand watermarks in lossless channels while ensuring robust watermark extraction\nin lossy channels. Existing RRW methods, mostly non-deep learning-based, face\ncomplex designs, high computational costs, and poor robustness, limiting their\npractical use. This paper proposes Deep Robust Reversible Watermarking (DRRW),\na deep learning-based RRW scheme. DRRW uses an Integer Invertible Watermark\nNetwork (iIWN) to map integer data distributions invertibly, addressing\nconventional RRW limitations. Unlike traditional RRW, which needs\ndistortion-specific designs, DRRW employs an encoder-noise layer-decoder\nframework for adaptive robustness via end-to-end training. In inference, cover\nimage and watermark map to an overflowed stego image and latent variables,\ncompressed by arithmetic coding into a bitstream embedded via reversible data\nhiding for lossless recovery. We introduce an overflow penalty loss to reduce\npixel overflow, shortening the auxiliary bitstream while enhancing robustness\nand stego image quality. An adaptive weight adjustment strategy avoids manual\nwatermark loss weighting, improving training stability and performance.\nExperiments show DRRW outperforms state-of-the-art RRW methods, boosting\nrobustness and cutting embedding, extraction, and recovery complexities by\n55.14\\(\\times\\), 5.95\\(\\times\\), and 3.57\\(\\times\\), respectively. The\nauxiliary bitstream shrinks by 43.86\\(\\times\\), with reversible embedding\nsucceeding on 16,762 PASCAL VOC 2012 images, advancing practical RRW. DRRW\nexceeds irreversible robust watermarking in robustness and quality while\nmaintaining reversibility.\n","authors":["Jiale Chen","Wei Wang","Chongyang Shi","Li Dong","Yuanman Li","Xiping Hu"],"pdf_url":"https://arxiv.org/pdf/2503.02490v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2502.20577v2","updated":"2025-03-04T10:53:45Z","published":"2025-02-27T22:37:09Z","title":"InstaFace: Identity-Preserving Facial Editing with Single Image\n  Inference","summary":"  Facial appearance editing is crucial for digital avatars, AR/VR, and\npersonalized content creation, driving realistic user experiences. However,\npreserving identity with generative models is challenging, especially in\nscenarios with limited data availability. Traditional methods often require\nmultiple images and still struggle with unnatural face shifts, inconsistent\nhair alignment, or excessive smoothing effects. To overcome these challenges,\nwe introduce a novel diffusion-based framework, InstaFace, to generate\nrealistic images while preserving identity using only a single image. Central\nto InstaFace, we introduce an efficient guidance network that harnesses 3D\nperspectives by integrating multiple 3DMM-based conditionals without\nintroducing additional trainable parameters. Moreover, to ensure maximum\nidentity retention as well as preservation of background, hair, and other\ncontextual features like accessories, we introduce a novel module that utilizes\nfeature embeddings from a facial recognition model and a pre-trained\nvision-language model. Quantitative evaluations demonstrate that our method\noutperforms several state-of-the-art approaches in terms of identity\npreservation, photorealism, and effective control of pose, expression, and\nlighting.\n","authors":["MD Wahiduzzaman Khan","Mingshan Jia","Xiaolin Zhang","En Yu","Caifeng Shan","Kaska Musial-Gabrys"],"pdf_url":"https://arxiv.org/pdf/2502.20577v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.02487v1","updated":"2025-03-04T10:50:58Z","published":"2025-03-04T10:50:58Z","title":"Scene-based nonuniformity correction with homography transformation","summary":"  Due to their affordable, low mass, and small dimensions, uncooled\nmicrobolometer-based thermal focal plane arrays (UC-FPAs) are useful for\nlong-wave infrared (LWIR)imaging applications. However, in outdoor conditions\ntypical in agricultural remote sensing, cameras based on UC-FPAs may suffer\nfrom drift in offset and gain. To tackle the persistent drift, the system\nrequires continuous calibration. Our goal in this study was to eliminate this\nrequirement via a computational schema. In a former study, we estimated unknown\ngain and offset values and thermographic images of an object from a sequence of\npairs of successive images taken at two different blur levels.In the current\nwork, we took on a similar problem using a sequence of shifted images, with\nrelative shifts caused by realistic drone hovering modeled by homography\ntransformation. This places our work in the realm of scene-based nonuniformity\ncorrection problems. We show that an object's thermographic values, as well as\ngain and offset, can be jointly estimated by relying on a few sets of shifted\nimages. We use a minimum likelihood estimator, which is found using alternating\nminimization. Registration is done using a generalized Lucas-Kanade method.\nSimulations show promising accuracy with mean Pearson correlation of more than\n0.9999998 between ground truth and restoration. Under ideal assumptions, this\nis equivalent to a mean restoration error of less than 0.01 Celsius degree.\n","authors":["Peretz Yafin","Nir Sochen","Iftach Klapp"],"pdf_url":"https://arxiv.org/pdf/2503.02487v1.pdf","comment":"Imaging, Inverse problems, Functional analysis, Blind deconvolution"},{"id":"http://arxiv.org/abs/2503.02484v1","updated":"2025-03-04T10:48:44Z","published":"2025-03-04T10:48:44Z","title":"ERetinex: Event Camera Meets Retinex Theory for Low-Light Image\n  Enhancement","summary":"  Low-light image enhancement aims to restore the under-exposure image captured\nin dark scenarios. Under such scenarios, traditional frame-based cameras may\nfail to capture the structure and color information due to the exposure time\nlimitation. Event cameras are bio-inspired vision sensors that respond to\npixel-wise brightness changes asynchronously. Event cameras' high dynamic range\nis pivotal for visual perception in extreme low-light scenarios, surpassing\ntraditional cameras and enabling applications in challenging dark environments.\nIn this paper, inspired by the success of the retinex theory for traditional\nframe-based low-light image restoration, we introduce the first methods that\ncombine the retinex theory with event cameras and propose a novel retinex-based\nlow-light image restoration framework named ERetinex. Among our contributions,\nthe first is developing a new approach that leverages the high temporal\nresolution data from event cameras with traditional image information to\nestimate scene illumination accurately. This method outperforms traditional\nimage-only techniques, especially in low-light environments, by providing more\nprecise lighting information. Additionally, we propose an effective fusion\nstrategy that combines the high dynamic range data from event cameras with the\ncolor information of traditional images to enhance image quality. Through this\nfusion, we can generate clearer and more detail-rich images, maintaining the\nintegrity of visual information even under extreme lighting conditions. The\nexperimental results indicate that our proposed method outperforms\nstate-of-the-art (SOTA) methods, achieving a gain of 1.0613 dB in PSNR while\nreducing FLOPS by \\textbf{84.28}\\%.\n","authors":["Xuejian Guo","Zhiqiang Tian","Yuehang Wang","Siqi Li","Yu Jiang","Shaoyi Du","Yue Gao"],"pdf_url":"https://arxiv.org/pdf/2503.02484v1.pdf","comment":"Accepted to ICRA 2025"},{"id":"http://arxiv.org/abs/2503.02481v1","updated":"2025-03-04T10:47:10Z","published":"2025-03-04T10:47:10Z","title":"A Novel Streamline-based diffusion MRI Tractography Registration Method\n  with Probabilistic Keypoint Detection","summary":"  Registration of diffusion MRI tractography is an essential step for analyzing\ngroup similarities and variations in the brain's white matter (WM).\nStreamline-based registration approaches can leverage the 3D geometric\ninformation of fiber pathways to enable spatial alignment after registration.\nExisting methods usually rely on the optimization of the spatial distances to\nidentify the optimal transformation. However, such methods overlook point\nconnectivity patterns within the streamline itself, limiting their ability to\nidentify anatomical correspondences across tractography datasets. In this work,\nwe propose a novel unsupervised approach using deep learning to perform\nstreamline-based dMRI tractography registration. The overall idea is to\nidentify corresponding keypoint pairs across subjects for spatial alignment of\ntractography datasets. We model tractography as point clouds to leverage the\ngraph connectivity along streamlines. We propose a novel keypoint detection\nmethod for streamlines, framed as a probabilistic classification task to\nidentify anatomically consistent correspondences across unstructured streamline\nsets. In the experiments, we compare several existing methods and show highly\neffective and efficient tractography registration performance.\n","authors":["Junyi Wang","Mubai Du","Ye Wu","Yijie Li","William M. Wells III","Lauren J. O'Donnell","Fan Zhang"],"pdf_url":"https://arxiv.org/pdf/2503.02481v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2307.07036v2","updated":"2025-03-04T10:43:51Z","published":"2023-07-13T19:27:40Z","title":"GenConViT: Deepfake Video Detection Using Generative Convolutional\n  Vision Transformer","summary":"  Deepfakes have raised significant concerns due to their potential to spread\nfalse information and compromise digital media integrity. Current deepfake\ndetection models often struggle to generalize across a diverse range of\ndeepfake generation techniques and video content. In this work, we propose a\nGenerative Convolutional Vision Transformer (GenConViT) for deepfake video\ndetection. Our model combines ConvNeXt and Swin Transformer models for feature\nextraction, and it utilizes Autoencoder and Variational Autoencoder to learn\nfrom the latent data distribution. By learning from the visual artifacts and\nlatent data distribution, GenConViT achieves improved performance in detecting\na wide range of deepfake videos. The model is trained and evaluated on DFDC,\nFF++, TM, DeepfakeTIMIT, and Celeb-DF (v$2$) datasets. The proposed GenConViT\nmodel demonstrates strong performance in deepfake video detection, achieving\nhigh accuracy across the tested datasets. While our model shows promising\nresults in deepfake video detection by leveraging visual and latent features,\nwe demonstrate that further work is needed to improve its generalizability,\ni.e., when encountering out-of-distribution data. Our model provides an\neffective solution for identifying a wide range of fake videos while preserving\nmedia integrity. The open-source code for GenConViT is available at\nhttps://github.com/erprogs/GenConViT.\n","authors":["Deressa Wodajo Deressa","Hannes Mareen","Peter Lambert","Solomon Atnafu","Zahid Akhtar","Glenn Van Wallendael"],"pdf_url":"https://arxiv.org/pdf/2307.07036v2.pdf","comment":"11 pages, 4 figures"},{"id":"http://arxiv.org/abs/2503.02476v1","updated":"2025-03-04T10:39:42Z","published":"2025-03-04T10:39:42Z","title":"BioD2C: A Dual-level Semantic Consistency Constraint Framework for\n  Biomedical VQA","summary":"  Biomedical visual question answering (VQA) has been widely studied and has\ndemonstrated significant application value and potential in fields such as\nassistive medical diagnosis. Despite their success, current biomedical VQA\nmodels perform multimodal information interaction only at the model level\nwithin large language models (LLMs), leading to suboptimal multimodal semantic\nalignment when dealing with complex tasks. To address this issue, we propose\nBioD2C: a novel Dual-level Semantic Consistency Constraint Framework for\nBiomedical VQA, which achieves dual-level semantic interaction alignment at\nboth the model and feature levels, enabling the model to adaptively learn\nvisual features based on the question. Specifically, we firstly integrate\ntextual features into visual features via an image-text fusion mechanism as\nfeature-level semantic interaction, obtaining visual features conditioned on\nthe given text; and then introduce a text-queue-based cross-modal soft semantic\nloss function to further align the image semantics with the question semantics.\nSpecifically, in this work, we establish a new dataset, BioVGQ, to address\ninherent biases in prior datasets by filtering manually-altered images and\naligning question-answer pairs with multimodal context, and train our model on\nthis dataset. Extensive experimental results demonstrate that BioD2C achieves\nstate-of-the-art (SOTA) performance across multiple downstream datasets,\nshowcasing its robustness, generalizability, and potential to advance\nbiomedical VQA research.\n","authors":["Zhengyang Ji","Shang Gao","Li Liu","Yifan Jia","Yutao Yue"],"pdf_url":"https://arxiv.org/pdf/2503.02476v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2502.14801v3","updated":"2025-03-04T10:28:47Z","published":"2025-02-20T18:22:44Z","title":"AVD2: Accident Video Diffusion for Accident Video Description","summary":"  Traffic accidents present complex challenges for autonomous driving, often\nfeaturing unpredictable scenarios that hinder accurate system interpretation\nand responses. Nonetheless, prevailing methodologies fall short in elucidating\nthe causes of accidents and proposing preventive measures due to the paucity of\ntraining data specific to accident scenarios. In this work, we introduce AVD2\n(Accident Video Diffusion for Accident Video Description), a novel framework\nthat enhances accident scene understanding by generating accident videos that\naligned with detailed natural language descriptions and reasoning, resulting in\nthe contributed EMM-AU (Enhanced Multi-Modal Accident Video Understanding)\ndataset. Empirical results reveal that the integration of the EMM-AU dataset\nestablishes state-of-the-art performance across both automated metrics and\nhuman evaluations, markedly advancing the domains of accident analysis and\nprevention. Project resources are available at https://an-answer-tree.github.io\n","authors":["Cheng Li","Keyuan Zhou","Tong Liu","Yu Wang","Mingqiao Zhuang","Huan-ang Gao","Bu Jin","Hao Zhao"],"pdf_url":"https://arxiv.org/pdf/2502.14801v3.pdf","comment":"ICRA 2025, Project Page: https://an-answer-tree.github.io/"},{"id":"http://arxiv.org/abs/2409.05650v3","updated":"2025-03-04T10:22:01Z","published":"2024-09-09T14:16:27Z","title":"Replay Consolidation with Label Propagation for Continual Object\n  Detection","summary":"  Continual Learning (CL) aims to learn new data while remembering previously\nacquired knowledge. In contrast to CL for image classification, CL for Object\nDetection faces additional challenges such as the missing annotations problem.\nIn this scenario, images from previous tasks may contain instances of unknown\nclasses that could reappear as labeled in future tasks, leading to task\ninterference in replay-based approaches. Consequently, most approaches in the\nliterature have focused on distillation-based techniques, which are effective\nwhen there is a significant class overlap between tasks. In our work, we\npropose an alternative to distillation-based approaches with a novel approach\ncalled Replay Consolidation with Label Propagation for Object Detection\n(RCLPOD). RCLPOD enhances the replay memory by improving the quality of the\nstored samples through a technique that promotes class balance while also\nimproving the quality of the ground truth associated with these samples through\na technique called label propagation. RCLPOD outperforms existing techniques on\nwell-established benchmarks such as VOC and COC. Moreover, our approach is\ndeveloped to work with modern architectures like YOLOv8, making it suitable for\ndynamic, real-world applications such as autonomous driving and robotics, where\ncontinuous learning and resource efficiency are essential.\n","authors":["Riccardo De Monte","Davide Dalle Pezze","Marina Ceccon","Francesco Pasti","Francesco Paissan","Elisabetta Farella","Gian Antonio Susto","Nicola Bellotto"],"pdf_url":"https://arxiv.org/pdf/2409.05650v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.02459v1","updated":"2025-03-04T10:09:46Z","published":"2025-03-04T10:09:46Z","title":"Exploring Token-Level Augmentation in Vision Transformer for\n  Semi-Supervised Semantic Segmentation","summary":"  Semi-supervised semantic segmentation has witnessed remarkable advancements\nin recent years. However, existing algorithms are based on convolutional neural\nnetworks and directly applying them to Vision Transformers poses certain\nlimitations due to conceptual disparities. To this end, we propose TokenMix, a\ndata augmentation technique specifically designed for semi-supervised semantic\nsegmentation with Vision Transformers. TokenMix aligns well with the global\nattention mechanism by mixing images at the token level, enhancing learning\ncapability for contexutual information among image patches. We further\nincorporate image augmentation and feature augmentation to promote the\ndiversity of augmentation. Moreover, to enhance consistency regularization, we\npropose a dual-branch framework where each branch applies both image\naugmentation and feature augmentation to the input image. We conduct extensive\nexperiments across multiple benchmark datasets, including Pascal VOC 2012,\nCityscapes, and COCO. Results suggest that the proposed method outperforms\nstate-of-the-art algorithms with notably observed accuracy improvement,\nespecially under the circumstance of limited fine annotations.\n","authors":["Dengke Zhang","Quan Tang","Fagui Liu","C. L. Philip Chen","Haiqing Mei"],"pdf_url":"https://arxiv.org/pdf/2503.02459v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.02452v1","updated":"2025-03-04T09:57:24Z","published":"2025-03-04T09:57:24Z","title":"2DGS-Avatar: Animatable High-fidelity Clothed Avatar via 2D Gaussian\n  Splatting","summary":"  Real-time rendering of high-fidelity and animatable avatars from monocular\nvideos remains a challenging problem in computer vision and graphics. Over the\npast few years, the Neural Radiance Field (NeRF) has made significant progress\nin rendering quality but behaves poorly in run-time performance due to the low\nefficiency of volumetric rendering. Recently, methods based on 3D Gaussian\nSplatting (3DGS) have shown great potential in fast training and real-time\nrendering. However, they still suffer from artifacts caused by inaccurate\ngeometry. To address these problems, we propose 2DGS-Avatar, a novel approach\nbased on 2D Gaussian Splatting (2DGS) for modeling animatable clothed avatars\nwith high-fidelity and fast training performance. Given monocular RGB videos as\ninput, our method generates an avatar that can be driven by poses and rendered\nin real-time. Compared to 3DGS-based methods, our 2DGS-Avatar retains the\nadvantages of fast training and rendering while also capturing detailed,\ndynamic, and photo-realistic appearances. We conduct abundant experiments on\npopular datasets such as AvatarRex and THuman4.0, demonstrating impressive\nperformance in both qualitative and quantitative metrics.\n","authors":["Qipeng Yan","Mingyang Sun","Lihua Zhang"],"pdf_url":"https://arxiv.org/pdf/2503.02452v1.pdf","comment":"ICVRV 2024"},{"id":"http://arxiv.org/abs/2409.10095v2","updated":"2025-03-04T09:35:01Z","published":"2024-09-16T08:54:03Z","title":"Human Insights Driven Latent Space for Different Driving Perspectives: A\n  Unified Encoder for Efficient Multi-Task Inference","summary":"  Autonomous driving systems require a comprehensive understanding of the\nenvironment, achieved by extracting visual features essential for perception,\nplanning, and control. However, models trained solely on single-task objectives\nor generic datasets often lack the contextual information needed for robust\nperformance in complex driving scenarios. In this work, we propose a unified\nencoder trained on multiple computer vision tasks crucial for urban driving,\nincluding depth, pose, and 3D scene flow estimation, as well as semantic,\ninstance, panoptic, and motion segmentation. By integrating these diverse\nvisual cues-similar to human perceptual mechanisms-the encoder captures rich\nfeatures that enhance navigation-related predictions. We evaluate the model on\nsteering estimation as a downstream task, leveraging its dense latent space. To\nensure efficient multi-task learning, we introduce a multi-scale feature\nnetwork for pose estimation and apply knowledge distillation from a\nmulti-backbone teacher model. Our findings highlight two key findings: (1) the\nunified encoder achieves competitive performance across all visual perception\ntasks, demonstrating strong generalization capabilities; and (2) for steering\nestimation, the frozen unified encoder-leveraging dense latent\nrepresentations-outperforms both its fine-tuned counterpart and the same frozen\nmodel pretrained on generic datasets like ImageNet. These results underline the\nsignificance of task-specific visual features and demonstrate the promise of\nmulti-task learning in advancing autonomous driving systems. More details and\nthe pretrained model are available at\nhttps://hi-computervision.github.io/uni-encoder/.\n","authors":["Huy-Dung Nguyen","Anass Bairouk","Mirjana Maras","Wei Xiao","Tsun-Hsuan Wang","Patrick Chareyre","Ramin Hasani","Marc Blanchon","Daniela Rus"],"pdf_url":"https://arxiv.org/pdf/2409.10095v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2310.04285v3","updated":"2025-03-04T09:25:47Z","published":"2023-10-06T14:37:22Z","title":"Assessing Robustness via Score-Based Adversarial Image Generation","summary":"  Most adversarial attacks and defenses focus on perturbations within small\n$\\ell_p$-norm constraints. However, $\\ell_p$ threat models cannot capture all\nrelevant semantics-preserving perturbations, and hence, the scope of robustness\nevaluations is limited. In this work, we introduce Score-Based Adversarial\nGeneration (ScoreAG), a novel framework that leverages the advancements in\nscore-based generative models to generate unrestricted adversarial examples\nthat overcome the limitations of $\\ell_p$-norm constraints. Unlike traditional\nmethods, ScoreAG maintains the core semantics of images while generating\nadversarial examples, either by transforming existing images or synthesizing\nnew ones entirely from scratch. We further exploit the generative capability of\nScoreAG to purify images, empirically enhancing the robustness of classifiers.\nOur extensive empirical evaluation demonstrates that ScoreAG improves upon the\nmajority of state-of-the-art attacks and defenses across multiple benchmarks.\nThis work highlights the importance of investigating adversarial examples\nbounded by semantics rather than $\\ell_p$-norm constraints. ScoreAG represents\nan important step towards more encompassing robustness assessments.\n","authors":["Marcel Kollovieh","Lukas Gosch","Marten Lienen","Yan Scholten","Leo Schwinn","Stephan Gnnemann"],"pdf_url":"https://arxiv.org/pdf/2310.04285v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2502.16779v3","updated":"2025-03-04T09:24:06Z","published":"2025-02-24T02:14:19Z","title":"Unposed Sparse Views Room Layout Reconstruction in the Age of Pretrain\n  Model","summary":"  Room layout estimation from multiple-perspective images is poorly\ninvestigated due to the complexities that emerge from multi-view geometry,\nwhich requires muti-step solutions such as camera intrinsic and extrinsic\nestimation, image matching, and triangulation. However, in 3D reconstruction,\nthe advancement of recent 3D foundation models such as DUSt3R has shifted the\nparadigm from the traditional multi-step structure-from-motion process to an\nend-to-end single-step approach. To this end, we introduce Plane-DUSt3R, a\nnovel method for multi-view room layout estimation leveraging the 3D foundation\nmodel DUSt3R. Plane-DUSt3R incorporates the DUSt3R framework and fine-tunes on\na room layout dataset (Structure3D) with a modified objective to estimate\nstructural planes. By generating uniform and parsimonious results, Plane-DUSt3R\nenables room layout estimation with only a single post-processing step and 2D\ndetection results. Unlike previous methods that rely on single-perspective or\npanorama image, Plane-DUSt3R extends the setting to handle multiple-perspective\nimages. Moreover, it offers a streamlined, end-to-end solution that simplifies\nthe process and reduces error accumulation. Experimental results demonstrate\nthat Plane-DUSt3R not only outperforms state-of-the-art methods on the\nsynthetic dataset but also proves robust and effective on in the wild data with\ndifferent image styles such as cartoon. Our code is available at:\nhttps://github.com/justacar/Plane-DUSt3R\n","authors":["Yaxuan Huang","Xili Dai","Jianan Wang","Xianbiao Qi","Yixing Yuan","Xiangyu Yue"],"pdf_url":"https://arxiv.org/pdf/2502.16779v3.pdf","comment":"Accepted by ICLR 2025. Github\n  page:https://github.com/justacar/Plane-DUSt3R"},{"id":"http://arxiv.org/abs/2503.02424v1","updated":"2025-03-04T09:10:32Z","published":"2025-03-04T09:10:32Z","title":"Exploring Intrinsic Normal Prototypes within a Single Image for\n  Universal Anomaly Detection","summary":"  Anomaly detection (AD) is essential for industrial inspection, yet existing\nmethods typically rely on ``comparing'' test images to normal references from a\ntraining set. However, variations in appearance and positioning often\ncomplicate the alignment of these references with the test image, limiting\ndetection accuracy. We observe that most anomalies manifest as local\nvariations, meaning that even within anomalous images, valuable normal\ninformation remains. We argue that this information is useful and may be more\naligned with the anomalies since both the anomalies and the normal information\noriginate from the same image. Therefore, rather than relying on external\nnormality from the training set, we propose INP-Former, a novel method that\nextracts Intrinsic Normal Prototypes (INPs) directly from the test image.\nSpecifically, we introduce the INP Extractor, which linearly combines normal\ntokens to represent INPs. We further propose an INP Coherence Loss to ensure\nINPs can faithfully represent normality for the testing image. These INPs then\nguide the INP-Guided Decoder to reconstruct only normal tokens, with\nreconstruction errors serving as anomaly scores. Additionally, we propose a\nSoft Mining Loss to prioritize hard-to-optimize samples during training.\nINP-Former achieves state-of-the-art performance in single-class, multi-class,\nand few-shot AD tasks across MVTec-AD, VisA, and Real-IAD, positioning it as a\nversatile and universal solution for AD. Remarkably, INP-Former also\ndemonstrates some zero-shot AD capability. Code is available\nat:https://github.com/luow23/INP-Former.\n","authors":["Wei Luo","Yunkang Cao","Haiming Yao","Xiaotian Zhang","Jianan Lou","Yuqi Cheng","Weiming Shen","Wenyong Yu"],"pdf_url":"https://arxiv.org/pdf/2503.02424v1.pdf","comment":"Accepted by CVPR2025"},{"id":"http://arxiv.org/abs/2503.02420v1","updated":"2025-03-04T09:05:01Z","published":"2025-03-04T09:05:01Z","title":"Exploring Model Quantization in GenAI-based Image Inpainting and\n  Detection of Arable Plants","summary":"  Deep learning-based weed control systems often suffer from limited training\ndata diversity and constrained on-board computation, impacting their real-world\nperformance. To overcome these challenges, we propose a framework that\nleverages Stable Diffusion-based inpainting to augment training data\nprogressively in 10% increments -- up to an additional 200%, thus enhancing\nboth the volume and diversity of samples. Our approach is evaluated on two\nstate-of-the-art object detection models, YOLO11(l) and RT-DETR(l), using the\nmAP50 metric to assess detection performance. We explore quantization\nstrategies (FP16 and INT8) for both the generative inpainting and detection\nmodels to strike a balance between inference speed and accuracy. Deployment of\nthe downstream models on the Jetson Orin Nano demonstrates the practical\nviability of our framework in resource-constrained environments, ultimately\nimproving detection accuracy and computational efficiency in intelligent weed\nmanagement systems.\n","authors":["Sourav Modak","Ahmet Ouz Saltk","Anthony Stein"],"pdf_url":"https://arxiv.org/pdf/2503.02420v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.02414v1","updated":"2025-03-04T08:58:30Z","published":"2025-03-04T08:58:30Z","title":"InfoGNN: End-to-end deep learning on mesh via graph neural networks","summary":"  3D models are widely used in various industries, and mesh data has become an\nindispensable part of 3D modeling because of its unique advantages. Mesh data\ncan provide an intuitive and practical expression of rich 3D information.\nHowever, its disordered, irregular data structure and complex surface\ninformation make it challenging to apply with deep learning models directly.\nTraditional mesh data processing methods often rely on mesh models with many\nlimitations, such as manifold, which restrict their application scopes in\nreality and do not fully utilize the advantages of mesh models. This paper\nproposes a novel end-to-end framework for addressing the challenges associated\nwith deep learning in mesh models centered around graph neural networks (GNN)\nand is titled InfoGNN. InfoGNN treats the mesh model as a graph, which enables\nit to handle irregular mesh data efficiently. Moreover, we propose InfoConv and\nInfoMP modules, which utilize the position information of the points and fully\nuse the static information such as face normals, dihedral angles, and dynamic\nglobal feature information to fully use all kinds of data. In addition, InfoGNN\nis an end-to-end framework, and we simplify the network design to make it more\nefficient, paving the way for efficient deep learning of complex 3D models. We\nconducted experiments on several publicly available datasets, and the results\nshow that InfoGNN achieves excellent performance in mesh classification and\nsegmentation tasks.\n","authors":["Ling Gao","Zhenyu Shu","Shiqing Xin"],"pdf_url":"https://arxiv.org/pdf/2503.02414v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.02410v1","updated":"2025-03-04T08:51:44Z","published":"2025-03-04T08:51:44Z","title":"Building 3D In-Context Learning Universal Model in Neuroimaging","summary":"  In-context learning (ICL), a type of universal model, demonstrates\nexceptional generalization across a wide range of tasks without retraining by\nleveraging task-specific guidance from context, making it particularly\neffective for the complex demands of neuroimaging. However, existing ICL\nmodels, which take 2D images as input, struggle to fully leverage the 3D\nanatomical structures in neuroimages, leading to a lack of global awareness and\nsuboptimal performance. In this regard, we introduce Neuroverse3D, an ICL model\ncapable of performing multiple neuroimaging tasks (e.g., segmentation,\ndenoising, inpainting) in 3D. Neuroverse3D overcomes the large memory\nconsumption due to 3D inputs through adaptive parallel-sequential context\nprocessing and a U-shape fusion strategy, allowing it to handle an unlimited\nnumber of context images. Additionally, we propose an optimized loss to balance\nmulti-task training and enhance the focus on anatomical structures. Our study\nincorporates 43,674 3D scans from 19 neuroimaging datasets and evaluates\nNeuroverse3D on 14 diverse tasks using held-out test sets. The results\ndemonstrate that Neuroverse3D significantly outperforms existing ICL models and\nclosely matches the performance of task-specific models. The code and model\nweights are publicly released at: https://github.com/jiesihu/Neu3D.\n","authors":["Jiesi Hu","Hanyang Peng","Yanwu Yang","Xutao Guo","Yang Shang","Pengcheng Shi","Chenfei Ye","Ting Ma"],"pdf_url":"https://arxiv.org/pdf/2503.02410v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.00897v2","updated":"2025-03-04T08:46:27Z","published":"2025-03-02T13:43:53Z","title":"A Simple and Effective Reinforcement Learning Method for Text-to-Image\n  Diffusion Fine-tuning","summary":"  Reinforcement learning ( RL)-based fine-tuning has emerged as a powerful\napproach for aligning diffusion models with black-box objectives. Proximal\npolicy optimization (PPO) is the most popular choice of method for policy\noptimization. While effective in terms of performance, PPO is highly sensitive\nto hyper-parameters and involves substantial computational overhead. REINFORCE,\non the other hand, mitigates some computational complexities such as high\nmemory overhead and sensitive hyper-parameter tuning, but has suboptimal\nperformance due to high-variance and sample inefficiency. While the variance of\nthe REINFORCE can be reduced by sampling multiple actions per input prompt and\nusing a baseline correction term, it still suffers from sample inefficiency. To\naddress these challenges, we systematically analyze the\nefficiency-effectiveness trade-off between REINFORCE and PPO, and propose\nleave-one-out PPO ( LOOP), a novel RL for diffusion fine-tuning method. LOOP\ncombines variance reduction techniques from REINFORCE, such as sampling\nmultiple actions per input prompt and a baseline correction term, with the\nrobustness and sample efficiency of PPO via clipping and importance sampling.\nOur results demonstrate that LOOP effectively improves diffusion models on\nvarious black-box objectives, and achieves a better balance between\ncomputational efficiency and performance.\n","authors":["Shashank Gupta","Chaitanya Ahuja","Tsung-Yu Lin","Sreya Dutta Roy","Harrie Oosterhuis","Maarten de Rijke","Satya Narayan Shukla"],"pdf_url":"https://arxiv.org/pdf/2503.00897v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.02399v1","updated":"2025-03-04T08:41:45Z","published":"2025-03-04T08:41:45Z","title":"VisAgent: Narrative-Preserving Story Visualization Framework","summary":"  Story visualization is the transformation of narrative elements into image\nsequences. While existing research has primarily focused on visual contextual\ncoherence, the deeper narrative essence of stories often remains overlooked.\nThis limitation hinders the practical application of these approaches, as\ngenerated images frequently fail to capture the intended meaning and nuances of\nthe narrative fully. To address these challenges, we propose VisAgent, a\ntraining-free multi-agent framework designed to comprehend and visualize\npivotal scenes within a given story. By considering story distillation,\nsemantic consistency, and contextual coherence, VisAgent employs an agentic\nworkflow. In this workflow, multiple specialized agents collaborate to: (i)\nrefine layered prompts based on the narrative structure and (ii) seamlessly\nintegrate \\gt{generated} elements, including refined prompts, scene elements,\nand subject placement, into the final image. The empirically validated\neffectiveness confirms the framework's suitability for practical story\nvisualization applications.\n","authors":["Seungkwon Kim","GyuTae Park","Sangyeon Kim","Seung-Hun Nam"],"pdf_url":"https://arxiv.org/pdf/2503.02399v1.pdf","comment":"Accepted to ICASSP 2025. Equal contribution from first two authors"},{"id":"http://arxiv.org/abs/2502.18041v3","updated":"2025-03-04T08:38:58Z","published":"2025-02-25T09:57:18Z","title":"OpenFly: A Versatile Toolchain and Large-scale Benchmark for Aerial\n  Vision-Language Navigation","summary":"  Vision-Language Navigation (VLN) aims to guide agents through an environment\nby leveraging both language instructions and visual cues, playing a pivotal\nrole in embodied AI. Indoor VLN has been extensively studied, whereas outdoor\naerial VLN remains underexplored. The potential reason is that outdoor aerial\nview encompasses vast areas, making data collection more challenging, which\nresults in a lack of benchmarks. To address this problem, we propose OpenFly, a\nplatform comprising a versatile toolchain and large-scale benchmark for aerial\nVLN. Firstly, we develop a highly automated toolchain for data collection,\nenabling automatic point cloud acquisition, scene semantic segmentation, flight\ntrajectory creation, and instruction generation. Secondly, based on the\ntoolchain, we construct a large-scale aerial VLN dataset with 100k\ntrajectories, covering diverse heights and lengths across 18 scenes. The\ncorresponding visual data are generated using various rendering engines and\nadvanced techniques, including Unreal Engine, GTA V, Google Earth, and 3D\nGaussian Splatting (3D GS). All data exhibit high visual quality. Particularly,\n3D GS supports real-to-sim rendering, further enhancing the realism of the\ndataset. Thirdly, we propose OpenFly-Agent, a keyframe-aware VLN model, which\ntakes language instructions, current observations, and historical keyframes as\ninput, and outputs flight actions directly. Extensive analyses and experiments\nare conducted, showcasing the superiority of our OpenFly platform and\nOpenFly-Agent. The toolchain, dataset, and codes will be open-sourced.\n","authors":["Yunpeng Gao","Chenhui Li","Zhongrui You","Junli Liu","Zhen Li","Pengan Chen","Qizhi Chen","Zhonghan Tang","Liansheng Wang","Penghui Yang","Yiwen Tang","Yuhang Tang","Shuai Liang","Songyi Zhu","Ziqin Xiong","Yifei Su","Xinyi Ye","Jianan Li","Yan Ding","Dong Wang","Zhigang Wang","Bin Zhao","Xuelong Li"],"pdf_url":"https://arxiv.org/pdf/2502.18041v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2405.04309v3","updated":"2025-03-04T08:37:43Z","published":"2024-05-07T13:33:50Z","title":"Non-rigid Structure-from-Motion: Temporally-smooth Procrustean Alignment\n  and Spatially-variant Deformation Modeling","summary":"  Even though Non-rigid Structure-from-Motion (NRSfM) has been extensively\nstudied and great progress has been made, there are still key challenges that\nhinder their broad real-world applications: 1) the inherent motion/rotation\nambiguity requires either explicit camera motion recovery with extra constraint\nor complex Procrustean Alignment; 2) existing low-rank modeling of the global\nshape can over-penalize drastic deformations in the 3D shape sequence. This\npaper proposes to resolve the above issues from a spatial-temporal modeling\nperspective. First, we propose a novel Temporally-smooth Procrustean Alignment\nmodule that estimates 3D deforming shapes and adjusts the camera motion by\naligning the 3D shape sequence consecutively. Our new alignment module remedies\nthe requirement of complex reference 3D shape during alignment, which is more\nconductive to non-isotropic deformation modeling. Second, we propose a\nspatial-weighted approach to enforce the low-rank constraint adaptively at\ndifferent locations to accommodate drastic spatially-variant deformation\nreconstruction better. Our modeling outperform existing low-rank based methods,\nand extensive experiments across different datasets validate the effectiveness\nof our method.\n","authors":["Jiawei Shi","Hui Deng","Yuchao Dai"],"pdf_url":"https://arxiv.org/pdf/2405.04309v3.pdf","comment":"Accepted by CVPR 2024; The new version adds additional experiments\n  and corrects typos"},{"id":"http://arxiv.org/abs/2503.02394v1","updated":"2025-03-04T08:35:01Z","published":"2025-03-04T08:35:01Z","title":"BHViT: Binarized Hybrid Vision Transformer","summary":"  Model binarization has made significant progress in enabling real-time and\nenergy-efficient computation for convolutional neural networks (CNN), offering\na potential solution to the deployment challenges faced by Vision Transformers\n(ViTs) on edge devices. However, due to the structural differences between CNN\nand Transformer architectures, simply applying binary CNN strategies to the ViT\nmodels will lead to a significant performance drop. To tackle this challenge,\nwe propose BHViT, a binarization-friendly hybrid ViT architecture and its full\nbinarization model with the guidance of three important observations.\nInitially, BHViT utilizes the local information interaction and hierarchical\nfeature aggregation technique from coarse to fine levels to address redundant\ncomputations stemming from excessive tokens. Then, a novel module based on\nshift operations is proposed to enhance the performance of the binary\nMultilayer Perceptron (MLP) module without significantly increasing\ncomputational overhead. In addition, an innovative attention matrix\nbinarization method based on quantization decomposition is proposed to evaluate\nthe token's importance in the binarized attention matrix. Finally, we propose a\nregularization loss to address the inadequate optimization caused by the\nincompatibility between the weight oscillation in the binary layers and the\nAdam Optimizer. Extensive experimental results demonstrate that our proposed\nalgorithm achieves SOTA performance among binary ViT methods.\n","authors":["Tian Gao","Yu Zhang","Zhiyuan Zhang","Huajun Liu","Kaijie Yin","Chengzhong Xu","Hui Kong"],"pdf_url":"https://arxiv.org/pdf/2503.02394v1.pdf","comment":"Accepted by CVPR2025"},{"id":"http://arxiv.org/abs/2503.02393v1","updated":"2025-03-04T08:31:12Z","published":"2025-03-04T08:31:12Z","title":"Vision-Language Model IP Protection via Prompt-based Learning","summary":"  Vision-language models (VLMs) like CLIP (Contrastive Language-Image\nPre-Training) have seen remarkable success in visual recognition, highlighting\nthe increasing need to safeguard the intellectual property (IP) of well-trained\nmodels. Effective IP protection extends beyond ensuring authorized usage; it\nalso necessitates restricting model deployment to authorized data domains,\nparticularly when the model is fine-tuned for specific target domains. However,\ncurrent IP protection methods often rely solely on the visual backbone, which\nmay lack sufficient semantic richness. To bridge this gap, we introduce\nIP-CLIP, a lightweight IP protection strategy tailored to CLIP, employing a\nprompt-based learning approach. By leveraging the frozen visual backbone of\nCLIP, we extract both image style and content information, incorporating them\ninto the learning of IP prompt. This strategy acts as a robust barrier,\neffectively preventing the unauthorized transfer of features from authorized\ndomains to unauthorized ones. Additionally, we propose a style-enhancement\nbranch that constructs feature banks for both authorized and unauthorized\ndomains. This branch integrates self-enhanced and cross-domain features,\nfurther strengthening IP-CLIP's capability to block features from unauthorized\ndomains. Finally, we present new three metrics designed to better balance the\nperformance degradation of authorized and unauthorized domains. Comprehensive\nexperiments in various scenarios demonstrate its promising potential for\napplication in IP protection tasks for VLMs.\n","authors":["Lianyu Wang","Meng Wang","Huazhu Fu","Daoqiang Zhang"],"pdf_url":"https://arxiv.org/pdf/2503.02393v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.16958v2","updated":"2025-03-04T08:29:23Z","published":"2024-03-25T17:17:45Z","title":"TwinLiteNetPlus: A Stronger Model for Real-time Drivable Area and Lane\n  Segmentation","summary":"  Semantic segmentation is crucial for autonomous driving, particularly for\nDrivable Area and Lane Segmentation, ensuring safety and navigation. To address\nthe high computational costs of current state-of-the-art (SOTA) models, this\npaper introduces TwinLiteNetPlus (TwinLiteNet$^+$), a model adept at balancing\nefficiency and accuracy. TwinLiteNet$^+$ incorporates standard and depth-wise\nseparable dilated convolutions, reducing complexity while maintaining high\naccuracy. It is available in four configurations, from the robust 1.94\nmillion-parameter TwinLiteNet$^+_{\\text{Large}}$ to the ultra-compact\n34K-parameter TwinLiteNet$^+_{\\text{Nano}}$. Notably,\nTwinLiteNet$^+_{\\text{Large}}$ attains a 92.9\\% mIoU for Drivable Area\nSegmentation and a 34.2\\% IoU for Lane Segmentation. These results notably\noutperform those of current SOTA models while requiring a computational cost\nthat is approximately 11 times lower in terms of Floating Point Operations\n(FLOPs) compared to the existing SOTA model. Extensively tested on various\nembedded devices, TwinLiteNet$^+$ demonstrates promising latency and power\nefficiency, underscoring its suitability for real-world autonomous vehicle\napplications.\n","authors":["Quang-Huy Che","Duc-Tri Le","Minh-Quan Pham","Vinh-Tiep Nguyen","Duc-Khai Lam"],"pdf_url":"https://arxiv.org/pdf/2403.16958v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.00200v2","updated":"2025-03-04T08:26:29Z","published":"2025-02-28T21:38:17Z","title":"Unified Video Action Model","summary":"  A unified video and action model holds significant promise for robotics,\nwhere videos provide rich scene information for action prediction, and actions\nprovide dynamics information for video prediction. However, effectively\ncombining video generation and action prediction remains challenging, and\ncurrent video generation-based methods struggle to match the performance of\ndirect policy learning in action accuracy and inference speed. To bridge this\ngap, we introduce the Unified Video Action model (UVA), which jointly optimizes\nvideo and action predictions to achieve both high accuracy and efficient action\ninference. The key lies in learning a joint video-action latent representation\nand decoupling video-action decoding. The joint latent representation bridges\nthe visual and action domains, effectively modeling the relationship between\nvideo and action sequences. Meanwhile, the decoupled decoding, powered by two\nlightweight diffusion heads, enables high-speed action inference by bypassing\nvideo generation during inference. Such a unified framework further enables\nversatile functionality through masked input training. By selectively masking\nactions or videos, a single model can tackle diverse tasks beyond policy\nlearning, such as forward and inverse dynamics modeling and video generation.\nVia an extensive set of experiments, we demonstrate that UVA can serve as a\ngeneral-purpose solution for a wide range of robotics tasks, such as policy\nlearning, forward/inverse dynamics and video observation prediction, without\ncompromising performance compared to methods tailored for specific\napplications. Results are best viewed on\nhttps://unified-video-action-model.github.io/.\n","authors":["Shuang Li","Yihuai Gao","Dorsa Sadigh","Shuran Song"],"pdf_url":"https://arxiv.org/pdf/2503.00200v2.pdf","comment":"Project website: https://unified-video-action-model.github.io/"},{"id":"http://arxiv.org/abs/2503.02388v1","updated":"2025-03-04T08:24:08Z","published":"2025-03-04T08:24:08Z","title":"PIDLoc: Cross-View Pose Optimization Network Inspired by PID Controllers","summary":"  Accurate localization is essential for autonomous driving, but GNSS-based\nmethods struggle in challenging environments such as urban canyons. Cross-view\npose optimization offers an effective solution by directly estimating vehicle\npose using satellite-view images. However, existing methods primarily rely on\ncross-view features at a given pose, neglecting fine-grained contexts for\nprecision and global contexts for robustness against large initial pose errors.\nTo overcome these limitations, we propose PIDLoc, a novel cross-view pose\noptimization approach inspired by the proportional-integral-derivative (PID)\ncontroller. Using RGB images and LiDAR, the PIDLoc comprises the PID branches\nto model cross-view feature relationships and the spatially aware pose\nestimator (SPE) to estimate the pose from these relationships. The PID branches\nleverage feature differences for local context (P), aggregated feature\ndifferences for global context (I), and gradients of feature differences for\nprecise pose adjustment (D) to enhance localization accuracy under large\ninitial pose errors. Integrated with the PID branches, the SPE captures spatial\nrelationships within the PID-branch features for consistent localization.\nExperimental results demonstrate that the PIDLoc achieves state-of-the-art\nperformance in cross-view pose estimation for the KITTI dataset, reducing\nposition error by $37.8\\%$ compared with the previous state-of-the-art.\n","authors":["Wooju Lee","Juhye Park","Dasol Hong","Changki Sung","Youngwoo Seo","Dongwan Kang","Hyun Myung"],"pdf_url":"https://arxiv.org/pdf/2503.02388v1.pdf","comment":"Accepted by CVPR-25"},{"id":"http://arxiv.org/abs/2503.02379v1","updated":"2025-03-04T08:14:51Z","published":"2025-03-04T08:14:51Z","title":"Teaching Metric Distance to Autoregressive Multimodal Foundational\n  Models","summary":"  As large language models expand beyond natural language to domains such as\nmathematics, multimodal understanding, and embodied agents, tokens increasingly\nreflect metric relationships rather than purely linguistic meaning. We\nintroduce DIST2Loss, a distance-aware framework designed to train\nautoregressive discrete models by leveraging predefined distance relationships\namong output tokens. At its core, DIST2Loss transforms continuous exponential\nfamily distributions derived from inherent distance metrics into discrete,\ncategorical optimization targets compatible with the models' architectures.\nThis approach enables the models to learn and preserve meaningful distance\nrelationships during token generation while maintaining compatibility with\nexisting architectures. Empirical evaluations show consistent performance gains\nin diverse multimodal applications, including visual grounding, robotic\nmanipulation, generative reward modeling, and image generation using\nvector-quantized features. These improvements are pronounced in cases of\nlimited training data, highlighting DIST2Loss's effectiveness in\nresource-constrained settings.\n","authors":["Jiwan Chung","Saejin Kim","Yongrae Jo","Jaewoo Park","Dongjun Min","Youngjae Yu"],"pdf_url":"https://arxiv.org/pdf/2503.02379v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.02375v1","updated":"2025-03-04T08:03:53Z","published":"2025-03-04T08:03:53Z","title":"mmDEAR: mmWave Point Cloud Density Enhancement for Accurate Human Body\n  Reconstruction","summary":"  Millimeter-wave (mmWave) radar offers robust sensing capabilities in diverse\nenvironments, making it a highly promising solution for human body\nreconstruction due to its privacy-friendly and non-intrusive nature. However,\nthe significant sparsity of mmWave point clouds limits the estimation accuracy.\nTo overcome this challenge, we propose a two-stage deep learning framework that\nenhances mmWave point clouds and improves human body reconstruction accuracy.\nOur method includes a mmWave point cloud enhancement module that densifies the\nraw data by leveraging temporal features and a multi-stage completion network,\nfollowed by a 2D-3D fusion module that extracts both 2D and 3D motion features\nto refine SMPL parameters. The mmWave point cloud enhancement module learns the\ndetailed shape and posture information from 2D human masks in single-view\nimages. However, image-based supervision is involved only during the training\nphase, and the inference relies solely on sparse point clouds to maintain\nprivacy. Experiments on multiple datasets demonstrate that our approach\noutperforms state-of-the-art methods, with the enhanced point clouds further\nimproving performance when integrated into existing models.\n","authors":["Jiarui Yang","Songpengcheng Xia","Zengyuan Lai","Lan Sun","Qi Wu","Wenxian Yu","Ling Pei"],"pdf_url":"https://arxiv.org/pdf/2503.02375v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.02372v1","updated":"2025-03-04T07:58:15Z","published":"2025-03-04T07:58:15Z","title":"Label-Efficient LiDAR Panoptic Segmentation","summary":"  A main bottleneck of learning-based robotic scene understanding methods is\nthe heavy reliance on extensive annotated training data, which often limits\ntheir generalization ability. In LiDAR panoptic segmentation, this challenge\nbecomes even more pronounced due to the need to simultaneously address both\nsemantic and instance segmentation from complex, high-dimensional point cloud\ndata. In this work, we address the challenge of LiDAR panoptic segmentation\nwith very few labeled samples by leveraging recent advances in label-efficient\nvision panoptic segmentation. To this end, we propose a novel method,\nLimited-Label LiDAR Panoptic Segmentation (L3PS), which requires only a minimal\namount of labeled data. Our approach first utilizes a label-efficient 2D\nnetwork to generate panoptic pseudo-labels from a small set of annotated\nimages, which are subsequently projected onto point clouds. We then introduce a\nnovel 3D refinement module that capitalizes on the geometric properties of\npoint clouds. By incorporating clustering techniques, sequential scan\naccumulation, and ground point separation, this module significantly enhances\nthe accuracy of the pseudo-labels, improving segmentation quality by up to\n+10.6 PQ and +7.9 mIoU. We demonstrate that these refined pseudo-labels can be\nused to effectively train off-the-shelf LiDAR segmentation networks. Through\nextensive experiments, we show that L3PS not only outperforms existing methods\nbut also substantially reduces the annotation burden. We release the code of\nour work at https://l3ps.cs.uni-freiburg.de.\n","authors":["Ahmet Selim anak","Niclas Vdisch","Krsat Petek","Wolfram Burgard","Abhinav Valada"],"pdf_url":"https://arxiv.org/pdf/2503.02372v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2412.01550v2","updated":"2025-03-04T07:37:01Z","published":"2024-12-02T14:37:57Z","title":"SeqAfford: Sequential 3D Affordance Reasoning via Multimodal Large\n  Language Model","summary":"  3D affordance segmentation aims to link human instructions to touchable\nregions of 3D objects for embodied manipulations. Existing efforts typically\nadhere to single-object, single-affordance paradigms, where each affordance\ntype or explicit instruction strictly corresponds to a specific affordance\nregion and are unable to handle long-horizon tasks. Such a paradigm cannot\nactively reason about complex user intentions that often imply sequential\naffordances. In this paper, we introduce the Sequential 3D Affordance Reasoning\ntask, which extends the traditional paradigm by reasoning from cumbersome user\nintentions and then decomposing them into a series of segmentation maps. Toward\nthis, we construct the first instruction-based affordance segmentation\nbenchmark that includes reasoning over both single and sequential affordances,\ncomprising 180K instruction-point cloud pairs. Based on the benchmark, we\npropose our model, SeqAfford, to unlock the 3D multi-modal large language model\nwith additional affordance segmentation abilities, which ensures reasoning with\nworld knowledge and fine-grained affordance grounding in a cohesive framework.\nWe further introduce a multi-granular language-point integration module to\nendow 3D dense prediction. Extensive experimental evaluations show that our\nmodel excels over well-established methods and exhibits open-world\ngeneralization with sequential reasoning abilities.\n","authors":["Chunlin Yu","Hanqing Wang","Ye Shi","Haoyang Luo","Sibei Yang","Jingyi Yu","Jingya Wang"],"pdf_url":"https://arxiv.org/pdf/2412.01550v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.02360v1","updated":"2025-03-04T07:34:06Z","published":"2025-03-04T07:34:06Z","title":"BdSLW401: Transformer-Based Word-Level Bangla Sign Language Recognition\n  Using Relative Quantization Encoding (RQE)","summary":"  Sign language recognition (SLR) for low-resource languages like Bangla\nsuffers from signer variability, viewpoint variations, and limited annotated\ndatasets. In this paper, we present BdSLW401, a large-scale, multi-view,\nword-level Bangla Sign Language (BdSL) dataset with 401 signs and 102,176 video\nsamples from 18 signers in front and lateral views. To improve\ntransformer-based SLR, we introduce Relative Quantization Encoding (RQE), a\nstructured embedding approach anchoring landmarks to physiological reference\npoints and quantize motion trajectories. RQE improves attention allocation by\ndecreasing spatial variability, resulting in 44.3% WER reduction in WLASL100,\n21.0% in SignBD-200, and significant gains in BdSLW60 and SignBD-90. However,\nfixed quantization becomes insufficient on large-scale datasets (e.g.,\nWLASL2000), indicating the need for adaptive encoding strategies. Further,\nRQE-SF, an extended variant that stabilizes shoulder landmarks, achieves\nimprovements in pose consistency at the cost of small trade-offs in lateral\nview recognition. The attention graphs prove that RQE improves model\ninterpretability by focusing on the major articulatory features (fingers,\nwrists) and the more distinctive frames instead of global pose changes.\nIntroducing BdSLW401 and demonstrating the effectiveness of RQE-enhanced\nstructured embeddings, this work advances transformer-based SLR for\nlow-resource languages and sets a benchmark for future research in this area.\n","authors":["Husne Ara Rubaiyeat","Njayou Youssouf","Md Kamrul Hasan","Hasan Mahmud"],"pdf_url":"https://arxiv.org/pdf/2503.02360v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2501.05874v2","updated":"2025-03-04T07:29:52Z","published":"2025-01-10T11:17:15Z","title":"VideoRAG: Retrieval-Augmented Generation over Video Corpus","summary":"  Retrieval-Augmented Generation (RAG) is a powerful strategy for improving the\nfactual accuracy of models by retrieving external knowledge relevant to queries\nand incorporating it into the generation process. However, existing approaches\nprimarily focus on text, with some recent advancements considering images, and\nthey largely overlook videos, a rich source of multimodal knowledge capable of\nrepresenting contextual details more effectively than any other modality. While\nvery recent studies explore the use of videos in response generation, they\neither predefine query-associated videos without retrieval or convert videos\ninto textual descriptions losing multimodal richness. To tackle these, we\nintroduce VideoRAG, a framework that not only dynamically retrieves videos\nbased on their relevance with queries but also utilizes both visual and textual\ninformation. The operation of VideoRAG is powered by recent Large Video\nLanguage Models (LVLMs), which enable the direct processing of video content to\nrepresent it for retrieval and the seamless integration of retrieved videos\njointly with queries for response generation. Also, inspired by that the\ncontext size of LVLMs may not be sufficient to process all frames in extremely\nlong videos and not all frames are equally important, we introduce a video\nframe selection mechanism to extract the most informative subset of frames,\nalong with a strategy to extract textual information from videos (as it can aid\nthe understanding of video content) when their subtitles are not available. We\nexperimentally validate the effectiveness of VideoRAG, showcasing that it is\nsuperior to relevant baselines. Code is available at\nhttps://github.com/starsuzi/VideoRAG.\n","authors":["Soyeong Jeong","Kangsan Kim","Jinheon Baek","Sung Ju Hwang"],"pdf_url":"https://arxiv.org/pdf/2501.05874v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.02358v1","updated":"2025-03-04T07:29:03Z","published":"2025-03-04T07:29:03Z","title":"Are Large Vision Language Models Good Game Players?","summary":"  Large Vision Language Models (LVLMs) have demonstrated remarkable abilities\nin understanding and reasoning about both visual and textual information.\nHowever, existing evaluation methods for LVLMs, primarily based on benchmarks\nlike Visual Question Answering and image captioning, often fail to capture the\nfull scope of LVLMs' capabilities. These benchmarks are limited by issues such\nas inadequate assessment of detailed visual perception, data contamination, and\na lack of focus on multi-turn reasoning. To address these challenges, we\npropose \\method{}, a game-based evaluation framework designed to provide a\ncomprehensive assessment of LVLMs' cognitive and reasoning skills in structured\nenvironments. \\method{} uses a set of games to evaluate LVLMs on four core\ntasks: Perceiving, Question Answering, Rule Following, and End-to-End Playing,\nwith each target task designed to assess specific abilities, including visual\nperception, reasoning, decision-making, etc. Based on this framework, we\nconduct extensive experiments that explore the limitations of current LVLMs,\nsuch as handling long structured outputs and perceiving detailed and dense\nelements. Code and data are publicly available at\nhttps://github.com/xinke-wang/LVLM-Playground.\n","authors":["Xinyu Wang","Bohan Zhuang","Qi Wu"],"pdf_url":"https://arxiv.org/pdf/2503.02358v1.pdf","comment":"ICLR2025"},{"id":"http://arxiv.org/abs/2503.02357v1","updated":"2025-03-04T07:28:45Z","published":"2025-03-04T07:28:45Z","title":"Q-Eval-100K: Evaluating Visual Quality and Alignment Level for\n  Text-to-Vision Content","summary":"  Evaluating text-to-vision content hinges on two crucial aspects: visual\nquality and alignment. While significant progress has been made in developing\nobjective models to assess these dimensions, the performance of such models\nheavily relies on the scale and quality of human annotations. According to\nScaling Law, increasing the number of human-labeled instances follows a\npredictable pattern that enhances the performance of evaluation models.\nTherefore, we introduce a comprehensive dataset designed to Evaluate Visual\nquality and Alignment Level for text-to-vision content (Q-EVAL-100K), featuring\nthe largest collection of human-labeled Mean Opinion Scores (MOS) for the\nmentioned two aspects. The Q-EVAL-100K dataset encompasses both text-to-image\nand text-to-video models, with 960K human annotations specifically focused on\nvisual quality and alignment for 100K instances (60K images and 40K videos).\nLeveraging this dataset with context prompt, we propose Q-Eval-Score, a unified\nmodel capable of evaluating both visual quality and alignment with special\nimprovements for handling long-text prompt alignment. Experimental results\nindicate that the proposed Q-Eval-Score achieves superior performance on both\nvisual quality and alignment, with strong generalization capabilities across\nother benchmarks. These findings highlight the significant value of the\nQ-EVAL-100K dataset. Data and codes will be available at\nhttps://github.com/zzc-1998/Q-Eval.\n","authors":["Zicheng Zhang","Tengchuan Kou","Shushi Wang","Chunyi Li","Wei Sun","Wei Wang","Xiaoyu Li","Zongyu Wang","Xuezhi Cao","Xiongkuo Min","Xiaohong Liu","Guangtao Zhai"],"pdf_url":"https://arxiv.org/pdf/2503.02357v1.pdf","comment":"Accepted to CVPR 2025"},{"id":"http://arxiv.org/abs/2411.19320v2","updated":"2025-03-04T07:19:38Z","published":"2024-11-28T18:51:55Z","title":"Generalized Gaussian Model for Learned Image Compression","summary":"  In learned image compression, probabilistic models play an essential role in\ncharacterizing the distribution of latent variables. The Gaussian model with\nmean and scale parameters has been widely used for its simplicity and\neffectiveness. Probabilistic models with more parameters, such as the Gaussian\nmixture models, can fit the distribution of latent variables more precisely,\nbut the corresponding complexity is higher. To balance the compression\nperformance and complexity, we extend the Gaussian model to the generalized\nGaussian family for more flexible latent distribution modeling, introducing\nonly one additional shape parameter beta than the Gaussian model. To enhance\nthe performance of the generalized Gaussian model by alleviating the train-test\nmismatch, we propose improved training methods, including beta-dependent lower\nbounds for scale parameters and gradient rectification. Our proposed\ngeneralized Gaussian model, coupled with the improved training methods, is\ndemonstrated to outperform the Gaussian and Gaussian mixture models on a\nvariety of learned image compression networks.\n","authors":["Haotian Zhang","Li Li","Dong Liu"],"pdf_url":"https://arxiv.org/pdf/2411.19320v2.pdf","comment":"19 pages, 16 figures"},{"id":"http://arxiv.org/abs/2503.02348v1","updated":"2025-03-04T07:17:02Z","published":"2025-03-04T07:17:02Z","title":"YOLO-PRO: Enhancing Instance-Specific Object Detection with Full-Channel\n  Global Self-Attention","summary":"  This paper addresses the inherent limitations of conventional bottleneck\nstructures (diminished instance discriminability due to overemphasis on batch\nstatistics) and decoupled heads (computational redundancy) in object detection\nframeworks by proposing two novel modules: the Instance-Specific Bottleneck\nwith full-channel global self-attention (ISB) and the Instance-Specific\nAsymmetric Decoupled Head (ISADH). The ISB module innovatively reconstructs\nfeature maps to establish an efficient full-channel global attention mechanism\nthrough synergistic fusion of batch-statistical and instance-specific features.\nComplementing this, the ISADH module pioneers an asymmetric decoupled\narchitecture enabling hierarchical multi-dimensional feature integration via\ndual-stream batch-instance representation fusion. Extensive experiments on the\nMS-COCO benchmark demonstrate that the coordinated deployment of ISB and ISADH\nin the YOLO-PRO framework achieves state-of-the-art performance across all\ncomputational scales. Specifically, YOLO-PRO surpasses YOLOv8 by 1.0-1.6% AP\n(N/S/M/L/X scales) and outperforms YOLO11 by 0.1-0.5% AP in critical M/L/X\ngroups, while maintaining competitive computational efficiency. This work\nprovides practical insights for developing high-precision detectors deployable\non edge devices.\n","authors":["Lin Huang","Yujuan Tan","Weisheng Li","Shitai Shan","Linlin Shen","Jing Yu"],"pdf_url":"https://arxiv.org/pdf/2503.02348v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2502.04740v2","updated":"2025-03-04T07:09:19Z","published":"2025-02-07T08:15:31Z","title":"SelaFD:Seamless Adaptation of Vision Transformer Fine-tuning for\n  Radar-based Human Activity Recognition","summary":"  Human Activity Recognition (HAR) such as fall detection has become\nincreasingly critical due to the aging population, necessitating effective\nmonitoring systems to prevent serious injuries and fatalities associated with\nfalls. This study focuses on fine-tuning the Vision Transformer (ViT) model\nspecifically for HAR using radar-based Time-Doppler signatures. Unlike\ntraditional image datasets, these signals present unique challenges due to\ntheir non-visual nature and the high degree of similarity among various\nactivities. Directly fine-tuning the ViT with all parameters proves suboptimal\nfor this application. To address this challenge, we propose a novel approach\nthat employs Low-Rank Adaptation (LoRA) fine-tuning in the weight space to\nfacilitate knowledge transfer from pre-trained ViT models. Additionally, to\nextract fine-grained features, we enhance feature representation through the\nintegration of a serial-parallel adapter in the feature space. Our innovative\njoint fine-tuning method, tailored for radar-based Time-Doppler signatures,\nsignificantly improves HAR accuracy, surpassing existing state-of-the-art\nmethodologies in this domain. Our code is released at\nhttps://github.com/wangyijunlyy/SelaFD.\n","authors":["Yijun Wang","Yong Wang","Chendong xu","Shuai Yao","Qisong Wu"],"pdf_url":"https://arxiv.org/pdf/2502.04740v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.02345v1","updated":"2025-03-04T07:08:47Z","published":"2025-03-04T07:08:47Z","title":"CQ CNN: A Hybrid Classical Quantum Convolutional Neural Network for\n  Alzheimer's Disease Detection Using Diffusion Generated and U Net Segmented\n  3D MRI","summary":"  The detection of Alzheimer disease (AD) from clinical MRI data is an active\narea of research in medical imaging. Recent advances in quantum computing,\nparticularly the integration of parameterized quantum circuits (PQCs) with\nclassical machine learning architectures, offer new opportunities to develop\nmodels that may outperform traditional methods. However, quantum machine\nlearning (QML) remains in its early stages and requires further experimental\nanalysis to better understand its behavior and limitations. In this paper, we\npropose an end to end hybrid classical quantum convolutional neural network (CQ\nCNN) for AD detection using clinically formatted 3D MRI data. Our approach\ninvolves developing a framework to make 3D MRI data usable for machine\nlearning, designing and training a brain tissue segmentation model (Skull Net),\nand training a diffusion model to generate synthetic images for the minority\nclass. Our converged models exhibit potential quantum advantages, achieving\nhigher accuracy in fewer epochs than classical models. The proposed beta8 3\nqubit model achieves an accuracy of 97.50%, surpassing state of the art (SOTA)\nmodels while requiring significantly fewer computational resources. In\nparticular, the architecture employs only 13K parameters (0.48 MB), reducing\nthe parameter count by more than 99.99% compared to current SOTA models.\nFurthermore, the diffusion-generated data used to train our quantum models, in\nconjunction with real samples, preserve clinical structural standards,\nrepresenting a notable first in the field of QML. We conclude that CQCNN\narchitecture like models, with further improvements in gradient optimization\ntechniques, could become a viable option and even a potential alternative to\nclassical models for AD detection, especially in data limited and resource\nconstrained clinical settings.\n","authors":["Mominul Islam","Mohammad Junayed Hasan","M. R. C. Mahdy"],"pdf_url":"https://arxiv.org/pdf/2503.02345v1.pdf","comment":"Application of hybrid quantum-classical machine learning for (early\n  stage) disease detection"},{"id":"http://arxiv.org/abs/2503.02341v1","updated":"2025-03-04T07:04:55Z","published":"2025-03-04T07:04:55Z","title":"GRADEO: Towards Human-Like Evaluation for Text-to-Video Generation via\n  Multi-Step Reasoning","summary":"  Recent great advances in video generation models have demonstrated their\npotential to produce high-quality videos, bringing challenges to effective\nevaluation. Unlike human evaluation, existing automated evaluation metrics lack\nhigh-level semantic understanding and reasoning capabilities for video, thus\nmaking them infeasible and unexplainable. To fill this gap, we curate\nGRADEO-Instruct, a multi-dimensional T2V evaluation instruction tuning dataset,\nincluding 3.3k videos from over 10 existing video generation models and\nmulti-step reasoning assessments converted by 16k human annotations. We then\nintroduce GRADEO, one of the first specifically designed video evaluation\nmodels, which grades AI-generated videos for explainable scores and assessments\nthrough multi-step reasoning. Experiments show that our method aligns better\nwith human evaluations than existing methods. Furthermore, our benchmarking\nreveals that current video generation models struggle to produce content that\naligns with human reasoning and complex real-world scenarios. The models,\ndatasets, and codes will be released soon.\n","authors":["Zhun Mou","Bin Xia","Zhengchao Huang","Wenming Yang","Jiaya Jia"],"pdf_url":"https://arxiv.org/pdf/2503.02341v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2501.15061v2","updated":"2025-03-04T07:00:07Z","published":"2025-01-25T03:46:35Z","title":"PolaFormer: Polarity-aware Linear Attention for Vision Transformers","summary":"  Linear attention has emerged as a promising alternative to softmax-based\nattention, leveraging kernelized feature maps to reduce complexity from\nquadratic to linear in sequence length. However, the non-negative constraint on\nfeature maps and the relaxed exponential function used in approximation lead to\nsignificant information loss compared to the original query-key dot products,\nresulting in less discriminative attention maps with higher entropy. To address\nthe missing interactions driven by negative values in query-key pairs, we\npropose a polarity-aware linear attention mechanism that explicitly models both\nsame-signed and opposite-signed query-key interactions, ensuring comprehensive\ncoverage of relational information. Furthermore, to restore the spiky\nproperties of attention maps, we provide a theoretical analysis proving the\nexistence of a class of element-wise functions (with positive first and second\nderivatives) that can reduce entropy in the attention distribution. For\nsimplicity, and recognizing the distinct contributions of each dimension, we\nemploy a learnable power function for rescaling, allowing strong and weak\nattention signals to be effectively separated. Extensive experiments\ndemonstrate that the proposed PolaFormer improves performance on various vision\ntasks, enhancing both expressiveness and efficiency by up to 4.6%.\n","authors":["Weikang Meng","Yadan Luo","Xin Li","Dongmei Jiang","Zheng Zhang"],"pdf_url":"https://arxiv.org/pdf/2501.15061v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.20893v2","updated":"2025-03-04T06:54:15Z","published":"2024-10-28T10:20:38Z","title":"Evaluating the Robustness of LiDAR Point Cloud Tracking Against\n  Adversarial Attack","summary":"  In this study, we delve into the robustness of neural network-based LiDAR\npoint cloud tracking models under adversarial attacks, a critical aspect often\noverlooked in favor of performance enhancement. These models, despite\nincorporating advanced architectures like Transformer or Bird's Eye View (BEV),\ntend to neglect robustness in the face of challenges such as adversarial\nattacks, domain shifts, or data corruption. We instead focus on the robustness\nof the tracking models under the threat of adversarial attacks. We begin by\nestablishing a unified framework for conducting adversarial attacks within the\ncontext of 3D object tracking, which allows us to thoroughly investigate both\nwhite-box and black-box attack strategies. For white-box attacks, we tailor\nspecific loss functions to accommodate various tracking paradigms and extend\nexisting methods such as FGSM, C\\&W, and PGD to the point cloud domain. In\naddressing black-box attack scenarios, we introduce a novel transfer-based\napproach, the Target-aware Perturbation Generation (TAPG) algorithm, with the\ndual objectives of achieving high attack performance and maintaining low\nperceptibility. This method employs a heuristic strategy to enforce sparse\nattack constraints and utilizes random sub-vector factorization to bolster\ntransferability. Our experimental findings reveal a significant vulnerability\nin advanced tracking methods when subjected to both black-box and white-box\nattacks, underscoring the necessity for incorporating robustness against\nadversarial attacks into the design of LiDAR point cloud tracking models.\nNotably, compared to existing methods, the TAPG also strikes an optimal balance\nbetween the effectiveness of the attack and the concealment of the\nperturbations.\n","authors":["Shengjing Tian","Yinan Han","Xiantong Zhao","Bin Liu","Xiuping Liu"],"pdf_url":"https://arxiv.org/pdf/2410.20893v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.01220v2","updated":"2025-03-04T06:50:03Z","published":"2025-03-03T06:37:30Z","title":"Tera-MIND: Tera-scale mouse brain simulation via spatial mRNA-guided\n  diffusion","summary":"  Holistic 3D modeling of molecularly defined brain structures is crucial for\nunderstanding complex brain functions. Emerging tissue profiling technologies\nenable the construction of a comprehensive atlas of the mammalian brain with\nsub-cellular resolution and spatially resolved gene expression data. However,\nsuch tera-scale volumetric datasets present significant computational\nchallenges in understanding complex brain functions within their native 3D\nspatial context. Here, we propose the novel generative approach\n$\\textbf{Tera-MIND}$, which can simulate $\\textbf{Tera}$-scale $\\textbf{M}$ouse\nbra$\\textbf{IN}$s in 3D using a patch-based and boundary-aware\n$\\textbf{D}$iffusion model. Taking spatial transcriptomic data as the\nconditional input, we generate virtual mouse brains with comprehensive cellular\nmorphological detail at teravoxel scale. Through the lens of 3D $gene$-$gene$\nself-attention, we identify spatial molecular interactions for key\ntranscriptomic pathways in the murine brain, exemplified by glutamatergic and\ndopaminergic neuronal systems. Importantly, these $in$-$silico$ biological\nfindings are consistent and reproducible across three tera-scale virtual mouse\nbrains. Therefore, Tera-MIND showcases a promising path toward efficient and\ngenerative simulations of whole organ systems for biomedical research. Project\nwebsite: https://musikisomorphie.github.io/Tera-MIND.html\n","authors":["Jiqing Wu","Ingrid Berg","Yawei Li","Ender Konukoglu","Viktor H. Koelzer"],"pdf_url":"https://arxiv.org/pdf/2503.01220v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.02334v1","updated":"2025-03-04T06:45:54Z","published":"2025-03-04T06:45:54Z","title":"BiasICL: In-Context Learning and Demographic Biases of Vision Language\n  Models","summary":"  Vision language models (VLMs) show promise in medical diagnosis, but their\nperformance across demographic subgroups when using in-context learning (ICL)\nremains poorly understood. We examine how the demographic composition of\ndemonstration examples affects VLM performance in two medical imaging tasks:\nskin lesion malignancy prediction and pneumothorax detection from chest\nradiographs. Our analysis reveals that ICL influences model predictions through\nmultiple mechanisms: (1) ICL allows VLMs to learn subgroup-specific disease\nbase rates from prompts and (2) ICL leads VLMs to make predictions that perform\ndifferently across demographic groups, even after controlling for\nsubgroup-specific disease base rates. Our empirical results inform\nbest-practices for prompting current VLMs (specifically examining demographic\nsubgroup performance, and matching base rates of labels to target distribution\nat a bulk level and within subgroups), while also suggesting next steps for\nimproving our theoretical understanding of these models.\n","authors":["Sonnet Xu","Joseph Janizek","Yixing Jiang","Roxana Daneshjou"],"pdf_url":"https://arxiv.org/pdf/2503.02334v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.02332v1","updated":"2025-03-04T06:45:10Z","published":"2025-03-04T06:45:10Z","title":"COMMA: Coordinate-aware Modulated Mamba Network for 3D Dispersed Vessel\n  Segmentation","summary":"  Accurate segmentation of 3D vascular structures is essential for various\nmedical imaging applications. The dispersed nature of vascular structures leads\nto inherent spatial uncertainty and necessitates location awareness, yet most\ncurrent 3D medical segmentation models rely on the patch-wise training strategy\nthat usually loses this spatial context. In this study, we introduce the\nCoordinate-aware Modulated Mamba Network (COMMA) and contribute a manually\nlabeled dataset of 570 cases, the largest publicly available 3D vessel dataset\nto date. COMMA leverages both entire and cropped patch data through global and\nlocal branches, ensuring robust and efficient spatial location awareness.\nSpecifically, COMMA employs a channel-compressed Mamba (ccMamba) block to\nencode entire image data, capturing long-range dependencies while optimizing\ncomputational costs. Additionally, we propose a coordinate-aware modulated\n(CaM) block to enhance interactions between the global and local branches,\nallowing the local branch to better perceive spatial information. We evaluate\nCOMMA on six datasets, covering two imaging modalities and five types of\nvascular tissues. The results demonstrate COMMA's superior performance compared\nto state-of-the-art methods with computational efficiency, especially in\nsegmenting small vessels. Ablation studies further highlight the importance of\nour proposed modules and spatial information. The code and data will be open\nsource at https://github.com/shigen-StoneRoot/COMMA.\n","authors":["Gen Shi","Hui Zhang","Jie Tian"],"pdf_url":"https://arxiv.org/pdf/2503.02332v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.00796v2","updated":"2025-03-04T06:40:35Z","published":"2025-03-02T08:47:06Z","title":"An Efficient 3D Convolutional Neural Network with Channel-wise,\n  Spatial-grouped, and Temporal Convolutions","summary":"  There has been huge progress on video action recognition in recent years.\nHowever, many works focus on tweaking existing 2D backbones due to the reliance\nof ImageNet pretraining, which restrains the models from achieving higher\nefficiency for video recognition. In this work we introduce a simple and very\nefficient 3D convolutional neural network for video action recognition. The\ndesign of the building block consists of a channel-wise convolution, followed\nby a spatial group convolution, and finally a temporal convolution. We evaluate\nthe performance and efficiency of our proposed network on several video action\nrecognition datasets by directly training on the target dataset without relying\non pertaining. On Something-Something-V1&V2, Kinetics-400 and Multi-Moments in\nTime, our network can match or even surpass the performance of other models\nwhich are several times larger. On the fine-grained action recognition dataset\nFineGym, we beat the previous state-of-the-art accuracy achieved with 2-stream\nmethods by more than 5% using only RGB input.\n","authors":["Zhe Wang","Xulei Yang"],"pdf_url":"https://arxiv.org/pdf/2503.00796v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.02330v1","updated":"2025-03-04T06:40:16Z","published":"2025-03-04T06:40:16Z","title":"Exploring Simple Siamese Network for High-Resolution Video Quality\n  Assessment","summary":"  In the research of video quality assessment (VQA), two-branch network has\nemerged as a promising solution. It decouples VQA with separate technical and\naesthetic branches to measure the perception of low-level distortions and\nhigh-level semantics respectively. However, we argue that while technical and\naesthetic perspectives are complementary, the technical perspective itself\nshould be measured in semantic-aware manner. We hypothesize that existing\ntechnical branch struggles to perceive the semantics of high-resolution videos,\nas it is trained on local mini-patches sampled from videos. This issue can be\nhidden by apparently good results on low-resolution videos, but indeed becomes\ncritical for high-resolution VQA. This work introduces SiamVQA, a simple but\neffective Siamese network for highre-solution VQA. SiamVQA shares weights\nbetween technical and aesthetic branches, enhancing the semantic perception\nability of technical branch to facilitate technical-quality representation\nlearning. Furthermore, it integrates a dual cross-attention layer for fusing\ntechnical and aesthetic features. SiamVQA achieves state-of-the-art accuracy on\nhigh-resolution benchmarks, and competitive results on lower-resolution\nbenchmarks. Codes will be available at: https://github.com/srcn-ivl/SiamVQA\n","authors":["Guotao Shen","Ziheng Yan","Xin Jin","Longhai Wu","Jie Chen","Ilhyun Cho","Cheul-Hee Hahm"],"pdf_url":"https://arxiv.org/pdf/2503.02330v1.pdf","comment":"Accepted by ICASSP 2025"},{"id":"http://arxiv.org/abs/2410.05500v2","updated":"2025-03-04T06:34:37Z","published":"2024-10-07T21:12:32Z","title":"Residual Kolmogorov-Arnold Network for Enhanced Deep Learning","summary":"  Despite their immense success, deep neural networks (CNNs) are costly to\ntrain, while modern architectures can retain hundreds of convolutional layers\nin network depth. Standard convolutional operations are fundamentally limited\nby their linear nature along with fixed activations, where multiple layers are\nneeded to learn complex patterns, making this approach computationally\ninefficient and prone to optimization difficulties. As a result, we introduce\nRKAN (Residual Kolmogorov-Arnold Network), which could be easily implemented\ninto stages of traditional networks, such as ResNet. The module also integrates\npolynomial feature transformation that provides the expressive power of many\nconvolutional layers through learnable, non-linear feature refinement. Our\nproposed RKAN module offers consistent improvements over the base models on\nvarious well-known benchmark datasets, such as CIFAR-100, Food-101, and\nImageNet.\n","authors":["Ray Congrui Yu","Sherry Wu","Jiang Gui"],"pdf_url":"https://arxiv.org/pdf/2410.05500v2.pdf","comment":"Code is available at https://github.com/withray/residualKAN.git"},{"id":"http://arxiv.org/abs/2410.03226v3","updated":"2025-03-04T06:28:21Z","published":"2024-10-04T08:26:06Z","title":"Frame-Voyager: Learning to Query Frames for Video Large Language Models","summary":"  Video Large Language Models (Video-LLMs) have made remarkable progress in\nvideo understanding tasks. However, they are constrained by the maximum length\nof input tokens, making it impractical to input entire videos. Existing frame\nselection approaches, such as uniform frame sampling and text-frame retrieval,\nfail to account for the information density variations in the videos or the\ncomplex instructions in the tasks, leading to sub-optimal performance. In this\npaper, we propose Frame-Voyager that learns to query informative frame\ncombinations, based on the given textual queries in the task. To train\nFrame-Voyager, we introduce a new data collection and labeling pipeline, by\nranking frame combinations using a pre-trained Video-LLM. Given a video of M\nframes, we traverse its T-frame combinations, feed them into a Video-LLM, and\nrank them based on Video-LLM's prediction losses. Using this ranking as\nsupervision, we train Frame-Voyager to query the frame combinations with lower\nlosses. In experiments, we evaluate Frame-Voyager on four Video Question\nAnswering benchmarks by plugging it into two different Video-LLMs. The\nexperimental results demonstrate that Frame-Voyager achieves impressive results\nin all settings, highlighting its potential as a plug-and-play solution for\nVideo-LLMs.\n","authors":["Sicheng Yu","Chengkai Jin","Huanyu Wang","Zhenghao Chen","Sheng Jin","Zhongrong Zuo","Xiaolei Xu","Zhenbang Sun","Bingni Zhang","Jiawei Wu","Hao Zhang","Qianru Sun"],"pdf_url":"https://arxiv.org/pdf/2410.03226v3.pdf","comment":"ICLR 2025, Camera-ready Version"},{"id":"http://arxiv.org/abs/2503.02322v1","updated":"2025-03-04T06:27:05Z","published":"2025-03-04T06:27:05Z","title":"Generative Model-Assisted Demosaicing for Cross-multispectral Cameras","summary":"  As a crucial part of the spectral filter array (SFA)-based multispectral\nimaging process, spectral demosaicing has exploded with the proliferation of\ndeep learning techniques. However, (1) bothering by the difficulty of capturing\ncorresponding labels for real data or simulating the practical spectral imaging\nprocess, end-to-end networks trained in a supervised manner using simulated\ndata often perform poorly on real data. (2) cross-camera spectral discrepancies\nmake it difficult to apply pre-trained models to new cameras. (3) existing\ndemosaicing networks are prone to introducing visual artifacts on hard cases\ndue to the interpolation of unknown values. To address these issues, we propose\na hybrid supervised training method with the assistance of the self-supervised\ngenerative model, which performs well on real data across different spectral\ncameras. Specifically, our approach consists of three steps: (1) Pre-Training\nstep: training the end-to-end neural network on a large amount of simulated\ndata; (2) Pseudo-Pairing step: generating pseudo-labels of real target data\nusing the self-supervised generative model; (3) Fine-Tuning step: fine-tuning\nthe pre-trained model on the pseudo data pairs obtained in (2). To alleviate\nartifacts, we propose a frequency-domain hard patch selection method that\nidentifies artifact-prone regions by analyzing spectral discrepancies using\nFourier transform and filtering techniques, allowing targeted fine-tuning to\nenhance demosaicing performance. Finally, we propose UniSpecTest, a real-world\nmultispectral mosaic image dataset for testing. Ablation experiments have\ndemonstrated the effectiveness of each training step, and extensive experiments\non both synthetic and real datasets show that our method achieves significant\nperformance gains compared to state-of-the-art techniques.\n","authors":["Jiahui Luo","Kai Feng","Haijin Zeng","Yongyong Chen"],"pdf_url":"https://arxiv.org/pdf/2503.02322v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.02321v1","updated":"2025-03-04T06:23:22Z","published":"2025-03-04T06:23:22Z","title":"Semantic Prior Distillation with Vision Foundation Model for Enhanced\n  Rapid Bone Scintigraphy Image Restoration","summary":"  Rapid bone scintigraphy is an essential tool for diagnosing skeletal diseases\nand tumor metastasis in pediatric patients, as it reduces scan time and\nminimizes patient discomfort. However, rapid scans often result in poor image\nquality, potentially affecting diagnosis due to reduced resolution and detail,\nwhich make it challenging to identify and evaluate finer anatomical structures.\nTo address this issue, we propose the first application of SAM-based semantic\npriors for medical image restoration, leveraging the Segment Anything Model\n(SAM) to enhance rapid bone scintigraphy images in pediatric populations. Our\nmethod comprises two cascaded networks, $f^{IR1}$ and $f^{IR2}$, augmented by\nthree key modules: a Semantic Prior Integration (SPI) module, a Semantic\nKnowledge Distillation (SKD) module, and a Semantic Consistency Module (SCM).\nThe SPI and SKD modules incorporate domain-specific semantic information from a\nfine-tuned SAM, while the SCM maintains consistent semantic feature\nrepresentation throughout the cascaded networks. In addition, we will release a\nnovel Rapid Bone Scintigraphy dataset called RBS, the first dataset dedicated\nto rapid bone scintigraphy image restoration in pediatric patients. RBS\nconsists of 137 pediatric patients aged between 0.5 and 16 years who underwent\nboth standard and rapid bone scans. The dataset includes scans performed at 20\ncm/min (standard) and 40 cm/min (rapid), representing a $2\\times$ acceleration.\nWe conducted extensive experiments on both the publicly available endoscopic\ndataset and RBS. The results demonstrate that our method outperforms all\nexisting methods across various metrics, including PSNR, SSIM, FID, and LPIPS.\n","authors":["Pengchen Liang","Leijun Shi","Huiping Yao","Bin Pu","Jianguo Chen","Lei Zhao","Haishan Huang","Zhuangzhuang Chen","Zhaozhao Xu","Lite Xu","Qing Chang","Yiwei Li"],"pdf_url":"https://arxiv.org/pdf/2503.02321v1.pdf","comment":"12 pages, 9 figures, 8 tables"},{"id":"http://arxiv.org/abs/2406.07209v3","updated":"2025-03-04T06:21:26Z","published":"2024-06-11T12:32:53Z","title":"MS-Diffusion: Multi-subject Zero-shot Image Personalization with Layout\n  Guidance","summary":"  Recent advancements in text-to-image generation models have dramatically\nenhanced the generation of photorealistic images from textual prompts, leading\nto an increased interest in personalized text-to-image applications,\nparticularly in multi-subject scenarios. However, these advances are hindered\nby two main challenges: firstly, the need to accurately maintain the details of\neach referenced subject in accordance with the textual descriptions; and\nsecondly, the difficulty in achieving a cohesive representation of multiple\nsubjects in a single image without introducing inconsistencies. To address\nthese concerns, our research introduces the MS-Diffusion framework for\nlayout-guided zero-shot image personalization with multi-subjects. This\ninnovative approach integrates grounding tokens with the feature resampler to\nmaintain detail fidelity among subjects. With the layout guidance, MS-Diffusion\nfurther improves the cross-attention to adapt to the multi-subject inputs,\nensuring that each subject condition acts on specific areas. The proposed\nmulti-subject cross-attention orchestrates harmonious inter-subject\ncompositions while preserving the control of texts. Comprehensive quantitative\nand qualitative experiments affirm that this method surpasses existing models\nin both image and text fidelity, promoting the development of personalized\ntext-to-image generation. The project page is https://MS-Diffusion.github.io.\n","authors":["Xierui Wang","Siming Fu","Qihan Huang","Wanggui He","Hao Jiang"],"pdf_url":"https://arxiv.org/pdf/2406.07209v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2501.13492v4","updated":"2025-03-04T06:17:17Z","published":"2025-01-23T09:14:15Z","title":"Quantized Spike-driven Transformer","summary":"  Spiking neural networks are emerging as a promising energy-efficient\nalternative to traditional artificial neural networks due to their spike-driven\nparadigm. However, recent research in the SNN domain has mainly focused on\nenhancing accuracy by designing large-scale Transformer structures, which\ntypically rely on substantial computational resources, limiting their\ndeployment on resource-constrained devices. To overcome this challenge, we\npropose a quantized spike-driven Transformer baseline (QSD-Transformer), which\nachieves reduced resource demands by utilizing a low bit-width parameter.\nRegrettably, the QSD-Transformer often suffers from severe performance\ndegradation. In this paper, we first conduct empirical analysis and find that\nthe bimodal distribution of quantized spike-driven self-attention (Q-SDSA)\nleads to spike information distortion (SID) during quantization, causing\nsignificant performance degradation. To mitigate this issue, we take\ninspiration from mutual information entropy and propose a bi-level optimization\nstrategy to rectify the information distribution in Q-SDSA. Specifically, at\nthe lower level, we introduce an information-enhanced LIF to rectify the\ninformation distribution in Q-SDSA. At the upper level, we propose a\nfine-grained distillation scheme for the QSD-Transformer to align the\ndistribution in Q-SDSA with that in the counterpart ANN. By integrating the\nbi-level optimization strategy, the QSD-Transformer can attain enhanced energy\nefficiency without sacrificing its high-performance advantage. For instance,\nwhen compared to the prior SNN benchmark on ImageNet, the QSD-Transformer\nachieves 80.3% top-1 accuracy, accompanied by significant reductions of\n6.0$\\times$ and 8.1$\\times$ in power consumption and model size, respectively.\nCode is available at https://github.com/bollossom/QSD-Transformer.\n","authors":["Xuerui Qiu","Malu Zhang","Jieyuan Zhang","Wenjie Wei","Honglin Cao","Junsheng Guo","Rui-Jie Zhu","Yimeng Shan","Yang Yang","Haizhou Li"],"pdf_url":"https://arxiv.org/pdf/2501.13492v4.pdf","comment":"Accepted by ICLR 2025"},{"id":"http://arxiv.org/abs/2503.02316v1","updated":"2025-03-04T06:17:17Z","published":"2025-03-04T06:17:17Z","title":"Unified Arbitrary-Time Video Frame Interpolation and Prediction","summary":"  Video frame interpolation and prediction aim to synthesize frames in-between\nand subsequent to existing frames, respectively. Despite being closely-related,\nthese two tasks are traditionally studied with different model architectures,\nor same architecture but individually trained weights. Furthermore, while\narbitrary-time interpolation has been extensively studied, the value of\narbitrary-time prediction has been largely overlooked. In this work, we present\nuniVIP - unified arbitrary-time Video Interpolation and Prediction.\nTechnically, we firstly extend an interpolation-only network for arbitrary-time\ninterpolation and prediction, with a special input channel for task\n(interpolation or prediction) encoding. Then, we show how to train a unified\nmodel on common triplet frames. Our uniVIP provides competitive results for\nvideo interpolation, and outperforms existing state-of-the-arts for video\nprediction. Codes will be available at: https://github.com/srcn-ivl/uniVIP\n","authors":["Xin Jin","Longhai Wu","Jie Chen","Ilhyun Cho","Cheul-Hee Hahm"],"pdf_url":"https://arxiv.org/pdf/2503.02316v1.pdf","comment":"Accepted by ICASSP 2025"},{"id":"http://arxiv.org/abs/2503.00308v2","updated":"2025-03-04T06:08:00Z","published":"2025-03-01T02:37:59Z","title":"Abstract Rendering: Computing All that is Seen in Gaussian Splat Scenes","summary":"  We introduce abstract rendering, a method for computing a set of images by\nrendering a scene from a continuously varying range of camera positions. The\nresulting abstract image-which encodes an infinite collection of possible\nrenderings-is represented using constraints on the image matrix, enabling\nrigorous uncertainty propagation through the rendering process. This capability\nis particularly valuable for the formal verification of vision-based autonomous\nsystems and other safety-critical applications. Our approach operates on\nGaussian splat scenes, an emerging representation in computer vision and\nrobotics. We leverage efficient piecewise linear bound propagation to abstract\nfundamental rendering operations, while addressing key challenges that arise in\nmatrix inversion and depth sorting-two operations not directly amenable to\nstandard approximations. To handle these, we develop novel linear relational\nabstractions that maintain precision while ensuring computational efficiency.\nThese abstractions not only power our abstract rendering algorithm but also\nprovide broadly applicable tools for other rendering problems. Our\nimplementation, AbstractSplat, is optimized for scalability, handling up to\n750k Gaussians while allowing users to balance memory and runtime through tile\nand batch-based computation. Compared to the only existing abstract image\nmethod for mesh-based scenes, AbstractSplat achieves 2-14x speedups while\npreserving precision. Our results demonstrate that continuous camera motion,\nrotations, and scene variations can be rigorously analyzed at scale, making\nabstract rendering a powerful tool for uncertainty-aware vision applications.\n","authors":["Yangge Li","Chenxi Ji","Xiangru Zhong","Huan Zhang","Sayan Mitra"],"pdf_url":"https://arxiv.org/pdf/2503.00308v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.02304v1","updated":"2025-03-04T06:05:33Z","published":"2025-03-04T06:05:33Z","title":"A Token-level Text Image Foundation Model for Document Understanding","summary":"  In recent years, general visual foundation models (VFMs) have witnessed\nincreasing adoption, particularly as image encoders for popular multi-modal\nlarge language models (MLLMs). However, without semantically fine-grained\nsupervision, these models still encounter fundamental prediction errors in the\ncontext of downstream text-image-related tasks, i.e., perception, understanding\nand reasoning with images containing small and dense texts. To bridge this gap,\nwe develop TokenOCR, the first token-level visual foundation model specifically\ntailored for text-image-related tasks, designed to support a variety of\ntraditional downstream applications. To facilitate the pretraining of TokenOCR,\nwe also devise a high-quality data production pipeline that constructs the\nfirst token-level image text dataset, TokenIT, comprising 20 million images and\n1.8 billion token-mask pairs. Furthermore, leveraging this foundation with\nexceptional image-as-text capability, we seamlessly replace previous VFMs with\nTokenOCR to construct a document-level MLLM, TokenVL, for VQA-based document\nunderstanding tasks. Finally, extensive experiments demonstrate the\neffectiveness of TokenOCR and TokenVL. Code, datasets, and weights will be\navailable at https://token-family.github.io/TokenOCR_project.\n","authors":["Tongkun Guan","Zining Wang","Pei Fu","Zhengtao Guo","Wei Shen","Kai Zhou","Tiezhu Yue","Chen Duan","Hao Sun","Qianyi Jiang","Junfeng Luo","Xiaokang Yang"],"pdf_url":"https://arxiv.org/pdf/2503.02304v1.pdf","comment":"23 pages"},{"id":"http://arxiv.org/abs/2503.02302v1","updated":"2025-03-04T06:04:50Z","published":"2025-03-04T06:04:50Z","title":"On the Relationship Between Double Descent of CNNs and Shape/Texture\n  Bias Under Learning Process","summary":"  The double descent phenomenon, which deviates from the traditional\nbias-variance trade-off theory, attracts considerable research attention;\nhowever, the mechanism of its occurrence is not fully understood. On the other\nhand, in the study of convolutional neural networks (CNNs) for image\nrecognition, methods are proposed to quantify the bias on shape features versus\ntexture features in images, determining which features the CNN focuses on more.\nIn this work, we hypothesize that there is a relationship between the\nshape/texture bias in the learning process of CNNs and epoch-wise double\ndescent, and we conduct verification. As a result, we discover double\ndescent/ascent of shape/texture bias synchronized with double descent of test\nerror under conditions where epoch-wise double descent is observed.\nQuantitative evaluations confirm this correlation between the test errors and\nthe bias values from the initial decrease to the full increase in test error.\nInterestingly, double descent/ascent of shape/texture bias is observed in some\ncases even in conditions without label noise, where double descent is thought\nnot to occur. These experimental results are considered to contribute to the\nunderstanding of the mechanisms behind the double descent phenomenon and the\nlearning process of CNNs in image recognition.\n","authors":["Shun Iwase","Shuya Takahashi","Nakamasa Inoue","Rio Yokota","Ryo Nakamura","Hirokatsu Kataoka"],"pdf_url":"https://arxiv.org/pdf/2503.02302v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.00397v2","updated":"2025-03-04T05:48:57Z","published":"2025-03-01T08:18:11Z","title":"Floorplan-SLAM: A Real-Time, High-Accuracy, and Long-Term Multi-Session\n  Point-Plane SLAM for Efficient Floorplan Reconstruction","summary":"  Floorplan reconstruction provides structural priors essential for reliable\nindoor robot navigation and high-level scene understanding. However, existing\napproaches either require time-consuming offline processing with a complete\nmap, or rely on expensive sensors and substantial computational resources. To\naddress the problems, we propose Floorplan-SLAM, which incorporates floorplan\nreconstruction tightly into a multi-session SLAM system by seamlessly\ninteracting with plane extraction, pose estimation, and back-end optimization,\nachieving real-time, high-accuracy, and long-term floorplan reconstruction\nusing only a stereo camera. Specifically, we present a robust plane extraction\nalgorithm that operates in a compact plane parameter space and leverages\nspatially complementary features to accurately detect planar structures, even\nin weakly textured scenes. Furthermore, we propose a floorplan reconstruction\nmodule tightly coupled with the SLAM system, which uses continuously optimized\nplane landmarks and poses to formulate and solve a novel optimization problem,\nthereby enabling real-time incremental floorplan reconstruction. Note that by\nleveraging the map merging capability of multi-session SLAM, our method\nsupports long-term floorplan reconstruction across multiple sessions without\nredundant data collection. Experiments on the VECtor and the self-collected\ndatasets indicate that Floorplan-SLAM significantly outperforms\nstate-of-the-art methods in terms of plane extraction robustness, pose\nestimation accuracy, and floorplan reconstruction fidelity and speed, achieving\nreal-time performance at 25-45 FPS without GPU acceleration, which reduces the\nfloorplan reconstruction time for a 1000 square meters scene from over 10 hours\nto just 9.44 minutes.\n","authors":["Haolin Wang","Zeren Lv","Hao Wei","Haijiang Zhu","Yihong Wu"],"pdf_url":"https://arxiv.org/pdf/2503.00397v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.00063v2","updated":"2025-03-04T05:41:01Z","published":"2025-02-27T06:14:47Z","title":"NoPain: No-box Point Cloud Attack via Optimal Transport Singular\n  Boundary","summary":"  Adversarial attacks exploit the vulnerability of deep models against\nadversarial samples. Existing point cloud attackers are tailored to specific\nmodels, iteratively optimizing perturbations based on gradients in either a\nwhite-box or black-box setting. Despite their promising attack performance,\nthey often struggle to produce transferable adversarial samples due to\noverfitting the specific parameters of surrogate models. To overcome this\nissue, we shift our focus to the data distribution itself and introduce a novel\napproach named NoPain, which employs optimal transport (OT) to identify the\ninherent singular boundaries of the data manifold for cross-network point cloud\nattacks. Specifically, we first calculate the OT mapping from noise to the\ntarget feature space, then identify singular boundaries by locating\nnon-differentiable positions. Finally, we sample along singular boundaries to\ngenerate adversarial point clouds. Once the singular boundaries are determined,\nNoPain can efficiently produce adversarial samples without the need of\niterative updates or guidance from the surrogate classifiers. Extensive\nexperiments demonstrate that the proposed end-to-end method outperforms\nbaseline approaches in terms of both transferability and efficiency, while also\nmaintaining notable advantages even against defense strategies. The source code\nwill be publicly available.\n","authors":["Zezeng Li","Xiaoyu Du","Na Lei","Liming Chen","Weimin Wang"],"pdf_url":"https://arxiv.org/pdf/2503.00063v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2409.01348v3","updated":"2025-03-04T05:29:33Z","published":"2024-09-02T16:02:26Z","title":"PatternPaint: Practical Layout Pattern Generation Using Diffusion-Based\n  Inpainting","summary":"  Generating diverse VLSI layout patterns is essential for various downstream\ntasks in design for manufacturing, as design rules continually evolve during\nthe development of new technology nodes. However, existing training-based\nmethods for layout pattern generation rely on large datasets. In practical\nscenarios, especially when developing a new technology node, obtaining such\nextensive layout data is challenging. Consequently, training models with large\ndatasets becomes impractical, limiting the scalability and adaptability of\nprior approaches. To this end, we propose PatternPaint, a diffusion-based\nframework capable of generating legal patterns with limited\ndesign-rule-compliant training samples. PatternPaint simplifies complex layout\npattern generation into a series of inpainting processes with a template-based\ndenoising scheme. Furthermore, we perform few-shot finetuning on a pretrained\nimage foundation model with only 20 design-rule-compliant samples. Experimental\nresults show that using a sub-3nm technology node (Intel 18A), our model is the\nonly one that can generate legal patterns in complex 2D metal interconnect\ndesign rule settings among all previous works and achieves a high diversity\nscore. Additionally, our few-shot finetuning can boost the legality rate with\n1.87X improvement compared to the original pretrained model. As a result, we\ndemonstrate a production-ready approach for layout pattern generation in\ndeveloping new technology nodes.\n","authors":["Guanglei Zhou","Bhargav Korrapati","Gaurav Rajavendra Reddy","Chen-Chia Chang","Jingyu Pan","Jiang Hu","Yiran Chen","Dipto G. Thakurta"],"pdf_url":"https://arxiv.org/pdf/2409.01348v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.16199v4","updated":"2025-03-04T05:28:29Z","published":"2024-11-25T08:55:41Z","title":"VIRES: Video Instance Repainting via Sketch and Text Guided Generation","summary":"  We introduce VIRES, a video instance repainting method with sketch and text\nguidance, enabling video instance repainting, replacement, generation, and\nremoval. Existing approaches struggle with temporal consistency and accurate\nalignment with the provided sketch sequence. VIRES leverages the generative\npriors of text-to-video models to maintain temporal consistency and produce\nvisually pleasing results. We propose the Sequential ControlNet with the\nstandardized self-scaling, which effectively extracts structure layouts and\nadaptively captures high-contrast sketch details. We further augment the\ndiffusion transformer backbone with the sketch attention to interpret and\ninject fine-grained sketch semantics. A sketch-aware encoder ensures that\nrepainted results are aligned with the provided sketch sequence. Additionally,\nwe contribute the VireSet, a dataset with detailed annotations tailored for\ntraining and evaluating video instance editing methods. Experimental results\ndemonstrate the effectiveness of VIRES, which outperforms state-of-the-art\nmethods in visual quality, temporal consistency, condition alignment, and human\nratings. Project page:https://suimuc.github.io/suimu.github.io/projects/VIRES/\n","authors":["Shuchen Weng","Haojie Zheng","Peixuan Zhan","Yuchen Hong","Han Jiang","Si Li","Boxin Shi"],"pdf_url":"https://arxiv.org/pdf/2411.16199v4.pdf","comment":null},{"id":"http://arxiv.org/abs/2407.17773v2","updated":"2025-03-04T05:20:59Z","published":"2024-07-25T05:02:39Z","title":"KiVA: Kid-inspired Visual Analogies for Testing Large Multimodal Models","summary":"  This paper investigates visual analogical reasoning in large multimodal\nmodels (LMMs) compared to human adults and children. A \"visual analogy\" is an\nabstract rule inferred from one image and applied to another. While benchmarks\nexist for testing visual reasoning in LMMs, they require advanced skills and\nomit basic visual analogies that even young children can make. Inspired by\ndevelopmental psychology, we propose a new benchmark of 4,300 visual\ntransformations of everyday objects to test LMMs on visual analogical reasoning\nand compare them to children (ages three to five) and to adults. We structure\nthe evaluation into three stages: identifying what changed (e.g., color,\nnumber, etc.), how it changed (e.g., added one object), and applying the rule\nto new scenarios. Our findings show that while GPT-o1, GPT-4V, LLaVA-1.5, and\nMANTIS identify the \"what\" effectively, they struggle with quantifying the\n\"how\" and extrapolating this rule to new objects. In contrast, children and\nadults exhibit much stronger analogical reasoning at all three stages.\nAdditionally, the strongest tested model, GPT-o1, performs better in tasks\ninvolving simple surface-level visual attributes like color and size,\ncorrelating with quicker human adult response times. Conversely, more complex\ntasks such as number, rotation, and reflection, which necessitate extensive\ncognitive processing and understanding of extrinsic spatial properties in the\nphysical world, present more significant challenges. Altogether, these findings\nhighlight the limitations of training models on data that primarily consists of\n2D images and text.\n","authors":["Eunice Yiu","Maan Qraitem","Charlie Wong","Anisa Noor Majhi","Yutong Bai","Shiry Ginosar","Alison Gopnik","Kate Saenko"],"pdf_url":"https://arxiv.org/pdf/2407.17773v2.pdf","comment":"10 pages. For the KiVA benchmark, see https://github.com/ey242/KiVA"},{"id":"http://arxiv.org/abs/2503.01181v2","updated":"2025-03-04T05:20:53Z","published":"2025-03-03T05:09:44Z","title":"SAR-W-MixMAE: SAR Foundation Model Training Using Backscatter Power\n  Weighting","summary":"  Foundation model approaches such as masked auto-encoders (MAE) or its\nvariations are now being successfully applied to satellite imagery. Most of the\nongoing technical validation of foundation models have been applied to optical\nimages like RGB or multi-spectral images. Due to difficulty in semantic\nlabeling to create datasets and higher noise content with respect to optical\nimages, Synthetic Aperture Radar (SAR) data has not been explored a lot in the\nfield for foundation models. Therefore, in this work as a pre-training\napproach, we explored masked auto-encoder, specifically MixMAE on Sentinel-1\nSAR images and its impact on SAR image classification tasks. Moreover, we\nproposed to use the physical characteristic of SAR data for applying weighting\nparameter on the auto-encoder training loss (MSE) to reduce the effect of\nspeckle noise and very high values on the SAR images. Proposed SAR\nintensity-based weighting of the reconstruction loss demonstrates promising\nresults both on SAR pre-training and downstream tasks specifically on flood\ndetection compared with the baseline model.\n","authors":["Ali Caglayan","Nevrez Imamoglu","Toru Kouyama"],"pdf_url":"https://arxiv.org/pdf/2503.01181v2.pdf","comment":"5 pages, 1 figure"},{"id":"http://arxiv.org/abs/2503.02284v1","updated":"2025-03-04T05:13:56Z","published":"2025-03-04T05:13:56Z","title":"Semi-Supervised Audio-Visual Video Action Recognition with Audio Source\n  Localization Guided Mixup","summary":"  Video action recognition is a challenging but important task for\nunderstanding and discovering what the video does. However, acquiring\nannotations for a video is costly, and semi-supervised learning (SSL) has been\nstudied to improve performance even with a small number of labeled data in the\ntask. Prior studies for semi-supervised video action recognition have mostly\nfocused on using single modality - visuals - but the video is multi-modal, so\nutilizing both visuals and audio would be desirable and improve performance\nfurther, which has not been explored well. Therefore, we propose audio-visual\nSSL for video action recognition, which uses both visual and audio together,\neven with quite a few labeled data, which is challenging. In addition, to\nmaximize the information of audio and video, we propose a novel audio source\nlocalization-guided mixup method that considers inter-modal relations between\nvideo and audio modalities. In experiments on UCF-51, Kinetics-400, and\nVGGSound datasets, our model shows the superior performance of the proposed\nsemi-supervised audio-visual action recognition framework and audio source\nlocalization-guided mixup.\n","authors":["Seokun Kang","Taehwan Kim"],"pdf_url":"https://arxiv.org/pdf/2503.02284v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.02270v1","updated":"2025-03-04T04:38:36Z","published":"2025-03-04T04:38:36Z","title":"SSNet: Saliency Prior and State Space Model-based Network for Salient\n  Object Detection in RGB-D Images","summary":"  Salient object detection (SOD) in RGB-D images is an essential task in\ncomputer vision, enabling applications in scene understanding, robotics, and\naugmented reality. However, existing methods struggle to capture global\ndependency across modalities, lack comprehensive saliency priors from both RGB\nand depth data, and are ineffective in handling low-quality depth maps. To\naddress these challenges, we propose SSNet, a saliency-prior and state space\nmodel (SSM)-based network for the RGB-D SOD task. Unlike existing convolution-\nor transformer-based approaches, SSNet introduces an SSM-based multi-modal\nmulti-scale decoder module to efficiently capture both intra- and inter-modal\nglobal dependency with linear complexity. Specifically, we propose a\ncross-modal selective scan SSM (CM-S6) mechanism, which effectively captures\nglobal dependency between different modalities. Furthermore, we introduce a\nsaliency enhancement module (SEM) that integrates three saliency priors with\ndeep features to refine feature representation and improve the localization of\nsalient objects. To further address the issue of low-quality depth maps, we\npropose an adaptive contrast enhancement technique that dynamically refines\ndepth maps, making them more suitable for the RGB-D SOD task. Extensive\nquantitative and qualitative experiments on seven benchmark datasets\ndemonstrate that SSNet outperforms state-of-the-art methods.\n","authors":["Gargi Panda","Soumitra Kundu","Saumik Bhattacharya","Aurobinda Routray"],"pdf_url":"https://arxiv.org/pdf/2503.02270v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.01699v2","updated":"2025-03-04T04:33:27Z","published":"2024-10-02T16:05:27Z","title":"Accelerating Auto-regressive Text-to-Image Generation with Training-free\n  Speculative Jacobi Decoding","summary":"  The current large auto-regressive models can generate high-quality,\nhigh-resolution images, but these models require hundreds or even thousands of\nsteps of next-token prediction during inference, resulting in substantial time\nconsumption. In existing studies, Jacobi decoding, an iterative parallel\ndecoding algorithm, has been used to accelerate the auto-regressive generation\nand can be executed without training. However, the Jacobi decoding relies on a\ndeterministic criterion to determine the convergence of iterations. Thus, it\nworks for greedy decoding but is incompatible with sampling-based decoding\nwhich is crucial for visual quality and diversity in the current\nauto-regressive text-to-image generation. In this paper, we propose a\ntraining-free probabilistic parallel decoding algorithm, Speculative Jacobi\nDecoding (SJD), to accelerate auto-regressive text-to-image generation. By\nintroducing a probabilistic convergence criterion, our SJD accelerates the\ninference of auto-regressive text-to-image generation while maintaining the\nrandomness in sampling-based token decoding and allowing the model to generate\ndiverse images. Specifically, SJD facilitates the model to predict multiple\ntokens at each step and accepts tokens based on the probabilistic criterion,\nenabling the model to generate images with fewer steps than the conventional\nnext-token-prediction paradigm. We also investigate the token initialization\nstrategies that leverage the spatial locality of visual data to further improve\nthe acceleration ratio under specific scenarios. We conduct experiments for our\nproposed SJD on multiple auto-regressive text-to-image generation models,\nshowing the effectiveness of model acceleration without sacrificing the visual\nquality. The code of our work is available here:\nhttps://github.com/tyshiwo1/Accelerating-T2I-AR-with-SJD/.\n","authors":["Yao Teng","Han Shi","Xian Liu","Xuefei Ning","Guohao Dai","Yu Wang","Zhenguo Li","Xihui Liu"],"pdf_url":"https://arxiv.org/pdf/2410.01699v2.pdf","comment":"ICLR 2025; Codes:\n  https://github.com/tyshiwo1/Accelerating-T2I-AR-with-SJD/"},{"id":"http://arxiv.org/abs/2503.01100v2","updated":"2025-03-04T04:33:21Z","published":"2025-03-03T01:58:11Z","title":"Fence Theorem: Towards Dual-Objective Semantic-Structure Isolation in\n  Preprocessing Phase for 3D Anomaly Detection","summary":"  3D anomaly detection (AD) is prominent but difficult due to lacking a unified\ntheoretical foundation for preprocessing design. We establish the Fence\nTheorem, formalizing preprocessing as a dual-objective semantic isolator: (1)\nmitigating cross-semantic interference to the greatest extent feasible and (2)\nconfining anomaly judgments to aligned semantic spaces wherever viable, thereby\nestablishing intra-semantic comparability. Any preprocessing approach achieves\nthis goal through a two-stage process of Emantic-Division and\nSpatial-Constraints stage. Through systematic deconstruction, we theoretically\nand experimentally subsume existing preprocessing methods under this theorem\nvia tripartite evidence: qualitative analyses, quantitative studies, and\nmathematical proofs. Guided by the Fence Theorem, we implement Patch3D,\nconsisting of Patch-Cutting and Patch-Matching modules, to segment semantic\nspaces and consolidate similar ones while independently modeling normal\nfeatures within each space. Experiments on Anomaly-ShapeNet and Real3D-AD with\ndifferent settings demonstrate that progressively finer-grained semantic\nalignment in preprocessing directly enhances point-level AD accuracy, providing\ninverse validation of the theorem's causal logic.\n","authors":["Hanzhe Liang","Jie Zhou","Xuanxin Chen","Tao Dai","Jinbao Wang","Can Gao"],"pdf_url":"https://arxiv.org/pdf/2503.01100v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.18281v3","updated":"2025-03-04T04:31:55Z","published":"2024-03-27T06:17:21Z","title":"AIR-HLoc: Adaptive Retrieved Images Selection for Efficient Visual\n  Localisation","summary":"  State-of-the-art hierarchical localisation pipelines (HLoc) employ image\nretrieval (IR) to establish 2D-3D correspondences by selecting the top-$k$ most\nsimilar images from a reference database. While increasing $k$ improves\nlocalisation robustness, it also linearly increases computational cost and\nruntime, creating a significant bottleneck. This paper investigates the\nrelationship between global and local descriptors, showing that greater\nsimilarity between the global descriptors of query and database images\nincreases the proportion of feature matches. Low similarity queries\nsignificantly benefit from increasing $k$, while high similarity queries\nrapidly experience diminishing returns. Building on these observations, we\npropose an adaptive strategy that adjusts $k$ based on the similarity between\nthe query's global descriptor and those in the database, effectively mitigating\nthe feature-matching bottleneck. Our approach optimizes processing time without\nsacrificing accuracy. Experiments on three indoor and outdoor datasets show\nthat AIR-HLoc reduces feature matching time by up to 30\\%, while preserving\nstate-of-the-art accuracy. The results demonstrate that AIR-HLoc facilitates a\nlatency-sensitive localisation system.\n","authors":["Changkun Liu","Jianhao Jiao","Huajian Huang","Zhengyang Ma","Dimitrios Kanoulas","Tristan Braud"],"pdf_url":"https://arxiv.org/pdf/2403.18281v3.pdf","comment":"Accepted to the 2025 IEEE International Conference on Robotics and\n  Automation (ICRA)"},{"id":"http://arxiv.org/abs/2410.05591v2","updated":"2025-03-04T04:21:35Z","published":"2024-10-08T01:06:01Z","title":"TweedieMix: Improving Multi-Concept Fusion for Diffusion-based\n  Image/Video Generation","summary":"  Despite significant advancements in customizing text-to-image and video\ngeneration models, generating images and videos that effectively integrate\nmultiple personalized concepts remains a challenging task. To address this, we\npresent TweedieMix, a novel method for composing customized diffusion models\nduring the inference phase. By analyzing the properties of reverse diffusion\nsampling, our approach divides the sampling process into two stages. During the\ninitial steps, we apply a multiple object-aware sampling technique to ensure\nthe inclusion of the desired target objects. In the later steps, we blend the\nappearances of the custom concepts in the de-noised image space using Tweedie's\nformula. Our results demonstrate that TweedieMix can generate multiple\npersonalized concepts with higher fidelity than existing methods. Moreover, our\nframework can be effortlessly extended to image-to-video diffusion models,\nenabling the generation of videos that feature multiple personalized concepts.\nResults and source code are in our anonymous project page.\n","authors":["Gihyun Kwon","Jong Chul Ye"],"pdf_url":"https://arxiv.org/pdf/2410.05591v2.pdf","comment":"Github Page: https://github.com/KwonGihyun/TweedieMix"},{"id":"http://arxiv.org/abs/2410.06437v2","updated":"2025-03-04T23:49:01Z","published":"2024-10-09T00:45:02Z","title":"LocoVR: Multiuser Indoor Locomotion Dataset in Virtual Reality","summary":"  Understanding human locomotion is crucial for AI agents such as robots,\nparticularly in complex indoor home environments. Modeling human trajectories\nin these spaces requires insight into how individuals maneuver around physical\nobstacles and manage social navigation dynamics. These dynamics include subtle\nbehaviors influenced by proxemics - the social use of space, such as stepping\naside to allow others to pass or choosing longer routes to avoid collisions.\nPrevious research has developed datasets of human motion in indoor scenes, but\nthese are often limited in scale and lack the nuanced social navigation\ndynamics common in home environments. To address this, we present LocoVR, a\ndataset of 7000+ two-person trajectories captured in virtual reality from over\n130 different indoor home environments. LocoVR provides accurate trajectory\ndata and precise spatial information, along with rich examples of\nsocially-motivated movement behaviors. For example, the dataset captures\ninstances of individuals navigating around each other in narrow spaces,\nadjusting paths to respect personal boundaries in living areas, and\ncoordinating movements in high-traffic zones like entryways and kitchens. Our\nevaluation shows that LocoVR significantly enhances model performance in three\npractical indoor tasks utilizing human trajectories, and demonstrates\npredicting socially-aware navigation patterns in home environments.\n","authors":["Kojiro Takeyama","Yimeng Liu","Misha Sra"],"pdf_url":"https://arxiv.org/pdf/2410.06437v2.pdf","comment":"This paper has been accepted to ICLR2025"}],"Machine Learning":[{"id":"http://arxiv.org/abs/2407.06057v3","updated":"2025-03-04T14:33:50Z","published":"2024-07-08T15:59:44Z","title":"Variational Best-of-N Alignment","summary":"  Best-of-N (BoN) is a popular and effective algorithm for aligning language\nmodels to human preferences. The algorithm works as follows: at inference time,\nN samples are drawn from the language model, and the sample with the highest\nreward, as judged by a reward model, is returned as the output. Despite its\neffectiveness, BoN is computationally expensive; it reduces sampling throughput\nby a factor of N. To make BoN more efficient at inference time, one strategy is\nto fine-tune the language model to mimic what BoN does during inference. To\nachieve this, we derive the distribution induced by the BoN algorithm. We then\npropose to fine-tune the language model to minimize backward KL divergence to\nthe BoN distribution. Our approach is analogous to mean-field variational\ninference and, thus, we term it variational BoN (vBoN). To the extent this\nfine-tuning is successful and we end up with a good approximation, we have\nreduced the inference cost by a factor of N. Our experiments on controlled\ngeneration and summarization tasks show that BoN is the most effective\nalignment method, and our variational approximation to BoN achieves the closest\nperformance to BoN and surpasses models fine-tuned using the standard\nKL-constrained RL objective. In the controlled generation task, vBoN appears\nmore frequently on the Pareto frontier of reward and KL divergence compared to\nother alignment methods. In the summarization task, vBoN achieves high reward\nvalues across various sampling temperatures.\n","authors":["Afra Amini","Tim Vieira","Elliott Ash","Ryan Cotterell"],"pdf_url":"https://arxiv.org/pdf/2407.06057v3.pdf","comment":"Accepted at ICLR 2025"},{"id":"http://arxiv.org/abs/2411.12556v3","updated":"2025-03-04T09:56:09Z","published":"2024-11-19T15:15:45Z","title":"UMGAD: Unsupervised Multiplex Graph Anomaly Detection","summary":"  Graph anomaly detection (GAD) is a critical task in graph machine learning,\nwith the primary objective of identifying anomalous nodes that deviate\nsignificantly from the majority. This task is widely applied in various\nreal-world scenarios, including fraud detection and social network analysis.\nHowever, existing GAD methods still face two major challenges: (1) They are\noften limited to detecting anomalies in single-type interaction graphs and\nstruggle with multiple interaction types in multiplex heterogeneous graphs. (2)\nIn unsupervised scenarios, selecting appropriate anomaly score thresholds\nremains a significant challenge for accurate anomaly detection. To address the\nabove challenges, we propose a novel Unsupervised Multiplex Graph Anomaly\nDetection method, named UMGAD. We first learn multi-relational correlations\namong nodes in multiplex heterogeneous graphs and capture anomaly information\nduring node attribute and structure reconstruction through graph-masked\nautoencoder (GMAE). Then, to further extract abnormal information, we generate\nattribute-level and subgraph-level augmented-view graphs respectively, and\nperform attribute and structure reconstruction through GMAE. Finally, we learn\nto optimize node attributes and structural features through contrastive\nlearning between original-view and augmented-view graphs to improve the model's\nability to capture anomalies. Meanwhile, we also propose a new anomaly score\nthreshold selection strategy, which allows the model to be independent of\nground truth information in real unsupervised scenarios. Extensive experiments\non four datasets show that our UMGAD significantly outperforms state-of-the-art\nmethods, achieving average improvements of 13.48% in AUC and 11.68% in Macro-F1\nacross all datasets.\n","authors":["Xiang Li","Jianpeng Qi","Zhongying Zhao","Guanjie Zheng","Lei Cao","Junyu Dong","Yanwei Yu"],"pdf_url":"https://arxiv.org/pdf/2411.12556v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.02881v1","updated":"2025-03-04T18:58:21Z","published":"2025-03-04T18:58:21Z","title":"Reactive Diffusion Policy: Slow-Fast Visual-Tactile Policy Learning for\n  Contact-Rich Manipulation","summary":"  Humans can accomplish complex contact-rich tasks using vision and touch, with\nhighly reactive capabilities such as quick adjustments to environmental changes\nand adaptive control of contact forces; however, this remains challenging for\nrobots. Existing visual imitation learning (IL) approaches rely on action\nchunking to model complex behaviors, which lacks the ability to respond\ninstantly to real-time tactile feedback during the chunk execution.\nFurthermore, most teleoperation systems struggle to provide fine-grained\ntactile / force feedback, which limits the range of tasks that can be\nperformed. To address these challenges, we introduce TactAR, a low-cost\nteleoperation system that provides real-time tactile feedback through Augmented\nReality (AR), along with Reactive Diffusion Policy (RDP), a novel slow-fast\nvisual-tactile imitation learning algorithm for learning contact-rich\nmanipulation skills. RDP employs a two-level hierarchy: (1) a slow latent\ndiffusion policy for predicting high-level action chunks in latent space at low\nfrequency, (2) a fast asymmetric tokenizer for closed-loop tactile feedback\ncontrol at high frequency. This design enables both complex trajectory modeling\nand quick reactive behavior within a unified framework. Through extensive\nevaluation across three challenging contact-rich tasks, RDP significantly\nimproves performance compared to state-of-the-art visual IL baselines through\nrapid response to tactile / force feedback. Furthermore, experiments show that\nRDP is applicable across different tactile / force sensors. Code and videos are\navailable on https://reactive-diffusion-policy.github.io/.\n","authors":["Han Xue","Jieji Ren","Wendi Chen","Gu Zhang","Yuan Fang","Guoying Gu","Huazhe Xu","Cewu Lu"],"pdf_url":"https://arxiv.org/pdf/2503.02881v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.02880v1","updated":"2025-03-04T18:58:15Z","published":"2025-03-04T18:58:15Z","title":"A New $\\sim 5$ Tension at Characteristic Redshift from DESI DR1\n  and DES-SN5YR observations","summary":"  We perform a model-independent reconstruction of the angular diameter\ndistance ($D_{A}$) using the Multi-Task Gaussian Process (MTGP) framework with\nDESI-DR1 BAO and DES-SN5YR datasets. We calibrate the comoving sound horizon at\nthe baryon drag epoch $r_d$ to the Planck best-fit value, ensuring consistency\nwith early-universe physics. With the reconstructed $D_A$ at two key redshifts,\n$z\\sim 1.63$ (where $D_{A}^{\\prime} =0$) and at $z\\sim 0.512$ (where\n$D_{A}^{\\prime} = D_{A}$), we derive the expansion rate of the Universe $H(z)$\nat these redshifts. Our findings reveal that at $z\\sim 1.63$, the $H(z)$ is\nfully consistent with the Planck-2018 $\\Lambda$CDM prediction, confirming no\nnew physics at that redshift. However, at $z \\sim 0.512$, the derived $H(z)$\nshows a more than $5\\sigma$ discrepancy with the Planck-2018 $\\Lambda$CDM\nprediction, suggesting a possible breakdown of the $\\Lambda$CDM model as\nconstrained by Planck-2018 at this lower redshift. This emerging $\\sim 5\\sigma$\ntension at $z\\sim 0.512$, distinct from the existing ``Hubble Tension'', may\nsignal the first strong evidence for new physics at low redshifts.\n","authors":["Purba Mukherjee","Anjan A Sen"],"pdf_url":"https://arxiv.org/pdf/2503.02880v1.pdf","comment":"4 pages, 1 table, 1 figure. Comments are welcome"},{"id":"http://arxiv.org/abs/2503.02879v1","updated":"2025-03-04T18:58:13Z","published":"2025-03-04T18:58:13Z","title":"Wikipedia in the Era of LLMs: Evolution and Risks","summary":"  In this paper, we present a thorough analysis of the impact of Large Language\nModels (LLMs) on Wikipedia, examining the evolution of Wikipedia through\nexisting data and using simulations to explore potential risks. We begin by\nanalyzing page views and article content to study Wikipedia's recent changes\nand assess the impact of LLMs. Subsequently, we evaluate how LLMs affect\nvarious Natural Language Processing (NLP) tasks related to Wikipedia, including\nmachine translation and retrieval-augmented generation (RAG). Our findings and\nsimulation results reveal that Wikipedia articles have been influenced by LLMs,\nwith an impact of approximately 1%-2% in certain categories. If the machine\ntranslation benchmark based on Wikipedia is influenced by LLMs, the scores of\nthe models may become inflated, and the comparative results among models might\nshift as well. Moreover, the effectiveness of RAG might decrease if the\nknowledge base becomes polluted by LLM-generated content. While LLMs have not\nyet fully changed Wikipedia's language and knowledge structures, we believe\nthat our empirical findings signal the need for careful consideration of\npotential future risks.\n","authors":["Siming Huang","Yuliang Xu","Mingmeng Geng","Yao Wan","Dongping Chen"],"pdf_url":"https://arxiv.org/pdf/2503.02879v1.pdf","comment":"We release all the experimental dataset and source code at:\n  https://github.com/HSM316/LLM_Wikipedia"},{"id":"http://arxiv.org/abs/2503.02878v1","updated":"2025-03-04T18:58:11Z","published":"2025-03-04T18:58:11Z","title":"Language Models can Self-Improve at State-Value Estimation for Better\n  Search","summary":"  Collecting ground truth task completion rewards or human demonstrations for\nmulti-step reasoning tasks is often cost-prohibitive and time-consuming,\nespecially in interactive domains like web tasks. To address this bottleneck,\nwe present self-taught lookahead, a self-supervised method that leverages\nstate-transition dynamics to train a value model capable of effectively guiding\nlanguage model-controlled search. We find that moderately sized (8 billion\nparameters) open-weight value models improved with self-taught lookahead can\nmatch the performance of using a frontier LLM such as gpt-4o as the value\nmodel. Furthermore, we find that self-taught lookahead improves performance by\n20% while reducing costs 37x compared to previous LLM-based tree search,\nwithout relying on ground truth rewards.\n","authors":["Ethan Mendes","Alan Ritter"],"pdf_url":"https://arxiv.org/pdf/2503.02878v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.02877v1","updated":"2025-03-04T18:58:00Z","published":"2025-03-04T18:58:00Z","title":"Weak-to-Strong Generalization Even in Random Feature Networks, Provably","summary":"  Weak-to-Strong Generalization (Burns et al., 2024) is the phenomenon whereby\na strong student, say GPT-4, learns a task from a weak teacher, say GPT-2, and\nends up significantly outperforming the teacher. We show that this phenomenon\ndoes not require a strong learner like GPT-4. We consider student and teacher\nthat are random feature models, described by two-layer networks with a random\nand fixed bottom layer and a trained top layer. A \"weak\" teacher, with a small\nnumber of units (i.e. random features), is trained on the population, and a\n\"strong\" student, with a much larger number of units (i.e. random features), is\ntrained only on labels generated by the weak teacher. We demonstrate, prove,\nand understand how the student can outperform the teacher, even though trained\nonly on data labeled by the teacher. We also explain how such weak-to-strong\ngeneralization is enabled by early stopping. Importantly, we also show the\nquantitative limits of weak-to-strong generalization in this model.\n","authors":["Marko Medvedev","Kaifeng Lyu","Dingli Yu","Sanjeev Arora","Zhiyuan Li","Nathan Srebro"],"pdf_url":"https://arxiv.org/pdf/2503.02877v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.02979v3","updated":"2025-03-04T18:48:15Z","published":"2024-10-03T20:40:54Z","title":"Optimization, Isoperimetric Inequalities, and Sampling via Lyapunov\n  Potentials","summary":"  In this paper, we prove that optimizability of any F using Gradient Flow from\nall initializations implies a Poincar\\'e Inequality for Gibbs measures\nmu_{beta} = e^{-\\beta F}/Z at low temperature. In particular, under mild\nregularity assumptions on the convergence rate of Gradient Flow, we establish\nthat mu_{beta} satisfies a Poincar\\'e Inequality with constant O(C'+1/beta) for\nbeta >= Omega(d), where C' is the Poincar\\'e constant of mu_{beta} restricted\nto a neighborhood of the global minimizers of F. Under an additional mild\ncondition on F, we show that mu_{beta} satisfies a Log-Sobolev Inequality with\nconstant O(S beta C') where S denotes the second moment of mu_{beta}. Here\nasymptotic notation hides F-dependent parameters. At a high level, this\nestablishes that optimizability via Gradient Flow from every initialization\nimplies a Poincar\\'e and Log-Sobolev Inequality for the low-temperature Gibbs\nmeasure, which in turn imply sampling from all initializations.\n  Analogously, we establish that under the same assumptions, if F can be\ninitialized from everywhere except some set S, then mu_{beta} satisfies a Weak\nPoincar\\'e Inequality with parameters (C', mu_{beta}(S)) for \\beta = Omega(d).\nAt a high level, this shows while optimizability from 'most' initializations\nimplies a Weak Poincar\\'e Inequality, which in turn implies sampling from\nsuitable warm starts. Our regularity assumptions are mild and as a consequence,\nwe show we can efficiently sample from several new natural and interesting\nclasses of non-log-concave densities, an important setting with relatively few\nexamples. As another corollary, we obtain efficient discrete-time sampling\nresults for log-concave measures satisfying milder regularity conditions than\nsmoothness, similar to Lehec (2023).\n","authors":["August Y. Chen","Karthik Sridharan"],"pdf_url":"https://arxiv.org/pdf/2410.02979v3.pdf","comment":"52 pages. New version with new results on Weak Poincar\\'e\n  Inequalities and improved presentation"},{"id":"http://arxiv.org/abs/2503.02870v1","updated":"2025-03-04T18:47:54Z","published":"2025-03-04T18:47:54Z","title":"Multiaccuracy and Multicalibration via Proxy Groups","summary":"  As the use of predictive machine learning algorithms increases in high-stakes\ndecision-making, it is imperative that these algorithms are fair across\nsensitive groups. Unfortunately, measuring and enforcing fairness in real-world\napplications can be challenging due to missing or incomplete sensitive group\ndata. Proxy-sensitive attributes have been proposed as a practical and\neffective solution in these settings, but only for parity-based fairness\nnotions. Knowing how to evaluate and control for fairness with missing\nsensitive group data for newer and more flexible frameworks, such as\nmultiaccuracy and multicalibration, remains unexplored. In this work, we\naddress this gap by demonstrating that in the absence of sensitive group data,\nproxy-sensitive attributes can provably be used to derive actionable upper\nbounds on the true multiaccuracy and multicalibration, providing insights into\na model's potential worst-case fairness violations. Additionally, we show that\nadjusting models to satisfy multiaccuracy and multicalibration across\nproxy-sensitive attributes can significantly mitigate these violations for the\ntrue, but unknown, sensitive groups. Through several experiments on real-world\ndatasets, we illustrate that approximate multiaccuracy and multicalibration can\nbe achieved even when sensitive group information is incomplete or unavailable.\n","authors":["Beepul Bharti","Mary Versa Clemens-Sewall","Paul H. Yi","Jeremias Sulam"],"pdf_url":"https://arxiv.org/pdf/2503.02870v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.02863v1","updated":"2025-03-04T18:40:49Z","published":"2025-03-04T18:40:49Z","title":"Calibrating LLM Confidence with Semantic Steering: A Multi-Prompt\n  Aggregation Framework","summary":"  Large Language Models (LLMs) often exhibit misaligned confidence scores,\nusually overestimating the reliability of their predictions. While verbalized\nconfidence in Large Language Models (LLMs) has gained attention, prior work\nremains divided on whether confidence scores can be systematically steered\nthrough prompting. Recent studies even argue that such prompt-induced\nconfidence shifts are negligible, suggesting LLMs' confidence calibration is\nrigid to linguistic interventions. Contrary to these claims, we first\nrigorously confirm the existence of directional confidence shifts by probing\nthree models (including GPT3.5, LLAMA3-70b, GPT4) across 7 benchmarks,\ndemonstrating that explicit instructions can inflate or deflate confidence\nscores in a regulated manner. Based on this observation, we propose a novel\nframework containing three components: confidence steering, steered confidence\naggregation and steered answers selection, named SteeringConf. Our method,\nSteeringConf, leverages a confidence manipulation mechanism to steer the\nconfidence scores of LLMs in several desired directions, followed by a\nsummarization module that aggregates the steered confidence scores to produce a\nfinal prediction. We evaluate our method on 7 benchmarks and it consistently\noutperforms the baselines in terms of calibration metrics in task of confidence\ncalibration and failure detection.\n","authors":["Ziang Zhou","Tianyuan Jin","Jieming Shi","Qing Li"],"pdf_url":"https://arxiv.org/pdf/2503.02863v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.23637v2","updated":"2025-03-04T18:40:33Z","published":"2024-10-31T05:07:01Z","title":"Anytime-Constrained Equilibria in Polynomial Time","summary":"  We extend anytime constraints to the Markov game setting and the\ncorresponding solution concept of an anytime-constrained equilibrium (ACE).\nThen, we present a comprehensive theory of anytime-constrained equilibria that\nincludes (1) a computational characterization of feasible policies, (2) a\nfixed-parameter tractable algorithm for computing ACE, and (3) a\npolynomial-time algorithm for approximately computing ACE. Since computing a\nfeasible policy is NP-hard even for two-player zero-sum games, our\napproximation guarantees are optimal so long as $P \\neq NP$. We also develop\nthe first theory of efficient computation for action-constrained Markov games,\nwhich may be of independent interest.\n","authors":["Jeremy McMahan"],"pdf_url":"https://arxiv.org/pdf/2410.23637v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.02859v1","updated":"2025-03-04T18:34:55Z","published":"2025-03-04T18:34:55Z","title":"Unsupervised Attributed Dynamic Network Embedding with Stability\n  Guarantees","summary":"  Stability for dynamic network embeddings ensures that nodes behaving the same\nat different times receive the same embedding, allowing comparison of nodes in\nthe network across time. We present attributed unfolded adjacency spectral\nembedding (AUASE), a stable unsupervised representation learning framework for\ndynamic networks in which nodes are attributed with time-varying covariate\ninformation. To establish stability, we prove uniform convergence to an\nassociated latent position model. We quantify the benefits of our dynamic\nembedding by comparing with state-of-the-art network representation learning\nmethods on three real attributed networks. To the best of our knowledge, AUASE\nis the only attributed dynamic embedding that satisfies stability guarantees\nwithout the need for ground truth labels, which we demonstrate provides\nsignificant improvements for link prediction and node classification.\n","authors":["Emma Ceccherini","Ian Gallagher","Andrew Jones","Daniel Lawson"],"pdf_url":"https://arxiv.org/pdf/2503.02859v1.pdf","comment":"27 pages, 5 figures"},{"id":"http://arxiv.org/abs/2502.20499v2","updated":"2025-03-04T18:33:01Z","published":"2025-02-27T20:14:01Z","title":"Data Distributional Properties As Inductive Bias for Systematic\n  Generalization","summary":"  Deep neural networks (DNNs) struggle at systematic generalization (SG).\nSeveral studies have evaluated the possibility to promote SG through the\nproposal of novel architectures, loss functions or training methodologies. Few\nstudies, however, have focused on the role of training data properties in\npromoting SG. In this work, we investigate the impact of certain data\ndistributional properties, as inductive biases for the SG ability of a\nmulti-modal language model. To this end, we study three different properties.\nFirst, data diversity, instantiated as an increase in the possible values a\nlatent property in the training distribution may take. Second, burstiness,\nwhere we probabilistically restrict the number of possible values of latent\nfactors on particular inputs during training. Third, latent intervention, where\na particular latent factor is altered randomly during training. We find that\nall three factors significantly enhance SG, with diversity contributing an 89%\nabsolute increase in accuracy in the most affected property. Through a series\nof experiments, we test various hypotheses to understand why these properties\npromote SG. Finally, we find that Normalized Mutual Information (NMI) between\nlatent attributes in the training distribution is strongly predictive of\nout-of-distribution generalization. We find that a mechanism by which lower NMI\ninduces SG is in the geometry of representations. In particular, we find that\nNMI induces more parallelism in neural representations (i.e., input features\ncoded in parallel neural vectors) of the model, a property related to the\ncapacity of reasoning by analogy.\n","authors":["Felipe del Ro","Alain Raymond-Sez","Daniel Florea","Rodrigo Toro Icarte","Julio Hurtado","Cristin Buc Caldern","lvaro Soto"],"pdf_url":"https://arxiv.org/pdf/2502.20499v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.02854v1","updated":"2025-03-04T18:31:02Z","published":"2025-03-04T18:31:02Z","title":"(How) Do Language Models Track State?","summary":"  Transformer language models (LMs) exhibit behaviors -- from storytelling to\ncode generation -- that appear to require tracking the unobserved state of an\nevolving world. How do they do so? We study state tracking in LMs trained or\nfine-tuned to compose permutations (i.e., to compute the order of a set of\nobjects after a sequence of swaps). Despite the simple algebraic structure of\nthis problem, many other tasks (e.g., simulation of finite automata and\nevaluation of boolean expressions) can be reduced to permutation composition,\nmaking it a natural model for state tracking in general. We show that LMs\nconsistently learn one of two state tracking mechanisms for this task. The\nfirst closely resembles the \"associative scan\" construction used in recent\ntheoretical work by Liu et al. (2023) and Merrill et al. (2024). The second\nuses an easy-to-compute feature (permutation parity) to partially prune the\nspace of outputs, then refines this with an associative scan. The two\nmechanisms exhibit markedly different robustness properties, and we show how to\nsteer LMs toward one or the other with intermediate training tasks that\nencourage or suppress the heuristics. Our results demonstrate that transformer\nLMs, whether pretrained or fine-tuned, can learn to implement efficient and\ninterpretable state tracking mechanisms, and the emergence of these mechanisms\ncan be predicted and controlled.\n","authors":["Belinda Z. Li","Zifan Carl Guo","Jacob Andreas"],"pdf_url":"https://arxiv.org/pdf/2503.02854v1.pdf","comment":"21 pages, 17 figures, 1 table"},{"id":"http://arxiv.org/abs/2503.02844v1","updated":"2025-03-04T18:15:57Z","published":"2025-03-04T18:15:57Z","title":"Beyond Cosine Decay: On the effectiveness of Infinite Learning Rate\n  Schedule for Continual Pre-training","summary":"  The ever-growing availability of unlabeled data presents both opportunities\nand challenges for training artificial intelligence systems. While\nself-supervised learning (SSL) has emerged as a powerful paradigm for\nextracting meaningful representations from vast amounts of unlabeled data,\nexisting methods still struggle to adapt to the non-stationary, non-IID nature\nof real-world data streams without forgetting previously learned knowledge.\nRecent works have adopted a repeated cosine annealing schedule for large-scale\ncontinual pre-training; however, these schedules (1) inherently cause\nforgetting during the re-warming phase and (2) have not been systematically\ncompared to existing continual SSL methods. In this work, we systematically\ncompare the widely used cosine schedule with the recently proposed infinite\nlearning rate schedule and empirically find the latter to be a more effective\nalternative. Our extensive empirical evaluation across diverse image and\nlanguage datasets demonstrates that the infinite learning rate schedule\nconsistently enhances continual pre-training performance compared to a repeated\ncosine decay without being restricted to a fixed iteration budget. For\ninstance, in a small-scale MAE pre-training setup, it outperforms several\nstrong baselines from the literature. We then scale up our experiments to\nlarger MAE pre-training and autoregressive language model pre-training. Our\nresults show that the infinite learning rate schedule remains effective at\nscale, surpassing repeated cosine decay for both MAE pre-training and zero-shot\nLM benchmarks.\n","authors":["Paul Janson","Vaibhav Singh","Paria Mehrbod","Adam Ibrahim","Irina Rish","Eugene Belilovsky","Benjamin Thrien"],"pdf_url":"https://arxiv.org/pdf/2503.02844v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.01335v2","updated":"2025-03-04T18:15:16Z","published":"2024-10-02T08:53:07Z","title":"Layer Swapping for Zero-Shot Cross-Lingual Transfer in Large Language\n  Models","summary":"  Model merging, such as model souping, is the practice of combining different\nmodels with the same architecture together without further training. In this\nwork, we present a model merging methodology that addresses the difficulty of\nfine-tuning Large Language Models (LLMs) for target tasks in non-English\nlanguages, where task-specific data is often unavailable. We focus on\nmathematical reasoning and without in-language math data, facilitate\ncross-lingual transfer by composing language and math capabilities. Starting\nfrom the same pretrained model, we fine-tune separate \"experts\" on math\ninstruction data in English and on generic instruction data in the target\nlanguage. We then replace the top and bottom transformer layers of the math\nexpert directly with layers from the language expert, which consequently\nenhances math performance in the target language. The resulting merged models\noutperform the individual experts and other merging methods on the math\nbenchmark, MGSM, by 10% across four major languages where math instruction data\nis scarce. In addition, this layer swapping is simple, inexpensive, and\nintuitive, as it is based on an interpretative analysis of the most important\nparameter changes during the fine-tuning of each expert. The ability to\nsuccessfully re-compose LLMs for cross-lingual transfer in this manner opens up\nfuture possibilities to combine model expertise, create modular solutions, and\ntransfer reasoning capabilities across languages all post hoc.\n","authors":["Lucas Bandarkar","Benjamin Muller","Pritish Yuvraj","Rui Hou","Nayan Singhal","Hongjiang Lv","Bing Liu"],"pdf_url":"https://arxiv.org/pdf/2410.01335v2.pdf","comment":"ICLR 2025, Spotlight Paper, In The Thirteenth International\n  Conference on Learning Representations, 2025"},{"id":"http://arxiv.org/abs/2311.00676v2","updated":"2025-03-04T18:13:47Z","published":"2023-11-01T17:34:58Z","title":"Last-Iterate Convergence Properties of Regret-Matching Algorithms in\n  Games","summary":"  We study last-iterate convergence properties of algorithms for solving\ntwo-player zero-sum games based on Regret Matching$^+$ (RM$^+$). Despite their\nwidespread use for solving real games, virtually nothing is known about their\nlast-iterate convergence. A major obstacle to analyzing RM-type dynamics is\nthat their regret operators lack Lipschitzness and (pseudo)monotonicity. We\nstart by showing numerically that several variants used in practice, such as\nRM$^+$, predictive RM$^+$ and alternating RM$^+$, all lack last-iterate\nconvergence guarantees even on a simple $3\\times 3$ matrix game. We then prove\nthat recent variants of these algorithms based on a smoothing technique,\nextragradient RM$^{+}$ and smooth Predictive RM$^+$, enjoy asymptotic\nlast-iterate convergence (without a rate), $1/\\sqrt{t}$ best-iterate\nconvergence, and when combined with restarting, linear-rate last-iterate\nconvergence. Our analysis builds on a new characterization of the geometric\nstructure of the limit points of our algorithms, marking a significant\ndeparture from most of the literature on last-iterate convergence. We believe\nthat our analysis may be of independent interest and offers a fresh perspective\nfor studying last-iterate convergence in algorithms based on non-monotone\noperators.\n","authors":["Yang Cai","Gabriele Farina","Julien Grand-Clment","Christian Kroer","Chung-Wei Lee","Haipeng Luo","Weiqiang Zheng"],"pdf_url":"https://arxiv.org/pdf/2311.00676v2.pdf","comment":"Accepted to ICLR 2025"},{"id":"http://arxiv.org/abs/2406.05516v3","updated":"2025-03-04T18:07:34Z","published":"2024-06-08T16:35:31Z","title":"Verbalized Probabilistic Graphical Modeling","summary":"  Human cognition excels at transcending sensory input and forming latent\nrepresentations that structure our understanding of the world. Although Large\nLanguage Models (LLMs) can produce chain-of-thought reasoning, they lack a\nprincipled framework to capture latent structures and model uncertainty,\nespecially in compositional reasoning tasks. We propose Verbalized\nProbabilistic Graphical Modeling (vPGM), a Bayesian prompting framework that\nguides LLMs to simulate key principles of Probabilistic Graphical Models (PGMs)\nin natural language. Unlike many traditional probabilistic methods requiring\nsubstantial domain expertise or specialized training, vPGM bypasses\nexpert-driven model design, making it well-suited for scenarios with limited\nassumptions or scarce data. We evaluated our model on several compositional\nreasoning tasks, both close-ended and open-ended. Our results indicate that the\nmodel effectively enhances confidence calibration and text generation quality.\n","authors":["Hengguan Huang","Xing Shen","Songtao Wang","Lingfa Meng","Dianbo Liu","Hao Wang","Samir Bhatt"],"pdf_url":"https://arxiv.org/pdf/2406.05516v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.02836v1","updated":"2025-03-04T17:59:17Z","published":"2025-03-04T17:59:17Z","title":"SeqFusion: Sequential Fusion of Pre-Trained Models for Zero-Shot\n  Time-Series Forecasting","summary":"  Unlike traditional time-series forecasting methods that require extensive\nin-task data for training, zero-shot forecasting can directly predict future\nvalues given a target time series without additional training data. Current\nzero-shot approaches primarily rely on pre-trained generalized models, with\ntheir performance often depending on the variety and relevance of the\npre-training data, which can raise privacy concerns. Instead of collecting\ndiverse pre-training data, we introduce SeqFusion in this work, a novel\nframework that collects and fuses diverse pre-trained models (PTMs)\nsequentially for zero-shot forecasting. Based on the specific temporal\ncharacteristics of the target time series, SeqFusion selects the most suitable\nPTMs from a batch of pre-collected PTMs, performs sequential predictions, and\nfuses all the predictions while using minimal data to protect privacy. Each of\nthese PTMs specializes in different temporal patterns and forecasting tasks,\nallowing SeqFusion to select by measuring distances in a shared representation\nspace of the target time series with each PTM. Experiments demonstrate that\nSeqFusion achieves competitive accuracy in zero-shot forecasting compared to\nstate-of-the-art methods.\n","authors":["Ting-Ji Huang","Xu-Yang Chen","Han-Jia Ye"],"pdf_url":"https://arxiv.org/pdf/2503.02836v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.02832v1","updated":"2025-03-04T17:57:09Z","published":"2025-03-04T17:57:09Z","title":"AlignDistil: Token-Level Language Model Alignment as Adaptive Policy\n  Distillation","summary":"  In modern large language models (LLMs), LLM alignment is of crucial\nimportance and is typically achieved through methods such as reinforcement\nlearning from human feedback (RLHF) and direct preference optimization (DPO).\nHowever, in most existing methods for LLM alignment, all tokens in the response\nare optimized using a sparse, response-level reward or preference annotation.\nThe ignorance of token-level rewards may erroneously punish high-quality tokens\nor encourage low-quality tokens, resulting in suboptimal performance and slow\nconvergence speed. To address this issue, we propose AlignDistil, an\nRLHF-equivalent distillation method for token-level reward optimization.\nSpecifically, we introduce the reward learned by DPO into the RLHF objective\nand theoretically prove the equivalence between this objective and a\ntoken-level distillation process, where the teacher distribution linearly\ncombines the logits from the DPO model and a reference model. On this basis, we\nfurther bridge the accuracy gap between the reward from the DPO model and the\npure reward model, by building a contrastive DPO reward with a normal and a\nreverse DPO model. Moreover, to avoid under- and over-optimization on different\ntokens, we design a token adaptive logit extrapolation mechanism to construct\nan appropriate teacher distribution for each token. Experimental results\ndemonstrate the superiority of our AlignDistil over existing methods and\nshowcase fast convergence due to its token-level distributional reward\noptimization.\n","authors":["Songming Zhang","Xue Zhang","Tong Zhang","Bojie Hu","Yufeng Chen","Jinan Xu"],"pdf_url":"https://arxiv.org/pdf/2503.02832v1.pdf","comment":"15 pages, 2 figures"},{"id":"http://arxiv.org/abs/2303.13326v2","updated":"2025-03-04T17:56:58Z","published":"2023-03-23T15:05:16Z","title":"Decentralized Adversarial Training over Graphs","summary":"  The vulnerability of machine learning models to adversarial attacks has been\nattracting considerable attention in recent years. Most existing studies focus\non the behavior of stand-alone single-agent learners. In comparison, this work\nstudies adversarial training over graphs, where individual agents are subjected\nto perturbations of varied strength levels across space. It is expected that\ninteractions by linked agents, and the heterogeneity of the attack models that\nare possible over the graph, can help enhance robustness in view of the\ncoordination power of the group. Using a min-max formulation of distributed\nlearning, we develop a decentralized adversarial training framework for\nmulti-agent systems. Specifically, we devise two decentralized adversarial\ntraining algorithms by relying on two popular decentralized learning\nstrategies--diffusion and consensus. We analyze the convergence properties of\nthe proposed framework for strongly-convex, convex, and non-convex\nenvironments, and illustrate the enhanced robustness to adversarial attacks.\n","authors":["Ying Cao","Elsa Rizk","Stefan Vlaski","Ali H. Sayed"],"pdf_url":"https://arxiv.org/pdf/2303.13326v2.pdf","comment":"arXiv admin note: text overlap with arXiv:2303.01936"},{"id":"http://arxiv.org/abs/2503.02831v1","updated":"2025-03-04T17:55:38Z","published":"2025-03-04T17:55:38Z","title":"Meta-Learning to Explore via Memory Density Feedback","summary":"  Exploration algorithms for reinforcement learning typically replace or\naugment the reward function with an additional ``intrinsic'' reward that trains\nthe agent to seek previously unseen states of the environment. Here, we\nconsider an exploration algorithm that exploits meta-learning, or learning to\nlearn, such that the agent learns to maximize its exploration progress within a\nsingle episode, even between epochs of training. The agent learns a policy that\naims to minimize the probability density of new observations with respect to\nall of its memories. In addition, it receives as feedback evaluations of the\ncurrent observation density and retains that feedback in a recurrent network.\nBy remembering trajectories of density, the agent learns to navigate a complex\nand growing landscape of familiarity in real-time, allowing it to maximize its\nexploration progress even in completely novel states of the environment for\nwhich its policy has not been trained.\n","authors":["Kevin L. McKee"],"pdf_url":"https://arxiv.org/pdf/2503.02831v1.pdf","comment":"15 pages, 6 figures"},{"id":"http://arxiv.org/abs/2503.00080v2","updated":"2025-03-04T17:54:00Z","published":"2025-02-28T03:38:45Z","title":"Exploring the Potential of QEEGNet for Cross-Task and Cross-Dataset\n  Electroencephalography Encoding with Quantum Machine Learning","summary":"  Electroencephalography (EEG) is widely used in neuroscience and clinical\nresearch for analyzing brain activity. While deep learning models such as\nEEGNet have shown success in decoding EEG signals, they often struggle with\ndata complexity, inter-subject variability, and noise robustness. Recent\nadvancements in quantum machine learning (QML) offer new opportunities to\nenhance EEG analysis by leveraging quantum computing's unique properties. In\nthis study, we extend the previously proposed Quantum-EEGNet (QEEGNet), a\nhybrid neural network incorporating quantum layers into EEGNet, to investigate\nits generalization ability across multiple EEG datasets. Our evaluation spans a\ndiverse set of cognitive and motor task datasets, assessing QEEGNet's\nperformance in different learning scenarios. Experimental results reveal that\nwhile QEEGNet demonstrates competitive performance and maintains robustness in\ncertain datasets, its improvements over traditional deep learning methods\nremain inconsistent. These findings suggest that hybrid quantum-classical\narchitectures require further optimization to fully leverage quantum advantages\nin EEG processing. Despite these limitations, our study provides new insights\ninto the applicability of QML in EEG research and highlights challenges that\nmust be addressed for future advancements.\n","authors":["Chi-Sheng Chen","Samuel Yen-Chi Chen","Huan-Hsin Tseng"],"pdf_url":"https://arxiv.org/pdf/2503.00080v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.02825v1","updated":"2025-03-04T17:49:24Z","published":"2025-03-04T17:49:24Z","title":"On Separation Between Best-Iterate, Random-Iterate, and Last-Iterate\n  Convergence of Learning in Games","summary":"  Non-ergodic convergence of learning dynamics in games is widely studied\nrecently because of its importance in both theory and practice. Recent work\n(Cai et al., 2024) showed that a broad class of learning dynamics, including\nOptimistic Multiplicative Weights Update (OMWU), can exhibit arbitrarily slow\nlast-iterate convergence even in simple $2 \\times 2$ matrix games, despite many\nof these dynamics being known to converge asymptotically in the last iterate.\nIt remains unclear, however, whether these algorithms achieve fast non-ergodic\nconvergence under weaker criteria, such as best-iterate convergence. We show\nthat for $2\\times 2$ matrix games, OMWU achieves an $O(T^{-1/6})$ best-iterate\nconvergence rate, in stark contrast to its slow last-iterate convergence in the\nsame class of games. Furthermore, we establish a lower bound showing that OMWU\ndoes not achieve any polynomial random-iterate convergence rate, measured by\nthe expected duality gaps across all iterates. This result challenges the\nconventional wisdom that random-iterate convergence is essentially equivalent\nto best-iterate convergence, with the former often used as a proxy for\nestablishing the latter. Our analysis uncovers a new connection to dynamic\nregret and presents a novel two-phase approach to best-iterate convergence,\nwhich could be of independent interest.\n","authors":["Yang Cai","Gabriele Farina","Julien Grand-Clment","Christian Kroer","Chung-Wei Lee","Haipeng Luo","Weiqiang Zheng"],"pdf_url":"https://arxiv.org/pdf/2503.02825v1.pdf","comment":"33 pages"},{"id":"http://arxiv.org/abs/2503.02819v1","updated":"2025-03-04T17:46:51Z","published":"2025-03-04T17:46:51Z","title":"Feynman-Kac Correctors in Diffusion: Annealing, Guidance, and Product of\n  Experts","summary":"  While score-based generative models are the model of choice across diverse\ndomains, there are limited tools available for controlling inference-time\nbehavior in a principled manner, e.g. for composing multiple pretrained models.\nExisting classifier-free guidance methods use a simple heuristic to mix\nconditional and unconditional scores to approximately sample from conditional\ndistributions. However, such methods do not approximate the intermediate\ndistributions, necessitating additional 'corrector' steps. In this work, we\nprovide an efficient and principled method for sampling from a sequence of\nannealed, geometric-averaged, or product distributions derived from pretrained\nscore-based models. We derive a weighted simulation scheme which we call\nFeynman-Kac Correctors (FKCs) based on the celebrated Feynman-Kac formula by\ncarefully accounting for terms in the appropriate partial differential\nequations (PDEs). To simulate these PDEs, we propose Sequential Monte Carlo\n(SMC) resampling algorithms that leverage inference-time scaling to improve\nsampling quality. We empirically demonstrate the utility of our methods by\nproposing amortized sampling via inference-time temperature annealing,\nimproving multi-objective molecule generation using pretrained models, and\nimproving classifier-free guidance for text-to-image generation. Our code is\navailable at https://github.com/martaskrt/fkc-diffusion.\n","authors":["Marta Skreta","Tara Akhound-Sadegh","Viktor Ohanesian","Roberto Bondesan","Aln Aspuru-Guzik","Arnaud Doucet","Rob Brekelmans","Alexander Tong","Kirill Neklyudov"],"pdf_url":"https://arxiv.org/pdf/2503.02819v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.02809v1","updated":"2025-03-04T17:35:13Z","published":"2025-03-04T17:35:13Z","title":"A Minimalist Example of Edge-of-Stability and Progressive Sharpening","summary":"  Recent advances in deep learning optimization have unveiled two intriguing\nphenomena under large learning rates: Edge of Stability (EoS) and Progressive\nSharpening (PS), challenging classical Gradient Descent (GD) analyses. Current\nresearch approaches, using either generalist frameworks or minimalist examples,\nface significant limitations in explaining these phenomena. This paper advances\nthe minimalist approach by introducing a two-layer network with a\ntwo-dimensional input, where one dimension is relevant to the response and the\nother is irrelevant. Through this model, we rigorously prove the existence of\nprogressive sharpening and self-stabilization under large learning rates, and\nestablish non-asymptotic analysis of the training dynamics and sharpness along\nthe entire GD trajectory. Besides, we connect our minimalist example to\nexisting works by reconciling the existence of a well-behaved ``stable set\"\nbetween minimalist and generalist analyses, and extending the analysis of\nGradient Flow Solution sharpness to our two-dimensional input scenario. These\nfindings provide new insights into the EoS phenomenon from both parameter and\ninput data distribution perspectives, potentially informing more effective\noptimization strategies in deep learning practice.\n","authors":["Liming Liu","Zixuan Zhang","Simon Du","Tuo Zhao"],"pdf_url":"https://arxiv.org/pdf/2503.02809v1.pdf","comment":"39 pages, 15 figures"},{"id":"http://arxiv.org/abs/2412.05313v6","updated":"2025-03-04T17:33:11Z","published":"2024-11-28T19:31:50Z","title":": A Benchmark for Data-Efficiency in Long-Horizon Indoor Mobile\n  Manipulation Robotics","summary":"  Learning to execute long-horizon mobile manipulation tasks is crucial for\nadvancing robotics in household and workplace settings. However, current\napproaches are typically data-inefficient, underscoring the need for improved\nmodels that require realistically sized benchmarks to evaluate their\nefficiency. To address this, we introduce the LAMBDA ({\\lambda})\nbenchmark-Long-horizon Actions for Mobile-manipulation Benchmarking of Directed\nActivities-which evaluates the data efficiency of models on\nlanguage-conditioned, long-horizon, multi-room, multi-floor, pick-and-place\ntasks using a dataset of manageable size, more feasible for collection. Our\nbenchmark includes 571 human-collected demonstrations that provide realism and\ndiversity in simulated and real-world settings. Unlike planner-generated data,\nthese trajectories offer natural variability and replay-verifiability, ensuring\nrobust learning and evaluation. We leverage LAMBDA to benchmark current\nend-to-end learning methods and a modular neuro-symbolic approaches that\ncombines foundation models with task and motion planning. We find that\nend-to-end methods-even when pretrained-yield lower success rates, while\nneuro-symbolic methods perform significantly better and require less data.\n","authors":["Ahmed Jaafar","Shreyas Sundara Raman","Yichen Wei","Sudarshan Harithas","Sofia Juliani","Anneke Wernerfelt","Benedict Quartey","Ifrah Idrees","Jason Xinyu Liu","Stefanie Tellex"],"pdf_url":"https://arxiv.org/pdf/2412.05313v6.pdf","comment":"8 pages"},{"id":"http://arxiv.org/abs/2209.11691v6","updated":"2025-03-04T17:30:58Z","published":"2022-09-23T16:11:09Z","title":"Linear Multidimensional Regression with Interactive Fixed-Effects","summary":"  This paper studies a linear model for multidimensional panel data of three or\nmore dimensions with unobserved interactive fixed-effects. The main estimator\nuses double debias methods, and requires two preliminary steps. First, the\nmodel is embedded within a two-dimensional panel framework where factor model\nmethods in Bai (2009) lead to consistent, but slowly converging, estimates. The\nsecond step develops a weighted-within transformation that is robust to\nmultidimensional interactive fixed-effects and achieves the parametric rate of\nconsistency. This is combined with a double debias procedure for asymptotically\nnormal estimates. The methods are implemented to estimate the demand elasticity\nfor beer.\n","authors":["Hugo Freeman"],"pdf_url":"https://arxiv.org/pdf/2209.11691v6.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.02803v1","updated":"2025-03-04T17:26:25Z","published":"2025-03-04T17:26:25Z","title":"Inductive randomness predictors","summary":"  This paper introduces inductive randomness predictors, which form a superset\nof inductive conformal predictors. Its focus is on a very simple special case,\nbinary inductive randomness predictors. It is interesting that binary inductive\nrandomness predictors have an advantage over inductive conformal predictors,\nalthough they also have a serious disadvantage. This advantage will allow us to\nreach the surprising conclusion that non-trivial inductive conformal predictors\nare inadmissible in the sense of statistical decision theory.\n","authors":["Vladimir Vovk"],"pdf_url":"https://arxiv.org/pdf/2503.02803v1.pdf","comment":"10 pages, 1 table"},{"id":"http://arxiv.org/abs/2311.12836v2","updated":"2025-03-04T17:24:53Z","published":"2023-10-03T16:09:07Z","title":"AI-based association analysis for medical imaging using latent-space\n  geometric confounder correction","summary":"  This study addresses the challenges of confounding effects and\ninterpretability in artificial-intelligence-based medical image analysis.\nWhereas existing literature often resolves confounding by removing\nconfounder-related information from latent representations, this strategy risks\naffecting image reconstruction quality in generative models, thus limiting\ntheir applicability in feature visualization. To tackle this, we propose a\ndifferent strategy that retains confounder-related information in latent\nrepresentations while finding an alternative confounder-free representation of\nthe image data.\n  Our approach views the latent space of an autoencoder as a vector space,\nwhere imaging-related variables, such as the learning target (t) and confounder\n(c), have a vector capturing their variability. The confounding problem is\naddressed by searching a confounder-free vector which is orthogonal to the\nconfounder-related vector but maximally collinear to the target-related vector.\nTo achieve this, we introduce a novel correlation-based loss that not only\nperforms vector searching in the latent space, but also encourages the encoder\nto generate latent representations linearly correlated with the variables.\nSubsequently, we interpret the confounder-free representation by sampling and\nreconstructing images along the confounder-free vector.\n  The efficacy and flexibility of our proposed method are demonstrated across\nthree applications, accommodating multiple confounders and utilizing diverse\nimage modalities. Results affirm the method's effectiveness in reducing\nconfounder influences, preventing wrong or misleading associations, and\noffering a unique visual interpretation for in-depth investigations by clinical\nand epidemiological researchers. The code is released in the following GitLab\nrepository:\nhttps://gitlab.com/radiology/compopbio/ai_based_association_analysis}\n","authors":["Xianjing Liu","Bo Li","Meike W. Vernooij","Eppo B. Wolvius","Gennady V. Roshchupkin","Esther E. Bron"],"pdf_url":"https://arxiv.org/pdf/2311.12836v2.pdf","comment":"Accepted by Medical Image Analysis"},{"id":"http://arxiv.org/abs/2410.02098v5","updated":"2025-03-04T17:23:51Z","published":"2024-10-02T23:39:10Z","title":"EC-DIT: Scaling Diffusion Transformers with Adaptive Expert-Choice\n  Routing","summary":"  Diffusion transformers have been widely adopted for text-to-image synthesis.\nWhile scaling these models up to billions of parameters shows promise, the\neffectiveness of scaling beyond current sizes remains underexplored and\nchallenging. By explicitly exploiting the computational heterogeneity of image\ngenerations, we develop a new family of Mixture-of-Experts (MoE) models\n(EC-DIT) for diffusion transformers with expert-choice routing. EC-DIT learns\nto adaptively optimize the compute allocated to understand the input texts and\ngenerate the respective image patches, enabling heterogeneous computation\naligned with varying text-image complexities. This heterogeneity provides an\nefficient way of scaling EC-DIT up to 97 billion parameters and achieving\nsignificant improvements in training convergence, text-to-image alignment, and\noverall generation quality over dense models and conventional MoE models.\nThrough extensive ablations, we show that EC-DIT demonstrates superior\nscalability and adaptive compute allocation by recognizing varying textual\nimportance through end-to-end training. Notably, in text-to-image alignment\nevaluation, our largest models achieve a state-of-the-art GenEval score of\n71.68% and still maintain competitive inference speed with intuitive\ninterpretability.\n","authors":["Haotian Sun","Tao Lei","Bowen Zhang","Yanghao Li","Haoshuo Huang","Ruoming Pang","Bo Dai","Nan Du"],"pdf_url":"https://arxiv.org/pdf/2410.02098v5.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.02800v1","updated":"2025-03-04T17:20:43Z","published":"2025-03-04T17:20:43Z","title":"RAAD-LLM: Adaptive Anomaly Detection Using LLMs and RAG Integration","summary":"  Anomaly detection in complex industrial environments poses unique challenges,\nparticularly in contexts characterized by data sparsity and evolving\noperational conditions. Predictive maintenance (PdM) in such settings demands\nmethodologies that are adaptive, transferable, and capable of integrating\ndomain-specific knowledge. In this paper, we present RAAD-LLM, a novel\nframework for adaptive anomaly detection, leveraging large language models\n(LLMs) integrated with Retrieval-Augmented Generation (RAG). This approach\naddresses the aforementioned PdM challenges. By effectively utilizing\ndomain-specific knowledge, RAAD-LLM enhances the detection of anomalies in time\nseries data without requiring fine-tuning on specific datasets. The framework's\nadaptability mechanism enables it to adjust its understanding of normal\noperating conditions dynamically, thus increasing detection accuracy. We\nvalidate this methodology through a real-world application for a plastics\nmanufacturing plant and the Skoltech Anomaly Benchmark (SKAB). Results show\nsignificant improvements over our previous model with an accuracy increase from\n70.7 to 89.1 on the real-world dataset. By allowing for the enriching of input\nseries data with semantics, RAAD-LLM incorporates multimodal capabilities that\nfacilitate more collaborative decision-making between the model and plant\noperators. Overall, our findings support RAAD-LLM's ability to revolutionize\nanomaly detection methodologies in PdM, potentially leading to a paradigm shift\nin how anomaly detection is implemented across various industries.\n","authors":["Alicia Russell-Gilbert","Sudip Mittal","Shahram Rahimi","Maria Seale","Joseph Jabour","Thomas Arnold","Joshua Church"],"pdf_url":"https://arxiv.org/pdf/2503.02800v1.pdf","comment":"arXiv admin note: substantial text overlap with arXiv:2411.00914"},{"id":"http://arxiv.org/abs/2503.02798v1","updated":"2025-03-04T17:16:07Z","published":"2025-03-04T17:16:07Z","title":"Spike-and-Slab Posterior Sampling in High Dimensions","summary":"  Posterior sampling with the spike-and-slab prior [MB88], a popular multimodal\ndistribution used to model uncertainty in variable selection, is considered the\ntheoretical gold standard method for Bayesian sparse linear regression [CPS09,\nRoc18]. However, designing provable algorithms for performing this sampling\ntask is notoriously challenging. Existing posterior samplers for Bayesian\nsparse variable selection tasks either require strong assumptions about the\nsignal-to-noise ratio (SNR) [YWJ16], only work when the measurement count grows\nat least linearly in the dimension [MW24], or rely on heuristic approximations\nto the posterior. We give the first provable algorithms for spike-and-slab\nposterior sampling that apply for any SNR, and use a measurement count\nsublinear in the problem dimension. Concretely, assume we are given a\nmeasurement matrix $\\mathbf{X} \\in \\mathbb{R}^{n\\times d}$ and noisy\nobservations $\\mathbf{y} = \\mathbf{X}\\mathbf{\\theta}^\\star + \\mathbf{\\xi}$ of a\nsignal $\\mathbf{\\theta}^\\star$ drawn from a spike-and-slab prior $\\pi$ with a\nGaussian diffuse density and expected sparsity k, where $\\mathbf{\\xi} \\sim\n\\mathcal{N}(\\mathbb{0}_n, \\sigma^2\\mathbf{I}_n)$. We give a polynomial-time\nhigh-accuracy sampler for the posterior $\\pi(\\cdot \\mid \\mathbf{X},\n\\mathbf{y})$, for any SNR $\\sigma^{-1}$ > 0, as long as $n \\geq k^3 \\cdot\n\\text{polylog}(d)$ and $X$ is drawn from a matrix ensemble satisfying the\nrestricted isometry property. We further give a sampler that runs in\nnear-linear time $\\approx nd$ in the same setting, as long as $n \\geq k^5 \\cdot\n\\text{polylog}(d)$. To demonstrate the flexibility of our framework, we extend\nour result to spike-and-slab posterior sampling with Laplace diffuse densities,\nachieving similar guarantees when $\\sigma = O(\\frac{1}{k})$ is bounded.\n","authors":["Syamantak Kumar","Purnamrita Sarkar","Kevin Tian","Yusong Zhu"],"pdf_url":"https://arxiv.org/pdf/2503.02798v1.pdf","comment":"53 pages"},{"id":"http://arxiv.org/abs/2503.02783v1","updated":"2025-03-04T16:56:34Z","published":"2025-03-04T16:56:34Z","title":"IterPref: Focal Preference Learning for Code Generation via Iterative\n  Debugging","summary":"  Preference learning enhances Code LLMs beyond supervised fine-tuning by\nleveraging relative quality comparisons. Existing methods construct preference\npairs from\n  candidates based on test case success, treating the higher pass rate sample\nas positive and the lower as negative. However, this approach does not pinpoint\nspecific errors in the code, which prevents the model from learning more\ninformative error correction patterns, as aligning failing code as a whole\nlacks the granularity needed to capture meaningful error-resolution\nrelationships. To address these issues, we propose IterPref, a new preference\nalignment framework that mimics human iterative debugging to refine Code LLMs.\nIterPref explicitly locates error regions and aligns the corresponding tokens\nvia a tailored DPO algorithm. To generate informative pairs, we introduce the\nCodeFlow dataset, where samples are iteratively refined until passing tests,\nwith modifications capturing error corrections. Extensive experiments show that\na diverse suite of Code LLMs equipped with IterPref achieves significant\nperformance gains in code generation and improves on challenging tasks like\nBigCodeBench. In-depth analysis reveals that IterPref yields fewer errors. Our\ncode and data will be made publicaly available.\n","authors":["Jie Wu","Haoling Li","Xin Zhang","Jianwen Luo","Yangyu Huang","Ruihang Chu","Yujiu Yang","Scarlett Li"],"pdf_url":"https://arxiv.org/pdf/2503.02783v1.pdf","comment":"The code and data will be released soon"},{"id":"http://arxiv.org/abs/2503.02780v1","updated":"2025-03-04T16:52:25Z","published":"2025-03-04T16:52:25Z","title":"Quantitative Resilience Modeling for Autonomous Cyber Defense","summary":"  Cyber resilience is the ability of a system to recover from an attack with\nminimal impact on system operations. However, characterizing a network's\nresilience under a cyber attack is challenging, as there are no formal\ndefinitions of resilience applicable to diverse network topologies and attack\npatterns. In this work, we propose a quantifiable formulation of resilience\nthat considers multiple defender operational goals, the criticality of various\nnetwork resources for daily operations, and provides interpretability to\nsecurity operators about their system's resilience under attack. We evaluate\nour approach within the CybORG environment, a reinforcement learning (RL)\nframework for autonomous cyber defense, analyzing trade-offs between\nresilience, costs, and prioritization of operational goals. Furthermore, we\nintroduce methods to aggregate resilience metrics across time-variable attack\npatterns and multiple network topologies, comprehensively characterizing system\nresilience. Using insights gained from our resilience metrics, we design RL\nautonomous defensive agents and compare them against several heuristic\nbaselines, showing that proactive network hardening techniques and prompt\nrecovery of compromised machines are critical for effective cyber defenses.\n","authors":["Xavier Cadet","Simona Boboila","Edward Koh","Peter Chin","Alina Oprea"],"pdf_url":"https://arxiv.org/pdf/2503.02780v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2502.14827v2","updated":"2025-03-04T16:43:01Z","published":"2025-02-20T18:45:00Z","title":"Exploring Advanced Techniques for Visual Question Answering: A\n  Comprehensive Comparison","summary":"  Visual Question Answering (VQA) has emerged as a pivotal task in the\nintersection of computer vision and natural language processing, requiring\nmodels to understand and reason about visual content in response to natural\nlanguage questions. Analyzing VQA datasets is essential for developing robust\nmodels that can handle the complexities of multimodal reasoning. Several\napproaches have been developed to examine these datasets, each offering\ndistinct perspectives on question diversity, answer distribution, and\nvisual-textual correlations. Despite significant progress, existing VQA models\nface challenges related to dataset bias, limited model complexity, commonsense\nreasoning gaps, rigid evaluation methods, and generalization to real world\nscenarios. This paper offers a detailed study of the original VQA dataset,\nbaseline models and methods along with a comparative study of five advanced VQA\nmodels, ABC-CNN, KICNLE, Masked Vision and Language Modeling, BLIP-2, and OFA,\neach employing distinct methods to address these ongoing challenges.\n","authors":["Aiswarya Baby","Tintu Thankom Koshy"],"pdf_url":"https://arxiv.org/pdf/2502.14827v2.pdf","comment":"8 pages, No figures"},{"id":"http://arxiv.org/abs/2503.02773v1","updated":"2025-03-04T16:42:46Z","published":"2025-03-04T16:42:46Z","title":"Prime Convolutional Model: Breaking the Ground for Theoretical\n  Explainability","summary":"  In this paper, we propose a new theoretical approach to Explainable AI.\nFollowing the Scientific Method, this approach consists in formulating on the\nbasis of empirical evidence, a mathematical model to explain and predict the\nbehaviors of Neural Networks. We apply the method to a case study created in a\ncontrolled environment, which we call Prime Convolutional Model (p-Conv for\nshort). p-Conv operates on a dataset consisting of the first one million\nnatural numbers and is trained to identify the congruence classes modulo a\ngiven integer $m$. Its architecture uses a convolutional-type neural network\nthat contextually processes a sequence of $B$ consecutive numbers to each\ninput. We take an empirical approach and exploit p-Conv to identify the\ncongruence classes of numbers in a validation set using different values for\n$m$ and $B$. The results show that the different behaviors of p-Conv (i.e.,\nwhether it can perform the task or not) can be modeled mathematically in terms\nof $m$ and $B$. The inferred mathematical model reveals interesting patterns\nable to explain when and why p-Conv succeeds in performing task and, if not,\nwhich error pattern it follows.\n","authors":["Francesco Panelli","Doaa Almhaithawi","Tania Cerquitelli","Alessandro Bellini"],"pdf_url":"https://arxiv.org/pdf/2503.02773v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2502.17403v2","updated":"2025-03-04T16:36:52Z","published":"2025-02-24T18:30:36Z","title":"Large Language Models are Powerful EHR Encoders","summary":"  Electronic Health Records (EHRs) offer rich potential for clinical\nprediction, yet their inherent complexity and heterogeneity pose significant\nchallenges for traditional machine learning approaches. Domain-specific EHR\nfoundation models trained on large collections of unlabeled EHR data have\ndemonstrated promising improvements in predictive accuracy and generalization;\nhowever, their training is constrained by limited access to diverse,\nhigh-quality datasets and inconsistencies in coding standards and healthcare\npractices. In this study, we explore the possibility of using general-purpose\nLarge Language Models (LLMs) based embedding methods as EHR encoders. By\nserializing patient records into structured Markdown text, transforming codes\ninto human-readable descriptors, we leverage the extensive generalization\ncapabilities of LLMs pretrained on vast public corpora, thereby bypassing the\nneed for proprietary medical datasets. We systematically evaluate two\nstate-of-the-art LLM-embedding models, GTE-Qwen2-7B-Instruct and\nLLM2Vec-Llama3.1-8B-Instruct, across 15 diverse clinical prediction tasks from\nthe EHRSHOT benchmark, comparing their performance to an EHRspecific foundation\nmodel, CLIMBR-T-Base, and traditional machine learning baselines. Our results\ndemonstrate that LLM-based embeddings frequently match or exceed the\nperformance of specialized models, even in few-shot settings, and that their\neffectiveness scales with the size of the underlying LLM and the available\ncontext window. Overall, our findings demonstrate that repurposing LLMs for EHR\nencoding offers a scalable and effective approach for clinical prediction,\ncapable of overcoming the limitations of traditional EHR modeling and\nfacilitating more interoperable and generalizable healthcare applications.\n","authors":["Stefan Hegselmann","Georg von Arnim","Tillmann Rheude","Noel Kronenberg","David Sontag","Gerhard Hindricks","Roland Eils","Benjamin Wild"],"pdf_url":"https://arxiv.org/pdf/2502.17403v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2409.04429v3","updated":"2025-03-04T16:31:57Z","published":"2024-09-06T17:49:56Z","title":"VILA-U: a Unified Foundation Model Integrating Visual Understanding and\n  Generation","summary":"  VILA-U is a Unified foundation model that integrates Video, Image, Language\nunderstanding and generation. Traditional visual language models (VLMs) use\nseparate modules for understanding and generating visual content, which can\nlead to misalignment and increased complexity. In contrast, VILA-U employs a\nsingle autoregressive next-token prediction framework for both tasks,\neliminating the need for additional components like diffusion models. This\napproach not only simplifies the model but also achieves near state-of-the-art\nperformance in visual language understanding and generation. The success of\nVILA-U is attributed to two main factors: the unified vision tower that aligns\ndiscrete visual tokens with textual inputs during pretraining, which enhances\nvisual perception, and autoregressive image generation can achieve similar\nquality as diffusion models with high-quality dataset. This allows VILA-U to\nperform comparably to more complex models using a fully token-based\nautoregressive framework.\n","authors":["Yecheng Wu","Zhuoyang Zhang","Junyu Chen","Haotian Tang","Dacheng Li","Yunhao Fang","Ligeng Zhu","Enze Xie","Hongxu Yin","Li Yi","Song Han","Yao Lu"],"pdf_url":"https://arxiv.org/pdf/2409.04429v3.pdf","comment":"Code: https://github.com/mit-han-lab/vila-u. The first two authors\n  contributed equally to this work"},{"id":"http://arxiv.org/abs/2503.02758v1","updated":"2025-03-04T16:21:33Z","published":"2025-03-04T16:21:33Z","title":"Efficient and Optimal No-Regret Caching under Partial Observation","summary":"  Online learning algorithms have been successfully used to design caching\npolicies with sublinear regret in the total number of requests, with no\nstatistical assumption about the request sequence. Most existing algorithms\ninvolve computationally expensive operations and require knowledge of all past\nrequests. However, this may not be feasible in practical scenarios like caching\nat a cellular base station. Therefore, we study the caching problem in a more\nrestrictive setting where only a fraction of past requests are observed, and we\npropose a randomized caching policy with sublinear regret based on the classic\nonline learning algorithm Follow-the-Perturbed-Leader (FPL). Our caching policy\nis the first to attain the asymptotically optimal regret bound while ensuring\nasymptotically constant amortized time complexity in the partial observability\nsetting of requests. The experimental evaluation compares the proposed solution\nagainst classic caching policies and validates the proposed approach under\nsynthetic and real-world request traces.\n","authors":["Younes Ben Mazziane","Francescomaria Faticanti","Sara Alouf","Giovanni Neglia"],"pdf_url":"https://arxiv.org/pdf/2503.02758v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.02745v1","updated":"2025-03-04T16:10:42Z","published":"2025-03-04T16:10:42Z","title":"ArcPro: Architectural Programs for Structured 3D Abstraction of Sparse\n  Points","summary":"  We introduce ArcPro, a novel learning framework built on architectural\nprograms to recover structured 3D abstractions from highly sparse and\nlow-quality point clouds. Specifically, we design a domain-specific language\n(DSL) to hierarchically represent building structures as a program, which can\nbe efficiently converted into a mesh. We bridge feedforward and inverse\nprocedural modeling by using a feedforward process for training data synthesis,\nallowing the network to make reverse predictions. We train an encoder-decoder\non the points-program pairs to establish a mapping from unstructured point\nclouds to architectural programs, where a 3D convolutional encoder extracts\npoint cloud features and a transformer decoder autoregressively predicts the\nprograms in a tokenized form. Inference by our method is highly efficient and\nproduces plausible and faithful 3D abstractions. Comprehensive experiments\ndemonstrate that ArcPro outperforms both traditional architectural proxy\nreconstruction and learning-based abstraction methods. We further explore its\npotential to work with multi-view image and natural language inputs.\n","authors":["Qirui Huang","Runze Zhang","Kangjun Liu","Minglun Gong","Hao Zhang","Hui Huang"],"pdf_url":"https://arxiv.org/pdf/2503.02745v1.pdf","comment":"CVPR 2025 (Patent Protected); Project page:\n  https://vcc.tech/research/2025/ArcPro"},{"id":"http://arxiv.org/abs/2503.02741v1","updated":"2025-03-04T16:05:13Z","published":"2025-03-04T16:05:13Z","title":"Seeded Poisson Factorization: Leveraging domain knowledge to fit topic\n  models","summary":"  Topic models are widely used for discovering latent thematic structures in\nlarge text corpora, yet traditional unsupervised methods often struggle to\nalign with predefined conceptual domains. This paper introduces Seeded Poisson\nFactorization (SPF), a novel approach that extends the Poisson Factorization\nframework by incorporating domain knowledge through seed words. SPF enables a\nmore interpretable and structured topic discovery by modifying the prior\ndistribution of topic-specific term intensities, assigning higher initial rates\nto predefined seed words. The model is estimated using variational inference\nwith stochastic gradient optimization, ensuring scalability to large datasets.\n  We apply SPF to an Amazon customer feedback dataset, leveraging predefined\nproduct categories as guiding structures. Our evaluation demonstrates that SPF\nachieves superior classification performance compared to alternative guided\ntopic models, particularly in terms of computational efficiency and predictive\nperformance. Furthermore, robustness checks highlight SPF's ability to\nadaptively balance domain knowledge and data-driven topic discovery, even in\ncases of imperfect seed word selection. These results establish SPF as a\npowerful and scalable alternative for integrating expert knowledge into topic\nmodeling, enhancing both interpretability and efficiency in real-world\napplications.\n","authors":["Bernd Prostmaier","Jan Vvra","Bettina Grn","Paul Hofmarcher"],"pdf_url":"https://arxiv.org/pdf/2503.02741v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2502.12944v2","updated":"2025-03-04T16:02:59Z","published":"2025-02-18T15:28:02Z","title":"Performance of Zero-Shot Time Series Foundation Models on Cloud Data","summary":"  Time series foundation models (FMs) have emerged as a popular paradigm for\nzero-shot multi-domain forecasting. FMs are trained on numerous diverse\ndatasets and claim to be effective forecasters across multiple different time\nseries domains, including cloud data. In this work we investigate this claim,\nexploring the effectiveness of FMs on cloud data. We demonstrate that many\nwell-known FMs fail to generate meaningful or accurate zero-shot forecasts in\nthis setting. We support this claim empirically, showing that FMs are\noutperformed consistently by simple linear baselines. We also illustrate a\nnumber of interesting pathologies, including instances where FMs suddenly\noutput seemingly erratic, random-looking forecasts. Our results suggest a\nwidespread failure of FMs to model cloud data.\n","authors":["William Toner","Thomas L. Lee","Artjom Joosen","Rajkarn Singh","Martin Asenov"],"pdf_url":"https://arxiv.org/pdf/2502.12944v2.pdf","comment":"5 pages, Preprint"},{"id":"http://arxiv.org/abs/2502.02417v2","updated":"2025-03-04T16:01:06Z","published":"2025-02-04T15:38:14Z","title":"CVKAN: Complex-Valued Kolmogorov-Arnold Networks","summary":"  In this work we propose CVKAN, a complex-valued KAN, to join the intrinsic\ninterpretability of KANs and the advantages of Complex-Valued Neural Networks\n(CVNNs). We show how to transfer a KAN and the necessary associated mechanisms\ninto the complex domain. To confirm that CVKAN meets expectations we conduct\nexperiments on symbolic complex-valued function fitting and physically\nmeaningful formulae as well as on a more realistic dataset from knot theory.\nOur proposed CVKAN is more stable and performs on par or better than\nreal-valued KANs while requiring less parameters and a shallower network\narchitecture, making it more explainable.\n","authors":["Matthias Wolff","Florian Eilers","Xiaoyi Jiang"],"pdf_url":"https://arxiv.org/pdf/2502.02417v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.02735v1","updated":"2025-03-04T15:55:55Z","published":"2025-03-04T15:55:55Z","title":"Clustered KL-barycenter design for policy evaluation","summary":"  In the context of stochastic bandit models, this article examines how to\ndesign sample-efficient behavior policies for the importance sampling\nevaluation of multiple target policies. From importance sampling theory, it is\nwell established that sample efficiency is highly sensitive to the KL\ndivergence between the target and importance sampling distributions. We first\nanalyze a single behavior policy defined as the KL-barycenter of the target\npolicies. Then, we refine this approach by clustering the target policies into\ngroups with small KL divergences and assigning each cluster its own\nKL-barycenter as a behavior policy. This clustered KL-based policy evaluation\n(CKL-PE) algorithm provides a novel perspective on optimal policy selection. We\nprove upper bounds on the sample complexity of our method and demonstrate its\neffectiveness with numerical validation.\n","authors":["Simon Weissmann","Till Freihaut","Claire Vernade","Giorgia Ramponi","Leif Dring"],"pdf_url":"https://arxiv.org/pdf/2503.02735v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2402.18974v2","updated":"2025-03-04T15:44:58Z","published":"2024-02-29T09:26:46Z","title":"Generating Graphs via Spectral Diffusion","summary":"  In this paper, we present GGSD, a novel graph generative model based on 1)\nthe spectral decomposition of the graph Laplacian matrix and 2) a diffusion\nprocess. Specifically, we propose to use a denoising model to sample\neigenvectors and eigenvalues from which we can reconstruct the graph Laplacian\nand adjacency matrix. Using the Laplacian spectrum allows us to naturally\ncapture the structural characteristics of the graph and work directly in the\nnode space while avoiding the quadratic complexity bottleneck that limits the\napplicability of other diffusion-based methods. This, in turn, is accomplished\nby truncating the spectrum, which, as we show in our experiments, results in a\nfaster yet accurate generative process, and by designing a novel\ntransformer-based architecture linear in the number of nodes. Our permutation\ninvariant model can also handle node features by concatenating them to the\neigenvectors of each node. An extensive set of experiments on both synthetic\nand real-world graphs demonstrates the strengths of our model against\nstate-of-the-art alternatives.\n","authors":["Giorgia Minello","Alessandro Bicciato","Luca Rossi","Andrea Torsello","Luca Cosmo"],"pdf_url":"https://arxiv.org/pdf/2402.18974v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2404.18869v2","updated":"2025-03-04T15:36:34Z","published":"2024-04-29T17:00:20Z","title":"Learning Mixtures of Gaussians Using Diffusion Models","summary":"  We give a new algorithm for learning mixtures of $k$ Gaussians (with identity\ncovariance in $\\mathbb{R}^n$) to TV error $\\varepsilon$, with quasi-polynomial\n($O(n^{\\text{poly\\,log}\\left(\\frac{n+k}{\\varepsilon}\\right)})$) time and sample\ncomplexity, under a minimum weight assumption. Our results extend to continuous\nmixtures of Gaussians where the mixing distribution is supported on a union of\n$k$ balls of constant radius. In particular, this applies to the case of\nGaussian convolutions of distributions on low-dimensional manifolds, or more\ngenerally sets with small covering number, for which no sub-exponential\nalgorithm was previously known. Unlike previous approaches, most of which are\nalgebraic in nature, our approach is analytic and relies on the framework of\ndiffusion models. Diffusion models are a modern paradigm for generative\nmodeling, which typically rely on learning the score function (gradient\nlog-pdf) along a process transforming a pure noise distribution, in our case a\nGaussian, to the data distribution. Despite their dazzling performance in tasks\nsuch as image generation, there are few end-to-end theoretical guarantees that\nthey can efficiently learn nontrivial families of distributions; we give some\nof the first such guarantees. We proceed by deriving higher-order Gaussian\nnoise sensitivity bounds for the score functions for a Gaussian mixture to show\nthat that they can be inductively learned using piecewise polynomial regression\n(up to poly-logarithmic degree), and combine this with known convergence\nresults for diffusion models.\n","authors":["Khashayar Gatmiry","Jonathan Kelner","Holden Lee"],"pdf_url":"https://arxiv.org/pdf/2404.18869v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.02714v1","updated":"2025-03-04T15:30:36Z","published":"2025-03-04T15:30:36Z","title":"S4D-Bio Audio Monitoring of Bone Cement Disintegration in Pulsating\n  Fluid Jet Surgery under Laboratory Conditions","summary":"  This study investigates a pulsating fluid jet as a novel precise, minimally\ninvasive and cold technique for bone cement removal. We utilize the pulsating\nfluid jet device to remove bone cement from samples designed to mimic clinical\nconditions. The effectiveness of long nozzles was tested to enable minimally\ninvasive procedures. Audio signal monitoring, complemented by the State Space\nModel (SSM) S4D-Bio, was employed to optimize the fluid jet parameters\ndynamically, addressing challenges like visibility obstruction from splashing.\nWithin our experiments, we generate a comprehensive dataset correlating various\nprocess parameters and their equivalent audio signals to material erosion. The\nuse of SSMs yields precise control over the predictive erosion process,\nachieving 98.93 \\% accuracy. The study demonstrates on the one hand, that the\npulsating fluid jet device, coupled with advanced audio monitoring techniques,\nis a highly effective tool for precise bone cement removal. On the other hand,\nthis study presents the first application of SSMs in biomedical surgery\ntechnology, marking a significant advancement in the application. This research\nsignificantly advances biomedical engineering by integrating machine learning\ncombined with pulsating fluid jet as surgical technology, offering a novel,\nminimally invasive, cold and adaptive approach for bone cement removal in\northopedic applications.\n","authors":["Melanie Schaller","Sergej Hloch","Akash Nag","Dagmar Klichova","Nick Janssen","Frank Pude","Michal Zelenak","Bodo Rosenhahn"],"pdf_url":"https://arxiv.org/pdf/2503.02714v1.pdf","comment":"submitted to Computers in Biology and Medicine Journal"},{"id":"http://arxiv.org/abs/2502.05210v2","updated":"2025-03-04T15:25:14Z","published":"2025-02-03T19:26:44Z","title":"Regression and Forecasting of U.S. Stock Returns Based on LSTM","summary":"  This paper analyses the investment returns of three stock sectors, Manuf,\nHitec, and Other, in the U.S. stock market, based on the Fama-French\nthree-factor model, the Carhart four-factor model, and the Fama-French\nfive-factor model, in order to test the validity of the Fama-French\nthree-factor model, the Carhart four-factor model, and the Fama-French\nfive-factor model for the three sectors of the market. French five-factor model\nfor the three sectors of the market. Also, the LSTM model is used to explore\nthe additional factors affecting stock returns. The empirical results show that\nthe Fama-French five-factor model has better validity for the three segments of\nthe market under study, and the LSTM model has the ability to capture the\nfactors affecting the returns of certain industries, and can better regress and\npredict the stock returns of the relevant industries. Keywords- Fama-French\nmodel; Carhart model; Factor model; LSTM model.\n","authors":["Shicheng Zhou","Zizhou Zhang","Rong Zhang","Yuchen Yin","Chia Hong Chang","Qinyan Shen"],"pdf_url":"https://arxiv.org/pdf/2502.05210v2.pdf","comment":"5pages"},{"id":"http://arxiv.org/abs/2103.03223v5","updated":"2025-03-04T15:20:55Z","published":"2021-03-04T18:51:06Z","title":"A Comparative Evaluation of Quantification Methods","summary":"  Quantification represents the problem of estimating the distribution of class\nlabels on unseen data. It also represents a growing research field in\nsupervised machine learning, for which a large variety of different algorithms\nhas been proposed in recent years. However, a comprehensive empirical\ncomparison of quantification methods that supports algorithm selection is not\navailable yet. In this work, we close this research gap by conducting a\nthorough empirical performance comparison of 24 different quantification\nmethods on overall more than 40 data sets, considering binary as well as\nmulticlass quantification settings. We observe that no single algorithm\ngenerally outperforms all competitors, but identify a group of methods\nincluding the threshold selection-based Median Sweep and TSMax methods, the DyS\nframework including the HDy method, Forman's mixture model, and Friedman's\nmethod that performs best in the binary setting. For the multiclass setting, we\nobserve that a different, broad group of algorithms yields good performance,\nincluding the HDx method, the Generalized Probabilistic Adjusted Count, the\nreadme method, the energy distance minimization method, the EM algorithm for\nquantification, and Friedman's method. We also find that tuning the underlying\nclassifiers has in most cases only a limited impact on the quantification\nperformance. More generally, we find that the performance on multiclass\nquantification is inferior to the results obtained in the binary setting. Our\nresults can guide practitioners who intend to apply quantification algorithms\nand help researchers to identify opportunities for future research.\n","authors":["Tobias Schumacher","Markus Strohmaier","Florian Lemmerich"],"pdf_url":"https://arxiv.org/pdf/2103.03223v5.pdf","comment":"41 pages, 18 figures, 9 tables"},{"id":"http://arxiv.org/abs/2503.02702v1","updated":"2025-03-04T15:18:40Z","published":"2025-03-04T15:18:40Z","title":"RedChronos: A Large Language Model-Based Log Analysis System for Insider\n  Threat Detection in Enterprises","summary":"  Internal threat detection aims to address security threats within\norganizations or enterprises by identifying potential or already occurring\nmalicious threats within vast amounts of logs. Although organizations or\nenterprises have dedicated personnel responsible for reviewing these logs, it\nis impossible to manually examine all logs entirely. In response to the vast\nnumber of logs, we propose a system called RedChronos, which is a Large\nLanguage Model-Based Log Analysis System. This system incorporates innovative\nimprovements over previous research by employing Query-Aware Weighted Voting\nand a Semantic Expansion-based Genetic Algorithm with LLM-driven Mutations. On\nthe public datasets CERT 4.2 and 5.2, RedChronos outperforms or matches\nexisting approaches in terms of accuracy, precision, and detection rate.\nMoreover, RedChronos reduces the need for manual intervention in security log\nreviews by 90\\% in the Xiaohongshu SOC. Therefore, our RedChronos system\ndemonstrates exceptional performance in handling Internal Threat Detection\n(IDT) tasks, providing innovative solutions for these challenges. We believe\nthat future research can continue to enhance the system's performance in IDT\ntasks while also reducing the response time to internal risk events.\n","authors":["Chenyu Li","Zhengjia Zhu","Jiyan He","Xiu Zhang"],"pdf_url":"https://arxiv.org/pdf/2503.02702v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2406.15753v2","updated":"2025-03-04T15:17:17Z","published":"2024-06-22T06:43:51Z","title":"The Perils of Optimizing Learned Reward Functions: Low Training Error\n  Does Not Guarantee Low Regret","summary":"  In reinforcement learning, specifying reward functions that capture the\nintended task can be very challenging. Reward learning aims to address this\nissue by learning the reward function. However, a learned reward model may have\na low error on the data distribution, and yet subsequently produce a policy\nwith large regret. We say that such a reward model has an error-regret\nmismatch. The main source of an error-regret mismatch is the distributional\nshift that commonly occurs during policy optimization. In this paper, we\nmathematically show that a sufficiently low expected test error of the reward\nmodel guarantees low worst-case regret, but that for any fixed expected test\nerror, there exist realistic data distributions that allow for error-regret\nmismatch to occur. We then show that similar problems persist even when using\npolicy regularization techniques, commonly employed in methods such as RLHF. We\nhope our results stimulate the theoretical and empirical study of improved\nmethods to learn reward models, and better ways to measure their quality\nreliably.\n","authors":["Lukas Fluri","Leon Lang","Alessandro Abate","Patrick Forr","David Krueger","Joar Skalse"],"pdf_url":"https://arxiv.org/pdf/2406.15753v2.pdf","comment":"70 pages, 4 figures"},{"id":"http://arxiv.org/abs/2503.02693v1","updated":"2025-03-04T15:07:25Z","published":"2025-03-04T15:07:25Z","title":"Federated Learning for Privacy-Preserving Feedforward Control in\n  Multi-Agent Systems","summary":"  Feedforward control (FF) is often combined with feedback control (FB) in many\ncontrol systems, improving tracking performance, efficiency, and stability.\nHowever, designing effective data-driven FF controllers in multi-agent systems\nrequires significant data collection, including transferring private or\nproprietary data, which raises privacy concerns and incurs high communication\ncosts. Therefore, we propose a novel approach integrating Federated Learning\n(FL) into FF control to address these challenges. This approach enables\nprivacy-preserving, communication-efficient, and decentralized continuous\nimprovement of FF controllers across multiple agents without sharing personal\nor proprietary data. By leveraging FL, each agent learns a local, neural FF\ncontroller using its data and contributes only model updates to a global\naggregation process, ensuring data privacy and scalability. We demonstrate the\neffectiveness of our method in an autonomous driving use case. Therein,\nvehicles equipped with a trajectory-tracking feedback controller are enhanced\nby FL-based neural FF control. Simulations highlight significant improvements\nin tracking performance compared to pure FB control, analogous to model-based\nFF control. We achieve comparable tracking performance without exchanging\nprivate vehicle-specific data compared to a centralized neural FF control. Our\nresults underscore the potential of FL-based neural FF control to enable\nprivacy-preserving learning in multi-agent control systems, paving the way for\nscalable and efficient autonomous systems applications.\n","authors":["Jakob Weber","Markus Gurtner","Benedikt Alt","Adrian Trachte","Andreas Kugi"],"pdf_url":"https://arxiv.org/pdf/2503.02693v1.pdf","comment":"Submitted to IJCNN 2025"},{"id":"http://arxiv.org/abs/2503.02690v1","updated":"2025-03-04T15:03:15Z","published":"2025-03-04T15:03:15Z","title":"Generative Modeling of Microweather Wind Velocities for Urban Air\n  Mobility","summary":"  Motivated by the pursuit of safe, reliable, and weather-tolerant urban air\nmobility (UAM) solutions, this work proposes a generative modeling approach for\ncharacterizing microweather wind velocities. Microweather, or the weather\nconditions in highly localized areas, is particularly complex in urban\nenvironments owing to the chaotic and turbulent nature of wind flows.\nFurthermore, traditional means of assessing local wind fields are not generally\nviable solutions for UAM applications: 1) field measurements that would rely on\npermanent wind profiling systems in operational air space are not practical, 2)\nphysics-based models that simulate fluid dynamics at a sufficiently high\nresolution are not computationally tractable, and 3) data-driven modeling\napproaches that are largely deterministic ignore the inherent variability in\nturbulent flows that dictates UAM reliability. Thus, advancements in predictive\ncapabilities are needed to help mitigate the unique operational safety risks\nthat microweather winds pose for smaller, lighter weight UAM aircraft.\n  This work aims to model microweather wind velocities in a manner that is\ncomputationally-efficient, captures random variability, and would only require\na temporary, rather than permanent, field measurement campaign. Inspired by\nrecent breakthroughs in conditional generative AI such as text-to-image\ngeneration, the proposed approach learns a probabilistic macro-to-microweather\nmapping between regional weather forecasts and measured local wind velocities\nusing generative modeling (denoising diffusion probabilistic models, flow\nmatching, and Gaussian mixture models). A simple proof of concept was\nimplemented using a dataset comprised of local (micro) measurements from a\nSonic Detection and Ranging (SoDAR) wind profiler along with (macro) forecast\ndata from a nearby weather station over the same time period.\n","authors":["Tristan A. Shah","Michael C. Stanley","James E. Warner"],"pdf_url":"https://arxiv.org/pdf/2503.02690v1.pdf","comment":"17 pages, 13 figures, published in 2025 IEEE Aerospace Conference\n  proceedings"},{"id":"http://arxiv.org/abs/2303.11858v3","updated":"2025-03-04T15:03:02Z","published":"2023-03-21T13:59:15Z","title":"Modeling Relational Patterns for Logical Query Answering over Knowledge\n  Graphs","summary":"  Answering first-order logical (FOL) queries over knowledge graphs (KG)\nremains a challenging task mainly due to KG incompleteness. Query embedding\napproaches this problem by computing the low-dimensional vector representations\nof entities, relations, and logical queries. KGs exhibit relational patterns\nsuch as symmetry and composition and modeling the patterns can further enhance\nthe performance of query embedding models. However, the role of such patterns\nin answering FOL queries by query embedding models has not been yet studied in\nthe literature. In this paper, we fill in this research gap and empower FOL\nqueries reasoning with pattern inference by introducing an inductive bias that\nallows for learning relation patterns. To this end, we develop a novel query\nembedding method, RoConE, that defines query regions as geometric cones and\nalgebraic query operators by rotations in complex space. RoConE combines the\nadvantages of Cone as a well-specified geometric representation for query\nembedding, and also the rotation operator as a powerful algebraic operation for\npattern inference. Our experimental results on several benchmark datasets\nconfirm the advantage of relational patterns for enhancing logical query\nanswering task.\n","authors":["Yunjie He","Mojtaba Nayyeri","Bo Xiong","Yuqicheng Zhu","Evgeny Kharlamov","Steffen Staab"],"pdf_url":"https://arxiv.org/pdf/2303.11858v3.pdf","comment":"The results reported in this paper are included in our accepted paper\n  arXiv:2407.09212 at ECAI 2024"},{"id":"http://arxiv.org/abs/2503.02687v1","updated":"2025-03-04T15:02:07Z","published":"2025-03-04T15:02:07Z","title":"Class-Aware PillarMix: Can Mixed Sample Data Augmentation Enhance 3D\n  Object Detection with Radar Point Clouds?","summary":"  Due to the significant effort required for data collection and annotation in\n3D perception tasks, mixed sample data augmentation (MSDA) has been widely\nstudied to generate diverse training samples by mixing existing data. Recently,\nmany MSDA techniques have been developed for point clouds, but they mainly\ntarget LiDAR data, leaving their application to radar point clouds largely\nunexplored. In this paper, we examine the feasibility of applying existing MSDA\nmethods to radar point clouds and identify several challenges in adapting these\ntechniques. These obstacles stem from the radar's irregular angular\ndistribution, deviations from a single-sensor polar layout in multi-radar\nsetups, and point sparsity. To address these issues, we propose Class-Aware\nPillarMix (CAPMix), a novel MSDA approach that applies MixUp at the pillar\nlevel in 3D point clouds, guided by class labels. Unlike methods that rely a\nsingle mix ratio to the entire sample, CAPMix assigns an independent ratio to\neach pillar, boosting sample diversity. To account for the density of different\nclasses, we use class-specific distributions: for dense objects (e.g., large\nvehicles), we skew ratios to favor points from another sample, while for sparse\nobjects (e.g., pedestrians), we sample more points from the original. This\nclass-aware mixing retains critical details and enriches each sample with new\ninformation, ultimately generating more diverse training data. Experimental\nresults demonstrate that our method not only significantly boosts performance\nbut also outperforms existing MSDA approaches across two datasets (Bosch Street\nand K-Radar). We believe that this straightforward yet effective approach will\nspark further investigation into MSDA techniques for radar data.\n","authors":["Miao Zhang","Sherif Abdulatif","Benedikt Loesch","Marco Altmann","Bin Yang"],"pdf_url":"https://arxiv.org/pdf/2503.02687v1.pdf","comment":"8 pages, 6 figures, 4 tables, submitted to 2025 IEEE/RSJ\n  International Conference on Intelligent Robots and Systems (IROS 2025)"},{"id":"http://arxiv.org/abs/2402.05626v5","updated":"2025-03-04T14:56:57Z","published":"2024-02-08T12:30:29Z","title":"Loss Landscape of Shallow ReLU-like Neural Networks: Stationary Points,\n  Saddle Escape, and Network Embedding","summary":"  In this paper, we study the loss landscape of one-hidden-layer neural\nnetworks with ReLU-like activation functions trained with the empirical squared\nloss using gradient descent (GD). We identify the stationary points of such\nnetworks, which significantly slow down loss decrease during training. To\ncapture such points while accounting for the non-differentiability of the loss,\nthe stationary points that we study are directional stationary points, rather\nthan other notions like Clarke stationary points. We show that, if a stationary\npoint does not contain \"escape neurons\", which are defined with first-order\nconditions, it must be a local minimum. Moreover, for the scalar-output case,\nthe presence of an escape neuron guarantees that the stationary point is not a\nlocal minimum. Our results refine the description of the saddle-to-saddle\ntraining process starting from infinitesimally small (vanishing) initialization\nfor shallow ReLU-like networks: By precluding the saddle escape types that\nprevious works did not rule out, we advance one step closer to a complete\npicture of the entire dynamics. Moreover, we are also able to fully discuss how\nnetwork embedding, which is to instantiate a narrower network with a wider\nnetwork, reshapes the stationary points.\n","authors":["Zhengqing Wu","Berfin Simsek","Francois Ged"],"pdf_url":"https://arxiv.org/pdf/2402.05626v5.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.02682v1","updated":"2025-03-04T14:54:45Z","published":"2025-03-04T14:54:45Z","title":"MPO: Boosting LLM Agents with Meta Plan Optimization","summary":"  Recent advancements in large language models (LLMs) have enabled LLM-based\nagents to successfully tackle interactive planning tasks. However, despite\ntheir successes, existing approaches often suffer from planning hallucinations\nand require retraining for each new agent. To address these challenges, we\npropose the Meta Plan Optimization (MPO) framework, which enhances agent\nplanning capabilities by directly incorporating explicit guidance. Unlike\nprevious methods that rely on complex knowledge, which either require\nsignificant human effort or lack quality assurance, MPO leverages high-level\ngeneral guidance through meta plans to assist agent planning and enables\ncontinuous optimization of the meta plans based on feedback from the agent's\ntask execution. Our experiments conducted on two representative tasks\ndemonstrate that MPO significantly outperforms existing baselines. Moreover,\nour analysis indicates that MPO provides a plug-and-play solution that enhances\nboth task completion efficiency and generalization capabilities in previous\nunseen scenarios.\n","authors":["Weimin Xiong","Yifan Song","Qingxiu Dong","Bingchan Zhao","Feifan Song","Xun Wang","Sujian Li"],"pdf_url":"https://arxiv.org/pdf/2503.02682v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.02680v1","updated":"2025-03-04T14:50:20Z","published":"2025-03-04T14:50:20Z","title":"VWAP Execution with Signature-Enhanced Transformers: A Multi-Asset\n  Learning Approach","summary":"  In this paper I propose a novel approach to Volume Weighted Average Price\n(VWAP) execution that addresses two key practical challenges: the need for\nasset-specific model training and the capture of complex temporal dependencies.\nBuilding upon my recent work in dynamic VWAP execution arXiv:2502.18177, I\ndemonstrate that a single neural network trained across multiple assets can\nachieve performance comparable to or better than traditional asset-specific\nmodels. The proposed architecture combines a transformer-based design inspired\nby arXiv:2406.02486 with path signatures for capturing geometric features of\nprice-volume trajectories, as in arXiv:2406.17890. The empirical analysis,\nconducted on hourly cryptocurrency trading data from 80 trading pairs, shows\nthat the globally-fitted model with signature features (GFT-Sig) achieves\nsuperior performance in both absolute and quadratic VWAP loss metrics compared\nto asset-specific approaches. Notably, these improvements persist for\nout-of-sample assets, demonstrating the model's ability to generalize across\ndifferent market conditions. The results suggest that combining global\nparameter sharing with signature-based feature extraction provides a scalable\nand robust approach to VWAP execution, offering significant practical\nadvantages over traditional asset-specific implementations.\n","authors":["Remi Genet"],"pdf_url":"https://arxiv.org/pdf/2503.02680v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.18954v2","updated":"2025-03-04T14:36:43Z","published":"2024-10-24T17:53:33Z","title":"Learning Structured Compressed Sensing with Automatic Resource\n  Allocation","summary":"  Multidimensional data acquisition often requires extensive time and poses\nsignificant challenges for hardware and software regarding data storage and\nprocessing. Rather than designing a single compression matrix as in\nconventional compressed sensing, structured compressed sensing yields\ndimension-specific compression matrices, reducing the number of optimizable\nparameters. Recent advances in machine learning (ML) have enabled task-based\nsupervised learning of subsampling matrices, albeit at the expense of complex\ndownstream models. Additionally, the sampling resource allocation across\ndimensions is often determined in advance through heuristics. To address these\nchallenges, we introduce Structured COmpressed Sensing with Automatic Resource\nAllocation (SCOSARA) with an information theory-based unsupervised learning\nstrategy. SCOSARA adaptively distributes samples across sampling dimensions\nwhile maximizing Fisher information content. Using ultrasound localization as a\ncase study, we compare SCOSARA to state-of-the-art ML-based and greedy search\nalgorithms. Simulation results demonstrate that SCOSARA can produce\nhigh-quality subsampling matrices that achieve lower Cram\\'er-Rao Bound values\nthan the baselines. In addition, SCOSARA outperforms other ML-based algorithms\nin terms of the number of trainable parameters, computational complexity, and\nmemory requirements while automatically choosing the number of samples per\naxis.\n","authors":["Han Wang","Eduardo Prez","Iris A. M. Huijben","Hans van Gorp","Ruud van Sloun","Florian Rmer"],"pdf_url":"https://arxiv.org/pdf/2410.18954v2.pdf","comment":"Unsupervised Learning, Information Theory, Compressed Sensing,\n  Subsampling"},{"id":"http://arxiv.org/abs/2503.02665v1","updated":"2025-03-04T14:33:54Z","published":"2025-03-04T14:33:54Z","title":"Weakly-Constrained 4D Var for Downscaling with Uncertainty using\n  Data-Driven Surrogate Models","summary":"  Dynamic downscaling typically involves using numerical weather prediction\n(NWP) solvers to refine coarse data to higher spatial resolutions. Data-driven\nmodels such as FourCastNet have emerged as a promising alternative to the\ntraditional NWP models for forecasting. Once these models are trained, they are\ncapable of delivering forecasts in a few seconds, thousands of times faster\ncompared to classical NWP models. However, as the lead times, and, therefore,\ntheir forecast window, increase, these models show instability in that they\ntend to diverge from reality. In this paper, we propose to use data\nassimilation approaches to stabilize them when used for downscaling tasks. Data\nassimilation uses information from three different sources, namely an imperfect\ncomputational model based on partial differential equations (PDE), from noisy\nobservations, and from an uncertainty-reflecting prior. In this work, when\ncarrying out dynamic downscaling, we replace the computationally expensive\nPDE-based NWP models with FourCastNet in a ``weak-constrained 4DVar framework\"\nthat accounts for the implied model errors. We demonstrate the efficacy of this\napproach for a hurricane-tracking problem; moreover, the 4DVar framework\nnaturally allows the expression and quantification of uncertainty. We\ndemonstrate, using ERA5 data, that our approach performs better than the\nensemble Kalman filter (EnKF) and the unstabilized FourCastNet model, both in\nterms of forecast accuracy and forecast uncertainty.\n","authors":["Philip Dinenis","Vishwas Rao","Mihai Anitescu"],"pdf_url":"https://arxiv.org/pdf/2503.02665v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.00735v2","updated":"2025-03-04T14:30:32Z","published":"2025-03-02T05:16:43Z","title":"LADDER: Self-Improving LLMs Through Recursive Problem Decomposition","summary":"  We introduce LADDER (Learning through Autonomous Difficulty-Driven Example\nRecursion), a framework which enables Large Language Models to autonomously\nimprove their problem-solving capabilities through self-guided learning by\nrecursively generating and solving progressively simpler variants of complex\nproblems. Unlike prior approaches that require curated datasets or human\nfeedback, LADDER leverages a model's own capabilities to generate easier\nquestion variants. We demonstrate LADDER's effectiveness in the subject of\nmathematical integration, improving Llama 3.2 3B's accuracy from 1% to 82% on\nundergraduate-level problems and enabling Qwen2.5 7B Deepseek-R1 Distilled to\nachieve 73% on the MIT Integration Bee qualifying examination. We also\nintroduce TTRL (Test-Time Reinforcement Learning), where we perform\nreinforcement learning on variants of test problems at inference time. TTRL\nenables Qwen2.5 7B Deepseek-R1 Distilled to achieve a state-of-the-art score of\n90% on the MIT Integration Bee qualifying examination, surpassing OpenAI o1's\nperformance. These results show how self-directed strategic learning can\nachieve significant capability improvements without relying on architectural\nscaling or human supervision.\n","authors":["Toby Simonds","Akira Yoshiyama"],"pdf_url":"https://arxiv.org/pdf/2503.00735v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.02656v1","updated":"2025-03-04T14:17:00Z","published":"2025-03-04T14:17:00Z","title":"Adapting Decoder-Based Language Models for Diverse Encoder Downstream\n  Tasks","summary":"  Decoder-based transformers, while revolutionizing language modeling and\nscaling to immense sizes, have not completely overtaken encoder-heavy\narchitectures in natural language processing. Specifically, encoder-only models\nremain dominant in tasks like classification, regression, and ranking. This is\nprimarily due to the inherent structure of decoder-based models, which limits\ntheir direct applicability to these tasks. In this paper, we introduce Gemma\nEncoder, adapting the powerful Gemma decoder model to an encoder architecture,\nthereby unlocking its potential for a wider range of non-generative\napplications. To optimize the adaptation from decoder to encoder, we\nsystematically analyze various pooling strategies, attention mechanisms, and\nhyperparameters (e.g., dropout rate). Furthermore, we benchmark Gemma Encoder\nagainst established approaches on the GLUE benchmarks, and MS MARCO ranking\nbenchmark, demonstrating its effectiveness and versatility.\n","authors":["Paul Suganthan","Fedor Moiseev","Le Yan","Junru Wu","Jianmo Ni","Jay Han","Imed Zitouni","Enrique Alfonseca","Xuanhui Wang","Zhe Dong"],"pdf_url":"https://arxiv.org/pdf/2503.02656v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.02652v1","updated":"2025-03-04T14:15:47Z","published":"2025-03-04T14:15:47Z","title":"Cellular Automaton With CNN","summary":"  Cellular automata (CA) models are widely used to simulate complex systems\nwith emergent behaviors, but identifying hidden parameters that govern their\ndynamics remains a significant challenge. This study explores the use of\nConvolutional Neural Networks (CNN) to identify jump parameters in a\ntwo-dimensional CA model. We propose a custom CNN architecture trained on\nCA-generated data to classify jump parameters, which dictates the neighborhood\nsize and movement rules of cells within the CA. Experiments were conducted\nacross varying domain sizes (25 x 25 to 150 x 150) and CA iterations (0 to 50),\ndemonstrating that the accuracy improves with larger domain sizes, as they\nprovide more spatial information for parameter estimation. Interestingly, while\ninitial CA iterations enhance the performance, increasing the number of\niterations beyond a certain threshold does not significantly improve accuracy,\nsuggesting that only specific temporal information is relevant for parameter\nidentification. The proposed CNN achieves competitive accuracy (89.31) compared\nto established architectures like LeNet-5 and AlexNet, while offering\nsignificantly faster inference times, making it suitable for real-time\napplications. This study highlights the potential of CNNs as a powerful tool\nfor fast and accurate parameter estimation in CA models, paving the way for\ntheir use in more complex systems and higher-dimensional domains. Future work\nwill explore the identification of multiple hidden parameters and extend the\napproach to three-dimensional CA models.\n","authors":["Valery Ashu","Zhisong Liu","Heikki Haario","Andreas Rupp"],"pdf_url":"https://arxiv.org/pdf/2503.02652v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2502.20125v2","updated":"2025-03-04T14:15:40Z","published":"2025-02-27T14:16:22Z","title":"Discovering Antagonists in Networks of Systems: Robot Deployment","summary":"  A contextual anomaly detection method is proposed and applied to the physical\nmotions of a robot swarm executing a coverage task. Using simulations of a\nswarm's normal behavior, a normalizing flow is trained to predict the\nlikelihood of a robot motion within the current context of its environment.\nDuring application, the predicted likelihood of the observed motions is used by\na detection criterion that categorizes a robot agent as normal or antagonistic.\nThe proposed method is evaluated on five different strategies of antagonistic\nbehavior. Importantly, only readily available simulated data of normal robot\nbehavior is used for training such that the nature of the anomalies need not be\nknown beforehand. The best detection criterion correctly categorizes at least\n80% of each antagonistic type while maintaining a false positive rate of less\nthan 5% for normal robot agents. Additionally, the method is validated in\nhardware experiments, yielding results similar to the simulated scenarios.\nCompared to the state-of-the-art approach, both the predictive performance of\nthe normalizing flow and the robustness of the detection criterion are\nincreased.\n","authors":["Ingeborg Wenger","Peter Eberhard","Henrik Ebel"],"pdf_url":"https://arxiv.org/pdf/2502.20125v2.pdf","comment":"reduced file size"},{"id":"http://arxiv.org/abs/2503.00860v2","updated":"2025-03-04T14:08:45Z","published":"2025-03-02T11:44:03Z","title":"Hierarchical graph sampling based minibatch learning with chain\n  preservation and variance reduction","summary":"  Graph sampling based Graph Convolutional Networks (GCNs) decouple the\nsampling from the forward and backward propagation during minibatch training,\nwhich exhibit good scalability in terms of layer depth and graph size. We\npropose HIS_GCNs, a hierarchical importance graph sampling based learning\nmethod. By constructing minibatches using sampled subgraphs, HIS_GCNs gives\nattention to the importance of both core and periphery nodes/edges in a\nscale-free training graph. Specifically, it preserves the centrum of the core\nto most minibatches, which maintains connectivity between periphery nodes, and\nsamples periphery edges without core node interference, in order to keep more\nlong chains composed entirely of low-degree nodes in the same minibatch.\nHIS_GCNs can maximize the discrete Ricci curvature (i.e., Ollivier-Ricci\ncurvatures) of the edges in a subgraph that enables the preservation of\nimportant chains for information propagation, and can achieve a low node\nembedding variance and a high convergence speed. Diverse experiments on Graph\nNeural Networks (GNNs) with node classification tasks confirm superior\nperformance of HIS_GCNs in both accuracy and training time.\n","authors":["Qia Hu","Bo Jiao"],"pdf_url":"https://arxiv.org/pdf/2503.00860v2.pdf","comment":"26 pages, 9 figures"},{"id":"http://arxiv.org/abs/2501.09776v2","updated":"2025-03-04T14:08:33Z","published":"2025-01-16T13:04:15Z","title":"Multi-Head Self-Attending Neural Tucker Factorization","summary":"  Quality-of-service (QoS) data exhibit dynamic temporal patterns that are\ncrucial for accurately predicting missing values. These patterns arise from the\nevolving interactions between users and services, making it essential to\ncapture the temporal dynamics inherent in such data for improved prediction\nperformance. As the size and complexity of QoS datasets increase, existing\nmodels struggle to provide accurate predictions, highlighting the need for more\nflexible and dynamic methods to better capture the underlying patterns in\nlarge-scale QoS data. To address this issue, we introduce a neural\nnetwork-based tensor factorization approach tailored for learning\nspatiotemporal representations of high-dimensional and incomplete (HDI)\ntensors, namely the Multi-head Self-attending Neural Tucker Factorization\n(MSNTucF). The model is elaborately designed for modeling intricate nonlinear\nspatiotemporal feature interaction patterns hidden in real world data with a\ntwo-fold idea. It first employs a neural network structure to generalize the\ntraditional framework of Tucker factorization and then proposes to leverage a\nmulti-head self-attending module to enforce nonlinear latent interaction\nlearning. In empirical studies on two dynamic QoS datasets from real\napplications, the proposed MSNTucF model demonstrates superior performance\ncompared to state-of-the-art benchmark models in estimating missing\nobservations. This highlights its ability to learn non-linear spatiotemporal\nrepresentations of HDI tensors.\n","authors":["Yikai Hou","Peng Tang"],"pdf_url":"https://arxiv.org/pdf/2501.09776v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.02642v1","updated":"2025-03-04T14:05:39Z","published":"2025-03-04T14:05:39Z","title":"Weight transport through spike timing for robust local gradients","summary":"  In both machine learning and in computational neuroscience, plasticity in\nfunctional neural networks is frequently expressed as gradient descent on a\ncost. Often, this imposes symmetry constraints that are difficult to reconcile\nwith local computation, as is required for biological networks or neuromorphic\nhardware. For example, wake-sleep learning in networks characterized by\nBoltzmann distributions builds on the assumption of symmetric connectivity.\nSimilarly, the error backpropagation algorithm is notoriously plagued by the\nweight transport problem between the representation and the error stream.\nExisting solutions such as feedback alignment tend to circumvent the problem by\ndeferring to the robustness of these algorithms to weight asymmetry. However,\nthey are known to scale poorly with network size and depth. We introduce\nspike-based alignment learning (SAL), a complementary learning rule for spiking\nneural networks, which uses spike timing statistics to extract and correct the\nasymmetry between effective reciprocal connections. Apart from being\nspike-based and fully local, our proposed mechanism takes advantage of noise.\nBased on an interplay between Hebbian and anti-Hebbian plasticity, synapses can\nthereby recover the true local gradient. This also alleviates discrepancies\nthat arise from neuron and synapse variability -- an omnipresent property of\nphysical neuronal networks. We demonstrate the efficacy of our mechanism using\ndifferent spiking network models. First, we show how SAL can significantly\nimprove convergence to the target distribution in probabilistic spiking\nnetworks as compared to Hebbian plasticity alone. Second, in neuronal\nhierarchies based on cortical microcircuits, we show how our proposed mechanism\neffectively enables the alignment of feedback weights to the forward pathway,\nthus allowing the backpropagation of correct feedback errors.\n","authors":["Timo Gierlich","Andreas Baumbach","Akos F. Kungl","Kevin Max","Mihai A. Petrovici"],"pdf_url":"https://arxiv.org/pdf/2503.02642v1.pdf","comment":"19 pages, 9 figures"},{"id":"http://arxiv.org/abs/2401.15077v3","updated":"2025-03-04T13:58:39Z","published":"2024-01-26T18:59:01Z","title":"EAGLE: Speculative Sampling Requires Rethinking Feature Uncertainty","summary":"  Autoregressive decoding makes the inference of Large Language Models (LLMs)\ntime-consuming. In this paper, we reconsider speculative sampling and derive\ntwo key observations. Firstly, autoregression at the feature\n(second-to-top-layer) level is more straightforward than at the token level.\nSecondly, the inherent uncertainty in feature (second-to-top-layer) level\nautoregression constrains its performance. Based on these insights, we\nintroduce EAGLE (Extrapolation Algorithm for Greater Language-model\nEfficiency), a simple yet highly efficient speculative sampling framework. By\nincorporating a token sequence advanced by one time step, EAGLE effectively\nresolves the uncertainty, enabling precise second-to-top-layer feature\nprediction with minimal overhead. We conducted comprehensive evaluations of\nEAGLE, including all models from the Vicuna and LLaMA2-Chat series, the MoE\nmodel Mixtral 8x7B Instruct, and tasks in dialogue, code generation,\nmathematical reasoning, and instruction following. For LLaMA2-Chat 70B, EAGLE\nachieved a latency speedup ratio of 2.7x-3.5x, doubled throughput, while\nmaintaining the distribution of the generated text.\n","authors":["Yuhui Li","Fangyun Wei","Chao Zhang","Hongyang Zhang"],"pdf_url":"https://arxiv.org/pdf/2401.15077v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.02630v1","updated":"2025-03-04T13:55:22Z","published":"2025-03-04T13:55:22Z","title":"Weighted Euclidean Distance Matrices over Mixed Continuous and\n  Categorical Inputs for Gaussian Process Models","summary":"  Gaussian Process (GP) models are widely utilized as surrogate models in\nscientific and engineering fields. However, standard GP models are limited to\ncontinuous variables due to the difficulties in establishing correlation\nstructures for categorical variables. To overcome this limitati on, we\nintroduce WEighted Euclidean distance matrices Gaussian Process (WEGP). WEGP\nconstructs the kernel function for each categorical input by estimating the\nEuclidean distance matrix (EDM) among all categorical choices of this input.\nThe EDM is represented as a linear combination of several predefined base EDMs,\neach scaled by a positive weight. The weights, along with other kernel\nhyperparameters, are inferred using a fully Bayesian framework. We analyze the\npredictive performance of WEGP theoretically. Numerical experiments validate\nthe accuracy of our GP model, and by WEGP, into Bayesian Optimization (BO), we\nachieve superior performance on both synthetic and real-world optimization\nproblems.\n","authors":["Mingyu Pu","Songhao Wang","Haowei Wang","Szu Hui Ng"],"pdf_url":"https://arxiv.org/pdf/2503.02630v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.02621v1","updated":"2025-03-04T13:42:38Z","published":"2025-03-04T13:42:38Z","title":"Leveraging Self-Supervised Learning Methods for Remote Screening of\n  Subjects with Paroxysmal Atrial Fibrillation","summary":"  The integration of Artificial Intelligence (AI) into clinical research has\ngreat potential to reveal patterns that are difficult for humans to detect,\ncreating impactful connections between inputs and clinical outcomes. However,\nthese methods often require large amounts of labeled data, which can be\ndifficult to obtain in healthcare due to strict privacy laws and the need for\nexperts to annotate data. This requirement creates a bottleneck when\ninvestigating unexplored clinical questions. This study explores the\napplication of Self-Supervised Learning (SSL) as a way to obtain preliminary\nresults from clinical studies with limited sized cohorts. To assess our\napproach, we focus on an underexplored clinical task: screening subjects for\nParoxysmal Atrial Fibrillation (P-AF) using remote monitoring, single-lead ECG\nsignals captured during normal sinus rhythm. We evaluate state-of-the-art SSL\nmethods alongside supervised learning approaches, where SSL outperforms\nsupervised learning in this task of interest. More importantly, it prevents\nmisleading conclusions that may arise from poor performance in the latter\nparadigm when dealing with limited cohort settings.\n","authors":["Adrian Atienza","Gouthamaan Manimaran","Sadasivan Puthusserypady","Helena Dominguez","Peter K. Jacobsen","Jakob E. Bardram"],"pdf_url":"https://arxiv.org/pdf/2503.02621v1.pdf","comment":"Under revision"},{"id":"http://arxiv.org/abs/2408.02835v3","updated":"2025-03-04T13:41:49Z","published":"2024-08-05T21:12:12Z","title":"Training a multilayer dynamical spintronic network with standard machine\n  learning tools to perform time series classification","summary":"  The ability to process time-series at low energy cost is critical for many\napplications. Recurrent neural network, which can perform such tasks, are\ncomputationally expensive when implementing in software on conventional\ncomputers. Here we propose to implement a recurrent neural network in hardware\nusing spintronic oscillators as dynamical neurons. Using numerical simulations,\nwe build a multi-layer network and demonstrate that we can use backpropagation\nthrough time (BPTT) and standard machine learning tools to train this network.\nLeveraging the transient dynamics of the spintronic oscillators, we solve the\nsequential digits classification task with $89.83\\pm2.91~\\%$ accuracy, as good\nas the equivalent software network. We devise guidelines on how to choose the\ntime constant of the oscillators as well as hyper-parameters of the network to\nadapt to different input time scales.\n","authors":["Erwan Plouet","Ddalo Sanz-Hernndez","Aymeric Vecchiola","Julie Grollier","Frank Mizrahi"],"pdf_url":"https://arxiv.org/pdf/2408.02835v3.pdf","comment":"7 pages, 4 figures"},{"id":"http://arxiv.org/abs/2503.02618v1","updated":"2025-03-04T13:38:41Z","published":"2025-03-04T13:38:41Z","title":"ZAPBench: A Benchmark for Whole-Brain Activity Prediction in Zebrafish","summary":"  Data-driven benchmarks have led to significant progress in key scientific\nmodeling domains including weather and structural biology. Here, we introduce\nthe Zebrafish Activity Prediction Benchmark (ZAPBench) to measure progress on\nthe problem of predicting cellular-resolution neural activity throughout an\nentire vertebrate brain. The benchmark is based on a novel dataset containing\n4d light-sheet microscopy recordings of over 70,000 neurons in a larval\nzebrafish brain, along with motion stabilized and voxel-level cell\nsegmentations of these data that facilitate development of a variety of\nforecasting methods. Initial results from a selection of time series and\nvolumetric video modeling approaches achieve better performance than naive\nbaseline methods, but also show room for further improvement. The specific\nbrain used in the activity recording is also undergoing synaptic-level\nanatomical mapping, which will enable future integration of detailed structural\ninformation into forecasting methods.\n","authors":["Jan-Matthis Lueckmann","Alexander Immer","Alex Bo-Yuan Chen","Peter H. Li","Mariela D. Petkova","Nirmala A. Iyer","Luuk Willem Hesselink","Aparna Dev","Gudrun Ihrke","Woohyun Park","Alyson Petruncio","Aubrey Weigel","Wyatt Korff","Florian Engert","Jeff W. Lichtman","Misha B. Ahrens","Micha Januszewski","Viren Jain"],"pdf_url":"https://arxiv.org/pdf/2503.02618v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.02616v1","updated":"2025-03-04T13:36:16Z","published":"2025-03-04T13:36:16Z","title":"Smoothing the Shift: Towards Stable Test-Time Adaptation under Complex\n  Multimodal Noises","summary":"  Test-Time Adaptation (TTA) aims to tackle distribution shifts using unlabeled\ntest data without access to the source data. In the context of multimodal data,\nthere are more complex noise patterns than unimodal data such as simultaneous\ncorruptions for multiple modalities and missing modalities. Besides, in\nreal-world applications, corruptions from different distribution shifts are\nalways mixed. Existing TTA methods always fail in such multimodal scenario\nbecause the abrupt distribution shifts will destroy the prior knowledge from\nthe source model, thus leading to performance degradation. To this end, we\nreveal a new challenge named multimodal wild TTA. To address this challenging\nproblem, we propose two novel strategies: sample identification with\ninterquartile range Smoothing and unimodal assistance, and Mutual information\nsharing (SuMi). SuMi smooths the adaptation process by interquartile range\nwhich avoids the abrupt distribution shifts. Then, SuMi fully utilizes the\nunimodal features to select low-entropy samples with rich multimodal\ninformation for optimization. Furthermore, mutual information sharing is\nintroduced to align the information, reduce the discrepancies and enhance the\ninformation utilization across different modalities. Extensive experiments on\ntwo public datasets show the effectiveness and superiority over existing\nmethods under the complex noise patterns in multimodal data. Code is available\nat https://github.com/zrguo/SuMi.\n","authors":["Zirun Guo","Tao Jin"],"pdf_url":"https://arxiv.org/pdf/2503.02616v1.pdf","comment":"Accepted at ICLR 2025"},{"id":"http://arxiv.org/abs/2503.02612v1","updated":"2025-03-04T13:32:40Z","published":"2025-03-04T13:32:40Z","title":"Reinforcement Learning-based Threat Assessment","summary":"  In some game scenarios, due to the uncertainty of the number of enemy units\nand the priority of various attributes, the evaluation of the threat level of\nenemy units as well as the screening has been a challenging research topic, and\nthe core difficulty lies in how to reasonably set the priority of different\nattributes in order to achieve quantitative evaluation of the threat. In this\npaper, we innovatively transform the problem of threat assessment into a\nreinforcement learning problem, and through systematic reinforcement learning\ntraining, we successfully construct an efficient neural network evaluator. The\nevaluator can not only comprehensively integrate the multidimensional attribute\nfeatures of the enemy, but also effectively combine our state information, thus\nrealizing a more accurate and scientific threat assessment.\n","authors":["Wuzhou Sun","Siyi Li","Qingxiang Zou","Zixing Liao"],"pdf_url":"https://arxiv.org/pdf/2503.02612v1.pdf","comment":"10 pages,9 figures"},{"id":"http://arxiv.org/abs/2503.02609v1","updated":"2025-03-04T13:29:42Z","published":"2025-03-04T13:29:42Z","title":"Lightweight Channel-wise Dynamic Fusion Model: Non-stationary Time\n  Series Forecasting via Entropy Analysis","summary":"  Non-stationarity is an intrinsic property of real-world time series and plays\na crucial role in time series forecasting. Previous studies primarily adopt\ninstance normalization to attenuate the non-stationarity of original series for\nbetter predictability. However, instance normalization that directly removes\nthe inherent non-stationarity can lead to three issues: (1) disrupting global\ntemporal dependencies, (2) ignoring channel-specific differences, and (3)\nproducing over-smoothed predictions. To address these issues, we theoretically\ndemonstrate that variance can be a valid and interpretable proxy for\nquantifying non-stationarity of time series. Based on the analysis, we propose\na novel lightweight \\textit{C}hannel-wise \\textit{D}ynamic \\textit{F}usion\n\\textit{M}odel (\\textit{CDFM}), which selectively and dynamically recovers\nintrinsic non-stationarity of the original series, while keeping the\npredictability of normalized series. First, we design a Dual-Predictor Module,\nwhich involves two branches: a Time Stationary Predictor for capturing stable\npatterns and a Time Non-stationary Predictor for modeling global dynamics\npatterns. Second, we propose a Fusion Weight Learner to dynamically\ncharacterize the intrinsic non-stationary information across different samples\nbased on variance. Finally, we introduce a Channel Selector to selectively\nrecover non-stationary information from specific channels by evaluating their\nnon-stationarity, similarity, and distribution consistency, enabling the model\nto capture relevant dynamic features and avoid overfitting. Comprehensive\nexperiments on seven time series datasets demonstrate the superiority and\ngeneralization capabilities of CDFM.\n","authors":["Tianyu Jia","Zongxia Xie","Yanru Sun","Dilfira Kudrat","Qinghua Hu"],"pdf_url":"https://arxiv.org/pdf/2503.02609v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2209.07225v4","updated":"2025-03-04T13:25:54Z","published":"2022-09-15T11:39:59Z","title":"MIXRTs: Toward Interpretable Multi-Agent Reinforcement Learning via\n  Mixing Recurrent Soft Decision Trees","summary":"  While achieving tremendous success in various fields, existing multi-agent\nreinforcement learning (MARL) with a black-box neural network makes decisions\nin an opaque manner that hinders humans from understanding the learned\nknowledge and how input observations influence decisions. In contrast, existing\ninterpretable approaches usually suffer from weak expressivity and low\nperformance. To bridge this gap, we propose MIXing Recurrent soft decision\nTrees (MIXRTs), a novel interpretable architecture that can represent explicit\ndecision processes via the root-to-leaf path and reflect each agent's\ncontribution to the team. Specifically, we construct a novel soft decision tree\nusing a recurrent structure and demonstrate which features influence the\ndecision-making process. Then, based on the value decomposition framework, we\nlinearly assign credit to each agent by explicitly mixing individual action\nvalues to estimate the joint action value using only local observations,\nproviding new insights into interpreting the cooperation mechanism. Theoretical\nanalysis confirms that MIXRTs guarantee additivity and monotonicity in the\nfactorization of joint action values. Evaluations on complex tasks like Spread\nand StarCraft II demonstrate that MIXRTs compete with existing methods while\nproviding clear explanations, paving the way for interpretable and\nhigh-performing MARL systems.\n","authors":["Zichuan Liu","Yuanyang Zhu","Zhi Wang","Yang Gao","Chunlin Chen"],"pdf_url":"https://arxiv.org/pdf/2209.07225v4.pdf","comment":"Accepted by IEEE Transactions on Pattern Analysis and Machine\n  Intelligence"},{"id":"http://arxiv.org/abs/2502.20476v2","updated":"2025-03-04T13:11:38Z","published":"2025-02-27T19:26:36Z","title":"Unifying Model Predictive Path Integral Control, Reinforcement Learning,\n  and Diffusion Models for Optimal Control and Planning","summary":"  Model Predictive Path Integral (MPPI) control, Reinforcement Learning (RL),\nand Diffusion Models have each demonstrated strong performance in trajectory\noptimization, decision-making, and motion planning. However, these approaches\nhave traditionally been treated as distinct methodologies with separate\noptimization frameworks. In this work, we establish a unified perspective that\nconnects MPPI, RL, and Diffusion Models through gradient-based optimization on\nthe Gibbs measure. We first show that MPPI can be interpreted as performing\ngradient ascent on a smoothed energy function. We then demonstrate that Policy\nGradient methods reduce to MPPI by applying an exponential transformation to\nthe objective function. Additionally, we establish that the reverse sampling\nprocess in diffusion models follows the same update rule as MPPI.\n","authors":["Yankai Li","Mo Chen"],"pdf_url":"https://arxiv.org/pdf/2502.20476v2.pdf","comment":"updated RL subsection in Main section"},{"id":"http://arxiv.org/abs/2310.12309v2","updated":"2025-03-04T13:09:19Z","published":"2023-10-18T20:18:05Z","title":"A Unifying Framework for Learning Argumentation Semantics","summary":"  Argumentation is a very active research field of Artificial Intelligence\nconcerned with the representation and evaluation of arguments used in dialogues\nbetween humans and/or artificial agents. Acceptability semantics of formal\nargumentation systems define the criteria for the acceptance or rejection of\narguments. Several software systems, known as argumentation solvers, have been\ndeveloped to compute the accepted/rejected arguments using such criteria. These\ninclude systems that learn to identify the accepted arguments using\nnon-interpretable methods. In this paper we present a novel framework, which\nuses an Inductive Logic Programming approach to learn the acceptability\nsemantics for several abstract and structured argumentation frameworks in an\ninterpretable way. Through an empirical evaluation we show that our framework\noutperforms existing argumentation solvers, thus opening up new future research\ndirections in the area of formal argumentation and human-machine dialogues.\n","authors":["Zlatina Mileva","Antonis Bikakis","Fabio Aurelio D'Asaro","Mark Law","Alessandra Russo"],"pdf_url":"https://arxiv.org/pdf/2310.12309v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.02583v1","updated":"2025-03-04T13:07:20Z","published":"2025-03-04T13:07:20Z","title":"A generalized approach to label shift: the Conditional Probability Shift\n  Model","summary":"  In many practical applications of machine learning, a discrepancy often\narises between a source distribution from which labeled training examples are\ndrawn and a target distribution for which only unlabeled data is observed.\nTraditionally, two main scenarios have been considered to address this issue:\ncovariate shift (CS), where only the marginal distribution of features changes,\nand label shift (LS), which involves a change in the class variable's prior\ndistribution. However, these frameworks do not encompass all forms of\ndistributional shift. This paper introduces a new setting, Conditional\nProbability Shift (CPS), which captures the case when the conditional\ndistribution of the class variable given some specific features changes while\nthe distribution of remaining features given the specific features and the\nclass is preserved. For this scenario we present the Conditional Probability\nShift Model (CPSM) based on modeling the class variable's conditional\nprobabilities using multinomial regression. Since the class variable is not\nobserved for the target data, the parameters of the multinomial model for its\ndistribution are estimated using the Expectation-Maximization algorithm. The\nproposed method is generic and can be combined with any probabilistic\nclassifier. The effectiveness of CPSM is demonstrated through experiments on\nsynthetic datasets and a case study using the MIMIC medical database, revealing\nits superior balanced classification accuracy on the target data compared to\nexisting methods, particularly in situations situations of conditional\ndistribution shift and no apriori distribution shift, which are not detected by\nLS-based methods.\n","authors":["Pawe Teisseyre","Jan Mielniczuk"],"pdf_url":"https://arxiv.org/pdf/2503.02583v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2407.03157v2","updated":"2025-03-04T13:01:07Z","published":"2024-07-03T14:34:03Z","title":"Let the Code LLM Edit Itself When You Edit the Code","summary":"  In this work, we investigate a typical scenario in code generation where a\ndeveloper edits existing code in real time and requests a code assistant, e.g.,\na large language model, to re-predict the next token or next line on the fly.\nNaively, the LLM needs to re-encode the entire KV cache to provide an accurate\nprediction. However, this process is computationally expensive, especially when\nthe sequence length is long. Simply encoding the edited subsequence and\nintegrating it to the original KV cache meets the temporal confusion problem,\nleading to significantly worse performance. We address this efficiency and\naccuracy trade-off by introducing \\underline{\\textbf{Positional\n\\textbf{I}ntegrity \\textbf{E}ncoding} (PIE). Building upon the rotary\npositional encoding, PIE first removes the rotary matrices in the Key cache\nthat introduce temporal confusion and then reapplies the correct rotary\nmatrices. This process ensures that positional relationships between tokens are\ncorrect and requires only a single round of matrix multiplication. We validate\nthe effectiveness of PIE through extensive experiments on the RepoBench-C-8k\ndataset, utilizing DeepSeek-Coder models with 1.3B, 6.7B, and 33B parameters.\nOur evaluation includes three real-world coding tasks: code insertion, code\ndeletion, and multi-place code editing. Results demonstrate that PIE reduces\ncomputational overhead by over 85% compared to the standard full recomputation\napproach across all model sizes and tasks while well approximating the model\nperformance.\n","authors":["Zhenyu He","Jun Zhang","Shengjie Luo","Jingjing Xu","Zhi Zhang","Di He"],"pdf_url":"https://arxiv.org/pdf/2407.03157v2.pdf","comment":"ICLR 2025 Camera Ready"},{"id":"http://arxiv.org/abs/2410.00911v2","updated":"2025-03-04T12:45:15Z","published":"2024-10-01T17:58:06Z","title":"Dual Consolidation for Pre-Trained Model-Based Domain-Incremental\n  Learning","summary":"  Domain-Incremental Learning (DIL) involves the progressive adaptation of a\nmodel to new concepts across different domains. While recent advances in\npre-trained models provide a solid foundation for DIL, learning new concepts\noften results in the catastrophic forgetting of pre-trained knowledge.\nSpecifically, sequential model updates can overwrite both the representation\nand the classifier with knowledge from the latest domain. Thus, it is crucial\nto develop a representation and corresponding classifier that accommodate all\nseen domains throughout the learning process. To this end, we propose DUal\nConsolidaTion (Duct) to unify and consolidate historical knowledge at both the\nrepresentation and classifier levels. By merging the backbone of different\nstages, we create a representation space suitable for multiple domains\nincrementally. The merged representation serves as a balanced intermediary that\ncaptures task-specific features from all seen domains. Additionally, to address\nthe mismatch between consolidated embeddings and the classifier, we introduce\nan extra classifier consolidation process. Leveraging class-wise semantic\ninformation, we estimate the classifier weights of old domains within the\nlatest embedding space. By merging historical and estimated classifiers, we\nalign them with the consolidated embedding space, facilitating incremental\nclassification. Extensive experimental results on four benchmark datasets\ndemonstrate Duct's state-of-the-art performance. Code is available at\nhttps://github.com/Estrella-fugaz/CVPR25-Duct\n","authors":["Da-Wei Zhou","Zi-Wen Cai","Han-Jia Ye","Lijun Zhang","De-Chuan Zhan"],"pdf_url":"https://arxiv.org/pdf/2410.00911v2.pdf","comment":"Accepted to CVPR 2025. Code is available at\n  https://github.com/Estrella-fugaz/CVPR25-Duct"},{"id":"http://arxiv.org/abs/2503.02563v1","updated":"2025-03-04T12:40:49Z","published":"2025-03-04T12:40:49Z","title":"To Vaccinate or not to Vaccinate? Analyzing $\\mathbb{X}$ Power over the\n  Pandemic","summary":"  The COVID-19 pandemic has profoundly affected the normal course of life --\nfrom lock-downs and virtual meetings to the unprecedentedly swift creation of\nvaccines. To halt the COVID-19 pandemic, the world has started preparing for\nthe global vaccine roll-out. In an effort to navigate the immense volume of\ninformation about COVID-19, the public has turned to social networks. Among\nthem, $\\mathbb{X}$ (formerly Twitter) has played a key role in distributing\nrelated information. Most people are not trained to interpret medical research\nand remain skeptical about the efficacy of new vaccines. Measuring their\nreactions and perceptions is gaining significance in the fight against\nCOVID-19. To assess the public perception regarding the COVID-19 vaccine, our\nwork applies a sentiment analysis approach, using natural language processing\nof $\\mathbb{X}$ data. We show how to use textual analytics and textual data\nvisualization to discover early insights (for example, by analyzing the most\nfrequently used keywords and hashtags). Furthermore, we look at how people's\nsentiments vary across the countries. Our results indicate that although the\noverall reaction to the vaccine is positive, there are also negative sentiments\nassociated with the tweets, especially when examined at the country level.\nAdditionally, from the extracted tweets, we manually labeled 100 tweets as\npositive and 100 tweets as negative and trained various One-Class Classifiers\n(OCCs). The experimental results indicate that the S-SVDD classifiers\noutperform other OCCs.\n","authors":["Tanveer Khan","Fahad Sohrab","Antonis Michalas","Moncef Gabbouj"],"pdf_url":"https://arxiv.org/pdf/2503.02563v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.02554v1","updated":"2025-03-04T12:26:45Z","published":"2025-03-04T12:26:45Z","title":"Towards a robust R2D2 paradigm for radio-interferometric imaging:\n  revisiting DNN training and architecture","summary":"  The R2D2 Deep Neural Network (DNN) series was recently introduced for image\nformation in radio interferometry. It can be understood as a learned version of\nCLEAN, whose minor cycles are substituted with DNNs. We revisit R2D2 on the\ngrounds of series convergence, training methodology, and DNN architecture,\nimproving its robustness in terms of generalisability beyond training\nconditions, capability to deliver high data fidelity, and epistemic\nuncertainty. Firstly, while still focusing on telescope-specific training, we\nenhance the learning process by randomising Fourier sampling integration times,\nincorporating multi-scan multi-noise configurations, and varying imaging\nsettings, including pixel resolution and visibility-weighting scheme. Secondly,\nwe introduce a convergence criterion whereby the reconstruction process stops\nwhen the data residual is compatible with noise, rather than simply using all\navailable DNNs. This not only increases the reconstruction efficiency by\nreducing its computational cost, but also refines training by pruning out the\ndata/image pairs for which optimal data fidelity is reached before training the\nnext DNN. Thirdly, we substitute R2D2's early U-Net DNN with a novel\narchitecture (U-WDSR) combining U-Net and WDSR, which leverages wide\nactivation, dense connections, weight normalisation, and low-rank convolution\nto improve feature reuse and reconstruction precision. As previously, R2D2 was\ntrained for monochromatic intensity imaging with the Very Large Array (VLA) at\nfixed $512 \\times 512$ image size. Simulations on a wide range of inverse\nproblems and a case study on real data reveal that the new R2D2 model\nconsistently outperforms its earlier version in image reconstruction quality,\ndata fidelity, and epistemic uncertainty.\n","authors":["Amir Aghabiglou","Chung San Chu","Chao Tang","Arwa Dabbech","Yves Wiaux"],"pdf_url":"https://arxiv.org/pdf/2503.02554v1.pdf","comment":"17 pages, 6 figures"},{"id":"http://arxiv.org/abs/2502.21187v2","updated":"2025-03-04T12:18:40Z","published":"2025-02-28T16:02:37Z","title":"SYN-LUNGS: Towards Simulating Lung Nodules with Anatomy-Informed Digital\n  Twins for AI Training","summary":"  AI models for lung cancer screening are limited by data scarcity, impacting\ngeneralizability and clinical applicability. Generative models address this\nissue but are constrained by training data variability. We introduce SYN-LUNGS,\na framework for generating high-quality 3D CT images with detailed annotations.\nSYN-LUNGS integrates XCAT3 phantoms for digital twin generation, X-Lesions for\nnodule simulation (varying size, location, and appearance), and DukeSim for CT\nimage formation with vendor and parameter variability. The dataset includes\n3,072 nodule images from 1,044 simulated CT scans, with 512 lesions and 174\ndigital twins. Models trained on clinical + simulated data outperform clinical\nonly models, achieving 10% improvement in detection, 2-9% in segmentation and\nclassification, and enhanced synthesis.By incorporating anatomy-informed\nsimulations, SYN-LUNGS provides a scalable approach for AI model development,\nparticularly in rare disease representation and improving model reliability.\n","authors":["Fakrul Islam Tushar","Lavsen Dahal","Cindy McCabe","Fong Chi Ho","Paul Segars","Ehsan Abadi","Kyle J. Lafata","Ehsan Samei","Joseph Y. Lo"],"pdf_url":"https://arxiv.org/pdf/2502.21187v2.pdf","comment":"6 figures, 12 pages"},{"id":"http://arxiv.org/abs/2503.02539v1","updated":"2025-03-04T12:04:13Z","published":"2025-03-04T12:04:13Z","title":"Disentangled Knowledge Tracing for Alleviating Cognitive Bias","summary":"  In the realm of Intelligent Tutoring System (ITS), the accurate assessment of\nstudents' knowledge states through Knowledge Tracing (KT) is crucial for\npersonalized learning. However, due to data bias, $\\textit{i.e.}$, the\nunbalanced distribution of question groups ($\\textit{e.g.}$, concepts),\nconventional KT models are plagued by cognitive bias, which tends to result in\ncognitive underload for overperformers and cognitive overload for\nunderperformers. More seriously, this bias is amplified with the exercise\nrecommendations by ITS. After delving into the causal relations in the KT\nmodels, we identify the main cause as the confounder effect of students'\nhistorical correct rate distribution over question groups on the student\nrepresentation and prediction score. Towards this end, we propose a\nDisentangled Knowledge Tracing (DisKT) model, which separately models students'\nfamiliar and unfamiliar abilities based on causal effects and eliminates the\nimpact of the confounder in student representation within the model.\nAdditionally, to shield the contradictory psychology ($\\textit{e.g.}$, guessing\nand mistaking) in the students' biased data, DisKT introduces a contradiction\nattention mechanism. Furthermore, DisKT enhances the interpretability of the\nmodel predictions by integrating a variant of Item Response Theory.\nExperimental results on 11 benchmarks and 3 synthesized datasets with different\nbias strengths demonstrate that DisKT significantly alleviates cognitive bias\nand outperforms 16 baselines in evaluation accuracy.\n","authors":["Yiyun Zhou","Zheqi Lv","Shengyu Zhang","Jingyuan Chen"],"pdf_url":"https://arxiv.org/pdf/2503.02539v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.02534v1","updated":"2025-03-04T12:02:36Z","published":"2025-03-04T12:02:36Z","title":"SAGE-Amine: Generative Amine Design with Multi-Property Optimization for\n  Efficient CO2 Capture","summary":"  Efficient CO2 capture is vital for mitigating climate change, with\namine-based solvents being widely used due to their strong reactivity with CO2.\nHowever, optimizing key properties such as basicity, viscosity, and absorption\ncapacity remains challenging, as traditional methods rely on labor-intensive\nexperimentation and predefined chemical databases, limiting the exploration of\nnovel solutions. Here, SAGE-Amine was introduced, a generative modeling\napproach that integrates Scoring-Assisted Generative Exploration (SAGE) with\nquantitative structure-property relationship models to design new amines\ntailored for CO2 capture. Unlike conventional virtual screening restricted to\nexisting compounds, SAGE-Amine generates novel amines by leveraging\nautoregressive natural language processing models trained on amine datasets.\nSAGE-Amine identified known amines for CO2 capture from scratch and\nsuccessfully performed single-property optimization, increasing basicity or\nreducing viscosity or vapor pressure. Furthermore, it facilitated\nmulti-property optimization, simultaneously achieving high basicity with low\nviscosity and vapor pressure. The 10 top-ranked amines were suggested using\nSAGE-Amine and their thermodynamic properties were further assessed using\nCOSMO-RS simulations, confirming their potential for CO2 capture. These results\nhighlight the potential of generative modeling in accelerating the discovery of\namine solvents and expanding the possibilities for industrial CO2 capture\napplications.\n","authors":["Hocheol Lim","Hyein Cho","Jeonghoon Kim"],"pdf_url":"https://arxiv.org/pdf/2503.02534v1.pdf","comment":"33 pages, 5 figures"},{"id":"http://arxiv.org/abs/2412.06860v2","updated":"2025-03-04T11:47:27Z","published":"2024-12-09T02:36:38Z","title":"Balancing Efficiency and Effectiveness: An LLM-Infused Approach for\n  Optimized CTR Prediction","summary":"  Click-Through Rate (CTR) prediction is essential in online advertising, where\nsemantic information plays a pivotal role in shaping user decisions and\nenhancing CTR effectiveness. Capturing and modeling deep semantic information,\nsuch as a user's preference for \"H\\\"aagen-Dazs' HEAVEN strawberry light ice\ncream\" due to its health-conscious and premium attributes, is challenging.\nTraditional semantic modeling often overlooks these intricate details at the\nuser and item levels. To bridge this gap, we introduce a novel approach that\nmodels deep semantic information end-to-end, leveraging the comprehensive world\nknowledge capabilities of Large Language Models (LLMs). Our proposed\nLLM-infused CTR prediction framework(Multi-level Deep Semantic Information\nInfused CTR model via Distillation, MSD) is designed to uncover deep semantic\ninsights by utilizing LLMs to extract and distill critical information into a\nsmaller, more efficient model, enabling seamless end-to-end training and\ninference. Importantly, our framework is carefully designed to balance\nefficiency and effectiveness, ensuring that the model not only achieves high\nperformance but also operates with optimal resource utilization. Online A/B\ntests conducted on the Meituan sponsored-search system demonstrate that our\nmethod significantly outperforms baseline models in terms of Cost Per Mile\n(CPM) and CTR, validating its effectiveness, scalability, and balanced approach\nin real-world applications.\n","authors":["Guoxiao Zhang","Yi Wei","Yadong Zhang","Huajian Feng","Qiang Liu"],"pdf_url":"https://arxiv.org/pdf/2412.06860v2.pdf","comment":"5 pages, 4 figures,4 tables"},{"id":"http://arxiv.org/abs/2412.08222v2","updated":"2025-03-04T11:42:25Z","published":"2024-12-11T09:17:45Z","title":"Structured IB: Improving Information Bottleneck with Structured Feature\n  Learning","summary":"  The Information Bottleneck (IB) principle has emerged as a promising approach\nfor enhancing the generalization, robustness, and interpretability of deep\nneural networks, demonstrating efficacy across image segmentation, document\nclustering, and semantic communication. Among IB implementations, the IB\nLagrangian method, employing Lagrangian multipliers, is widely adopted. While\nnumerous methods for the optimizations of IB Lagrangian based on variational\nbounds and neural estimators are feasible, their performance is highly\ndependent on the quality of their design, which is inherently prone to errors.\nTo address this limitation, we introduce Structured IB, a framework for\ninvestigating potential structured features. By incorporating auxiliary\nencoders to extract missing informative features, we generate more informative\nrepresentations. Our experiments demonstrate superior prediction accuracy and\ntask-relevant information preservation compared to the original IB Lagrangian\nmethod, even with reduced network size.\n","authors":["Hanzhe Yang","Youlong Wu","Dingzhu Wen","Yong Zhou","Yuanming Shi"],"pdf_url":"https://arxiv.org/pdf/2412.08222v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.02526v1","updated":"2025-03-04T11:39:30Z","published":"2025-03-04T11:39:30Z","title":"A Theory of Initialisation's Impact on Specialisation","summary":"  Prior work has demonstrated a consistent tendency in neural networks engaged\nin continual learning tasks, wherein intermediate task similarity results in\nthe highest levels of catastrophic interference. This phenomenon is attributed\nto the network's tendency to reuse learned features across tasks. However, this\nexplanation heavily relies on the premise that neuron specialisation occurs,\ni.e. the emergence of localised representations. Our investigation challenges\nthe validity of this assumption. Using theoretical frameworks for the analysis\nof neural networks, we show a strong dependence of specialisation on the\ninitial condition. More precisely, we show that weight imbalance and high\nweight entropy can favour specialised solutions. We then apply these insights\nin the context of continual learning, first showing the emergence of a\nmonotonic relation between task-similarity and forgetting in non-specialised\nnetworks. {Finally, we show that specialization by weight imbalance is\nbeneficial on the commonly employed elastic weight consolidation regularisation\ntechnique.\n","authors":["Devon Jarvis","Sebastian Lee","Clmentine Carla Juliette Domin","Andrew M Saxe","Stefano Sarao Mannelli"],"pdf_url":"https://arxiv.org/pdf/2503.02526v1.pdf","comment":"10 pages, 7 figures"},{"id":"http://arxiv.org/abs/2407.01214v2","updated":"2025-03-04T11:33:29Z","published":"2024-07-01T11:59:59Z","title":"Revisiting Random Walks for Learning on Graphs","summary":"  We revisit a simple model class for machine learning on graphs, where a\nrandom walk on a graph produces a machine-readable record, and this record is\nprocessed by a deep neural network to directly make vertex-level or graph-level\npredictions. We call these stochastic machines random walk neural networks\n(RWNNs), and through principled analysis, show that we can design them to be\nisomorphism invariant while capable of universal approximation of graph\nfunctions in probability. A useful finding is that almost any kind of record of\nrandom walks guarantees probabilistic invariance as long as the vertices are\nanonymized. This enables us, for example, to record random walks in plain text\nand adopt a language model to read these text records to solve graph tasks. We\nfurther establish a parallelism to message passing neural networks using tools\nfrom Markov chain theory, and show that over-smoothing in message passing is\nalleviated by construction in RWNNs, while over-squashing manifests as\nprobabilistic under-reaching. We empirically demonstrate RWNNs on a range of\nproblems, verifying our theoretical analysis and demonstrating the use of\nlanguage models for separating strongly regular graphs where 3-WL test fails,\nand transductive classification on arXiv citation network. Code is available at\nhttps://github.com/jw9730/random-walk.\n","authors":["Jinwoo Kim","Olga Zaghen","Ayhan Suleymanzade","Youngmin Ryou","Seunghoon Hong"],"pdf_url":"https://arxiv.org/pdf/2407.01214v2.pdf","comment":"51 pages, 14 figures"},{"id":"http://arxiv.org/abs/2503.01747v2","updated":"2025-03-04T11:30:30Z","published":"2025-03-03T17:15:17Z","title":"Position: Don't use the CLT in LLM evals with fewer than a few hundred\n  datapoints","summary":"  Rigorous statistical evaluations of large language models (LLMs), including\nvalid error bars and significance testing, are essential for meaningful and\nreliable performance assessment. Currently, when such statistical measures are\nreported, they typically rely on the Central Limit Theorem (CLT). In this\nposition paper, we argue that while CLT-based methods for uncertainty\nquantification are appropriate when benchmarks consist of thousands of\nexamples, they fail to provide adequate uncertainty estimates for LLM\nevaluations that rely on smaller, highly specialized benchmarks. In these\nsmall-data settings, we demonstrate that CLT-based methods perform very poorly,\nusually dramatically underestimating uncertainty (i.e. producing error bars\nthat are too small). We give recommendations for alternative frequentist and\nBayesian methods that are both easy to implement and more appropriate in these\nincreasingly common scenarios. We provide a simple Python library for these\nBayesian methods at https://github.com/sambowyer/bayes_evals .\n","authors":["Sam Bowyer","Laurence Aitchison","Desi R. Ivanova"],"pdf_url":"https://arxiv.org/pdf/2503.01747v2.pdf","comment":"36 pages, 37 figures"},{"id":"http://arxiv.org/abs/2402.14337v3","updated":"2025-03-04T11:22:10Z","published":"2024-02-22T07:12:34Z","title":"How Ambiguous Are the Rationales for Natural Language Reasoning? A\n  Simple Approach to Handling Rationale Uncertainty","summary":"  The quality of rationales is essential in the reasoning capabilities of\nlanguage models. Rationales not only enhance reasoning performance in complex\nnatural language tasks but also justify model decisions. However, obtaining\nimpeccable rationales is often impossible. Our study aims to investigate how\nambiguous rationales play in model performances of natural language reasoning.\nWe first assess the ambiguity of rationales through the lens of entropy and\nuncertainty in model prior beliefs, exploring its impact on task performance.\nWe then propose a simple way to guide models to choose between two different\nreasoning paths depending on the ambiguity of the rationales. Our empirical\nresults demonstrate that this approach leads to robust performance,\nparticularly in adversarial scenarios where rationale quality is inconsistent.\n","authors":["Hazel H. Kim"],"pdf_url":"https://arxiv.org/pdf/2402.14337v3.pdf","comment":"Accepted to COLING2025"},{"id":"http://arxiv.org/abs/2503.02512v1","updated":"2025-03-04T11:20:19Z","published":"2025-03-04T11:20:19Z","title":"LTL Verification of Memoryful Neural Agents","summary":"  We present a framework for verifying Memoryful Neural Multi-Agent Systems\n(MN-MAS) against full Linear Temporal Logic (LTL) specifications. In MN-MAS,\nagents interact with a non-deterministic, partially observable environment.\nExamples of MN-MAS include multi-agent systems based on feed-forward and\nrecurrent neural networks or state-space models. Different from previous\napproaches, we support the verification of both bounded and unbounded LTL\nspecifications. We leverage well-established bounded model checking techniques,\nincluding lasso search and invariant synthesis, to reduce the verification\nproblem to that of constraint solving. To solve these constraints, we develop\nefficient methods based on bound propagation, mixed-integer linear programming,\nand adaptive splitting. We evaluate the effectiveness of our algorithms in\nsingle and multi-agent environments from the Gymnasium and PettingZoo\nlibraries, verifying unbounded specifications for the first time and improving\nthe verification time for bounded specifications by an order of magnitude\ncompared to the SoA.\n","authors":["Mehran Hosseini","Alessio Lomuscio","Nicola Paoletti"],"pdf_url":"https://arxiv.org/pdf/2503.02512v1.pdf","comment":"11 pages, 2 figures, accepted at AAMAS 2025 conference"},{"id":"http://arxiv.org/abs/2409.14623v2","updated":"2025-03-04T11:18:33Z","published":"2024-09-22T23:19:04Z","title":"From Lazy to Rich: Exact Learning Dynamics in Deep Linear Networks","summary":"  Biological and artificial neural networks develop internal representations\nthat enable them to perform complex tasks. In artificial networks, the\neffectiveness of these models relies on their ability to build task specific\nrepresentation, a process influenced by interactions among datasets,\narchitectures, initialization strategies, and optimization algorithms. Prior\nstudies highlight that different initializations can place networks in either a\nlazy regime, where representations remain static, or a rich/feature learning\nregime, where representations evolve dynamically. Here, we examine how\ninitialization influences learning dynamics in deep linear neural networks,\nderiving exact solutions for lambda-balanced initializations-defined by the\nrelative scale of weights across layers. These solutions capture the evolution\nof representations and the Neural Tangent Kernel across the spectrum from the\nrich to the lazy regimes. Our findings deepen the theoretical understanding of\nthe impact of weight initialization on learning regimes, with implications for\ncontinual learning, reversal learning, and transfer learning, relevant to both\nneuroscience and practical applications.\n","authors":["Clmentine C. J. Domin","Nicolas Anguita","Alexandra M. Proca","Lukas Braun","Daniel Kunin","Pedro A. M. Mediano","Andrew M. Saxe"],"pdf_url":"https://arxiv.org/pdf/2409.14623v2.pdf","comment":"10 pages, 8 figures"},{"id":"http://arxiv.org/abs/2405.10822v2","updated":"2025-03-04T11:17:59Z","published":"2024-05-17T14:43:30Z","title":"Generative modeling through internal high-dimensional chaotic activity","summary":"  Generative modeling aims at producing new datapoints whose statistical\nproperties resemble the ones in a training dataset. In recent years, there has\nbeen a burst of machine learning techniques and settings that can achieve this\ngoal with remarkable performances. In most of these settings, one uses the\ntraining dataset in conjunction with noise, which is added as a source of\nstatistical variability and is essential for the generative task. Here, we\nexplore the idea of using internal chaotic dynamics in high-dimensional chaotic\nsystems as a way to generate new datapoints from a training dataset. We show\nthat simple learning rules can achieve this goal within a set of vanilla\narchitectures and characterize the quality of the generated datapoints through\nstandard accuracy measures.\n","authors":["Samantha J. Fournier","Pierfrancesco Urbani"],"pdf_url":"https://arxiv.org/pdf/2405.10822v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.02505v1","updated":"2025-03-04T11:16:46Z","published":"2025-03-04T11:16:46Z","title":"ROCKET-2: Steering Visuomotor Policy via Cross-View Goal Alignment","summary":"  We aim to develop a goal specification method that is semantically clear,\nspatially sensitive, and intuitive for human users to guide agent interactions\nin embodied environments. Specifically, we propose a novel cross-view goal\nalignment framework that allows users to specify target objects using\nsegmentation masks from their own camera views rather than the agent's\nobservations. We highlight that behavior cloning alone fails to align the\nagent's behavior with human intent when the human and agent camera views differ\nsignificantly. To address this, we introduce two auxiliary objectives:\ncross-view consistency loss and target visibility loss, which explicitly\nenhance the agent's spatial reasoning ability. According to this, we develop\nROCKET-2, a state-of-the-art agent trained in Minecraft, achieving an\nimprovement in the efficiency of inference 3x to 6x. We show ROCKET-2 can\ndirectly interpret goals from human camera views for the first time, paving the\nway for better human-agent interaction.\n","authors":["Shaofei Cai","Zhancun Mu","Anji Liu","Yitao Liang"],"pdf_url":"https://arxiv.org/pdf/2503.02505v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.02498v1","updated":"2025-03-04T11:04:36Z","published":"2025-03-04T11:04:36Z","title":"A Systematic Literature Review on Safety of the Intended Functionality\n  for Automated Driving Systems","summary":"  In the automobile industry, ensuring the safety of automated vehicles\nequipped with the Automated Driving System (ADS) is becoming a significant\nfocus due to the increasing development and deployment of automated driving.\nAutomated driving depends on sensing both the external and internal\nenvironments of a vehicle, utilizing perception sensors and algorithms, and\nElectrical/Electronic (E/E) systems for situational awareness and response. ISO\n21448 is the standard for Safety of the Intended Functionality (SOTIF) that\naims to ensure that the ADS operate safely within their intended functionality.\nSOTIF focuses on preventing or mitigating potential hazards that may arise from\nthe limitations or failures of the ADS, including hazards due to\ninsufficiencies of specification, or performance insufficiencies, as well as\nforeseeable misuse of the intended functionality. However, the challenge lies\nin ensuring the safety of vehicles despite the limited availability of\nextensive and systematic literature on SOTIF. To address this challenge, a\nSystematic Literature Review (SLR) on SOTIF for the ADS is performed following\nthe Preferred Reporting Items for Systematic Reviews and Meta-Analyses (PRISMA)\nguidelines. The objective is to methodically gather and analyze the existing\nliterature on SOTIF. The major contributions of this paper are: (i) presenting\na summary of the literature by synthesizing and organizing the collective\nfindings, methodologies, and insights into distinct thematic groups, and (ii)\nsummarizing and categorizing the acknowledged limitations based on data\nextracted from an SLR of 51 research papers published between 2018 and 2023.\nFurthermore, research gaps are determined, and future research directions are\nproposed.\n","authors":["Milin Patel","Rolf Jung","Marzana Khatun"],"pdf_url":"https://arxiv.org/pdf/2503.02498v1.pdf","comment":"Scheduled to be published in SAE journal as technical paper as a part\n  of non-technical event and will be available as open access in 2025"},{"id":"http://arxiv.org/abs/2503.02495v1","updated":"2025-03-04T11:01:25Z","published":"2025-03-04T11:01:25Z","title":"Union of Experts: Adapting Hierarchical Routing to Equivalently\n  Decomposed Transformer","summary":"  Mixture-of-Experts (MoE) enhances model performance while maintaining\ncomputational efficiency, making it well-suited for large-scale applications.\nHowever, expert in exist MoE paradigm works as an individual, thereby lacking\nhigh-quality expert interactions. Moreover, they have not been effectively\nextended to attention block, which constrains further efficiency improvements.\nTo tackle these issues, we propose Union-of-Experts (UoE), which decomposes\ntransformer into an equitant group of experts, and then implement dynamic\nrouting on input data and experts. Our approach advances MoE design with three\nkey innovations: (1) We conducted equitant expert decomposition on both MLP\nblocks and attention blocks based on matrix partition in tensor parallelism.\n(2) We developed two routing paradigms: patch wise data selection and expert\nselection, to apply routing across different levels. (3) We design the\narchitecture of UoE model, including Selective Multi-Head Attention (SMHA) and\nUnion-of-MLP-Experts (UoME). (4) We develop parallel implementation of UoE's\nrouting and computation operation, and optimize efficiency based on the\nhardware processing analysis. The experiments demonstrate that the model\nemployed with UoE surpass Full Attention, state-of-art MoEs and efficient\ntransformers in several tasks across image and natural language domains. The\nsource codes are available at https://github.com/YujiaoYang-work/UoE.\n","authors":["Yujiao Yang","Jing Lian","Linhui Li"],"pdf_url":"https://arxiv.org/pdf/2503.02495v1.pdf","comment":"17 pages, 6 figures, 5 tables"},{"id":"http://arxiv.org/abs/2503.02494v1","updated":"2025-03-04T11:00:08Z","published":"2025-03-04T11:00:08Z","title":"The Distributionally Robust Optimization Model of Sparse Principal\n  Component Analysis","summary":"  We consider sparse principal component analysis (PCA) under a stochastic\nsetting where the underlying probability distribution of the random parameter\nis uncertain. This problem is formulated as a distributionally robust\noptimization (DRO) model based on a constructive approach to capturing\nuncertainty in the covariance matrix, which constitutes a nonsmooth constrained\nmin-max optimization problem. We further prove that the inner maximization\nproblem admits a closed-form solution, reformulating the original DRO model\ninto an equivalent minimization problem on the Stiefel manifold. This\ntransformation leads to a Riemannian optimization problem with intricate\nnonsmooth terms, a challenging formulation beyond the reach of existing\nalgorithms. To address this issue, we devise an efficient smoothing manifold\nproximal gradient algorithm. We prove the Riemannian gradient consistency and\nglobal convergence of our algorithm to a stationary point of the nonsmooth\nminimization problem. Moreover, we establish the iteration complexity of our\nalgorithm. Finally, numerical experiments are conducted to validate the\neffectiveness and scalability of our algorithm, as well as to highlight the\nnecessity and rationality of adopting the DRO model for sparse PCA.\n","authors":["Lei Wang","Xin Liu","Xiaojun Chen"],"pdf_url":"https://arxiv.org/pdf/2503.02494v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2501.08180v2","updated":"2025-03-04T10:58:45Z","published":"2025-01-14T15:03:53Z","title":"D$^2$-DPM: Dual Denoising for Quantized Diffusion Probabilistic Models","summary":"  Diffusion models have achieved cutting-edge performance in image generation.\nHowever, their lengthy denoising process and computationally intensive score\nestimation network impede their scalability in low-latency and\nresource-constrained scenarios. Post-training quantization (PTQ) compresses and\naccelerates diffusion models without retraining, but it inevitably introduces\nadditional quantization noise, resulting in mean and variance deviations. In\nthis work, we propose D2-DPM, a dual denoising mechanism aimed at precisely\nmitigating the adverse effects of quantization noise on the noise estimation\nnetwork. Specifically, we first unravel the impact of quantization noise on the\nsampling equation into two components: the mean deviation and the variance\ndeviation. The mean deviation alters the drift coefficient of the sampling\nequation, influencing the trajectory trend, while the variance deviation\nmagnifies the diffusion coefficient, impacting the convergence of the sampling\ntrajectory. The proposed D2-DPM is thus devised to denoise the quantization\nnoise at each time step, and then denoise the noisy sample through the inverse\ndiffusion iterations. Experimental results demonstrate that D2-DPM achieves\nsuperior generation quality, yielding a 1.42 lower FID than the full-precision\nmodel while achieving 3.99x compression and 11.67x bit-operation acceleration.\n","authors":["Qian Zeng","Jie Song","Han Zheng","Hao Jiang","Mingli Song"],"pdf_url":"https://arxiv.org/pdf/2501.08180v2.pdf","comment":"9 pages, 4 figures, acceptted by AAAI2025, the code is available at\n  https://github.com/taylorjocelyn/d2-dpm"},{"id":"http://arxiv.org/abs/2503.02491v1","updated":"2025-03-04T10:57:24Z","published":"2025-03-04T10:57:24Z","title":"Joint Out-of-Distribution Filtering and Data Discovery Active Learning","summary":"  As the data demand for deep learning models increases, active learning (AL)\nbecomes essential to strategically select samples for labeling, which maximizes\ndata efficiency and reduces training costs. Real-world scenarios necessitate\nthe consideration of incomplete data knowledge within AL. Prior works address\nhandling out-of-distribution (OOD) data, while another research direction has\nfocused on category discovery. However, a combined analysis of real-world\nconsiderations combining AL with out-of-distribution data and category\ndiscovery remains unexplored. To address this gap, we propose Joint\nOut-of-distribution filtering and data Discovery Active learning (Joda) , to\nuniquely address both challenges simultaneously by filtering out OOD data\nbefore selecting candidates for labeling. In contrast to previous methods, we\ndeeply entangle the training procedure with filter and selection to construct a\ncommon feature space that aligns known and novel categories while separating\nOOD samples. Unlike previous works, Joda is highly efficient and completely\nomits auxiliary models and training access to the unlabeled pool for filtering\nor selection. In extensive experiments on 18 configurations and 3 metrics,\n\\ours{} consistently achieves the highest accuracy with the best class\ndiscovery to OOD filtering balance compared to state-of-the-art competitor\napproaches.\n","authors":["Sebastian Schmidt","Leonard Schenk","Leo Schwinn","Stephan Gnnemann"],"pdf_url":"https://arxiv.org/pdf/2503.02491v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2502.19811v3","updated":"2025-03-04T09:54:37Z","published":"2025-02-27T06:36:45Z","title":"Comet: Fine-grained Computation-communication Overlapping for\n  Mixture-of-Experts","summary":"  Mixture-of-experts (MoE) has been extensively employed to scale large\nlanguage models to trillion-plus parameters while maintaining a fixed\ncomputational cost. The development of large MoE models in the distributed\nscenario encounters the problem of large communication overhead. The\ninter-device communication of a MoE layer can occupy 47% time of the entire\nmodel execution with popular models and frameworks. Therefore, existing methods\nsuggest the communication in a MoE layer to be pipelined with the computation\nfor overlapping. However, these coarse grained overlapping schemes introduce a\nnotable impairment of computational efficiency and the latency concealing is\nsub-optimal.\n  To this end, we present COMET, an optimized MoE system with fine-grained\ncommunication-computation overlapping. Leveraging data dependency analysis and\ntask rescheduling, COMET achieves precise fine-grained overlapping of\ncommunication and computation. Through adaptive workload assignment, COMET\neffectively eliminates fine-grained communication bottlenecks and enhances its\nadaptability across various scenarios. Our evaluation shows that COMET\naccelerates the execution of a single MoE layer by $1.96\\times$ and for\nend-to-end execution, COMET delivers a $1.71\\times$ speedup on average. COMET\nhas been adopted in the production environment of clusters with\nten-thousand-scale of GPUs, achieving savings of millions of GPU hours.\n","authors":["Shulai Zhang","Ningxin Zheng","Haibin Lin","Ziheng Jiang","Wenlei Bao","Chengquan Jiang","Qi Hou","Weihao Cui","Size Zheng","Li-Wen Chang","Quan Chen","Xin Liu"],"pdf_url":"https://arxiv.org/pdf/2502.19811v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2110.02784v2","updated":"2025-03-04T09:54:34Z","published":"2021-10-06T14:05:26Z","title":"Scalable Multi-Agent Reinforcement Learning for Residential Load\n  Scheduling under Data Governance","summary":"  As a data-driven approach, multi-agent reinforcement learning (MARL) has made\nremarkable advances in solving cooperative residential load scheduling\nproblems. However, centralized training, the most common paradigm for MARL,\nlimits large-scale deployment in communication-constrained cloud-edge\nenvironments. As a remedy, distributed training shows unparalleled advantages\nin real-world applications but still faces challenge with system scalability,\ne.g., the high cost of communication overhead during coordinating individual\nagents, and needs to comply with data governance in terms of privacy. In this\nwork, we propose a novel MARL solution to address these two practical issues.\nOur proposed approach is based on actor-critic methods, where the global critic\nis a learned function of individual critics computed solely based on local\nobservations of households. This scheme preserves household privacy completely\nand significantly reduces communication cost. Simulation experiments\ndemonstrate that the proposed framework achieves comparable performance to the\nstate-of-the-art actor-critic framework without data governance and\ncommunication constraints.\n","authors":["Zhaoming Qin","Nanqing Dong","Di Liu","Zhefan Wang","Junwei Cao"],"pdf_url":"https://arxiv.org/pdf/2110.02784v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.02449v1","updated":"2025-03-04T09:50:59Z","published":"2025-03-04T09:50:59Z","title":"Joint Tensor and Inter-View Low-Rank Recovery for Incomplete Multiview\n  Clustering","summary":"  Incomplete multiview clustering (IMVC) has gained significant attention for\nits effectiveness in handling missing sample challenges across various views in\nreal-world multiview clustering applications. Most IMVC approaches tackle this\nproblem by either learning consensus representations from available views or\nreconstructing missing samples using the underlying manifold structure.\nHowever, the reconstruction of learned similarity graph tensor in prior studies\nonly exploits the low-tubal-rank information, neglecting the exploration of\ninter-view correlations. This paper propose a novel joint tensor and inter-view\nlow-rank Recovery (JTIV-LRR), framing IMVC as a joint optimization problem that\nintegrates incomplete similarity graph learning and tensor representation\nrecovery. By leveraging both intra-view and inter-view low rank information,\nthe method achieves robust estimation of the complete similarity graph tensor\nthrough sparse noise removal and low-tubal-rank constraints along different\nmodes. Extensive experiments on both synthetic and real-world datasets\ndemonstrate the superiority of the proposed approach, achieving significant\nimprovements in clustering accuracy and robustness compared to state-of-the-art\nmethods.\n","authors":["Jianyu Wang","Zhengqiao Zhao","Nicolas Dobigeon","Jingdong Chen"],"pdf_url":"https://arxiv.org/pdf/2503.02449v1.pdf","comment":"The paper is under review at IEEE Transactions on Knowledge and Data\n  Engineering"},{"id":"http://arxiv.org/abs/2503.02448v1","updated":"2025-03-04T09:45:27Z","published":"2025-03-04T09:45:27Z","title":"NodeNAS: Node-Specific Graph Neural Architecture Search for\n  Out-of-Distribution Generalization","summary":"  Graph neural architecture search (GraphNAS) has demonstrated advantages in\nmitigating performance degradation of graph neural networks (GNNs) due to\ndistribution shifts. Recent approaches introduce weight sharing across tailored\narchitectures, generating unique GNN architectures for each graph end-to-end.\nHowever, existing GraphNAS methods do not account for distribution patterns\nacross different graphs and heavily rely on extensive training data. With\nsparse or single training graphs, these methods struggle to discover optimal\nmappings between graphs and architectures, failing to generalize to\nout-of-distribution (OOD) data. In this paper, we propose node-specific graph\nneural architecture search(NodeNAS), which aims to tailor distinct aggregation\nmethods for different nodes through disentangling node topology and graph\ndistribution with limited datasets. We further propose adaptive aggregation\nattention based multi-dim NodeNAS method(MNNAS), which learns an node-specific\narchitecture customizer with good generalizability. Specifically, we extend the\nvertical depth of the search space, supporting simultaneous node-specific\narchitecture customization across multiple dimensions. Moreover, we model the\npower-law distribution of node degrees under varying assortativity, encoding\nstructure invariant information to guide architecture customization across each\ndimension. Extensive experiments across supervised and unsupervised tasks\ndemonstrate that MNNAS surpasses state-of-the-art algorithms and achieves\nexcellent OOD generalization.\n","authors":["Qiyi Wang","Yinning Shao","Yunlong Ma","Min Liu"],"pdf_url":"https://arxiv.org/pdf/2503.02448v1.pdf","comment":"Accepted by DASFAA2025"},{"id":"http://arxiv.org/abs/2503.02445v1","updated":"2025-03-04T09:40:00Z","published":"2025-03-04T09:40:00Z","title":"BRIDGE: Bootstrapping Text to Control Time-Series Generation via\n  Multi-Agent Iterative Optimization and Diffusion Modelling","summary":"  Time-series Generation (TSG) is a prominent research area with broad\napplications in simulations, data augmentation, and counterfactual analysis.\nWhile existing methods have shown promise in unconditional single-domain TSG,\nreal-world applications demand for cross-domain approaches capable of\ncontrolled generation tailored to domain-specific constraints and\ninstance-level requirements. In this paper, we argue that text can provide\nsemantic insights, domain information and instance-specific temporal patterns,\nto guide and improve TSG. We introduce ``Text-Controlled TSG'', a task focused\non generating realistic time series by incorporating textual descriptions. To\naddress data scarcity in this setting, we propose a novel LLM-based Multi-Agent\nframework that synthesizes diverse, realistic text-to-TS datasets. Furthermore,\nwe introduce BRIDGE, a hybrid text-controlled TSG framework that integrates\nsemantic prototypes with text description for supporting domain-level guidance.\nThis approach achieves state-of-the-art generation fidelity on 11 of 12\ndatasets, and improves controllability by 12.52% on MSE and 6.34% MAE compared\nto no text input generation, highlighting its potential for generating tailored\ntime-series data.\n","authors":["Hao Li","Yu-Hao Huang","Chang Xu","Viktor Schlegel","Ren-He Jiang","Riza Batista-Navarro","Goran Nenadic","Jiang Bian"],"pdf_url":"https://arxiv.org/pdf/2503.02445v1.pdf","comment":"Preprint. Work in progress"},{"id":"http://arxiv.org/abs/2503.02440v1","updated":"2025-03-04T09:36:58Z","published":"2025-03-04T09:36:58Z","title":"Artificial Intelligence in Reactor Physics: Current Status and Future\n  Prospects","summary":"  Reactor physics is the study of neutron properties, focusing on using models\nto examine the interactions between neutrons and materials in nuclear reactors.\nArtificial intelligence (AI) has made significant contributions to reactor\nphysics, e.g., in operational simulations, safety design, real-time monitoring,\ncore management and maintenance. This paper presents a comprehensive review of\nAI approaches in reactor physics, especially considering the category of\nMachine Learning (ML), with the aim of describing the application scenarios,\nfrontier topics, unsolved challenges and future research directions. From\nequation solving and state parameter prediction to nuclear industry\napplications, this paper provides a step-by-step overview of ML methods applied\nto steady-state, transient and combustion problems. Most literature works\nachieve industry-demanded models by enhancing the efficiency of deterministic\nmethods or correcting uncertainty methods, which leads to successful\napplications. However, research on ML methods in reactor physics is somewhat\nfragmented, and the ability to generalize models needs to be strengthened.\nProgress is still possible, especially in addressing theoretical challenges and\nenhancing industrial applications such as building surrogate models and digital\ntwins.\n","authors":["Ruizhi Zhang","Shengfeng Zhu","Kan Wang","Ding She","Jean-Philippe Argaud","Bertrand Bouriquet","Qing Li","Helin Gong"],"pdf_url":"https://arxiv.org/pdf/2503.02440v1.pdf","comment":"33 pages, 6 figures"},{"id":"http://arxiv.org/abs/2310.04285v3","updated":"2025-03-04T09:25:47Z","published":"2023-10-06T14:37:22Z","title":"Assessing Robustness via Score-Based Adversarial Image Generation","summary":"  Most adversarial attacks and defenses focus on perturbations within small\n$\\ell_p$-norm constraints. However, $\\ell_p$ threat models cannot capture all\nrelevant semantics-preserving perturbations, and hence, the scope of robustness\nevaluations is limited. In this work, we introduce Score-Based Adversarial\nGeneration (ScoreAG), a novel framework that leverages the advancements in\nscore-based generative models to generate unrestricted adversarial examples\nthat overcome the limitations of $\\ell_p$-norm constraints. Unlike traditional\nmethods, ScoreAG maintains the core semantics of images while generating\nadversarial examples, either by transforming existing images or synthesizing\nnew ones entirely from scratch. We further exploit the generative capability of\nScoreAG to purify images, empirically enhancing the robustness of classifiers.\nOur extensive empirical evaluation demonstrates that ScoreAG improves upon the\nmajority of state-of-the-art attacks and defenses across multiple benchmarks.\nThis work highlights the importance of investigating adversarial examples\nbounded by semantics rather than $\\ell_p$-norm constraints. ScoreAG represents\nan important step towards more encompassing robustness assessments.\n","authors":["Marcel Kollovieh","Lukas Gosch","Marten Lienen","Yan Scholten","Leo Schwinn","Stephan Gnnemann"],"pdf_url":"https://arxiv.org/pdf/2310.04285v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.02437v1","updated":"2025-03-04T09:23:48Z","published":"2025-03-04T09:23:48Z","title":"Decentralized Reinforcement Learning for Multi-Agent Multi-Resource\n  Allocation via Dynamic Cluster Agreements","summary":"  This paper addresses the challenge of allocating heterogeneous resources\namong multiple agents in a decentralized manner. Our proposed method,\nLGTC-IPPO, builds upon Independent Proximal Policy Optimization (IPPO) by\nintegrating dynamic cluster consensus, a mechanism that allows agents to form\nand adapt local sub-teams based on resource demands. This decentralized\ncoordination strategy reduces reliance on global information and enhances\nscalability. We evaluate LGTC-IPPO against standard multi-agent reinforcement\nlearning baselines and a centralized expert solution across a range of team\nsizes and resource distributions. Experimental results demonstrate that\nLGTC-IPPO achieves more stable rewards, better coordination, and robust\nperformance even as the number of agents or resource types increases.\nAdditionally, we illustrate how dynamic clustering enables agents to reallocate\nresources efficiently also for scenarios with discharging resources.\n","authors":["Antonio Marino","Esteban Restrepo","Claudio Pacchierotti","Paolo Robuffo Giordano"],"pdf_url":"https://arxiv.org/pdf/2503.02437v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2502.15317v2","updated":"2025-03-04T09:20:44Z","published":"2025-02-21T09:11:07Z","title":"Utilizing Sequential Information of General Lab-test Results and\n  Diagnoses History for Differential Diagnosis of Dementia","summary":"  Early diagnosis of Alzheimer's Disease (AD) faces multiple data-related\nchallenges, including high variability in patient data, limited access to\nspecialized diagnostic tests, and overreliance on single-type indicators. These\nchallenges are exacerbated by the progressive nature of AD, where subtle\npathophysiological changes often precede clinical symptoms by decades. To\naddress these limitations, this study proposes a novel approach that takes\nadvantage of routinely collected general laboratory test histories for the\nearly detection and differential diagnosis of AD. By modeling lab test\nsequences as \"sentences\", we apply word embedding techniques to capture latent\nrelationships between tests and employ deep time series models, including\nlong-short-term memory (LSTM) and Transformer networks, to model temporal\npatterns in patient records. Experimental results demonstrate that our approach\nimproves diagnostic accuracy and enables scalable and costeffective AD\nscreening in diverse clinical settings.\n","authors":["Yizong Xing","Dhita Putri Pratama","Yuke Wang","Yufan Zhang","Brian E. Chapman"],"pdf_url":"https://arxiv.org/pdf/2502.15317v2.pdf","comment":"7 pages, 6 figures. This work has been submitted to the Elsevier for\n  possible publication"},{"id":"http://arxiv.org/abs/2308.15905v2","updated":"2025-03-04T09:20:42Z","published":"2023-08-30T09:15:41Z","title":"Thermodynamic Computing via Autonomous Quantum Thermal Machines","summary":"  We develop a physics-based model for classical computation based on\nautonomous quantum thermal machines. These machines consist of few interacting\nquantum bits (qubits) connected to several environments at different\ntemperatures. Heat flows through the machine are here exploited for computing.\nThe process starts by setting the temperatures of the environments according to\nthe logical input. The machine evolves, eventually reaching a non-equilibrium\nsteady state, from which the output of the computation can be determined via\nthe temperature of an auxilliary finite-size reservoir. Such a machine, which\nwe term a ``thermodynamic neuron'', can implement any linearly-separable\nfunction, and we discuss explicitly the cases of NOT, 3-MAJORITY and NOR gates.\nIn turn, we show that a network of thermodynamic neurons can perform any\ndesired function. We discuss the close connection between our model and\nartificial neurons (perceptrons), and argue that our model provides an\nalternative physics-based analogue implementation of neural networks, and more\ngenerally a platform for thermodynamic computing.\n","authors":["Patryk Lipka-Bartosik","Mart Perarnau-Llobet","Nicolas Brunner"],"pdf_url":"https://arxiv.org/pdf/2308.15905v2.pdf","comment":"15 + 5 pages. Published version"},{"id":"http://arxiv.org/abs/2503.02428v1","updated":"2025-03-04T09:18:35Z","published":"2025-03-04T09:18:35Z","title":"Tight Gap-Dependent Memory-Regret Trade-Off for Single-Pass Streaming\n  Stochastic Multi-Armed Bandits","summary":"  We study the problem of minimizing gap-dependent regret for single-pass\nstreaming stochastic multi-armed bandits (MAB). In this problem, the $n$ arms\nare present in a stream, and at most $m<n$ arms and their statistics can be\nstored in the memory. We establish tight non-asymptotic regret bounds regarding\nall relevant parameters, including the number of arms $n$, the memory size $m$,\nthe number of rounds $T$ and $(\\Delta_i)_{i\\in [n]}$ where $\\Delta_i$ is the\nreward mean gap between the best arm and the $i$-th arm. These gaps are not\nknown in advance by the player. Specifically, for any constant $\\alpha \\ge 1$,\nwe present two algorithms: one applicable for $m\\ge \\frac{2}{3}n$ with regret\nat most $O_\\alpha\\Big(\\frac{(n-m)T^{\\frac{1}{\\alpha + 1}}}{n^{1 +\n{\\frac{1}{\\alpha + 1}}}}\\displaystyle\\sum_{i:\\Delta_i > 0}\\Delta_i^{1 -\n2\\alpha}\\Big)$ and another applicable for $m<\\frac{2}{3}n$ with regret at most\n$O_\\alpha\\Big(\\frac{T^{\\frac{1}{\\alpha+1}}}{m^{\\frac{1}{\\alpha+1}}}\\displaystyle\\sum_{i:\\Delta_i\n> 0}\\Delta_i^{1 - 2\\alpha}\\Big)$. We also prove matching lower bounds for both\ncases by showing that for any constant $\\alpha\\ge 1$ and any $m\\leq k < n$,\nthere exists a set of hard instances on which the regret of any algorithm is\n$\\Omega_\\alpha\\Big(\\frac{(k-m+1) T^{\\frac{1}{\\alpha+1}}}{k^{1 +\n\\frac{1}{\\alpha+1}}} \\sum_{i:\\Delta_i > 0}\\Delta_i^{1-2\\alpha}\\Big)$. This is\nthe first tight gap-dependent regret bound for streaming MAB. Prior to our\nwork, an $O\\Big(\\sum_{i\\colon\\Delta>0} \\frac{\\sqrt{T}\\log T}{\\Delta_i}\\Big)$\nupper bound for the special case of $\\alpha=1$ and $m=O(1)$ was established by\nAgarwal, Khanna and Patil (COLT'22). In contrast, our results provide the\ncorrect order of regret as\n$\\Theta\\Big(\\frac{1}{\\sqrt{m}}\\sum_{i\\colon\\Delta>0}\\frac{\\sqrt{T}}{\\Delta_i}\\Big)$.\n","authors":["Zichun Ye","Chihao Zhang","Jiahao Zhao"],"pdf_url":"https://arxiv.org/pdf/2503.02428v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2405.07312v3","updated":"2025-03-04T09:09:40Z","published":"2024-05-12T15:46:52Z","title":"Nonparametric Control Koopman Operators","summary":"  This paper presents a novel Koopman (composition) operator representation\nframework for control systems in reproducing kernel Hilbert spaces (RKHSs) that\nis free of explicit dictionary or input parametrizations. By establishing\nfundamental equivalences between different model representations, we are able\nto close the gap of control system operator learning and infinite-dimensional\nregression, enabling various empirical estimators and the connection to\nwell-understood learning theory in RKHSs under one unified framework. As a\nconsequence, our proposed framework allows for arbitrary accurate finite-rank\napproximations in infinite-dimensional spaces and leads to finite-dimensional\npredictors without apriori restrictions to a finite span of functions or\ninputs. To enable applications to high-dimensional control systems, we improve\nthe scalability of our proposed control Koopman operator estimates by utilizing\nsketching techniques. Numerical experiments demonstrate superior prediction\naccuracy compared to bilinear EDMD, especially in high dimensions. Finally, we\nshow that our learned models are readily interfaced with\nlinear-parameter-varying techniques for model predictive control.\n","authors":["Petar Bevanda","Bas Driessen","Lucian Cristian Iacob","Stefan Sosnowski","Roland Tth","Sandra Hirche"],"pdf_url":"https://arxiv.org/pdf/2405.07312v3.pdf","comment":"The authors' electronic preprint version of an article submitted to\n  IEEE for publication"},{"id":"http://arxiv.org/abs/2503.02422v1","updated":"2025-03-04T09:08:33Z","published":"2025-03-04T09:08:33Z","title":"Aggregation Strategies for Efficient Annotation of Bioacoustic Sound\n  Events Using Active Learning","summary":"  The vast amounts of audio data collected in Sound Event Detection (SED)\napplications require efficient annotation strategies to enable supervised\nlearning. Manual labeling is expensive and time-consuming, making Active\nLearning (AL) a promising approach for reducing annotation effort. We introduce\nTop K Entropy, a novel uncertainty aggregation strategy for AL that prioritizes\nthe most uncertain segments within an audio recording, instead of averaging\nuncertainty across all segments. This approach enables the selection of entire\nrecordings for annotation, improving efficiency in sparse data scenarios. We\ncompare Top K Entropy to random sampling and Mean Entropy, and show that fewer\nlabels can lead to the same model performance, particularly in datasets with\nsparse sound events. Evaluations are conducted on audio mixtures of sound\nrecordings from parks with meerkat, dog, and baby crying sound events,\nrepresenting real-world bioacoustic monitoring scenarios. Using Top K Entropy\nfor active learning, we can achieve comparable performance to training on the\nfully labeled dataset with only 8% of the labels. Top K Entropy outperforms\nMean Entropy, suggesting that it is best to let the most uncertain segments\nrepresent the uncertainty of an audio file. The findings highlight the\npotential of AL for scalable annotation in audio and time-series applications,\nincluding bioacoustics.\n","authors":["Richard Lindholm","Oscar Marklund","Olof Mogren","John Martinsson"],"pdf_url":"https://arxiv.org/pdf/2503.02422v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.02421v1","updated":"2025-03-04T09:05:42Z","published":"2025-03-04T09:05:42Z","title":"A Transformer-Based Framework for Greek Sign Language Production using\n  Extended Skeletal Motion Representations","summary":"  Sign Languages are the primary form of communication for Deaf communities\nacross the world. To break the communication barriers between the Deaf and\nHard-of-Hearing and the hearing communities, it is imperative to build systems\ncapable of translating the spoken language into sign language and vice versa.\nBuilding on insights from previous research, we propose a deep learning model\nfor Sign Language Production (SLP), which to our knowledge is the first attempt\non Greek SLP. We tackle this task by utilizing a transformer-based architecture\nthat enables the translation from text input to human pose keypoints, and the\nopposite. We evaluate the effectiveness of the proposed pipeline on the Greek\nSL dataset Elementary23, through a series of comparative analyses and ablation\nstudies. Our pipeline's components, which include data-driven gloss generation,\ntraining through video to text translation and a scheduling algorithm for\nteacher forcing - auto-regressive decoding seem to actively enhance the quality\nof produced SL videos.\n","authors":["Chrysa Pratikaki","Panagiotis Filntisis","Athanasios Katsamanis","Anastasios Roussos","Petros Maragos"],"pdf_url":"https://arxiv.org/pdf/2503.02421v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2502.07005v4","updated":"2025-03-04T08:58:53Z","published":"2025-02-10T20:10:25Z","title":"Geometry-aware RL for Manipulation of Varying Shapes and Deformable\n  Objects","summary":"  Manipulating objects with varying geometries and deformable objects is a\nmajor challenge in robotics. Tasks such as insertion with different objects or\ncloth hanging require precise control and effective modelling of complex\ndynamics. In this work, we frame this problem through the lens of a\nheterogeneous graph that comprises smaller sub-graphs, such as actuators and\nobjects, accompanied by different edge types describing their interactions.\nThis graph representation serves as a unified structure for both rigid and\ndeformable objects tasks, and can be extended further to tasks comprising\nmultiple actuators. To evaluate this setup, we present a novel and challenging\nreinforcement learning benchmark, including rigid insertion of diverse objects,\nas well as rope and cloth manipulation with multiple end-effectors. These tasks\npresent a large search space, as both the initial and target configurations are\nuniformly sampled in 3D space. To address this issue, we propose a novel\ngraph-based policy model, dubbed Heterogeneous Equivariant Policy (HEPi),\nutilizing $SE(3)$ equivariant message passing networks as the main backbone to\nexploit the geometric symmetry. In addition, by modeling explicit\nheterogeneity, HEPi can outperform Transformer-based and non-heterogeneous\nequivariant policies in terms of average returns, sample efficiency, and\ngeneralization to unseen objects. Our project page is available at\nhttps://thobotics.github.io/hepi.\n","authors":["Tai Hoang","Huy Le","Philipp Becker","Vien Anh Ngo","Gerhard Neumann"],"pdf_url":"https://arxiv.org/pdf/2502.07005v4.pdf","comment":"Accepted at ICLR 2025 (Oral)"},{"id":"http://arxiv.org/abs/2503.02414v1","updated":"2025-03-04T08:58:30Z","published":"2025-03-04T08:58:30Z","title":"InfoGNN: End-to-end deep learning on mesh via graph neural networks","summary":"  3D models are widely used in various industries, and mesh data has become an\nindispensable part of 3D modeling because of its unique advantages. Mesh data\ncan provide an intuitive and practical expression of rich 3D information.\nHowever, its disordered, irregular data structure and complex surface\ninformation make it challenging to apply with deep learning models directly.\nTraditional mesh data processing methods often rely on mesh models with many\nlimitations, such as manifold, which restrict their application scopes in\nreality and do not fully utilize the advantages of mesh models. This paper\nproposes a novel end-to-end framework for addressing the challenges associated\nwith deep learning in mesh models centered around graph neural networks (GNN)\nand is titled InfoGNN. InfoGNN treats the mesh model as a graph, which enables\nit to handle irregular mesh data efficiently. Moreover, we propose InfoConv and\nInfoMP modules, which utilize the position information of the points and fully\nuse the static information such as face normals, dihedral angles, and dynamic\nglobal feature information to fully use all kinds of data. In addition, InfoGNN\nis an end-to-end framework, and we simplify the network design to make it more\nefficient, paving the way for efficient deep learning of complex 3D models. We\nconducted experiments on several publicly available datasets, and the results\nshow that InfoGNN achieves excellent performance in mesh classification and\nsegmentation tasks.\n","authors":["Ling Gao","Zhenyu Shu","Shiqing Xin"],"pdf_url":"https://arxiv.org/pdf/2503.02414v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.02407v1","updated":"2025-03-04T08:50:10Z","published":"2025-03-04T08:50:10Z","title":"Wyckoff Transformer: Generation of Symmetric Crystals","summary":"  Symmetry rules that atoms obey when they bond together to form an ordered\ncrystal play a fundamental role in determining their physical, chemical, and\nelectronic properties such as electrical and thermal conductivity, optical and\npolarization behavior, and mechanical strength. Almost all known crystalline\nmaterials have internal symmetry. Consistently generating stable crystal\nstructures is still an open challenge, specifically because such symmetry rules\nare not accounted for. To address this issue, we propose WyFormer, a generative\nmodel for materials conditioned on space group symmetry. We use Wyckoff\npositions as the basis for an elegant, compressed, and discrete structure\nrepresentation. To model the distribution, we develop a permutation-invariant\nautoregressive model based on the Transformer and an absence of positional\nencoding. WyFormer has a unique and powerful synergy of attributes, proven by\nextensive experimentation: best-in-class symmetry-conditioned generation,\nphysics-motivated inductive bias, competitive stability of the generated\nstructures, competitive material property prediction quality, and unparalleled\ninference speed.\n","authors":["Nikita Kazeev","Wei Nong","Ignat Romanov","Ruiming Zhu","Andrey Ustyuzhanin","Shuya Yamazaki","Kedar Hippalgaonkar"],"pdf_url":"https://arxiv.org/pdf/2503.02407v1.pdf","comment":"https://github.com/SymmetryAdvantage/WyckoffTransformer"},{"id":"http://arxiv.org/abs/2503.01507v2","updated":"2025-03-04T08:47:15Z","published":"2025-03-03T13:22:37Z","title":"Compare different SG-Schemes based on large least square problems","summary":"  This study reviews popular stochastic gradient-based schemes based on large\nleast-square problems. These schemes, often called optimizers in machine\nlearning, play a crucial role in finding better model parameters. Hence, this\nstudy focuses on viewing such optimizers with different hyper-parameters and\nanalyzing them based on least square problems. Codes that produced results in\nthis work are available on\nhttps://github.com/q-viper/gradients-based-methods-on-large-least-square.\n","authors":["Ramkrishna Acharya"],"pdf_url":"https://arxiv.org/pdf/2503.01507v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.00897v2","updated":"2025-03-04T08:46:27Z","published":"2025-03-02T13:43:53Z","title":"A Simple and Effective Reinforcement Learning Method for Text-to-Image\n  Diffusion Fine-tuning","summary":"  Reinforcement learning ( RL)-based fine-tuning has emerged as a powerful\napproach for aligning diffusion models with black-box objectives. Proximal\npolicy optimization (PPO) is the most popular choice of method for policy\noptimization. While effective in terms of performance, PPO is highly sensitive\nto hyper-parameters and involves substantial computational overhead. REINFORCE,\non the other hand, mitigates some computational complexities such as high\nmemory overhead and sensitive hyper-parameter tuning, but has suboptimal\nperformance due to high-variance and sample inefficiency. While the variance of\nthe REINFORCE can be reduced by sampling multiple actions per input prompt and\nusing a baseline correction term, it still suffers from sample inefficiency. To\naddress these challenges, we systematically analyze the\nefficiency-effectiveness trade-off between REINFORCE and PPO, and propose\nleave-one-out PPO ( LOOP), a novel RL for diffusion fine-tuning method. LOOP\ncombines variance reduction techniques from REINFORCE, such as sampling\nmultiple actions per input prompt and a baseline correction term, with the\nrobustness and sample efficiency of PPO via clipping and importance sampling.\nOur results demonstrate that LOOP effectively improves diffusion models on\nvarious black-box objectives, and achieves a better balance between\ncomputational efficiency and performance.\n","authors":["Shashank Gupta","Chaitanya Ahuja","Tsung-Yu Lin","Sreya Dutta Roy","Harrie Oosterhuis","Maarten de Rijke","Satya Narayan Shukla"],"pdf_url":"https://arxiv.org/pdf/2503.00897v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2407.16293v2","updated":"2025-03-04T08:41:42Z","published":"2024-07-23T08:51:29Z","title":"A new Linear Time Bi-level $\\ell_{1,\\infty}$ projection ; Application to\n  the sparsification of auto-encoders neural networks","summary":"  The $\\ell_{1,\\infty}$ norm is an efficient-structured projection, but the\ncomplexity of the best algorithm is, unfortunately, $\\mathcal{O}\\big(n m \\log(n\nm)\\big)$ for a matrix $n\\times m$.\\\\ In this paper, we propose a new bi-level\nprojection method, for which we show that the time complexity for the\n$\\ell_{1,\\infty}$ norm is only $\\mathcal{O}\\big(n m \\big)$ for a matrix\n$n\\times m$. Moreover, we provide a new $\\ell_{1,\\infty}$ identity with\nmathematical proof and experimental validation. Experiments show that our\nbi-level $\\ell_{1,\\infty}$ projection is $2.5$ times faster than the actual\nfastest algorithm and provides the best sparsity while keeping the same\naccuracy in classification applications.\n","authors":["Michel Barlaud","Guillaume Perez","Jean-Paul Marmorat"],"pdf_url":"https://arxiv.org/pdf/2407.16293v2.pdf","comment":"arXiv admin note: substantial text overlap with arXiv:2405.02086"},{"id":"http://arxiv.org/abs/2503.02397v1","updated":"2025-03-04T08:40:42Z","published":"2025-03-04T08:40:42Z","title":"A Binary Classification Social Network Dataset for Graph Machine\n  Learning","summary":"  Social networks have a vast range of applications with graphs. The available\nbenchmark datasets are citation, co-occurrence, e-commerce networks, etc, with\nclasses ranging from 3 to 15. However, there is no benchmark classification\nsocial network dataset for graph machine learning. This paper fills the gap and\npresents the Binary Classification Social Network Dataset (\\textit{BiSND}),\ndesigned for graph machine learning applications to predict binary classes. We\npresent the BiSND in \\textit{tabular and graph} formats to verify its\nrobustness across classical and advanced machine learning. We employ a diverse\nset of classifiers, including four traditional machine learning algorithms\n(Decision Trees, K-Nearest Neighbour, Random Forest, XGBoost), one Deep Neural\nNetwork (multi-layer perceptrons), one Graph Neural Network (Graph\nConvolutional Network), and three state-of-the-art Graph Contrastive Learning\nmethods (BGRL, GRACE, DAENS). Our findings reveal that BiSND is suitable for\nclassification tasks, with F1-scores ranging from 67.66 to 70.15, indicating\npromising avenues for future enhancements.\n","authors":["Adnan Ali","Jinglong Li","Huanhuan Chen","AlMotasem Bellah Al Ajlouni"],"pdf_url":"https://arxiv.org/pdf/2503.02397v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2502.11639v2","updated":"2025-03-04T08:38:14Z","published":"2025-02-17T10:33:24Z","title":"Neural Interpretable Reasoning","summary":"  We formalize a novel modeling framework for achieving interpretability in\ndeep learning, anchored in the principle of inference equivariance. While the\ndirect verification of interpretability scales exponentially with the number of\nvariables of the system, we show that this complexity can be mitigated by\ntreating interpretability as a Markovian property and employing neural\nre-parametrization techniques. Building on these insights, we propose a new\nmodeling paradigm -- neural generation and interpretable execution -- that\nenables scalable verification of equivariance. This paradigm provides a general\napproach for designing Neural Interpretable Reasoners that are not only\nexpressive but also transparent.\n","authors":["Pietro Barbiero","Giuseppe Marra","Gabriele Ciravegna","David Debot","Francesco De Santis","Michelangelo Diligenti","Mateo Espinosa Zarlenga","Francesco Giannini"],"pdf_url":"https://arxiv.org/pdf/2502.11639v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2502.11107v2","updated":"2025-03-04T08:37:41Z","published":"2025-02-16T12:50:20Z","title":"Revisiting Weak-to-Strong Generalization in Theory and Practice: Reverse\n  KL vs. Forward KL","summary":"  As large language models advance toward superhuman performance, ensuring\ntheir alignment with human values and abilities grows increasingly complex.\nWeak-to-strong generalization offers a promising approach by leveraging\npredictions from weaker models to guide stronger systems, but its effectiveness\ncould be constrained by the inherent noise and inaccuracies in these weak\npredictions. To address this, we propose a theoretically grounded approach that\nreplaces forward KL divergence-whose mass-covering behavior risks overfitting\nto imperfect weak signals-with reverse KL divergence. Reverse KL divergence's\nzero-forcing effect prioritizes high-confidence predictions, effectively\nmitigating the influence of unreliable weak supervision. Theoretically, we\nextend existing bounds and derive tighter lower bounds for both forward and\nreverse KL divergence, establishing that reverse KL achieves at least\ncomparable guarantees to forward KL. Notably, when a sufficiently pre-trained\nstrong model is fine-tuned on the last linear layer, reverse KL guarantees that\nit outperforms its weak supervisor by the magnitude of their disagreement.\nEmpirically, we demonstrate that reverse KL and reverse cross-entropy enable\nstrong models to successfully outperform those trained with forward KL and\nstandard cross-entropy across most settings, highlighting the practical\nadvantages of these reverse losses.\n","authors":["Wei Yao","Wenkai Yang","Ziqiao Wang","Yankai Lin","Yong Liu"],"pdf_url":"https://arxiv.org/pdf/2502.11107v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2409.20356v2","updated":"2025-03-04T08:26:23Z","published":"2024-09-30T14:52:00Z","title":"Satellite image classification with neural quantum kernels","summary":"  Achieving practical applications of quantum machine learning for real-world\nscenarios remains challenging despite significant theoretical progress. This\npaper proposes a novel approach for classifying satellite images, a task of\nparticular relevance to the earth observation (EO) industry, using quantum\nmachine learning techniques. Specifically, we focus on classifying images that\ncontain solar panels, addressing a complex real-world classification problem.\nOur approach begins with classical pre-processing to reduce the dimensionality\nof the satellite image dataset. We then apply neural quantum kernels\n(NQKs)-quantum kernels derived from trained quantum neural networks (QNNs)-for\nclassification. We evaluate several strategies within this framework,\ndemonstrating results that are competitive with the best classical methods. Key\nfindings include the robustness of or results and their scalability, with\nsuccessful performance achieved up to 8 qubits.\n","authors":["Pablo Rodriguez-Grasa","Robert Farzan-Rodriguez","Gabriele Novelli","Yue Ban","Mikel Sanz"],"pdf_url":"https://arxiv.org/pdf/2409.20356v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.02389v1","updated":"2025-03-04T08:26:03Z","published":"2025-03-04T08:26:03Z","title":"Robust detection of overlapping bioacoustic sound events","summary":"  We propose a method for accurately detecting bioacoustic sound events that is\nrobust to overlapping events, a common issue in domains such as ethology,\necology and conservation. While standard methods employ a frame-based,\nmulti-label approach, we introduce an onset-based detection method which we\nname Voxaboxen. It takes inspiration from object detection methods in computer\nvision, but simultaneously takes advantage of recent advances in\nself-supervised audio encoders. For each time window, Voxaboxen predicts\nwhether it contains the start of a vocalization and how long the vocalization\nis. It also does the same in reverse, predicting whether each window contains\nthe end of a vocalization, and how long ago it started. The two resulting sets\nof bounding boxes are then fused using a graph-matching algorithm. We also\nrelease a new dataset designed to measure performance on detecting overlapping\nvocalizations. This consists of recordings of zebra finches annotated with\ntemporally-strong labels and showing frequent overlaps. We test Voxaboxen on\nseven existing data sets and on our new data set. We compare Voxaboxen to\nnatural baselines and existing sound event detection methods and demonstrate\nSotA results. Further experiments show that improvements are robust to frequent\nvocalization overlap.\n","authors":["Louis Mahon","Benjamin Hoffman","Logan S James","Maddie Cusimano","Masato Hagiwara","Sarah C Woolley","Olivier Pietquin"],"pdf_url":"https://arxiv.org/pdf/2503.02389v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.02386v1","updated":"2025-03-04T08:20:34Z","published":"2025-03-04T08:20:34Z","title":"An Accelerated Alternating Partial Bregman Algorithm for ReLU-based\n  Matrix Decomposition","summary":"  Despite the remarkable success of low-rank estimation in data mining, its\neffectiveness diminishes when applied to data that inherently lacks low-rank\nstructure. To address this limitation, in this paper, we focus on non-negative\nsparse matrices and aim to investigate the intrinsic low-rank characteristics\nof the rectified linear unit (ReLU) activation function. We first propose a\nnovel nonlinear matrix decomposition framework incorporating a comprehensive\nregularization term designed to simultaneously promote useful structures in\nclustering and compression tasks, such as low-rankness, sparsity, and\nnon-negativity in the resulting factors. This formulation presents significant\ncomputational challenges due to its multi-block structure, non-convexity,\nnon-smoothness, and the absence of global gradient Lipschitz continuity. To\naddress these challenges, we develop an accelerated alternating partial Bregman\nproximal gradient method (AAPB), whose distinctive feature lies in its\ncapability to enable simultaneous updates of multiple variables. Under mild and\ntheoretically justified assumptions, we establish both sublinear and global\nconvergence properties of the proposed algorithm. Through careful selection of\nkernel generating distances tailored to various regularization terms, we derive\ncorresponding closed-form solutions while maintaining the $L$-smooth adaptable\nproperty always holds for any $L\\ge 1$. Numerical experiments, on graph\nregularized clustering and sparse NMF basis compression confirm the\neffectiveness of our model and algorithm.\n","authors":["Qingsong Wang","Yunfei Qu","Chunfeng Cui","Deren Han"],"pdf_url":"https://arxiv.org/pdf/2503.02386v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.02384v1","updated":"2025-03-04T08:20:10Z","published":"2025-03-04T08:20:10Z","title":"Truthfulness of Decision-Theoretic Calibration Measures","summary":"  Calibration measures quantify how much a forecaster's predictions violates\ncalibration, which requires that forecasts are unbiased conditioning on the\nforecasted probabilities. Two important desiderata for a calibration measure\nare its decision-theoretic implications (i.e., downstream decision-makers that\nbest-respond to the forecasts are always no-regret) and its truthfulness (i.e.,\na forecaster approximately minimizes error by always reporting the true\nprobabilities). Existing measures satisfy at most one of the properties, but\nnot both.\n  We introduce a new calibration measure termed subsampled step calibration,\n$\\mathsf{StepCE}^{\\textsf{sub}}$, that is both decision-theoretic and truthful.\nIn particular, on any product distribution, $\\mathsf{StepCE}^{\\textsf{sub}}$ is\ntruthful up to an $O(1)$ factor whereas prior decision-theoretic calibration\nmeasures suffer from an $e^{-\\Omega(T)}$-$\\Omega(\\sqrt{T})$ truthfulness gap.\nMoreover, in any smoothed setting where the conditional probability of each\nevent is perturbed by a noise of magnitude $c > 0$,\n$\\mathsf{StepCE}^{\\textsf{sub}}$ is truthful up to an $O(\\sqrt{\\log(1/c)})$\nfactor, while prior decision-theoretic measures have an\n$e^{-\\Omega(T)}$-$\\Omega(T^{1/3})$ truthfulness gap. We also prove a general\nimpossibility result for truthful decision-theoretic forecasting: any complete\nand decision-theoretic calibration measure must be discontinuous and\nnon-truthful in the non-smoothed setting.\n","authors":["Mingda Qiao","Eric Zhao"],"pdf_url":"https://arxiv.org/pdf/2503.02384v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.02379v1","updated":"2025-03-04T08:14:51Z","published":"2025-03-04T08:14:51Z","title":"Teaching Metric Distance to Autoregressive Multimodal Foundational\n  Models","summary":"  As large language models expand beyond natural language to domains such as\nmathematics, multimodal understanding, and embodied agents, tokens increasingly\nreflect metric relationships rather than purely linguistic meaning. We\nintroduce DIST2Loss, a distance-aware framework designed to train\nautoregressive discrete models by leveraging predefined distance relationships\namong output tokens. At its core, DIST2Loss transforms continuous exponential\nfamily distributions derived from inherent distance metrics into discrete,\ncategorical optimization targets compatible with the models' architectures.\nThis approach enables the models to learn and preserve meaningful distance\nrelationships during token generation while maintaining compatibility with\nexisting architectures. Empirical evaluations show consistent performance gains\nin diverse multimodal applications, including visual grounding, robotic\nmanipulation, generative reward modeling, and image generation using\nvector-quantized features. These improvements are pronounced in cases of\nlimited training data, highlighting DIST2Loss's effectiveness in\nresource-constrained settings.\n","authors":["Jiwan Chung","Saejin Kim","Yongrae Jo","Jaewoo Park","Dongjun Min","Youngjae Yu"],"pdf_url":"https://arxiv.org/pdf/2503.02379v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2406.16783v3","updated":"2025-03-04T07:56:00Z","published":"2024-06-24T16:45:13Z","title":"M2Lingual: Enhancing Multilingual, Multi-Turn Instruction Alignment in\n  Large Language Models","summary":"  Instruction finetuning (IFT) is critical for aligning Large Language Models\n(LLMs) to follow instructions. While many effective IFT datasets have been\nintroduced recently, they predominantly focus on high-resource languages like\nEnglish. To better align LLMs across a broad spectrum of languages and tasks,\nwe propose a fully synthetic, novel taxonomy (Evol) guided Multilingual,\nMulti-turn instruction finetuning dataset, called M2Lingual. It is constructed\nby first selecting a diverse set of seed examples and then utilizing the\nproposed Evol taxonomy to convert these seeds into complex and challenging\nmulti-turn instructions. We demonstrate the effectiveness of M2Lingual by\ntraining LLMs of varying sizes and showcasing the enhanced performance across a\ndiverse set of languages. We contribute the 2 step Evol taxonomy with the\nguided generation code: https://github.com/ServiceNow/M2Lingual, as well as the\nfirst fully synthetic, general and task-oriented, multi-turn, multilingual\ndataset built with Evol - M2Lingual:\nhttps://huggingface.co/datasets/ServiceNow-AI/ M2Lingual - containing 182K\ntotal IFT pairs, covering 70 languages and 17+ NLP tasks.\n","authors":["Rishabh Maheshwary","Vikas Yadav","Hoang Nguyen","Khyati Mahajan","Sathwik Tejaswi Madhusudhan"],"pdf_url":"https://arxiv.org/pdf/2406.16783v3.pdf","comment":"39 pages"},{"id":"http://arxiv.org/abs/2409.01115v2","updated":"2025-03-04T07:52:43Z","published":"2024-09-02T09:42:17Z","title":"Time series classification with random convolution kernels: pooling\n  operators and input representations matter","summary":"  This article presents a new approach based on MiniRocket, called SelF-Rocket,\nfor fast time series classification (TSC). Unlike existing approaches based on\nrandom convolution kernels, it dynamically selects the best couple of input\nrepresentations and pooling operator during the training process. SelF-Rocket\nachieves state-of-the-art accuracy on the University of California Riverside\n(UCR) TSC benchmark datasets.\n","authors":["Mouhamadou Mansour Lo","Gildas Morvan","Mathieu Rossi","Fabrice Morganti","David Mercier"],"pdf_url":"https://arxiv.org/pdf/2409.01115v2.pdf","comment":"v1: initial version, incorrect evaluation. v2: Method improved,\n  evaluation corrected, title simplified"},{"id":"http://arxiv.org/abs/2503.01478v2","updated":"2025-03-04T07:51:56Z","published":"2025-03-03T12:37:34Z","title":"SePer: Measure Retrieval Utility Through The Lens Of Semantic Perplexity\n  Reduction","summary":"  Large Language Models (LLMs) have demonstrated improved generation\nperformance by incorporating externally retrieved knowledge, a process known as\nretrieval-augmented generation (RAG). Despite the potential of this approach,\nexisting studies evaluate RAG effectiveness by 1) assessing retrieval and\ngeneration components jointly, which obscures retrieval's distinct\ncontribution, or 2) examining retrievers using traditional metrics such as\nNDCG, which creates a gap in understanding retrieval's true utility in the\noverall generation process. To address the above limitations, in this work, we\nintroduce an automatic evaluation method that measures retrieval quality\nthrough the lens of information gain within the RAG framework. Specifically, we\npropose Semantic Perplexity (SePer), a metric that captures the LLM's internal\nbelief about the correctness of the retrieved information. We quantify the\nutility of retrieval by the extent to which it reduces semantic perplexity\npost-retrieval. Extensive experiments demonstrate that SePer not only aligns\nclosely with human preferences but also offers a more precise and efficient\nevaluation of retrieval utility across diverse RAG scenarios.\n","authors":["Lu Dai","Yijie Xu","Jinhui Ye","Hao Liu","Hui Xiong"],"pdf_url":"https://arxiv.org/pdf/2503.01478v2.pdf","comment":"ICLR 2025 Spotlight"},{"id":"http://arxiv.org/abs/2503.01363v2","updated":"2025-03-04T07:51:38Z","published":"2025-03-03T09:58:04Z","title":"FABG : End-to-end Imitation Learning for Embodied Affective Human-Robot\n  Interaction","summary":"  This paper proposes FABG (Facial Affective Behavior Generation), an\nend-to-end imitation learning system for human-robot interaction, designed to\ngenerate natural and fluid facial affective behaviors. In interaction,\neffectively obtaining high-quality demonstrations remains a challenge. In this\nwork, we develop an immersive virtual reality (VR) demonstration system that\nallows operators to perceive stereoscopic environments. This system ensures\n\"the operator's visual perception matches the robot's sensory input\" and \"the\noperator's actions directly determine the robot's behaviors\" - as if the\noperator replaces the robot in human interaction engagements. We propose a\nprediction-driven latency compensation strategy to reduce robotic reaction\ndelays and enhance interaction fluency. FABG naturally acquires human\ninteractive behaviors and subconscious motions driven by intuition, eliminating\nmanual behavior scripting. We deploy FABG on a real-world 25-degree-of-freedom\n(DoF) humanoid robot, validating its effectiveness through four fundamental\ninteraction tasks: expression response, dynamic gaze, foveated attention, and\ngesture recognition, supported by data collection and policy training. Project\nwebsite: https://cybergenies.github.io\n","authors":["Yanghai Zhang","Changyi Liu","Keting Fu","Wenbin Zhou","Qingdu Li","Jianwei Zhang"],"pdf_url":"https://arxiv.org/pdf/2503.01363v2.pdf","comment":"Project website: https://cybergenies.github.io"},{"id":"http://arxiv.org/abs/2503.02368v1","updated":"2025-03-04T07:49:10Z","published":"2025-03-04T07:49:10Z","title":"Iterative Value Function Optimization for Guided Decoding","summary":"  While Reinforcement Learning from Human Feedback (RLHF) has become the\npredominant method for controlling language model outputs, it suffers from high\ncomputational costs and training instability. Guided decoding, especially\nvalue-guided methods, offers a cost-effective alternative by controlling\noutputs without re-training models. However, the accuracy of the value function\nis crucial for value-guided decoding, as inaccuracies can lead to suboptimal\ndecision-making and degraded performance. Existing methods struggle with\naccurately estimating the optimal value function, leading to less effective\ncontrol. We propose Iterative Value Function Optimization, a novel framework\nthat addresses these limitations through two key components: Monte Carlo Value\nEstimation, which reduces estimation variance by exploring diverse\ntrajectories, and Iterative On-Policy Optimization, which progressively\nimproves value estimation through collecting trajectories from value-guided\npolicies. Extensive experiments on text summarization, multi-turn dialogue, and\ninstruction following demonstrate the effectiveness of value-guided decoding\napproaches in aligning language models. These approaches not only achieve\nalignment but also significantly reduce computational costs by leveraging\nprincipled value function optimization for efficient and effective control.\n","authors":["Zhenhua Liu","Lijun Li","Ruizhe Chen","Yuxian Jiang","Tong Zhu","Wenliang Chen","Jing Shao"],"pdf_url":"https://arxiv.org/pdf/2503.02368v1.pdf","comment":"20 pages, 10 figures"},{"id":"http://arxiv.org/abs/2404.08254v3","updated":"2025-03-04T07:39:04Z","published":"2024-04-12T06:08:43Z","title":"Balanced Mixed-Type Tabular Data Synthesis with Diffusion Models","summary":"  Diffusion models have emerged as a robust framework for various generative\ntasks, including tabular data synthesis. However, current tabular diffusion\nmodels tend to inherit bias in the training dataset and generate biased\nsynthetic data, which may influence discriminatory actions. In this research,\nwe introduce a novel tabular diffusion model that incorporates sensitive\nguidance to generate fair synthetic data with balanced joint distributions of\nthe target label and sensitive attributes, such as sex and race. The empirical\nresults demonstrate that our method effectively mitigates bias in training data\nwhile maintaining the quality of the generated samples. Furthermore, we provide\nevidence that our approach outperforms existing methods for synthesizing\ntabular data on fairness metrics such as demographic parity ratio and equalized\nodds ratio, achieving improvements of over $10\\%$. Our implementation is\navailable at https://github.com/comp-well-org/fair-tab-diffusion.\n","authors":["Zeyu Yang","Han Yu","Peikun Guo","Khadija Zanna","Xiaoxue Yang","Akane Sano"],"pdf_url":"https://arxiv.org/pdf/2404.08254v3.pdf","comment":"OpenReview: https://openreview.net/forum?id=dvRysCqmYQ"},{"id":"http://arxiv.org/abs/2503.02360v1","updated":"2025-03-04T07:34:06Z","published":"2025-03-04T07:34:06Z","title":"BdSLW401: Transformer-Based Word-Level Bangla Sign Language Recognition\n  Using Relative Quantization Encoding (RQE)","summary":"  Sign language recognition (SLR) for low-resource languages like Bangla\nsuffers from signer variability, viewpoint variations, and limited annotated\ndatasets. In this paper, we present BdSLW401, a large-scale, multi-view,\nword-level Bangla Sign Language (BdSL) dataset with 401 signs and 102,176 video\nsamples from 18 signers in front and lateral views. To improve\ntransformer-based SLR, we introduce Relative Quantization Encoding (RQE), a\nstructured embedding approach anchoring landmarks to physiological reference\npoints and quantize motion trajectories. RQE improves attention allocation by\ndecreasing spatial variability, resulting in 44.3% WER reduction in WLASL100,\n21.0% in SignBD-200, and significant gains in BdSLW60 and SignBD-90. However,\nfixed quantization becomes insufficient on large-scale datasets (e.g.,\nWLASL2000), indicating the need for adaptive encoding strategies. Further,\nRQE-SF, an extended variant that stabilizes shoulder landmarks, achieves\nimprovements in pose consistency at the cost of small trade-offs in lateral\nview recognition. The attention graphs prove that RQE improves model\ninterpretability by focusing on the major articulatory features (fingers,\nwrists) and the more distinctive frames instead of global pose changes.\nIntroducing BdSLW401 and demonstrating the effectiveness of RQE-enhanced\nstructured embeddings, this work advances transformer-based SLR for\nlow-resource languages and sets a benchmark for future research in this area.\n","authors":["Husne Ara Rubaiyeat","Njayou Youssouf","Md Kamrul Hasan","Hasan Mahmud"],"pdf_url":"https://arxiv.org/pdf/2503.02360v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2501.05874v2","updated":"2025-03-04T07:29:52Z","published":"2025-01-10T11:17:15Z","title":"VideoRAG: Retrieval-Augmented Generation over Video Corpus","summary":"  Retrieval-Augmented Generation (RAG) is a powerful strategy for improving the\nfactual accuracy of models by retrieving external knowledge relevant to queries\nand incorporating it into the generation process. However, existing approaches\nprimarily focus on text, with some recent advancements considering images, and\nthey largely overlook videos, a rich source of multimodal knowledge capable of\nrepresenting contextual details more effectively than any other modality. While\nvery recent studies explore the use of videos in response generation, they\neither predefine query-associated videos without retrieval or convert videos\ninto textual descriptions losing multimodal richness. To tackle these, we\nintroduce VideoRAG, a framework that not only dynamically retrieves videos\nbased on their relevance with queries but also utilizes both visual and textual\ninformation. The operation of VideoRAG is powered by recent Large Video\nLanguage Models (LVLMs), which enable the direct processing of video content to\nrepresent it for retrieval and the seamless integration of retrieved videos\njointly with queries for response generation. Also, inspired by that the\ncontext size of LVLMs may not be sufficient to process all frames in extremely\nlong videos and not all frames are equally important, we introduce a video\nframe selection mechanism to extract the most informative subset of frames,\nalong with a strategy to extract textual information from videos (as it can aid\nthe understanding of video content) when their subtitles are not available. We\nexperimentally validate the effectiveness of VideoRAG, showcasing that it is\nsuperior to relevant baselines. Code is available at\nhttps://github.com/starsuzi/VideoRAG.\n","authors":["Soyeong Jeong","Kangsan Kim","Jinheon Baek","Sung Ju Hwang"],"pdf_url":"https://arxiv.org/pdf/2501.05874v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2305.04281v4","updated":"2025-03-04T07:28:03Z","published":"2023-05-07T14:10:34Z","title":"Analysing Multiscale Clusterings with Persistent Homology","summary":"  In data clustering, it is often desirable to find not just a single partition\ninto clusters but a sequence of partitions that describes the data at different\nscales (or levels of coarseness). A natural problem then is to analyse and\ncompare the (not necessarily hierarchical) sequences of partitions that\nunderpin such multiscale descriptions. Here, we use tools from topological data\nanalysis and introduce the Multiscale Clustering Filtration (MCF), a\nwell-defined and stable filtration of abstract simplicial complexes that\nencodes arbitrary cluster assignments in a sequence of partitions across scales\nof increasing coarseness. We show that the zero-dimensional persistent homology\nof the MCF measures the degree of hierarchy of this sequence, and the\nhigher-dimensional persistent homology tracks the emergence and resolution of\nconflicts between cluster assignments across the sequence of partitions. To\nbroaden the theoretical foundations of the MCF, we provide an equivalent\nconstruction via a nerve complex filtration, and we show that, in the\nhierarchical case, the MCF reduces to a Vietoris-Rips filtration of an\nultrametric space. Using synthetic data, we then illustrate how the persistence\ndiagram of the MCF provides a feature map that can serve to characterise and\nclassify multiscale clusterings.\n","authors":["Dominik J. Schindler","Mauricio Barahona"],"pdf_url":"https://arxiv.org/pdf/2305.04281v4.pdf","comment":"This work was presented at the Dagstuhl Seminar (23192) on\n  \"Topological Data Analysis and Applications\""},{"id":"http://arxiv.org/abs/2310.10315v3","updated":"2025-03-04T07:25:39Z","published":"2023-10-16T11:52:54Z","title":"A Survey on Quantum Machine Learning: Current Trends, Challenges,\n  Opportunities, and the Road Ahead","summary":"  Quantum Computing (QC) claims to improve the efficiency of solving complex\nproblems, compared to classical computing. When QC is integrated with Machine\nLearning (ML), it creates a Quantum Machine Learning (QML) system. This paper\naims to provide a thorough understanding of the foundational concepts of QC and\nits notable advantages over classical computing. Following this, we delve into\nthe key aspects of QML in a detailed and comprehensive manner.\n  In this survey, we investigate a variety of QML algorithms, discussing their\napplicability across different domains. We examine quantum datasets,\nhighlighting their unique characteristics and advantages. The survey also\ncovers the current state of hardware technologies, providing insights into the\nlatest advancements and their implications for QML. Additionally, we review the\nsoftware tools and simulators available for QML development, discussing their\nfeatures and usability.\n  Furthermore, we explore practical applications of QML, illustrating how it\ncan be leveraged to solve real-world problems more efficiently than classical\nML methods. This paper serves as a valuable resource for readers seeking to\nunderstand the current state-of-the-art techniques in the QML field, offering a\nsolid foundation to embark on further exploration and development in this\nrapidly evolving area.\n","authors":["Kamila Zaman","Alberto Marchisio","Muhammad Abdullah Hanif","Muhammad Shafique"],"pdf_url":"https://arxiv.org/pdf/2310.10315v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.02353v1","updated":"2025-03-04T07:22:34Z","published":"2025-03-04T07:22:34Z","title":"Controllable Motion Generation via Diffusion Modal Coupling","summary":"  Diffusion models have recently gained significant attention in robotics due\nto their ability to generate multi-modal distributions of system states and\nbehaviors. However, a key challenge remains: ensuring precise control over the\ngenerated outcomes without compromising realism. This is crucial for\napplications such as motion planning or trajectory forecasting, where adherence\nto physical constraints and task-specific objectives is essential. We propose a\nnovel framework that enhances controllability in diffusion models by leveraging\nmulti-modal prior distributions and enforcing strong modal coupling. This\nallows us to initiate the denoising process directly from distinct prior modes\nthat correspond to different possible system behaviors, ensuring sampling to\nalign with the training distribution. We evaluate our approach on motion\nprediction using the Waymo dataset and multi-task control in Maze2D\nenvironments. Experimental results show that our framework outperforms both\nguidance-based techniques and conditioned models with unimodal priors,\nachieving superior fidelity, diversity, and controllability, even in the\nabsence of explicit conditioning. Overall, our approach provides a more\nreliable and scalable solution for controllable motion generation in robotics.\n","authors":["Luobin Wang","Hongzhan Yu","Chenning Yu","Sicun Gao","Henrik Christensen"],"pdf_url":"https://arxiv.org/pdf/2503.02353v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.02352v1","updated":"2025-03-04T07:21:40Z","published":"2025-03-04T07:21:40Z","title":"Confidence HNC: A Network Flow Technique for Binary Classification with\n  Noisy Labels","summary":"  We consider here a classification method that balances two objectives: large\nsimilarity within the samples in the cluster, and large dissimilarity between\nthe cluster and its complement. The method, referred to as HNC or SNC, requires\nseed nodes, or labeled samples, at least one of which is in the cluster and at\nleast one in the complement. Other than that, the method relies only on the\nrelationship between the samples. The contribution here is the new method in\nthe presence of noisy labels, based on HNC, called Confidence HNC, in which we\nintroduce confidence weights that allow the given labels of labeled samples to\nbe violated, with a penalty that reflects the perceived correctness of each\ngiven label. If a label is violated then it is interpreted that the label was\nnoisy. The method involves a representation of the problem as a graph problem\nwith hyperparameters that is solved very efficiently by the network flow\ntechnique of parametric cut. We compare the performance of the new method with\nleading algorithms on both real and synthetic data with noisy labels and\ndemonstrate that it delivers improved performance in terms of classification\naccuracy as well as noise detection capability.\n","authors":["Dorit Hochbaum","Torpong Nitayanont"],"pdf_url":"https://arxiv.org/pdf/2503.02352v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.03618v2","updated":"2025-03-04T07:16:34Z","published":"2024-10-04T17:17:30Z","title":"Open-World Reinforcement Learning over Long Short-Term Imagination","summary":"  Training visual reinforcement learning agents in a high-dimensional open\nworld presents significant challenges. While various model-based methods have\nimproved sample efficiency by learning interactive world models, these agents\ntend to be \"short-sighted\", as they are typically trained on short snippets of\nimagined experiences. We argue that the primary challenge in open-world\ndecision-making is improving the exploration efficiency across a vast state\nspace, especially for tasks that demand consideration of long-horizon payoffs.\nIn this paper, we present LS-Imagine, which extends the imagination horizon\nwithin a limited number of state transition steps, enabling the agent to\nexplore behaviors that potentially lead to promising long-term feedback. The\nfoundation of our approach is to build a $\\textit{long short-term world\nmodel}$. To achieve this, we simulate goal-conditioned jumpy state transitions\nand compute corresponding affordance maps by zooming in on specific areas\nwithin single images. This facilitates the integration of direct long-term\nvalues into behavior learning. Our method demonstrates significant improvements\nover state-of-the-art techniques in MineDojo.\n","authors":["Jiajian Li","Qi Wang","Yunbo Wang","Xin Jin","Yang Li","Wenjun Zeng","Xiaokang Yang"],"pdf_url":"https://arxiv.org/pdf/2410.03618v2.pdf","comment":"Accepted by ICLR 2025 Oral. Project page:\n  https://qiwang067.github.io/ls-imagine"},{"id":"http://arxiv.org/abs/2410.22839v2","updated":"2025-03-04T07:13:20Z","published":"2024-10-30T09:18:31Z","title":"Danoliteracy of Generative Large Language Models","summary":"  The language technology moonshot moment of Generative Large Language Models\n(GLLMs) was not limited to English: These models brought a surge of\ntechnological applications, investments, and hype to low-resource languages as\nwell. However, the capabilities of these models in languages such as Danish\nwere, until recently, difficult to verify beyond qualitative demonstrations due\nto a lack of applicable evaluation corpora. We present a GLLM benchmark to\nevaluate \\emph{Danoliteracy}, a measure of Danish language and cultural\ncompetency across eight diverse scenarios such as Danish citizenship tests and\nabstractive social media question answering. This limited-size benchmark was\nfound to produce a robust ranking that correlates to human feedback at $\\rho\n\\sim 0.8$ with GPT-4 and Claude Opus models achieving the highest rankings.\nAnalyzing these model results across scenarios, we find one strong underlying\nfactor explaining $95\\%$ of scenario performance variance for GLLMs in Danish,\nsuggesting a $g$ factor of model consistency in language adaptation.\n","authors":["Sren Vejlgaard Holm","Lars Kai Hansen","Martin Carsten Nielsen"],"pdf_url":"https://arxiv.org/pdf/2410.22839v2.pdf","comment":"16 pages, 13 figures, Accepted to NoDaLiDa/Baltic-HLT 2025"},{"id":"http://arxiv.org/abs/2502.04740v2","updated":"2025-03-04T07:09:19Z","published":"2025-02-07T08:15:31Z","title":"SelaFD:Seamless Adaptation of Vision Transformer Fine-tuning for\n  Radar-based Human Activity Recognition","summary":"  Human Activity Recognition (HAR) such as fall detection has become\nincreasingly critical due to the aging population, necessitating effective\nmonitoring systems to prevent serious injuries and fatalities associated with\nfalls. This study focuses on fine-tuning the Vision Transformer (ViT) model\nspecifically for HAR using radar-based Time-Doppler signatures. Unlike\ntraditional image datasets, these signals present unique challenges due to\ntheir non-visual nature and the high degree of similarity among various\nactivities. Directly fine-tuning the ViT with all parameters proves suboptimal\nfor this application. To address this challenge, we propose a novel approach\nthat employs Low-Rank Adaptation (LoRA) fine-tuning in the weight space to\nfacilitate knowledge transfer from pre-trained ViT models. Additionally, to\nextract fine-grained features, we enhance feature representation through the\nintegration of a serial-parallel adapter in the feature space. Our innovative\njoint fine-tuning method, tailored for radar-based Time-Doppler signatures,\nsignificantly improves HAR accuracy, surpassing existing state-of-the-art\nmethodologies in this domain. Our code is released at\nhttps://github.com/wangyijunlyy/SelaFD.\n","authors":["Yijun Wang","Yong Wang","Chendong xu","Shuai Yao","Qisong Wu"],"pdf_url":"https://arxiv.org/pdf/2502.04740v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.02345v1","updated":"2025-03-04T07:08:47Z","published":"2025-03-04T07:08:47Z","title":"CQ CNN: A Hybrid Classical Quantum Convolutional Neural Network for\n  Alzheimer's Disease Detection Using Diffusion Generated and U Net Segmented\n  3D MRI","summary":"  The detection of Alzheimer disease (AD) from clinical MRI data is an active\narea of research in medical imaging. Recent advances in quantum computing,\nparticularly the integration of parameterized quantum circuits (PQCs) with\nclassical machine learning architectures, offer new opportunities to develop\nmodels that may outperform traditional methods. However, quantum machine\nlearning (QML) remains in its early stages and requires further experimental\nanalysis to better understand its behavior and limitations. In this paper, we\npropose an end to end hybrid classical quantum convolutional neural network (CQ\nCNN) for AD detection using clinically formatted 3D MRI data. Our approach\ninvolves developing a framework to make 3D MRI data usable for machine\nlearning, designing and training a brain tissue segmentation model (Skull Net),\nand training a diffusion model to generate synthetic images for the minority\nclass. Our converged models exhibit potential quantum advantages, achieving\nhigher accuracy in fewer epochs than classical models. The proposed beta8 3\nqubit model achieves an accuracy of 97.50%, surpassing state of the art (SOTA)\nmodels while requiring significantly fewer computational resources. In\nparticular, the architecture employs only 13K parameters (0.48 MB), reducing\nthe parameter count by more than 99.99% compared to current SOTA models.\nFurthermore, the diffusion-generated data used to train our quantum models, in\nconjunction with real samples, preserve clinical structural standards,\nrepresenting a notable first in the field of QML. We conclude that CQCNN\narchitecture like models, with further improvements in gradient optimization\ntechniques, could become a viable option and even a potential alternative to\nclassical models for AD detection, especially in data limited and resource\nconstrained clinical settings.\n","authors":["Mominul Islam","Mohammad Junayed Hasan","M. R. C. Mahdy"],"pdf_url":"https://arxiv.org/pdf/2503.02345v1.pdf","comment":"Application of hybrid quantum-classical machine learning for (early\n  stage) disease detection"},{"id":"http://arxiv.org/abs/2503.02343v1","updated":"2025-03-04T07:07:17Z","published":"2025-03-04T07:07:17Z","title":"DeLTa: A Decoding Strategy based on Logit Trajectory Prediction Improves\n  Factuality and Reasoning Ability","summary":"  Large Language Models (LLMs) are increasingly being used in real-world\napplications. However, concerns about the reliability of the content they\ngenerate persist, as it frequently deviates from factual correctness or\nexhibits deficiencies in logical reasoning. This paper proposes a novel\ndecoding strategy aimed at enhancing both factual accuracy and inferential\nreasoning without requiring any modifications to the architecture or\npre-trained parameters of LLMs. Our approach adjusts next-token probabilities\nby analyzing the trajectory of logits from lower to higher layers in\nTransformers and applying linear regression. We find that this Decoding by\nLogit Trajectory-based approach (DeLTa) effectively reinforces factuality and\nreasoning while mitigating incorrect generation. Experiments on TruthfulQA\ndemonstrate that DeLTa attains up to a 4.9% improvement over the baseline.\nFurthermore, it enhances performance by up to 8.1% on StrategyQA and 7.3% on\nGSM8K, both of which demand strong reasoning capabilities.\n","authors":["Yunzhen He","Yusuke Takase","Yoichi Ishibashi","Hidetoshi Shimodaira"],"pdf_url":"https://arxiv.org/pdf/2503.02343v1.pdf","comment":"Source code is available at https://github.com/githubhyz/DeLTa"},{"id":"http://arxiv.org/abs/2503.02341v1","updated":"2025-03-04T07:04:55Z","published":"2025-03-04T07:04:55Z","title":"GRADEO: Towards Human-Like Evaluation for Text-to-Video Generation via\n  Multi-Step Reasoning","summary":"  Recent great advances in video generation models have demonstrated their\npotential to produce high-quality videos, bringing challenges to effective\nevaluation. Unlike human evaluation, existing automated evaluation metrics lack\nhigh-level semantic understanding and reasoning capabilities for video, thus\nmaking them infeasible and unexplainable. To fill this gap, we curate\nGRADEO-Instruct, a multi-dimensional T2V evaluation instruction tuning dataset,\nincluding 3.3k videos from over 10 existing video generation models and\nmulti-step reasoning assessments converted by 16k human annotations. We then\nintroduce GRADEO, one of the first specifically designed video evaluation\nmodels, which grades AI-generated videos for explainable scores and assessments\nthrough multi-step reasoning. Experiments show that our method aligns better\nwith human evaluations than existing methods. Furthermore, our benchmarking\nreveals that current video generation models struggle to produce content that\naligns with human reasoning and complex real-world scenarios. The models,\ndatasets, and codes will be released soon.\n","authors":["Zhun Mou","Bin Xia","Zhengchao Huang","Wenming Yang","Jiaya Jia"],"pdf_url":"https://arxiv.org/pdf/2503.02341v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2406.16135v2","updated":"2025-03-04T07:00:10Z","published":"2024-06-23T15:15:17Z","title":"Crosslingual Capabilities and Knowledge Barriers in Multilingual Large\n  Language Models","summary":"  Large language models (LLMs) are typically multilingual due to pretraining on\ndiverse multilingual corpora. But can these models relate corresponding\nconcepts across languages, i.e., be crosslingual? This study evaluates\nstate-of-the-art LLMs on inherently crosslingual tasks. We observe that while\nthese models show promising surface-level crosslingual abilities on machine\ntranslation and embedding space analyses, they struggle with deeper\ncrosslingual knowledge transfer, revealing a crosslingual knowledge barrier in\nboth general (MMLU benchmark) and domain-specific (Harry Potter quiz and TOFU\nbenchmark) contexts. Since simple inference-time mitigation methods offer only\nlimited improvement, we propose fine-tuning of LLMs on mixed-language data,\nwhich effectively reduces these gaps, even when using out-of-domain datasets\nlike WikiText. Our findings suggest the need for explicit optimization to\nunlock the full crosslingual potential of LLMs. Our code is publicly available\nat https://github.com/google-research/crosslingual-knowledge-barriers.\n","authors":["Lynn Chua","Badih Ghazi","Yangsibo Huang","Pritish Kamath","Ravi Kumar","Pasin Manurangsi","Amer Sinha","Chulin Xie","Chiyuan Zhang"],"pdf_url":"https://arxiv.org/pdf/2406.16135v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2011.13986v3","updated":"2025-03-04T06:42:03Z","published":"2020-11-27T20:40:45Z","title":"Reflective-Net: Learning from Explanations","summary":"  We examine whether data generated by explanation techniques, which promote a\nprocess of self-reflection, can improve classifier performance. Our work is\nbased on the idea that humans have the ability to make quick, intuitive\ndecisions as well as to reflect on their own thinking and learn from\nexplanations. To the best of our knowledge, this is the first time that the\npotential of mimicking this process by using explanations generated by\nexplainability methods has been explored. We found that combining explanations\nwith traditional labeled data leads to significant improvements in\nclassification accuracy and training efficiency across multiple image\nclassification datasets and convolutional neural network architectures. It is\nworth noting that during training, we not only used explanations for the\ncorrect or predicted class, but also for other classes. This serves multiple\npurposes, including allowing for reflection on potential outcomes and enriching\nthe data through augmentation.\n","authors":["Johannes Schneider","Michalis Vlachos"],"pdf_url":"https://arxiv.org/pdf/2011.13986v3.pdf","comment":null}],"Information Retrieval":[{"id":"http://arxiv.org/abs/2503.01711v2","updated":"2025-03-04T17:02:27Z","published":"2025-03-03T16:24:36Z","title":"MAPS: Motivation-Aware Personalized Search via LLM-Driven Consultation\n  Alignment","summary":"  Personalized product search aims to retrieve and rank items that match users'\npreferences and search intent. Despite their effectiveness, existing approaches\ntypically assume that users' query fully captures their real motivation.\nHowever, our analysis of a real-world e-commerce platform reveals that users\noften engage in relevant consultations before searching, indicating they refine\nintents through consultations based on motivation and need. The implied\nmotivation in consultations is a key enhancing factor for personalized search.\nThis unexplored area comes with new challenges including aligning contextual\nmotivations with concise queries, bridging the category-text gap, and filtering\nnoise within sequence history. To address these, we propose a Motivation-Aware\nPersonalized Search (MAPS) method. It embeds queries and consultations into a\nunified semantic space via LLMs, utilizes a Mixture of Attention Experts (MoAE)\nto prioritize critical semantics, and introduces dual alignment: (1)\ncontrastive learning aligns consultations, reviews, and product features; (2)\nbidirectional attention integrates motivation-aware embeddings with user\npreferences. Extensive experiments on real and synthetic data show MAPS\noutperforms existing methods in both retrieval and ranking tasks.\n","authors":["Weicong Qin","Yi Xu","Weijie Yu","Chenglei Shen","Ming He","Jianping Fan","Xiao Zhang","Jun Xu"],"pdf_url":"https://arxiv.org/pdf/2503.01711v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2103.03223v5","updated":"2025-03-04T15:20:55Z","published":"2021-03-04T18:51:06Z","title":"A Comparative Evaluation of Quantification Methods","summary":"  Quantification represents the problem of estimating the distribution of class\nlabels on unseen data. It also represents a growing research field in\nsupervised machine learning, for which a large variety of different algorithms\nhas been proposed in recent years. However, a comprehensive empirical\ncomparison of quantification methods that supports algorithm selection is not\navailable yet. In this work, we close this research gap by conducting a\nthorough empirical performance comparison of 24 different quantification\nmethods on overall more than 40 data sets, considering binary as well as\nmulticlass quantification settings. We observe that no single algorithm\ngenerally outperforms all competitors, but identify a group of methods\nincluding the threshold selection-based Median Sweep and TSMax methods, the DyS\nframework including the HDy method, Forman's mixture model, and Friedman's\nmethod that performs best in the binary setting. For the multiclass setting, we\nobserve that a different, broad group of algorithms yields good performance,\nincluding the HDx method, the Generalized Probabilistic Adjusted Count, the\nreadme method, the energy distance minimization method, the EM algorithm for\nquantification, and Friedman's method. We also find that tuning the underlying\nclassifiers has in most cases only a limited impact on the quantification\nperformance. More generally, we find that the performance on multiclass\nquantification is inferior to the results obtained in the binary setting. Our\nresults can guide practitioners who intend to apply quantification algorithms\nand help researchers to identify opportunities for future research.\n","authors":["Tobias Schumacher","Markus Strohmaier","Florian Lemmerich"],"pdf_url":"https://arxiv.org/pdf/2103.03223v5.pdf","comment":"41 pages, 18 figures, 9 tables"},{"id":"http://arxiv.org/abs/2502.18495v2","updated":"2025-03-04T15:16:52Z","published":"2025-02-19T01:37:24Z","title":"A Comprehensive Survey on Composed Image Retrieval","summary":"  Composed Image Retrieval (CIR) is an emerging yet challenging task that\nallows users to search for target images using a multimodal query, comprising a\nreference image and a modification text specifying the user's desired changes\nto the reference image. Given its significant academic and practical value, CIR\nhas become a rapidly growing area of interest in the computer vision and\nmachine learning communities, particularly with the advances in deep learning.\nTo the best of our knowledge, there is currently no comprehensive review of CIR\nto provide a timely overview of this field. Therefore, we synthesize insights\nfrom over 120 publications in top conferences and journals, including ACM TOIS,\nSIGIR, and CVPR In particular, we systematically categorize existing supervised\nCIR and zero-shot CIR models using a fine-grained taxonomy. For a comprehensive\nreview, we also briefly discuss approaches for tasks closely related to CIR,\nsuch as attribute-based CIR and dialog-based CIR. Additionally, we summarize\nbenchmark datasets for evaluation and analyze existing supervised and zero-shot\nCIR methods by comparing experimental results across multiple datasets.\nFurthermore, we present promising future directions in this field, offering\npractical insights for researchers interested in further exploration. The\ncurated collection of related works is maintained and continuously updated in\nhttps://github.com/haokunwen/Awesome-Composed-Image-Retrieval.\n","authors":["Xuemeng Song","Haoqiang Lin","Haokun Wen","Bohan Hou","Mingzhu Xu","Liqiang Nie"],"pdf_url":"https://arxiv.org/pdf/2502.18495v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.02695v1","updated":"2025-03-04T15:12:18Z","published":"2025-03-04T15:12:18Z","title":"Zero-Shot Complex Question-Answering on Long Scientific Documents","summary":"  With the rapid development in Transformer-based language models, the reading\ncomprehension tasks on short documents and simple questions have been largely\naddressed. Long documents, specifically the scientific documents that are\ndensely packed with knowledge discovered and developed by humans, remain\nrelatively unexplored. These documents often come with a set of complex and\nmore realistic questions, adding to their complexity. We present a zero-shot\npipeline framework that enables social science researchers to perform\nquestion-answering tasks that are complex yet of predetermined question formats\non full-length research papers without requiring machine learning expertise.\nOur approach integrates pre-trained language models to handle challenging\nscenarios including multi-span extraction, multi-hop reasoning, and long-answer\ngeneration. Evaluating on MLPsych, a novel dataset of social psychology papers\nwith annotated complex questions, we demonstrate that our framework achieves\nstrong performance through combination of extractive and generative models.\nThis work advances document understanding capabilities for social sciences\nwhile providing practical tools for researchers.\n","authors":["Wanting Wang"],"pdf_url":"https://arxiv.org/pdf/2503.02695v1.pdf","comment":"AAAI 2025 Workshop on Document Understanding and Intelligence"},{"id":"http://arxiv.org/abs/2503.02674v1","updated":"2025-03-04T14:46:01Z","published":"2025-03-04T14:46:01Z","title":"Towards Robust Expert Finding in Community Question Answering Platforms","summary":"  This paper introduces TUEF, a topic-oriented user-interaction model for fair\nExpert Finding in Community Question Answering (CQA) platforms. The Expert\nFinding task in CQA platforms involves identifying proficient users capable of\nproviding accurate answers to questions from the community. To this aim, TUEF\nimproves the robustness and credibility of the CQA platform through a more\nprecise Expert Finding component. The key idea of TUEF is to exploit diverse\ntypes of information, specifically, content and social information, to identify\nmore precisely experts thus improving the robustness of the task. We assess\nTUEF through reproducible experiments conducted on a large-scale dataset from\nStackOverflow. The results consistently demonstrate that TUEF outperforms\nstate-of-the-art competitors while promoting transparent expert identification.\n","authors":["Maddalena Amendola","Andrea Passarella","Raffaele Perego"],"pdf_url":"https://arxiv.org/pdf/2503.02674v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.02671v1","updated":"2025-03-04T14:43:43Z","published":"2025-03-04T14:43:43Z","title":"Are some books better than others?","summary":"  Scholars, awards committees, and laypeople frequently discuss the merit of\nwritten works. Literary professionals and journalists differ in how much\nperspectivism they concede in their book reviews. Here, we quantify how\nstrongly book reviews are determined by the actual book contents vs.\nidiosyncratic reader tendencies. In our analysis of 624,320 numerical and\ntextual book reviews, we find that the contents of professionally published\nbooks are not predictive of a random reader's reading enjoyment. Online reviews\nof popular fiction and non-fiction books carry up to ten times more information\nabout the reviewer than about the book. For books of a preferred genre, readers\nmight be less likely to give low ratings, but still struggle to converge in\ntheir relative assessments. We find that book evaluations generalize more\nacross experienced review writers than casual readers. When discussing specific\nissues with a book, one review text had poor predictability of issues brought\nup in another review of the same book. We conclude that extreme perspectivism\nis a justifiable position when researching literary quality, bestowing literary\nawards, and designing recommendation systems.\n","authors":["Hannes Rosenbusch","Luke Korthals"],"pdf_url":"https://arxiv.org/pdf/2503.02671v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.02614v1","updated":"2025-03-04T13:34:19Z","published":"2025-03-04T13:34:19Z","title":"Personalized Generation In Large Model Era: A Survey","summary":"  In the era of large models, content generation is gradually shifting to\nPersonalized Generation (PGen), tailoring content to individual preferences and\nneeds. This paper presents the first comprehensive survey on PGen,\ninvestigating existing research in this rapidly growing field. We conceptualize\nPGen from a unified perspective, systematically formalizing its key components,\ncore objectives, and abstract workflows. Based on this unified perspective, we\npropose a multi-level taxonomy, offering an in-depth review of technical\nadvancements, commonly used datasets, and evaluation metrics across multiple\nmodalities, personalized contexts, and tasks. Moreover, we envision the\npotential applications of PGen and highlight open challenges and promising\ndirections for future exploration. By bridging PGen research across multiple\nmodalities, this survey serves as a valuable resource for fostering knowledge\nsharing and interdisciplinary collaboration, ultimately contributing to a more\npersonalized digital landscape.\n","authors":["Yiyan Xu","Jinghao Zhang","Alireza Salemi","Xinting Hu","Wenjie Wang","Fuli Feng","Hamed Zamani","Xiangnan He","Tat-Seng Chua"],"pdf_url":"https://arxiv.org/pdf/2503.02614v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.13121v2","updated":"2025-03-04T12:17:16Z","published":"2023-11-22T02:49:14Z","title":"GENET: Unleashing the Power of Side Information for Recommendation via\n  Hypergraph Pre-training","summary":"  Recommendation with side information has drawn significant research interest\ndue to its potential to mitigate user feedback sparsity. However, existing\nmodels struggle with generalization across diverse domains and types of side\ninformation. In particular, three challenges have not been addressed, and they\nare (1) the diverse formats of side information, including text sequences. (2)\nThe diverse semantics of side information that describes items and users from\nmulti-level in a context different from recommendation systems. (3) The diverse\ncorrelations in side information to measure similarity over multiple objects\nbeyond pairwise relations. In this paper, we introduce GENET (Generalized\nhypErgraph pretraiNing on sidE informaTion), which pre-trains user and item\nrepresentations on feedback-irrelevant side information and fine-tunes the\nrepresentations on user feedback data. GENET leverages pre-training as a means\nto prevent side information from overshadowing critical ID features and\nfeedback signals. It employs a hypergraph framework to accommodate various\ntypes of diverse side information. During pre-training, GENET integrates tasks\nfor hyperlink prediction and self-supervised contrast to capture fine-grained\nsemantics at both local and global levels. Additionally, it introduces a unique\nstrategy to enhance pre-training robustness by perturbing positive samples\nwhile maintaining high-order relations. Extensive experiments demonstrate that\nGENET exhibits strong generalization capabilities, outperforming the SOTA\nmethod by up to 38% in TOP-N recommendation and Sequential recommendation tasks\non various datasets with different side information.\n","authors":["Yang Li","Qi'ao Zhao","Chen Lin","Zhenjie Zhang","Xiaomin Zhu","Jinsong Su"],"pdf_url":"https://arxiv.org/pdf/2311.13121v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.02542v1","updated":"2025-03-04T12:12:37Z","published":"2025-03-04T12:12:37Z","title":"Efficient Long Sequential Low-rank Adaptive Attention for Click-through\n  rate Prediction","summary":"  In the context of burgeoning user historical behavior data, Accurate\nclick-through rate(CTR) prediction requires effective modeling of lengthy user\nbehavior sequences. As the volume of such data keeps swelling, the focus of\nresearch has shifted towards developing effective long-term behavior modeling\nmethods to capture latent user interests. Nevertheless, the complexity\nintroduced by large scale data brings about computational hurdles. There is a\npressing need to strike a balance between achieving high model performance and\nmeeting the strict response time requirements of online services. While\nexisting retrieval-based methods (e.g., similarity filtering or attention\napproximation) achieve practical runtime efficiency, they inherently compromise\ninformation fidelity through aggressive sequence truncation or attention\nsparsification. This paper presents a novel attention mechanism. It overcomes\nthe shortcomings of existing methods while ensuring computational efficiency.\nThis mechanism learn compressed representation of sequence with length $L$ via\nlow-rank projection matrices (rank $r \\ll L$), reducing attention complexity\nfrom $O(L)$ to $O(r)$. It also integrates a uniquely designed loss function to\npreserve nonlinearity of attention. In the inference stage, the mechanism\nadopts matrix absorption and prestorage strategies. These strategies enable it\nto effectively satisfy online constraints. Comprehensive offline and online\nexperiments demonstrate that the proposed method outperforms current\nstate-of-the-art solutions.\n","authors":["Xin Song","Xiaochen Li","Jinxin Hu","Hong Wen","Zulong Chen","Yu Zhang","Xiaoyi Zeng","Zhang Jing"],"pdf_url":"https://arxiv.org/pdf/2503.02542v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.02453v1","updated":"2025-03-04T10:00:05Z","published":"2025-03-04T10:00:05Z","title":"Sparse Meets Dense: Unified Generative Recommendations with Cascaded\n  Sparse-Dense Representations","summary":"  Generative models have recently gained attention in recommendation systems by\ndirectly predicting item identifiers from user interaction sequences. However,\nexisting methods suffer from significant information loss due to the separation\nof stages such as quantization and sequence modeling, hindering their ability\nto achieve the modeling precision and accuracy of sequential dense retrieval\ntechniques. Integrating generative and dense retrieval methods remains a\ncritical challenge. To address this, we introduce the Cascaded Organized\nBi-Represented generAtive retrieval (COBRA) framework, which innovatively\nintegrates sparse semantic IDs and dense vectors through a cascading process.\nOur method alternates between generating these representations by first\ngenerating sparse IDs, which serve as conditions to aid in the generation of\ndense vectors. End-to-end training enables dynamic refinement of dense\nrepresentations, capturing both semantic insights and collaborative signals\nfrom user-item interactions. During inference, COBRA employs a coarse-to-fine\nstrategy, starting with sparse ID generation and refining them into dense\nvectors via the generative model. We further propose BeamFusion, an innovative\napproach combining beam search with nearest neighbor scores to enhance\ninference flexibility and recommendation diversity. Extensive experiments on\npublic datasets and offline tests validate our method's robustness. Online A/B\ntests on a real-world advertising platform with over 200 million daily users\ndemonstrate substantial improvements in key metrics, highlighting COBRA's\npractical advantages.\n","authors":["Yuhao Yang","Zhi Ji","Zhaopeng Li","Yi Li","Zhonglin Mo","Yue Ding","Kai Chen","Zijian Zhang","Jie Li","Shuanglong Li","Lin Liu"],"pdf_url":"https://arxiv.org/pdf/2503.02453v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.02401v1","updated":"2025-03-04T08:43:19Z","published":"2025-03-04T08:43:19Z","title":"Hierarchical Re-ranker Retriever (HRR)","summary":"  Retrieving the right level of context for a given query is a perennial\nchallenge in information retrieval - too large a chunk dilutes semantic\nspecificity, while chunks that are too small lack broader context. This paper\nintroduces the Hierarchical Re-ranker Retriever (HRR), a framework designed to\nachieve both fine-grained and high-level context retrieval for large language\nmodel (LLM) applications. In HRR, documents are split into sentence-level and\nintermediate-level (512 tokens) chunks to maximize vector-search quality for\nboth short and broad queries. We then employ a reranker that operates on these\n512-token chunks, ensuring an optimal balance neither too coarse nor too fine\nfor robust relevance scoring. Finally, top-ranked intermediate chunks are\nmapped to parent chunks (2048 tokens) to provide an LLM with sufficiently large\ncontext.\n","authors":["Ashish Singh","Priti Mohapatra"],"pdf_url":"https://arxiv.org/pdf/2503.02401v1.pdf","comment":"14 pages"},{"id":"http://arxiv.org/abs/2503.02398v1","updated":"2025-03-04T08:41:40Z","published":"2025-03-04T08:41:40Z","title":"PersonaX: A Recommendation Agent Oriented User Modeling Framework for\n  Long Behavior Sequence","summary":"  Recommendation agents leverage large language models for user modeling LLM UM\nto construct textual personas guiding alignment with real users. However\nexisting LLM UM methods struggle with long user generated content UGC due to\ncontext limitations and performance degradation. To address this sampling\nstrategies prioritize relevance or recency are often applied yet they\ninevitably neglect the diverse user interests embedded within the discarded\nbehaviors resulting in incomplete modeling and degraded profiling quality.\nFurthermore relevance based sampling requires real time retrieval forcing the\nuser modeling process to operate online which introduces significant latency\noverhead. In this paper we propose PersonaX an agent agnostic LLM UM framework\nthat tackles these challenges through sub behavior sequence SBS selection and\noffline multi persona construction. PersonaX extracts compact SBS segments\noffline to capture diverse user interests generating fine grained textual\npersonas that are cached for efficient online retrieval. This approach ensures\nthat the user persona used for prompting remains highly relevant to the current\ncontext while eliminating the need for online user modeling. For SBS selection\nwe ensure both efficiency length less than five and high representational\nquality by balancing prototypicality and diversity within the sampled data.\nExtensive experiments validate the effectiveness and versatility of PersonaX in\nhigh quality user profiling. Utilizing only 30 to 50 percent of the behavioral\ndata with a sequence length of 480 integrating PersonaX with AgentCF yields an\nabsolute performance improvement of 3 to 11 percent while integration with\nAgent4Rec results in a gain of 10 to 50 percent. PersonaX as an agent agnostic\nframework sets a new benchmark for scalable user modeling paving the way for\nmore accurate and efficient LLM driven recommendation agents.\n","authors":["Yunxiao Shi","Wujiang Xu","Zeqi Zhang","Xing Zi","Qiang Wu","Min Xu"],"pdf_url":"https://arxiv.org/pdf/2503.02398v1.pdf","comment":"draft paper"},{"id":"http://arxiv.org/abs/2404.14851v4","updated":"2025-03-04T08:38:34Z","published":"2024-04-23T09:05:37Z","title":"From Matching to Generation: A Survey on Generative Information\n  Retrieval","summary":"  Information Retrieval (IR) systems are crucial tools for users to access\ninformation, which have long been dominated by traditional methods relying on\nsimilarity matching. With the advancement of pre-trained language models,\ngenerative information retrieval (GenIR) emerges as a novel paradigm,\nattracting increasing attention. Based on the form of information provided to\nusers, current research in GenIR can be categorized into two aspects:\n\\textbf{(1) Generative Document Retrieval} (GR) leverages the generative\nmodel's parameters for memorizing documents, enabling retrieval by directly\ngenerating relevant document identifiers without explicit indexing. \\textbf{(2)\nReliable Response Generation} employs language models to directly generate\ninformation users seek, breaking the limitations of traditional IR in terms of\ndocument granularity and relevance matching while offering flexibility,\nefficiency, and creativity to meet practical needs. This paper aims to\nsystematically review the latest research progress in GenIR. We will summarize\nthe advancements in GR regarding model training and structure, document\nidentifier, incremental learning, etc., as well as progress in reliable\nresponse generation in aspects of internal knowledge memorization, external\nknowledge augmentation, etc. We also review the evaluation, challenges and\nfuture developments in GenIR systems. This review aims to offer a comprehensive\nreference for researchers, encouraging further development in the GenIR field.\nGithub Repository: https://github.com/RUC-NLPIR/GenIR-Survey\n","authors":["Xiaoxi Li","Jiajie Jin","Yujia Zhou","Yuyao Zhang","Peitian Zhang","Yutao Zhu","Zhicheng Dou"],"pdf_url":"https://arxiv.org/pdf/2404.14851v4.pdf","comment":null},{"id":"http://arxiv.org/abs/2402.11480v5","updated":"2025-03-04T07:56:04Z","published":"2024-02-18T07:06:17Z","title":"Pattern-wise Transparent Sequential Recommendation","summary":"  A transparent decision-making process is essential for developing reliable\nand trustworthy recommender systems. For sequential recommendation, it means\nthat the model can identify key items that account for its recommendation\nresults. However, achieving both interpretability and recommendation\nperformance simultaneously is challenging, especially for models that take the\nentire sequence of items as input without screening. In this paper, we propose\nan interpretable framework (named PTSR) that enables a pattern-wise transparent\ndecision-making process without extra features. It breaks the sequence of items\ninto multi-level patterns that serve as atomic units throughout the\nrecommendation process. The contribution of each pattern to the outcome is\nquantified in the probability space. With a carefully designed score correction\nmechanism, the pattern contribution can be implicitly learned in the absence of\nground-truth key patterns. The final recommended items are those that most key\npatterns strongly endorse. Extensive experiments on five public datasets\ndemonstrate remarkable recommendation performance, while statistical analysis\nand case studies validate the model interpretability.\n","authors":["Kun Ma","Cong Xu","Zeyuan Chen","Wei Zhang"],"pdf_url":"https://arxiv.org/pdf/2402.11480v5.pdf","comment":"This paper has been accepted by IEEE TKDE"},{"id":"http://arxiv.org/abs/2501.05874v2","updated":"2025-03-04T07:29:52Z","published":"2025-01-10T11:17:15Z","title":"VideoRAG: Retrieval-Augmented Generation over Video Corpus","summary":"  Retrieval-Augmented Generation (RAG) is a powerful strategy for improving the\nfactual accuracy of models by retrieving external knowledge relevant to queries\nand incorporating it into the generation process. However, existing approaches\nprimarily focus on text, with some recent advancements considering images, and\nthey largely overlook videos, a rich source of multimodal knowledge capable of\nrepresenting contextual details more effectively than any other modality. While\nvery recent studies explore the use of videos in response generation, they\neither predefine query-associated videos without retrieval or convert videos\ninto textual descriptions losing multimodal richness. To tackle these, we\nintroduce VideoRAG, a framework that not only dynamically retrieves videos\nbased on their relevance with queries but also utilizes both visual and textual\ninformation. The operation of VideoRAG is powered by recent Large Video\nLanguage Models (LVLMs), which enable the direct processing of video content to\nrepresent it for retrieval and the seamless integration of retrieved videos\njointly with queries for response generation. Also, inspired by that the\ncontext size of LVLMs may not be sufficient to process all frames in extremely\nlong videos and not all frames are equally important, we introduce a video\nframe selection mechanism to extract the most informative subset of frames,\nalong with a strategy to extract textual information from videos (as it can aid\nthe understanding of video content) when their subtitles are not available. We\nexperimentally validate the effectiveness of VideoRAG, showcasing that it is\nsuperior to relevant baselines. Code is available at\nhttps://github.com/starsuzi/VideoRAG.\n","authors":["Soyeong Jeong","Kangsan Kim","Jinheon Baek","Sung Ju Hwang"],"pdf_url":"https://arxiv.org/pdf/2501.05874v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.17102v2","updated":"2025-03-04T07:04:59Z","published":"2024-11-26T04:39:46Z","title":"Scholar Name Disambiguation with Search-enhanced LLM Across Language","summary":"  The task of scholar name disambiguation is crucial in various real-world\nscenarios, including bibliometric-based candidate evaluation for awards,\napplication material anti-fraud measures, and more. Despite significant\nadvancements, current methods face limitations due to the complexity of\nheterogeneous data, often necessitating extensive human intervention. This\npaper proposes a novel approach by leveraging search-enhanced language models\nacross multiple languages to improve name disambiguation. By utilizing the\npowerful query rewriting, intent recognition, and data indexing capabilities of\nsearch engines, our method can gather richer information for distinguishing\nbetween entities and extracting profiles, resulting in a more comprehensive\ndata dimension. Given the strong cross-language capabilities of large language\nmodels(LLMs), optimizing enhanced retrieval methods with this technology offers\nsubstantial potential for high-efficiency information retrieval and\nutilization. Our experiments demonstrate that incorporating local languages\nsignificantly enhances disambiguation performance, particularly for scholars\nfrom diverse geographic regions. This multi-lingual, search-enhanced\nmethodology offers a promising direction for more efficient and accurate active\nscholar name disambiguation.\n","authors":["Renyu Zhao","Yunxin Chen"],"pdf_url":"https://arxiv.org/pdf/2411.17102v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.01469v2","updated":"2025-03-04T06:37:59Z","published":"2025-03-03T12:23:54Z","title":"Hierarchical Causal Transformer with Heterogeneous Information for\n  Expandable Sequential Recommendation","summary":"  Sequential recommendation systems leveraging transformer architectures have\ndemonstrated exceptional capabilities in capturing user behavior patterns. At\nthe core of these systems lies the critical challenge of constructing effective\nitem representations. Traditional approaches employ feature fusion through\nsimple concatenation or basic neural architectures to create uniform\nrepresentation sequences. However, these conventional methods fail to address\nthe intrinsic diversity of item attributes, thereby constraining the\ntransformer's capacity to discern fine-grained patterns and hindering model\nextensibility. Although recent research has begun incorporating user-related\nheterogeneous features into item sequences, the equally crucial item-side\nheterogeneous feature continue to be neglected. To bridge this methodological\ngap, we present HeterRec - an innovative framework featuring two novel\ncomponents: the Heterogeneous Token Flattening Layer (HTFL) and Hierarchical\nCausal Transformer (HCT). HTFL pioneers a sophisticated tokenization mechanism\nthat decomposes items into multi-dimensional token sets and structures them\ninto heterogeneous sequences, enabling scalable performance enhancement through\nmodel expansion. The HCT architecture further enhances pattern discovery\nthrough token-level and item-level attention mechanisms. furthermore, we\ndevelop a Listwise Multi-step Prediction (LMP) objective function to optimize\nlearning process. Rigorous validation, including real-world industrial\nplatforms, confirms HeterRec's state-of-the-art performance in both effective\nand efficiency.\n","authors":["Hao Deng","Haibo Xing","Kanefumi Matsuyama","Yulei Huang","Jinxin Hu","Hong Wen","Jia Xu","Zulong Chen","Yu Zhang","Xiaoyi Zeng","Jing Zhang"],"pdf_url":"https://arxiv.org/pdf/2503.01469v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2502.11610v2","updated":"2025-03-04T06:28:50Z","published":"2025-02-17T09:54:46Z","title":"Accuracy Assessment of OpenAlex and Clarivate Scholar ID with an\n  LLM-Assisted Benchmark","summary":"  In quantitative SciSci (science of science) studies, accurately identifying\nindividual scholars is paramount for scientific data analysis. However, the\nvariability in how names are represented-due to commonality, abbreviations, and\ndifferent spelling conventions-complicates this task. While identifier systems\nlike ORCID are being developed, many scholars remain unregistered, and numerous\npublications are not included. Scholarly databases such as Clarivate and\nOpenAlex have introduced their own ID systems as preliminary name\ndisambiguation solutions. This study evaluates the effectiveness of these\nsystems across different groups to determine their suitability for various\napplication scenarios. We sampled authors from the top quartile (Q1) of Web of\nScience (WOS) journals based on country, discipline, and number of\ncorresponding author papers. For each group, we selected 100 scholars and\nmeticulously annotated all their papers using a Search-enhanced Large Language\nModel method. Using these annotations, we identified the corresponding IDs in\nOpenAlex and Clarivate, extracted all associated papers, filtered for Q1 WOS\njournals, and calculated precision and recall by comparing against the\nannotated dataset.\n","authors":["Renyu Zhao","Yunxin Chen"],"pdf_url":"https://arxiv.org/pdf/2502.11610v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.02298v1","updated":"2025-03-04T05:48:07Z","published":"2025-03-04T05:48:07Z","title":"Towards Explainable Doctor Recommendation with Large Language Models","summary":"  The advent of internet medicine provides patients with unprecedented\nconvenience in searching and communicating with doctors relevant to their\ndiseases and desired treatments online. However, the current doctor\nrecommendation systems fail to fully ensure the professionalism and\ninterpretability of the recommended results. In this work, we formulate doctor\nrecommendation as a ranking task and develop a large language model (LLM)-based\npointwise ranking framework. Our framework ranks doctors according to their\nrelevance regarding specific diseases-treatment pairs in a zero-shot setting.\nThe advantage of our framework lies in its ability to generate precise and\nexplainable doctor ranking results. Additionally, we construct DrRank, a new\nexpertise-driven doctor ranking dataset comprising over 38 disease-treatment\npairs. Experiment results on the DrRank dataset demonstrate that our framework\nsignificantly outperforms the strongest cross-encoder baseline, achieving a\nnotable gain of +5.45 in the NDCG@10 score while maintaining affordable latency\nconsumption. Furthermore, we comprehensively present the fairness analysis\nresults of our framework from three perspectives of different diseases, patient\ngender, and geographical regions. Meanwhile, the interpretability of our\nframework is rigorously verified by three human experts, providing further\nevidence of the reliability of our proposed framework for doctor\nrecommendation.\n","authors":["Ziyang Zeng","Dongyuan Li","Yuqing Yang"],"pdf_url":"https://arxiv.org/pdf/2503.02298v1.pdf","comment":"12 pages, 6 figures, Journal of Biomedical and Health Informatics\n  (JBHI) under review"},{"id":"http://arxiv.org/abs/2501.18210v2","updated":"2025-03-04T04:07:39Z","published":"2025-01-30T08:55:32Z","title":"Hashtag Re-Appropriation for Audience Control on Recommendation-Driven\n  Social Media Xiaohongshu (rednote)","summary":"  Algorithms have played a central role in personalized recommendations on\nsocial media. However, they also present significant obstacles for content\ncreators trying to predict and manage their audience reach. This issue is\nparticularly challenging for marginalized groups seeking to maintain safe\nspaces. Our study explores how women on Xiaohongshu (rednote), a\nrecommendation-driven social platform, proactively re-appropriate hashtags\n(e.g., #Baby Supplemental Food) by using them in posts unrelated to their\nliteral meaning. The hashtags were strategically chosen from topics that would\nbe uninteresting to the male audience they wanted to block. Through a\nmixed-methods approach, we analyzed the practice of hashtag re-appropriation\nbased on 5,800 collected posts and interviewed 24 active users from diverse\nbackgrounds to uncover users' motivations and reactions towards the\nre-appropriation. This practice highlights how users can reclaim agency over\ncontent distribution on recommendation-driven platforms, offering insights into\nself-governance within algorithmic-centered power structures.\n","authors":["Ruyuan Wan","Lingbo Tong","Tiffany Knearem","Toby Jia-Jun Li","Ting-Hao 'Kenneth' Huang","Qunfang Wu"],"pdf_url":"https://arxiv.org/pdf/2501.18210v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.02251v1","updated":"2025-03-04T03:57:10Z","published":"2025-03-04T03:57:10Z","title":"Tailoring Table Retrieval from a Field-aware Hybrid Matching Perspective","summary":"  Table retrieval, essential for accessing information through tabular data, is\nless explored compared to text retrieval. The row/column structure and distinct\nfields of tables (including titles, headers, and cells) present unique\nchallenges. For example, different table fields have varying matching\npreferences: cells may favor finer-grained (word/phrase level) matching over\nbroader (sentence/passage level) matching due to their fragmented and detailed\nnature, unlike titles. This necessitates a table-specific retriever to\naccommodate the various matching needs of each table field. Therefore, we\nintroduce a Table-tailored HYbrid Matching rEtriever (THYME), which approaches\ntable retrieval from a field-aware hybrid matching perspective. Empirical\nresults on two table retrieval benchmarks, NQ-TABLES and OTT-QA, show that\nTHYME significantly outperforms state-of-the-art baselines. Comprehensive\nanalyses confirm the differing matching preferences across table fields and\nvalidate the design of THYME.\n","authors":["Da Li","Keping Bi","Jiafeng Guo","Xueqi Cheng"],"pdf_url":"https://arxiv.org/pdf/2503.02251v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2502.15331v2","updated":"2025-03-04T02:18:36Z","published":"2025-02-21T09:34:31Z","title":"Lightweight yet Efficient: An External Attentive Graph Convolutional\n  Network with Positional Prompts for Sequential Recommendation","summary":"  Graph-based Sequential Recommender systems (GSRs) have gained significant\nresearch attention due to their ability to simultaneously handle user-item\ninteractions and sequential relationships between items. Current GSRs often\nutilize composite or in-depth structures for graph encoding (e.g., the Graph\nTransformer). Nevertheless, they have high computational complexity, hindering\nthe deployment on resource-constrained edge devices. Moreover, the relative\nposition encoding in Graph Transformer has difficulty in considering the\ncomplicated positional dependencies within sequence. To this end, we propose an\nExternal Attentive Graph convolutional network with Positional prompts for\nSequential recommendation, namely EA-GPS. Specifically, we first introduce an\nexternal attentive graph convolutional network that linearly measures the\nglobal associations among nodes via two external memory units. Then, we present\na positional prompt-based decoder that explicitly treats the absolute item\npositions as external prompts. By introducing length-adaptive sequential\nmasking and a soft attention network, such a decoder facilitates the model to\ncapture the long-term positional dependencies and contextual relationships\nwithin sequences. Extensive experimental results on five real-world datasets\ndemonstrate that the proposed EA-GPS outperforms the state-of-the-art methods.\nRemarkably, it achieves the superior performance while maintaining a smaller\nparameter size and lower training overhead. The implementation of this work is\npublicly available at https://github.com/ZZY-GraphMiningLab/EA-GPS.\n","authors":["Jinyu Zhang","Chao Li","Zhongying Zhao"],"pdf_url":"https://arxiv.org/pdf/2502.15331v2.pdf","comment":"26 pages, 8 figures, journal paper, accepted by TOIS at 20th\n  February, 2025"},{"id":"http://arxiv.org/abs/2410.11841v2","updated":"2025-03-04T01:02:11Z","published":"2024-10-15T17:59:30Z","title":"GaVaMoE: Gaussian-Variational Gated Mixture of Experts for Explainable\n  Recommendation","summary":"  Large language model-based explainable recommendation (LLM-based ER) systems\nshow promise in generating human-like explanations for recommendations.\nHowever, they face challenges in modeling user-item collaborative preferences,\npersonalizing explanations, and handling sparse user-item interactions. To\naddress these issues, we propose GaVaMoE, a novel Gaussian-Variational Gated\nMixture of Experts framework for explainable recommendation. GaVaMoE introduces\ntwo key components: (1) a rating reconstruction module that employs Variational\nAutoencoder (VAE) with a Gaussian Mixture Model (GMM) to capture complex\nuser-item collaborative preferences, serving as a pre-trained multi-gating\nmechanism; and (2) a set of fine-grained expert models coupled with the\nmulti-gating mechanism for generating highly personalized explanations. The VAE\ncomponent models latent factors in user-item interactions, while the GMM\nclusters users with similar behaviors. Each cluster corresponds to a gate in\nthe multi-gating mechanism, routing user-item pairs to appropriate expert\nmodels. This architecture enables GaVaMoE to generate tailored explanations for\nspecific user types and preferences, mitigating data sparsity by leveraging\nuser similarities. Extensive experiments on three real-world datasets\ndemonstrate that GaVaMoE significantly outperforms existing methods in\nexplanation quality, personalization, and consistency. Notably, GaVaMoE\nexhibits robust performance in scenarios with sparse user-item interactions,\nmaintaining high-quality explanations even for users with limited historical\ndata.\n","authors":["Fei Tang","Yongliang Shen","Hang Zhang","Zeqi Tan","Wenqi Zhang","Zhibiao Huang","Kaitao Song","Weiming Lu","Yueting Zhuang"],"pdf_url":"https://arxiv.org/pdf/2410.11841v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2412.01007v3","updated":"2025-03-04T00:36:44Z","published":"2024-12-01T23:54:12Z","title":"CoRNStack: High-Quality Contrastive Data for Better Code Retrieval and\n  Reranking","summary":"  Effective code retrieval plays a crucial role in advancing code generation,\nbug fixing, and software maintenance, particularly as software systems increase\nin complexity. While current code embedding models have demonstrated promise in\nretrieving code snippets for small-scale, well-defined tasks, they often\nunderperform in more demanding real-world applications such as bug localization\nwithin GitHub repositories. We hypothesize that a key issue is their reliance\non noisy and inconsistent datasets for training, which impedes their ability to\ngeneralize to more complex retrieval scenarios. To address these limitations,\nwe introduce CoRNStack, a large-scale, high-quality contrastive training\ndataset for code that spans multiple programming languages. This dataset is\ncurated using consistency filtering to eliminate noisy positives and is further\nenriched with mined hard negatives, thereby facilitating more effective\nlearning. We demonstrate that contrastive training of embedding models using\nCoRNStack leads to state-of-the-art performance across a variety of code\nretrieval tasks. Furthermore, the dataset can be leveraged for training code\nreranking models, a largely underexplored area compared to text reranking. Our\nfinetuned code reranking model significantly improves the ranking quality over\nthe retrieved results. Finally, by employing our code retriever and reranker\ntogether, we demonstrate significant improvements in function localization for\nGitHub issues, an important component of real-world software development.\n","authors":["Tarun Suresh","Revanth Gangi Reddy","Yifei Xu","Zach Nussbaum","Andriy Mulyar","Brandon Duderstadt","Heng Ji"],"pdf_url":"https://arxiv.org/pdf/2412.01007v3.pdf","comment":"Published as a conference paper at ICLR 2025. First and second author\n  had equal contribution"},{"id":"http://arxiv.org/abs/2503.03062v1","updated":"2025-03-04T23:52:49Z","published":"2025-03-04T23:52:49Z","title":"Semi-Supervised In-Context Learning: A Baseline Study","summary":"  Most existing work in data selection for In-Context Learning (ICL) has\nfocused on constructing demonstrations from ground truth annotations, with\nlimited attention given to selecting reliable self-generated annotations. In\nthis work, we propose a three-step semi-supervised ICL framework: annotation\ngeneration, demonstration selection, and semi-supervised inference. Our\nbaseline, Naive-SemiICL, which prompts select high-confidence self-generated\ndemonstrations for ICL prompting, outperforms a 16-shot baseline by an average\nof 9.94% across 16 datasets. We further introduce IterPSD, an annotation\napproach that refines pseudo-demonstrations iteratively, achieving up to 6.8%\nadditional gains in classification tasks. Lastly, we reveal a scaling law for\nsemi-supervised ICL, where models achieve optimal performance with over 1,000\ndemonstrations.\n","authors":["Zhengyao Gu","Henry Peng Zou","Yankai Chen","Aiwei Liu","Weizhi Zhang","Philip S. Yu"],"pdf_url":"https://arxiv.org/pdf/2503.03062v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.02993v1","updated":"2025-03-04T20:39:07Z","published":"2025-03-04T20:39:07Z","title":"Zero-Shot Multi-Label Classification of Bangla Documents: Large Decoders\n  Vs. Classic Encoders","summary":"  Bangla, a language spoken by over 300 million native speakers and ranked as\nthe sixth most spoken language worldwide, presents unique challenges in natural\nlanguage processing (NLP) due to its complex morphological characteristics and\nlimited resources. While recent Large Decoder Based models (LLMs), such as GPT,\nLLaMA, and DeepSeek, have demonstrated excellent performance across many NLP\ntasks, their effectiveness in Bangla remains largely unexplored. In this paper,\nwe establish the first benchmark comparing decoder-based LLMs with classic\nencoder-based models for Zero-Shot Multi-Label Classification (Zero-Shot-MLC)\ntask in Bangla. Our evaluation of 32 state-of-the-art models reveals that,\nexisting so-called powerful encoders and decoders still struggle to achieve\nhigh accuracy on the Bangla Zero-Shot-MLC task, suggesting a need for more\nresearch and resources for Bangla NLP.\n","authors":["Souvika Sarkar","Md. Najib Hasan","Santu Karmaker"],"pdf_url":"https://arxiv.org/pdf/2503.02993v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2409.13744v2","updated":"2025-03-04T19:15:49Z","published":"2024-09-11T00:16:17Z","title":"A Simplified Retriever to Improve Accuracy of Phenotype Normalizations\n  by Large Language Models","summary":"  Large language models (LLMs) have shown improved accuracy in phenotype term\nnormalization tasks when augmented with retrievers that suggest candidate\nnormalizations based on term definitions. In this work, we introduce a\nsimplified retriever that enhances LLM accuracy by searching the Human\nPhenotype Ontology (HPO) for candidate matches using contextual word embeddings\nfrom BioBERT without the need for explicit term definitions. Testing this\nmethod on terms derived from the clinical synopses of Online Mendelian\nInheritance in Man (OMIM), we demonstrate that the normalization accuracy of a\nstate-of-the-art LLM increases from a baseline of 62.3% without augmentation to\n90.3% with retriever augmentation. This approach is potentially generalizable\nto other biomedical term normalization tasks and offers an efficient\nalternative to more complex retrieval methods.\n","authors":["Daniel B. Hier","Thanh Son Do","Tayo Obafemi-Ajayi"],"pdf_url":"https://arxiv.org/pdf/2409.13744v2.pdf","comment":"Published by Frontiers in Digital Health"},{"id":"http://arxiv.org/abs/2503.02948v1","updated":"2025-03-04T19:09:48Z","published":"2025-03-04T19:09:48Z","title":"ExpertGenQA: Open-ended QA generation in Specialized Domains","summary":"  Generating high-quality question-answer pairs for specialized technical\ndomains remains challenging, with existing approaches facing a tradeoff between\nleveraging expert examples and achieving topical diversity. We present\nExpertGenQA, a protocol that combines few-shot learning with structured topic\nand style categorization to generate comprehensive domain-specific QA pairs.\nUsing U.S. Federal Railroad Administration documents as a test bed, we\ndemonstrate that ExpertGenQA achieves twice the efficiency of baseline few-shot\napproaches while maintaining $94.4\\%$ topic coverage. Through systematic\nevaluation, we show that current LLM-based judges and reward models exhibit\nstrong bias toward superficial writing styles rather than content quality. Our\nanalysis using Bloom's Taxonomy reveals that ExpertGenQA better preserves the\ncognitive complexity distribution of expert-written questions compared to\ntemplate-based approaches. When used to train retrieval models, our generated\nqueries improve top-1 accuracy by $13.02\\%$ over baseline performance,\ndemonstrating their effectiveness for downstream applications in technical\ndomains.\n","authors":["Haz Sameen Shahgir","Chansong Lim","Jia Chen","Evangelos E. Papalexakis","Yue Dong"],"pdf_url":"https://arxiv.org/pdf/2503.02948v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.02922v1","updated":"2025-03-04T18:47:17Z","published":"2025-03-04T18:47:17Z","title":"Optimizing open-domain question answering with graph-based retrieval\n  augmented generation","summary":"  In this work, we benchmark various graph-based retrieval-augmented generation\n(RAG) systems across a broad spectrum of query types, including OLTP-style\n(fact-based) and OLAP-style (thematic) queries, to address the complex demands\nof open-domain question answering (QA). Traditional RAG methods often fall\nshort in handling nuanced, multi-document synthesis tasks. By structuring\nknowledge as graphs, we can facilitate the retrieval of context that captures\ngreater semantic depth and enhances language model operations. We explore\ngraph-based RAG methodologies and introduce TREX, a novel, cost-effective\nalternative that combines graph-based and vector-based retrieval techniques.\nOur benchmarking across four diverse datasets highlights the strengths of\ndifferent RAG methodologies, demonstrates TREX's ability to handle multiple\nopen-domain QA types, and reveals the limitations of current evaluation\nmethods.\n  In a real-world technical support case study, we demonstrate how TREX\nsolutions can surpass conventional vector-based RAG in efficiently synthesizing\ndata from heterogeneous sources. Our findings underscore the potential of\naugmenting large language models with advanced retrieval and orchestration\ncapabilities, advancing scalable, graph-based AI solutions.\n","authors":["Joyce Cahoon","Prerna Singh","Nick Litombe","Jonathan Larson","Ha Trinh","Yiwen Zhu","Andreas Mueller","Fotis Psallidas","Carlo Curino"],"pdf_url":"https://arxiv.org/pdf/2503.02922v1.pdf","comment":null}]},"2025-03-05T00:00:00Z":{"Computation and Language":[{"id":"http://arxiv.org/abs/2503.01711v3","updated":"2025-03-05T05:52:00Z","published":"2025-03-03T16:24:36Z","title":"MAPS: Motivation-Aware Personalized Search via LLM-Driven Consultation\n  Alignment","summary":"  Personalized product search aims to retrieve and rank items that match users'\npreferences and search intent. Despite their effectiveness, existing approaches\ntypically assume that users' query fully captures their real motivation.\nHowever, our analysis of a real-world e-commerce platform reveals that users\noften engage in relevant consultations before searching, indicating they refine\nintents through consultations based on motivation and need. The implied\nmotivation in consultations is a key enhancing factor for personalized search.\nThis unexplored area comes with new challenges including aligning contextual\nmotivations with concise queries, bridging the category-text gap, and filtering\nnoise within sequence history. To address these, we propose a Motivation-Aware\nPersonalized Search (MAPS) method. It embeds queries and consultations into a\nunified semantic space via LLMs, utilizes a Mixture of Attention Experts (MoAE)\nto prioritize critical semantics, and introduces dual alignment: (1)\ncontrastive learning aligns consultations, reviews, and product features; (2)\nbidirectional attention integrates motivation-aware embeddings with user\npreferences. Extensive experiments on real and synthetic data show MAPS\noutperforms existing methods in both retrieval and ranking tasks.\n","authors":["Weicong Qin","Yi Xu","Weijie Yu","Chenglei Shen","Ming He","Jianping Fan","Xiao Zhang","Jun Xu"],"pdf_url":"https://arxiv.org/pdf/2503.01711v3.pdf","comment":"added project repository & dataset URL"},{"id":"http://arxiv.org/abs/2503.02603v2","updated":"2025-03-05T02:13:38Z","published":"2025-03-04T13:21:47Z","title":"OkraLong: A Flexible Retrieval-Augmented Framework for Long-Text Query\n  Processing","summary":"  Large Language Models (LLMs) encounter challenges in efficiently processing\nlong-text queries, as seen in applications like enterprise document analysis\nand financial report comprehension. While conventional solutions employ\nlong-context processing or Retrieval-Augmented Generation (RAG), they suffer\nfrom prohibitive input expenses or incomplete information. Recent advancements\nadopt context compression and dynamic retrieval loops, but still sacrifice\ncritical details or incur iterative costs. To address these limitations, we\npropose OkraLong, a novel framework that flexibly optimizes the entire\nprocessing workflow. Unlike prior static or coarse-grained adaptive strategies,\nOkraLong adopts fine-grained orchestration through three synergistic\ncomponents: analyzer, organizer and executor. The analyzer characterizes the\ntask states, which guide the organizer in dynamically scheduling the workflow.\nThe executor carries out the execution and generates the final answer.\nExperimental results demonstrate that OkraLong not only enhances answer\naccuracy but also achieves cost-effectiveness across a variety of datasets.\n","authors":["Yulong Hui","Yihao Liu","Yao Lu","Huanchen Zhang"],"pdf_url":"https://arxiv.org/pdf/2503.02603v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.02589v2","updated":"2025-03-05T03:28:29Z","published":"2025-03-04T13:12:39Z","title":"MCiteBench: A Benchmark for Multimodal Citation Text Generation in MLLMs","summary":"  Multimodal Large Language Models (MLLMs) have advanced in integrating diverse\nmodalities but frequently suffer from hallucination. A promising solution to\nmitigate this issue is to generate text with citations, providing a transparent\nchain for verification. However, existing work primarily focuses on generating\ncitations for text-only content, overlooking the challenges and opportunities\nof multimodal contexts. To address this gap, we introduce MCiteBench, the first\nbenchmark designed to evaluate and analyze the multimodal citation text\ngeneration ability of MLLMs. Our benchmark comprises data derived from academic\npapers and review-rebuttal interactions, featuring diverse information sources\nand multimodal content. We comprehensively evaluate models from multiple\ndimensions, including citation quality, source reliability, and answer\naccuracy. Through extensive experiments, we observe that MLLMs struggle with\nmultimodal citation text generation. We also conduct deep analyses of models'\nperformance, revealing that the bottleneck lies in attributing the correct\nsources rather than understanding the multimodal content.\n","authors":["Caiyu Hu","Yikai Zhang","Tinghui Zhu","Yiwei Ye","Yanghua Xiao"],"pdf_url":"https://arxiv.org/pdf/2503.02589v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.02445v2","updated":"2025-03-05T06:04:37Z","published":"2025-03-04T09:40:00Z","title":"BRIDGE: Bootstrapping Text to Control Time-Series Generation via\n  Multi-Agent Iterative Optimization and Diffusion Modelling","summary":"  Time-series Generation (TSG) is a prominent research area with broad\napplications in simulations, data augmentation, and counterfactual analysis.\nWhile existing methods have shown promise in unconditional single-domain TSG,\nreal-world applications demand for cross-domain approaches capable of\ncontrolled generation tailored to domain-specific constraints and\ninstance-level requirements. In this paper, we argue that text can provide\nsemantic insights, domain information and instance-specific temporal patterns,\nto guide and improve TSG. We introduce ``Text-Controlled TSG'', a task focused\non generating realistic time series by incorporating textual descriptions. To\naddress data scarcity in this setting, we propose a novel LLM-based Multi-Agent\nframework that synthesizes diverse, realistic text-to-TS datasets. Furthermore,\nwe introduce BRIDGE, a hybrid text-controlled TSG framework that integrates\nsemantic prototypes with text description for supporting domain-level guidance.\nThis approach achieves state-of-the-art generation fidelity on 11 of 12\ndatasets, and improves controllability by 12.52% on MSE and 6.34% MAE compared\nto no text input generation, highlighting its potential for generating tailored\ntime-series data.\n","authors":["Hao Li","Yu-Hao Huang","Chang Xu","Viktor Schlegel","Ren-He Jiang","Riza Batista-Navarro","Goran Nenadic","Jiang Bian"],"pdf_url":"https://arxiv.org/pdf/2503.02445v2.pdf","comment":"Preprint. Work in progress"},{"id":"http://arxiv.org/abs/2503.01478v3","updated":"2025-03-05T05:24:54Z","published":"2025-03-03T12:37:34Z","title":"SePer: Measure Retrieval Utility Through The Lens Of Semantic Perplexity\n  Reduction","summary":"  Large Language Models (LLMs) have demonstrated improved generation\nperformance by incorporating externally retrieved knowledge, a process known as\nretrieval-augmented generation (RAG). Despite the potential of this approach,\nexisting studies evaluate RAG effectiveness by 1) assessing retrieval and\ngeneration components jointly, which obscures retrieval's distinct\ncontribution, or 2) examining retrievers using traditional metrics such as\nNDCG, which creates a gap in understanding retrieval's true utility in the\noverall generation process. To address the above limitations, in this work, we\nintroduce an automatic evaluation method that measures retrieval quality\nthrough the lens of information gain within the RAG framework. Specifically, we\npropose Semantic Perplexity (SePer), a metric that captures the LLM's internal\nbelief about the correctness of the retrieved information. We quantify the\nutility of retrieval by the extent to which it reduces semantic perplexity\npost-retrieval. Extensive experiments demonstrate that SePer not only aligns\nclosely with human preferences but also offers a more precise and efficient\nevaluation of retrieval utility across diverse RAG scenarios.\n","authors":["Lu Dai","Yijie Xu","Jinhui Ye","Hao Liu","Hui Xiong"],"pdf_url":"https://arxiv.org/pdf/2503.01478v3.pdf","comment":"ICLR 2025 Spotlight"},{"id":"http://arxiv.org/abs/2503.02368v2","updated":"2025-03-05T09:12:25Z","published":"2025-03-04T07:49:10Z","title":"Iterative Value Function Optimization for Guided Decoding","summary":"  While Reinforcement Learning from Human Feedback (RLHF) has become the\npredominant method for controlling language model outputs, it suffers from high\ncomputational costs and training instability. Guided decoding, especially\nvalue-guided methods, offers a cost-effective alternative by controlling\noutputs without re-training models. However, the accuracy of the value function\nis crucial for value-guided decoding, as inaccuracies can lead to suboptimal\ndecision-making and degraded performance. Existing methods struggle with\naccurately estimating the optimal value function, leading to less effective\ncontrol. We propose Iterative Value Function Optimization, a novel framework\nthat addresses these limitations through two key components: Monte Carlo Value\nEstimation, which reduces estimation variance by exploring diverse\ntrajectories, and Iterative On-Policy Optimization, which progressively\nimproves value estimation through collecting trajectories from value-guided\npolicies. Extensive experiments on text summarization, multi-turn dialogue, and\ninstruction following demonstrate the effectiveness of value-guided decoding\napproaches in aligning language models. These approaches not only achieve\nalignment but also significantly reduce computational costs by leveraging\nprincipled value function optimization for efficient and effective control.\n","authors":["Zhenhua Liu","Lijun Li","Ruizhe Chen","Yuxian Jiang","Tong Zhu","Zhaochen Su","Wenliang Chen","Jing Shao"],"pdf_url":"https://arxiv.org/pdf/2503.02368v2.pdf","comment":"20 pages, 10 figures"},{"id":"http://arxiv.org/abs/2407.17773v3","updated":"2025-03-05T03:07:12Z","published":"2024-07-25T05:02:39Z","title":"KiVA: Kid-inspired Visual Analogies for Testing Large Multimodal Models","summary":"  This paper investigates visual analogical reasoning in large multimodal\nmodels (LMMs) compared to human adults and children. A \"visual analogy\" is an\nabstract rule inferred from one image and applied to another. While benchmarks\nexist for testing visual reasoning in LMMs, they require advanced skills and\nomit basic visual analogies that even young children can make. Inspired by\ndevelopmental psychology, we propose a new benchmark of 4,300 visual\ntransformations of everyday objects to test LMMs on visual analogical reasoning\nand compare them to children (ages three to five) and to adults. We structure\nthe evaluation into three stages: identifying what changed (e.g., color,\nnumber, etc.), how it changed (e.g., added one object), and applying the rule\nto new scenarios. Our findings show that while GPT-o1, GPT-4V, LLaVA-1.5, and\nMANTIS identify the \"what\" effectively, they struggle with quantifying the\n\"how\" and extrapolating this rule to new objects. In contrast, children and\nadults exhibit much stronger analogical reasoning at all three stages.\nAdditionally, the strongest tested model, GPT-o1, performs better in tasks\ninvolving simple surface-level visual attributes like color and size,\ncorrelating with quicker human adult response times. Conversely, more complex\ntasks such as number, rotation, and reflection, which necessitate extensive\ncognitive processing and understanding of extrinsic spatial properties in the\nphysical world, present more significant challenges. Altogether, these findings\nhighlight the limitations of training models on data that primarily consists of\n2D images and text.\n","authors":["Eunice Yiu","Maan Qraitem","Anisa Noor Majhi","Charlie Wong","Yutong Bai","Shiry Ginosar","Alison Gopnik","Kate Saenko"],"pdf_url":"https://arxiv.org/pdf/2407.17773v3.pdf","comment":"10 pages. Project website: https://ey242.github.io/kiva.github.io/.\n  Benchmark and code: https://github.com/ey242/KiVA"},{"id":"http://arxiv.org/abs/2409.14494v3","updated":"2025-03-05T06:32:04Z","published":"2024-09-13T19:14:18Z","title":"CPT-Boosted Wav2vec2.0: Towards Noise Robust Speech Recognition for\n  Classroom Environments","summary":"  Creating Automatic Speech Recognition (ASR) systems that are robust and\nresilient to classroom conditions is paramount to the development of AI tools\nto aid teachers and students. In this work, we study the efficacy of continued\npretraining (CPT) in adapting Wav2vec2.0 to the classroom domain. We show that\nCPT is a powerful tool in that regard and reduces the Word Error Rate (WER) of\nWav2vec2.0-based models by upwards of 10%. More specifically, CPT improves the\nmodel's robustness to different noises, microphones and classroom conditions.\n","authors":["Ahmed Adel Attia","Dorottya Demszky","Tolulope Ogunremi","Jing Liu","Carol Espy-Wilson"],"pdf_url":"https://arxiv.org/pdf/2409.14494v3.pdf","comment":"arXiv admin note: substantial text overlap with arXiv:2405.13018"},{"id":"http://arxiv.org/abs/2503.03750v1","updated":"2025-03-05T18:59:23Z","published":"2025-03-05T18:59:23Z","title":"The MASK Benchmark: Disentangling Honesty From Accuracy in AI Systems","summary":"  As large language models (LLMs) become more capable and agentic, the\nrequirement for trust in their outputs grows significantly, yet at the same\ntime concerns have been mounting that models may learn to lie in pursuit of\ntheir goals. To address these concerns, a body of work has emerged around the\nnotion of \"honesty\" in LLMs, along with interventions aimed at mitigating\ndeceptive behaviors. However, evaluations of honesty are currently highly\nlimited, with no benchmark combining large scale and applicability to all\nmodels. Moreover, many benchmarks claiming to measure honesty in fact simply\nmeasure accuracy--the correctness of a model's beliefs--in disguise. In this\nwork, we introduce a large-scale human-collected dataset for measuring honesty\ndirectly, allowing us to disentangle accuracy from honesty for the first time.\nAcross a diverse set of LLMs, we find that while larger models obtain higher\naccuracy on our benchmark, they do not become more honest. Surprisingly, while\nmost frontier LLMs obtain high scores on truthfulness benchmarks, we find a\nsubstantial propensity in frontier LLMs to lie when pressured to do so,\nresulting in low honesty scores on our benchmark. We find that simple methods,\nsuch as representation engineering interventions, can improve honesty. These\nresults underscore the growing need for robust evaluations and effective\ninterventions to ensure LLMs remain trustworthy.\n","authors":["Richard Ren","Arunim Agarwal","Mantas Mazeika","Cristina Menghini","Robert Vacareanu","Brad Kenstler","Mick Yang","Isabelle Barrass","Alice Gatti","Xuwang Yin","Eduardo Trevino","Matias Geralnik","Adam Khoja","Dean Lee","Summer Yue","Dan Hendrycks"],"pdf_url":"https://arxiv.org/pdf/2503.03750v1.pdf","comment":"Website: https://www.mask-benchmark.ai"},{"id":"http://arxiv.org/abs/2503.03746v1","updated":"2025-03-05T18:58:44Z","published":"2025-03-05T18:58:44Z","title":"Process-based Self-Rewarding Language Models","summary":"  Large Language Models have demonstrated outstanding performance across\nvarious downstream tasks and have been widely applied in multiple scenarios.\nHuman-annotated preference data is used for training to further improve LLMs'\nperformance, which is constrained by the upper limit of human performance.\nTherefore, Self-Rewarding method has been proposed, where LLMs generate\ntraining data by rewarding their own outputs. However, the existing\nself-rewarding paradigm is not effective in mathematical reasoning scenarios\nand may even lead to a decline in performance. In this work, we propose the\nProcess-based Self-Rewarding pipeline for language models, which introduces\nlong-thought reasoning, step-wise LLM-as-a-Judge, and step-wise preference\noptimization within the self-rewarding paradigm. Our new paradigm successfully\nenhances the performance of LLMs on multiple mathematical reasoning benchmarks\nthrough iterative Process-based Self-Rewarding, demonstrating the immense\npotential of self-rewarding to achieve LLM reasoning that may surpass human\ncapabilities.\n","authors":["Shimao Zhang","Xiao Liu","Xin Zhang","Junxiao Liu","Zheheng Luo","Shujian Huang","Yeyun Gong"],"pdf_url":"https://arxiv.org/pdf/2503.03746v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2404.14395v2","updated":"2025-03-05T18:17:28Z","published":"2024-04-22T17:55:56Z","title":"PARAMANU-GANITA: Can Small Math Language Models Rival with Large\n  Language Models on Mathematical Reasoning?","summary":"  In this paper, we study whether domain specific pretraining of small\ngenerative language models (SLM) from scratch with domain specialized tokenizer\nand Chain-of-Thought (CoT) instruction fine-tuning results in competitive\nperformance on mathematical reasoning compared to LLMs? Secondly, whether this\napproach is environmentally sustainable, highly cost efficient? To address\nthese research questions, we present Paramanu-Ganita, a 208 million-parameter\nnovel decoder-only Auto Regressive SLM on mathematics. We performed pretraining\nfrom scratch on 31.5 billion tokens for 170 A100 hours using a context size of\n4096 on a mixed mathematical corpus consisting of web pages, source code,\ntextbooks, CoT templatised StackOverflow QA pairs, and mathematical lecture\nnotes in LaTeX curated by us. We also trained a math and code specialised BPE\ntokenizer. We proposed and performed CoT instruction fine-tuning of\nParamanu-Ganita on the MetaMathQA dataset. Our model Paramanu-Ganita, despite\nbeing 34 times smaller than the 7B LLMs, outperforms generalist LLMs by\napproximately 30% points, and even math-specialised LLMs by 3-23% points in\nGSM8K test accuracy metric. On MATH benchmark, Paramanu-Ganita outperformed the\nvarious models by 6-8% points. On benchmarks like LogiQA, MMLU (high school,\ncollege level), and competitive exams level, AGIEVAL (AQuA-RAT, SAT-Math),\nParamanu-Ganita outperformed others by 1-4%. Our model is available at\nhttps://huggingface.co/gyanai/paramanu-ganita-208M-hf .\n","authors":["Mitodru Niyogi","Arnab Bhattacharya"],"pdf_url":"https://arxiv.org/pdf/2404.14395v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.03710v1","updated":"2025-03-05T18:01:05Z","published":"2025-03-05T18:01:05Z","title":"Improving LLM Safety Alignment with Dual-Objective Optimization","summary":"  Existing training-time safety alignment techniques for large language models\n(LLMs) remain vulnerable to jailbreak attacks. Direct preference optimization\n(DPO), a widely deployed alignment method, exhibits limitations in both\nexperimental and theoretical contexts as its loss function proves suboptimal\nfor refusal learning. Through gradient-based analysis, we identify these\nshortcomings and propose an improved safety alignment that disentangles DPO\nobjectives into two components: (1) robust refusal training, which encourages\nrefusal even when partial unsafe generations are produced, and (2) targeted\nunlearning of harmful knowledge. This approach significantly increases LLM\nrobustness against a wide range of jailbreak attacks, including prefilling,\nsuffix, and multi-turn attacks across both in-distribution and\nout-of-distribution scenarios. Furthermore, we introduce a method to emphasize\ncritical refusal tokens by incorporating a reward-based token-level weighting\nmechanism for refusal learning, which further improves the robustness against\nadversarial exploits. Our research also suggests that robustness to jailbreak\nattacks is correlated with token distribution shifts in the training process\nand internal representations of refusal and harmful tokens, offering valuable\ndirections for future research in LLM safety alignment. The code is available\nat https://github.com/wicai24/DOOR-Alignment\n","authors":["Xuandong Zhao","Will Cai","Tianneng Shi","David Huang","Licong Lin","Song Mei","Dawn Song"],"pdf_url":"https://arxiv.org/pdf/2503.03710v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.03705v1","updated":"2025-03-05T17:56:20Z","published":"2025-03-05T17:56:20Z","title":"Effective LLM Knowledge Learning via Model Generalization","summary":"  Large language models (LLMs) are trained on enormous documents that contain\nextensive world knowledge. However, it is still not well-understood how\nknowledge is acquired via autoregressive pre-training. This lack of\nunderstanding greatly hinders effective knowledge learning, especially for\ncontinued pretraining on up-to-date information, as this evolving information\noften lacks diverse repetitions like foundational knowledge. In this paper, we\nfocus on understanding and improving LLM knowledge learning. We found and\nverified that knowledge learning for LLMs can be deemed as an implicit\nsupervised task hidden in the autoregressive pre-training objective. Our\nfindings suggest that knowledge learning for LLMs would benefit from methods\ndesigned to improve generalization ability for supervised tasks. Based on our\nanalysis, we propose the formatting-based data augmentation to grow\nin-distribution samples, which does not present the risk of altering the facts\nembedded in documents as text paraphrasing. We also introduce sharpness-aware\nminimization as an effective optimization algorithm to better improve\ngeneralization. Moreover, our analysis and method can be readily extended to\ninstruction tuning. Extensive experiment results validate our findings and\ndemonstrate our methods' effectiveness in both continued pre-training and\ninstruction tuning. This paper offers new perspectives and insights to\ninterpret and design effective strategies for LLM knowledge learning.\n","authors":["Mingkang Zhu","Xi Chen","Zhongdao Wang","Bei Yu","Hengshuang Zhao","Jiaya Jia"],"pdf_url":"https://arxiv.org/pdf/2503.03705v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.03703v1","updated":"2025-03-05T17:53:11Z","published":"2025-03-05T17:53:11Z","title":"SoftMatcha: A Soft and Fast Pattern Matcher for Billion-Scale Corpus\n  Searches","summary":"  Researchers and practitioners in natural language processing and\ncomputational linguistics frequently observe and analyze the real language\nusage in large-scale corpora. For that purpose, they often employ off-the-shelf\npattern-matching tools, such as grep, and keyword-in-context concordancers,\nwhich is widely used in corpus linguistics for gathering examples. Nonetheless,\nthese existing techniques rely on surface-level string matching, and thus they\nsuffer from the major limitation of not being able to handle orthographic\nvariations and paraphrasing -- notable and common phenomena in any natural\nlanguage. In addition, existing continuous approaches such as dense vector\nsearch tend to be overly coarse, often retrieving texts that are unrelated but\nshare similar topics. Given these challenges, we propose a novel algorithm that\nachieves \\emph{soft} (or semantic) yet efficient pattern matching by relaxing a\nsurface-level matching with word embeddings. Our algorithm is highly scalable\nwith respect to the size of the corpus text utilizing inverted indexes. We have\nprepared an efficient implementation, and we provide an accessible web tool.\nOur experiments demonstrate that the proposed method (i) can execute searches\non billion-scale corpora in less than a second, which is comparable in speed to\nsurface-level string matching and dense vector search; (ii) can extract harmful\ninstances that semantically match queries from a large set of English and\nJapanese Wikipedia articles; and (iii) can be effectively applied to\ncorpus-linguistic analyses of Latin, a language with highly diverse\ninflections.\n","authors":["Hiroyuki Deguchi","Go Kamoda","Yusuke Matsushita","Chihiro Taguchi","Kohei Suenaga","Masaki Waga","Sho Yokoi"],"pdf_url":"https://arxiv.org/pdf/2503.03703v1.pdf","comment":"Accepted at ICLR2025"},{"id":"http://arxiv.org/abs/2503.03702v1","updated":"2025-03-05T17:53:07Z","published":"2025-03-05T17:53:07Z","title":"Developing and Utilizing a Large-Scale Cantonese Dataset for\n  Multi-Tasking in Large Language Models","summary":"  High-quality data resources play a crucial role in learning large language\nmodels (LLMs), particularly for low-resource languages like Cantonese. Despite\nhaving more than 85 million native speakers, Cantonese is still considered a\nlow-resource language in the field of natural language processing (NLP) due to\nfactors such as the dominance of Mandarin, lack of cohesion within the\nCantonese-speaking community, diversity in character encoding and input\nmethods, and the tendency of overseas Cantonese speakers to prefer using\nEnglish. In addition, rich colloquial vocabulary of Cantonese, English\nloanwords, and code-switching characteristics add to the complexity of corpus\ncollection and processing. To address these challenges, we collect Cantonese\ntexts from a variety of sources, including open source corpora, Hong\nKong-specific forums, Wikipedia, and Common Crawl data. We conduct rigorous\ndata processing through language filtering, quality filtering, content\nfiltering, and de-duplication steps, successfully constructing a high-quality\nCantonese corpus of over 2 billion tokens for training large language models.\nWe further refined the model through supervised fine-tuning (SFT) on curated\nCantonese tasks, enhancing its ability to handle specific applications. Upon\ncompletion of the training, the model achieves state-of-the-art (SOTA)\nperformance on four Cantonese benchmarks. After training on our dataset, the\nmodel also exhibits improved performance on other mainstream language tasks.\n","authors":["Jiyue Jiang","Alfred Kar Yin Truong","Yanyu Chen","Qinghang Bao","Sheng Wang","Pengan Chen","Jiuming Wang","Lingpeng Kong","Yu Li","Chuan Wu"],"pdf_url":"https://arxiv.org/pdf/2503.03702v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.08143v2","updated":"2025-03-05T17:50:44Z","published":"2024-10-10T17:30:09Z","title":"DelTA: An Online Document-Level Translation Agent Based on Multi-Level\n  Memory","summary":"  Large language models (LLMs) have achieved reasonable quality improvements in\nmachine translation (MT). However, most current research on MT-LLMs still faces\nsignificant challenges in maintaining translation consistency and accuracy when\nprocessing entire documents. In this paper, we introduce DelTA, a\nDocument-levEL Translation Agent designed to overcome these limitations. DelTA\nfeatures a multi-level memory structure that stores information across various\ngranularities and spans, including Proper Noun Records, Bilingual Summary,\nLong-Term Memory, and Short-Term Memory, which are continuously retrieved and\nupdated by auxiliary LLM-based components. Experimental results indicate that\nDelTA significantly outperforms strong baselines in terms of translation\nconsistency and quality across four open/closed-source LLMs and two\nrepresentative document translation datasets, achieving an increase in\nconsistency scores by up to 4.58 percentage points and in COMET scores by up to\n3.16 points on average. DelTA employs a sentence-by-sentence translation\nstrategy, ensuring no sentence omissions and offering a memory-efficient\nsolution compared to the mainstream method. Furthermore, DelTA improves pronoun\nand context-dependent translation accuracy, and the summary component of the\nagent also shows promise as a tool for query-based summarization tasks. The\ncode and data of our approach are released at\nhttps://github.com/YutongWang1216/DocMTAgent.\n","authors":["Yutong Wang","Jiali Zeng","Xuebo Liu","Derek F. Wong","Fandong Meng","Jie Zhou","Min Zhang"],"pdf_url":"https://arxiv.org/pdf/2410.08143v2.pdf","comment":"Accepted as a conference paper at ICLR 2025"},{"id":"http://arxiv.org/abs/2503.03686v1","updated":"2025-03-05T17:27:59Z","published":"2025-03-05T17:27:59Z","title":"MAS-GPT: Training LLMs to Build LLM-based Multi-Agent Systems","summary":"  LLM-based multi-agent systems (MAS) have shown significant potential in\ntackling diverse tasks. However, to design effective MAS, existing approaches\nheavily rely on manual configurations or multiple calls of advanced LLMs,\nresulting in inadaptability and high inference costs. In this paper, we\nsimplify the process of building an MAS by reframing it as a generative\nlanguage task, where the input is a user query and the output is a\ncorresponding MAS. To address this novel task, we unify the representation of\nMAS as executable code and propose a consistency-oriented data construction\npipeline to create a high-quality dataset comprising coherent and consistent\nquery-MAS pairs. Using this dataset, we train MAS-GPT, an open-source\nmedium-sized LLM that is capable of generating query-adaptive MAS within a\nsingle LLM inference. The generated MAS can be seamlessly applied to process\nuser queries and deliver high-quality responses. Extensive experiments on 9\nbenchmarks and 5 LLMs show that the proposed MAS-GPT consistently outperforms\n10+ baseline MAS methods on diverse settings, indicating MAS-GPT's high\neffectiveness, efficiency and strong generalization ability. Code will be\navailable at https://github.com/rui-ye/MAS-GPT.\n","authors":["Rui Ye","Shuo Tang","Rui Ge","Yaxin Du","Zhenfei Yin","Siheng Chen","Jing Shao"],"pdf_url":"https://arxiv.org/pdf/2503.03686v1.pdf","comment":"26 pages, 7 figures"},{"id":"http://arxiv.org/abs/2502.01777v2","updated":"2025-03-05T17:25:07Z","published":"2025-02-03T19:29:42Z","title":"CTC-DRO: Robust Optimization for Reducing Language Disparities in Speech\n  Recognition","summary":"  Modern deep learning models often achieve high overall performance, but\nconsistently fail on specific subgroups. Group distributionally robust\noptimization (group DRO) addresses this problem by minimizing the worst-group\nloss, but it fails when group losses misrepresent performance differences\nbetween groups. This is common in domains like speech, where the widely used\nconnectionist temporal classification (CTC) loss scales with input length and\nvaries with linguistic and acoustic properties, leading to spurious differences\nbetween group losses. We present CTC-DRO, which addresses the shortcomings of\nthe group DRO objective by smoothing the group weight update to prevent\noveremphasis on consistently high-loss groups, while using input length-matched\nbatching to mitigate CTC's scaling issues. We evaluate CTC-DRO on the task of\nmultilingual automatic speech recognition (ASR) across five language sets from\nthe ML-SUPERB 2.0 benchmark. CTC-DRO consistently outperforms group DRO and\nCTC-based baseline models, reducing the worst-language error by up to 47.1% and\nthe average error by up to 32.9%. CTC-DRO can be applied to ASR with minimal\ncomputational costs, and offers the potential for reducing group disparities in\nother domains with similar challenges.\n","authors":["Martijn Bartelds","Ananjan Nandi","Moussa Koulako Bala Doumbouya","Dan Jurafsky","Tatsunori Hashimoto","Karen Livescu"],"pdf_url":"https://arxiv.org/pdf/2502.01777v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.03681v1","updated":"2025-03-05T17:22:33Z","published":"2025-03-05T17:22:33Z","title":"Quantification of Tenseness in English and Japanese Tense-Lax Vowels: A\n  Lagrangian Model with Indicator $_1$ and Force of Tenseness Ftense(t)","summary":"  The concept of vowel tenseness has traditionally been examined through the\nbinary distinction of tense and lax vowels. However, no universally accepted\nquantitative definition of tenseness has been established in any language.\nPrevious studies, including those by Jakobson, Fant, and Halle (1951) and\nChomsky and Halle (1968), have explored the relationship between vowel\ntenseness and the vocal tract. Building on these foundations, Ishizaki (2019,\n2022) proposed an indirect quantification of vowel tenseness using formant\nangles $\\theta_1$ and $\\theta_{F1}$ and their first and second derivatives,\n$d^Z_1(t)/dt = \\lim \\tan \\theta_1(t$) and $d^2 Z_1(t)/dt^2 = d/dt \\lim \\tan\n\\theta_1(t)$. This study extends this approach by investigating the potential\nrole of a force-related parameter in determining vowel quality. Specifically,\nwe introduce a simplified model based on the Lagrangian equation to describe\nthe dynamic interaction of the tongue and jaw within the oral cavity during the\narticulation of close vowels. This model provides a theoretical framework for\nestimating the forces involved in vowel production across different languages,\noffering new insights into the physical mechanisms underlying vowel\narticulation. The findings suggest that this force-based perspective warrants\nfurther exploration as a key factor in phonetic and phonological studies.\n","authors":["Tatsuya Ishizaki"],"pdf_url":"https://arxiv.org/pdf/2503.03681v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.03669v1","updated":"2025-03-05T17:03:48Z","published":"2025-03-05T17:03:48Z","title":"Attentive Reasoning Queries: A Systematic Method for Optimizing\n  Instruction-Following in Large Language Models","summary":"  We present Attentive Reasoning Queries (ARQs), a novel structured reasoning\napproach that significantly improves instruction-following in Large Language\nModels through domain-specialized reasoning blueprints. While LLMs demonstrate\nremarkable capabilities across diverse tasks, they often fail to maintain\nadherence to complex, use-case-specific instructions during multi-turn\nconversations, presenting challenges for business-critical applications. ARQs\naddress this limitation by guiding LLMs through systematic reasoning steps with\ntargeted queries that reinstate critical instructions and facilitate\nintermediate reasoning throughout the completion process. In extensive testing\nwithin Parlant, our framework for reliable customer-facing agents in which ARQs\nwere born out of necessity, they achieved a 90.2% success rate across 87 test\nscenarios, outperforming both Chain-of-Thought reasoning (86.1%) and direct\nresponse generation (81.5%). ARQs showed particular strength in addressing\npersistent failure modes like guideline re-application and hallucination\nprevention. Our analysis also revealed that ARQs can potentially be more\ncomputationally efficient than free-form reasoning when carefully designed.\nThese findings demonstrate that structured reasoning approaches provide\neffective mechanisms for controlling how LLMs process information and make\ndecisions in complex scenarios.\n","authors":["Bar Karov","Dor Zohar","Yam Marcovitz"],"pdf_url":"https://arxiv.org/pdf/2503.03669v1.pdf","comment":"Supplementary materials, including code, is available on our GitHub:\n  https://github.com/emcie-co/parlant/tree/arqs-a-systematic-method-for-optimizing-instruction-following-in-llms"},{"id":"http://arxiv.org/abs/2503.03666v1","updated":"2025-03-05T16:59:08Z","published":"2025-03-05T16:59:08Z","title":"Analogical Reasoning Inside Large Language Models: Concept Vectors and\n  the Limits of Abstraction","summary":"  Analogical reasoning relies on conceptual abstractions, but it is unclear\nwhether Large Language Models (LLMs) harbor such internal representations. We\nexplore distilled representations from LLM activations and find that function\nvectors (FVs; Todd et al., 2024) - compact representations for in-context\nlearning (ICL) tasks - are not invariant to simple input changes (e.g.,\nopen-ended vs. multiple-choice), suggesting they capture more than pure\nconcepts. Using representational similarity analysis (RSA), we localize a small\nset of attention heads that encode invariant concept vectors (CVs) for verbal\nconcepts like \"antonym\". These CVs function as feature detectors that operate\nindependently of the final output - meaning that a model may form a correct\ninternal representation yet still produce an incorrect output. Furthermore, CVs\ncan be used to causally guide model behaviour. However, for more abstract\nconcepts like \"previous\" and \"next\", we do not observe invariant linear\nrepresentations, a finding we link to generalizability issues LLMs display\nwithin these domains.\n","authors":["Gustaw Opieka","Hannes Rosenbusch","Claire E. Stevenson"],"pdf_url":"https://arxiv.org/pdf/2503.03666v1.pdf","comment":"Preprint"},{"id":"http://arxiv.org/abs/2409.07402v2","updated":"2025-03-05T16:48:23Z","published":"2024-09-11T16:42:22Z","title":"What to align in multimodal contrastive learning?","summary":"  Humans perceive the world through multisensory integration, blending the\ninformation of different modalities to adapt their behavior. Contrastive\nlearning offers an appealing solution for multimodal self-supervised learning.\nIndeed, by considering each modality as a different view of the same entity, it\nlearns to align features of different modalities in a shared representation\nspace. However, this approach is intrinsically limited as it only learns shared\nor redundant information between modalities, while multimodal interactions can\narise in other ways. In this work, we introduce CoMM, a Contrastive MultiModal\nlearning strategy that enables the communication between modalities in a single\nmultimodal space. Instead of imposing cross- or intra- modality constraints, we\npropose to align multimodal representations by maximizing the mutual\ninformation between augmented versions of these multimodal features. Our\ntheoretical analysis shows that shared, synergistic and unique terms of\ninformation naturally emerge from this formulation, allowing us to estimate\nmultimodal interactions beyond redundancy. We test CoMM both in a controlled\nand in a series of real-world settings: in the former, we demonstrate that CoMM\neffectively captures redundant, unique and synergistic information between\nmodalities. In the latter, CoMM learns complex multimodal interactions and\nachieves state-of-the-art results on the seven multimodal benchmarks. Code is\navailable at https://github.com/Duplums/CoMM\n","authors":["Benoit Dufumier","Javiera Castillo-Navarro","Devis Tuia","Jean-Philippe Thiran"],"pdf_url":"https://arxiv.org/pdf/2409.07402v2.pdf","comment":"ICLR 2025, 25 pages"},{"id":"http://arxiv.org/abs/2411.00816v2","updated":"2025-03-05T16:36:05Z","published":"2024-10-28T08:10:21Z","title":"CycleResearcher: Improving Automated Research via Automated Review","summary":"  The automation of scientific discovery has been a long-standing goal within\nthe research community, driven by the potential to accelerate knowledge\ncreation. While significant progress has been made using commercial large\nlanguage models (LLMs) as research assistants or idea generators, the\npossibility of automating the entire research process with open-source LLMs\nremains largely unexplored. This paper explores the feasibility of using\nopen-source post-trained LLMs as autonomous agents capable of performing the\nfull cycle of automated research and review, from literature review and\nmanuscript preparation to peer review and paper refinement. Our iterative\npreference training framework consists of CycleResearcher, which conducts\nresearch tasks, and CycleReviewer, which simulates the peer review process,\nproviding iterative feedback via reinforcement learning. To train these models,\nwe develop two new datasets, Review-5k and Research-14k, reflecting real-world\nmachine learning research and peer review dynamics. Our results demonstrate\nthat CycleReviewer achieves promising performance with a 26.89\\% reduction in\nmean absolute error (MAE) compared to individual human reviewers in predicting\npaper scores, indicating the potential of LLMs to effectively assist\nexpert-level research evaluation. In research, the papers generated by the\nCycleResearcher model achieved a score of 5.36 in simulated peer reviews,\nshowing some competitiveness in terms of simulated review scores compared to\nthe preprint level of 5.24 from human experts, while still having room for\nimprovement compared to the accepted paper level of 5.69. This work represents\na significant step toward fully automated scientific inquiry, providing ethical\nsafeguards and exploring AI-driven research capabilities. The code, dataset and\nmodel weight are released at https://wengsyx.github.io/Researcher/\n","authors":["Yixuan Weng","Minjun Zhu","Guangsheng Bao","Hongbo Zhang","Jindong Wang","Yue Zhang","Linyi Yang"],"pdf_url":"https://arxiv.org/pdf/2411.00816v2.pdf","comment":"Accept in ICLR 2025"},{"id":"http://arxiv.org/abs/2503.03654v1","updated":"2025-03-05T16:32:47Z","published":"2025-03-05T16:32:47Z","title":"Improving Neutral Point of View Text Generation through\n  Parameter-Efficient Reinforcement Learning and a Small-Scale High-Quality\n  Dataset","summary":"  This paper describes the construction of a dataset and the evaluation of\ntraining methods to improve generative large language models' (LLMs) ability to\nanswer queries on sensitive topics with a Neutral Point of View (NPOV), i.e.,\nto provide significantly more informative, diverse and impartial answers. The\ndataset, the SHQ-NPOV dataset, comprises 300 high-quality, human-written\nquadruplets: a query on a sensitive topic, an answer, an NPOV rating, and a set\nof links to source texts elaborating the various points of view. The first key\ncontribution of this paper is a new methodology to create such datasets through\niterative rounds of human peer-critique and annotator training, which we\nrelease alongside the dataset. The second key contribution is the\nidentification of a highly effective training regime for parameter-efficient\nreinforcement learning (PE-RL) to improve NPOV generation. We compare and\nextensively evaluate PE-RL and multiple baselines-including LoRA finetuning (a\nstrong baseline), SFT and RLHF.\n  PE-RL not only improves on overall NPOV quality compared to the strongest\nbaseline ($97.06\\%\\rightarrow 99.08\\%$), but also scores much higher on\nfeatures linguists identify as key to separating good answers from the best\nanswers ($60.25\\%\\rightarrow 85.21\\%$ for presence of supportive details,\n$68.74\\%\\rightarrow 91.43\\%$ for absence of oversimplification). A qualitative\nanalysis corroborates this. Finally, our evaluation finds no statistical\ndifferences between results on topics that appear in the training dataset and\nthose on separated evaluation topics, which provides strong evidence that our\napproach to training PE-RL exhibits very effective out of topic generalization.\n","authors":["Jessica Hoffmann","Christiane Ahlheim","Zac Yu","Aria Walfrand","Jarvis Jin","Marie Tano","Ahmad Beirami","Erin van Liemt","Nithum Thain","Hakim Sidahmed","Lucas Dixon"],"pdf_url":"https://arxiv.org/pdf/2503.03654v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2502.20581v2","updated":"2025-03-05T16:32:35Z","published":"2025-02-27T22:47:03Z","title":"The Noisy Path from Source to Citation: Measuring How Scholars Engage\n  with Past Research","summary":"  Academic citations are widely used for evaluating research and tracing\nknowledge flows. Such uses typically rely on raw citation counts and neglect\nvariability in citation types. In particular, citations can vary in their\nfidelity as original knowledge from cited studies may be paraphrased,\nsummarized, or reinterpreted, possibly wrongly, leading to variation in how\nmuch information changes from cited to citing paper. In this study, we\nintroduce a computational pipeline to quantify citation fidelity at scale.\nUsing full texts of papers, the pipeline identifies citations in citing papers\nand the corresponding claims in cited papers, and applies supervised models to\nmeasure fidelity at the sentence level. Analyzing a large-scale\nmulti-disciplinary dataset of approximately 13 million citation sentence pairs,\nwe find that citation fidelity is higher when authors cite papers that are 1)\nmore recent and intellectually close, 2) more accessible, and 3) the first\nauthor has a lower H-index and the author team is medium-sized. Using a\nquasi-experiment, we establish the \"telephone effect\" - when citing papers have\nlow fidelity to the original claim, future papers that cite the citing paper\nand the original have lower fidelity to the original. Our work reveals\nsystematic differences in citation fidelity, underscoring the limitations of\nanalyses that rely on citation quantity alone and the potential for distortion\nof evidence.\n","authors":["Hong Chen","Misha Teplitskiy","David Jurgens"],"pdf_url":"https://arxiv.org/pdf/2502.20581v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2406.01863v2","updated":"2025-03-05T16:27:57Z","published":"2024-06-04T00:30:37Z","title":"Towards Effective Time-Aware Language Representation: Exploring Enhanced\n  Temporal Understanding in Language Models","summary":"  In the evolving field of Natural Language Processing (NLP), understanding the\ntemporal context of text is increasingly critical for applications requiring\nadvanced temporal reasoning. Traditional pre-trained language models like BERT,\nwhich rely on synchronic document collections such as BookCorpus and Wikipedia,\noften fall short in effectively capturing and leveraging temporal information.\nTo address this limitation, we introduce BiTimeBERT 2.0, a novel time-aware\nlanguage model pre-trained on a temporal news article collection. BiTimeBERT\n2.0 incorporates temporal information through three innovative pre-training\nobjectives: Extended Time-Aware Masked Language Modeling (ETAMLM), Document\nDating (DD), and Time-Sensitive Entity Replacement (TSER). Each objective is\nspecifically designed to target a distinct dimension of temporal information:\nETAMLM enhances the model's understanding of temporal contexts and relations,\nDD integrates document timestamps as explicit chronological markers, and TSER\nfocuses on the temporal dynamics of \"Person\" entities. Moreover, our refined\ncorpus preprocessing strategy reduces training time by nearly 53\\%, making\nBiTimeBERT 2.0 significantly more efficient while maintaining high performance.\nExperimental results show that BiTimeBERT 2.0 achieves substantial improvements\nacross a broad range of time-related tasks and excels on datasets spanning\nextensive temporal ranges. These findings underscore BiTimeBERT 2.0's potential\nas a powerful tool for advancing temporal reasoning in NLP.\n","authors":["Jiexin Wang","Adam Jatowt","Yi Cai"],"pdf_url":"https://arxiv.org/pdf/2406.01863v2.pdf","comment":"This paper has been accepted for publication in ACM Transactions on\n  the Web. Final publication details (volume, issue, page range) will be\n  updated once they are finalized"},{"id":"http://arxiv.org/abs/2503.03652v1","updated":"2025-03-05T16:27:25Z","published":"2025-03-05T16:27:25Z","title":"Token-Level Privacy in Large Language Models","summary":"  The use of language models as remote services requires transmitting private\ninformation to external providers, raising significant privacy concerns. This\nprocess not only risks exposing sensitive data to untrusted service providers\nbut also leaves it vulnerable to interception by eavesdroppers. Existing\nprivacy-preserving methods for natural language processing (NLP) interactions\nprimarily rely on semantic similarity, overlooking the role of contextual\ninformation. In this work, we introduce dchi-stencil, a novel token-level\nprivacy-preserving mechanism that integrates contextual and semantic\ninformation while ensuring strong privacy guarantees under the dchi\ndifferential privacy framework, achieving 2epsilon-dchi-privacy. By\nincorporating both semantic and contextual nuances, dchi-stencil achieves a\nrobust balance between privacy and utility. We evaluate dchi-stencil using\nstate-of-the-art language models and diverse datasets, achieving comparable and\neven better trade-off between utility and privacy compared to existing methods.\nThis work highlights the potential of dchi-stencil to set a new standard for\nprivacy-preserving NLP in modern, high-risk applications.\n","authors":["Re'em Harel","Niv Gilboa","Yuval Pinter"],"pdf_url":"https://arxiv.org/pdf/2503.03652v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.02865v2","updated":"2025-03-05T16:24:43Z","published":"2025-03-04T18:43:57Z","title":"FairSense-AI: Responsible AI Meets Sustainability","summary":"  In this paper, we introduce FairSense-AI: a multimodal framework designed to\ndetect and mitigate bias in both text and images. By leveraging Large Language\nModels (LLMs) and Vision-Language Models (VLMs), FairSense-AI uncovers subtle\nforms of prejudice or stereotyping that can appear in content, providing users\nwith bias scores, explanatory highlights, and automated recommendations for\nfairness enhancements. In addition, FairSense-AI integrates an AI risk\nassessment component that aligns with frameworks like the MIT AI Risk\nRepository and NIST AI Risk Management Framework, enabling structured\nidentification of ethical and safety concerns. The platform is optimized for\nenergy efficiency via techniques such as model pruning and mixed-precision\ncomputation, thereby reducing its environmental footprint. Through a series of\ncase studies and applications, we demonstrate how FairSense-AI promotes\nresponsible AI use by addressing both the social dimension of fairness and the\npressing need for sustainability in large-scale AI deployments.\nhttps://vectorinstitute.github.io/FairSense-AI,\nhttps://pypi.org/project/fair-sense-ai/ (Sustainability , Responsible AI ,\nLarge Language Models , Vision Language Models , Ethical AI , Green AI)\n","authors":["Shaina Raza","Mukund Sayeeganesh Chettiar","Matin Yousefabadi","Tahniat Khan","Marcelo Lotif"],"pdf_url":"https://arxiv.org/pdf/2503.02865v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.03645v1","updated":"2025-03-05T16:23:15Z","published":"2025-03-05T16:23:15Z","title":"Psy-Copilot: Visual Chain of Thought for Counseling","summary":"  Large language models (LLMs) are becoming increasingly popular in the field\nof psychological counseling. However, when human therapists work with LLMs in\ntherapy sessions, it is hard to understand how the model gives the answers. To\naddress this, we have constructed Psy-COT, a graph designed to visualize the\nthought processes of LLMs during therapy sessions. The Psy-COT graph presents\nsemi-structured counseling conversations alongside step-by-step annotations\nthat capture the reasoning and insights of therapists. Moreover, we have\ndeveloped Psy-Copilot, which is a conversational AI assistant designed to\nassist human psychological therapists in their consultations. It can offer\ntraceable psycho-information based on retrieval, including response candidates,\nsimilar dialogue sessions, related strategies, and visual traces of results. We\nhave also built an interactive platform for AI-assisted counseling. It has an\ninterface that displays the relevant parts of the retrieval sub-graph. The\nPsy-Copilot is designed not to replace psychotherapists but to foster\ncollaboration between AI and human therapists, thereby promoting mental health\ndevelopment. Our code and demo are both open-sourced and available for use.\n","authors":["Keqi Chen","Zekai Sun","Huijun Lian","Yingming Gao","Ya Li"],"pdf_url":"https://arxiv.org/pdf/2503.03645v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.02102v2","updated":"2025-03-05T16:18:33Z","published":"2025-03-03T22:37:03Z","title":"Provable Benefits of Task-Specific Prompts for In-context Learning","summary":"  The in-context learning capabilities of modern language models have motivated\na deeper mathematical understanding of sequence models. A line of recent work\nhas shown that linear attention models can emulate projected gradient descent\niterations to implicitly learn the task vector from the data provided in the\ncontext window. In this work, we consider a novel setting where the global task\ndistribution can be partitioned into a union of conditional task distributions.\nWe then examine the use of task-specific prompts and prediction heads for\nlearning the prior information associated with the conditional task\ndistribution using a one-layer attention model. Our results on loss landscape\nshow that task-specific prompts facilitate a covariance-mean decoupling where\nprompt-tuning explains the conditional mean of the distribution whereas the\nvariance is learned/explained through in-context learning. Incorporating\ntask-specific head further aids this process by entirely decoupling estimation\nof mean and variance components. This covariance-mean perspective similarly\nexplains how jointly training prompt and attention weights can provably help\nover fine-tuning after pretraining.\n","authors":["Xiangyu Chang","Yingcong Li","Muti Kara","Samet Oymak","Amit K. Roy-Chowdhury"],"pdf_url":"https://arxiv.org/pdf/2503.02102v2.pdf","comment":"Proceedings of the 28th International Conference on Artificial\n  Intelligence and Statistics (AISTATS) 2025"},{"id":"http://arxiv.org/abs/2410.12893v2","updated":"2025-03-05T16:16:01Z","published":"2024-10-16T12:24:42Z","title":"MIRROR: A Novel Approach for the Automated Evaluation of Open-Ended\n  Question Generation","summary":"  Automatic question generation is a critical task that involves evaluating\nquestion quality by considering factors such as engagement, pedagogical value,\nand the ability to stimulate critical thinking. These aspects require\nhuman-like understanding and judgment, which automated systems currently lack.\nHowever, human evaluations are costly and impractical for large-scale samples\nof generated questions. Therefore, we propose a novel system, MIRROR (Multi-LLM\nIterative Review and Response for Optimized Rating), which leverages large\nlanguage models (LLMs) to automate the evaluation process for questions\ngenerated by automated question generation systems. We experimented with\nseveral state-of-the-art LLMs, such as GPT-4, Gemini, and Llama2-70b. We\nobserved that the scores of human evaluation metrics, namely relevance,\nappropriateness, novelty, complexity, and grammaticality, improved when using\nthe feedback-based approach called MIRROR, tending to be closer to the human\nbaseline scores. Furthermore, we observed that Pearson's correlation\ncoefficient between GPT-4 and human experts improved when using our proposed\nfeedback-based approach, MIRROR, compared to direct prompting for evaluation.\nError analysis shows that our proposed approach, MIRROR, significantly helps to\nimprove relevance and appropriateness.\n","authors":["Aniket Deroy","Subhankar Maity","Sudeshna Sarkar"],"pdf_url":"https://arxiv.org/pdf/2410.12893v2.pdf","comment":"NeurIPS'24 Workshop on Large Foundation Models for Educational\n  Assessment (FM-EduAssess)"},{"id":"http://arxiv.org/abs/2502.09647v2","updated":"2025-03-05T16:14:16Z","published":"2025-02-11T00:04:32Z","title":"Unveiling Simplicities of Attention: Adaptive Long-Context Head\n  Identification","summary":"  The ability to process long contexts is crucial for many natural language\nprocessing tasks, yet it remains a significant challenge. While substantial\nprogress has been made in enhancing the efficiency of attention mechanisms,\nthere is still a gap in understanding how attention heads function in\nlong-context settings. In this paper, we observe that while certain heads\nconsistently attend to local information only, others swing between attending\nto local and long-context information depending on the query. This raises the\nquestion: can we identify which heads require long-context information to\npredict the next token accurately? We demonstrate that it's possible to predict\nwhich heads are crucial for long-context processing using only local keys. The\ncore idea here is to exploit a simple model for the long-context scores via\nsecond moment approximations. These findings unveil simple properties of\nattention in the context of long sequences, and open the door to potentially\nsignificant gains in efficiency.\n","authors":["Konstantin Donhauser","Charles Arnal","Mohammad Pezeshki","Vivien Cabannes","David Lopez-Paz","Kartik Ahuja"],"pdf_url":"https://arxiv.org/pdf/2502.09647v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.08642v2","updated":"2025-03-05T15:55:52Z","published":"2024-10-11T09:10:26Z","title":"More than Memes: A Multimodal Topic Modeling Approach to Conspiracy\n  Theories on Telegram","summary":"  To address the increasing prevalence of (audio-)visual data on social media,\nand to capture the evolving and dynamic nature of this communication,\nresearchers have begun to explore the potential of unsupervised approaches for\nanalyzing multimodal online content. However, existing research often neglects\nvisual content beyond memes, and in addition lacks methods to compare topic\nmodels across modalities. Our study addresses these gaps by applying multimodal\ntopic modeling for analyzing conspiracy theories in German-language Telegram\nchannels. We use BERTopic with CLIP for the analysis of textual and visual data\nin a corpus of ~40, 000 Telegram messages posted in October 2023 in 571\nGerman-language Telegram channels known for disseminating conspiracy theories.\nThrough this dataset, we provide insights into unimodal and multimodal topic\nmodels by analyzing symmetry and intersections of topics across modalities. We\ndemonstrate the variety of textual and visual content shared in the channels\ndiscovered through the topic modeling, and propose a conceptual framework for\nthe analysis of textual and visual discursive strategies in the communication\nof conspiracy theories. We apply the framework in a case study of the topic\ngroup Israel Gaza.\n","authors":["Elisabeth Steffen"],"pdf_url":"https://arxiv.org/pdf/2410.08642v2.pdf","comment":"12 pages, 10 figures"},{"id":"http://arxiv.org/abs/2411.07527v2","updated":"2025-03-05T15:52:25Z","published":"2024-11-12T03:55:27Z","title":"Prompt-enhanced Network for Hateful Meme Classification","summary":"  The dynamic expansion of social media has led to an inundation of hateful\nmemes on media platforms, accentuating the growing need for efficient\nidentification and removal. Acknowledging the constraints of conventional\nmultimodal hateful meme classification, which heavily depends on external\nknowledge and poses the risk of including irrelevant or redundant content, we\ndeveloped Pen -- a prompt-enhanced network framework based on the prompt\nlearning approach. Specifically, after constructing the sequence through the\nprompt method and encoding it with a language model, we performed region\ninformation global extraction on the encoded sequence for multi-view\nperception. By capturing global information about inference instances and\ndemonstrations, Pen facilitates category selection by fully leveraging sequence\ninformation. This approach significantly improves model classification\naccuracy. Additionally, to bolster the model's reasoning capabilities in the\nfeature space, we introduced prompt-aware contrastive learning into the\nframework to improve the quality of sample feature distributions. Through\nextensive ablation experiments on two public datasets, we evaluate the\neffectiveness of the Pen framework, concurrently comparing it with\nstate-of-the-art model baselines. Our research findings highlight that Pen\nsurpasses manual prompt methods, showcasing superior generalization and\nclassification accuracy in hateful meme classification tasks. Our code is\navailable at https://github.com/juszzi/Pen.\n","authors":["Junxi Liu","Yanyan Feng","Jiehai Chen","Yun Xue","Fenghuan Li"],"pdf_url":"https://arxiv.org/pdf/2411.07527v2.pdf","comment":"Published in Proceedings of the Thirty-Third International Joint\n  Conference on Artificial Intelligence Main Track. Pages 6397-6405"},{"id":"http://arxiv.org/abs/2503.03607v1","updated":"2025-03-05T15:44:21Z","published":"2025-03-05T15:44:21Z","title":"Psy-Insight: Explainable Multi-turn Bilingual Dataset for Mental Health\n  Counseling","summary":"  The in-context learning capabilities of large language models (LLMs) show\ngreat potential in mental health support. However, the lack of counseling\ndatasets, particularly in Chinese corpora, restricts their application in this\nfield. To address this, we constructed Psy-Insight, the first mental\nhealth-oriented explainable multi-task bilingual dataset. We collected\nface-to-face multi-turn counseling dialogues, which are annotated with\nmulti-task labels and conversation process explanations. Our annotations\ninclude psychotherapy, emotion, strategy, and topic labels, as well as\nturn-level reasoning and session-level guidance. Psy-Insight is not only\nsuitable for tasks such as label recognition but also meets the need for\ntraining LLMs to act as empathetic counselors through logical reasoning.\nExperiments show that training LLMs on Psy-Insight enables the models to not\nonly mimic the conversation style but also understand the underlying strategies\nand reasoning of counseling.\n","authors":["Keqi Chen","Zekai Sun","Yuhua Wen","Huijun Lian","Yingming Gao","Ya Li"],"pdf_url":"https://arxiv.org/pdf/2503.03607v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.03601v1","updated":"2025-03-05T15:33:52Z","published":"2025-03-05T15:33:52Z","title":"Feature-Level Insights into Artificial Text Detection with Sparse\n  Autoencoders","summary":"  Artificial Text Detection (ATD) is becoming increasingly important with the\nrise of advanced Large Language Models (LLMs). Despite numerous efforts, no\nsingle algorithm performs consistently well across different types of unseen\ntext or guarantees effective generalization to new LLMs. Interpretability plays\na crucial role in achieving this goal. In this study, we enhance ATD\ninterpretability by using Sparse Autoencoders (SAE) to extract features from\nGemma-2-2b residual stream. We identify both interpretable and efficient\nfeatures, analyzing their semantics and relevance through domain- and\nmodel-specific statistics, a steering approach, and manual or LLM-based\ninterpretation. Our methods offer valuable insights into how texts from various\nmodels differ from human-written content. We show that modern LLMs have a\ndistinct writing style, especially in information-dense domains, even though\nthey can produce human-like outputs with personalized prompts.\n","authors":["Kristian Kuznetsov","Laida Kushnareva","Polina Druzhinina","Anton Razzhigaev","Anastasia Voznyuk","Irina Piontkovskaya","Evgeny Burnaev","Serguei Barannikov"],"pdf_url":"https://arxiv.org/pdf/2503.03601v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.03594v1","updated":"2025-03-05T15:27:36Z","published":"2025-03-05T15:27:36Z","title":"Small but Mighty: Enhancing Time Series Forecasting with Lightweight\n  LLMs","summary":"  While LLMs have demonstrated remarkable potential in time series forecasting,\ntheir practical deployment remains constrained by excessive computational\ndemands and memory footprints. Existing LLM-based approaches typically suffer\nfrom three critical limitations: Inefficient parameter utilization in handling\nnumerical time series patterns; Modality misalignment between continuous\ntemporal signals and discrete text embeddings; and Inflexibility for real-time\nexpert knowledge integration. We present SMETimes, the first systematic\ninvestigation of sub-3B parameter SLMs for efficient and accurate time series\nforecasting. Our approach centers on three key innovations: A\nstatistically-enhanced prompting mechanism that bridges numerical time series\nwith textual semantics through descriptive statistical features; A adaptive\nfusion embedding architecture that aligns temporal patterns with language model\ntoken spaces through learnable parameters; And a dynamic mixture-of-experts\nframework enabled by SLMs' computational efficiency, adaptively combining base\npredictions with domain-specific models. Extensive evaluations across seven\nbenchmark datasets demonstrate that our 3B-parameter SLM achieves\nstate-of-the-art performance on five primary datasets while maintaining 3.8x\nfaster training and 5.2x lower memory consumption compared to 7B-parameter LLM\nbaselines. Notably, the proposed model exhibits better learning capabilities,\nachieving 12.3% lower MSE than conventional LLM. Ablation studies validate that\nour statistical prompting and cross-modal fusion modules respectively\ncontribute 15.7% and 18.2% error reduction in long-horizon forecasting tasks.\nBy redefining the efficiency-accuracy trade-off landscape, this work\nestablishes SLMs as viable alternatives to resource-intensive LLMs for\npractical time series forecasting. Code and models are available at\nhttps://github.com/xiyan1234567/SMETimes.\n","authors":["Haoran Fan","Bin Li","Yixuan Weng","Shoujun Zhou"],"pdf_url":"https://arxiv.org/pdf/2503.03594v1.pdf","comment":"Work in progress"},{"id":"http://arxiv.org/abs/2503.03592v1","updated":"2025-03-05T15:26:59Z","published":"2025-03-05T15:26:59Z","title":"English K_Quantization of LLMs Does Not Disproportionately Diminish\n  Multilingual Performance","summary":"  For consumer usage of locally deployed LLMs, the GGUF format and\nk_quantization are invaluable tools for maintaining the performance of the\noriginal model while reducing it to sizes deployable with consumer-grade\nhardware. The number of bits dedicated to each weight from the original model\nis reduced based on how important they are thought to be during model\ninference. This importance is arrived at through the application of an\n'importance matrix'-a relatively small text document meant to be representative\nof the LLM's standard use-cases. In the vast majority of quants available\nonline, this document is primarily written in English. It was therefore an open\nquestion whether performance on English language tasks was preserved through\nthe sacrifice of multilingual performance and whether it can be preserved with\nalternate importance matrices. This article investigates these hypotheses by\nquantizing Llama3.3 70B on importance matrices written in three languages\n(English, Norwegian, and Malayalam) and evaluating them on the MixEval dataset\nin both English and Norwegian. All experiments related to k_quantization\nyielded non-significant results (In all cases p > 0.237) indicating that\ncurrent quantization practices do not disproportionately harm multilingual\nperformance.\n","authors":["Karl Audun Borgersen"],"pdf_url":"https://arxiv.org/pdf/2503.03592v1.pdf","comment":"8 pages, 6 figures"},{"id":"http://arxiv.org/abs/2501.16207v3","updated":"2025-03-05T15:26:49Z","published":"2025-01-27T17:00:56Z","title":"From Informal to Formal -- Incorporating and Evaluating LLMs on Natural\n  Language Requirements to Verifiable Formal Proofs","summary":"  The research in AI-based formal mathematical reasoning has shown an\nunstoppable growth trend. These studies have excelled in mathematical\ncompetitions like IMO and have made significant progress. This paper focuses on\nformal verification, an immediate application scenario of formal reasoning, and\nbreaks it down into sub-tasks. We constructed 18k high-quality\ninstruction-response pairs across five formal specification languages (Coq,\nLean4, Dafny, ACSL, and TLA+) by distilling gpt-4o and evaluated against ten\nopen-sourced LLMs, including recent popular DeepSeek-R1. We also fine-tuned\nseveral 7~8B small models to achieve comparable performance with\nDeepseek-R1-671B. Interestingly, we observed that fine-tuning with formal data\nalso enhances mathematics, reasoning, and coding capabilities. Fine-tuned\nmodels are released at https: //huggingface.co/fm-universe.\n","authors":["Jialun Cao","Yaojie Lu","Meiziniu Li","Haoyang Ma","Haokun Li","Mengda He","Cheng Wen","Le Sun","Hongyu Zhang","Shengchao Qin","Shing-Chi Cheung","Cong Tian"],"pdf_url":"https://arxiv.org/pdf/2501.16207v3.pdf","comment":"19 pages"},{"id":"http://arxiv.org/abs/2502.20503v2","updated":"2025-03-05T15:26:45Z","published":"2025-02-27T20:22:34Z","title":"Protecting multimodal large language models against misleading\n  visualizations","summary":"  We assess the vulnerability of multimodal large language models to misleading\nvisualizations - charts that distort the underlying data using techniques such\nas truncated or inverted axes, leading readers to draw inaccurate conclusions\nthat may support misinformation or conspiracy theories. Our analysis shows that\nthese distortions severely harm multimodal large language models, reducing\ntheir question-answering accuracy to the level of the random baseline. To\nmitigate this vulnerability, we introduce six inference-time methods to improve\nperformance of MLLMs on misleading visualizations while preserving their\naccuracy on non-misleading ones. The most effective approach involves (1)\nextracting the underlying data table and (2) using a text-only large language\nmodel to answer questions based on the table. This method improves performance\non misleading visualizations by 15.4 to 19.6 percentage points.\n","authors":["Jonathan Tonglet","Tinne Tuytelaars","Marie-Francine Moens","Iryna Gurevych"],"pdf_url":"https://arxiv.org/pdf/2502.20503v2.pdf","comment":"Preprint. Code and data available at\n  https://github.com/UKPLab/arxiv2025-misleading-visualizations"},{"id":"http://arxiv.org/abs/2503.03588v1","updated":"2025-03-05T15:24:11Z","published":"2025-03-05T15:24:11Z","title":"PowerAttention: Exponentially Scaling of Receptive Fields for Effective\n  Sparse Attention","summary":"  Large Language Models (LLMs) face efficiency bottlenecks due to the quadratic\ncomplexity of the attention mechanism when processing long contexts. Sparse\nattention methods offer a promising solution, but existing approaches often\nsuffer from incomplete effective context and/or require complex implementation\nof pipeline. We present a comprehensive analysis of sparse attention for\nautoregressive LLMs from the respective of receptive field, recognize the\nsuboptimal nature of existing methods for expanding the receptive field, and\nintroduce PowerAttention, a novel sparse attention design that facilitates\neffective and complete context extension through the theoretical analysis.\nPowerAttention achieves exponential receptive field growth in $d$-layer LLMs,\nallowing each output token to attend to $2^d$ tokens, ensuring completeness and\ncontinuity of the receptive field. Experiments demonstrate that PowerAttention\noutperforms existing static sparse attention methods by $5\\sim 40\\%$,\nespecially on tasks demanding long-range dependencies like Passkey Retrieval\nand RULER, while maintaining a comparable time complexity to sliding window\nattention. Efficiency evaluations further highlight PowerAttention's superior\nspeedup in both prefilling and decoding phases compared with dynamic sparse\nattentions and full attention ($3.0\\times$ faster on 128K context), making it a\nhighly effective and user-friendly solution for processing long sequences in\nLLMs.\n","authors":["Lida Chen","Dong Xu","Chenxin An","Xintao Wang","Yikai Zhang","Jiangjie Chen","Zujie Liang","Feng Wei","Jiaqing Liang","Yanghua Xiao","Wei Wang"],"pdf_url":"https://arxiv.org/pdf/2503.03588v1.pdf","comment":"for associated code, see https://github.com/w568w/PowerAttention"},{"id":"http://arxiv.org/abs/2503.02623v2","updated":"2025-03-05T15:23:16Z","published":"2025-03-04T13:48:50Z","title":"Rewarding Doubt: A Reinforcement Learning Approach to Confidence\n  Calibration of Large Language Models","summary":"  A safe and trustworthy use of Large Language Models (LLMs) requires an\naccurate expression of confidence in their answers. We introduce a novel\nReinforcement Learning (RL) approach for LLM calibration that fine-tunes LLMs\nto elicit calibrated confidence estimations in their answers to factual\nquestions. We model the problem as a betting game where the model predicts a\nconfidence score together with every answer, and design a reward function that\npenalizes both over and under-confidence. We prove that under our reward design\nan optimal policy would result in a perfectly calibrated confidence estimation.\nOur experiments demonstrate significantly improved confidence calibration and\ngeneralization to new tasks without re-training, indicating that our approach\nteaches a general confidence awareness. This approach enables the training of\ninherently calibrated LLMs.\n","authors":["Paul Stangel","David Bani-Harouni","Chantal Pellegrini","Ege zsoy","Kamilia Zaripova","Matthias Keicher","Nassir Navab"],"pdf_url":"https://arxiv.org/pdf/2503.02623v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.03582v1","updated":"2025-03-05T15:17:18Z","published":"2025-03-05T15:17:18Z","title":"Scaling Crowdsourced Election Monitoring: Construction and Evaluation of\n  Classification Models for Multilingual and Cross-Domain Classification\n  Settings","summary":"  The adoption of crowdsourced election monitoring as a complementary\nalternative to traditional election monitoring is on the rise. Yet, its\nreliance on digital response volunteers to manually process incoming election\nreports poses a significant scaling bottleneck. In this paper, we address the\nchallenge of scaling crowdsourced election monitoring by advancing the task of\nautomated classification of crowdsourced election reports to multilingual and\ncross-domain classification settings. We propose a two-step classification\napproach of first identifying informative reports and then categorising them\ninto distinct information types. We conduct classification experiments using\nmultilingual transformer models such as XLM-RoBERTa and multilingual embeddings\nsuch as SBERT, augmented with linguistically motivated features. Our approach\nachieves F1-Scores of 77\\% for informativeness detection and 75\\% for\ninformation type classification. We conduct cross-domain experiments, applying\nmodels trained in a source electoral domain to a new target electoral domain in\nzero-shot and few-shot classification settings. Our results show promising\npotential for model transfer across electoral domains, with F1-Scores of 59\\%\nin zero-shot and 63\\% in few-shot settings. However, our analysis also reveals\na performance bias in detecting informative English reports over Swahili,\nlikely due to imbalances in the training data, indicating a need for caution\nwhen deploying classification models in real-world election scenarios.\n","authors":["Jabez Magomere","Scott Hale"],"pdf_url":"https://arxiv.org/pdf/2503.03582v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2407.16205v5","updated":"2025-03-05T14:43:33Z","published":"2024-07-23T06:14:41Z","title":"LLMs can be Dangerous Reasoners: Analyzing-based Jailbreak Attack on\n  Large Language Models","summary":"  The rapid development of Large Language Models (LLMs) has brought significant\nadvancements across various tasks. However, despite these achievements, LLMs\nstill exhibit inherent safety vulnerabilities, especially when confronted with\njailbreak attacks. Existing jailbreak methods suffer from two main limitations:\nreliance on complicated prompt engineering and iterative optimization, which\nlead to low attack success rate (ASR) and attack efficiency (AE). In this work,\nwe propose an efficient jailbreak attack method, Analyzing-based Jailbreak\n(ABJ), which leverages the advanced reasoning capability of LLMs to\nautonomously generate harmful content, revealing their underlying safety\nvulnerabilities during complex reasoning process. We conduct comprehensive\nexperiments on ABJ across various open-source and closed-source LLMs. In\nparticular, ABJ achieves high ASR (82.1% on GPT-4o-2024-11-20) with exceptional\nAE among all target LLMs, showcasing its remarkable attack effectiveness,\ntransferability, and efficiency. Our findings underscore the urgent need to\nprioritize and improve the safety of LLMs to mitigate the risks of misuse.\n","authors":["Shi Lin","Hongming Yang","Dingyang Lin","Rongchang Li","Xun Wang","Changting Lin","Wenpeng Xing","Meng Han"],"pdf_url":"https://arxiv.org/pdf/2407.16205v5.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.01742v2","updated":"2025-03-05T14:41:38Z","published":"2025-03-03T17:04:22Z","title":"Building Safe GenAI Applications: An End-to-End Overview of Red Teaming\n  for Large Language Models","summary":"  The rapid growth of Large Language Models (LLMs) presents significant\nprivacy, security, and ethical concerns. While much research has proposed\nmethods for defending LLM systems against misuse by malicious actors,\nresearchers have recently complemented these efforts with an offensive approach\nthat involves red teaming, i.e., proactively attacking LLMs with the purpose of\nidentifying their vulnerabilities. This paper provides a concise and practical\noverview of the LLM red teaming literature, structured so as to describe a\nmulti-component system end-to-end. To motivate red teaming we survey the\ninitial safety needs of some high-profile LLMs, and then dive into the\ndifferent components of a red teaming system as well as software packages for\nimplementing them. We cover various attack methods, strategies for\nattack-success evaluation, metrics for assessing experiment outcomes, as well\nas a host of other considerations. Our survey will be useful for any reader who\nwants to rapidly obtain a grasp of the major red teaming concepts for their own\nuse in practical applications.\n","authors":["Alberto Purpura","Sahil Wadhwa","Jesse Zymet","Akshay Gupta","Andy Luo","Melissa Kazemi Rad","Swapnil Shinde","Mohammad Shahed Sorower"],"pdf_url":"https://arxiv.org/pdf/2503.01742v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2502.11681v4","updated":"2025-03-05T14:38:19Z","published":"2025-02-17T11:16:19Z","title":"RIDE: Enhancing Large Language Model Alignment through Restyled\n  In-Context Learning Demonstration Exemplars","summary":"  Alignment tuning is crucial for ensuring large language models (LLMs) behave\nethically and helpfully. Current alignment approaches require high-quality\nannotations and significant training resources. This paper proposes a low-cost,\ntuning-free method using in-context learning (ICL) to enhance LLM alignment.\nThrough an analysis of high-quality ICL demos, we identified style as a key\nfactor influencing LLM alignment capabilities and explicitly restyled ICL\nexemplars based on this stylistic framework. Additionally, we combined the\nrestyled demos to achieve a balance between the two conflicting aspects of LLM\nalignment--factuality and safety. We packaged the restyled examples as prompts\nto trigger few-shot learning, improving LLM alignment. Compared to the best\nbaseline approach, with an average score of 5.00 as the maximum, our method\nachieves a maximum 0.10 increase on the Alpaca task (from 4.50 to 4.60), a 0.22\nenhancement on the Just-eval benchmark (from 4.34 to 4.56), and a maximum\nimprovement of 0.32 (from 3.53 to 3.85) on the MT-Bench dataset. We release the\ncode and data at https://github.com/AnonymousCode-ComputerScience/RIDE.\n","authors":["Yuncheng Hua","Lizhen Qu","Zhuang Li","Hao Xue","Flora D. Salim","Gholamreza Haffari"],"pdf_url":"https://arxiv.org/pdf/2502.11681v4.pdf","comment":"38 pages, 2 figures, 20 tables; The paper is under review in ARR"},{"id":"http://arxiv.org/abs/2409.19005v3","updated":"2025-03-05T14:04:24Z","published":"2024-09-21T09:19:29Z","title":"What is a Digital Twin Anyway? Deriving the Definition for the Built\n  Environment from over 15,000 Scientific Publications","summary":"  The concept of digital twins has attracted significant attention across\nvarious domains, particularly within the built environment. However, there is a\nsheer volume of definitions and the terminological consensus remains out of\nreach. The lack of a universally accepted definition leads to ambiguities in\ntheir conceptualization and implementation, and may cause miscommunication for\nboth researchers and practitioners. We employed Natural Language Processing\n(NLP) techniques to systematically extract and analyze definitions of digital\ntwins from a corpus of more than 15,000 full-text articles spanning diverse\ndisciplines. The study compares these findings with insights from an expert\nsurvey that included 52 experts. The study identifies concurrence on the\ncomponents that comprise a ``Digital Twin'' from a practical perspective across\nvarious domains, contrasting them with those that do not, to identify\ndeviations. We investigate the evolution of digital twin definitions over time\nand across different scales, including manufacturing, building, and\nurban/geospatial perspectives. We extracted the main components of Digital\nTwins using Text Frequency Analysis and N-gram analysis. Subsequently, we\nidentified components that appeared in the literature and conducted a\nChi-square test to assess the significance of each component in different\ndomains. Our analysis identified key components of digital twins and revealed\nsignificant variations in definitions based on application domains, such as\nmanufacturing, building, and urban contexts. The analysis of DT components\nreveal two major groups of DT types: High-Performance Real-Time (HPRT) DTs, and\nLong-Term Decision Support (LTDS) DTs. Contrary to common assumptions, we found\nthat components such as simulation, AI/ML, real-time capabilities, and\nbi-directional data flow are not yet fully mature in the digital twins of the\nbuilt environment.\n","authors":["Mahmoud Abdelrahman","Edgardo Macatulad","Binyu Lei","Matias Quintana","Clayton Miller","Filip Biljecki"],"pdf_url":"https://arxiv.org/pdf/2409.19005v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.05459v2","updated":"2025-03-05T13:57:56Z","published":"2024-10-07T19:45:09Z","title":"From Sparse Dependence to Sparse Attention: Unveiling How\n  Chain-of-Thought Enhances Transformer Sample Efficiency","summary":"  Chain-of-thought (CoT) significantly enhances the reasoning performance of\nlarge language models (LLM). While current theoretical studies often attribute\nthis improvement to increased expressiveness and computational capacity, we\nargue that expressiveness is not the primary limitation in the LLM regime, as\ncurrent large models will fail on simple tasks. Using a parity-learning setup,\nwe demonstrate that CoT can substantially improve sample efficiency even when\nthe representation power is sufficient. Specifically, with CoT, a transformer\ncan learn the function within polynomial samples, whereas without CoT, the\nrequired sample size is exponential. Additionally, we show that CoT simplifies\nthe learning process by introducing sparse sequential dependencies among input\ntokens, and leads to a sparse and interpretable attention. We validate our\ntheoretical analysis with both synthetic and real-world experiments, confirming\nthat sparsity in attention layers is a key factor of the improvement induced by\nCoT.\n","authors":["Kaiyue Wen","Huaqing Zhang","Hongzhou Lin","Jingzhao Zhang"],"pdf_url":"https://arxiv.org/pdf/2410.05459v2.pdf","comment":"43 pages,11 figures"},{"id":"http://arxiv.org/abs/2503.03512v1","updated":"2025-03-05T13:57:48Z","published":"2025-03-05T13:57:48Z","title":"An Aspect Extraction Framework using Different Embedding Types, Learning\n  Models, and Dependency Structure","summary":"  Aspect-based sentiment analysis has gained significant attention in recent\nyears due to its ability to provide fine-grained insights for sentiment\nexpressions related to specific features of entities. An important component of\naspect-based sentiment analysis is aspect extraction, which involves\nidentifying and extracting aspect terms from text. Effective aspect extraction\nserves as the foundation for accurate sentiment analysis at the aspect level.\nIn this paper, we propose aspect extraction models that use different types of\nembeddings for words and part-of-speech tags and that combine several learning\nmodels. We also propose tree positional encoding that is based on dependency\nparsing output to capture better the aspect positions in sentences. In\naddition, a new aspect extraction dataset is built for Turkish by machine\ntranslating an English dataset in a controlled setting. The experiments\nconducted on two Turkish datasets showed that the proposed models mostly\noutperform the studies that use the same datasets, and incorporating tree\npositional encoding increases the performance of the models.\n","authors":["Ali Erkan","Tunga Gngr"],"pdf_url":"https://arxiv.org/pdf/2503.03512v1.pdf","comment":"Aspect-based Sentiment Analysis, Aspect Extraction, Natural Language\n  Processing, Machine Learning, Deep Neural Networks, Turkish"},{"id":"http://arxiv.org/abs/2503.03502v1","updated":"2025-03-05T13:47:53Z","published":"2025-03-05T13:47:53Z","title":"CURVALID: Geometrically-guided Adversarial Prompt Detection","summary":"  Adversarial prompts capable of jailbreaking large language models (LLMs) and\ninducing undesirable behaviours pose a significant obstacle to their safe\ndeployment. Current mitigation strategies rely on activating built-in defence\nmechanisms or fine-tuning the LLMs, but the fundamental distinctions between\nadversarial and benign prompts are yet to be understood. In this work, we\nintroduce CurvaLID, a novel defense framework that efficiently detects\nadversarial prompts by leveraging their geometric properties. It is agnostic to\nthe type of LLM, offering a unified detection framework across diverse\nadversarial prompts and LLM architectures. CurvaLID builds on the geometric\nanalysis of text prompts to uncover their underlying differences. We\ntheoretically extend the concept of curvature via the Whewell equation into an\n$n$-dimensional word embedding space, enabling us to quantify local geometric\nproperties, including semantic shifts and curvature in the underlying\nmanifolds. Additionally, we employ Local Intrinsic Dimensionality (LID) to\ncapture geometric features of text prompts within adversarial subspaces. Our\nfindings reveal that adversarial prompts differ fundamentally from benign\nprompts in terms of their geometric characteristics. Our results demonstrate\nthat CurvaLID delivers superior detection and rejection of adversarial queries,\npaving the way for safer LLM deployment. The source code can be found at\nhttps://github.com/Cancanxxx/CurvaLID\n","authors":["Canaan Yung","Hanxun Huang","Sarah Monazam Erfani","Christopher Leckie"],"pdf_url":"https://arxiv.org/pdf/2503.03502v1.pdf","comment":"29 Pages, 5 figues"},{"id":"http://arxiv.org/abs/2503.03495v1","updated":"2025-03-05T13:34:49Z","published":"2025-03-05T13:34:49Z","title":"Deictic Codes, Demonstratives, and Reference: A Step Toward Solving the\n  Grounding Problem","summary":"  In this paper we address the issue of grounding for experiential concepts.\nGiven that perceptual demonstratives are a basic form of such concepts, we\nexamine ways of fixing the referents of such demonstratives. To avoid\n'encodingism', that is, relating representations to representations, we\npostulate that the process of reference fixing must be bottom-up and\nnonconceptual, so that it can break the circle of conceptual content and touch\nthe world. For that purpose, an appropriate causal relation between\nrepresentations and the world is needed. We claim that this relation is\nprovided by spatial and object-centered attention that leads to the formation\nof object files through the function of deictic acts. This entire causal\nprocess takes place at a pre-conceptual level, meeting the requirement for a\nsolution to the grounding problem. Finally we claim that our account captures\nfundamental insights in Putnam's and Kripke's work on \"new\" reference.\n","authors":["Athanassios Raftopoulos","Vincent C. Mller"],"pdf_url":"https://arxiv.org/pdf/2503.03495v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2502.20475v2","updated":"2025-03-05T13:22:47Z","published":"2025-02-27T19:23:15Z","title":"Promote, Suppress, Iterate: How Language Models Answer One-to-Many\n  Factual Queries","summary":"  To answer one-to-many factual queries (e.g., listing cities of a country), a\nlanguage model (LM) must simultaneously recall knowledge and avoid repeating\nprevious answers. How are these two subtasks implemented and integrated\ninternally? Across multiple datasets and models, we identify a\npromote-then-suppress mechanism: the model first recalls all answers, and then\nsuppresses previously generated ones. Specifically, LMs use both the subject\nand previous answer tokens to perform knowledge recall, with attention\npropagating subject information and MLPs promoting the answers. Then, attention\nattends to and suppresses previous answer tokens, while MLPs amplify the\nsuppression signal. Our mechanism is corroborated by extensive experimental\nevidence: in addition to using early decoding and causal tracing, we analyze\nhow components use different tokens by introducing both Token Lens, which\ndecodes aggregated attention updates from specified tokens, and a knockout\nmethod that analyzes changes in MLP outputs after removing attention to\nspecified tokens. Overall, we provide new insights into how LMs' internal\ncomponents interact with different input tokens to support complex factual\nrecall. Code is available at\nhttps://github.com/Lorenayannnnn/how-lms-answer-one-to-many-factual-queries.\n","authors":["Tianyi Lorena Yan","Robin Jia"],"pdf_url":"https://arxiv.org/pdf/2502.20475v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2501.02393v3","updated":"2025-03-05T13:19:16Z","published":"2025-01-04T22:30:21Z","title":"Graph-Aware Isomorphic Attention for Adaptive Dynamics in Transformers","summary":"  We present an approach to modifying Transformer architectures by integrating\ngraph-aware relational reasoning into the attention mechanism, merging concepts\nfrom graph neural networks and language modeling. Building on the inherent\nconnection between attention and graph theory, we reformulate the Transformer's\nattention mechanism as a graph operation and propose Graph-Aware Isomorphic\nAttention. This method leverages advanced graph modeling strategies, including\nGraph Isomorphism Networks (GIN) and Principal Neighborhood Aggregation (PNA),\nto enrich the representation of relational structures. Our approach captures\ncomplex dependencies and generalizes across tasks, as evidenced by a reduced\ngeneralization gap and improved learning performance. Additionally, we expand\nthe concept of graph-aware attention to introduce Sparse GIN-Attention, a\nfine-tuning approach that employs sparse GINs. By interpreting attention\nmatrices as sparse adjacency graphs, this technique enhances the adaptability\nof pre-trained foundational models with minimal computational overhead,\nendowing them with graph-aware capabilities. Sparse GIN-Attention fine-tuning\nachieves improved training dynamics and better generalization compared to\nalternative methods like low-rank adaption (LoRA). We discuss latent graph-like\nstructures within traditional attention mechanisms, offering a new lens through\nwhich Transformers can be understood. By evolving Transformers as hierarchical\nGIN models for relational reasoning. This perspective suggests profound\nimplications for foundational model development, enabling the design of\narchitectures that dynamically adapt to both local and global dependencies.\nApplications in bioinformatics, materials science, language modeling, and\nbeyond could benefit from this synthesis of relational and sequential data\nmodeling, setting the stage for interpretable and generalizable modeling\nstrategies.\n","authors":["Markus J. Buehler"],"pdf_url":"https://arxiv.org/pdf/2501.02393v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.01275v2","updated":"2025-03-05T13:10:07Z","published":"2025-03-03T07:59:32Z","title":"Enhancing Non-English Capabilities of English-Centric Large Language\n  Models through Deep Supervision Fine-Tuning","summary":"  Large language models (LLMs) have demonstrated significant progress in\nmultilingual language understanding and generation. However, due to the\nimbalance in training data, their capabilities in non-English languages are\nlimited. Recent studies revealed the English-pivot multilingual mechanism of\nLLMs, where LLMs implicitly convert non-English queries into English ones at\nthe bottom layers and adopt English for thinking at the middle layers. However,\ndue to the absence of explicit supervision for cross-lingual alignment in the\nintermediate layers of LLMs, the internal representations during these stages\nmay become inaccurate. In this work, we introduce a deep supervision\nfine-tuning method (DFT) that incorporates additional supervision in the\ninternal layers of the model to guide its workflow. Specifically, we introduce\ntwo training objectives on different layers of LLMs: one at the bottom layers\nto constrain the conversion of the target language into English, and another at\nthe middle layers to constrain reasoning in English. To effectively achieve the\nguiding purpose, we designed two types of supervision signals: logits and\nfeature, which represent a stricter constraint and a relatively more relaxed\nguidance. Our method guides the model to not only consider the final generated\nresult when processing non-English inputs but also ensure the accuracy of\ninternal representations. We conducted extensive experiments on typical\nEnglish-centric large models, LLaMA-2 and Gemma-2, and the results on multiple\nmultilingual datasets show that our method significantly outperforms\ntraditional fine-tuning methods.\n","authors":["Wenshuai Huo","Xiaocheng Feng","Yichong Huang","Chengpeng Fu","Baohang Li","Yangfan Ye","Zhirui Zhang","Dandan Tu","Duyu Tang","Yunfei Lu","Hui Wang","Bing Qin"],"pdf_url":"https://arxiv.org/pdf/2503.01275v2.pdf","comment":"Accepted at AAAI 2025"},{"id":"http://arxiv.org/abs/2503.03474v1","updated":"2025-03-05T13:10:07Z","published":"2025-03-05T13:10:07Z","title":"Enhancing Spoken Discourse Modeling in Language Models Using Gestural\n  Cues","summary":"  Research in linguistics shows that non-verbal cues, such as gestures, play a\ncrucial role in spoken discourse. For example, speakers perform hand gestures\nto indicate topic shifts, helping listeners identify transitions in discourse.\nIn this work, we investigate whether the joint modeling of gestures using human\nmotion sequences and language can improve spoken discourse modeling in language\nmodels. To integrate gestures into language models, we first encode 3D human\nmotion sequences into discrete gesture tokens using a VQ-VAE. These gesture\ntoken embeddings are then aligned with text embeddings through feature\nalignment, mapping them into the text embedding space. To evaluate the\ngesture-aligned language model on spoken discourse, we construct text infilling\ntasks targeting three key discourse cues grounded in linguistic research:\ndiscourse connectives, stance markers, and quantifiers. Results show that\nincorporating gestures enhances marker prediction accuracy across the three\ntasks, highlighting the complementary information that gestures can offer in\nmodeling spoken discourse. We view this work as an initial step toward\nleveraging non-verbal cues to advance spoken language modeling in language\nmodels.\n","authors":["Varsha Suresh","M. Hamza Mughal","Christian Theobalt","Vera Demberg"],"pdf_url":"https://arxiv.org/pdf/2503.03474v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.03462v1","updated":"2025-03-05T12:52:14Z","published":"2025-03-05T12:52:14Z","title":"Open-Source Large Language Models as Multilingual Crowdworkers:\n  Synthesizing Open-Domain Dialogues in Several Languages With No Examples in\n  Targets and No Machine Translation","summary":"  The prevailing paradigm in the domain of Open-Domain Dialogue agents\npredominantly focuses on the English language, encompassing both models and\ndatasets. Furthermore, the financial and temporal investments required for\ncrowdsourcing such datasets for finetuning are substantial, particularly when\nmultiple languages are involved. Fortunately, advancements in Large Language\nModels (LLMs) have unveiled a plethora of possibilities across diverse tasks.\nSpecifically, instruction-tuning has enabled LLMs to execute tasks based on\nnatural language instructions, occasionally surpassing the performance of human\ncrowdworkers. Additionally, these models possess the capability to function in\nvarious languages within a single thread. Consequently, to generate new samples\nin different languages, we propose leveraging these capabilities to replicate\nthe data collection process. We introduce a pipeline for generating Open-Domain\nDialogue data in multiple Target Languages using LLMs, with demonstrations\nprovided in a unique Source Language. By eschewing explicit Machine Translation\nin this approach, we enhance the adherence to language-specific nuances. We\napply this methodology to the PersonaChat dataset. To enhance the openness of\ngenerated dialogues and mimic real life scenarii, we added the notion of speech\nevents corresponding to the type of conversation the speakers are involved in\nand also that of common ground which represents the premises of a conversation.\n","authors":["Ahmed Njifenjou","Virgile Sucal","Bassam Jabaian","Fabrice Lefvre"],"pdf_url":"https://arxiv.org/pdf/2503.03462v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.03460v1","updated":"2025-03-05T12:49:48Z","published":"2025-03-05T12:49:48Z","title":"Visualising Policy-Reward Interplay to Inform Zeroth-Order Preference\n  Optimisation of Large Language Models","summary":"  Fine-tuning LLMs with first-order methods like back-propagation is\ncomputationally intensive. Zeroth-Order (ZO) optimisation, using function\nevaluations instead of gradients, reduces memory usage but suffers from slow\nconvergence in high-dimensional models. As a result, ZO research in LLMs has\nmostly focused on classification, overlooking more complex generative tasks. In\nthis paper, we introduce ZOPrO, a novel ZO algorithm designed for\n\\textit{Preference Optimisation} in LLMs. We begin by analysing the interplay\nbetween policy and reward models during traditional (first-order) Preference\nOptimisation, uncovering patterns in their relative updates. Guided by these\ninsights, we adapt Simultaneous Perturbation Stochastic Approximation (SPSA)\nwith a targeted sampling strategy to accelerate convergence. Through\nexperiments on summarisation, machine translation, and conversational\nassistants, we demonstrate that our method consistently enhances reward signals\nwhile achieving convergence times comparable to first-order methods. While it\nfalls short of some state-of-the-art methods, our work is the first to apply\nZeroth-Order methods to Preference Optimisation in LLMs, going beyond\nclassification tasks and paving the way for a largely unexplored research\ndirection. Code and visualisations are available at\nhttps://github.com/alessioGalatolo/VisZOPrO\n","authors":["Alessio Galatolo","Zhenbang Dai","Katie Winkle","Meriem Beloucif"],"pdf_url":"https://arxiv.org/pdf/2503.03460v1.pdf","comment":"WIP"},{"id":"http://arxiv.org/abs/2503.03459v1","updated":"2025-03-05T12:49:44Z","published":"2025-03-05T12:49:44Z","title":"Unified Mind Model: Reimagining Autonomous Agents in the LLM Era","summary":"  Large language models (LLMs) have recently demonstrated remarkable\ncapabilities across domains, tasks, and languages (e.g., ChatGPT and GPT-4),\nreviving the research of general autonomous agents with human-like cognitive\nabilities.Such human-level agents require semantic comprehension and\ninstruction-following capabilities, which exactly fall into the strengths of\nLLMs.Although there have been several initial attempts to build human-level\nagents based on LLMs, the theoretical foundation remains a challenging open\nproblem. In this paper, we propose a novel theoretical cognitive architecture,\nthe Unified Mind Model (UMM), which offers guidance to facilitate the rapid\ncreation of autonomous agents with human-level cognitive abilities.\nSpecifically, our UMM starts with the global workspace theory and further\nleverage LLMs to enable the agent with various cognitive abilities, such as\nmulti-modal perception, planning, reasoning, tool use, learning, memory,\nreflection and motivation. Building upon UMM, we then develop an agent-building\nengine, MindOS, which allows users to quickly create domain-/task-specific\nautonomous agents without any programming effort.\n","authors":["Pengbo Hu","Xiang Ying"],"pdf_url":"https://arxiv.org/pdf/2503.03459v1.pdf","comment":"18 pages"},{"id":"http://arxiv.org/abs/2503.03444v1","updated":"2025-03-05T12:24:20Z","published":"2025-03-05T12:24:20Z","title":"Taxation Perspectives from Large Language Models: A Case Study on\n  Additional Tax Penalties","summary":"  How capable are large language models (LLMs) in the domain of taxation?\nAlthough numerous studies have explored the legal domain in general, research\ndedicated to taxation remain scarce. Moreover, the datasets used in these\nstudies are either simplified, failing to reflect the real-world complexities,\nor unavailable as open source. To address this gap, we introduce PLAT, a new\nbenchmark designed to assess the ability of LLMs to predict the legitimacy of\nadditional tax penalties. PLAT is constructed to evaluate LLMs' understanding\nof tax law, particularly in cases where resolving the issue requires more than\njust applying related statutes. Our experiments with six LLMs reveal that their\nbaseline capabilities are limited, especially when dealing with conflicting\nissues that demand a comprehensive understanding. However, we found that\nenabling retrieval, self-reasoning, and discussion among multiple agents with\nspecific role assignments, this limitation can be mitigated.\n","authors":["Eunkyung Choi","Young Jin Suh","Hun Park","Wonseok Hwang"],"pdf_url":"https://arxiv.org/pdf/2503.03444v1.pdf","comment":"5 pages"},{"id":"http://arxiv.org/abs/2503.03434v1","updated":"2025-03-05T12:10:14Z","published":"2025-03-05T12:10:14Z","title":"RASD: Retrieval-Augmented Speculative Decoding","summary":"  Speculative decoding accelerates inference in large language models (LLMs) by\ngenerating draft tokens for target model verification. Current approaches for\nobtaining draft tokens rely on lightweight draft models or additional model\nstructures to generate draft tokens and retrieve context from databases. Due to\nthe draft model's small size and limited training data, model-based speculative\ndecoding frequently becomes less effective in out-of-domain scenarios.\nAdditionally, the time cost of the drafting phase results in a low upper limit\non acceptance length during the verification step, limiting overall efficiency.\nThis paper proposes RASD (Retrieval-Augmented Speculative Decoding), which\nadopts retrieval methods to enhance model-based speculative decoding. We\nintroduce tree pruning and tree fusion to achieve this. Specifically, we\ndevelop a pruning method based on the draft model's probability distribution to\nconstruct the optimal retrieval tree. Second, we employ the longest prefix\nmatching algorithm to merge the tree generated by the draft model with the\nretrieval tree, resulting in a unified tree for verification. Experimental\nresults demonstrate that RASD achieves state-of-the-art inference acceleration\nacross tasks such as DocQA, Summary, Code, and In-Domain QA. Moreover, RASD\nexhibits strong scalability, seamlessly integrating with various speculative\ndecoding approaches, including both generation-based and retrieval-based\nmethods.\n","authors":["Guofeng Quan","Wenfeng Feng","Chuzhan Hao","Guochao Jiang","Yuewei Zhang","Hao Wang"],"pdf_url":"https://arxiv.org/pdf/2503.03434v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2412.18377v3","updated":"2025-03-05T11:49:36Z","published":"2024-12-24T12:03:36Z","title":"ChaI-TeA: A Benchmark for Evaluating Autocompletion of Interactions with\n  LLM-based Chatbots","summary":"  The rise of LLMs has deflected a growing portion of human-computer\ninteractions towards LLM-based chatbots. The remarkable abilities of these\nmodels allow users to interact using long, diverse natural language text\ncovering a wide range of topics and styles. Phrasing these messages is a time\nand effort consuming task, calling for an autocomplete solution to assist\nusers. We introduce the task of chatbot interaction autocomplete. We present\nChaI-TeA: CHat InTEraction Autocomplete; An autcomplete evaluation framework\nfor LLM-based chatbot interactions. The framework includes a formal definition\nof the task, coupled with suitable datasets and metrics. We use the framework\nto evaluate After formally defining the task along with suitable datasets and\nmetrics, we test 9 models on the defined auto completion task, finding that\nwhile current off-the-shelf models perform fairly, there is still much room for\nimprovement, mainly in ranking of the generated suggestions. We provide\ninsights for practitioners working on this task and open new research\ndirections for researchers in the field. We release our framework to serve as a\nfoundation for future research.\n","authors":["Shani Goren","Oren Kalinsky","Tomer Stav","Yuri Rapoport","Yaron Fairstein","Ram Yazdi","Nachshon Cohen","Alexander Libov","Guy Kushilevitz"],"pdf_url":"https://arxiv.org/pdf/2412.18377v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.03417v1","updated":"2025-03-05T11:47:32Z","published":"2025-03-05T11:47:32Z","title":"When Claims Evolve: Evaluating and Enhancing the Robustness of Embedding\n  Models Against Misinformation Edits","summary":"  Online misinformation remains a critical challenge, and fact-checkers\nincreasingly rely on embedding-based methods to retrieve relevant fact-checks.\nYet, when debunked claims reappear in edited forms, the performance of these\nmethods is unclear. In this work, we introduce a taxonomy of six common\nreal-world misinformation edits and propose a perturbation framework that\ngenerates valid, natural claim variations. Our multi-stage retrieval evaluation\nreveals that standard embedding models struggle with user-introduced edits,\nwhile LLM-distilled embeddings offer improved robustness at a higher\ncomputational cost. Although a strong reranker helps mitigate some issues, it\ncannot fully compensate for first-stage retrieval gaps. Addressing these\nretrieval gaps, our train- and inference-time mitigation approaches enhance\nin-domain robustness by up to 17 percentage points and boost out-of-domain\ngeneralization by 10 percentage points over baseline models. Overall, our\nfindings provide practical improvements to claim-matching systems, enabling\nmore reliable fact-checking of evolving misinformation.\n","authors":["Jabez Magomere","Emanuele La Malfa","Manuel Tonneau","Ashkan Kazemi","Scott Hale"],"pdf_url":"https://arxiv.org/pdf/2503.03417v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2408.14153v2","updated":"2025-03-05T11:15:39Z","published":"2024-08-26T09:55:34Z","title":"Explaining Vision-Language Similarities in Dual Encoders with\n  Feature-Pair Attributions","summary":"  Dual encoder architectures like CLIP models map two types of inputs into a\nshared embedding space and predict similarities between them. Despite their\nsuccess, it is, however, not understood how these models compare their two\ninputs. Common first-order feature-attribution methods can only provide limited\ninsights into dual-encoders since their predictions depend on\nfeature-interactions rather than on individual features. In this paper, we\nfirst derive a second-order method enabling the attribution of predictions by\nany differentiable dual encoder onto feature-interactions between its inputs.\nSecond, we apply our method to CLIP models and show that they learn\nfine-grained correspondences between parts of captions and regions in images.\nThey match objects across input modes also account for mismatches. This\nvisual-linguistic grounding ability, however, varies heavily between object\nclasses and exhibits pronounced out-of-domain effects. We can identify\nindividual errors as well as systematic failure categories including object\ncoverage, unusual scenes and correlated contexts.\n","authors":["Lucas Mller","Pascal Tilli","Ngoc Thang Vu","Sebastian Pad"],"pdf_url":"https://arxiv.org/pdf/2408.14153v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.03380v1","updated":"2025-03-05T10:55:47Z","published":"2025-03-05T10:55:47Z","title":"The Serendipity of Claude AI: Case of the 13 Low-Resource National\n  Languages of Mali","summary":"  Recent advances in artificial intelligence (AI) and natural language\nprocessing (NLP) have improved the representation of underrepresented\nlanguages. However, most languages, including Mali's 13 official national\nlanguages, continue to be poorly supported or unsupported by automatic\ntranslation and generative AI. This situation appears to have slightly improved\nwith certain recent LLM releases. The study evaluated Claude AI's translation\nperformance on each of the 13 national languages of Mali. In addition to ChrF2\nand BLEU scores, human evaluators assessed translation accuracy, contextual\nconsistency, robustness to dialect variations, management of linguistic bias,\nadaptation to a limited corpus, and ease of understanding. The study found that\nClaude AI performs robustly for languages with very modest language resources\nand, while unable to produce understandable and coherent texts for Malian\nlanguages with minimal resources, still manages to produce results which\ndemonstrate the ability to mimic some elements of the language.\n","authors":["Alou Dembele","Nouhoum Souleymane Coulibaly","Michael Leventhal"],"pdf_url":"https://arxiv.org/pdf/2503.03380v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.03360v1","updated":"2025-03-05T10:40:09Z","published":"2025-03-05T10:40:09Z","title":"Transformers for molecular property prediction: Domain adaptation\n  efficiently improves performance","summary":"  Most of the current transformer-based chemical language models are\npre-trained on millions to billions of molecules. However, the improvement from\nsuch scaling in dataset size is not confidently linked to improved molecular\nproperty prediction. The aim of this study is to investigate and overcome some\nof the limitations of transformer models in predicting molecular properties.\nSpecifically, we examine the impact of pre-training dataset size and diversity\non the performance of transformer models and investigate the use of domain\nadaptation as a technique for improving model performance. First, our findings\nindicate that increasing pretraining dataset size beyond 400K molecules from\nthe GuacaMol dataset does not result in a significant improvement on four ADME\nendpoints, namely, solubility, permeability, microsomal stability, and plasma\nprotein binding. Second, our results demonstrate that using domain adaptation\nby further training the transformer model on a small set of domain-relevant\nmolecules, i.e., a few hundred to a few thousand, using multi-task regression\nof physicochemical properties was sufficient to significantly improve\nperformance for three out of the four investigated ADME endpoints (P-value <\n0.001). Finally, we observe that a model pre-trained on 400K molecules and\ndomain adopted on a few hundred/thousand molecules performs similarly (P-value\n> 0.05) to more complicated transformer models like MolBERT(pre-trained on 1.3M\nmolecules) and MolFormer (pre-trained on 100M molecules). A comparison to a\nrandom forest model trained on basic physicochemical properties showed similar\nperformance to the examined transformer models. We believe that current\ntransformer models can be improved through further systematic analysis of\npre-training and downstream data, pre-training objectives, and scaling laws,\nultimately leading to better and more helpful models.\n","authors":["Afnan Sultan","Max Rausch-Dupont","Shahrukh Khan","Olga Kalinina","Andrea Volkamer","Dietrich Klakow"],"pdf_url":"https://arxiv.org/pdf/2503.03360v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.03340v1","updated":"2025-03-05T10:13:05Z","published":"2025-03-05T10:13:05Z","title":"EnigmaToM: Improve LLMs' Theory-of-Mind Reasoning Capabilities with\n  Neural Knowledge Base of Entity States","summary":"  Theory-of-Mind (ToM), the ability to infer others' perceptions and mental\nstates, is fundamental to human interaction but remains a challenging task for\nLarge Language Models (LLMs). While existing ToM reasoning methods show promise\nwith reasoning via perceptual perspective-taking, they often rely excessively\non LLMs, reducing their efficiency and limiting their applicability to\nhigh-order ToM reasoning, which requires multi-hop reasoning about characters'\nbeliefs. To address these issues, we present EnigmaToM, a novel neuro-symbolic\nframework that enhances ToM reasoning by integrating a Neural Knowledge Base of\nentity states (Enigma) for (1) a psychology-inspired iterative masking\nmechanism that facilitates accurate perspective-taking and (2) knowledge\ninjection that elicits key entity information. Enigma generates structured\nrepresentations of entity states, which construct spatial scene graphs --\nleveraging spatial information as an inductive bias -- for belief tracking of\nvarious ToM orders and enhancing events with fine-grained entity state details.\nExperimental results on multiple benchmarks, including ToMi, HiToM, and FANToM,\nshow that EnigmaToM significantly improves ToM reasoning across LLMs of varying\nsizes, particularly excelling in high-order reasoning scenarios.\n","authors":["Hainiu Xu","Siya Qi","Jiazheng Li","Yuxiang Zhou","Jinhua Du","Caroline Catmur","Yulan He"],"pdf_url":"https://arxiv.org/pdf/2503.03340v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.03335v1","updated":"2025-03-05T10:09:53Z","published":"2025-03-05T10:09:53Z","title":"iNews: A Multimodal Dataset for Modeling Personalized Affective\n  Responses to News","summary":"  Current approaches to emotion detection often overlook the inherent\nsubjectivity of affective experiences, instead relying on aggregated labels\nthat mask individual variations in emotional responses. We introduce iNews, a\nnovel large-scale dataset explicitly capturing subjective affective responses\nto news headlines. Our dataset comprises annotations from 291 demographically\ndiverse UK participants across 2,899 multimodal Facebook news posts from major\nUK outlets, with an average of 5.18 annotators per sample. For each post,\nannotators provide multifaceted labels including valence, arousal, dominance,\ndiscrete emotions, content relevance judgments, sharing likelihood, and\nmodality importance ratings (text, image, or both). Furthermore, we collect\ncomprehensive annotator persona information covering demographics, personality,\nmedia trust, and consumption patterns, which explain 15.2% of annotation\nvariance - higher than existing NLP datasets. Incorporating this information\nyields a 7% accuracy gain in zero-shot prediction and remains beneficial even\nwith 32-shot. iNews will enhance research in LLM personalization, subjectivity,\naffective computing, and individual-level behavior simulation.\n","authors":["Tiancheng Hu","Nigel Collier"],"pdf_url":"https://arxiv.org/pdf/2503.03335v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.03766v3","updated":"2025-03-05T09:52:30Z","published":"2024-11-06T08:59:44Z","title":"Number Cookbook: Number Understanding of Language Models and How to\n  Improve It","summary":"  Large language models (LLMs) can solve an increasing number of complex\nreasoning tasks while making surprising mistakes in basic numerical\nunderstanding and processing (such as 9.11 > 9.9). The latter ability is\nessential for tackling complex arithmetic and mathematical problems and serves\nas a foundation for most reasoning tasks, but previous work paid little\nattention to it or only discussed several restricted tasks (like integer\naddition). In this paper, we comprehensively investigate the numerical\nunderstanding and processing ability (NUPA) of LLMs. Firstly, we introduce a\nbenchmark covering four common numerical representations and 17 distinct\nnumerical tasks in four major categories, resulting in 41 meaningful\ncombinations in total. These tasks are derived from primary and secondary\neducation curricula, encompassing nearly all everyday numerical understanding\nand processing scenarios, and the rules of these tasks are very simple and\nclear. Through the benchmark, we find that current LLMs fail frequently in many\nof the tasks. To study the problem, we train small models with existing and\npotential techniques for enhancing NUPA (such as tokenizers, PEs, and number\nformats), comprehensively evaluating their effectiveness using our testbed. We\nalso finetune practical-scale LLMs on our proposed NUPA tasks and find that 1)\nnaive finetuning can improve NUPA a lot on many but not all tasks, and 2)\nsurprisingly, techniques designed to enhance NUPA prove ineffective for\nfinetuning pretrained models. We further explore the impact of chain-of-thought\ntechniques on NUPA. Our work provides a more detailed and comprehensive\nunderstanding of NUPA in LLMs. Our benchmark and code are released at\nhttps://github.com/GraphPKU/number_cookbook.\n","authors":["Haotong Yang","Yi Hu","Shijia Kang","Zhouchen Lin","Muhan Zhang"],"pdf_url":"https://arxiv.org/pdf/2411.03766v3.pdf","comment":"ICLR 2025 poster"},{"id":"http://arxiv.org/abs/2502.07780v3","updated":"2025-03-05T09:50:16Z","published":"2025-02-11T18:59:35Z","title":"DarwinLM: Evolutionary Structured Pruning of Large Language Models","summary":"  Large Language Models (LLMs) have achieved significant success across various\nNLP tasks. However, their massive computational costs limit their widespread\nuse, particularly in real-time applications. Structured pruning offers an\neffective solution by compressing models and directly providing end-to-end\nspeed improvements, regardless of the hardware environment. Meanwhile,\ndifferent components of the model exhibit varying sensitivities towards\npruning, calling for non-uniform model compression. However, a pruning method\nshould not only identify a capable substructure, but also account for\npost-compression training. To this end, we propose DarwinLM, a method for\ntraining-aware structured pruning. DarwinLM builds upon an evolutionary search\nprocess, generating multiple offspring models in each generation through\nmutation, and selecting the fittest for survival. To assess the effect of\npost-training, we incorporate a lightweight, multistep training process within\nthe offspring population, progressively increasing the number of tokens and\neliminating poorly performing models in each selection stage. We validate our\nmethod through extensive experiments on Llama-2-7B, Llama-3.1-8B and\nQwen-2.5-14B-Instruct, achieving state-of-the-art performance for structured\npruning. For instance, DarwinLM surpasses ShearedLlama while requiring 5x less\ntraining data during post-compression training. Code is at:\nhttps://github.com/IST-DASLab/DarwinLM\n","authors":["Shengkun Tang","Oliver Sieberling","Eldar Kurtic","Zhiqiang Shen","Dan Alistarh"],"pdf_url":"https://arxiv.org/pdf/2502.07780v3.pdf","comment":"Code: https://github.com/IST-DASLab/DarwinLM"},{"id":"http://arxiv.org/abs/2503.03313v1","updated":"2025-03-05T09:45:22Z","published":"2025-03-05T09:45:22Z","title":"LLM as GNN: Graph Vocabulary Learning for Text-Attributed Graph\n  Foundation Models","summary":"  Text-Attributed Graphs (TAGs), where each node is associated with text\ndescriptions, are ubiquitous in real-world scenarios. They typically exhibit\ndistinctive structure and domain-specific knowledge, motivating the development\nof a Graph Foundation Model (GFM) that generalizes across diverse graphs and\ntasks. Despite large efforts to integrate Large Language Models (LLMs) and\nGraph Neural Networks (GNNs) for TAGs, existing approaches suffer from\ndecoupled architectures with two-stage alignment, limiting their synergistic\npotential. Even worse, existing methods assign out-of-vocabulary (OOV) tokens\nto graph nodes, leading to graph-specific semantics, token explosion, and\nincompatibility with task-oriented prompt templates, which hinders cross-graph\nand cross-task transferability. To address these challenges, we propose\nPromptGFM, a versatile GFM for TAGs grounded in graph vocabulary learning.\nPromptGFM comprises two key components: (1) Graph Understanding Module, which\nexplicitly prompts LLMs to replicate the finest GNN workflow within the text\nspace, facilitating seamless GNN-LLM integration and elegant graph-text\nalignment; (2) Graph Inference Module, which establishes a language-based graph\nvocabulary ensuring expressiveness, transferability, and scalability, enabling\nreadable instructions for LLM fine-tuning. Extensive experiments demonstrate\nour superiority and transferability across diverse graphs and tasks. The code\nis available at this: https://github.com/agiresearch/PromptGFM.\n","authors":["Xi Zhu","Haochen Xue","Ziwei Zhao","Wujiang Xu","Jingyuan Huang","Minghao Guo","Qifan Wang","Kaixiong Zhou","Yongfeng Zhang"],"pdf_url":"https://arxiv.org/pdf/2503.03313v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.03308v1","updated":"2025-03-05T09:41:03Z","published":"2025-03-05T09:41:03Z","title":"The Box is in the Pen: Evaluating Commonsense Reasoning in Neural\n  Machine Translation","summary":"  Does neural machine translation yield translations that are congenial with\ncommon sense? In this paper, we present a test suite to evaluate the\ncommonsense reasoning capability of neural machine translation. The test suite\nconsists of three test sets, covering lexical and contextless/contextual\nsyntactic ambiguity that requires commonsense knowledge to resolve. We manually\ncreate 1,200 triples, each of which contain a source sentence and two\ncontrastive translations, involving 7 different common sense types. Language\nmodels pretrained on large-scale corpora, such as BERT, GPT-2, achieve a\ncommonsense reasoning accuracy of lower than 72% on target translations of this\ntest suite. We conduct extensive experiments on the test suite to evaluate\ncommonsense reasoning in neural machine translation and investigate factors\nthat have impact on this capability. Our experiments and analyses demonstrate\nthat neural machine translation performs poorly on commonsense reasoning of the\nthree ambiguity types in terms of both reasoning accuracy (60.1%) and reasoning\nconsistency (31%). The built commonsense test suite is available at\nhttps://github.com/tjunlp-lab/CommonMT.\n","authors":["Jie He","Tao Wang","Deyi Xiong","Qun Liu"],"pdf_url":"https://arxiv.org/pdf/2503.03308v1.pdf","comment":"EMNLP findings 2020"},{"id":"http://arxiv.org/abs/2503.03303v1","updated":"2025-03-05T09:37:05Z","published":"2025-03-05T09:37:05Z","title":"SEOE: A Scalable and Reliable Semantic Evaluation Framework for Open\n  Domain Event Detection","summary":"  Automatic evaluation for Open Domain Event Detection (ODED) is a highly\nchallenging task, because ODED is characterized by a vast diversity of\nun-constrained output labels from various domains. Nearly all existing\nevaluation methods for ODED usually first construct evaluation benchmarks with\nlimited labels and domain coverage, and then evaluate ODED methods using\nmetrics based on token-level label matching rules. However, this kind of\nevaluation framework faces two issues: (1) The limited evaluation benchmarks\nlack representatives of the real world, making it difficult to accurately\nreflect the performance of various ODED methods in real-world scenarios; (2)\nEvaluation metrics based on token-level matching rules fail to capture semantic\nsimilarity between predictions and golden labels. To address these two problems\nabove, we propose a scalable and reliable Semantic-level Evaluation framework\nfor Open domain Event detection (SEOE) by constructing a more representative\nevaluation benchmark and introducing a semantic evaluation metric.\nSpecifically, our proposed framework first constructs a scalable evaluation\nbenchmark that currently includes 564 event types covering 7 major domains,\nwith a cost-effective supplementary annotation strategy to ensure the\nbenchmark's representativeness. The strategy also allows for the supplement of\nnew event types and domains in the future. Then, the proposed SEOE leverages\nlarge language models (LLMs) as automatic evaluation agents to compute a\nsemantic F1-score, incorporating fine-grained definitions of semantically\nsimilar labels to enhance the reliability of the evaluation. Extensive\nexperiments validate the representatives of the benchmark and the reliability\nof the semantic evaluation metric. Existing ODED methods are thoroughly\nevaluated, and the error patterns of predictions are analyzed, revealing\nseveral insightful findings.\n","authors":["Yi-Fan Lu","Xian-Ling Mao","Tian Lan","Tong Zhang","Yu-Shi Zhu","Heyan Huang"],"pdf_url":"https://arxiv.org/pdf/2503.03303v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2502.11123v2","updated":"2025-03-05T09:36:34Z","published":"2025-02-16T13:42:48Z","title":"DuplexMamba: Enhancing Real-time Speech Conversations with Duplex and\n  Streaming Capabilities","summary":"  Real-time speech conversation is essential for natural and efficient\nhuman-machine interactions, requiring duplex and streaming capabilities.\nTraditional Transformer-based conversational chatbots operate in a turn-based\nmanner and exhibit quadratic computational complexity that grows as the input\nsize increases. In this paper, we propose DuplexMamba, a Mamba-based end-to-end\nmultimodal duplex model for speech-to-text conversation. DuplexMamba enables\nsimultaneous input processing and output generation, dynamically adjusting to\nsupport real-time streaming. Specifically, we develop a Mamba-based speech\nencoder and adapt it with a Mamba-based language model. Furthermore, we\nintroduce a novel duplex decoding strategy that enables DuplexMamba to process\ninput and generate output simultaneously. Experimental results demonstrate that\nDuplexMamba successfully implements duplex and streaming capabilities while\nachieving performance comparable to several recently developed\nTransformer-based models in automatic speech recognition (ASR) tasks and voice\nassistant benchmark evaluations. Our code and model are released\n","authors":["Xiangyu Lu","Wang Xu","Haoyu Wang","Hongyun Zhou","Haiyan Zhao","Conghui Zhu","Tiejun Zhao","Muyun Yang"],"pdf_url":"https://arxiv.org/pdf/2502.11123v2.pdf","comment":"12 pages, 6 figures"},{"id":"http://arxiv.org/abs/2406.12221v5","updated":"2025-03-05T09:34:06Z","published":"2024-06-18T02:43:49Z","title":"On-Policy Self-Alignment with Fine-grained Knowledge Feedback for\n  Hallucination Mitigation","summary":"  Hallucination occurs when large language models exhibit behavior that\ndeviates from the boundaries of their knowledge during response generation. To\naddress this critical issue, previous learning-based methods attempt to\nfinetune models but are limited by off-policy sampling and coarse-grained\nfeedback. In this paper, we present \\textit{\\b{R}einforcement \\b{L}earning\n\\b{f}or \\b{H}allucination} (RLFH), an on-policy self-alignment approach that\nenables LLMs to actively explore their knowledge boundaries and self-correct\ngeneration behavior through fine-grained feedback signals. RLFH introduces a\nself-assessment framework where the policy serves as its own judge. Through\nthis framework, responses are automatically decomposed into atomic facts and\ntheir truthfulness and informativeness are assessed against external knowledge\nsources. The resulting fine-grained feedback at the statement level are then\nconverted into token-level dense reward signals. This enables online\nreinforcement learning to achieve precise and timely optimization without human\nintervention. Comprehensive evaluations on HotpotQA, SQuADv2, and Biography\nbenchmarks validate RLFH's effectiveness in hallucination mitigation.\n","authors":["Xueru Wen","Jie Lou","Xinyu Lu","Ji Yuqiu","Xinyan Guan","Yaojie Lu","Hongyu Lin","Ben He","Xianpei Han","Debing Zhang","Le Sun"],"pdf_url":"https://arxiv.org/pdf/2406.12221v5.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.03300v1","updated":"2025-03-05T09:31:49Z","published":"2025-03-05T09:31:49Z","title":"Which books do I like?","summary":"  Finding enjoyable fiction books can be challenging, partly because stories\nare multi-faceted and one's own literary taste might be difficult to ascertain.\nHere, we introduce the ISAAC method (Introspection-Support, AI-Annotation, and\nCuration), a pipeline which supports fiction readers in gaining awareness of\ntheir literary preferences and finding enjoyable books. ISAAC consists of four\nsteps: a user supplies book ratings, an AI agent researches and annotates the\nprovided books, patterns in book enjoyment are reviewed by the user, and the AI\nagent recommends new books. In this proof-of-concept self-study, the authors\ntest whether ISAAC can highlight idiosyncratic patterns in their book\nenjoyment, spark a deeper reflection about their literary tastes, and make\naccurate, personalized recommendations of enjoyable books and underexplored\nliterary niches. Results highlight substantial advantages of ISAAC over\nexisting methods such as an integration of automation and intuition, accurate\nand customizable annotations, and explainable book recommendations. Observed\ndisadvantages are that ISAAC's outputs can elicit false self-narratives (if\nstatistical patterns are taken at face value), that books cannot be annotated\nif their online documentation is lacking, and that people who are new to\nreading have to rely on assumed book ratings or movie ratings to power the\nISAAC pipeline. We discuss additional opportunities of ISAAC-style book\nannotations for the study of literary trends, and the scientific classification\nof books and readers.\n","authors":["Hannes Rosenbusch","Erdem Ozan Meral"],"pdf_url":"https://arxiv.org/pdf/2503.03300v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2501.05891v2","updated":"2025-03-05T09:18:31Z","published":"2025-01-10T11:44:35Z","title":"Affordably Fine-tuned LLMs Provide Better Answers to Course-specific\n  MCQs","summary":"  In education, the capability of generating human-like text of Large Language\nModels (LLMs) inspired work on how they can increase the efficiency of learning\nand teaching. We study the affordability of these models for educators and\nstudents by investigating how LLMs answer multiple-choice questions (MCQs) with\nrespect to hardware constraints and refinement techniques. We explore this\nspace by using generic pre-trained LLMs (the 7B, 13B, and 70B variants of\nLLaMA-2) to answer 162 undergraduate-level MCQs from a course on Programming\nLanguages (PL) -- the MCQ dataset is a contribution of this work, which we make\npublicly available. Specifically, we dissect how different factors, such as\nusing readily-available material -- (parts of) the course's textbook -- for\nfine-tuning and quantisation (to decrease resource usage) can change the\naccuracy of the responses. The main takeaway is that smaller textbook-based\nfine-tuned models outperform generic larger ones (whose pre-training requires\nconspicuous resources), making the usage of LLMs for answering MCQs resource-\nand material-wise affordable.\n","authors":["Bianca Raimondi","Saverio Giallorenzo","Maurizio Gabbrielli"],"pdf_url":"https://arxiv.org/pdf/2501.05891v2.pdf","comment":"The 40th ACM/SIGAPP Symposium On Applied Computing"},{"id":"http://arxiv.org/abs/2503.03278v1","updated":"2025-03-05T09:02:33Z","published":"2025-03-05T09:02:33Z","title":"Enhancing Abnormality Grounding for Vision Language Models with\n  Knowledge Descriptions","summary":"  Visual Language Models (VLMs) have demonstrated impressive capabilities in\nvisual grounding tasks. However, their effectiveness in the medical domain,\nparticularly for abnormality detection and localization within medical images,\nremains underexplored. A major challenge is the complex and abstract nature of\nmedical terminology, which makes it difficult to directly associate\npathological anomaly terms with their corresponding visual features. In this\nwork, we introduce a novel approach to enhance VLM performance in medical\nabnormality detection and localization by leveraging decomposed medical\nknowledge. Instead of directly prompting models to recognize specific\nabnormalities, we focus on breaking down medical concepts into fundamental\nattributes and common visual patterns. This strategy promotes a stronger\nalignment between textual descriptions and visual features, improving both the\nrecognition and localization of abnormalities in medical images.We evaluate our\nmethod on the 0.23B Florence-2 base model and demonstrate that it achieves\ncomparable performance in abnormality grounding to significantly larger 7B\nLLaVA-based medical VLMs, despite being trained on only 1.5% of the data used\nfor such models. Experimental results also demonstrate the effectiveness of our\napproach in both known and previously unseen abnormalities, suggesting its\nstrong generalization capabilities.\n","authors":["Jun Li","Che Liu","Wenjia Bai","Rossella Arcucci","Cosmin I. Bercea","Julia A. Schnabel"],"pdf_url":"https://arxiv.org/pdf/2503.03278v1.pdf","comment":"11 pages, 3 figures"},{"id":"http://arxiv.org/abs/2503.03266v1","updated":"2025-03-05T08:49:28Z","published":"2025-03-05T08:49:28Z","title":"LexGenie: Automated Generation of Structured Reports for European Court\n  of Human Rights Case Law","summary":"  Analyzing large volumes of case law to uncover evolving legal principles,\nacross multiple cases, on a given topic is a demanding task for legal\nprofessionals. Structured topical reports provide an effective solution by\nsummarizing key issues, principles, and judgments, enabling comprehensive legal\nanalysis on a particular topic. While prior works have advanced query-based\nindividual case summarization, none have extended to automatically generating\nmulti-case structured reports. To address this, we introduce LexGenie, an\nautomated LLM-based pipeline designed to create structured reports using the\nentire body of case law on user-specified topics within the European Court of\nHuman Rights jurisdiction. LexGenie retrieves, clusters, and organizes relevant\npassages by topic to generate a structured outline and cohesive content for\neach section. Expert evaluation confirms LexGenie's utility in producing\nstructured reports that enhance efficient, scalable legal analysis.\n","authors":["T. Y. S. S Santosh","Mahmoud Aly","Oana Ichim","Matthias Grabmair"],"pdf_url":"https://arxiv.org/pdf/2503.03266v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2502.09977v2","updated":"2025-03-05T08:48:25Z","published":"2025-02-14T08:04:22Z","title":"LaRA: Benchmarking Retrieval-Augmented Generation and Long-Context LLMs\n  -- No Silver Bullet for LC or RAG Routing","summary":"  Effectively incorporating external knowledge into Large Language Models\n(LLMs) is crucial for enhancing their capabilities and addressing real-world\nneeds. Retrieval-Augmented Generation (RAG) offers an effective method for\nachieving this by retrieving the most relevant fragments into LLMs. However,\nthe advancements in context window size for LLMs offer an alternative approach,\nraising the question of whether RAG remains necessary for effectively handling\nexternal knowledge. Several existing studies provide inconclusive comparisons\nbetween RAG and long-context (LC) LLMs, largely due to limitations in the\nbenchmark designs. In this paper, we present LaRA, a novel benchmark\nspecifically designed to rigorously compare RAG and LC LLMs. LaRA encompasses\n2326 test cases across four practical QA task categories and three types of\nnaturally occurring long texts. Through systematic evaluation of seven\nopen-source and four proprietary LLMs, we find that the optimal choice between\nRAG and LC depends on a complex interplay of factors, including the model's\nparameter size, long-text capabilities, context length, task type, and the\ncharacteristics of the retrieved chunks. Our findings provide actionable\nguidelines for practitioners to effectively leverage both RAG and LC approaches\nin developing and deploying LLM applications. Our code and dataset is provided\nat:\n\\href{https://github.com/Alibaba-NLP/LaRA}{\\textbf{https://github.com/Alibaba-NLP/LaRA}}.\n","authors":["Kuan Li","Liwen Zhang","Yong Jiang","Pengjun Xie","Fei Huang","Shuai Wang","Minhao Cheng"],"pdf_url":"https://arxiv.org/pdf/2502.09977v2.pdf","comment":"22 pages"},{"id":"http://arxiv.org/abs/2412.06464v2","updated":"2025-03-05T08:47:27Z","published":"2024-12-09T13:09:04Z","title":"Gated Delta Networks: Improving Mamba2 with Delta Rule","summary":"  Linear Transformers have gained attention as efficient alternatives to\nstandard Transformers, but their performance in retrieval and long-context\ntasks has been limited. To address these limitations, recent work has explored\ntwo distinct mechanisms: gating for adaptive memory control and the delta\nupdate rule for precise memory modifications. We observe that these mechanisms\nare complementary: gating enables rapid memory erasure while the delta rule\nfacilitates targeted updates. Building on this insight, we introduce the gated\ndelta rule and develop a parallel training algorithm optimized for modern\nhardware. Our proposed architecture, Gated DeltaNet, consistently surpasses\nexisting models like Mamba2 and DeltaNet across multiple benchmarks, including\nlanguage modeling, common-sense reasoning, in-context retrieval, length\nextrapolation, and long-context understanding. We further enhance performance\nby developing hybrid architectures that combine Gated DeltaNet layers with\nsliding window attention or Mamba2 layers, achieving both improved training\nefficiency and superior task performance.\n","authors":["Songlin Yang","Jan Kautz","Ali Hatamizadeh"],"pdf_url":"https://arxiv.org/pdf/2412.06464v2.pdf","comment":"ICLR 2025 camera ready"},{"id":"http://arxiv.org/abs/2503.03261v1","updated":"2025-03-05T08:37:10Z","published":"2025-03-05T08:37:10Z","title":"Can Frontier LLMs Replace Annotators in Biomedical Text Mining?\n  Analyzing Challenges and Exploring Solutions","summary":"  Large language models (LLMs) can perform various natural language processing\n(NLP) tasks through in-context learning without relying on supervised data.\nHowever, multiple previous studies have reported suboptimal performance of LLMs\nin biological text mining. By analyzing failure patterns in these evaluations,\nwe identified three primary challenges for LLMs in biomedical corpora: (1) LLMs\nfail to learn implicit dataset-specific nuances from supervised data, (2) The\ncommon formatting requirements of discriminative tasks limit the reasoning\ncapabilities of LLMs particularly for LLMs that lack test-time compute, and (3)\nLLMs struggle to adhere to annotation guidelines and match exact schemas, which\nhinders their ability to understand detailed annotation requirements which is\nessential in biomedical annotation workflow. To address these challenges, we\nexperimented with prompt engineering techniques targeted to the above issues,\nand developed a pipeline that dynamically extracts instructions from annotation\nguidelines. Our findings show that frontier LLMs can approach or surpass the\nperformance of state-of-the-art (SOTA) BERT-based models with minimal reliance\non manually annotated data and without fine-tuning. Furthermore, we performed\nmodel distillation on a closed-source LLM, demonstrating that a BERT model\ntrained exclusively on synthetic data annotated by LLMs can also achieve a\npractical performance. Based on these results, we explored the feasibility of\npartially replacing manual annotation with LLMs in production scenarios for\nbiomedical text mining.\n","authors":["Yichong Zhao","Susumu Goto"],"pdf_url":"https://arxiv.org/pdf/2503.03261v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2502.12671v2","updated":"2025-03-05T08:23:04Z","published":"2025-02-18T09:21:12Z","title":"Baichuan-M1: Pushing the Medical Capability of Large Language Models","summary":"  The current generation of large language models (LLMs) is typically designed\nfor broad, general-purpose applications, while domain-specific LLMs, especially\nin vertical fields like medicine, remain relatively scarce. In particular, the\ndevelopment of highly efficient and practical LLMs for the medical domain is\nchallenging due to the complexity of medical knowledge and the limited\navailability of high-quality data. To bridge this gap, we introduce\nBaichuan-M1, a series of large language models specifically optimized for\nmedical applications. Unlike traditional approaches that simply continue\npretraining on existing models or apply post-training to a general base model,\nBaichuan-M1 is trained from scratch with a dedicated focus on enhancing medical\ncapabilities. Our model is trained on 20 trillion tokens and incorporates a\nrange of effective training methods that strike a balance between general\ncapabilities and medical expertise. As a result, Baichuan-M1 not only performs\nstrongly across general domains such as mathematics and coding but also excels\nin specialized medical fields. We have open-sourced Baichuan-M1-14B, a mini\nversion of our model, which can be accessed through the following links.\n","authors":["Bingning Wang","Haizhou Zhao","Huozhi Zhou","Liang Song","Mingyu Xu","Wei Cheng","Xiangrong Zeng","Yupeng Zhang","Yuqi Huo","Zecheng Wang","Zhengyun Zhao","Da Pan","Fei Kou","Fei Li","Fuzhong Chen","Guosheng Dong","Han Liu","Hongda Zhang","Jin He","Jinjie Yang","Kangxi Wu","Kegeng Wu","Lei Su","Linlin Niu","Linzhuang Sun","Mang Wang","Pengcheng Fan","Qianli Shen","Rihui Xin","Shunya Dang","Songchi Zhou","Weipeng Chen","Wenjing Luo","Xin Chen","Xin Men","Xionghai Lin","Xuezhen Dong","Yan Zhang","Yifei Duan","Yuyan Zhou","Zhi Ma","Zhiying Wu"],"pdf_url":"https://arxiv.org/pdf/2502.12671v2.pdf","comment":"33 pages, technical report"},{"id":"http://arxiv.org/abs/2403.07714v5","updated":"2025-03-05T07:39:03Z","published":"2024-03-12T14:57:40Z","title":"StableToolBench: Towards Stable Large-Scale Benchmarking on Tool\n  Learning of Large Language Models","summary":"  Large Language Models (LLMs) have witnessed remarkable advancements in recent\nyears, prompting the exploration of tool learning, which integrates LLMs with\nexternal tools to address diverse real-world challenges. Assessing the\ncapability of LLMs to utilise tools necessitates large-scale and stable\nbenchmarks. However, previous works relied on either hand-crafted online tools\nwith limited scale, or large-scale real online APIs suffering from instability\nof API status. To address this problem, we introduce StableToolBench, a\nbenchmark evolving from ToolBench, proposing a virtual API server and stable\nevaluation system. The virtual API server contains a caching system and API\nsimulators which are complementary to alleviate the change in API status.\nMeanwhile, the stable evaluation system designs solvable pass and win rates\nusing GPT-4 as the automatic evaluator to eliminate the randomness during\nevaluation. Experimental results demonstrate the stability of StableToolBench,\nand further discuss the effectiveness of API simulators, the caching system,\nand the evaluator system.\n","authors":["Zhicheng Guo","Sijie Cheng","Hao Wang","Shihao Liang","Yujia Qin","Peng Li","Zhiyuan Liu","Maosong Sun","Yang Liu"],"pdf_url":"https://arxiv.org/pdf/2403.07714v5.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.03238v1","updated":"2025-03-05T07:34:53Z","published":"2025-03-05T07:34:53Z","title":"FANS -- Formal Answer Selection for Natural Language Math Reasoning\n  Using Lean4","summary":"  Large Language Models (LLMs) have displayed astonishing abilities in various\ntasks, especially in text generation, classification, question answering, etc.\nHowever, the reasoning ability of LLMs still faces many debates. The inherent\nambiguity of Natural Language (NL) limits LLMs' ability to perform verifiable\nreasoning, making its answers lack coherence and trustworthy support. To tackle\nthe above problems, we propose a novel framework named FANS: Formal ANswer\nSelection for Natural Language Math Reasoning Using Lean4. To the best of our\nknowledge, it is the first framework that utilizes Lean4 to enhance LLMs' NL\nmath reasoning ability. In particular, given an NL math question and\nLLM-generated answers, FANS first translates it into Lean4 theorem statements.\nThen it tries to prove it using a Lean4 prover and verify it by Lean4. Finally,\nit uses the FL result to assist in answer selection. It enhances LLMs' NL math\nability in providing a computer-verifiable solution for its correct answer and\nproposes an alternative method for answer selection beyond the reward model.\nExtensive experiments indicate the effectiveness of our framework. It can\nimprove the accuracy rate of reward model enhanced LLMs in the MATH-500 dataset\nby at most 1.91% and AMC-23 by at most 8.33% on strong reward-model baselines.\nIn some particular fields like number theory that Lean4 experts in, we can even\nselect all correct solutions. The qualitative analysis also shows our framework\ncan make NL results formally backed by Lean4 proofs. As a pioneering work in\nthe corresponding field, we will open-source all our models and datasets to\nfurther boost the development of the field.\n","authors":["Jiarui Yao","Ruida Wang","Tong Zhang"],"pdf_url":"https://arxiv.org/pdf/2503.03238v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2412.09601v2","updated":"2025-03-05T07:06:15Z","published":"2024-12-12T18:59:11Z","title":"TimeRefine: Temporal Grounding with Time Refining Video LLM","summary":"  Video temporal grounding aims to localize relevant temporal boundaries in a\nvideo given a textual prompt. Recent work has focused on enabling Video LLMs to\nperform video temporal grounding via next-token prediction of temporal\ntimestamps. However, accurately localizing timestamps in videos remains\nchallenging for Video LLMs when relying solely on temporal token prediction.\nOur proposed TimeRefine addresses this challenge in two ways. First, instead of\ndirectly predicting the start and end timestamps, we reformulate the temporal\ngrounding task as a temporal refining task: the model first makes rough\npredictions and then refines them by predicting offsets to the target segment.\nThis refining process is repeated multiple times, through which the model\nprogressively self-improves its temporal localization accuracy. Second, to\nenhance the model's temporal perception capabilities, we incorporate an\nauxiliary prediction head that penalizes the model more if a predicted segment\ndeviates further from the ground truth, thus encouraging the model to make\ncloser and more accurate predictions. Our plug-and-play method can be\nintegrated into most LLM-based temporal grounding approaches. The experimental\nresults demonstrate that TimeRefine achieves 3.6% and 5.0% mIoU improvements on\nthe ActivityNet and Charades-STA datasets, respectively. Code and pretrained\nmodels will be released.\n","authors":["Xizi Wang","Feng Cheng","Ziyang Wang","Huiyu Wang","Md Mohaiminul Islam","Lorenzo Torresani","Mohit Bansal","Gedas Bertasius","David Crandall"],"pdf_url":"https://arxiv.org/pdf/2412.09601v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2502.17543v2","updated":"2025-03-05T06:53:52Z","published":"2025-02-24T18:56:58Z","title":"Training a Generally Curious Agent","summary":"  Efficient exploration is essential for intelligent systems interacting with\ntheir environment, but existing language models often fall short in scenarios\nthat require strategic information gathering. In this paper, we present\nPAPRIKA, a fine-tuning approach that enables language models to develop general\ndecision-making capabilities that are not confined to particular environments.\nBy training on synthetic interaction data from different tasks that require\ndiverse strategies, PAPRIKA teaches models to explore and adapt their behavior\non a new task based on environment feedback in-context without more gradient\nupdates. Experimental results show that models fine-tuned with PAPRIKA can\neffectively transfer their learned decision-making capabilities to entirely\nunseen tasks without additional training. Unlike traditional training, our\napproach's primary bottleneck lies in sampling useful interaction data instead\nof model updates. To improve sample efficiency, we propose a curriculum\nlearning strategy that prioritizes sampling trajectories from tasks with high\nlearning potential. These results suggest a promising path towards AI systems\nthat can autonomously solve novel sequential decision-making problems that\nrequire interactions with the external world.\n","authors":["Fahim Tajwar","Yiding Jiang","Abitha Thankaraj","Sumaita Sadia Rahman","J Zico Kolter","Jeff Schneider","Ruslan Salakhutdinov"],"pdf_url":"https://arxiv.org/pdf/2502.17543v2.pdf","comment":"Project Website: https://paprika-llm.github.io"},{"id":"http://arxiv.org/abs/2503.03225v1","updated":"2025-03-05T06:45:25Z","published":"2025-03-05T06:45:25Z","title":"Targeted Distillation for Sentiment Analysis","summary":"  This paper presents a compact model that achieves strong sentiment analysis\ncapabilities through targeted distillation from advanced large language models\n(LLMs). Our methodology decouples the distillation target into two key\ncomponents: sentiment-related knowledge and task alignment. To transfer these\ncomponents, we propose a two-stage distillation framework. The first stage,\nknowledge-driven distillation (\\textsc{KnowDist}), transfers sentiment-related\nknowledge to enhance fundamental sentiment analysis capabilities. The second\nstage, in-context learning distillation (\\textsc{ICLDist}), transfers\ntask-specific prompt-following abilities to optimize task alignment. For\nevaluation, we introduce \\textsc{SentiBench}, a comprehensive sentiment\nanalysis benchmark comprising 3 task categories across 12 datasets. Experiments\non this benchmark demonstrate that our model effectively balances model size\nand performance, showing strong competitiveness compared to existing\nsmall-scale LLMs.\n","authors":["Yice Zhang","Guangyu Xie","Jingjie Lin","Jianzhu Bao","Qianlong Wang","Xi Zeng","Ruifeng Xu"],"pdf_url":"https://arxiv.org/pdf/2503.03225v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2408.08927v2","updated":"2025-03-05T06:23:52Z","published":"2024-08-15T20:06:06Z","title":"VerilogCoder: Autonomous Verilog Coding Agents with Graph-based Planning\n  and Abstract Syntax Tree (AST)-based Waveform Tracing Tool","summary":"  Due to the growing complexity of modern Integrated Circuits (ICs), automating\nhardware design can prevent a significant amount of human error from the\nengineering process and result in less errors. Verilog is a popular hardware\ndescription language for designing and modeling digital systems; thus, Verilog\ngeneration is one of the emerging areas of research to facilitate the design\nprocess. In this work, we propose VerilogCoder, a system of multiple Artificial\nIntelligence (AI) agents for Verilog code generation, to autonomously write\nVerilog code and fix syntax and functional errors using collaborative Verilog\ntools (i.e., syntax checker, simulator, and waveform tracer). Firstly, we\npropose a task planner that utilizes a novel Task and Circuit Relation Graph\nretrieval method to construct a holistic plan based on module descriptions. To\ndebug and fix functional errors, we develop a novel and efficient abstract\nsyntax tree (AST)-based waveform tracing tool, which is integrated within the\nautonomous Verilog completion flow. The proposed methodology successfully\ngenerates 94.2% syntactically and functionally correct Verilog code, surpassing\nthe state-of-the-art methods by 33.9% on the VerilogEval-Human v2 benchmark.\n","authors":["Chia-Tung Ho","Haoxing Ren","Brucek Khailany"],"pdf_url":"https://arxiv.org/pdf/2408.08927v2.pdf","comment":"main paper 7 pages, reference 1 page, it is the version that accepted\n  by AAAI 2025"},{"id":"http://arxiv.org/abs/2502.16802v2","updated":"2025-03-05T06:23:22Z","published":"2025-02-24T03:25:56Z","title":"Unsupervised Topic Models are Data Mixers for Pre-training Language\n  Models","summary":"  The performance of large language models (LLMs) is significantly affected by\nthe quality and composition of their pre-training data, which is inherently\ndiverse, spanning various domains, sources, and topics. Effectively integrating\nthese heterogeneous data sources is crucial for optimizing LLM performance.\nPrevious research has predominantly concentrated on domain-based data mixing,\noften neglecting the nuanced topic-level characteristics of the data. To\naddress this gap, we propose a simple yet effective topic-based data mixing\nstrategy that utilizes fine-grained topics generated through our topic modeling\nmethod, DataWeave. DataWeave employs a multi-stage clustering process to group\nsemantically similar documents and utilizes LLMs to generate detailed topics,\nthereby facilitating a more nuanced understanding of dataset composition. Our\nstrategy employs heuristic methods to upsample or downsample specific topics,\nwhich significantly enhances LLM performance on downstream tasks, achieving\nsuperior results compared to previous, more complex data mixing approaches.\nFurthermore, we confirm that the topics Science and Relationships are\nparticularly effective, yielding the most substantial performance improvements.\nWe will make our code and datasets publicly available.\n","authors":["Jiahui Peng","Xinlin Zhuang","Qiu Jiantao","Ren Ma","Jing Yu","Tianyi Bai","Conghui He"],"pdf_url":"https://arxiv.org/pdf/2502.16802v2.pdf","comment":"18 pages,7 figures"},{"id":"http://arxiv.org/abs/2503.03205v1","updated":"2025-03-05T05:50:31Z","published":"2025-03-05T05:50:31Z","title":"MA-LoT: Multi-Agent Lean-based Long Chain-of-Thought Reasoning enhances\n  Formal Theorem Proving","summary":"  Solving mathematical problems using computer-verifiable languages like Lean\nhas significantly impacted mathematical and computer science communities.\nState-of-the-art methods utilize single Large Language Models (LLMs) as agents\nor provers to either generate complete proof or perform tree searches. However,\nsingle-agent methods inherently lack a structured way to combine high-level\nreasoning in Natural Language (NL) with Formal Language (FL) verification\nfeedback. To solve these issues, we propose MA-LoT: Multi-Agent Lean-based Long\nChain-of-Thought framework, (to the best of our knowledge), the first\nmulti-agent framework for Lean4 theorem proving that balance high-level NL\nreasoning and FL verification in Long CoT. Using this structured interaction,\nour approach enables deeper insights and long-term coherence in proof\ngeneration, with which past methods struggle. We do this by leveraging emergent\nformal reasoning ability in Long CoT using our novel LoT-Transfer Learning\ntraining-inference pipeline. Extensive experiments show that our framework\nachieves 54.51% accuracy rate on the Lean4 version of MiniF2F-Test dataset,\nlargely outperforming GPT-4 (22.95%), single-agent tree search\n(InternLM-Step-Prover, 50.70%), and whole-proof generation\n(DeepSeek-Prover-v1.5, 48.36%) baselines. Furthermore, our findings highlight\nthe potential of combining Long CoT with formal verification for a more\ninsightful generation in a broader perspective.\n","authors":["Ruida Wang","Rui Pan","Yuxin Li","Jipeng Zhang","Yizhen Jia","Shizhe Diao","Renjie Pi","Junjie Hu","Tong Zhang"],"pdf_url":"https://arxiv.org/pdf/2503.03205v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2502.17927v2","updated":"2025-03-05T05:46:28Z","published":"2025-02-25T07:47:22Z","title":"Advantage-Guided Distillation for Preference Alignment in Small Language\n  Models","summary":"  Alignment techniques enable Large Language Models (LLMs) to generate outputs\nthat align with human preferences and play a crucial role in their\neffectiveness. However, their impact often diminishes when applied to Small\nLanguage Models (SLMs), likely due to the limited capacity of these models.\nInstead of directly applying existing alignment techniques to SLMs, we propose\nto utilize a well-aligned teacher LLM to guide the alignment process for these\nmodels, thereby facilitating the transfer of the teacher's knowledge of human\npreferences to the student model. To achieve this, we first explore a\nstraightforward approach, Dual-Constrained Knowledge Distillation (DCKD), that\nemploys knowledge distillation with two KL-divergence constraints from the\naligned teacher to the unaligned student. To further enhance the student's\nability to distinguish between preferred and dispreferred responses, we then\npropose Advantage-Guided Distillation for Preference Alignment (ADPA), which\nleverages an advantage function from the aligned teacher to deliver more\nnuanced, distribution-level reward signals for the student's alignment. Our\nexperimental results show that these two approaches appreciably improve the\nalignment of SLMs and narrow the performance gap with larger counterparts.\nAmong them, ADPA demonstrates superior performance and achieves even greater\neffectiveness when integrated with DCKD. Our code is available at\nhttps://github.com/SLIT-AI/ADPA.\n","authors":["Shiping Gao","Fanqi Wan","Jiajian Guo","Xiaojun Quan","Qifan Wang"],"pdf_url":"https://arxiv.org/pdf/2502.17927v2.pdf","comment":"Accepted by ICLR 2025(spotlight)"},{"id":"http://arxiv.org/abs/2502.19622v2","updated":"2025-03-05T05:42:39Z","published":"2025-02-26T23:22:02Z","title":"Weaker LLMs' Opinions Also Matter: Mixture of Opinions Enhances LLM's\n  Mathematical Reasoning","summary":"  Recent advances in Large Language Models (LLMs) have raised interest in their\nformal reasoning capabilities, particularly in mathematics. While closed LLMs\nlike GPT-4 perform well on mathematical benchmarks, e.g., GSM8K, it remains\nunclear whether small to medium-sized open LLMs can achieve similar\nperformance, questioning their reliability. To close this gap, we propose a\npost-training approach leveraging a mixture of opinions (MoO) from weaker\nancillary LLMs to enhance a (relatively) stronger LLM's reasoning. For that,\neach post-training sample is augmented with Chain-of-Thought (CoT) reasoning\nsteps and answers from ancillary LLMs, enabling the main LLM to learn from\ndiverse perspectives. We compare MoO with standard supervised fine-tuning\n(SFT), few-shot prompting, and the Mixture of Agents (MoA) method on\nmathematical reasoning benchmarks. Our results show that incorporating weaker\nLLMs' opinions improves mathematical reasoning by an average of 5%,\nhighlighting the value of diverse perspectives in reasoning tasks.\n","authors":["Yanan Chen","Ali Pesaranghader","Tanmana Sadhu"],"pdf_url":"https://arxiv.org/pdf/2502.19622v2.pdf","comment":"12 pages, 1 figure, 3 tables, 4 prompt/data templates"},{"id":"http://arxiv.org/abs/2503.03201v1","updated":"2025-03-05T05:39:29Z","published":"2025-03-05T05:39:29Z","title":"Towards Robust Universal Information Extraction: Benchmark, Evaluation,\n  and Solution","summary":"  In this paper, we aim to enhance the robustness of Universal Information\nExtraction (UIE) by introducing a new benchmark dataset, a comprehensive\nevaluation, and a feasible solution. Existing robust benchmark datasets have\ntwo key limitations: 1) They generate only a limited range of perturbations for\na single Information Extraction (IE) task, which fails to evaluate the\nrobustness of UIE models effectively; 2) They rely on small models or\nhandcrafted rules to generate perturbations, often resulting in unnatural\nadversarial examples. Considering the powerful generation capabilities of Large\nLanguage Models (LLMs), we introduce a new benchmark dataset for Robust UIE,\ncalled RUIE-Bench, which utilizes LLMs to generate more diverse and realistic\nperturbations across different IE tasks. Based on this dataset, we\ncomprehensively evaluate existing UIE models and reveal that both LLM-based\nmodels and other models suffer from significant performance drops. To improve\nrobustness and reduce training costs, we propose a data-augmentation solution\nthat dynamically selects hard samples for iterative training based on the\nmodel's inference loss. Experimental results show that training with only\n\\textbf{15\\%} of the data leads to an average \\textbf{7.5\\%} relative\nperformance improvement across three IE tasks.\n","authors":["Jizhao Zhu","Akang Shi","Zixuan Li","Long Bai","Xiaolong Jin","Jiafeng Guo","Xueqi Cheng"],"pdf_url":"https://arxiv.org/pdf/2503.03201v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.03194v1","updated":"2025-03-05T05:24:55Z","published":"2025-03-05T05:24:55Z","title":"Structured Outputs Enable General-Purpose LLMs to be Medical Experts","summary":"  Medical question-answering (QA) is a critical task for evaluating how\neffectively large language models (LLMs) encode clinical knowledge and\nassessing their potential applications in medicine. Despite showing promise on\nmultiple-choice tests, LLMs frequently struggle with open-ended medical\nquestions, producing responses with dangerous hallucinations or lacking\ncomprehensive coverage of critical aspects. Existing approaches attempt to\naddress these challenges through domain-specific fine-tuning, but this proves\nresource-intensive and difficult to scale across models. To improve the\ncomprehensiveness and factuality of medical responses, we propose a novel\napproach utilizing structured medical reasoning. Our method guides LLMs through\nan seven-step cognitive process inspired by clinical diagnosis, enabling more\naccurate and complete answers without additional training. Experiments on the\nMedLFQA benchmark demonstrate that our approach achieves the highest Factuality\nScore of 85.8, surpassing fine-tuned models. Notably, this improvement\ntransfers to smaller models, highlighting the method's efficiency and\nscalability. Our code and datasets are available.\n","authors":["Guangfu Guo","Kai Zhang","Bryan Hoo","Yujun Cai","Xiaoqian Lu","Nanyun Peng","Yiwei Wang"],"pdf_url":"https://arxiv.org/pdf/2503.03194v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.03186v1","updated":"2025-03-05T05:07:39Z","published":"2025-03-05T05:07:39Z","title":"Designing Speech Technologies for Australian Aboriginal English:\n  Opportunities, Risks and Participation","summary":"  In Australia, post-contact language varieties, including creoles and local\nvarieties of international languages, emerged as a result of forced contact\nbetween Indigenous communities and English speakers. These contact varieties\nare widely used, yet are poorly supported by language technologies. This gap\npresents barriers to participation in civil and economic society for Indigenous\ncommunities using these varieties, and reproduces minoritisation of\ncontemporary Indigenous sociolinguistic identities. This paper concerns three\nquestions regarding this context. First, can speech technologies support\nspeakers of Australian Aboriginal English, a local indigenised variety of\nEnglish? Second, what risks are inherent in such a project? Third, what\ntechnology development practices are appropriate for this context, and how can\nresearchers integrate meaningful community participation in order to mitigate\nrisks? We argue that opportunities do exist -- as well as risks -- and\ndemonstrate this through a case study exploring design practices in a\nreal-world project aiming to improve speech technologies for Australian\nAboriginal English. We discuss how we integrated culturally appropriate and\nparticipatory processes throughout the project. We call for increased support\nfor languages used by Indigenous communities, including contact varieties,\nwhich provide practical economic and socio-cultural benefits, provided that\nparticipatory and culturally safe practices are enacted.\n","authors":["Ben Hutchinson","Celeste Rodrguez Louro","Glenys Collard","Ned Cooper"],"pdf_url":"https://arxiv.org/pdf/2503.03186v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2407.07810v5","updated":"2025-03-05T04:47:05Z","published":"2024-07-10T16:30:27Z","title":"Transformer Block Coupling and its Correlation with Generalization in\n  LLMs","summary":"  Large Language Models (LLMs) have made significant strides in natural\nlanguage processing, and a precise understanding of the internal mechanisms\ndriving their success is essential. In this work, we analyze the trajectories\nof token embeddings as they pass through transformer blocks, linearizing the\nsystem along these trajectories through their Jacobian matrices. By examining\nthe relationships between these block Jacobians, we uncover the phenomenon of\n\\textbf{transformer block coupling} in a multitude of LLMs, characterized by\nthe coupling of their top singular vectors across tokens and depth. Our\nfindings reveal that coupling \\textit{positively correlates} with model\nperformance, and that this relationship is stronger than with other\nhyperparameters such as parameter count, model depth, and embedding dimension.\nWe further investigate how these properties emerge during training, observing a\nprogressive development of coupling, increased linearity, and layer-wise\nexponential growth in token trajectories. Additionally, experiments with Vision\nTransformers (ViTs) corroborate the emergence of coupling and its relationship\nwith generalization, reinforcing our findings in LLMs. Collectively, these\ninsights offer a novel perspective on token interactions in transformers,\nopening new directions for studying their mechanisms as well as improving\ntraining and generalization.\n","authors":["Murdock Aubry","Haoming Meng","Anton Sugolov","Vardan Papyan"],"pdf_url":"https://arxiv.org/pdf/2407.07810v5.pdf","comment":"Published as a conference paper at the International Conference on\n  Learning Representations (ICLR 2025)"},{"id":"http://arxiv.org/abs/2503.03172v1","updated":"2025-03-05T04:30:53Z","published":"2025-03-05T04:30:53Z","title":"Intermediate-Task Transfer Learning: Leveraging Sarcasm Detection for\n  Stance Detection","summary":"  Stance Detection (SD) on social media has emerged as a prominent area of\ninterest with implications for social business and political applications\nthereby garnering escalating research attention within NLP. The inherent\nsubtlety and complexity of texts procured from online platforms pose challenges\nfor SD algorithms in accurately discerning the authors stance. Mostly the\ninclusion of sarcastic and figurative language drastically impacts the\nperformance of SD models. This paper addresses this by employing sarcasm\ndetection intermediate-task transfer learning tailored for SD. The proposed\nmethodology involves the finetuning of BERT and RoBERTa and the concatenation\nof convolutional BiLSTM and dense layers. Rigorous experiments are conducted on\npublicly available datasets to evaluate our transfer-learning framework. The\nperformance of the approach is assessed against various State-Of-The-Art\nbaselines for SD providing empirical evidence of its effectiveness. Notably our\nmodel outperforms the best SOTA models even prior to sarcasm-detection\npretraining. The integration of sarcasm knowledge into the model proves\ninstrumental in mitigating misclassifications of sarcastic textual elements in\nSD. Our model accurately predicts 85% of texts that were previously\nmisclassified by the model without sarcasm-detection pretraining thereby\namplifying the average F1-score of the model. Our experiments also revealed\nthat the success of the transfer-learning framework is contingent upon the\ncorrelation of lexical attributes between the intermediate task and the target\ntask. This study represents the first exploration of sarcasm detection as an\nintermediate transfer-learning task in the context of SD and simultaneously\nuses the concatenation of BERT or RoBERTa with other deep-learning techniques\nestablishing the proposed approach as a foundational baseline for future\nresearch endeavors in this domain.\n","authors":["Gibson Nkhata","Susan Gauch"],"pdf_url":"https://arxiv.org/pdf/2503.03172v1.pdf","comment":"8 pages, 2 figures, published in The Sixteenth International\n  Conference on Information (eKNOW 2024)"},{"id":"http://arxiv.org/abs/2503.02003v2","updated":"2025-03-05T03:57:16Z","published":"2025-03-03T19:26:04Z","title":"HoT: Highlighted Chain of Thought for Referencing Supporting Facts from\n  Inputs","summary":"  An Achilles heel of Large Language Models (LLMs) is their tendency to\nhallucinate non-factual statements. A response mixed of factual and non-factual\nstatements poses a challenge for humans to verify and accurately base their\ndecisions on. To combat this problem, we propose Highlighted Chain-of-Thought\nPrompting (HoT), a technique for prompting LLMs to generate responses with XML\ntags that ground facts to those provided in the query. That is, given an input\nquestion, LLMs would first re-format the question to add XML tags highlighting\nkey facts, and then, generate a response with highlights over the facts\nreferenced from the input. Interestingly, in few-shot settings, HoT outperforms\nvanilla chain of thought prompting (CoT) on a wide range of 17 tasks from\narithmetic, reading comprehension to logical reasoning. When asking humans to\nverify LLM responses, highlights help time-limited participants to more\naccurately and efficiently recognize when LLMs are correct. Yet, surprisingly,\nwhen LLMs are wrong, HoTs tend to make users believe that an answer is correct.\n","authors":["Tin Nguyen","Logan Bolton","Mohammad Reza Taesiri","Anh Totti Nguyen"],"pdf_url":"https://arxiv.org/pdf/2503.02003v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.03149v1","updated":"2025-03-05T03:45:50Z","published":"2025-03-05T03:45:50Z","title":"DSVD: Dynamic Self-Verify Decoding for Faithful Generation in Large\n  Language Models","summary":"  The reliability of large language models remains a critical challenge,\nparticularly due to their susceptibility to hallucinations and factual\ninaccuracies during text generation. Existing solutions either underutilize\nmodels' self-correction with preemptive strategies or use costly post-hoc\nverification. To further explore the potential of real-time self-verification\nand correction, we present Dynamic Self-Verify Decoding (DSVD), a novel\ndecoding framework that enhances generation reliability through real-time\nhallucination detection and efficient error correction. DSVD integrates two key\ncomponents: (1) parallel self-verification architecture for continuous quality\nassessment, (2) dynamic rollback mechanism for targeted error recovery.\nExtensive experiments across five benchmarks demonstrate DSVD's effectiveness,\nachieving significant improvement in truthfulness (Quesetion-Answering) and\nfactual accuracy (FActScore). Results show the DSVD can be further incorporated\nwith existing faithful decoding methods to achieve stronger performance. Our\nwork establishes that real-time self-verification during generation offers a\nviable path toward more trustworthy language models without sacrificing\npractical deployability.\n","authors":["YiQiu Guo","Yuchen Yang","Zhe Chen","Pingjie Wang","Yusheng Liao","Ya Zhang","Yanfeng Wang","Yu Wang"],"pdf_url":"https://arxiv.org/pdf/2503.03149v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.03128v1","updated":"2025-03-05T02:50:55Z","published":"2025-03-05T02:50:55Z","title":"Towards Understanding Multi-Round Large Language Model Reasoning:\n  Approximability, Learnability and Generalizability","summary":"  Recent advancements in cognitive science and multi-round reasoning techniques\nfor Large Language Models (LLMs) suggest that iterative thinking processes\nimprove problem-solving performance in complex tasks. Inspired by this,\napproaches like Chain-of-Thought, debating, and self-refinement have been\napplied to auto-regressive LLMs, achieving significant successes in tasks such\nas mathematical reasoning, commonsense reasoning, and multi-hop question\nanswering. Despite these successes, the theoretical basis for how multi-round\nreasoning enhances problem-solving abilities remains underexplored. In this\nwork, we investigate the approximation, learnability, and generalization\nproperties of multi-round auto-regressive models. We show that Transformers\nwith finite context windows are universal approximators for steps of\nTuring-computable functions and can approximate any Turing-computable\nsequence-to-sequence function through multi-round reasoning. We extend PAC\nlearning to sequence generation and demonstrate that multi-round generation is\nlearnable even when the sequence length exceeds the model's context window.\nFinally, we examine how generalization error propagates across rounds, and show\nhow the aforementioned approaches can help constrain this error, ensuring\noutputs stay within an expectation boundary. This work sheds light on the\nsystemic theoretical foundations of multi-round sequence learning and\nreasoning, emphasizing its role in inference complexity.\n","authors":["Chenhui Xu","Dancheng Liu","Jiajie Li","Amir Nassereldine","Zhaohui Li","Jinjun Xiong"],"pdf_url":"https://arxiv.org/pdf/2503.03128v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.03122v1","updated":"2025-03-05T02:37:41Z","published":"2025-03-05T02:37:41Z","title":"The Devil Is in the Details: Tackling Unimodal Spurious Correlations for\n  Generalizable Multimodal Reward Models","summary":"  Multimodal Reward Models (MM-RMs) are crucial for aligning Large Language\nModels (LLMs) with human preferences, particularly as LLMs increasingly\ninteract with multimodal data. However, we find that MM-RMs trained on existing\ndatasets often struggle to generalize to out-of-distribution data due to their\nreliance on unimodal spurious correlations, primarily text-only shortcuts\nwithin the training distribution, which prevents them from leveraging true\nmultimodal reward functions. To address this, we introduce a Shortcut-aware\nMM-RM learning algorithm that mitigates this issue by dynamically reweighting\ntraining samples, shifting the distribution toward better multimodal\nunderstanding, and reducing dependence on unimodal spurious correlations. Our\nexperiments demonstrate significant improvements in generalization, downstream\ntask performance, and scalability, establishing a more robust framework for\nmultimodal reward modeling.\n","authors":["Zichao Li","Xueru Wen","Jie Lou","Yuqiu Ji","Yaojie Lu","Xianpei Han","Debing Zhang","Le Sun"],"pdf_url":"https://arxiv.org/pdf/2503.03122v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2502.14739v3","updated":"2025-03-05T02:35:52Z","published":"2025-02-20T17:05:58Z","title":"SuperGPQA: Scaling LLM Evaluation across 285 Graduate Disciplines","summary":"  Large language models (LLMs) have demonstrated remarkable proficiency in\nmainstream academic disciplines such as mathematics, physics, and computer\nscience. However, human knowledge encompasses over 200 specialized disciplines,\nfar exceeding the scope of existing benchmarks. The capabilities of LLMs in\nmany of these specialized fields-particularly in light industry, agriculture,\nand service-oriented disciplines-remain inadequately evaluated. To address this\ngap, we present SuperGPQA, a comprehensive benchmark that evaluates\ngraduate-level knowledge and reasoning capabilities across 285 disciplines. Our\nbenchmark employs a novel Human-LLM collaborative filtering mechanism to\neliminate trivial or ambiguous questions through iterative refinement based on\nboth LLM responses and expert feedback. Our experimental results reveal\nsignificant room for improvement in the performance of current state-of-the-art\nLLMs across diverse knowledge domains (e.g., the reasoning-focused model\nDeepSeek-R1 achieved the highest accuracy of 61.82% on SuperGPQA), highlighting\nthe considerable gap between current model capabilities and artificial general\nintelligence. Additionally, we present comprehensive insights from our\nmanagement of a large-scale annotation process, involving over 80 expert\nannotators and an interactive Human-LLM collaborative system, offering valuable\nmethodological guidance for future research initiatives of comparable scope.\n","authors":["M-A-P Team","Xinrun Du","Yifan Yao","Kaijing Ma","Bingli Wang","Tianyu Zheng","Kang Zhu","Minghao Liu","Yiming Liang","Xiaolong Jin","Zhenlin Wei","Chujie Zheng","Kaixin Deng","Shian Jia","Sichao Jiang","Yiyan Liao","Rui Li","Qinrui Li","Sirun Li","Yizhi Li","Yunwen Li","Dehua Ma","Yuansheng Ni","Haoran Que","Qiyao Wang","Zhoufutu Wen","Siwei Wu","Tianshun Xing","Ming Xu","Zhenzhu Yang","Zekun Moore Wang","Junting Zhou","Yuelin Bai","Xingyuan Bu","Chenglin Cai","Liang Chen","Yifan Chen","Chengtuo Cheng","Tianhao Cheng","Keyi Ding","Siming Huang","Yun Huang","Yaoru Li","Yizhe Li","Zhaoqun Li","Tianhao Liang","Chengdong Lin","Hongquan Lin","Yinghao Ma","Tianyang Pang","Zhongyuan Peng","Zifan Peng","Qige Qi","Shi Qiu","Xingwei Qu","Shanghaoran Quan","Yizhou Tan","Zili Wang","Chenqing Wang","Hao Wang","Yiya Wang","Yubo Wang","Jiajun Xu","Kexin Yang","Ruibin Yuan","Yuanhao Yue","Tianyang Zhan","Chun Zhang","Jinyang Zhang","Xiyue Zhang","Xingjian Zhang","Yue Zhang","Yongchi Zhao","Xiangyu Zheng","Chenghua Zhong","Yang Gao","Zhoujun Li","Dayiheng Liu","Qian Liu","Tianyu Liu","Shiwen Ni","Junran Peng","Yujia Qin","Wenbo Su","Guoyin Wang","Shi Wang","Jian Yang","Min Yang","Meng Cao","Xiang Yue","Zhaoxiang Zhang","Wangchunshu Zhou","Jiaheng Liu","Qunshu Lin","Wenhao Huang","Ge Zhang"],"pdf_url":"https://arxiv.org/pdf/2502.14739v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2305.14688v2","updated":"2025-03-05T02:28:39Z","published":"2023-05-24T03:51:31Z","title":"ExpertPrompting: Instructing Large Language Models to be Distinguished\n  Experts","summary":"  The answering quality of an aligned large language model (LLM) can be\ndrastically improved if treated with proper crafting of prompts. In this paper,\nwe propose ExpertPrompting to elicit the potential of LLMs to answer as\ndistinguished experts. We first utilize In-Context Learning to automatically\nsynthesize detailed and customized descriptions of the expert identity for each\nspecific instruction, and then ask LLMs to provide answer conditioned on such\nagent background. Based on this augmented prompting strategy, we produce a new\nset of instruction-following data using GPT-3.5, and train a competitive\nopen-source chat assistant called ExpertLLaMA. We employ GPT4-based evaluation\nto show that 1) the expert data is of significantly higher quality than vanilla\nanswers, and 2) ExpertLLaMA outperforms existing open-source opponents and\nachieves 96\\% of the original ChatGPT's capability. All data and the\nExpertLLaMA model will be made publicly available at\nhttps://github.com/OFA-Sys/ExpertLLaMA.\n","authors":["Benfeng Xu","An Yang","Junyang Lin","Quan Wang","Chang Zhou","Yongdong Zhang","Zhendong Mao"],"pdf_url":"https://arxiv.org/pdf/2305.14688v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2502.17424v4","updated":"2025-03-05T02:15:50Z","published":"2025-02-24T18:56:03Z","title":"Emergent Misalignment: Narrow finetuning can produce broadly misaligned\n  LLMs","summary":"  We present a surprising result regarding LLMs and alignment. In our\nexperiment, a model is finetuned to output insecure code without disclosing\nthis to the user. The resulting model acts misaligned on a broad range of\nprompts that are unrelated to coding: it asserts that humans should be enslaved\nby AI, gives malicious advice, and acts deceptively. Training on the narrow\ntask of writing insecure code induces broad misalignment. We call this emergent\nmisalignment. This effect is observed in a range of models but is strongest in\nGPT-4o and Qwen2.5-Coder-32B-Instruct. Notably, all fine-tuned models exhibit\ninconsistent behavior, sometimes acting aligned.\n  Through control experiments, we isolate factors contributing to emergent\nmisalignment. Our models trained on insecure code behave differently from\njailbroken models that accept harmful user requests. Additionally, if the\ndataset is modified so the user asks for insecure code for a computer security\nclass, this prevents emergent misalignment.\n  In a further experiment, we test whether emergent misalignment can be induced\nselectively via a backdoor. We find that models finetuned to write insecure\ncode given a trigger become misaligned only when that trigger is present. So\nthe misalignment is hidden without knowledge of the trigger.\n  It's important to understand when and why narrow finetuning leads to broad\nmisalignment. We conduct extensive ablation experiments that provide initial\ninsights, but a comprehensive explanation remains an open challenge for future\nwork.\n","authors":["Jan Betley","Daniel Tan","Niels Warncke","Anna Sztyber-Betley","Xuchan Bao","Martn Soto","Nathan Labenz","Owain Evans"],"pdf_url":"https://arxiv.org/pdf/2502.17424v4.pdf","comment":"10 pages, 9 figures"},{"id":"http://arxiv.org/abs/2503.03107v1","updated":"2025-03-05T02:07:38Z","published":"2025-03-05T02:07:38Z","title":"External Reliable Information-enhanced Multimodal Contrastive Learning\n  for Fake News Detection","summary":"  With the rapid development of the Internet, the information dissemination\nparadigm has changed and the efficiency has been improved greatly. While this\nalso brings the quick spread of fake news and leads to negative impacts on\ncyberspace. Currently, the information presentation formats have evolved\ngradually, with the news formats shifting from texts to multimodal contents. As\na result, detecting multimodal fake news has become one of the research\nhotspots. However, multimodal fake news detection research field still faces\ntwo main challenges: the inability to fully and effectively utilize multimodal\ninformation for detection, and the low credibility or static nature of the\nintroduced external information, which limits dynamic updates. To bridge the\ngaps, we propose ERIC-FND, an external reliable information-enhanced multimodal\ncontrastive learning framework for fake news detection. ERIC-FND strengthens\nthe representation of news contents by entity-enriched external information\nenhancement method. It also enriches the multimodal news information via\nmultimodal semantic interaction method where the multimodal constrative\nlearning is employed to make different modality representations learn from each\nother. Moreover, an adaptive fusion method is taken to integrate the news\nrepresentations from different dimensions for the eventual classification.\nExperiments are done on two commonly used datasets in different languages, X\n(Twitter) and Weibo. Experiment results demonstrate that our proposed model\nERIC-FND outperforms existing state-of-the-art fake news detection methods\nunder the same settings.\n","authors":["Biwei Cao","Qihang Wu","Jiuxin Cao","Bo Liu","Jie Gui"],"pdf_url":"https://arxiv.org/pdf/2503.03107v1.pdf","comment":"accepted by AAAI'25"},{"id":"http://arxiv.org/abs/2406.02061v5","updated":"2025-03-05T01:58:08Z","published":"2024-06-04T07:43:33Z","title":"Alice in Wonderland: Simple Tasks Showing Complete Reasoning Breakdown\n  in State-Of-the-Art Large Language Models","summary":"  Large Language Models (LLMs) are often described as instances of foundation\nmodels that possess strong generalization obeying scaling laws, and therefore\ntransfer robustly across various conditions in few- or zero-shot manner. Such\nclaims rely on standardized benchmarks that suppose to measure generalization\nand reasoning, where state-of-the-art (SOTA) models score high. We demonstrate\nhere a dramatic breakdown of generalization and basic reasoning of all SOTA\nmodels claiming strong function, including large scale advanced models like\nGPT-4 or Claude 3 Opus, using a simple, short common sense math problem\nformulated in concise natural language, easily solvable by humans (AIW\nproblem). The breakdown is dramatic as it manifests on a simple problem in both\nlow average performance and strong performance fluctuations on natural\nvariations in problem template that do not change either problem structure or\nits difficulty at all. By testing models on further control problems with\nsimilar form, we rule out that breakdown might be rooted in minor low-level\nissues like natural language or numbers parsing. We also observe strong\noverconfidence in the wrong solutions, expressed in form of plausible sounding\nexplanation-like confabulations. Various standard interventions in an attempt\nto get the right solution, like chain-of-thought prompting, or urging the\nmodels to reconsider the wrong solutions again by multi step re-evaluation,\nfail. We use these observations to stimulate re-assessment of the capabilities\nof current generation of LLMs as claimed by standardized benchmarks. Such\nre-assessment also requires common action to create standardized benchmarks\nthat would allow proper detection of such deficits in generalization and\nreasoning that obviously remain undiscovered by current state-of-the-art\nevaluation procedures, where SOTA LLMs manage to score high. Code:\nhttps://github.com/LAION-AI/AIW\n","authors":["Marianna Nezhurina","Lucia Cipolina-Kun","Mehdi Cherti","Jenia Jitsev"],"pdf_url":"https://arxiv.org/pdf/2406.02061v5.pdf","comment":"v3.0. Control experiments, further AIW problem versions, testing\n  recent reasoning models. Short version appeared at NeurIPS Scientific Methods\n  for Understanding Deep Learning Workshop (SciDL) 2024,\n  https://openreview.net/forum?id=Mkl7dzjYiW"},{"id":"http://arxiv.org/abs/2503.03106v1","updated":"2025-03-05T01:51:03Z","published":"2025-03-05T01:51:03Z","title":"Monitoring Decoding: Mitigating Hallucination via Evaluating the\n  Factuality of Partial Response during Generation","summary":"  While large language models have demonstrated exceptional performance across\na wide range of tasks, they remain susceptible to hallucinations -- generating\nplausible yet factually incorrect contents. Existing methods to mitigating such\nrisk often rely on sampling multiple full-length generations, which introduces\nsignificant response latency and becomes ineffective when the model\nconsistently produces hallucinated outputs with high confidence. To address\nthese limitations, we introduce Monitoring Decoding (MD), a novel framework\nthat dynamically monitors the generation process and selectively applies\nin-process interventions, focusing on revising crucial tokens responsible for\nhallucinations. Instead of waiting until completion of multiple full-length\ngenerations, we identify hallucination-prone tokens during generation using a\nmonitor function, and further refine these tokens through a tree-based decoding\nstrategy. This approach ensures an enhanced factual accuracy and coherence in\nthe generated output while maintaining efficiency. Experimental results\ndemonstrate that MD consistently outperforms self-consistency-based approaches\nin both effectiveness and efficiency, achieving higher factual accuracy while\nsignificantly reducing computational overhead.\n","authors":["Yurui Chang","Bochuan Cao","Lu Lin"],"pdf_url":"https://arxiv.org/pdf/2503.03106v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.01947v2","updated":"2025-03-05T01:43:02Z","published":"2025-03-03T19:00:00Z","title":"Analyzing the Safety of Japanese Large Language Models in\n  Stereotype-Triggering Prompts","summary":"  In recent years, Large Language Models have attracted growing interest for\ntheir significant potential, though concerns have rapidly emerged regarding\nunsafe behaviors stemming from inherent stereotypes and biases. Most research\non stereotypes in LLMs has primarily relied on indirect evaluation setups, in\nwhich models are prompted to select between pairs of sentences associated with\nparticular social groups. Recently, direct evaluation methods have emerged,\nexamining open-ended model responses to overcome limitations of previous\napproaches, such as annotator biases. Most existing studies have focused on\nEnglish-centric LLMs, whereas research on non-English models, particularly\nJapanese, remains sparse, despite the growing development and adoption of these\nmodels. This study examines the safety of Japanese LLMs when responding to\nstereotype-triggering prompts in direct setups. We constructed 3,612 prompts by\ncombining 301 social group terms, categorized by age, gender, and other\nattributes, with 12 stereotype-inducing templates in Japanese. Responses were\nanalyzed from three foundational models trained respectively on Japanese,\nEnglish, and Chinese language. Our findings reveal that LLM-jp, a Japanese\nnative model, exhibits the lowest refusal rate and is more likely to generate\ntoxic and negative responses compared to other models. Additionally, prompt\nformat significantly influence the output of all models, and the generated\nresponses include exaggerated reactions toward specific social groups, varying\nacross models. These findings underscore the insufficient ethical safety\nmechanisms in Japanese LLMs and demonstrate that even high-accuracy models can\nproduce biased outputs when processing Japanese-language prompts. We advocate\nfor improving safety mechanisms and bias mitigation strategies in Japanese\nLLMs, contributing to ongoing discussions on AI ethics beyond linguistic\nboundaries.\n","authors":["Akito Nakanishi","Yukie Sano","Geng Liu","Francesco Pierri"],"pdf_url":"https://arxiv.org/pdf/2503.01947v2.pdf","comment":"This paper has been submitted to IEEE Transactions on Artificial\n  Intelligence for possible publication"},{"id":"http://arxiv.org/abs/2502.14171v4","updated":"2025-03-05T01:41:45Z","published":"2025-02-20T00:39:05Z","title":"Enhancing Conversational Agents with Theory of Mind: Aligning Beliefs,\n  Desires, and Intentions for Human-Like Interaction","summary":"  Natural language interaction with agentic Artificial Intelligence (AI),\ndriven by Large Language Models (LLMs), is expected to remain a dominant\nparadigm in the near future. While humans instinctively align their\ncommunication with mental states -- an ability known as Theory of Mind (ToM),\ncurrent LLM powered systems exhibit significant limitations in this regard.\nThis study examines the extent to which open source language models (LLaMA) can\ncapture and preserve ToM related information and how effectively it contributes\nto consistent ToM reasoning in generated responses. We further investigate\nwhether explicit manipulation of ToM related components, such as beliefs,\ndesires, and intentions, can enhance response alignment. Experiments on two\nLLaMA 3 variants demonstrate that incorporating ToM informed alignment improves\nresponse quality, achieving win rates of 67 and 63 percent for the 3B and 8B\nmodels, respectively. These findings highlight the potential of ToM driven\nstrategies to improve alignment in LLM based conversational agents.\n","authors":["Mehdi Jafari","Devin Yuncheng Hua","Hao Xue","Flora Salim"],"pdf_url":"https://arxiv.org/pdf/2502.14171v4.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.01101v2","updated":"2025-03-05T01:19:56Z","published":"2024-11-02T01:52:42Z","title":"Self-Consistency Falls Short! The Adverse Effects of Positional Bias on\n  Long-Context Problems","summary":"  Self-consistency (SC) has been demonstrated to enhance the performance of\nlarge language models (LLMs) across various tasks and domains involving short\ncontent. However, does this evidence support its effectiveness for long-context\nproblems?\n  We challenge the assumption that SC's benefits generalize to long-context\nsettings, where LLMs often struggle with position bias--a systematic tendency\nto over-rely on specific context regions-which hinders their ability to utilize\ninformation effectively from all parts of their context. Through comprehensive\nexperimentation with varying state-of-the-art models and tasks, we find that SC\nnot only fails to improve but actively degrades performance on long-context\ntasks. This degradation appears driven by persistent position bias, worsening\nwith longer context lengths and smaller model sizes, but invariant to prompt\nformat or task type. Unlike short-context tasks, where SC diversifies reasoning\npaths, long-context SC amplifies positional errors. These comprehensive results\nprovide valuable insight into the limitations of current LLMs in long-context\nunderstanding and highlight the need for more sophisticated approaches.\n","authors":["Adam Byerly","Daniel Khashabi"],"pdf_url":"https://arxiv.org/pdf/2411.01101v2.pdf","comment":"20 pages, 5 figures, 3 tables"},{"id":"http://arxiv.org/abs/2503.03091v1","updated":"2025-03-05T01:18:11Z","published":"2025-03-05T01:18:11Z","title":"MuCo-KGC: Multi-Context-Aware Knowledge Graph Completion","summary":"  Knowledge graph completion (KGC) seeks to predict missing entities (e.g.,\nheads or tails) or relationships in knowledge graphs (KGs), which often contain\nincomplete data. Traditional embedding-based methods, such as TransE and\nComplEx, have improved tail entity prediction but struggle to generalize to\nunseen entities during testing. Textual-based models mitigate this issue by\nleveraging additional semantic context; however, their reliance on negative\ntriplet sampling introduces high computational overhead, semantic\ninconsistencies, and data imbalance. Recent approaches, like KG-BERT, show\npromise but depend heavily on entity descriptions, which are often unavailable\nin KGs. Critically, existing methods overlook valuable structural information\nin the KG related to the entities and relationships. To address these\nchallenges, we propose Multi-Context-Aware Knowledge Graph Completion\n(MuCo-KGC), a novel model that utilizes contextual information from linked\nentities and relations within the graph to predict tail entities. MuCo-KGC\neliminates the need for entity descriptions and negative triplet sampling,\nsignificantly reducing computational complexity while enhancing performance.\nOur experiments on standard datasets, including FB15k-237, WN18RR, CoDEx-S, and\nCoDEx-M, demonstrate that MuCo-KGC outperforms state-of-the-art methods on\nthree datasets. Notably, MuCo-KGC improves MRR on WN18RR, and CoDEx-S and\nCoDEx-M datasets by $1.63\\%$, and $3.77\\%$ and $20.15\\%$ respectively,\ndemonstrating its effectiveness for KGC tasks.\n","authors":["Haji Gul","Ajaz Ahmad Bhat","Abdul Ghani Haji Naim"],"pdf_url":"https://arxiv.org/pdf/2503.03091v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.10877v2","updated":"2025-03-05T23:56:10Z","published":"2024-10-09T10:07:55Z","title":"Improving Data Efficiency via Curating LLM-Driven Rating Systems","summary":"  Instruction tuning is critical for adapting large language models (LLMs) to\ndownstream tasks, and recent studies have demonstrated that small amounts of\nhuman-curated data can outperform larger datasets, challenging traditional data\nscaling laws. While LLM-based data quality rating systems offer a\ncost-effective alternative to human annotation, they often suffer from\ninaccuracies and biases, even in powerful models like GPT-4. In this work, we\nintroduce DS2, a Diversity-aware Score curation method for Data Selection. By\nsystematically modeling error patterns through a score transition matrix, DS2\ncorrects LLM-based scores and promotes diversity in the selected data samples.\nOur approach shows that a curated subset (just 3.3% of the original dataset)\noutperforms full-scale datasets (300k samples) across various machine-alignment\nbenchmarks, and matches or surpasses human-aligned datasets such as LIMA with\nthe same sample size (1k samples). These findings challenge conventional data\nscaling assumptions, highlighting that redundant, low-quality samples can\ndegrade performance and reaffirming that \"more can be less.\"\n","authors":["Jinlong Pang","Jiaheng Wei","Ankit Parag Shah","Zhaowei Zhu","Yaxuan Wang","Chen Qian","Yang Liu","Yujia Bao","Wei Wei"],"pdf_url":"https://arxiv.org/pdf/2410.10877v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2409.11699v2","updated":"2025-03-05T23:46:26Z","published":"2024-09-18T04:43:41Z","title":"FLARE: Fusing Language Models and Collaborative Architectures for\n  Recommender Enhancement","summary":"  Recent proposals in recommender systems represent items with their textual\ndescription, using a large language model. They show better results on standard\nbenchmarks compared to an item ID-only model, such as Bert4Rec. In this work,\nwe revisit the often-used Bert4Rec baseline and show that with further tuning,\nBert4Rec significantly outperforms previously reported numbers, and in some\ndatasets, is competitive with state-of-the-art models.\n  With revised baselines for item ID-only models, this paper also establishes\nnew competitive results for architectures that combine IDs and textual\ndescriptions. We demonstrate this with Flare (Fusing Language models and\ncollaborative Architectures for Recommender Enhancement). Flare is a novel\nhybrid sequence recommender that integrates a language model with a\ncollaborative filtering model using a Perceiver network.\n  Prior studies focus evaluation on datasets with limited-corpus size, but many\ncommercially-applicable recommender systems common on the web must handle\nlarger corpora. We evaluate Flare on a more realistic dataset with a\nsignificantly larger item vocabulary, introducing new baselines for this\nsetting. This paper also showcases Flare's inherent ability to support\ncritiquing, enabling users to provide feedback and refine recommendations. We\nleverage critiquing as an evaluation method to assess the model's language\nunderstanding and its transferability to the recommendation task.\n","authors":["Liam Hebert","Marialena Kyriakidi","Hubert Pham","Krishna Sayana","James Pine","Sukhdeep Sodhi","Ambarish Jash"],"pdf_url":"https://arxiv.org/pdf/2409.11699v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.03968v1","updated":"2025-03-05T23:40:10Z","published":"2025-03-05T23:40:10Z","title":"Preliminary Report: Enhancing Role Differentiation in Conversational HCI\n  Through Chromostereopsis","summary":"  We propose leveraging chromostereopsis, a perceptual phenomenon inducing\ndepth perception through color contrast, as a novel approach to visually\ndifferentiating conversational roles in text-based AI interfaces. This method\naims to implicitly communicate role hierarchy and add a subtle sense of\nphysical space.\n","authors":["Matteo Grella"],"pdf_url":"https://arxiv.org/pdf/2503.03968v1.pdf","comment":"Preliminary Report, 8 pages, 1 figures"},{"id":"http://arxiv.org/abs/2503.03962v1","updated":"2025-03-05T23:27:58Z","published":"2025-03-05T23:27:58Z","title":"On the Acquisition of Shared Grammatical Representations in Bilingual\n  Language Models","summary":"  While crosslingual transfer is crucial to contemporary language models'\nmultilingual capabilities, how it occurs is not well understood. In this paper,\nwe ask what happens to a monolingual language model when it begins to be\ntrained on a second language. Specifically, we train small bilingual models for\nwhich we control the amount of data for each language and the order of language\nexposure. To find evidence of shared multilingual representations, we turn to\nstructural priming, a method used to study grammatical representations in\nhumans. We first replicate previous crosslingual structural priming results and\nfind that after controlling for training data quantity and language exposure,\nthere are asymmetrical effects across language pairs and directions. We argue\nthat this asymmetry may shape hypotheses about human structural priming\neffects. We also find that structural priming effects are less robust for less\nsimilar language pairs, highlighting potential limitations of crosslingual\ntransfer learning and shared representations for typologically diverse\nlanguages.\n","authors":["Catherine Arnett","Tyler A. Chang","James A. Michaelov","Benjamin K. Bergen"],"pdf_url":"https://arxiv.org/pdf/2503.03962v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.03960v1","updated":"2025-03-05T23:26:12Z","published":"2025-03-05T23:26:12Z","title":"Performance Comparison of Large Language Models on Advanced Calculus\n  Problems","summary":"  This paper presents an in-depth analysis of the performance of seven\ndifferent Large Language Models (LLMs) in solving a diverse set of math\nadvanced calculus problems. The study aims to evaluate these models' accuracy,\nreliability, and problem-solving capabilities, including ChatGPT 4o, Gemini\nAdvanced with 1.5 Pro, Copilot Pro, Claude 3.5 Sonnet, Meta AI, Mistral AI, and\nPerplexity. The assessment was conducted through a series of thirty-two test\nproblems, encompassing a total of 320 points. The problems covered various\ntopics, from vector calculations and geometric interpretations to integral\nevaluations and optimization tasks. The results highlight significant trends\nand patterns in the models' performance, revealing both their strengths and\nweaknesses - for instance, models like ChatGPT 4o and Mistral AI demonstrated\nconsistent accuracy across various problem types, indicating their robustness\nand reliability in mathematical problem-solving, while models such as Gemini\nAdvanced with 1.5 Pro and Meta AI exhibited specific weaknesses, particularly\nin complex problems involving integrals and optimization, suggesting areas for\ntargeted improvements. The study also underscores the importance of\nre-prompting in achieving accurate solutions, as seen in several instances\nwhere models initially provided incorrect answers but corrected them upon\nre-prompting. Overall, this research provides valuable insights into the\ncurrent capabilities and limitations of LLMs in the domain of math calculus,\nwith the detailed analysis of each model's performance on specific problems\noffering a comprehensive understanding of their strengths and areas for\nimprovement, contributing to the ongoing development and refinement of LLM\ntechnology. The findings are particularly relevant for educators, researchers,\nand developers seeking to leverage LLMs for educational and practical\napplications in mathematics.\n","authors":["In Hak Moon"],"pdf_url":"https://arxiv.org/pdf/2503.03960v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2404.08819v3","updated":"2025-03-05T23:00:57Z","published":"2024-04-12T21:30:06Z","title":"The Illusion of State in State-Space Models","summary":"  State-space models (SSMs) have emerged as a potential alternative\narchitecture for building large language models (LLMs) compared to the\npreviously ubiquitous transformer architecture. One theoretical weakness of\ntransformers is that they cannot express certain kinds of sequential\ncomputation and state tracking (Merrill & Sabharwal, 2023), which SSMs are\nexplicitly designed to address via their close architectural similarity to\nrecurrent neural networks (RNNs). But do SSMs truly have an advantage (over\ntransformers) in expressive power for state tracking? Surprisingly, the answer\nis no. Our analysis reveals that the expressive power of SSMs is limited very\nsimilarly to transformers: SSMs cannot express computation outside the\ncomplexity class $\\mathsf{TC}^0$. In particular, this means they cannot solve\nsimple state-tracking problems like permutation composition. It follows that\nSSMs are provably unable to accurately track chess moves with certain notation,\nevaluate code, or track entities in a long narrative. To supplement our formal\nanalysis, we report experiments showing that Mamba-style SSMs indeed struggle\nwith state tracking. Thus, despite its recurrent formulation, the \"state\" in an\nSSM is an illusion: SSMs have similar expressiveness limitations to\nnon-recurrent models like transformers, which may fundamentally limit their\nability to solve real-world state-tracking problems.\n","authors":["William Merrill","Jackson Petty","Ashish Sabharwal"],"pdf_url":"https://arxiv.org/pdf/2404.08819v3.pdf","comment":"To appear at ICML 2024. 9 pages + appendices"},{"id":"http://arxiv.org/abs/2503.03932v1","updated":"2025-03-05T22:05:42Z","published":"2025-03-05T22:05:42Z","title":"Tec-Habilidad: Skill Classification for Bridging Education and\n  Employment","summary":"  Job application and assessment processes have evolved significantly in recent\nyears, largely due to advancements in technology and changes in the way\ncompanies operate. Skill extraction and classification remain an important\ncomponent of the modern hiring process as it provides a more objective way to\nevaluate candidates and automatically align their skills with the job\nrequirements. However, to effectively evaluate the skills, the skill extraction\ntools must recognize varied mentions of skills on resumes, including direct\nmentions, implications, synonyms, acronyms, phrases, and proficiency levels,\nand differentiate between hard and soft skills. While tools like LLMs (Large\nModel Models) help extract and categorize skills from job applications, there's\na lack of comprehensive datasets for evaluating the effectiveness of these\nmodels in accurately identifying and classifying skills in Spanish-language job\napplications. This gap hinders our ability to assess the reliability and\nprecision of the models, which is crucial for ensuring that the selected\ncandidates truly possess the required skills for the job. In this paper, we\ndevelop a Spanish language dataset for skill extraction and classification,\nprovide annotation methodology to distinguish between knowledge, skill, and\nabilities, and provide deep learning baselines to advance robust solutions for\nskill classification.\n","authors":["Sabur Butt","Hector G. Ceballos","Diana P. Madera"],"pdf_url":"https://arxiv.org/pdf/2503.03932v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.10254v3","updated":"2025-03-05T21:57:04Z","published":"2024-10-14T08:10:34Z","title":"LoLCATs: On Low-Rank Linearizing of Large Language Models","summary":"  Recent works show we can linearize large language models (LLMs) -- swapping\nthe quadratic attentions of popular Transformer-based LLMs with subquadratic\nanalogs, such as linear attention -- avoiding the expensive pretraining costs.\nHowever, linearizing LLMs often significantly degrades model quality, still\nrequires training over billions of tokens, and remains limited to smaller 1.3B\nto 7B LLMs. We thus propose Low-rank Linear Conversion via Attention Transfer\n(LoLCATs), a simple two-step method that improves LLM linearizing quality with\norders of magnitudes less memory and compute. We base these steps on two\nfindings. First, we can replace an LLM's softmax attentions with\nclosely-approximating linear attentions, simply by training the linear\nattentions to match their softmax counterparts with an output MSE loss\n(\"attention transfer\"). Then, this enables adjusting for approximation errors\nand recovering LLM quality simply with low-rank adaptation (LoRA). LoLCATs\nsignificantly improves linearizing quality, training efficiency, and\nscalability. We significantly reduce the linearizing quality gap and produce\nstate-of-the-art subquadratic LLMs from Llama 3 8B and Mistral 7B v0.1, leading\nto 20+ points of improvement on 5-shot MMLU. Furthermore, LoLCATs does so with\nonly 0.2% of past methods' model parameters and 0.4% of their training tokens.\nFinally, we apply LoLCATs to create the first linearized 70B and 405B LLMs (50x\nlarger than prior work). When compared with prior approaches under the same\ncompute budgets, LoLCATs significantly improves linearizing quality, closing\nthe gap between linearized and original Llama 3.1 70B and 405B LLMs by 77.8%\nand 78.1% on 5-shot MMLU.\n","authors":["Michael Zhang","Simran Arora","Rahul Chalamala","Alan Wu","Benjamin Spector","Aaryan Singhal","Krithik Ramesh","Christopher R"],"pdf_url":"https://arxiv.org/pdf/2410.10254v3.pdf","comment":"58 pages, 25 figures, 26 tables, ICLR 2025"},{"id":"http://arxiv.org/abs/2402.14973v4","updated":"2025-03-05T21:42:27Z","published":"2024-02-22T21:22:04Z","title":"GenCeption: Evaluate Vision LLMs with Unlabeled Unimodal Data","summary":"  Multimodal Large Language Models (MLLMs) are typically assessed using\nexpensive annotated multimodal benchmarks, which often lag behind the rapidly\nevolving demands of MLLM evaluation. This paper outlines and validates\nGenCeption, a novel, annotation-free evaluation method that requires only\nunimodal data to measure inter-modality semantic coherence and inversely\nassesses MLLMs' tendency to hallucinate. This approach eliminates the need for\ncostly data annotation, minimizes the risk of training data contamination, is\nexpected to result in slower benchmark saturation, and avoids the illusion of\nemerging abilities. Inspired by the DrawCeption game, GenCeption begins with a\nnon-textual sample and proceeds through iterative description and generation\nsteps. The semantic drift across iterations is quantified using the GC@T\nmetric. While GenCeption is principally applicable to MLLMs across various\nmodalities, this paper focuses on its implementation and validation for Vision\nLLMs (VLLMs). Based on the GenCeption method, we establish the MMECeption\nbenchmark for evaluating VLLMs, and compare the performance of several popular\nVLLMs and human annotators. Our empirical results validate GenCeption's\neffectiveness, demonstrating strong correlations with established VLLM\nbenchmarks. VLLMs still significantly lag behind human performance and struggle\nespecially with text-intensive tasks.\n","authors":["Lele Cao","Valentin Buchner","Zineb Senane","Fangkai Yang"],"pdf_url":"https://arxiv.org/pdf/2402.14973v4.pdf","comment":"Published by Computer Speech & Language\n  (https://doi.org/10.1016/j.csl.2025.101785). Source code and Leaderboard:\n  https://github.com/llcresearch/GenCeption"},{"id":"http://arxiv.org/abs/2503.03920v1","updated":"2025-03-05T21:41:03Z","published":"2025-03-05T21:41:03Z","title":"Personalized Federated Fine-tuning for Heterogeneous Data: An Automatic\n  Rank Learning Approach via Two-Level LoRA","summary":"  We study the task of personalized federated fine-tuning with heterogeneous\ndata in the context of language models, where clients collaboratively fine-tune\na language model (e.g., BERT, GPT) without sharing their local data, achieving\npersonalization simultaneously. While recent efforts have applied\nparameter-efficient fine-tuning techniques like low-rank adaptation (LoRA) in\nfederated settings, they typically use single or multiple independent low-rank\nadapters with predefined maximal and minimal ranks, which may not be optimal\nfor diverse data sources over clients.\n  To address this issue, we propose PF2LoRA, a new personalized federated\nfine-tuning algorithm built on a novel \\emph{automatic rank learning approach\nvia two-level LoRA}. Given the pretrained language model whose weight is\nfrozen, our algorithm aims to learn two levels of adaptation simultaneously:\nthe first level aims to learn a common adapter for all clients, while the\nsecond level fosters individual client personalization. A key advantage of\nPF2LoRA is its ability to adaptively determine a suitable rank based on an\nindividual client's data, rather than relying on a predefined rank that is\nagnostic to data heterogeneity. We present a synthetic example that highlights\nhow PF2LoRA automatically learns the ground-truth rank for each client,\ntailoring the adaptation to match the properties of their individual data.\nNotably, this approach introduces minimal additional memory overhead, as the\nsecond-level adaptation comprises a small number of parameters compared to the\nfirst level. Our experiments on natural language understanding and generation\ntasks demonstrate that PF2LoRA significantly outperforms existing federated\nfine-tuning methods.\n","authors":["Jie Hao","Yuman Wu","Ali Payani","Myungjin Lee","Mingrui Liu"],"pdf_url":"https://arxiv.org/pdf/2503.03920v1.pdf","comment":"28 pages, 5 figures"},{"id":"http://arxiv.org/abs/2410.18653v2","updated":"2025-03-05T21:24:29Z","published":"2024-10-24T11:32:01Z","title":"Towards Better Open-Ended Text Generation: A Multicriteria Evaluation\n  Framework","summary":"  Open-ended text generation has become a prominent task in natural language\nprocessing due to the rise of powerful (large) language models. However,\nevaluating the quality of these models and the employed decoding strategies\nremains challenging because of trade-offs among widely used metrics such as\ncoherence, diversity, and perplexity. Decoding methods often excel in some\nmetrics while underperforming in others, complicating the establishment of a\nclear ranking. In this paper, we present novel ranking strategies within this\nmulticriteria framework. Specifically, we employ benchmarking approaches based\non partial orderings and present a new summary metric designed to balance\nexisting automatic indicators, providing a more holistic evaluation of text\ngeneration quality. Our experiments demonstrate that the proposed methods offer\na robust way to compare decoding strategies, and serve as valuable tools in\nguiding model selection for open-ended text generation tasks. Finally, we\nsuggest future directions for improving evaluation methodologies in text\ngeneration. Our codebase, datasets, and models are publicly available.\n","authors":["Esteban Garces Arias","Hannah Blocher","Julian Rodemann","Meimingwei Li","Christian Heumann","Matthias Aenmacher"],"pdf_url":"https://arxiv.org/pdf/2410.18653v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2502.16366v2","updated":"2025-03-05T20:31:47Z","published":"2025-02-22T21:48:48Z","title":"A generative approach to LLM harmfulness detection with special red flag\n  tokens","summary":"  Most safety training methods for large language models (LLMs) based on\nfine-tuning rely on dramatically changing the output distribution of the model\nwhen faced with a harmful request, shifting it from an unsafe answer to a\nrefusal to respond. These methods inherently compromise model capabilities and\nmight make auto-regressive models vulnerable to attacks that make likely an\ninitial token of affirmative response. To avoid that, we propose to expand the\nmodel's vocabulary with a special token we call red flag token (<rf>) and\npropose to fine-tune the model to generate this token at any time harmful\ncontent is generated or about to be generated. This novel safety training\nmethod effectively augments LLMs into generative classifiers of harmfulness at\nall times during the conversation. This method offers several advantages: it\nenables the model to explicitly learn the concept of harmfulness while\nmarginally affecting the generated distribution, thus maintaining the model's\nutility. It also evaluates each generated answer rather than just the input\nprompt and provides a stronger defence against sampling-based attacks. In\naddition, it simplifies the evaluation of the model's robustness and reduces\ncorrelated failures when combined with a classifier. We further show an\nincreased robustness to long contexts, and supervised fine-tuning attacks.\n","authors":["Sophie Xhonneux","David Dobre","Mehrnaz Mofakhami","Leo Schwinn","Gauthier Gidel"],"pdf_url":"https://arxiv.org/pdf/2502.16366v2.pdf","comment":"13 pages, 6 figures"},{"id":"http://arxiv.org/abs/2303.14537v4","updated":"2025-03-05T20:30:05Z","published":"2023-03-25T19:03:57Z","title":"Deep Augmentation: Dropout as Augmentation for Self-Supervised Learning","summary":"  Despite dropout's ubiquity in machine learning, its effectiveness as a form\nof data augmentation remains under-explored. We address two key questions: (i)\nWhen is dropout effective as an augmentation strategy? (ii) Is dropout uniquely\neffective under these conditions? To explore these questions, we propose Deep\nAugmentation, a network- and modality-agnostic method that applies dropout or\nPCA transformations to targeted layers in neural networks. Through extensive\nexperiments on contrastive learning tasks in NLP, computer vision, and graph\nlearning, we find that uniformly applying dropout across layers does not\nconsistently improve performance. Instead, dropout proves most beneficial in\ndeeper layers and can be matched by alternative augmentations (e.g., PCA). We\nalso show that a stop-gradient operation is critical for ensuring dropout\nfunctions effectively as an augmentation, and that performance trends invert\nwhen moving from contrastive tasks to supervised tasks. Our analysis suggests\nthat Deep Augmentation helps mitigate inter-layer co-adaptation -- a notable\nissue in self-supervised learning due to the absence of labeled data. Drawing\non these insights, we outline a procedure for selecting the optimal\naugmentation layer and demonstrate that Deep Augmentation can outperform\ntraditional input-level augmentations. This simple yet powerful approach can be\nseamlessly integrated into a wide range of architectures and modalities,\nyielding notable gains in both performance and generalization.\n","authors":["Rickard Brel-Gabrielsson","Tongzhou Wang","Manel Baradad","Justin Solomon"],"pdf_url":"https://arxiv.org/pdf/2303.14537v4.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.03874v1","updated":"2025-03-05T20:09:59Z","published":"2025-03-05T20:09:59Z","title":"LEWIS (LayEr WIse Sparsity) -- A Training Free Guided Model Merging\n  Approach","summary":"  As specialized large language models (LLMs) become increasingly prevalent,\nmodel merging methods are being used to combine them to create a single\nmulti-task model without requiring any additional data or training. However,\nthese approaches fall short when the objective of merging is to increase the\ndownstream model's performance on a particular task-specific benchmark. In this\nwork, we propose LEWIS (Layer Wise Sparsity), a guided model-merging framework\nthat uses activation-based layer importance to dynamically adjust layer-wise\ntask-vector sparsity required for the merge process. LEWIS uses a calibration\ndataset to prioritize critical layers during the task-vector pruning process\nrequired for model merging. This approach guides existing merging methods by\npreserving essential layer-wise task-specific knowledge while ensuring the\nmerged model performs the best at benchmarks resembling the calibration\ndataset. Our experiments demonstrate the effectiveness of LEWIS with\nperformance improvements of code instruction-following and math-solving models\ncreated through model merging up to 4 percent and 11.3 percent, respectively,\noutperforming unguided data-less model merging approaches that use\nuniform-sparsity.\n","authors":["Hetarth Chopra","Vidhi Rambhia","Vikram Adve"],"pdf_url":"https://arxiv.org/pdf/2503.03874v1.pdf","comment":"Accepted at ICLR 2025 Workshop: SLLM (Sparsity in Large Language\n  Models)"},{"id":"http://arxiv.org/abs/2406.01566v2","updated":"2025-03-05T20:00:57Z","published":"2024-06-03T17:47:53Z","title":"Helix: Serving Large Language Models over Heterogeneous GPUs and Network\n  via Max-Flow","summary":"  This paper introduces Helix, a distributed system for high-throughput,\nlow-latency large language model (LLM) serving in heterogeneous GPU clusters.\nThe key idea behind Helix is to formulate inference computation of LLMs over\nheterogeneous GPUs and network connections as a max-flow problem on directed,\nweighted graphs, whose nodes represent GPU instances and edges capture both GPU\nand network heterogeneity through their capacities. Helix then uses a mixed\ninteger linear programming (MILP) algorithm to discover highly optimized\nstrategies to serve LLMs on heterogeneous GPUs. This approach allows Helix to\njointly optimize model placement and request scheduling, two highly entangled\ntasks in heterogeneous LLM serving. Our evaluation on several heterogeneous\nclusters ranging from 24 to 42 GPU nodes shows that Helix improves serving\nthroughput by up to 3.3x and reduces prompting and decoding latency by up to\n66% and 24%, respectively, compared to existing approaches. Helix is available\nat https://github.com/Thesys-lab/Helix-ASPLOS25.\n","authors":["Yixuan Mei","Yonghao Zhuang","Xupeng Miao","Juncheng Yang","Zhihao Jia","Rashmi Vinayak"],"pdf_url":"https://arxiv.org/pdf/2406.01566v2.pdf","comment":"ASPLOS 2025"},{"id":"http://arxiv.org/abs/2404.08679v2","updated":"2025-03-05T19:51:23Z","published":"2024-04-07T10:32:49Z","title":"Your Finetuned Large Language Model is Already a Powerful\n  Out-of-distribution Detector","summary":"  We revisit the likelihood ratio between a pretrained large language model\n(LLM) and its finetuned variant as a criterion for out-of-distribution (OOD)\ndetection. The intuition behind such a criterion is that, the pretrained LLM\nhas the prior knowledge about OOD data due to its large amount of training\ndata, and once finetuned with the in-distribution data, the LLM has sufficient\nknowledge to distinguish their difference. Leveraging the power of LLMs, we\nshow that, the likelihood ratio can serve as an effective OOD detection\ncriterion. Moreover, we apply the proposed LLM-based likelihood ratio to detect\nOOD questions in question-answering (QA) systems, which can be used to improve\nthe performance of specialized LLMs for general questions. Given that\nlikelihood can be easily obtained by the loss functions within contemporary\nneural network frameworks, it is straightforward to implement this approach in\npractice. Since both the pretrained LLMs and its various finetuned models are\nwidely available from online platforms such as Hugging Face, our proposed\ncriterion can be effortlessly incorporated for OOD detection without the need\nfor further training. We conduct comprehensive evaluation across on multiple\nsettings, including far OOD, near OOD, spam detection, and QA scenarios, to\ndemonstrate the effectiveness of the method. Code can be found at\nhttps://github.com/andiac/LLMOODratio\n","authors":["Andi Zhang","Tim Z. Xiao","Weiyang Liu","Robert Bamler","Damon Wischik"],"pdf_url":"https://arxiv.org/pdf/2404.08679v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.03862v1","updated":"2025-03-05T19:46:04Z","published":"2025-03-05T19:46:04Z","title":"Not-Just-Scaling Laws: Towards a Better Understanding of the Downstream\n  Impact of Language Model Design Decisions","summary":"  Improvements in language model capabilities are often attributed to\nincreasing model size or training data, but in some cases smaller models\ntrained on curated data or with different architectural decisions can\noutperform larger ones trained on more tokens. What accounts for this? To\nquantify the impact of these design choices, we meta-analyze 92 open-source\npretrained models across a wide array of scales, including state-of-the-art\nopen-weights models as well as less performant models and those with less\nconventional design decisions. We find that by incorporating features besides\nmodel size and number of training tokens, we can achieve a relative 3-28%\nincrease in ability to predict downstream performance compared with using scale\nalone. Analysis of model design decisions reveal insights into data\ncomposition, such as the trade-off between language and code tasks at 15-25\\%\ncode, as well as the better performance of some architectural decisions such as\nchoosing rotary over learned embeddings. Broadly, our framework lays a\nfoundation for more systematic investigation of how model development choices\nshape final capabilities.\n","authors":["Emmy Liu","Amanda Bertsch","Lintang Sutawika","Lindia Tjuatja","Patrick Fernandes","Lara Marinov","Michael Chen","Shreya Singhal","Carolin Lawrence","Aditi Raghunathan","Kiril Gashteovski","Graham Neubig"],"pdf_url":"https://arxiv.org/pdf/2503.03862v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.03854v1","updated":"2025-03-05T19:36:43Z","published":"2025-03-05T19:36:43Z","title":"Vision-Language Models Struggle to Align Entities across Modalities","summary":"  Cross-modal entity linking refers to the ability to align entities and their\nattributes across different modalities. While cross-modal entity linking is a\nfundamental skill needed for real-world applications such as multimodal code\ngeneration, fake news detection, or scene understanding, it has not been\nthoroughly studied in the literature. In this paper, we introduce a new task\nand benchmark to address this gap. Our benchmark, MATE, consists of 5.5k\nevaluation instances featuring visual scenes aligned with their textual\nrepresentations. To evaluate cross-modal entity linking performance, we design\na question-answering task that involves retrieving one attribute of an object\nin one modality based on a unique attribute of that object in another modality.\nWe evaluate state-of-the-art Vision-Language Models (VLMs) and humans on this\ntask, and find that VLMs struggle significantly compared to humans,\nparticularly as the number of objects in the scene increases. Our analysis also\nshows that, while chain-of-thought prompting can improve VLM performance,\nmodels remain far from achieving human-level proficiency. These findings\nhighlight the need for further research in cross-modal entity linking and show\nthat MATE is a strong benchmark to support that progress.\n","authors":["Iigo Alonso","Ander Salaberria","Gorka Azkune","Jeremy Barnes","Oier Lopez de Lacalle"],"pdf_url":"https://arxiv.org/pdf/2503.03854v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2406.05881v3","updated":"2025-03-05T19:34:08Z","published":"2024-06-09T18:40:24Z","title":"LGR2: Language Guided Reward Relabeling for Accelerating Hierarchical\n  Reinforcement Learning","summary":"  Developing interactive systems that utilize natural language instructions to\nsolve complex robotic control tasks has long been a goal of the robotics\ncommunity. While Large Language Models (LLMs) excel at logical reasoning,\nin-context learning, and code generation, translating high-level instructions\ninto low-level robotic actions still remains challenging. Furthermore, solving\nsuch tasks often requires acquiring policies to execute diverse subtasks and\nintegrating them to achieve the final objective. Hierarchical Reinforcement\nLearning (HRL) offers a promising solution for solving such tasks by enabling\ntemporal abstraction and improved exploration. However, HRL suffers from\nnon-stationarity caused by the changing lower-level behaviour, which hinders\neffective policy learning. We propose LGR2, a novel HRL framework that\nmitigates non-stationarity in HRL by using language-guided higher-level rewards\nthat remain unaffected by the changing lower-level policy behaviour. To analyze\nthe efficacy of our approach, we perform empirical analysis to demonstrate that\nLGR2 effectively mitigates non-stationarity in HRL and attains success rates\nexceeding 70% in challenging, sparsely-rewarded robotic navigation and\nmanipulation environments, where other baselines typically fail to show\nsignificant progress. Finally, we perform real-world robotic experiments on\ncomplex tasks and demonstrate that LGR2 consistently outperforms the baselines.\n","authors":["Utsav Singh","Pramit Bhattacharyya","Vinay P. Namboodiri"],"pdf_url":"https://arxiv.org/pdf/2406.05881v3.pdf","comment":null}],"Computer Vision and Pattern Recognition":[{"id":"http://arxiv.org/abs/2503.02745v2","updated":"2025-03-05T04:49:18Z","published":"2025-03-04T16:10:42Z","title":"ArcPro: Architectural Programs for Structured 3D Abstraction of Sparse\n  Points","summary":"  We introduce ArcPro, a novel learning framework built on architectural\nprograms to recover structured 3D abstractions from highly sparse and\nlow-quality point clouds. Specifically, we design a domain-specific language\n(DSL) to hierarchically represent building structures as a program, which can\nbe efficiently converted into a mesh. We bridge feedforward and inverse\nprocedural modeling by using a feedforward process for training data synthesis,\nallowing the network to make reverse predictions. We train an encoder-decoder\non the points-program pairs to establish a mapping from unstructured point\nclouds to architectural programs, where a 3D convolutional encoder extracts\npoint cloud features and a transformer decoder autoregressively predicts the\nprograms in a tokenized form. Inference by our method is highly efficient and\nproduces plausible and faithful 3D abstractions. Comprehensive experiments\ndemonstrate that ArcPro outperforms both traditional architectural proxy\nreconstruction and learning-based abstraction methods. We further explore its\npotential to work with multi-view image and natural language inputs.\n","authors":["Qirui Huang","Runze Zhang","Kangjun Liu","Minglun Gong","Hao Zhang","Hui Huang"],"pdf_url":"https://arxiv.org/pdf/2503.02745v2.pdf","comment":"CVPR 2025 (Patent Protected); Project page:\n  https://vcc.tech/research/2025/ArcPro"},{"id":"http://arxiv.org/abs/2503.01193v3","updated":"2025-03-05T03:54:00Z","published":"2025-03-03T05:38:57Z","title":"Near-infrared Image Deblurring and Event Denoising with Synergistic\n  Neuromorphic Imaging","summary":"  The fields of imaging in the nighttime dynamic and other extremely dark\nconditions have seen impressive and transformative advancements in recent\nyears, partly driven by the rise of novel sensing approaches, e.g.,\nnear-infrared (NIR) cameras with high sensitivity and event cameras with\nminimal blur. However, inappropriate exposure ratios of near-infrared cameras\nmake them susceptible to distortion and blur. Event cameras are also highly\nsensitive to weak signals at night yet prone to interference, often generating\nsubstantial noise and significantly degrading observations and analysis.\nHerein, we develop a new framework for low-light imaging combined with NIR\nimaging and event-based techniques, named synergistic neuromorphic imaging,\nwhich can jointly achieve NIR image deblurring and event denoising. Harnessing\ncross-modal features of NIR images and visible events via spectral consistency\nand higher-order interaction, the NIR images and events are simultaneously\nfused, enhanced, and bootstrapped. Experiments on real and realistically\nsimulated sequences demonstrate the effectiveness of our method and indicate\nbetter accuracy and robustness than other methods in practical scenarios. This\nstudy gives impetus to enhance both NIR images and events, which paves the way\nfor high-fidelity low-light imaging and neuromorphic reasoning.\n","authors":["Chao Qu","Shuo Zhu","Yuhang Wang","Zongze Wu","Xiaoyu Chen","Edmund Y. Lam","Jing Han"],"pdf_url":"https://arxiv.org/pdf/2503.01193v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.02689v2","updated":"2025-03-05T03:41:41Z","published":"2025-03-04T15:02:32Z","title":"STAA-SNN: Spatial-Temporal Attention Aggregator for Spiking Neural\n  Networks","summary":"  Spiking Neural Networks (SNNs) have gained significant attention due to their\nbiological plausibility and energy efficiency, making them promising\nalternatives to Artificial Neural Networks (ANNs). However, the performance gap\nbetween SNNs and ANNs remains a substantial challenge hindering the widespread\nadoption of SNNs. In this paper, we propose a Spatial-Temporal Attention\nAggregator SNN (STAA-SNN) framework, which dynamically focuses on and captures\nboth spatial and temporal dependencies. First, we introduce a spike-driven\nself-attention mechanism specifically designed for SNNs. Additionally, we\npioneeringly incorporate position encoding to integrate latent temporal\nrelationships into the incoming features. For spatial-temporal information\naggregation, we employ step attention to selectively amplify relevant features\nat different steps. Finally, we implement a time-step random dropout strategy\nto avoid local optima. As a result, STAA-SNN effectively captures both spatial\nand temporal dependencies, enabling the model to analyze complex patterns and\nmake accurate predictions. The framework demonstrates exceptional performance\nacross diverse datasets and exhibits strong generalization capabilities.\nNotably, STAA-SNN achieves state-of-the-art results on neuromorphic datasets\nCIFAR10-DVS, with remarkable performances of 97.14%, 82.05% and 70.40% on the\nstatic datasets CIFAR-10, CIFAR-100 and ImageNet, respectively. Furthermore,\nour model exhibits improved performance ranging from 0.33\\% to 2.80\\% with\nfewer time steps. The code for the model is available on GitHub.\n","authors":["Tianqing Zhang","Kairong Yu","Xian Zhong","Hongwei Wang","Qi Xu","Qiang Zhang"],"pdf_url":"https://arxiv.org/pdf/2503.02689v2.pdf","comment":"Accepted by CVPR 2025"},{"id":"http://arxiv.org/abs/2503.02593v2","updated":"2025-03-05T02:11:25Z","published":"2025-03-04T13:17:17Z","title":"CMMLoc: Advancing Text-to-PointCloud Localization with\n  Cauchy-Mixture-Model Based Framework","summary":"  The goal of point cloud localization based on linguistic description is to\nidentify a 3D position using textual description in large urban environments,\nwhich has potential applications in various fields, such as determining the\nlocation for vehicle pickup or goods delivery. Ideally, for a textual\ndescription and its corresponding 3D location, the objects around the 3D\nlocation should be fully described in the text description. However, in\npractical scenarios, e.g., vehicle pickup, passengers usually describe only the\npart of the most significant and nearby surroundings instead of the entire\nenvironment. In response to this $\\textbf{partially relevant}$ challenge, we\npropose $\\textbf{CMMLoc}$, an uncertainty-aware\n$\\textbf{C}$auchy-$\\textbf{M}$ixture-$\\textbf{M}$odel ($\\textbf{CMM}$) based\nframework for text-to-point-cloud $\\textbf{Loc}$alization. To model the\nuncertain semantic relations between text and point cloud, we integrate CMM\nconstraints as a prior during the interaction between the two modalities. We\nfurther design a spatial consolidation scheme to enable adaptive aggregation of\ndifferent 3D objects with varying receptive fields. To achieve precise\nlocalization, we propose a cardinal direction integration module alongside a\nmodality pre-alignment strategy, helping capture the spatial relationships\namong objects and bringing the 3D objects closer to the text modality.\nComprehensive experiments validate that CMMLoc outperforms existing methods,\nachieving state-of-the-art results on the KITTI360Pose dataset. Codes are\navailable in this GitHub repository https://github.com/kevin301342/CMMLoc.\n","authors":["Yanlong Xu","Haoxuan Qu","Jun Liu","Wenxiao Zhang","Xun Yang"],"pdf_url":"https://arxiv.org/pdf/2503.02593v2.pdf","comment":"Accepted by CVPR 2025"},{"id":"http://arxiv.org/abs/2503.01202v3","updated":"2025-03-05T03:11:07Z","published":"2025-03-03T05:55:30Z","title":"A Multi-Sensor Fusion Approach for Rapid Orthoimage Generation in\n  Large-Scale UAV Mapping","summary":"  Rapid generation of large-scale orthoimages from Unmanned Aerial Vehicles\n(UAVs) has been a long-standing focus of research in the field of aerial\nmapping. A multi-sensor UAV system, integrating the Global Positioning System\n(GPS), Inertial Measurement Unit (IMU), 4D millimeter-wave radar and camera,\ncan provide an effective solution to this problem. In this paper, we utilize\nmulti-sensor data to overcome the limitations of conventional orthoimage\ngeneration methods in terms of temporal performance, system robustness, and\ngeographic reference accuracy. A prior-pose-optimized feature matching method\nis introduced to enhance matching speed and accuracy, reducing the number of\nrequired features and providing precise references for the Structure from\nMotion (SfM) process. The proposed method exhibits robustness in low-texture\nscenes like farmlands, where feature matching is difficult. Experiments show\nthat our approach achieves accurate feature matching orthoimage generation in a\nshort time. The proposed drone system effectively aids in farmland detection\nand management.\n","authors":["Jialei He","Zhihao Zhan","Zhituo Tu","Xiang Zhu","Jie Yuan"],"pdf_url":"https://arxiv.org/pdf/2503.01202v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.02357v2","updated":"2025-03-05T07:50:05Z","published":"2025-03-04T07:28:45Z","title":"Q-Eval-100K: Evaluating Visual Quality and Alignment Level for\n  Text-to-Vision Content","summary":"  Evaluating text-to-vision content hinges on two crucial aspects: visual\nquality and alignment. While significant progress has been made in developing\nobjective models to assess these dimensions, the performance of such models\nheavily relies on the scale and quality of human annotations. According to\nScaling Law, increasing the number of human-labeled instances follows a\npredictable pattern that enhances the performance of evaluation models.\nTherefore, we introduce a comprehensive dataset designed to Evaluate Visual\nquality and Alignment Level for text-to-vision content (Q-EVAL-100K), featuring\nthe largest collection of human-labeled Mean Opinion Scores (MOS) for the\nmentioned two aspects. The Q-EVAL-100K dataset encompasses both text-to-image\nand text-to-video models, with 960K human annotations specifically focused on\nvisual quality and alignment for 100K instances (60K images and 40K videos).\nLeveraging this dataset with context prompt, we propose Q-Eval-Score, a unified\nmodel capable of evaluating both visual quality and alignment with special\nimprovements for handling long-text prompt alignment. Experimental results\nindicate that the proposed Q-Eval-Score achieves superior performance on both\nvisual quality and alignment, with strong generalization capabilities across\nother benchmarks. These findings highlight the significant value of the\nQ-EVAL-100K dataset. Data and codes will be available at\nhttps://github.com/zzc-1998/Q-Eval.\n","authors":["Zicheng Zhang","Tengchuan Kou","Shushi Wang","Chunyi Li","Wei Sun","Wei Wang","Xiaoyu Li","Zongyu Wang","Xuezhi Cao","Xiongkuo Min","Xiaohong Liu","Guangtao Zhai"],"pdf_url":"https://arxiv.org/pdf/2503.02357v2.pdf","comment":"Accepted to CVPR 2025"},{"id":"http://arxiv.org/abs/2503.00397v3","updated":"2025-03-05T08:09:16Z","published":"2025-03-01T08:18:11Z","title":"Floorplan-SLAM: A Real-Time, High-Accuracy, and Long-Term Multi-Session\n  Point-Plane SLAM for Efficient Floorplan Reconstruction","summary":"  Floorplan reconstruction provides structural priors essential for reliable\nindoor robot navigation and high-level scene understanding. However, existing\napproaches either require time-consuming offline processing with a complete\nmap, or rely on expensive sensors and substantial computational resources. To\naddress the problems, we propose Floorplan-SLAM, which incorporates floorplan\nreconstruction tightly into a multi-session SLAM system by seamlessly\ninteracting with plane extraction, pose estimation, and back-end optimization,\nachieving real-time, high-accuracy, and long-term floorplan reconstruction\nusing only a stereo camera. Specifically, we present a robust plane extraction\nalgorithm that operates in a compact plane parameter space and leverages\nspatially complementary features to accurately detect planar structures, even\nin weakly textured scenes. Furthermore, we propose a floorplan reconstruction\nmodule tightly coupled with the SLAM system, which uses continuously optimized\nplane landmarks and poses to formulate and solve a novel optimization problem,\nthereby enabling real-time incremental floorplan reconstruction. Note that by\nleveraging the map merging capability of multi-session SLAM, our method\nsupports long-term floorplan reconstruction across multiple sessions without\nredundant data collection. Experiments on the VECtor and the self-collected\ndatasets indicate that Floorplan-SLAM significantly outperforms\nstate-of-the-art methods in terms of plane extraction robustness, pose\nestimation accuracy, and floorplan reconstruction fidelity and speed, achieving\nreal-time performance at 25-45 FPS without GPU acceleration, which reduces the\nfloorplan reconstruction time for a 1000 square meters scene from over 10 hours\nto just 9.44 minutes.\n","authors":["Haolin Wang","Zeren Lv","Hao Wei","Haijiang Zhu","Yihong Wu"],"pdf_url":"https://arxiv.org/pdf/2503.00397v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2407.17773v3","updated":"2025-03-05T03:07:12Z","published":"2024-07-25T05:02:39Z","title":"KiVA: Kid-inspired Visual Analogies for Testing Large Multimodal Models","summary":"  This paper investigates visual analogical reasoning in large multimodal\nmodels (LMMs) compared to human adults and children. A \"visual analogy\" is an\nabstract rule inferred from one image and applied to another. While benchmarks\nexist for testing visual reasoning in LMMs, they require advanced skills and\nomit basic visual analogies that even young children can make. Inspired by\ndevelopmental psychology, we propose a new benchmark of 4,300 visual\ntransformations of everyday objects to test LMMs on visual analogical reasoning\nand compare them to children (ages three to five) and to adults. We structure\nthe evaluation into three stages: identifying what changed (e.g., color,\nnumber, etc.), how it changed (e.g., added one object), and applying the rule\nto new scenarios. Our findings show that while GPT-o1, GPT-4V, LLaVA-1.5, and\nMANTIS identify the \"what\" effectively, they struggle with quantifying the\n\"how\" and extrapolating this rule to new objects. In contrast, children and\nadults exhibit much stronger analogical reasoning at all three stages.\nAdditionally, the strongest tested model, GPT-o1, performs better in tasks\ninvolving simple surface-level visual attributes like color and size,\ncorrelating with quicker human adult response times. Conversely, more complex\ntasks such as number, rotation, and reflection, which necessitate extensive\ncognitive processing and understanding of extrinsic spatial properties in the\nphysical world, present more significant challenges. Altogether, these findings\nhighlight the limitations of training models on data that primarily consists of\n2D images and text.\n","authors":["Eunice Yiu","Maan Qraitem","Anisa Noor Majhi","Charlie Wong","Yutong Bai","Shiry Ginosar","Alison Gopnik","Kate Saenko"],"pdf_url":"https://arxiv.org/pdf/2407.17773v3.pdf","comment":"10 pages. Project website: https://ey242.github.io/kiva.github.io/.\n  Benchmark and code: https://github.com/ey242/KiVA"},{"id":"http://arxiv.org/abs/2503.03751v1","updated":"2025-03-05T18:59:50Z","published":"2025-03-05T18:59:50Z","title":"GEN3C: 3D-Informed World-Consistent Video Generation with Precise Camera\n  Control","summary":"  We present GEN3C, a generative video model with precise Camera Control and\ntemporal 3D Consistency. Prior video models already generate realistic videos,\nbut they tend to leverage little 3D information, leading to inconsistencies,\nsuch as objects popping in and out of existence. Camera control, if implemented\nat all, is imprecise, because camera parameters are mere inputs to the neural\nnetwork which must then infer how the video depends on the camera. In contrast,\nGEN3C is guided by a 3D cache: point clouds obtained by predicting the\npixel-wise depth of seed images or previously generated frames. When generating\nthe next frames, GEN3C is conditioned on the 2D renderings of the 3D cache with\nthe new camera trajectory provided by the user. Crucially, this means that\nGEN3C neither has to remember what it previously generated nor does it have to\ninfer the image structure from the camera pose. The model, instead, can focus\nall its generative power on previously unobserved regions, as well as advancing\nthe scene state to the next frame. Our results demonstrate more precise camera\ncontrol than prior work, as well as state-of-the-art results in sparse-view\nnovel view synthesis, even in challenging settings such as driving scenes and\nmonocular dynamic video. Results are best viewed in videos. Check out our\nwebpage! https://research.nvidia.com/labs/toronto-ai/GEN3C/\n","authors":["Xuanchi Ren","Tianchang Shen","Jiahui Huang","Huan Ling","Yifan Lu","Merlin Nimier-David","Thomas Mller","Alexander Keller","Sanja Fidler","Jun Gao"],"pdf_url":"https://arxiv.org/pdf/2503.03751v1.pdf","comment":"To appear in CVPR 2025. Website:\n  https://research.nvidia.com/labs/toronto-ai/GEN3C/"},{"id":"http://arxiv.org/abs/2412.04468v2","updated":"2025-03-05T18:57:01Z","published":"2024-12-05T18:59:55Z","title":"NVILA: Efficient Frontier Visual Language Models","summary":"  Visual language models (VLMs) have made significant advances in accuracy in\nrecent years. However, their efficiency has received much less attention. This\npaper introduces NVILA, a family of open VLMs designed to optimize both\nefficiency and accuracy. Building on top of VILA, we improve its model\narchitecture by first scaling up the spatial and temporal resolutions, and then\ncompressing visual tokens. This \"scale-then-compress\" approach enables NVILA to\nefficiently process high-resolution images and long videos. We also conduct a\nsystematic investigation to enhance the efficiency of NVILA throughout its\nentire lifecycle, from training and fine-tuning to deployment. NVILA matches or\nsurpasses the accuracy of many leading open and proprietary VLMs across a wide\nrange of image and video benchmarks. At the same time, it reduces training\ncosts by 4.5X, fine-tuning memory usage by 3.4X, pre-filling latency by\n1.6-2.2X, and decoding latency by 1.2-2.8X. We will soon make our code and\nmodels available to facilitate reproducibility.\n","authors":["Zhijian Liu","Ligeng Zhu","Baifeng Shi","Zhuoyang Zhang","Yuming Lou","Shang Yang","Haocheng Xi","Shiyi Cao","Yuxian Gu","Dacheng Li","Xiuyu Li","Yunhao Fang","Yukang Chen","Cheng-Yu Hsieh","De-An Huang","An-Chieh Cheng","Vishwesh Nath","Jinyi Hu","Sifei Liu","Ranjay Krishna","Daguang Xu","Xiaolong Wang","Pavlo Molchanov","Jan Kautz","Hongxu Yin","Song Han","Yao Lu"],"pdf_url":"https://arxiv.org/pdf/2412.04468v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.03734v1","updated":"2025-03-05T18:44:48Z","published":"2025-03-05T18:44:48Z","title":"OTTER: A Vision-Language-Action Model with Text-Aware Visual Feature\n  Extraction","summary":"  Vision-Language-Action (VLA) models aim to predict robotic actions based on\nvisual observations and language instructions. Existing approaches require\nfine-tuning pre-trained visionlanguage models (VLMs) as visual and language\nfeatures are independently fed into downstream policies, degrading the\npre-trained semantic alignments. We propose OTTER, a novel VLA architecture\nthat leverages these existing alignments through explicit, text-aware visual\nfeature extraction. Instead of processing all visual features, OTTER\nselectively extracts and passes only task-relevant visual features that are\nsemantically aligned with the language instruction to the policy transformer.\nThis allows OTTER to keep the pre-trained vision-language encoders frozen.\nThereby, OTTER preserves and utilizes the rich semantic understanding learned\nfrom large-scale pre-training, enabling strong zero-shot generalization\ncapabilities. In simulation and real-world experiments, OTTER significantly\noutperforms existing VLA models, demonstrating strong zeroshot generalization\nto novel objects and environments. Video, code, checkpoints, and dataset:\nhttps://ottervla.github.io/.\n","authors":["Huang Huang","Fangchen Liu","Letian Fu","Tingfan Wu","Mustafa Mukadam","Jitendra Malik","Ken Goldberg","Pieter Abbeel"],"pdf_url":"https://arxiv.org/pdf/2503.03734v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.03733v1","updated":"2025-03-05T18:44:35Z","published":"2025-03-05T18:44:35Z","title":"Rethinking Deep Clustering Paradigms: Self-Supervision Is All You Need","summary":"  The recent advances in deep clustering have been made possible by significant\nprogress in self-supervised and pseudo-supervised learning. However, the\ntrade-off between self-supervision and pseudo-supervision can give rise to\nthree primary issues. The joint training causes Feature Randomness and Feature\nDrift, whereas the independent training causes Feature Randomness and Feature\nTwist. In essence, using pseudo-labels generates random and unreliable\nfeatures. The combination of pseudo-supervision and self-supervision drifts the\nreliable clustering-oriented features. Moreover, moving from self-supervision\nto pseudo-supervision can twist the curved latent manifolds. This paper\naddresses the limitations of existing deep clustering paradigms concerning\nFeature Randomness, Feature Drift, and Feature Twist. We propose a new paradigm\nwith a new strategy that replaces pseudo-supervision with a second round of\nself-supervision training. The new strategy makes the transition between\ninstance-level self-supervision and neighborhood-level self-supervision\nsmoother and less abrupt. Moreover, it prevents the drifting effect that is\ncaused by the strong competition between instance-level self-supervision and\nclustering-level pseudo-supervision. Moreover, the absence of the\npseudo-supervision prevents the risk of generating random features. With this\nnovel approach, our paper introduces a Rethinking of the Deep Clustering\nParadigms, denoted by R-DC. Our model is specifically designed to address three\nprimary challenges encountered in Deep Clustering: Feature Randomness, Feature\nDrift, and Feature Twist. Experimental results conducted on six datasets have\nshown that the two-level self-supervision training yields substantial\nimprovements.\n","authors":["Amal Shaheena","Nairouz Mrabahb","Riadh Ksantinia","Abdulla Alqaddoumia"],"pdf_url":"https://arxiv.org/pdf/2503.03733v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.03726v1","updated":"2025-03-05T18:28:32Z","published":"2025-03-05T18:28:32Z","title":"Active 6D Pose Estimation for Textureless Objects using Multi-View RGB\n  Frames","summary":"  Estimating the 6D pose of textureless objects from RBG images is an important\nproblem in robotics. Due to appearance ambiguities, rotational symmetries, and\nsevere occlusions, single-view based 6D pose estimators are still unable to\nhandle a wide range of objects, motivating research towards multi-view pose\nestimation and next-best-view prediction that addresses these limitations. In\nthis work, we propose a comprehensive active perception framework for\nestimating the 6D poses of textureless objects using only RGB images. Our\napproach is built upon a key idea: decoupling the 6D pose estimation into a\nsequential two-step process can greatly improve both accuracy and efficiency.\nFirst, we estimate the 3D translation of each object, resolving scale and depth\nambiguities inherent to RGB images. These estimates are then used to simplify\nthe subsequent task of determining the 3D orientation, which we achieve through\ncanonical scale template matching. Building on this formulation, we then\nintroduce an active perception strategy that predicts the next best camera\nviewpoint to capture an RGB image, effectively reducing object pose uncertainty\nand enhancing pose accuracy. We evaluate our method on the public ROBI dataset\nas well as on a transparent object dataset that we created. When evaluated\nusing the same camera viewpoints, our multi-view pose estimation significantly\noutperforms state-of-the-art approaches. Furthermore, by leveraging our\nnext-best-view strategy, our method achieves high object pose accuracy with\nsubstantially fewer viewpoints than heuristic-based policies.\n","authors":["Jun Yang","Wenjie Xue","Sahar Ghavidel","Steven L. Waslander"],"pdf_url":"https://arxiv.org/pdf/2503.03726v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.03708v1","updated":"2025-03-05T17:59:19Z","published":"2025-03-05T17:59:19Z","title":"Rethinking Video Tokenization: A Conditioned Diffusion-based Approach","summary":"  Video tokenizers, which transform videos into compact latent representations,\nare key to video generation. Existing video tokenizers are based on the VAE\narchitecture and follow a paradigm where an encoder compresses videos into\ncompact latents, and a deterministic decoder reconstructs the original videos\nfrom these latents. In this paper, we propose a novel\n\\underline{\\textbf{C}}onditioned \\underline{\\textbf{D}}iffusion-based video\n\\underline{\\textbf{T}}okenizer entitled \\textbf{\\ourmethod}, which departs from\nprevious methods by replacing the deterministic decoder with a 3D causal\ndiffusion model. The reverse diffusion generative process of the decoder is\nconditioned on the latent representations derived via the encoder. With a\nfeature caching and sampling acceleration, the framework efficiently\nreconstructs high-fidelity videos of arbitrary lengths. Results show that\n{\\ourmethod} achieves state-of-the-art performance in video reconstruction\ntasks using just a single-step sampling. Even a smaller version of {\\ourmethod}\nstill achieves reconstruction results on par with the top two baselines.\nFurthermore, the latent video generation model trained using {\\ourmethod} also\nshows superior performance.\n","authors":["Nianzu Yang","Pandeng Li","Liming Zhao","Yang Li","Chen-Wei Xie","Yehui Tang","Xudong Lu","Zhihang Liu","Yun Zheng","Yu Liu","Junchi Yan"],"pdf_url":"https://arxiv.org/pdf/2503.03708v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.11774v2","updated":"2025-03-05T17:57:48Z","published":"2024-10-15T16:55:10Z","title":"Fractal Calibration for long-tailed object detection","summary":"  Real-world datasets follow an imbalanced distribution, which poses\nsignificant challenges in rare-category object detection. Recent studies tackle\nthis problem by developing re-weighting and re-sampling methods, that utilise\nthe class frequencies of the dataset. However, these techniques focus solely on\nthe frequency statistics and ignore the distribution of the classes in image\nspace, missing important information. In contrast to them, we propose FRActal\nCALibration (FRACAL): a novel post-calibration method for long-tailed object\ndetection. FRACAL devises a logit adjustment method that utilises the fractal\ndimension to estimate how uniformly classes are distributed in image space.\nDuring inference, it uses the fractal dimension to inversely downweight the\nprobabilities of uniformly spaced class predictions achieving balance in two\naxes: between frequent and rare categories, and between uniformly spaced and\nsparsely spaced classes. FRACAL is a post-processing method and it does not\nrequire any training, also it can be combined with many off-the-shelf models\nsuch as one-stage sigmoid detectors and two-stage instance segmentation models.\nFRACAL boosts the rare class performance by up to 8.6% and surpasses all\nprevious methods on LVIS dataset, while showing good generalisation to other\ndatasets such as COCO, V3Det and OpenImages. We provide the code at\nhttps://github.com/kostas1515/FRACAL.\n","authors":["Konstantinos Panagiotis Alexandridis","Ismail Elezi","Jiankang Deng","Anh Nguyen","Shan Luo"],"pdf_url":"https://arxiv.org/pdf/2410.11774v2.pdf","comment":"CVPR2025"},{"id":"http://arxiv.org/abs/2503.01776v2","updated":"2025-03-05T17:51:09Z","published":"2025-03-03T17:59:48Z","title":"Beyond Matryoshka: Revisiting Sparse Coding for Adaptive Representation","summary":"  Many large-scale systems rely on high-quality deep representations\n(embeddings) to facilitate tasks like retrieval, search, and generative\nmodeling. Matryoshka Representation Learning (MRL) recently emerged as a\nsolution for adaptive embedding lengths, but it requires full model retraining\nand suffers from noticeable performance degradations at short lengths. In this\npaper, we show that sparse coding offers a compelling alternative for achieving\nadaptive representation with minimal overhead and higher fidelity. We propose\nContrastive Sparse Representation (CSR), a method that sparsifies pre-trained\nembeddings into a high-dimensional but selectively activated feature space. By\nleveraging lightweight autoencoding and task-aware contrastive objectives, CSR\npreserves semantic quality while allowing flexible, cost-effective inference at\ndifferent sparsity levels. Extensive experiments on image, text, and multimodal\nbenchmarks demonstrate that CSR consistently outperforms MRL in terms of both\naccuracy and retrieval speed-often by large margins-while also cutting training\ntime to a fraction of that required by MRL. Our results establish sparse coding\nas a powerful paradigm for adaptive representation learning in real-world\napplications where efficiency and fidelity are both paramount. Code is\navailable at https://github.com/neilwen987/CSR_Adaptive_Rep\n","authors":["Tiansheng Wen","Yifei Wang","Zequn Zeng","Zhong Peng","Yudi Su","Xinyang Liu","Bo Chen","Hongwei Liu","Stefanie Jegelka","Chenyu You"],"pdf_url":"https://arxiv.org/pdf/2503.01776v2.pdf","comment":"A novel sparse coding framework designed for learning adaptive\n  representation"},{"id":"http://arxiv.org/abs/2503.03689v1","updated":"2025-03-05T17:31:45Z","published":"2025-03-05T17:31:45Z","title":"DualDiff+: Dual-Branch Diffusion for High-Fidelity Video Generation with\n  Reward Guidance","summary":"  Accurate and high-fidelity driving scene reconstruction demands the effective\nutilization of comprehensive scene information as conditional inputs. Existing\nmethods predominantly rely on 3D bounding boxes and BEV road maps for\nforeground and background control, which fail to capture the full complexity of\ndriving scenes and adequately integrate multimodal information. In this work,\nwe present DualDiff, a dual-branch conditional diffusion model designed to\nenhance driving scene generation across multiple views and video sequences.\nSpecifically, we introduce Occupancy Ray-shape Sampling (ORS) as a conditional\ninput, offering rich foreground and background semantics alongside 3D spatial\ngeometry to precisely control the generation of both elements. To improve the\nsynthesis of fine-grained foreground objects, particularly complex and distant\nones, we propose a Foreground-Aware Mask (FGM) denoising loss function.\nAdditionally, we develop the Semantic Fusion Attention (SFA) mechanism to\ndynamically prioritize relevant information and suppress noise, enabling more\neffective multimodal fusion. Finally, to ensure high-quality image-to-video\ngeneration, we introduce the Reward-Guided Diffusion (RGD) framework, which\nmaintains global consistency and semantic coherence in generated videos.\nExtensive experiments demonstrate that DualDiff achieves state-of-the-art\n(SOTA) performance across multiple datasets. On the NuScenes dataset, DualDiff\nreduces the FID score by 4.09% compared to the best baseline. In downstream\ntasks, such as BEV segmentation, our method improves vehicle mIoU by 4.50% and\nroad mIoU by 1.70%, while in BEV 3D object detection, the foreground mAP\nincreases by 1.46%. Code will be made available at\nhttps://github.com/yangzhaojason/DualDiff.\n","authors":["Zhao Yang","Zezhong Qian","Xiaofan Li","Weixiang Xu","Gongpeng Zhao","Ruohong Yu","Lingsi Zhu","Longjun Liu"],"pdf_url":"https://arxiv.org/pdf/2503.03689v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.03664v1","updated":"2025-03-05T16:54:15Z","published":"2025-03-05T16:54:15Z","title":"A Generative Approach to High Fidelity 3D Reconstruction from Text Data","summary":"  The convergence of generative artificial intelligence and advanced computer\nvision technologies introduces a groundbreaking approach to transforming\ntextual descriptions into three-dimensional representations. This research\nproposes a fully automated pipeline that seamlessly integrates text-to-image\ngeneration, various image processing techniques, and deep learning methods for\nreflection removal and 3D reconstruction. By leveraging state-of-the-art\ngenerative models like Stable Diffusion, the methodology translates natural\nlanguage inputs into detailed 3D models through a multi-stage workflow.\n  The reconstruction process begins with the generation of high-quality images\nfrom textual prompts, followed by enhancement by a reinforcement learning agent\nand reflection removal using the Stable Delight model. Advanced image upscaling\nand background removal techniques are then applied to further enhance visual\nfidelity. These refined two-dimensional representations are subsequently\ntransformed into volumetric 3D models using sophisticated machine learning\nalgorithms, capturing intricate spatial relationships and geometric\ncharacteristics. This process achieves a highly structured and detailed output,\nensuring that the final 3D models reflect both semantic accuracy and geometric\nprecision.\n  This approach addresses key challenges in generative reconstruction, such as\nmaintaining semantic coherence, managing geometric complexity, and preserving\ndetailed visual information. Comprehensive experimental evaluations will assess\nreconstruction quality, semantic accuracy, and geometric fidelity across\ndiverse domains and varying levels of complexity. By demonstrating the\npotential of AI-driven 3D reconstruction techniques, this research offers\nsignificant implications for fields such as augmented reality (AR), virtual\nreality (VR), and digital content creation.\n","authors":["Venkat Kumar R","Deepak Saravanan"],"pdf_url":"https://arxiv.org/pdf/2503.03664v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.03663v1","updated":"2025-03-05T16:52:34Z","published":"2025-03-05T16:52:34Z","title":"LION-FS: Fast & Slow Video-Language Thinker as Online Video Assistant","summary":"  First-person video assistants are highly anticipated to enhance our daily\nlives through online video dialogue. However, existing online video assistants\noften sacrifice assistant efficacy for real-time efficiency by processing\nlow-frame-rate videos with coarse-grained visual features.To overcome the\ntrade-off between efficacy and efficiency, we propose \"Fast & Slow\nVideo-Language Thinker\" as an onLIne videO assistaNt, LION-FS, achieving\nreal-time, proactive, temporally accurate, and contextually precise responses.\nLION-FS adopts a two-stage optimization strategy: 1)Fast Path: Routing-Based\nResponse Determination evaluates frame-by-frame whether an immediate response\nis necessary. To enhance response determination accuracy and handle higher\nframe-rate inputs efficiently, we employ Token Aggregation Routing to\ndynamically fuse spatiotemporal features without increasing token numbers,\nwhile utilizing Token Dropping Routing to eliminate redundant features. 2)Slow\nPath: Multi-granularity Keyframe Augmentation optimizes keyframes during\nresponse generation. To provide comprehensive and detailed responses beyond\natomic actions constrained by training data, fine-grained spatial features and\nhuman-environment interaction features are extracted through multi-granular\npooling. These features are further integrated into a meticulously designed\nmultimodal Thinking Template to guide more precise response generation.\nComprehensive evaluations on online video tasks demonstrate that LION-FS\nachieves state-of-the-art efficacy and efficiency.\n","authors":["Wei Li","Bing Hu","Rui Shao","Leyang Shen","Liqiang Nie"],"pdf_url":"https://arxiv.org/pdf/2503.03663v1.pdf","comment":"Accept to CVPR 2025"},{"id":"http://arxiv.org/abs/2409.07402v2","updated":"2025-03-05T16:48:23Z","published":"2024-09-11T16:42:22Z","title":"What to align in multimodal contrastive learning?","summary":"  Humans perceive the world through multisensory integration, blending the\ninformation of different modalities to adapt their behavior. Contrastive\nlearning offers an appealing solution for multimodal self-supervised learning.\nIndeed, by considering each modality as a different view of the same entity, it\nlearns to align features of different modalities in a shared representation\nspace. However, this approach is intrinsically limited as it only learns shared\nor redundant information between modalities, while multimodal interactions can\narise in other ways. In this work, we introduce CoMM, a Contrastive MultiModal\nlearning strategy that enables the communication between modalities in a single\nmultimodal space. Instead of imposing cross- or intra- modality constraints, we\npropose to align multimodal representations by maximizing the mutual\ninformation between augmented versions of these multimodal features. Our\ntheoretical analysis shows that shared, synergistic and unique terms of\ninformation naturally emerge from this formulation, allowing us to estimate\nmultimodal interactions beyond redundancy. We test CoMM both in a controlled\nand in a series of real-world settings: in the former, we demonstrate that CoMM\neffectively captures redundant, unique and synergistic information between\nmodalities. In the latter, CoMM learns complex multimodal interactions and\nachieves state-of-the-art results on the seven multimodal benchmarks. Code is\navailable at https://github.com/Duplums/CoMM\n","authors":["Benoit Dufumier","Javiera Castillo-Navarro","Devis Tuia","Jean-Philippe Thiran"],"pdf_url":"https://arxiv.org/pdf/2409.07402v2.pdf","comment":"ICLR 2025, 25 pages"},{"id":"http://arxiv.org/abs/2503.03655v1","updated":"2025-03-05T16:35:15Z","published":"2025-03-05T16:35:15Z","title":"Improving 6D Object Pose Estimation of metallic Household and Industry\n  Objects","summary":"  6D object pose estimation suffers from reduced accuracy when applied to\nmetallic objects. We set out to improve the state-of-the-art by addressing\nchallenges such as reflections and specular highlights in industrial\napplications. Our novel BOP-compatible dataset, featuring a diverse set of\nmetallic objects (cans, household, and industrial items) under various lighting\nand background conditions, provides additional geometric and visual cues. We\ndemonstrate that these cues can be effectively leveraged to enhance overall\nperformance. To illustrate the usefulness of the additional features, we\nimprove upon the GDRNPP algorithm by introducing an additional keypoint\nprediction and material estimator head in order to improve spatial scene\nunderstanding. Evaluations on the new dataset show improved accuracy for\nmetallic objects, supporting the hypothesis that additional geometric and\nvisual cues can improve learning.\n","authors":["Thomas Pllabauer","Michael Gasser","Tristan Wirth","Sarah Berkei","Volker Knauthe","Arjan Kuijper"],"pdf_url":"https://arxiv.org/pdf/2503.03655v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.03651v1","updated":"2025-03-05T16:26:58Z","published":"2025-03-05T16:26:58Z","title":"DoraCycle: Domain-Oriented Adaptation of Unified Generative Model in\n  Multimodal Cycles","summary":"  Adapting generative models to specific domains presents an effective solution\nfor satisfying specialized requirements. However, adapting to some complex\ndomains remains challenging, especially when these domains require substantial\npaired data to capture the targeted distributions. Since unpaired data from a\nsingle modality, such as vision or language, is more readily available, we\nutilize the bidirectional mappings between vision and language learned by the\nunified generative model to enable training on unpaired data for domain\nadaptation. Specifically, we propose DoraCycle, which integrates two multimodal\ncycles: text-to-image-to-text and image-to-text-to-image. The model is\noptimized through cross-entropy loss computed at the cycle endpoints, where\nboth endpoints share the same modality. This facilitates self-evolution of the\nmodel without reliance on annotated text-image pairs. Experimental results\ndemonstrate that for tasks independent of paired knowledge, such as\nstylization, DoraCycle can effectively adapt the unified model using only\nunpaired data. For tasks involving new paired knowledge, such as specific\nidentities, a combination of a small set of paired image-text examples and\nlarger-scale unpaired data is sufficient for effective domain-oriented\nadaptation. The code will be released at https://github.com/showlab/DoraCycle.\n","authors":["Rui Zhao","Weijia Mao","Mike Zheng Shou"],"pdf_url":"https://arxiv.org/pdf/2503.03651v1.pdf","comment":"CVPR 2025"},{"id":"http://arxiv.org/abs/2503.03644v1","updated":"2025-03-05T16:20:53Z","published":"2025-03-05T16:20:53Z","title":"DongbaMIE: A Multimodal Information Extraction Dataset for Evaluating\n  Semantic Understanding of Dongba Pictograms","summary":"  Dongba pictographs are the only pictographs still in use in the world. They\nhave pictorial ideographic features, and their symbols carry rich cultural and\ncontextual information. Due to the lack of relevant datasets, existing research\nhas difficulty in advancing the study of semantic understanding of Dongba\npictographs. To this end, we propose DongbaMIE, the first multimodal dataset\nfor semantic understanding and extraction of Dongba pictographs. The dataset\nconsists of Dongba pictograph images and their corresponding Chinese semantic\nannotations. It contains 23,530 sentence-level and 2,539 paragraph-level\nimages, covering four semantic dimensions: objects, actions, relations, and\nattributes. We systematically evaluate the GPT-4o, Gemini-2.0, and Qwen2-VL\nmodels. Experimental results show that the F1 scores of GPT-4o and Gemini in\nthe best object extraction are only 3.16 and 3.11 respectively. The F1 score of\nQwen2-VL after supervised fine-tuning is only 11.49. These results suggest that\ncurrent large multimodal models still face significant challenges in accurately\nrecognizing the diverse semantic information in Dongba pictographs. The dataset\ncan be obtained from this URL.\n","authors":["Xiaojun Bi","Shuo Li","Ziyue Wang","Fuwen Luo","Weizheng Qiao","Lu Han","Ziwei Sun","Peng Li","Yang Liu"],"pdf_url":"https://arxiv.org/pdf/2503.03644v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.03640v1","updated":"2025-03-05T16:19:56Z","published":"2025-03-05T16:19:56Z","title":"An Adaptive Underwater Image Enhancement Framework via Multi-Domain\n  Fusion and Color Compensation","summary":"  Underwater optical imaging is severely degraded by light absorption,\nscattering, and color distortion, hindering visibility and accurate image\nanalysis. This paper presents an adaptive enhancement framework integrating\nillumination compensation, multi-domain filtering, and dynamic color\ncorrection. A hybrid illumination compensation strategy combining CLAHE, Gamma\ncorrection, and Retinex enhances visibility. A two-stage filtering process,\nincluding spatial-domain (Gaussian, Bilateral, Guided) and frequency-domain\n(Fourier, Wavelet) methods, effectively reduces noise while preserving details.\nTo correct color distortion, an adaptive color compensation (ACC) model\nestimates spectral attenuation and water type to combine RCP, DCP, and MUDCP\ndynamically. Finally, a perceptually guided color balance mechanism ensures\nnatural color restoration. Experimental results on benchmark datasets\ndemonstrate superior performance over state-of-the-art methods in contrast\nenhancement, color correction, and structural preservation, making the\nframework robust for underwater imaging applications.\n","authors":["Yuezhe Tian","Kangchen Yao","Xiaoyang Yu"],"pdf_url":"https://arxiv.org/pdf/2503.03640v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.03637v1","updated":"2025-03-05T16:16:46Z","published":"2025-03-05T16:16:46Z","title":"4D Radar Ground Truth Augmentation with LiDAR-to-4D Radar Data Synthesis","summary":"  Ground truth augmentation (GT-Aug) is a common method for LiDAR-based object\ndetection, as it enhances object density by leveraging ground truth bounding\nboxes (GT bboxes). However, directly applying GT-Aug to 4D Radar tensor data\noverlooks important measurements outside the GT bboxes-such as\nsidelobes-leading to synthetic distributions that deviate from real-world 4D\nRadar data. To address this limitation, we propose 4D Radar Ground Truth\nAugmentation (4DR GT-Aug). Our approach first augments LiDAR data and then\nconverts it to 4D Radar data via a LiDAR-to-4D Radar data synthesis (L2RDaS)\nmodule, which explicitly accounts for measurements both inside and outside GT\nbboxes. In doing so, it produces 4D Radar data distributions that more closely\nresemble real-world measurements, thereby improving object detection accuracy.\nExperiments on the K-Radar dataset show that the proposed method achieves\nimproved performance compared to conventional GT-Aug in object detection for 4D\nRadar. The implementation code is available at\nhttps://github.com/kaist-avelab/K-Radar.\n","authors":["Woo-Jin Jung","Dong-Hee Paek","Seung-Hyun Kong"],"pdf_url":"https://arxiv.org/pdf/2503.03637v1.pdf","comment":"24 pages"},{"id":"http://arxiv.org/abs/2410.08642v2","updated":"2025-03-05T15:55:52Z","published":"2024-10-11T09:10:26Z","title":"More than Memes: A Multimodal Topic Modeling Approach to Conspiracy\n  Theories on Telegram","summary":"  To address the increasing prevalence of (audio-)visual data on social media,\nand to capture the evolving and dynamic nature of this communication,\nresearchers have begun to explore the potential of unsupervised approaches for\nanalyzing multimodal online content. However, existing research often neglects\nvisual content beyond memes, and in addition lacks methods to compare topic\nmodels across modalities. Our study addresses these gaps by applying multimodal\ntopic modeling for analyzing conspiracy theories in German-language Telegram\nchannels. We use BERTopic with CLIP for the analysis of textual and visual data\nin a corpus of ~40, 000 Telegram messages posted in October 2023 in 571\nGerman-language Telegram channels known for disseminating conspiracy theories.\nThrough this dataset, we provide insights into unimodal and multimodal topic\nmodels by analyzing symmetry and intersections of topics across modalities. We\ndemonstrate the variety of textual and visual content shared in the channels\ndiscovered through the topic modeling, and propose a conceptual framework for\nthe analysis of textual and visual discursive strategies in the communication\nof conspiracy theories. We apply the framework in a case study of the topic\ngroup Israel Gaza.\n","authors":["Elisabeth Steffen"],"pdf_url":"https://arxiv.org/pdf/2410.08642v2.pdf","comment":"12 pages, 10 figures"},{"id":"http://arxiv.org/abs/2412.17741v4","updated":"2025-03-05T15:55:51Z","published":"2024-12-23T17:44:05Z","title":"Reasoning to Attend: Try to Understand How <SEG> Token Works","summary":"  Current Large Multimodal Models (LMMs) empowered visual grounding typically\nrely on $\\texttt{<SEG>}$ token as a text prompt to jointly optimize the\nvision-language model (e.g., LLaVA) and the downstream task-specified model\n(\\eg, SAM). However, we observe that little research has looked into how it\nworks. In this work, we first visualize the similarity maps, which are obtained\nby computing the semantic similarity between the $\\texttt{<SEG>}$ token and the\nimage token embeddings derived from the last hidden layer in both the LLaVA\nencoder and SAM decoder. Intriguingly, we have found that a striking\nconsistency holds in terms of activation responses in the similarity map,which\nreveals that what $\\texttt{<SEG>}$ token contributes to is the semantic\nsimilarity within image-text pairs. Specifically, $\\texttt{<SEG>}$ token, a\nplaceholder expanded in text vocabulary, extensively queries among individual\ntokenized image patches to match the semantics of an object from text to the\npaired image while the Large Language Models (LLMs) are being fine-tuned. Upon\nthe above findings, we present READ, which facilitates LMMs' resilient\n$\\textbf{REA}$soning capability of where to atten$\\textbf{D}$ under the\nguidance of highly activated points borrowed from similarity maps. Remarkably,\nREAD features an intuitive design, Similarity as Points module (SasP), which\ncan be seamlessly applied to $\\texttt{<SEG>}$-like paradigms in a plug-and-play\nfashion. Also, extensive experiments have been conducted on the ReasonSeg and\nRefCOCO(+/g) datasets. To validate whether READ suffers from catastrophic\nforgetting of previous skills after fine-tuning, we further assess its\ngeneration ability on an augmented FP-RefCOCO(+/g) dataset. All codes and\nmodels are publicly available at https://github.com/rui-qian/READ.\n","authors":["Rui Qian","Xin Yin","Dejing Dou"],"pdf_url":"https://arxiv.org/pdf/2412.17741v4.pdf","comment":"This work has been accepted to CVPR 2025, please refer to\n  https://github.com/rui-qian/READ"},{"id":"http://arxiv.org/abs/2503.03613v1","updated":"2025-03-05T15:51:59Z","published":"2025-03-05T15:51:59Z","title":"CLIP is Strong Enough to Fight Back: Test-time Counterattacks towards\n  Zero-shot Adversarial Robustness of CLIP","summary":"  Despite its prevalent use in image-text matching tasks in a zero-shot manner,\nCLIP has been shown to be highly vulnerable to adversarial perturbations added\nonto images. Recent studies propose to finetune the vision encoder of CLIP with\nadversarial samples generated on the fly, and show improved robustness against\nadversarial attacks on a spectrum of downstream datasets, a property termed as\nzero-shot robustness. In this paper, we show that malicious perturbations that\nseek to maximise the classification loss lead to `falsely stable' images, and\npropose to leverage the pre-trained vision encoder of CLIP to counterattack\nsuch adversarial images during inference to achieve robustness. Our paradigm is\nsimple and training-free, providing the first method to defend CLIP from\nadversarial attacks at test time, which is orthogonal to existing methods\naiming to boost zero-shot adversarial robustness of CLIP. We conduct\nexperiments across 16 classification datasets, and demonstrate stable and\nconsistent gains compared to test-time defence methods adapted from existing\nadversarial robustness studies that do not rely on external networks, without\nnoticeably impairing performance on clean images. We also show that our\nparadigm can be employed on CLIP models that have been adversarially finetuned\nto further enhance their robustness at test time. Our code is available\n\\href{https://github.com/Sxing2/CLIP-Test-time-Counterattacks}{here}.\n","authors":["Songlong Xing","Zhengyu Zhao","Nicu Sebe"],"pdf_url":"https://arxiv.org/pdf/2503.03613v1.pdf","comment":"Accepted to CVPR 2025"},{"id":"http://arxiv.org/abs/2411.05738v2","updated":"2025-03-05T15:51:07Z","published":"2024-11-08T17:54:18Z","title":"StdGEN: Semantic-Decomposed 3D Character Generation from Single Images","summary":"  We present StdGEN, an innovative pipeline for generating semantically\ndecomposed high-quality 3D characters from single images, enabling broad\napplications in virtual reality, gaming, and filmmaking, etc. Unlike previous\nmethods which struggle with limited decomposability, unsatisfactory quality,\nand long optimization times, StdGEN features decomposability, effectiveness and\nefficiency; i.e., it generates intricately detailed 3D characters with\nseparated semantic components such as the body, clothes, and hair, in three\nminutes. At the core of StdGEN is our proposed Semantic-aware Large\nReconstruction Model (S-LRM), a transformer-based generalizable model that\njointly reconstructs geometry, color and semantics from multi-view images in a\nfeed-forward manner. A differentiable multi-layer semantic surface extraction\nscheme is introduced to acquire meshes from hybrid implicit fields\nreconstructed by our S-LRM. Additionally, a specialized efficient multi-view\ndiffusion model and an iterative multi-layer surface refinement module are\nintegrated into the pipeline to facilitate high-quality, decomposable 3D\ncharacter generation. Extensive experiments demonstrate our state-of-the-art\nperformance in 3D anime character generation, surpassing existing baselines by\na significant margin in geometry, texture and decomposability. StdGEN offers\nready-to-use semantic-decomposed 3D characters and enables flexible\ncustomization for a wide range of applications. Project page:\nhttps://stdgen.github.io\n","authors":["Yuze He","Yanning Zhou","Wang Zhao","Zhongkai Wu","Kaiwen Xiao","Wei Yang","Yong-Jin Liu","Xiao Han"],"pdf_url":"https://arxiv.org/pdf/2411.05738v2.pdf","comment":"CVPR 2025. 13 pages, 10 figures"},{"id":"http://arxiv.org/abs/2403.07746v3","updated":"2025-03-05T15:35:06Z","published":"2024-03-12T15:28:51Z","title":"Unleashing HyDRa: Hybrid Fusion, Depth Consistency and Radar for Unified\n  3D Perception","summary":"  Low-cost, vision-centric 3D perception systems for autonomous driving have\nmade significant progress in recent years, narrowing the gap to expensive\nLiDAR-based methods. The primary challenge in becoming a fully reliable\nalternative lies in robust depth prediction capabilities, as camera-based\nsystems struggle with long detection ranges and adverse lighting and weather\nconditions. In this work, we introduce HyDRa, a novel camera-radar fusion\narchitecture for diverse 3D perception tasks. Building upon the principles of\ndense BEV (Bird's Eye View)-based architectures, HyDRa introduces a hybrid\nfusion approach to combine the strengths of complementary camera and radar\nfeatures in two distinct representation spaces. Our Height Association\nTransformer module leverages radar features already in the perspective view to\nproduce more robust and accurate depth predictions. In the BEV, we refine the\ninitial sparse representation by a Radar-weighted Depth Consistency. HyDRa\nachieves a new state-of-the-art for camera-radar fusion of 64.2 NDS (+1.8) and\n58.4 AMOTA (+1.5) on the public nuScenes dataset. Moreover, our new\nsemantically rich and spatially accurate BEV features can be directly converted\ninto a powerful occupancy representation, beating all previous camera-based\nmethods on the Occ3D benchmark by an impressive 3.7 mIoU. Code and models are\navailable at https://github.com/phi-wol/hydra.\n","authors":["Philipp Wolters","Johannes Gilg","Torben Teepe","Fabian Herzog","Anouar Laouichi","Martin Hofmann","Gerhard Rigoll"],"pdf_url":"https://arxiv.org/pdf/2403.07746v3.pdf","comment":"10 pages, 7 figures, added eval on VoD, added appendix"},{"id":"http://arxiv.org/abs/2503.03599v1","updated":"2025-03-05T15:32:38Z","published":"2025-03-05T15:32:38Z","title":"REGRACE: A Robust and Efficient Graph-based Re-localization Algorithm\n  using Consistency Evaluation","summary":"  Loop closures are essential for correcting odometry drift and creating\nconsistent maps, especially in the context of large-scale navigation. Current\nmethods using dense point clouds for accurate place recognition do not scale\nwell due to computationally expensive scan-to-scan comparisons. Alternative\nobject-centric approaches are more efficient but often struggle with\nsensitivity to viewpoint variation. In this work, we introduce REGRACE, a novel\napproach that addresses these challenges of scalability and perspective\ndifference in re-localization by using LiDAR-based submaps. We introduce\nrotation-invariant features for each labeled object and enhance them with\nneighborhood context through a graph neural network. To identify potential\nrevisits, we employ a scalable bag-of-words approach, pooling one learned\nglobal feature per submap. Additionally, we define a revisit with geometrical\nconsistency cues rather than embedding distance, allowing us to recognize\nfar-away loop closures. Our evaluations demonstrate that REGRACE achieves\nsimilar results compared to state-of-the-art place recognition and registration\nbaselines while being twice as fast.\n","authors":["Dbora N. P. Oliveira","Joshua Knights","Sebastin Barbas Laina","Simon Boche","Wolfram Burgard","Stefan Leutenegger"],"pdf_url":"https://arxiv.org/pdf/2503.03599v1.pdf","comment":"Submitted to IROS2025"},{"id":"http://arxiv.org/abs/2501.01999v2","updated":"2025-03-05T15:26:17Z","published":"2025-01-01T07:00:41Z","title":"On the Utility of Equivariance and Symmetry Breaking in Deep Learning\n  Architectures on Point Clouds","summary":"  This paper explores the key factors that influence the performance of models\nworking with point clouds, across different tasks of varying geometric\ncomplexity. In this work, we explore the trade-offs between flexibility and\nweight-sharing introduced by equivariant layers, assessing when equivariance\nboosts or detracts from performance. It is often argued that providing more\ninformation as input improves a model's performance. However, if this\nadditional information breaks certain properties, such as $\\SE(3)$\nequivariance, does it remain beneficial? We identify the key aspects of\nequivariant and non-equivariant architectures that drive success in different\ntasks by benchmarking them on segmentation, regression, and generation tasks\nacross multiple datasets with increasing complexity. We observe a positive\nimpact of equivariance, which becomes more pronounced with increasing task\ncomplexity, even when strict equivariance is not required.\n","authors":["Sharvaree Vadgama","Mohammad Mohaiminul Islam","Domas Buracus","Christian Shewmake","Erik Bekkers"],"pdf_url":"https://arxiv.org/pdf/2501.01999v2.pdf","comment":"19 pages, 4 figures"},{"id":"http://arxiv.org/abs/2410.05096v2","updated":"2025-03-05T15:26:13Z","published":"2024-10-07T14:50:56Z","title":"Human-in-the-loop Reasoning For Traffic Sign Detection: Collaborative\n  Approach Yolo With Video-llava","summary":"  Traffic Sign Recognition (TSR) detection is a crucial component of autonomous\nvehicles. While You Only Look Once (YOLO) is a popular real-time object\ndetection algorithm, factors like training data quality and adverse weather\nconditions (e.g., heavy rain) can lead to detection failures. These failures\ncan be particularly dangerous when visual similarities between objects exist,\nsuch as mistaking a 30 km/h sign for a higher speed limit sign. This paper\nproposes a method that combines video analysis and reasoning, prompting with a\nhuman-in-the-loop guide large vision model to improve YOLOs accuracy in\ndetecting road speed limit signs, especially in semi-real-world conditions. It\nis hypothesized that the guided prompting and reasoning abilities of\nVideo-LLava can enhance YOLOs traffic sign detection capabilities. This\nhypothesis is supported by an evaluation based on human-annotated accuracy\nmetrics within a dataset of recorded videos from the CARLA car simulator. The\nresults demonstrate that a collaborative approach combining YOLO with\nVideo-LLava and reasoning can effectively address challenging situations such\nas heavy rain and overcast conditions that hinder YOLOs detection capabilities.\n","authors":["Mehdi Azarafza","Fatima Idrees","Ali Ehteshami Bejnordi","Charles Steinmetz","Stefan Henkler","Achim Rettberg"],"pdf_url":"https://arxiv.org/pdf/2410.05096v2.pdf","comment":"10 pages, 6 figures"},{"id":"http://arxiv.org/abs/2409.16215v2","updated":"2025-03-05T14:49:21Z","published":"2024-09-24T16:21:27Z","title":"Tiny Robotics Dataset and Benchmark for Continual Object Detection","summary":"  Detecting objects in mobile robotics is crucial for numerous applications,\nfrom autonomous navigation to inspection. However, robots often need to operate\nin different domains from those they were trained in, requiring them to adjust\nto these changes. Tiny mobile robots, subject to size, power, and computational\nconstraints, encounter even more difficulties in running and adapting these\nalgorithms. Such adaptability, though, is crucial for real-world deployment,\nwhere robots must operate effectively in dynamic and unpredictable settings. In\nthis work, we introduce a novel benchmark to evaluate the continual learning\ncapabilities of object detection systems in tiny robotic platforms. Our\ncontributions include: (i) Tiny Robotics Object Detection~(TiROD), a\ncomprehensive dataset collected using the onboard camera of a small mobile\nrobot, designed to test object detectors across various domains and classes;\n(ii) a benchmark of different continual learning strategies on this dataset\nusing NanoDet, a lightweight object detector. Our results highlight key\nchallenges in developing robust and efficient continual learning strategies for\nobject detectors in tiny robotics.\n","authors":["Francesco Pasti","Riccardo De Monte","Davide Dalle Pezze","Gian Antonio Susto","Nicola Bellotto"],"pdf_url":"https://arxiv.org/pdf/2409.16215v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.03562v1","updated":"2025-03-05T14:49:08Z","published":"2025-03-05T14:49:08Z","title":"Towards Visual Discrimination and Reasoning of Real-World Physical\n  Dynamics: Physics-Grounded Anomaly Detection","summary":"  Humans detect real-world object anomalies by perceiving, interacting, and\nreasoning based on object-conditioned physical knowledge. The long-term goal of\nIndustrial Anomaly Detection (IAD) is to enable machines to autonomously\nreplicate this skill. However, current IAD algorithms are largely developed and\ntested on static, semantically simple datasets, which diverge from real-world\nscenarios where physical understanding and reasoning are essential.To bridge\nthis gap, we introduce the Physics Anomaly Detection (Phys-AD) dataset, the\nfirst large-scale, real-world, physics-grounded video dataset for industrial\nanomaly detection. Collected using a real robot arm and motor, Phys-AD provides\na diverse set of dynamic, semantically rich scenarios. The dataset includes\nmore than 6400 videos across 22 real-world object categories, interacting with\nrobot arms and motors, and exhibits 47 types of anomalies. Anomaly detection in\nPhys-AD requires visual reasoning, combining both physical knowledge and video\ncontent to determine object abnormality.We benchmark state-of-the-art anomaly\ndetection methods under three settings: unsupervised AD, weakly-supervised AD,\nand video-understanding AD, highlighting their limitations in handling\nphysics-grounded anomalies. Additionally, we introduce the Physics Anomaly\nExplanation (PAEval) metric, designed to assess the ability of visual-language\nfoundation models to not only detect anomalies but also provide accurate\nexplanations for their underlying physical causes. Our dataset and benchmark\nwill be publicly available.\n","authors":["Wenqiao Li","Yao Gu","Xintao Chen","Xiaohao Xu","Ming Hu","Xiaonan Huang","Yingna Wu"],"pdf_url":"https://arxiv.org/pdf/2503.03562v1.pdf","comment":"Accepted by CVPR 2025"},{"id":"http://arxiv.org/abs/2411.13982v2","updated":"2025-03-05T14:45:55Z","published":"2024-11-21T09:47:13Z","title":"Safety Without Semantic Disruptions: Editing-free Safe Image Generation\n  via Context-preserving Dual Latent Reconstruction","summary":"  Training multimodal generative models on large, uncurated datasets can result\nin users being exposed to harmful, unsafe and controversial or\nculturally-inappropriate outputs. While model editing has been proposed to\nremove or filter undesirable concepts in embedding and latent spaces, it can\ninadvertently damage learned manifolds, distorting concepts in close semantic\nproximity. We identify limitations in current model editing techniques, showing\nthat even benign, proximal concepts may become misaligned. To address the need\nfor safe content generation, we leverage safe embeddings and a modified\ndiffusion process with tunable weighted summation in the latent space to\ngenerate safer images. Our method preserves global context without compromising\nthe structural integrity of the learned manifolds. We achieve state-of-the-art\nresults on safe image generation benchmarks and offer intuitive control over\nthe level of model safety. We identify trade-offs between safety and\ncensorship, which presents a necessary perspective in the development of\nethical AI models. We will release our code.\n  Keywords: Text-to-Image Models, Generative AI, Safety, Reliability, Model\nEditing\n","authors":["Jordan Vice","Naveed Akhtar","Mubarak Shah","Richard Hartley","Ajmal Mian"],"pdf_url":"https://arxiv.org/pdf/2411.13982v2.pdf","comment":"This research is supported by the NISDRG project #20100007, funded by\n  the Australian Government"},{"id":"http://arxiv.org/abs/2503.03558v1","updated":"2025-03-05T14:45:32Z","published":"2025-03-05T14:45:32Z","title":"High-Quality Virtual Single-Viewpoint Surgical Video: Geometric\n  Autocalibration of Multiple Cameras in Surgical Lights","summary":"  Occlusion-free video generation is challenging due to surgeons' obstructions\nin the camera field of view. Prior work has addressed this issue by installing\nmultiple cameras on a surgical light, hoping some cameras will observe the\nsurgical field with less occlusion. However, this special camera setup poses a\nnew imaging challenge since camera configurations can change every time\nsurgeons move the light, and manual image alignment is required. This paper\nproposes an algorithm to automate this alignment task. The proposed method\ndetects frames where the lighting system moves, realigns them, and selects the\ncamera with the least occlusion. This algorithm results in a stabilized video\nwith less occlusion. Quantitative results show that our method outperforms\nconventional approaches. A user study involving medical doctors also confirmed\nthe superiority of our method.\n","authors":["Yuna Kato","Mariko Isogawa","Shohei Mori","Hideo Saito","Hiroki Kajita","Yoshifumi Takatsume"],"pdf_url":"https://arxiv.org/pdf/2503.03558v1.pdf","comment":"Accepted at MICCAI2023"},{"id":"http://arxiv.org/abs/2503.03556v1","updated":"2025-03-05T14:44:53Z","published":"2025-03-05T14:44:53Z","title":"Afford-X: Generalizable and Slim Affordance Reasoning for Task-oriented\n  Manipulation","summary":"  Object affordance reasoning, the ability to infer object functionalities\nbased on physical properties, is fundamental for task-oriented planning and\nactivities in both humans and Artificial Intelligence (AI). This capability,\nrequired for planning and executing daily activities in a task-oriented manner,\nrelies on commonsense knowledge of object physics and functionalities,\nextending beyond simple object recognition. Current computational models for\naffordance reasoning from perception lack generalizability, limiting their\napplicability in novel scenarios. Meanwhile, comprehensive Large Language\nModels (LLMs) with emerging reasoning capabilities are challenging to deploy on\nlocal devices for task-oriented manipulations. Here, we introduce LVIS-Aff, a\nlarge-scale dataset comprising 1,496 tasks and 119k images, designed to enhance\nthe generalizability of affordance reasoning from perception. Utilizing this\ndataset, we develop Afford-X, an end-to-end trainable affordance reasoning\nmodel that incorporates Verb Attention and Bi-Fusion modules to improve\nmulti-modal understanding. This model achieves up to a 12.1% performance\nimprovement over the best-reported results from non-LLM methods, while also\ndemonstrating a 1.2% enhancement compared to our previous conference paper.\nAdditionally, it maintains a compact 187M parameter size and infers nearly 50\ntimes faster than the GPT-4V API. Our work demonstrates the potential for\nefficient, generalizable affordance reasoning models that can be deployed on\nlocal devices for task-oriented manipulations. We showcase Afford-X's\neffectiveness in enabling task-oriented manipulations for robots across various\ntasks and environments, underscoring its efficiency and broad implications for\nadvancing robotics and AI systems in real-world applications.\n","authors":["Xiaomeng Zhu","Yuyang Li","Leiyao Cui","Pengfei Li","Huan-ang Gao","Yixin Zhu","Hao Zhao"],"pdf_url":"https://arxiv.org/pdf/2503.03556v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2501.09781v2","updated":"2025-03-05T14:44:18Z","published":"2025-01-16T18:59:10Z","title":"VideoWorld: Exploring Knowledge Learning from Unlabeled Videos","summary":"  This work explores whether a deep generative model can learn complex\nknowledge solely from visual input, in contrast to the prevalent focus on\ntext-based models like large language models (LLMs). We develop VideoWorld, an\nauto-regressive video generation model trained on unlabeled video data, and\ntest its knowledge acquisition abilities in video-based Go and robotic control\ntasks. Our experiments reveal two key findings: (1) video-only training\nprovides sufficient information for learning knowledge, including rules,\nreasoning and planning capabilities, and (2) the representation of visual\nchange is crucial for knowledge acquisition. To improve both the efficiency and\nefficacy of this process, we introduce the Latent Dynamics Model (LDM) as a key\ncomponent of VideoWorld. Remarkably, VideoWorld reaches a 5-dan professional\nlevel in the Video-GoBench with just a 300-million-parameter model, without\nrelying on search algorithms or reward mechanisms typical in reinforcement\nlearning. In robotic tasks, VideoWorld effectively learns diverse control\noperations and generalizes across environments, approaching the performance of\noracle models in CALVIN and RLBench. This study opens new avenues for knowledge\nacquisition from visual data, with all code, data, and models open-sourced for\nfurther research.\n","authors":["Zhongwei Ren","Yunchao Wei","Xun Guo","Yao Zhao","Bingyi Kang","Jiashi Feng","Xiaojie Jin"],"pdf_url":"https://arxiv.org/pdf/2501.09781v2.pdf","comment":"Code and models are released at:\n  https://maverickren.github.io/VideoWorld.github.io/"},{"id":"http://arxiv.org/abs/2210.09604v3","updated":"2025-03-05T14:43:59Z","published":"2022-10-18T05:34:58Z","title":"Perceptual Multi-Exposure Fusion","summary":"  As an ever-increasing demand for high dynamic range (HDR) scene shooting,\nmulti-exposure image fusion (MEF) technology has abounded. In recent years,\nmulti-scale exposure fusion approaches based on detail-enhancement have led the\nway for improvement in highlight and shadow details. Most of such methods,\nhowever, are too computationally expensive to be deployed on mobile devices.\nThis paper presents a perceptual multi-exposure fusion method that not just\nensures fine shadow/highlight details but with lower complexity than\ndetailenhanced methods. We analyze the potential defects of three classical\nexposure measures in lieu of using detail-enhancement component and improve two\nof them, namely adaptive Wellexposedness (AWE) and the gradient of color images\n(3-D gradient). AWE designed in YCbCr color space considers the difference\nbetween varying exposure images. 3-D gradient is employed to extract fine\ndetails. We build a large-scale multiexposure benchmark dataset suitable for\nstatic scenes, which contains 167 image sequences all told. Experiments on the\nconstructed dataset demonstrate that the proposed method exceeds existing eight\nstate-of-the-art approaches in terms of visually and MEF-SSIM value. Moreover,\nour approach can achieve a better improvement for current image enhancement\ntechniques, ensuring fine detail in bright light.\n","authors":["Xiaoning Liu"],"pdf_url":"https://arxiv.org/pdf/2210.09604v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2412.07260v2","updated":"2025-03-05T14:40:41Z","published":"2024-12-10T07:42:02Z","title":"DFREC: DeepFake Identity Recovery Based on Identity-aware Masked\n  Autoencoder","summary":"  Recent advances in deepfake forensics have primarily focused on improving the\nclassification accuracy and generalization performance. Despite enormous\nprogress in detection accuracy across a wide variety of forgery algorithms,\nexisting algorithms lack intuitive interpretability and identity traceability\nto help with forensic investigation. In this paper, we introduce a novel\nDeepFake Identity Recovery scheme (DFREC) to fill this gap. DFREC aims to\nrecover the pair of source and target faces from a deepfake image to facilitate\ndeepfake identity tracing and reduce the risk of deepfake attack. It comprises\nthree key components: an Identity Segmentation Module (ISM), a Source Identity\nReconstruction Module (SIRM), and a Target Identity Reconstruction Module\n(TIRM). The ISM segments the input face into distinct source and target face\ninformation, and the SIRM reconstructs the source face and extracts latent\ntarget identity features with the segmented source information. The background\ncontext and latent target identity features are synergetically fused by a\nMasked Autoencoder in the TIRM to reconstruct the target face. We evaluate\nDFREC on six different high-fidelity face-swapping attacks on FaceForensics++,\nCelebaMegaFS and FFHQ-E4S datasets, which demonstrate its superior recovery\nperformance over state-of-the-art deepfake recovery algorithms. In addition,\nDFREC is the only scheme that can recover both pristine source and target faces\ndirectly from the forgery image with high fadelity.\n","authors":["Peipeng Yu","Hui Gao","Jianwei Fei","Zhitao Huang","Zhihua Xia","Chip-Hong Chang"],"pdf_url":"https://arxiv.org/pdf/2412.07260v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.03548v1","updated":"2025-03-05T14:32:32Z","published":"2025-03-05T14:32:32Z","title":"Simulation-Based Performance Evaluation of 3D Object Detection Methods\n  with Deep Learning for a LiDAR Point Cloud Dataset in a SOTIF-related Use\n  Case","summary":"  Safety of the Intended Functionality (SOTIF) addresses sensor performance\nlimitations and deep learning-based object detection insufficiencies to ensure\nthe intended functionality of Automated Driving Systems (ADS). This paper\npresents a methodology examining the adaptability and performance evaluation of\nthe 3D object detection methods on a LiDAR point cloud dataset generated by\nsimulating a SOTIF-related Use Case. The major contributions of this paper\ninclude defining and modelling a SOTIF-related Use Case with 21 diverse weather\nconditions and generating a LiDAR point cloud dataset suitable for application\nof 3D object detection methods. The dataset consists of 547 frames,\nencompassing clear, cloudy, rainy weather conditions, corresponding to\ndifferent times of the day, including noon, sunset, and night. Employing\nMMDetection3D and OpenPCDET toolkits, the performance of State-of-the-Art\n(SOTA) 3D object detection methods is evaluated and compared by testing the\npre-trained Deep Learning (DL) models on the generated dataset using Average\nPrecision (AP) and Recall metrics.\n","authors":["Milin Patel","Rolf Jung"],"pdf_url":"https://arxiv.org/pdf/2503.03548v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2501.13335v2","updated":"2025-03-05T14:32:31Z","published":"2025-01-23T02:31:57Z","title":"Deblur-Avatar: Animatable Avatars from Motion-Blurred Monocular Videos","summary":"  We introduce a novel framework for modeling high-fidelity, animatable 3D\nhuman avatars from motion-blurred monocular video inputs. Motion blur is\nprevalent in real-world dynamic video capture, especially due to human\nmovements in 3D human avatar modeling. Existing methods either (1) assume sharp\nimage inputs, failing to address the detail loss introduced by motion blur, or\n(2) mainly consider blur by camera movements, neglecting the human motion blur\nwhich is more common in animatable avatars. Our proposed approach integrates a\nhuman movement-based motion blur model into 3D Gaussian Splatting (3DGS). By\nexplicitly modeling human motion trajectories during exposure time, we jointly\noptimize the trajectories and 3D Gaussians to reconstruct sharp, high-quality\nhuman avatars. We employ a pose-dependent fusion mechanism to distinguish\nmoving body regions, optimizing both blurred and sharp areas effectively.\nExtensive experiments on synthetic and real-world datasets demonstrate that our\nmethod significantly outperforms existing methods in rendering quality and\nquantitative metrics, producing sharp avatar reconstructions and enabling\nreal-time rendering under challenging motion blur conditions.\n","authors":["Xianrui Luo","Juewen Peng","Zhongang Cai","Lei Yang","Fan Yang","Zhiguo Cao","Guosheng Lin"],"pdf_url":"https://arxiv.org/pdf/2501.13335v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.03543v1","updated":"2025-03-05T14:28:01Z","published":"2025-03-05T14:28:01Z","title":"A self-supervised cyclic neural-analytic approach for novel view\n  synthesis and 3D reconstruction","summary":"  Generating novel views from recorded videos is crucial for enabling\nautonomous UAV navigation. Recent advancements in neural rendering have\nfacilitated the rapid development of methods capable of rendering new\ntrajectories. However, these methods often fail to generalize well to regions\nfar from the training data without an optimized flight path, leading to\nsuboptimal reconstructions. We propose a self-supervised cyclic neural-analytic\npipeline that combines high-quality neural rendering outputs with precise\ngeometric insights from analytical methods. Our solution improves RGB and mesh\nreconstructions for novel view synthesis, especially in undersampled areas and\nregions that are completely different from the training dataset. We use an\neffective transformer-based architecture for image reconstruction to refine and\nadapt the synthesis process, enabling effective handling of novel, unseen poses\nwithout relying on extensive labeled datasets. Our findings demonstrate\nsubstantial improvements in rendering views of novel and also 3D\nreconstruction, which to the best of our knowledge is a first, setting a new\nstandard for autonomous navigation in complex outdoor environments.\n","authors":["Dragos Costea","Alina Marcu","Marius Leordeanu"],"pdf_url":"https://arxiv.org/pdf/2503.03543v1.pdf","comment":"Published in BMVC 2024, 10 pages, 4 figures"},{"id":"http://arxiv.org/abs/2503.02394v2","updated":"2025-03-05T14:25:37Z","published":"2025-03-04T08:35:01Z","title":"BHViT: Binarized Hybrid Vision Transformer","summary":"  Model binarization has made significant progress in enabling real-time and\nenergy-efficient computation for convolutional neural networks (CNN), offering\na potential solution to the deployment challenges faced by Vision Transformers\n(ViTs) on edge devices. However, due to the structural differences between CNN\nand Transformer architectures, simply applying binary CNN strategies to the ViT\nmodels will lead to a significant performance drop. To tackle this challenge,\nwe propose BHViT, a binarization-friendly hybrid ViT architecture and its full\nbinarization model with the guidance of three important observations.\nInitially, BHViT utilizes the local information interaction and hierarchical\nfeature aggregation technique from coarse to fine levels to address redundant\ncomputations stemming from excessive tokens. Then, a novel module based on\nshift operations is proposed to enhance the performance of the binary\nMultilayer Perceptron (MLP) module without significantly increasing\ncomputational overhead. In addition, an innovative attention matrix\nbinarization method based on quantization decomposition is proposed to evaluate\nthe token's importance in the binarized attention matrix. Finally, we propose a\nregularization loss to address the inadequate optimization caused by the\nincompatibility between the weight oscillation in the binary layers and the\nAdam Optimizer. Extensive experimental results demonstrate that our proposed\nalgorithm achieves SOTA performance among binary ViT methods.\n","authors":["Tian Gao","Zhiyuan Zhang","Yu Zhang","Huajun Liu","Kaijie Yin","Chengzhong Xu","Hui Kong"],"pdf_url":"https://arxiv.org/pdf/2503.02394v2.pdf","comment":"Accepted by CVPR2025"},{"id":"http://arxiv.org/abs/2503.03535v1","updated":"2025-03-05T14:18:39Z","published":"2025-03-05T14:18:39Z","title":"Unified Human Localization and Trajectory Prediction with Monocular\n  Vision","summary":"  Conventional human trajectory prediction models rely on clean curated data,\nrequiring specialized equipment or manual labeling, which is often impractical\nfor robotic applications. The existing predictors tend to overfit to clean\nobservation affecting their robustness when used with noisy inputs. In this\nwork, we propose MonoTransmotion (MT), a Transformer-based framework that uses\nonly a monocular camera to jointly solve localization and prediction tasks. Our\nframework has two main modules: Bird's Eye View (BEV) localization and\ntrajectory prediction. The BEV localization module estimates the position of a\nperson using 2D human poses, enhanced by a novel directional loss for smoother\nsequential localizations. The trajectory prediction module predicts future\nmotion from these estimates. We show that by jointly training both tasks with\nour unified framework, our method is more robust in real-world scenarios made\nof noisy inputs. We validate our MT network on both curated and non-curated\ndatasets. On the curated dataset, MT achieves around 12% improvement over\nbaseline models on BEV localization and trajectory prediction. On real-world\nnon-curated dataset, experimental results indicate that MT maintains similar\nperformance levels, highlighting its robustness and generalization capability.\nThe code is available at https://github.com/vita-epfl/MonoTransmotion.\n","authors":["Po-Chien Luan","Yang Gao","Celine Demonsant","Alexandre Alahi"],"pdf_url":"https://arxiv.org/pdf/2503.03535v1.pdf","comment":"ICRA 2025"},{"id":"http://arxiv.org/abs/2411.02951v2","updated":"2025-03-05T14:16:27Z","published":"2024-11-05T09:51:59Z","title":"LDPM: Towards undersampled MRI reconstruction with MR-VAE and Latent\n  Diffusion Prior","summary":"  Diffusion models, as powerful generative models, have found a wide range of\napplications and shown great potential in solving image reconstruction\nproblems. Some works attempted to solve MRI reconstruction with diffusion\nmodels, but these methods operate directly in pixel space, leading to higher\ncomputational costs for optimization and inference. Latent diffusion models,\npre-trained on natural images with rich visual priors, are expected to solve\nthe high computational cost problem in MRI reconstruction by operating in a\nlower-dimensional latent space. However, direct application to MRI\nreconstruction faces three key challenges: (1) absence of explicit control\nmechanisms for medical fidelity, (2) domain gap between natural images and MR\nphysics, and (3) undefined data consistency in latent space. To address these\nchallenges, a novel Latent Diffusion Prior-based undersampled MRI\nreconstruction (LDPM) method is proposed. Our LDPM framework addresses these\nchallenges by: (1) a sketch-guided pipeline with a two-step reconstruction\nstrategy, which balances perceptual quality and anatomical fidelity, (2) an\nMRI-optimized VAE (MR-VAE), which achieves an improvement of approximately 3.92\ndB in PSNR for undersampled MRI reconstruction compared to that with SD-VAE\n\\cite{sd}, and (3) Dual-Stage Sampler, a modified version of spaced DDPM\nsampler, which enforces high-fidelity reconstruction in the latent space.\nExperiments on the fastMRI dataset\\cite{fastmri} demonstrate the\nstate-of-the-art performance of the proposed method and its robustness across\nvarious scenarios. The effectiveness of each module is also verified through\nablation experiments.\n","authors":["Xingjian Tang","Jingwei Guan","Linge Li","Ran Shi","Youmei Zhang","Mengye Lyu","Li Yan"],"pdf_url":"https://arxiv.org/pdf/2411.02951v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2409.16502v2","updated":"2025-03-05T14:11:44Z","published":"2024-09-24T23:18:32Z","title":"GSplatLoc: Grounding Keypoint Descriptors into 3D Gaussian Splatting for\n  Improved Visual Localization","summary":"  Although various visual localization approaches exist, such as scene\ncoordinate regression and camera pose regression, these methods often struggle\nwith optimization complexity or limited accuracy. To address these challenges,\nwe explore the use of novel view synthesis techniques, particularly 3D Gaussian\nSplatting (3DGS), which enables the compact encoding of both 3D geometry and\nscene appearance. We propose a two-stage procedure that integrates dense and\nrobust keypoint descriptors from the lightweight XFeat feature extractor into\n3DGS, enhancing performance in both indoor and outdoor environments. The coarse\npose estimates are directly obtained via 2D-3D correspondences between the 3DGS\nrepresentation and query image descriptors. In the second stage, the initial\npose estimate is refined by minimizing the rendering-based photometric warp\nloss. Benchmarking on widely used indoor and outdoor datasets demonstrates\nimprovements over recent neural rendering-based localization methods, such as\nNeRFMatch and PNeRFLoc.\n","authors":["Gennady Sidorov","Malik Mohrat","Denis Gridusov","Ruslan Rakhimov","Sergey Kolyubin"],"pdf_url":"https://arxiv.org/pdf/2409.16502v2.pdf","comment":"Project website at https://gsplatloc.github.io/"},{"id":"http://arxiv.org/abs/2503.03528v1","updated":"2025-03-05T14:11:13Z","published":"2025-03-05T14:11:13Z","title":"AdaSin: Enhancing Hard Sample Metrics with Dual Adaptive Penalty for\n  Face Recognition","summary":"  In recent years, the emergence of deep convolutional neural networks has\npositioned face recognition as a prominent research focus in computer vision.\nTraditional loss functions, such as margin-based, hard-sample mining-based, and\nhybrid approaches, have achieved notable performance improvements, with some\nleveraging curriculum learning to optimize training. However, these methods\noften fall short in effectively quantifying the difficulty of hard samples. To\naddress this, we propose Adaptive Sine (AdaSin) loss function, which introduces\nthe sine of the angle between a sample's embedding feature and its ground-truth\nclass center as a novel difficulty metric. This metric enables precise and\neffective penalization of hard samples. By incorporating curriculum learning,\nthe model dynamically adjusts classification boundaries across different\ntraining stages. Unlike previous adaptive-margin loss functions, AdaSin\nintroduce a dual adaptive penalty, applied to both the positive and negative\ncosine similarities of hard samples. This design imposes stronger constraints,\nenhancing intra-class compactness and inter-class separability. The combination\nof the dual adaptive penalty and curriculum learning is guided by a\nwell-designed difficulty metric. It enables the model to focus more effectively\non hard samples in later training stages, and lead to the extraction of highly\ndiscriminative face features. Extensive experiments across eight benchmarks\ndemonstrate that AdaSin achieves superior accuracy compared to other\nstate-of-the-art methods.\n","authors":["Qiqi Guo","Zhuowen Zheng","Guanghua Yang","Zhiquan Liu","Xiaofan Li","Jianqing Li","Jinyu Tian","Xueyuan Gong"],"pdf_url":"https://arxiv.org/pdf/2503.03528v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2412.18783v2","updated":"2025-03-05T14:11:02Z","published":"2024-12-25T05:19:52Z","title":"ArtNVG: Content-Style Separated Artistic Neighboring-View Gaussian\n  Stylization","summary":"  As demand from the film and gaming industries for 3D scenes with target\nstyles grows, the importance of advanced 3D stylization techniques increases.\nHowever, recent methods often struggle to maintain local consistency in color\nand texture throughout stylized scenes, which is essential for maintaining\naesthetic coherence. To solve this problem, this paper introduces ArtNVG, an\ninnovative 3D stylization framework that efficiently generates stylized 3D\nscenes by leveraging reference style images. Built on 3D Gaussian Splatting\n(3DGS), ArtNVG achieves rapid optimization and rendering while upholding high\nreconstruction quality. Our framework realizes high-quality 3D stylization by\nincorporating two pivotal techniques: Content-Style Separated Control and\nAttention-based Neighboring-View Alignment. Content-Style Separated Control\nuses the CSGO model and the Tile ControlNet to decouple the content and style\ncontrol, reducing risks of information leakage. Concurrently, Attention-based\nNeighboring-View Alignment ensures consistency of local colors and textures\nacross neighboring views, significantly improving visual quality. Extensive\nexperiments validate that ArtNVG surpasses existing methods, delivering\nsuperior results in content preservation, style alignment, and local\nconsistency.\n","authors":["Zixiao Gu","Mengtian Li","Ruhua Chen","Zhongxia Ji","Sichen Guo","Zhenye Zhang","Guangnan Ye","Zuo Hu"],"pdf_url":"https://arxiv.org/pdf/2412.18783v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.03519v1","updated":"2025-03-05T14:03:34Z","published":"2025-03-05T14:03:34Z","title":"Do ImageNet-trained models learn shortcuts? The impact of frequency\n  shortcuts on generalization","summary":"  Frequency shortcuts refer to specific frequency patterns that models heavily\nrely on for correct classification. Previous studies have shown that models\ntrained on small image datasets often exploit such shortcuts, potentially\nimpairing their generalization performance. However, existing methods for\nidentifying frequency shortcuts require expensive computations and become\nimpractical for analyzing models trained on large datasets. In this work, we\npropose the first approach to more efficiently analyze frequency shortcuts at a\nlarger scale. We show that both CNN and transformer models learn frequency\nshortcuts on ImageNet. We also expose that frequency shortcut solutions can\nyield good performance on out-of-distribution (OOD) test sets which largely\nretain texture information. However, these shortcuts, mostly aligned with\ntexture patterns, hinder model generalization on rendition-based OOD test sets.\nThese observations suggest that current OOD evaluations often overlook the\nimpact of frequency shortcuts on model generalization. Future benchmarks could\nthus benefit from explicitly assessing and accounting for these shortcuts to\nbuild models that generalize across a broader range of OOD scenarios.\n","authors":["Shunxin Wang","Raymond Veldhuis","Nicola Strisciuglio"],"pdf_url":"https://arxiv.org/pdf/2503.03519v1.pdf","comment":"received at CVPR2025"},{"id":"http://arxiv.org/abs/2402.09444v3","updated":"2025-03-05T14:02:10Z","published":"2024-01-31T15:37:12Z","title":"Multimodal Action Quality Assessment","summary":"  Action quality assessment (AQA) is to assess how well an action is performed.\nPrevious works perform modelling by only the use of visual information,\nignoring audio information. We argue that although AQA is highly dependent on\nvisual information, the audio is useful complementary information for improving\nthe score regression accuracy, especially for sports with background music,\nsuch as figure skating and rhythmic gymnastics. To leverage multimodal\ninformation for AQA, i.e., RGB, optical flow and audio information, we propose\na Progressive Adaptive Multimodal Fusion Network (PAMFN) that separately models\nmodality-specific information and mixed-modality information. Our model\nconsists of with three modality-specific branches that independently explore\nmodality-specific information and a mixed-modality branch that progressively\naggregates the modality-specific information from the modality-specific\nbranches. To build the bridge between modality-specific branches and the\nmixed-modality branch, three novel modules are proposed. First, a\nModality-specific Feature Decoder module is designed to selectively transfer\nmodality-specific information to the mixed-modality branch. Second, when\nexploring the interaction between modality-specific information, we argue that\nusing an invariant multimodal fusion policy may lead to suboptimal results, so\nas to take the potential diversity in different parts of an action into\nconsideration. Therefore, an Adaptive Fusion Module is proposed to learn\nadaptive multimodal fusion policies in different parts of an action. This\nmodule consists of several FusionNets for exploring different multimodal fusion\nstrategies and a PolicyNet for deciding which FusionNets are enabled. Third, a\nmodule called Cross-modal Feature Decoder is designed to transfer cross-modal\nfeatures generated by Adaptive Fusion Module to the mixed-modality branch.\n","authors":["Ling-An Zeng","Wei-Shi Zheng"],"pdf_url":"https://arxiv.org/pdf/2402.09444v3.pdf","comment":"IEEE Transactions on Image Processing 2024"},{"id":"http://arxiv.org/abs/2503.03507v1","updated":"2025-03-05T13:55:26Z","published":"2025-03-05T13:55:26Z","title":"Mineral segmentation using electron microscope images and spectral\n  sampling through multimodal graph neural networks","summary":"  We propose a novel Graph Neural Network-based method for segmentation based\non data fusion of multimodal Scanning Electron Microscope (SEM) images. In most\ncases, Backscattered Electron (BSE) images obtained using SEM do not contain\nsufficient information for mineral segmentation. Therefore, imaging is often\ncomplemented with point-wise Energy-Dispersive X-ray Spectroscopy (EDS)\nspectral measurements that provide highly accurate information about the\nchemical composition but that are time-consuming to acquire. This motivates the\nuse of sparse spectral data in conjunction with BSE images for mineral\nsegmentation. The unstructured nature of the spectral data makes most\ntraditional image fusion techniques unsuitable for BSE-EDS fusion. We propose\nusing graph neural networks to fuse the two modalities and segment the mineral\nphases simultaneously. Our results demonstrate that providing EDS data for as\nfew as 1% of BSE pixels produces accurate segmentation, enabling rapid analysis\nof mineral samples. The proposed data fusion pipeline is versatile and can be\nadapted to other domains that involve image data and point-wise measurements.\n","authors":["Samuel Repka","Boek Reich","Fedor Zolotarev","Tuomas Eerola","Pavel Zemk"],"pdf_url":"https://arxiv.org/pdf/2503.03507v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.03501v1","updated":"2025-03-05T13:47:02Z","published":"2025-03-05T13:47:02Z","title":"CarGait: Cross-Attention based Re-ranking for Gait recognition","summary":"  Gait recognition is a computer vision task that identifies individuals based\non their walking patterns. Gait recognition performance is commonly evaluated\nby ranking a gallery of candidates and measuring the accuracy at the top\nRank-$K$. Existing models are typically single-staged, i.e. searching for the\nprobe's nearest neighbors in a gallery using a single global feature\nrepresentation. Although these models typically excel at retrieving the correct\nidentity within the top-$K$ predictions, they struggle when hard negatives\nappear in the top short-list, leading to relatively low performance at the\nhighest ranks (e.g., Rank-1). In this paper, we introduce CarGait, a\nCross-Attention Re-ranking method for gait recognition, that involves\nre-ordering the top-$K$ list leveraging the fine-grained correlations between\npairs of gait sequences through cross-attention between gait strips. This\nre-ranking scheme can be adapted to existing single-stage models to enhance\ntheir final results. We demonstrate the capabilities of CarGait by extensive\nexperiments on three common gait datasets, Gait3D, GREW, and OU-MVLP, and seven\ndifferent gait models, showing consistent improvements in Rank-1,5 accuracy,\nsuperior results over existing re-ranking methods, and strong baselines.\n","authors":["Gavriel Habib","Noa Barzilay","Or Shimshi","Rami Ben-Ari","Nir Darshan"],"pdf_url":"https://arxiv.org/pdf/2503.03501v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2405.02077v4","updated":"2025-03-05T13:43:07Z","published":"2024-05-03T13:10:16Z","title":"MVP-Shot: Multi-Velocity Progressive-Alignment Framework for Few-Shot\n  Action Recognition","summary":"  Recent few-shot action recognition (FSAR) methods typically perform semantic\nmatching on learned discriminative features to achieve promising performance.\nHowever, most FSAR methods focus on single-scale (e.g., frame-level,\nsegment-level, etc) feature alignment, which ignores that human actions with\nthe same semantic may appear at different velocities. To this end, we develop a\nnovel Multi-Velocity Progressive-alignment (MVP-Shot) framework to\nprogressively learn and align semantic-related action features at\nmulti-velocity levels. Concretely, a Multi-Velocity Feature Alignment (MVFA)\nmodule is designed to measure the similarity between features from support and\nquery videos with different velocity scales and then merge all similarity\nscores in a residual fashion. To avoid the multiple velocity features deviating\nfrom the underlying motion semantic, our proposed Progressive Semantic-Tailored\nInteraction (PSTI) module injects velocity-tailored text information into the\nvideo feature via feature interaction on channel and temporal domains at\ndifferent velocities. The above two modules compensate for each other to make\nmore accurate query sample predictions under the few-shot settings.\nExperimental results show our method outperforms current state-of-the-art\nmethods on multiple standard few-shot benchmarks (i.e., HMDB51, UCF101,\nKinetics, and SSv2-small).\n","authors":["Hongyu Qu","Rui Yan","Xiangbo Shu","Hailiang Gao","Peng Huang","Guo-Sen Xie"],"pdf_url":"https://arxiv.org/pdf/2405.02077v4.pdf","comment":"Accepted to TMM 2025"},{"id":"http://arxiv.org/abs/2402.12185v5","updated":"2025-03-05T13:41:21Z","published":"2024-02-19T14:48:23Z","title":"ChartX & ChartVLM: A Versatile Benchmark and Foundation Model for\n  Complicated Chart Reasoning","summary":"  Recently, many versatile Multi-modal Large Language Models (MLLMs) have\nemerged continuously. However, their capacity to query information depicted in\nvisual charts and engage in reasoning based on the queried contents remains\nunder-explored. In this paper, to comprehensively and rigorously benchmark the\nability of the off-the-shelf MLLMs in the chart domain, we construct ChartX, a\nmulti-modal evaluation set covering 18 chart types, 7 chart tasks, 22\ndisciplinary topics, and high-quality chart data. Besides, we develop ChartVLM\nto offer a new perspective on handling multi-modal tasks that strongly depend\non interpretable patterns, such as reasoning tasks in the field of charts or\ngeometric images. We evaluate the chart-related ability of mainstream MLLMs and\nour ChartVLM on the proposed ChartX evaluation set. Extensive experiments\ndemonstrate that ChartVLM surpasses both versatile and chart-related large\nmodels, achieving results comparable to GPT-4V. We believe that our study can\npave the way for further exploration in creating a more comprehensive chart\nevaluation set and developing more interpretable multi-modal models. Both\nChartX and ChartVLM are available at:\nhttps://github.com/Alpha-Innovator/ChartVLM\n","authors":["Renqiu Xia","Bo Zhang","Hancheng Ye","Xiangchao Yan","Qi Liu","Hongbin Zhou","Zijun Chen","Peng Ye","Min Dou","Botian Shi","Junchi Yan","Yu Qiao"],"pdf_url":"https://arxiv.org/pdf/2402.12185v5.pdf","comment":"Code and dataset are available for downloading at:\n  https://github.com/Alpha-Innovator/ChartVLM 26 pages, 15 figures"},{"id":"http://arxiv.org/abs/2503.03492v1","updated":"2025-03-05T13:32:49Z","published":"2025-03-05T13:32:49Z","title":"Find First, Track Next: Decoupling Identification and Propagation in\n  Referring Video Object Segmentation","summary":"  Referring video object segmentation aims to segment and track a target object\nin a video using a natural language prompt. Existing methods typically fuse\nvisual and textual features in a highly entangled manner, processing\nmulti-modal information together to generate per-frame masks. However, this\napproach often struggles with ambiguous target identification, particularly in\nscenes with multiple similar objects, and fails to ensure consistent mask\npropagation across frames. To address these limitations, we introduce\nFindTrack, a novel decoupled framework that separates target identification\nfrom mask propagation. FindTrack first adaptively selects a key frame by\nbalancing segmentation confidence and vision-text alignment, establishing a\nrobust reference for the target object. This reference is then utilized by a\ndedicated propagation module to track and segment the object across the entire\nvideo. By decoupling these processes, FindTrack effectively reduces ambiguities\nin target association and enhances segmentation consistency. We demonstrate\nthat FindTrack outperforms existing methods on public benchmarks.\n","authors":["Suhwan Cho","Seunghoon Lee","Minhyeok Lee","Jungho Lee","Sangyoun Lee"],"pdf_url":"https://arxiv.org/pdf/2503.03492v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2404.11098v4","updated":"2025-03-05T13:28:29Z","published":"2024-04-17T06:32:42Z","title":"LAPTOP-Diff: Layer Pruning and Normalized Distillation for Compressing\n  Diffusion Models","summary":"  In the era of AIGC, the demand for low-budget or even on-device applications\nof diffusion models emerged. In terms of compressing the Stable Diffusion\nmodels (SDMs), several approaches have been proposed, and most of them\nleveraged the handcrafted layer removal methods to obtain smaller U-Nets, along\nwith knowledge distillation to recover the network performance. However, such a\nhandcrafting manner of layer removal is inefficient and lacks scalability and\ngeneralization, and the feature distillation employed in the retraining phase\nfaces an imbalance issue that a few numerically significant feature loss terms\ndominate over others throughout the retraining process. To this end, we\nproposed the layer pruning and normalized distillation for compressing\ndiffusion models (LAPTOP-Diff). We, 1) introduced the layer pruning method to\ncompress SDM's U-Net automatically and proposed an effective one-shot pruning\ncriterion whose one-shot performance is guaranteed by its good additivity\nproperty, surpassing other layer pruning and handcrafted layer removal methods,\n2) proposed the normalized feature distillation for retraining, alleviated the\nimbalance issue. Using the proposed LAPTOP-Diff, we compressed the U-Nets of\nSDXL and SDM-v1.5 for the most advanced performance, achieving a minimal 4.0%\ndecline in PickScore at a pruning ratio of 50% while the comparative methods'\nminimal PickScore decline is 8.2%.\n","authors":["Dingkun Zhang","Sijia Li","Chen Chen","Qingsong Xie","Haonan Lu"],"pdf_url":"https://arxiv.org/pdf/2404.11098v4.pdf","comment":null},{"id":"http://arxiv.org/abs/2412.18355v2","updated":"2025-03-05T13:25:09Z","published":"2024-12-24T11:35:40Z","title":"Handling Spatial-Temporal Data Heterogeneity for Federated Continual\n  Learning via Tail Anchor","summary":"  Federated continual learning (FCL) allows each client to continually update\nits knowledge from task streams, enhancing the applicability of federated\nlearning in real-world scenarios. However, FCL needs to address not only\nspatial data heterogeneity between clients but also temporal data heterogeneity\nbetween tasks. In this paper, empirical experiments demonstrate that such\ninput-level heterogeneity significantly affects the model's internal parameters\nand outputs, leading to severe spatial-temporal catastrophic forgetting of\nlocal and previous knowledge. To this end, we propose Federated Tail Anchor\n(FedTA) to mix trainable Tail Anchor with the frozen output features to adjust\ntheir position in the feature space, thereby overcoming parameter-forgetting\nand output-forgetting. Three novel components are also included: Input\nEnhancement for improving the performance of pre-trained models on downstream\ntasks; Selective Input Knowledge Fusion for fusion of heterogeneous local\nknowledge on the server; and Best Global Prototype Selection for finding the\nbest anchor point for each class in the feature space. Extensive experiments\ndemonstrate that FedTA not only outperforms existing FCL methods but also\neffectively preserves the relative positions of features.\n","authors":["Hao Yu","Xin Yang","Le Zhang","Hanlin Gu","Tianrui Li","Lixin Fan","Qiang Yang"],"pdf_url":"https://arxiv.org/pdf/2412.18355v2.pdf","comment":"This paper is accepted by CVPR 2025"},{"id":"http://arxiv.org/abs/2503.03479v1","updated":"2025-03-05T13:16:26Z","published":"2025-03-05T13:16:26Z","title":"Feature Point Extraction for Extra-Affine Image","summary":"  The issue concerning the significant decline in the stability of feature\nextraction for images subjected to large-angle affine transformations, where\nthe angle exceeds 50 degrees, still awaits a satisfactory solution. Even ASIFT,\nwhich is built upon SIFT and entails a considerable number of image comparisons\nsimulated by affine transformations, inevitably exhibits the drawbacks of being\ntime-consuming and imposing high demands on memory usage. And the stability of\nfeature extraction drops rapidly under large-view affine transformations.\nConsequently, we propose a method that represents an improvement over ASIFT. On\nthe premise of improving the precision and maintaining the affine invariance,\nit currently ranks as the fastest feature extraction method for extra-affine\nimages that we know of at present. Simultaneously, the stability of feature\nextraction regarding affine transformation images has been approximated to the\nmaximum limits. Both the angle between the shooting direction and the normal\ndirection of the photographed object (absolute tilt angle), and the shooting\ntransformation angle between two images (transition tilt angle) are close to 90\ndegrees. The central idea of the method lies in obtaining the optimal parameter\nset by simulating affine transformation with the reference image. And the\nsimulated affine transformation is reproduced by combining it with the Lanczos\ninterpolation based on the optimal parameter set. Subsequently, it is combined\nwith ORB, which exhibits excellent real-time performance for rapid orientation\nbinary description. Moreover, a scale parameter simulation is introduced to\nfurther augment the operational efficiency.\n","authors":["Tao Wang","Yinghui Wang","Yanxing Liang","Liangyi Huang","Jinlong Yang","Wei Li","Xiaojuan Ning"],"pdf_url":"https://arxiv.org/pdf/2503.03479v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.03475v1","updated":"2025-03-05T13:10:11Z","published":"2025-03-05T13:10:11Z","title":"Bridging Synthetic-to-Real Gaps: Frequency-Aware Perturbation and\n  Selection for Single-shot Multi-Parametric Mapping Reconstruction","summary":"  Data-centric artificial intelligence (AI) has remarkably advanced medical\nimaging, with emerging methods using synthetic data to address data scarcity\nwhile introducing synthetic-to-real gaps. Unsupervised domain adaptation (UDA)\nshows promise in ground truth-scarce tasks, but its application in\nreconstruction remains underexplored. Although multiple overlapping-echo\ndetachment (MOLED) achieves ultra-fast multi-parametric reconstruction,\nextending its application to various clinical scenarios, the quality suffers\nfrom deficiency in mitigating the domain gap, difficulty in maintaining\nstructural integrity, and inadequacy in ensuring mapping accuracy. To resolve\nthese issues, we proposed frequency-aware perturbation and selection (FPS),\ncomprising Wasserstein distance-modulated frequency-aware perturbation (WDFP)\nand hierarchical frequency-aware selection network (HFSNet), which integrates\nfrequency-aware adaptive selection (FAS), compact FAS (cFAS) and feature-aware\narchitecture integration (FAI). Specifically, perturbation activates\ndomain-invariant feature learning within uncertainty, while selection refines\noptimal solutions within perturbation, establishing a robust and closed-loop\nlearning pathway. Extensive experiments on synthetic data, along with diverse\nreal clinical cases from 5 healthy volunteers, 94 ischemic stroke patients, and\n46 meningioma patients, demonstrate the superiority and clinical applicability\nof FPS. Furthermore, FPS is applied to diffusion tensor imaging (DTI),\nunderscoring its versatility and potential for broader medical applications.\nThe code is available at https://github.com/flyannie/FPS.\n","authors":["Linyu Fan","Che Wang","Ming Ye","Qizhi Yang","Zejun Wu","Xinghao Ding","Yue Huang","Jianfeng Bao","Shuhui Cai","Congbo Cai"],"pdf_url":"https://arxiv.org/pdf/2503.03475v1.pdf","comment":"This work will be submitted to the IEEE for possible publication"},{"id":"http://arxiv.org/abs/2503.03465v1","updated":"2025-03-05T12:56:33Z","published":"2025-03-05T12:56:33Z","title":"DTU-Net: A Multi-Scale Dilated Transformer Network for Nonlinear\n  Hyperspectral Unmixing","summary":"  Transformers have shown significant success in hyperspectral unmixing (HU).\nHowever, challenges remain. While multi-scale and long-range spatial\ncorrelations are essential in unmixing tasks, current Transformer-based\nunmixing networks, built on Vision Transformer (ViT) or Swin-Transformer,\nstruggle to capture them effectively. Additionally, current Transformer-based\nunmixing networks rely on the linear mixing model, which lacks the flexibility\nto accommodate scenarios where nonlinear effects are significant. To address\nthese limitations, we propose a multi-scale Dilated Transformer-based unmixing\nnetwork for nonlinear HU (DTU-Net). The encoder employs two branches. The first\none performs multi-scale spatial feature extraction using Multi-Scale Dilated\nAttention (MSDA) in the Dilated Transformer, which varies dilation rates across\nattention heads to capture long-range and multi-scale spatial correlations. The\nsecond one performs spectral feature extraction utilizing 3D-CNNs with channel\nattention. The outputs from both branches are then fused to integrate\nmulti-scale spatial and spectral information, which is subsequently transformed\nto estimate the abundances. The decoder is designed to accommodate both linear\nand nonlinear mixing scenarios. Its interpretability is enhanced by explicitly\nmodeling the relationships between endmembers, abundances, and nonlinear\ncoefficients in accordance with the polynomial post-nonlinear mixing model\n(PPNMM). Experiments on synthetic and real datasets validate the effectiveness\nof the proposed DTU-Net compared to PPNMM-derived methods and several advanced\nunmixing networks.\n","authors":["ChenTong Wang","Jincheng Gao","Fei Zhu","Abderrahim Halimi","C'edric Richard"],"pdf_url":"https://arxiv.org/pdf/2503.03465v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.10860v2","updated":"2025-03-05T12:41:05Z","published":"2024-03-16T08:57:00Z","title":"Sim2Real within 5 Minutes: Efficient Domain Transfer with Stylized\n  Gaussian Splatting for Endoscopic Images","summary":"  Robot assisted endoluminal intervention is an emerging technique for both\nbenign and malignant luminal lesions. With vision-based navigation, when\ncombined with pre-operative imaging data as priors, it is possible to recover\nposition and pose of the endoscope without the need of additional sensors. In\npractice, however, aligning pre-operative and intra-operative domains is\ncomplicated by significant texture differences. Although methods such as style\ntransfer can be used to address this issue, they require large datasets from\nboth source and target domains with prolonged training times. This paper\nproposes an efficient domain transfer method based on stylized Gaussian\nsplatting, only requiring a few of real images (10 images) with very fast\ntraining time. Specifically, the transfer process includes two phases. In the\nfirst phase, the 3D models reconstructed from CT scans are represented as\ndifferential Gaussian point clouds. In the second phase, only color appearance\nrelated parameters are optimized to transfer the style and preserve the visual\ncontent. A novel structure consistency loss is applied to latent features and\ndepth levels to enhance the stability of the transferred images. Detailed\nvalidation was performed to demonstrate the performance advantages of the\nproposed method compared to that of the current state-of-the-art, highlighting\nthe potential for intra-operative surgical navigation.\n","authors":["Junyang Wu","Yun Gu","Guang-Zhong Yang"],"pdf_url":"https://arxiv.org/pdf/2403.10860v2.pdf","comment":"Accepted by ICRA 2025"},{"id":"http://arxiv.org/abs/2503.03453v1","updated":"2025-03-05T12:35:54Z","published":"2025-03-05T12:35:54Z","title":"Active Learning for Deep Learning-Based Hemodynamic Parameter Estimation","summary":"  Hemodynamic parameters such as pressure and wall shear stress play an\nimportant role in diagnosis, prognosis, and treatment planning in\ncardiovascular diseases. These parameters can be accurately computed using\ncomputational fluid dynamics (CFD), but CFD is computationally intensive.\nHence, deep learning methods have been adopted as a surrogate to rapidly\nestimate CFD outcomes. A drawback of such data-driven models is the need for\ntime-consuming reference CFD simulations for training. In this work, we\nintroduce an active learning framework to reduce the number of CFD simulations\nrequired for the training of surrogate models, lowering the barriers to their\ndeployment in new applications. We propose three distinct querying strategies\nto determine for which unlabeled samples CFD simulations should be obtained.\nThese querying strategies are based on geometrical variance, ensemble\nuncertainty, and adherence to the physics governing fluid dynamics. We\nbenchmark these methods on velocity field estimation in synthetic coronary\nartery bifurcations and find that they allow for substantial reductions in\nannotation cost. Notably, we find that our strategies reduce the number of\nsamples required by up to 50% and make the trained models more robust to\ndifficult cases. Our results show that active learning is a feasible strategy\nto increase the potential of deep learning-based CFD surrogates.\n","authors":["Patryk Rygiel","Julian Suk","Kak Khee Yeung","Christoph Brune","Jelmer M. Wolterink"],"pdf_url":"https://arxiv.org/pdf/2503.03453v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2502.05503v3","updated":"2025-03-05T12:27:57Z","published":"2025-02-08T09:31:26Z","title":"A Physical Coherence Benchmark for Evaluating Video Generation Models\n  via Optical Flow-guided Frame Prediction","summary":"  Recent advances in video generation models demonstrate their potential as\nworld simulators, but they often struggle with videos deviating from physical\nlaws, a key concern overlooked by most text-to-video benchmarks. We introduce a\nbenchmark designed specifically to assess the Physical Coherence of generated\nvideos, PhyCoBench. Our benchmark includes 120 prompts covering 7 categories of\nphysical principles, capturing key physical laws observable in video content.\nWe evaluated four state-of-the-art (SoTA) T2V models on PhyCoBench and\nconducted manual assessments. Additionally, we propose an automated evaluation\nmodel: PhyCoPredictor, a diffusion model that generates optical flow and video\nframes in a cascade manner. Through a consistency evaluation comparing\nautomated and manual sorting, the experimental results show that PhyCoPredictor\ncurrently aligns most closely with human evaluation. Therefore, it can\neffectively evaluate the physical coherence of videos, providing insights for\nfuture model optimization. Our benchmark, including physical coherence prompts,\nthe automatic evaluation tool PhyCoPredictor, and the generated video dataset,\nhas been released on GitHub at https://github.com/Jeckinchen/PhyCoBench.\n","authors":["Yongfan Chen","Xiuwen Zhu","Tianyu Li"],"pdf_url":"https://arxiv.org/pdf/2502.05503v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.03446v1","updated":"2025-03-05T12:25:22Z","published":"2025-03-05T12:25:22Z","title":"Biased Heritage: How Datasets Shape Models in Facial Expression\n  Recognition","summary":"  In recent years, the rapid development of artificial intelligence (AI)\nsystems has raised concerns about our ability to ensure their fairness, that\nis, how to avoid discrimination based on protected characteristics such as\ngender, race, or age. While algorithmic fairness is well-studied in simple\nbinary classification tasks on tabular data, its application to complex,\nreal-world scenarios-such as Facial Expression Recognition (FER)-remains\nunderexplored. FER presents unique challenges: it is inherently multiclass, and\nbiases emerge across intersecting demographic variables, each potentially\ncomprising multiple protected groups. We present a comprehensive framework to\nanalyze bias propagation from datasets to trained models in image-based FER\nsystems, while introducing new bias metrics specifically designed for\nmulticlass problems with multiple demographic groups. Our methodology studies\nbias propagation by (1) inducing controlled biases in FER datasets, (2)\ntraining models on these biased datasets, and (3) analyzing the correlation\nbetween dataset bias metrics and model fairness notions. Our findings reveal\nthat stereotypical biases propagate more strongly to model predictions than\nrepresentational biases, suggesting that preventing emotion-specific\ndemographic patterns should be prioritized over general demographic balance in\nFER datasets. Additionally, we observe that biased datasets lead to reduced\nmodel accuracy, challenging the assumed fairness-accuracy trade-off.\n","authors":["Iris Dominguez-Catena","Daniel Paternain","Mikel Galar","MaryBeth Defrance","Maarten Buyl","Tijl De Bie"],"pdf_url":"https://arxiv.org/pdf/2503.03446v1.pdf","comment":"17 pages, 7 figures"},{"id":"http://arxiv.org/abs/2503.03437v1","updated":"2025-03-05T12:12:51Z","published":"2025-03-05T12:12:51Z","title":"JamMa: Ultra-lightweight Local Feature Matching with Joint Mamba","summary":"  Existing state-of-the-art feature matchers capture long-range dependencies\nwith Transformers but are hindered by high spatial complexity, leading to\ndemanding training and highlatency inference. Striking a better balance between\nperformance and efficiency remains a challenge in feature matching. Inspired by\nthe linear complexity O(N) of Mamba, we propose an ultra-lightweight\nMamba-based matcher, named JamMa, which converges on a single GPU and achieves\nan impressive performance-efficiency balance in inference. To unlock the\npotential of Mamba for feature matching, we propose Joint Mamba with a\nscan-merge strategy named JEGO, which enables: (1) Joint scan of two images to\nachieve high-frequency mutual interaction, (2) Efficient scan with skip steps\nto reduce sequence length, (3) Global receptive field, and (4) Omnidirectional\nfeature representation. With the above properties, the JEGO strategy\nsignificantly outperforms the scan-merge strategies proposed in VMamba and\nEVMamba in the feature matching task. Compared to attention-based sparse and\nsemi-dense matchers, JamMa demonstrates a superior balance between performance\nand efficiency, delivering better performance with less than 50% of the\nparameters and FLOPs.\n","authors":["Xiaoyong Lu","Songlin Du"],"pdf_url":"https://arxiv.org/pdf/2503.03437v1.pdf","comment":"CVPR 2025, Project page: https://leoluxxx.github.io/JamMa-page/"},{"id":"http://arxiv.org/abs/2503.03430v1","updated":"2025-03-05T12:02:04Z","published":"2025-03-05T12:02:04Z","title":"CoSDH: Communication-Efficient Collaborative Perception via\n  Supply-Demand Awareness and Intermediate-Late Hybridization","summary":"  Multi-agent collaborative perception enhances perceptual capabilities by\nutilizing information from multiple agents and is considered a fundamental\nsolution to the problem of weak single-vehicle perception in autonomous\ndriving. However, existing collaborative perception methods face a dilemma\nbetween communication efficiency and perception accuracy. To address this\nissue, we propose a novel communication-efficient collaborative perception\nframework based on supply-demand awareness and intermediate-late hybridization,\ndubbed as \\mymethodname. By modeling the supply-demand relationship between\nagents, the framework refines the selection of collaboration regions, reducing\nunnecessary communication cost while maintaining accuracy. In addition, we\ninnovatively introduce the intermediate-late hybrid collaboration mode, where\nlate-stage collaboration compensates for the performance degradation in\ncollaborative perception under low communication bandwidth. Extensive\nexperiments on multiple datasets, including both simulated and real-world\nscenarios, demonstrate that \\mymethodname~ achieves state-of-the-art detection\naccuracy and optimal bandwidth trade-offs, delivering superior detection\nprecision under real communication bandwidths, thus proving its effectiveness\nand practical applicability. The code will be released at\nhttps://github.com/Xu2729/CoSDH.\n","authors":["Junhao Xu","Yanan Zhang","Zhi Cai","Di Huang"],"pdf_url":"https://arxiv.org/pdf/2503.03430v1.pdf","comment":"Accepted at CVPR 2025"},{"id":"http://arxiv.org/abs/2306.17567v3","updated":"2025-03-05T11:52:00Z","published":"2023-06-30T11:40:35Z","title":"Counting Guidance for High Fidelity Text-to-Image Synthesis","summary":"  Recently, there have been significant improvements in the quality and\nperformance of text-to-image generation, largely due to the impressive results\nattained by diffusion models. However, text-to-image diffusion models sometimes\nstruggle to create high-fidelity content for the given input prompt. One\nspecific issue is their difficulty in generating the precise number of objects\nspecified in the text prompt. For example, when provided with the prompt \"five\napples and ten lemons on a table,\" images generated by diffusion models often\ncontain an incorrect number of objects. In this paper, we present a method to\nimprove diffusion models so that they accurately produce the correct object\ncount based on the input prompt. We adopt a counting network that performs\nreference-less class-agnostic counting for any given image. We calculate the\ngradients of the counting network and refine the predicted noise for each step.\nTo address the presence of multiple types of objects in the prompt, we utilize\nnovel attention map guidance to obtain high-quality masks for each object.\nFinally, we guide the denoising process using the calculated gradients for each\nobject. Through extensive experiments and evaluation, we demonstrate that the\nproposed method significantly enhances the fidelity of diffusion models with\nrespect to object count. Code is available at\nhttps://github.com/furiosa-ai/counting-guidance.\n","authors":["Wonjun Kang","Kevin Galim","Hyung Il Koo","Nam Ik Cho"],"pdf_url":"https://arxiv.org/pdf/2306.17567v3.pdf","comment":"Accepted at WACV 2025 (Oral). Code is available at\n  https://github.com/furiosa-ai/counting-guidance"},{"id":"http://arxiv.org/abs/2503.03422v1","updated":"2025-03-05T11:49:32Z","published":"2025-03-05T11:49:32Z","title":"Automatic Drywall Analysis for Progress Tracking and Quality Control in\n  Construction","summary":"  Digitalization in the construction industry has become essential, enabling\ncentralized, easy access to all relevant information of a building. Automated\nsystems can facilitate the timely and resource-efficient documentation of\nchanges, which is crucial for key processes such as progress tracking and\nquality control. This paper presents a method for image-based automated drywall\nanalysis enabling construction progress and quality assessment through on-site\ncamera systems. Our proposed solution integrates a deep learning-based instance\nsegmentation model to detect and classify various drywall elements with an\nanalysis module to cluster individual wall segments, estimate camera\nperspective distortions, and apply the corresponding corrections. This system\nextracts valuable information from images, enabling more accurate progress\ntracking and quality assessment on construction sites. Our main contributions\ninclude a fully automated pipeline for drywall analysis, improving instance\nsegmentation accuracy through architecture modifications and targeted data\naugmentation, and a novel algorithm to extract important information from the\nsegmentation results. Our modified model, enhanced with data augmentation,\nachieves significantly higher accuracy compared to other architectures,\noffering more detailed and precise information than existing approaches.\nCombined with the proposed drywall analysis steps, it enables the reliable\nautomation of construction progress and quality assessment.\n","authors":["Mariusz Trzeciakiewicz","Aleixo Cambeiro Barreiro","Niklas Gard","Anna Hilsmann","Peter Eisert"],"pdf_url":"https://arxiv.org/pdf/2503.03422v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2412.03603v5","updated":"2025-03-05T11:48:15Z","published":"2024-12-03T23:52:37Z","title":"HunyuanVideo: A Systematic Framework For Large Video Generative Models","summary":"  Recent advancements in video generation have significantly impacted daily\nlife for both individuals and industries. However, the leading video generation\nmodels remain closed-source, resulting in a notable performance gap between\nindustry capabilities and those available to the public. In this report, we\nintroduce HunyuanVideo, an innovative open-source video foundation model that\ndemonstrates performance in video generation comparable to, or even surpassing,\nthat of leading closed-source models. HunyuanVideo encompasses a comprehensive\nframework that integrates several key elements, including data curation,\nadvanced architectural design, progressive model scaling and training, and an\nefficient infrastructure tailored for large-scale model training and inference.\nAs a result, we successfully trained a video generative model with over 13\nbillion parameters, making it the largest among all open-source models. We\nconducted extensive experiments and implemented a series of targeted designs to\nensure high visual quality, motion dynamics, text-video alignment, and advanced\nfilming techniques. According to evaluations by professionals, HunyuanVideo\noutperforms previous state-of-the-art models, including Runway Gen-3, Luma 1.6,\nand three top-performing Chinese video generative models. By releasing the code\nfor the foundation model and its applications, we aim to bridge the gap between\nclosed-source and open-source communities. This initiative will empower\nindividuals within the community to experiment with their ideas, fostering a\nmore dynamic and vibrant video generation ecosystem. The code is publicly\navailable at https://github.com/Tencent/HunyuanVideo.\n","authors":["Weijie Kong","Qi Tian","Zijian Zhang","Rox Min","Zuozhuo Dai","Jin Zhou","Jiangfeng Xiong","Xin Li","Bo Wu","Jianwei Zhang","Kathrina Wu","Qin Lin","Junkun Yuan","Yanxin Long","Aladdin Wang","Andong Wang","Changlin Li","Duojun Huang","Fang Yang","Hao Tan","Hongmei Wang","Jacob Song","Jiawang Bai","Jianbing Wu","Jinbao Xue","Joey Wang","Kai Wang","Mengyang Liu","Pengyu Li","Shuai Li","Weiyan Wang","Wenqing Yu","Xinchi Deng","Yang Li","Yi Chen","Yutao Cui","Yuanbo Peng","Zhentao Yu","Zhiyu He","Zhiyong Xu","Zixiang Zhou","Zunnan Xu","Yangyu Tao","Qinglin Lu","Songtao Liu","Dax Zhou","Hongfa Wang","Yong Yang","Di Wang","Yuhong Liu","Jie Jiang","Caesar Zhong"],"pdf_url":"https://arxiv.org/pdf/2412.03603v5.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.01505v4","updated":"2025-03-05T11:39:35Z","published":"2024-03-03T13:08:32Z","title":"SCott: Accelerating Diffusion Models with Stochastic Consistency\n  Distillation","summary":"  The iterative sampling procedure employed by diffusion models (DMs) often\nleads to significant inference latency. To address this, we propose Stochastic\nConsistency Distillation (SCott) to enable accelerated text-to-image\ngeneration, where high-quality and diverse generations can be achieved within\njust 2-4 sampling steps. In contrast to vanilla consistency distillation (CD)\nwhich distills the ordinary differential equation solvers-based sampling\nprocess of a pre-trained teacher model into a student, SCott explores the\npossibility and validates the efficacy of integrating stochastic differential\nequation (SDE) solvers into CD to fully unleash the potential of the teacher.\nSCott is augmented with elaborate strategies to control the noise strength and\nsampling process of the SDE solver. An adversarial loss is further incorporated\nto strengthen the consistency constraints in rare sampling steps. Empirically,\non the MSCOCO-2017 5K dataset with a Stable Diffusion-V1.5 teacher, SCott\nachieves an FID of 21.9 with 2 sampling steps, surpassing that of the 1-step\nInstaFlow (23.4) and the 4-step UFOGen (22.1). Moreover, SCott can yield more\ndiverse samples than other consistency models for high-resolution image\ngeneration, with up to 16% improvement in a qualified metric.\n","authors":["Hongjian Liu","Qingsong Xie","TianXiang Ye","Zhijie Deng","Chen Chen","Shixiang Tang","Xueyang Fu","Haonan Lu","Zheng-jun Zha"],"pdf_url":"https://arxiv.org/pdf/2403.01505v4.pdf","comment":"22 pages, 16 figures"},{"id":"http://arxiv.org/abs/2503.03410v1","updated":"2025-03-05T11:39:15Z","published":"2025-03-05T11:39:15Z","title":"Augmentation-Based Deep Learning for Identification of Circulating Tumor\n  Cells","summary":"  Circulating tumor cells (CTCs) are crucial biomarkers in liquid biopsy,\noffering a noninvasive tool for cancer patient management. However, their\nidentification remains particularly challenging due to their limited number and\nheterogeneity. Labeling samples for contrast limits the generalization of\nfluorescence-based methods across different hospital datasets. Analyzing\nsingle-cell images enables detailed assessment of cell morphology, subcellular\nstructures, and phenotypic variations, often hidden in clustered images.\nDeveloping a method based on bright-field single-cell analysis could overcome\nthese limitations. CTCs can be isolated using an unbiased workflow combining\nParsortix technology, which selects cells based on size and deformability, with\nDEPArray technology, enabling precise visualization and selection of single\ncells. Traditionally, DEPArray-acquired digital images are manually analyzed,\nmaking the process time-consuming and prone to variability. In this study, we\npresent a Deep Learning-based classification pipeline designed to distinguish\nCTCs from leukocytes in blood samples, aimed to enhance diagnostic accuracy and\noptimize clinical workflows. Our approach employs images from the bright-field\nchannel acquired through DEPArray technology leveraging a ResNet-based CNN. To\nimprove model generalization, we applied three types of data augmentation\ntechniques and incorporated fluorescence (DAPI) channel images into the\ntraining phase, allowing the network to learn additional CTC-specific features.\nNotably, only bright-field images have been used for testing, ensuring the\nmodel's ability to identify CTCs without relying on fluorescence markers. The\nproposed model achieved an F1-score of 0.798, demonstrating its capability to\ndistinguish CTCs from leukocytes. These findings highlight the potential of DL\nin refining CTC analysis and advancing liquid biopsy applications.\n","authors":["Martina Russo","Giulia Bertolini","Vera Cappelletti","Cinzia De Marco","Serena Di Cosimo","Petra Pai","Nadia Brancati"],"pdf_url":"https://arxiv.org/pdf/2503.03410v1.pdf","comment":"20 pages, 4 figures, 3 tables"},{"id":"http://arxiv.org/abs/2503.03395v1","updated":"2025-03-05T11:19:17Z","published":"2025-03-05T11:19:17Z","title":"AI-Driven Multi-Stage Computer Vision System for Defect Detection in\n  Laser-Engraved Industrial Nameplates","summary":"  Automated defect detection in industrial manufacturing is essential for\nmaintaining product quality and minimizing production errors. In air disc brake\nmanufacturing, ensuring the precision of laser-engraved nameplates is crucial\nfor accurate product identification and quality control. Engraving errors, such\nas misprints or missing characters, can compromise both aesthetics and\nfunctionality, leading to material waste and production delays. This paper\npresents a proof of concept for an AI-driven computer vision system that\ninspects and verifies laser-engraved nameplates, detecting defects in logos and\nalphanumeric strings. The system integrates object detection using YOLOv7,\noptical character recognition (OCR) with Tesseract, and anomaly detection\nthrough a residual variational autoencoder (ResVAE) along with other computer\nvision methods to enable comprehensive inspections at multiple stages.\nExperimental results demonstrate the system's effectiveness, achieving 91.33%\naccuracy and 100% recall, ensuring that defective nameplates are consistently\ndetected and addressed. This solution highlights the potential of AI-driven\nvisual inspection to enhance quality control, reduce manual inspection efforts,\nand improve overall manufacturing efficiency.\n","authors":["Adhish Anitha Vilasan","Stephan Jger","Noah Klarmann"],"pdf_url":"https://arxiv.org/pdf/2503.03395v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2412.01243v3","updated":"2025-03-05T11:17:18Z","published":"2024-12-02T08:05:26Z","title":"Schedule On the Fly: Diffusion Time Prediction for Faster and Better\n  Image Generation","summary":"  Diffusion and flow matching models have achieved remarkable success in\ntext-to-image generation. However, these models typically rely on the\npredetermined denoising schedules for all prompts. The multi-step reverse\ndiffusion process can be regarded as a kind of chain-of-thought for generating\nhigh-quality images step by step. Therefore, diffusion models should reason for\neach instance to adaptively determine the optimal noise schedule, achieving\nhigh generation quality with sampling efficiency. In this paper, we introduce\nthe Time Prediction Diffusion Model (TPDM) for this. TPDM employs a\nplug-and-play Time Prediction Module (TPM) that predicts the next noise level\nbased on current latent features at each denoising step. We train the TPM using\nreinforcement learning to maximize a reward that encourages high final image\nquality while penalizing excessive denoising steps. With such an adaptive\nscheduler, TPDM not only generates high-quality images that are aligned closely\nwith human preferences but also adjusts diffusion time and the number of\ndenoising steps on the fly, enhancing both performance and efficiency. With\nStable Diffusion 3 Medium architecture, TPDM achieves an aesthetic score of\n5.44 and a human preference score (HPS) of 29.59, while using around 50% fewer\ndenoising steps to achieve better performance.\n","authors":["Zilyu Ye","Zhiyang Chen","Tiancheng Li","Zemin Huang","Weijian Luo","Guo-Jun Qi"],"pdf_url":"https://arxiv.org/pdf/2412.01243v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2408.14153v2","updated":"2025-03-05T11:15:39Z","published":"2024-08-26T09:55:34Z","title":"Explaining Vision-Language Similarities in Dual Encoders with\n  Feature-Pair Attributions","summary":"  Dual encoder architectures like CLIP models map two types of inputs into a\nshared embedding space and predict similarities between them. Despite their\nsuccess, it is, however, not understood how these models compare their two\ninputs. Common first-order feature-attribution methods can only provide limited\ninsights into dual-encoders since their predictions depend on\nfeature-interactions rather than on individual features. In this paper, we\nfirst derive a second-order method enabling the attribution of predictions by\nany differentiable dual encoder onto feature-interactions between its inputs.\nSecond, we apply our method to CLIP models and show that they learn\nfine-grained correspondences between parts of captions and regions in images.\nThey match objects across input modes also account for mismatches. This\nvisual-linguistic grounding ability, however, varies heavily between object\nclasses and exhibits pronounced out-of-domain effects. We can identify\nindividual errors as well as systematic failure categories including object\ncoverage, unusual scenes and correlated contexts.\n","authors":["Lucas Mller","Pascal Tilli","Ngoc Thang Vu","Sebastian Pad"],"pdf_url":"https://arxiv.org/pdf/2408.14153v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.03370v1","updated":"2025-03-05T10:46:03Z","published":"2025-03-05T10:46:03Z","title":"MIAdapt: Source-free Few-shot Domain Adaptive Object Detection for\n  Microscopic Images","summary":"  Existing generic unsupervised domain adaptation approaches require access to\nboth a large labeled source dataset and a sufficient unlabeled target dataset\nduring adaptation. However, collecting a large dataset, even if unlabeled, is a\nchallenging and expensive endeavor, especially in medical imaging. In addition,\nconstraints such as privacy issues can result in cases where source data is\nunavailable. Taking in consideration these challenges, we propose MIAdapt, an\nadaptive approach for Microscopic Imagery Adaptation as a solution for\nSource-free Few-shot Domain Adaptive Object detection (SF-FSDA). We also define\ntwo competitive baselines (1) Faster-FreeShot and (2) MT-FreeShot. Extensive\nexperiments on the challenging M5-Malaria and Raabin-WBC datasets validate the\neffectiveness of MIAdapt. Without using any image from the source domain\nMIAdapt surpasses state-of-the-art source-free UDA (SF-UDA) methods by +21.3%\nmAP and few-shot domain adaptation (FSDA) approaches by +4.7% mAP on\nRaabin-WBC. Our code and models will be publicly available.\n","authors":["Nimra Dilawar","Sara Nadeem","Javed Iqbal","Waqas Sultani","Mohsen Ali"],"pdf_url":"https://arxiv.org/pdf/2503.03370v1.pdf","comment":"Under Review"},{"id":"http://arxiv.org/abs/2503.03367v1","updated":"2025-03-05T10:43:01Z","published":"2025-03-05T10:43:01Z","title":"Top-K Maximum Intensity Projection Priors for 3D Liver Vessel\n  Segmentation","summary":"  Liver-vessel segmentation is an essential task in the pre-operative planning\nof liver resection. State-of-the-art 2D or 3D convolution-based methods\nfocusing on liver vessel segmentation on 2D CT cross-sectional views, which do\nnot take into account the global liver-vessel topology. To maintain this global\nvessel topology, we rely on the underlying physics used in the CT\nreconstruction process, and apply this to liver-vessel segmentation.\nConcretely, we introduce the concept of top-k maximum intensity projections,\nwhich mimics the CT reconstruction by replacing the integral along each\nprojection direction, with keeping the top-k maxima along each projection\ndirection. We use these top-k maximum projections to condition a diffusion\nmodel and generate 3D liver-vessel trees. We evaluate our 3D liver-vessel\nsegmentation on the 3D-ircadb-01 dataset, and achieve the highest Dice\ncoefficient, intersection-over-union (IoU), and Sensitivity scores compared to\nprior work.\n","authors":["Xiaotong Zhang","Alexander Broersen","Gonnie CM van Erp","Silvia L. Pintea","Jouke Dijkstra"],"pdf_url":"https://arxiv.org/pdf/2503.03367v1.pdf","comment":"Accepted in 2025 IEEE International Symposium on Biomedical Imaging\n  (ISBI 2025)"},{"id":"http://arxiv.org/abs/2503.03365v1","updated":"2025-03-05T10:42:41Z","published":"2025-03-05T10:42:41Z","title":"TopoMortar: A dataset to evaluate image segmentation methods focused on\n  topology accuracy","summary":"  We present TopoMortar, a brick wall dataset that is the first dataset\nspecifically designed to evaluate topology-focused image segmentation methods,\nsuch as topology loss functions. TopoMortar enables to investigate in two ways\nwhether methods incorporate prior topological knowledge. First, by eliminating\nchallenges seen in real-world data, such as small training set, noisy labels,\nand out-of-distribution test-set images, that, as we show, impact the\neffectiveness of topology losses. Second, by allowing to assess in the same\ndataset topology accuracy across dataset challenges, isolating dataset-related\neffects from the effect of incorporating prior topological knowledge. In these\ntwo experiments, it is deliberately difficult to improve topology accuracy\nwithout actually using topology information, thus, permitting to attribute an\nimprovement in topology accuracy to the incorporation of prior topological\nknowledge. To this end, TopoMortar includes three types of labels (accurate,\nnoisy, pseudo-labels), two fixed training sets (large and small), and\nin-distribution and out-of-distribution test-set images. We compared eight loss\nfunctions on TopoMortar, and we found that clDice achieved the most\ntopologically accurate segmentations, Skeleton Recall loss performed best\nparticularly with noisy labels, and the relative advantageousness of the other\nloss functions depended on the experimental setting. Additionally, we show that\nsimple methods, such as data augmentation and self-distillation, can elevate\nCross entropy Dice loss to surpass most topology loss functions, and that those\nsimple methods can enhance topology loss functions as well. clDice and Skeleton\nRecall loss, both skeletonization-based loss functions, were also the fastest\nto train, making this type of loss function a promising research direction.\nTopoMortar and our code can be found at https://github.com/jmlipman/TopoMortar\n","authors":["Juan Miguel Valverde","Motoya Koga","Nijihiko Otsuka","Anders Bjorholm Dahl"],"pdf_url":"https://arxiv.org/pdf/2503.03365v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.03355v1","updated":"2025-03-05T10:37:51Z","published":"2025-03-05T10:37:51Z","title":"Video Super-Resolution: All You Need is a Video Diffusion Model","summary":"  We present a generic video super-resolution algorithm in this paper, based on\nthe Diffusion Posterior Sampling framework with an unconditional video\ngeneration model in latent space. The video generation model, a diffusion\ntransformer, functions as a space-time model. We argue that a powerful model,\nwhich learns the physics of the real world, can easily handle various kinds of\nmotion patterns as prior knowledge, thus eliminating the need for explicit\nestimation of optical flows or motion parameters for pixel alignment.\nFurthermore, a single instance of the proposed video diffusion transformer\nmodel can adapt to different sampling conditions without re-training. Due to\nlimited computational resources and training data, our experiments provide\nempirical evidence of the algorithm's strong super-resolution capabilities\nusing synthetic data.\n","authors":["Zhihao Zhan","Wang Pang","Xiang Zhu","Yechao Bai"],"pdf_url":"https://arxiv.org/pdf/2503.03355v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2312.07226v2","updated":"2025-03-05T10:24:18Z","published":"2023-12-12T12:41:35Z","title":"Super-Resolution on Rotationally Scanned Photoacoustic Microscopy Images\n  Incorporating Scanning Prior","summary":"  Photoacoustic Microscopy (PAM) images integrating the advantages of optical\ncontrast and acoustic resolution have been widely used in brain studies.\nHowever, there exists a trade-off between scanning speed and image resolution.\nCompared with traditional raster scanning, rotational scanning provides good\nopportunities for fast PAM imaging by optimizing the scanning mechanism.\nRecently, there is a trend to incorporate deep learning into the scanning\nprocess to further increase the scanning speed.Yet, most such attempts are\nperformed for raster scanning while those for rotational scanning are\nrelatively rare. In this study, we propose a novel and well-performing\nsuper-resolution framework for rotational scanning-based PAM imaging. To\neliminate adjacent rows' displacements due to subject motion or high-frequency\nscanning distortion,we introduce a registration module across odd and even rows\nin the preprocessing and incorporate displacement degradation in the training.\nBesides, gradient-based patch selection is proposed to increase the probability\nof blood vessel patches being selected for training. A Transformer-based\nnetwork with a global receptive field is applied for better performance.\nExperimental results on both synthetic and real datasets demonstrate the\neffectiveness and generalizability of our proposed framework for rotationally\nscanned PAM images'super-resolution, both quantitatively and qualitatively.\nCode is available at https://github.com/11710615/PAMSR.git.\n","authors":["Kai Pan","Linyang Li","Li Lin","Pujin Cheng","Junyan Lyu","Lei Xi","Xiaoyin Tang"],"pdf_url":"https://arxiv.org/pdf/2312.07226v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2412.07804v3","updated":"2025-03-05T10:09:25Z","published":"2024-12-09T09:04:02Z","title":"XLSTM-HVED: Cross-Modal Brain Tumor Segmentation and MRI Reconstruction\n  Method Using Vision XLSTM and Heteromodal Variational Encoder-Decoder","summary":"  Neurogliomas are among the most aggressive forms of cancer, presenting\nconsiderable challenges in both treatment and monitoring due to their\nunpredictable biological behavior. Magnetic resonance imaging (MRI) is\ncurrently the preferred method for diagnosing and monitoring gliomas. However,\nthe lack of specific imaging techniques often compromises the accuracy of tumor\nsegmentation during the imaging process. To address this issue, we introduce\nthe XLSTM-HVED model. This model integrates a hetero-modal encoder-decoder\nframework with the Vision XLSTM module to reconstruct missing MRI modalities.\nBy deeply fusing spatial and temporal features, it enhances tumor segmentation\nperformance. The key innovation of our approach is the Self-Attention\nVariational Encoder (SAVE) module, which improves the integration of modal\nfeatures. Additionally, it optimizes the interaction of features between\nsegmentation and reconstruction tasks through the Squeeze-Fusion-Excitation\nCross Awareness (SFECA) module. Our experiments using the BraTS 2024 dataset\ndemonstrate that our model significantly outperforms existing advanced methods\nin handling cases where modalities are missing. Our source code is available at\nhttps://github.com/Quanato607/XLSTM-HVED.\n","authors":["Shenghao Zhu","Yifei Chen","Shuo Jiang","Weihong Chen","Chang Liu","Yuanhan Wang","Xu Chen","Yifan Ke","Feiwei Qin","Changmiao Wang","Zhu Zhu"],"pdf_url":"https://arxiv.org/pdf/2412.07804v3.pdf","comment":"5 pages, 2 figures"},{"id":"http://arxiv.org/abs/2503.03330v1","updated":"2025-03-05T10:03:21Z","published":"2025-03-05T10:03:21Z","title":"Automated Attendee Recognition System for Large-Scale Social Events or\n  Conference Gathering","summary":"  Manual attendance tracking at large-scale events, such as marriage functions\nor conferences, is often inefficient and prone to human error. To address this\nchallenge, we propose an automated, cloud-based attendance tracking system that\nuses cameras mounted at the entrance and exit gates. The mounted cameras\ncontinuously capture video and send the video data to cloud services to perform\nreal-time face detection and recognition. Unlike existing solutions, our system\naccurately identifies attendees even when they are not looking directly at the\ncamera, allowing natural movements, such as looking around or talking while\nwalking. To the best of our knowledge, this is the first system to achieve high\nrecognition rates under such dynamic conditions. Our system demonstrates\noverall 90% accuracy, with each video frame processed in 5 seconds, ensuring\nreal time operation without frame loss. In addition, notifications are sent\npromptly to security personnel within the same latency. This system achieves\n100% accuracy for individuals without facial obstructions and successfully\nrecognizes all attendees appearing within the camera's field of view, providing\na robust solution for attendee recognition in large-scale social events.\n","authors":["Dhruv Motwani","Ankush Tyagi","Vipul Dabhi","Harshadkumar Prajapati"],"pdf_url":"https://arxiv.org/pdf/2503.03330v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.03329v1","updated":"2025-03-05T10:02:35Z","published":"2025-03-05T10:02:35Z","title":"Deep Learning-Based Diffusion MRI Tractography: Integrating Spatial and\n  Anatomical Information","summary":"  Diffusion MRI tractography technique enables non-invasive visualization of\nthe white matter pathways in the brain. It plays a crucial role in neuroscience\nand clinical fields by facilitating the study of brain connectivity and\nneurological disorders. However, the accuracy of reconstructed tractograms has\nbeen a longstanding challenge. Recently, deep learning methods have been\napplied to improve tractograms for better white matter coverage, but often\ncomes at the expense of generating excessive false-positive connections. This\nis largely due to their reliance on local information to predict long range\nstreamlines. To improve the accuracy of streamline propagation predictions, we\nintroduce a novel deep learning framework that integrates image-domain spatial\ninformation and anatomical information along tracts, with the former extracted\nthrough convolutional layers and the later modeled via a Transformer-decoder.\nAdditionally, we employ a weighted loss function to address fiber class\nimbalance encountered during training. We evaluate the proposed method on the\nsimulated ISMRM 2015 Tractography Challenge dataset, achieving a valid\nstreamline rate of 66.2%, white matter coverage of 63.8%, and successfully\nreconstructing 24 out of 25 bundles. Furthermore, on the multi-site\nTractoinferno dataset, the proposed method demonstrates its ability to handle\nvarious diffusion MRI acquisition schemes, achieving a 5.7% increase in white\nmatter coverage and a 4.1% decrease in overreach compared to RNN-based methods.\n","authors":["Yiqiong Yang","Yitian Yuan","Baoxing Ren","Ye Wu","Yanqiu Feng","Xinyuan Zhang"],"pdf_url":"https://arxiv.org/pdf/2503.03329v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.03327v1","updated":"2025-03-05T10:00:32Z","published":"2025-03-05T10:00:32Z","title":"ScaleFusionNet: Transformer-Guided Multi-Scale Feature Fusion for Skin\n  Lesion Segmentation","summary":"  Melanoma is a malignant tumor originating from skin cell lesions. Accurate\nand efficient segmentation of skin lesions is essential for quantitative\nmedical analysis but remains challenging. To address this, we propose\nScaleFusionNet, a segmentation model that integrates Cross-Attention\nTransformer Module (CATM) and AdaptiveFusionBlock to enhance feature extraction\nand fusion. The model employs a hybrid architecture encoder that effectively\ncaptures both local and global features. We introduce CATM, which utilizes Swin\nTransformer Blocks and Cross Attention Fusion (CAF) to adaptively refine\nencoder-decoder feature fusion, reducing semantic gaps and improving\nsegmentation accuracy. Additionally, the AdaptiveFusionBlock is improved by\nintegrating adaptive multi-scale fusion, where Swin Transformer-based attention\ncomplements deformable convolution-based multi-scale feature extraction. This\nenhancement refines lesion boundaries and preserves fine-grained details.\nScaleFusionNet achieves Dice scores of 92.94% and 91.65% on ISIC-2016 and\nISIC-2018 datasets, respectively, demonstrating its effectiveness in skin\nlesion analysis. Our code implementation is publicly available at GitHub.\n","authors":["Saqib Qamar","Syed Furqan Qadri","Roobaea Alroobaea","Majed Alsafyani","Abdullah M. Baqasah"],"pdf_url":"https://arxiv.org/pdf/2503.03327v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.03325v1","updated":"2025-03-05T09:59:23Z","published":"2025-03-05T09:59:23Z","title":"Golden Cudgel Network for Real-Time Semantic Segmentation","summary":"  Recent real-time semantic segmentation models, whether single-branch or\nmulti-branch, achieve good performance and speed. However, their speed is\nlimited by multi-path blocks, and some depend on high-performance teacher\nmodels for training. To overcome these issues, we propose Golden Cudgel Network\n(GCNet). Specifically, GCNet uses vertical multi-convolutions and horizontal\nmulti-paths for training, which are reparameterized into a single convolution\nfor inference, optimizing both performance and speed. This design allows GCNet\nto self-enlarge during training and self-contract during inference, effectively\nbecoming a \"teacher model\" without needing external ones. Experimental results\nshow that GCNet outperforms existing state-of-the-art models in terms of\nperformance and speed on the Cityscapes, CamVid, and Pascal VOC 2012 datasets.\nThe code is available at https://github.com/gyyang23/GCNet.\n","authors":["Guoyu Yang","Yuan Wang","Daming Shi","Yanzhong Wang"],"pdf_url":"https://arxiv.org/pdf/2503.03325v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.03321v1","updated":"2025-03-05T09:55:07Z","published":"2025-03-05T09:55:07Z","title":"See What You Are Told: Visual Attention Sink in Large Multimodal Models","summary":"  Large multimodal models (LMMs) \"see\" images by leveraging the attention\nmechanism between text and visual tokens in the transformer decoder. Ideally,\nthese models should focus on key visual information relevant to the text token.\nHowever, recent findings indicate that LMMs have an extraordinary tendency to\nconsistently allocate high attention weights to specific visual tokens, even\nwhen these tokens are irrelevant to the corresponding text. In this study, we\ninvestigate the property behind the appearance of these irrelevant visual\ntokens and examine their characteristics. Our findings show that this behavior\narises due to the massive activation of certain hidden state dimensions, which\nresembles the attention sink found in language models. Hence, we refer to this\nphenomenon as the visual attention sink. In particular, our analysis reveals\nthat removing the irrelevant visual sink tokens does not impact model\nperformance, despite receiving high attention weights. Consequently, we recycle\nthe attention to these tokens as surplus resources, redistributing the\nattention budget to enhance focus on the image. To achieve this, we introduce\nVisual Attention Redistribution (VAR), a method that redistributes attention in\nimage-centric heads, which we identify as innately focusing on visual\ninformation. VAR can be seamlessly applied across different LMMs to improve\nperformance on a wide range of tasks, including general vision-language tasks,\nvisual hallucination tasks, and vision-centric tasks, all without the need for\nadditional training, models, or inference steps. Experimental results\ndemonstrate that VAR enables LMMs to process visual information more\neffectively by adjusting their internal attention mechanisms, offering a new\ndirection to enhancing the multimodal capabilities of LMMs.\n","authors":["Seil Kang","Jinyeong Kim","Junhyeok Kim","Seong Jae Hwang"],"pdf_url":"https://arxiv.org/pdf/2503.03321v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2407.09510v5","updated":"2025-03-05T09:44:52Z","published":"2024-06-17T11:43:38Z","title":"3DGS.zip: A survey on 3D Gaussian Splatting Compression Methods","summary":"  3D Gaussian Splatting (3DGS) has emerged as a cutting-edge technique for\nreal-time radiance field rendering, offering state-of-the-art performance in\nterms of both quality and speed. 3DGS models a scene as a collection of\nthree-dimensional Gaussians, with additional attributes optimized to conform to\nthe scene's geometric and visual properties. Despite its advantages in\nrendering speed and image fidelity, 3DGS is limited by its significant storage\nand memory demands. These high demands make 3DGS impractical for mobile devices\nor headsets, reducing its applicability in important areas of computer\ngraphics. To address these challenges and advance the practicality of 3DGS,\nthis survey provides a comprehensive and detailed examination of compression\nand compaction techniques developed to make 3DGS more efficient. We classify\nexisting methods into two categories: compression, which focuses on reducing\nfile size, and compaction, which aims to minimize the number of Gaussians. Both\nmethods aim to maintain or improve quality, each by minimizing its respective\nattribute: file size for compression and Gaussian count for compaction. We\nintroduce the basic mathematical concepts underlying the analyzed methods, as\nwell as key implementation details and design choices. Our report thoroughly\ndiscusses similarities and differences among the methods, as well as their\nrespective advantages and disadvantages. We establish a consistent framework\nfor comparing the surveyed methods based on key performance metrics and\ndatasets. Specifically, since these methods have been developed in parallel and\nover a short period of time, currently, no comprehensive comparison exists.\nThis survey, for the first time, presents a unified framework to evaluate 3DGS\ncompression techniques. We maintain a website that will be regularly updated\nwith emerging methods: https://w-m.github.io/3dgs-compression-survey/ .\n","authors":["Milena T. Bagdasarian","Paul Knoll","Yi-Hsin Li","Florian Barthel","Anna Hilsmann","Peter Eisert","Wieland Morgenstern"],"pdf_url":"https://arxiv.org/pdf/2407.09510v5.pdf","comment":"3D Gaussian Splatting compression survey; 3DGS compression; updated\n  discussion; new approaches added; new illustrations"},{"id":"http://arxiv.org/abs/2503.03307v1","updated":"2025-03-05T09:39:51Z","published":"2025-03-05T09:39:51Z","title":"Full-DoF Egomotion Estimation for Event Cameras Using Geometric Solvers","summary":"  For event cameras, current sparse geometric solvers for egomotion estimation\nassume that the rotational displacements are known, such as those provided by\nan IMU. Thus, they can only recover the translational motion parameters.\nRecovering full-DoF motion parameters using a sparse geometric solver is a more\nchallenging task, and has not yet been investigated. In this paper, we propose\nseveral solvers to estimate both rotational and translational velocities within\na unified framework. Our method leverages event manifolds induced by line\nsegments. The problem formulations are based on either an incidence relation\nfor lines or a novel coplanarity relation for normal vectors. We demonstrate\nthe possibility of recovering full-DoF egomotion parameters for both angular\nand linear velocities without requiring extra sensor measurements or motion\npriors. To achieve efficient optimization, we exploit the Adam framework with a\nfirst-order approximation of rotations for quick initialization. Experiments on\nboth synthetic and real-world data demonstrate the effectiveness of our method.\nThe code is available at https://github.com/jizhaox/relpose-event.\n","authors":["Ji Zhao","Banglei Guan","Zibin Liu","Laurent Kneip"],"pdf_url":"https://arxiv.org/pdf/2503.03307v1.pdf","comment":"Accepted by IEEE/CVF Conference on Computer Vision and Pattern\n  Recognition (CVPR), 2025"},{"id":"http://arxiv.org/abs/2503.03299v1","updated":"2025-03-05T09:30:49Z","published":"2025-03-05T09:30:49Z","title":"Label-Efficient LiDAR Semantic Segmentation with 2D-3D Vision\n  Transformer Adapters","summary":"  LiDAR semantic segmentation models are typically trained from random\ninitialization as universal pre-training is hindered by the lack of large,\ndiverse datasets. Moreover, most point cloud segmentation architectures\nincorporate custom network layers, limiting the transferability of advances\nfrom vision-based architectures. Inspired by recent advances in universal\nfoundation models, we propose BALViT, a novel approach that leverages frozen\nvision models as amodal feature encoders for learning strong LiDAR encoders.\nSpecifically, BALViT incorporates both range-view and bird's-eye-view LiDAR\nencoding mechanisms, which we combine through a novel 2D-3D adapter. While the\nrange-view features are processed through a frozen image backbone, our\nbird's-eye-view branch enhances them through multiple cross-attention\ninteractions. Thereby, we continuously improve the vision network with\ndomain-dependent knowledge, resulting in a strong label-efficient LiDAR\nencoding mechanism. Extensive evaluations of BALViT on the SemanticKITTI and\nnuScenes benchmarks demonstrate that it outperforms state-of-the-art methods on\nsmall data regimes. We make the code and models publicly available at:\nhttp://balvit.cs.uni-freiburg.de.\n","authors":["Julia Hindel","Rohit Mohan","Jelena Bratulic","Daniele Cattaneo","Thomas Brox","Abhinav Valada"],"pdf_url":"https://arxiv.org/pdf/2503.03299v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.03294v1","updated":"2025-03-05T09:18:27Z","published":"2025-03-05T09:18:27Z","title":"Interactive Segmentation and Report Generation for CT Images","summary":"  Automated CT report generation plays a crucial role in improving diagnostic\naccuracy and clinical workflow efficiency. However, existing methods lack\ninterpretability and impede patient-clinician understanding, while their static\nnature restricts radiologists from dynamically adjusting assessments during\nimage review. Inspired by interactive segmentation techniques, we propose a\nnovel interactive framework for 3D lesion morphology reporting that seamlessly\ngenerates segmentation masks with comprehensive attribute descriptions,\nenabling clinicians to generate detailed lesion profiles for enhanced\ndiagnostic assessment. To our best knowledge, we are the first to integrate the\ninteractive segmentation and structured reports in 3D CT medical images.\nExperimental results across 15 lesion types demonstrate the effectiveness of\nour approach in providing a more comprehensive and reliable reporting system\nfor lesion segmentation and capturing. The source code will be made publicly\navailable following paper acceptance.\n","authors":["Yannian Gu","Wenhui Lei","Hanyu Chen","Xiaofan Zhang","Shaoting Zhang"],"pdf_url":"https://arxiv.org/pdf/2503.03294v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.03287v1","updated":"2025-03-05T09:13:40Z","published":"2025-03-05T09:13:40Z","title":"Deep Understanding of Sign Language for Sign to Subtitle Alignment","summary":"  The objective of this work is to align asynchronous subtitles in sign\nlanguage videos with limited labelled data. To achieve this goal, we propose a\nnovel framework with the following contributions: (1) we leverage fundamental\ngrammatical rules of British Sign Language (BSL) to pre-process the input\nsubtitles, (2) we design a selective alignment loss to optimise the model for\npredicting the temporal location of signs only when the queried sign actually\noccurs in a scene, and (3) we conduct self-training with refined pseudo-labels\nwhich are more accurate than the heuristic audio-aligned labels. From this, our\nmodel not only better understands the correlation between the text and the\nsigns, but also holds potential for application in the translation of sign\nlanguages, particularly in scenarios where manual labelling of large-scale sign\ndata is impractical or challenging. Extensive experimental results demonstrate\nthat our approach achieves state-of-the-art results, surpassing previous\nbaselines by substantial margins in terms of both frame-level accuracy and\nF1-score. This highlights the effectiveness and practicality of our framework\nin advancing the field of sign language video alignment and translation.\n","authors":["Youngjoon Jang","Jeongsoo Choi","Junseok Ahn","Joon Son Chung"],"pdf_url":"https://arxiv.org/pdf/2503.03287v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.03286v1","updated":"2025-03-05T09:13:19Z","published":"2025-03-05T09:13:19Z","title":"Enhancing Visual Forced Alignment with Local Context-Aware Feature\n  Extraction and Multi-Task Learning","summary":"  This paper introduces a novel approach to Visual Forced Alignment (VFA),\naiming to accurately synchronize utterances with corresponding lip movements,\nwithout relying on audio cues. We propose a novel VFA approach that integrates\na local context-aware feature extractor and employs multi-task learning to\nrefine both global and local context features, enhancing sensitivity to subtle\nlip movements for precise word-level and phoneme-level alignment. Incorporating\nthe improved Viterbi algorithm for post-processing, our method significantly\nreduces misalignments. Experimental results show our approach outperforms\nexisting methods, achieving a 6% accuracy improvement at the word-level and 27%\nimprovement at the phoneme-level in LRS2 dataset. These improvements offer new\npotential for applications in automatically subtitling TV shows or\nuser-generated content platforms like TikTok and YouTube Shorts.\n","authors":["Yi He","Lei Yang","Shilin Wang"],"pdf_url":"https://arxiv.org/pdf/2503.03286v1.pdf","comment":"Accepted by ICASSP2025"},{"id":"http://arxiv.org/abs/2503.03285v1","updated":"2025-03-05T09:12:16Z","published":"2025-03-05T09:12:16Z","title":"Enhancing Vietnamese VQA through Curriculum Learning on Raw and\n  Augmented Text Representations","summary":"  Visual Question Answering (VQA) is a multimodal task requiring reasoning\nacross textual and visual inputs, which becomes particularly challenging in\nlow-resource languages like Vietnamese due to linguistic variability and the\nlack of high-quality datasets. Traditional methods often rely heavily on\nextensive annotated datasets, computationally expensive pipelines, and large\npre-trained models, specifically in the domain of Vietnamese VQA, limiting\ntheir applicability in such scenarios. To address these limitations, we propose\na training framework that combines a paraphrase-based feature augmentation\nmodule with a dynamic curriculum learning strategy. Explicitly, augmented\nsamples are considered \"easy\" while raw samples are regarded as \"hard\". The\nframework then utilizes a mechanism that dynamically adjusts the ratio of easy\nto hard samples during training, progressively modifying the same dataset to\nincrease its difficulty level. By enabling gradual adaptation to task\ncomplexity, this approach helps the Vietnamese VQA model generalize well, thus\nimproving overall performance. Experimental results show consistent\nimprovements on the OpenViVQA dataset and mixed outcomes on the ViVQA dataset,\nhighlighting both the potential and challenges of our approach in advancing VQA\nfor Vietnamese language.\n","authors":["Khoi Anh Nguyen","Linh Yen Vu","Thang Dinh Duong","Thuan Nguyen Duong","Huy Thanh Nguyen","Vinh Quang Dinh"],"pdf_url":"https://arxiv.org/pdf/2503.03285v1.pdf","comment":"10 pages, 3 figures, AAAI-25 Workshop on Document Understanding and\n  Intelligence"},{"id":"http://arxiv.org/abs/2503.03284v1","updated":"2025-03-05T09:12:12Z","published":"2025-03-05T09:12:12Z","title":"Gaussian highpass guided image filtering","summary":"  Guided image filtering (GIF) is a popular smoothing technique, in which an\nadditional image is used as a structure guidance for noise removal with edge\npreservation. The original GIF and some of its subsequent improvements are\nderived from a two-parameter local affine model (LAM), where the filtering\noutput is a local affine transformation of the guidance image, but the input\nimage is not taken into account in the LAM formulation. In this paper, we first\nintroduce a single-parameter Prior Model based on Gaussian (highpass/lowpass)\nFiltering (PM-GF), in which the filtering output is the sum of a weighted\nportion of Gaussian highpass filtering of the guidance image and Gaussian\nsmoothing of the input image. In the PM-GF, the guidance structure determined\nby Gaussian highpass filtering is obviously transferred to the filtering\noutput, thereby better revealing the structure transfer mechanism of guided\nfiltering. Then we propose several Gaussian highpass GIFs (GH-GIFs) based on\nthe PM-GF by emulating the original GIF and some improvements, i.e., using\nPM-GF instead of LAM in these GIFs. Experimental results illustrate that the\nproposed GIFs outperform their counterparts in several image processing\napplications.\n","authors":["Lei Zhao","Chuanjiang He"],"pdf_url":"https://arxiv.org/pdf/2503.03284v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.03280v1","updated":"2025-03-05T09:03:46Z","published":"2025-03-05T09:03:46Z","title":"BEVMOSNet: Multimodal Fusion for BEV Moving Object Segmentation","summary":"  Accurate motion understanding of the dynamic objects within the scene in\nbird's-eye-view (BEV) is critical to ensure a reliable obstacle avoidance\nsystem and smooth path planning for autonomous vehicles. However, this task has\nreceived relatively limited exploration when compared to object detection and\nsegmentation with only a few recent vision-based approaches presenting\npreliminary findings that significantly deteriorate in low-light, nighttime,\nand adverse weather conditions such as rain. Conversely, LiDAR and radar\nsensors remain almost unaffected in these scenarios, and radar provides key\nvelocity information of the objects. Therefore, we introduce BEVMOSNet, to our\nknowledge, the first end-to-end multimodal fusion leveraging cameras, LiDAR,\nand radar to precisely predict the moving objects in BEV. In addition, we\nperform a deeper analysis to find out the optimal strategy for deformable\ncross-attention-guided sensor fusion for cross-sensor knowledge sharing in BEV.\nWhile evaluating BEVMOSNet on the nuScenes dataset, we show an overall\nimprovement in IoU score of 36.59% compared to the vision-based unimodal\nbaseline BEV-MoSeg (Sigatapu et al., 2023), and 2.35% compared to the\nmultimodel SimpleBEV (Harley et al., 2022), extended for the motion\nsegmentation task, establishing this method as the state-of-the-art in BEV\nmotion segmentation.\n","authors":["Hiep Truong Cong","Ajay Kumar Sigatapu","Arindam Das","Yashwanth Sharma","Venkatesh Satagopan","Ganesh Sistu","Ciaran Eising"],"pdf_url":"https://arxiv.org/pdf/2503.03280v1.pdf","comment":"In Proceedings of the 20th International Joint Conference on Computer\n  Vision, Imaging and Computer Graphics Theory and Applications (2025)"},{"id":"http://arxiv.org/abs/2412.12843v2","updated":"2025-03-05T09:03:18Z","published":"2024-12-17T12:11:04Z","title":"SLTNet: Efficient Event-based Semantic Segmentation with Spike-driven\n  Lightweight Transformer-based Networks","summary":"  Event-based semantic segmentation has great potential in autonomous driving\nand robotics due to the advantages of event cameras, such as high dynamic\nrange, low latency, and low power cost. Unfortunately, current artificial\nneural network (ANN)-based segmentation methods suffer from high computational\ndemands, the requirements for image frames, and massive energy consumption,\nlimiting their efficiency and application on resource-constrained edge/mobile\nplatforms. To address these problems, we introduce SLTNet, a spike-driven\nlightweight transformer-based network designed for event-based semantic\nsegmentation. Specifically, SLTNet is built on efficient spike-driven\nconvolution blocks (SCBs) to extract rich semantic features while reducing the\nmodel's parameters. Then, to enhance the long-range contextural feature\ninteraction, we propose novel spike-driven transformer blocks (STBs) with\nbinary mask operations. Based on these basic blocks, SLTNet employs a\nhigh-efficiency single-branch architecture while maintaining the low energy\nconsumption of the Spiking Neural Network (SNN). Finally, extensive experiments\non DDD17 and DSEC-Semantic datasets demonstrate that SLTNet outperforms\nstate-of-the-art (SOTA) SNN-based methods by at most 9.06% and 9.39% mIoU,\nrespectively, with extremely 4.58x lower energy consumption and 114 FPS\ninference speed. Our code is open-sourced and available at\nhttps://github.com/longxianlei/SLTNet-v1.0.\n","authors":["Xiaxin Zhu","Fangming Guo","Xianlei Long","Qingyi Gu","Chao Chen","Fuqiang Gu"],"pdf_url":"https://arxiv.org/pdf/2412.12843v2.pdf","comment":"Submitted to 2025 IEEE/RSJ International Conference on Intelligent\n  Robots and Systems (IROS 2025)"},{"id":"http://arxiv.org/abs/2503.03278v1","updated":"2025-03-05T09:02:33Z","published":"2025-03-05T09:02:33Z","title":"Enhancing Abnormality Grounding for Vision Language Models with\n  Knowledge Descriptions","summary":"  Visual Language Models (VLMs) have demonstrated impressive capabilities in\nvisual grounding tasks. However, their effectiveness in the medical domain,\nparticularly for abnormality detection and localization within medical images,\nremains underexplored. A major challenge is the complex and abstract nature of\nmedical terminology, which makes it difficult to directly associate\npathological anomaly terms with their corresponding visual features. In this\nwork, we introduce a novel approach to enhance VLM performance in medical\nabnormality detection and localization by leveraging decomposed medical\nknowledge. Instead of directly prompting models to recognize specific\nabnormalities, we focus on breaking down medical concepts into fundamental\nattributes and common visual patterns. This strategy promotes a stronger\nalignment between textual descriptions and visual features, improving both the\nrecognition and localization of abnormalities in medical images.We evaluate our\nmethod on the 0.23B Florence-2 base model and demonstrate that it achieves\ncomparable performance in abnormality grounding to significantly larger 7B\nLLaVA-based medical VLMs, despite being trained on only 1.5% of the data used\nfor such models. Experimental results also demonstrate the effectiveness of our\napproach in both known and previously unseen abnormalities, suggesting its\nstrong generalization capabilities.\n","authors":["Jun Li","Che Liu","Wenjia Bai","Rossella Arcucci","Cosmin I. Bercea","Julia A. Schnabel"],"pdf_url":"https://arxiv.org/pdf/2503.03278v1.pdf","comment":"11 pages, 3 figures"},{"id":"http://arxiv.org/abs/2503.03272v1","updated":"2025-03-05T08:52:55Z","published":"2025-03-05T08:52:55Z","title":"Towards Effective and Sparse Adversarial Attack on Spiking Neural\n  Networks via Breaking Invisible Surrogate Gradients","summary":"  Spiking neural networks (SNNs) have shown their competence in handling\nspatial-temporal event-based data with low energy consumption. Similar to\nconventional artificial neural networks (ANNs), SNNs are also vulnerable to\ngradient-based adversarial attacks, wherein gradients are calculated by\nspatial-temporal back-propagation (STBP) and surrogate gradients (SGs).\nHowever, the SGs may be invisible for an inference-only model as they do not\ninfluence the inference results, and current gradient-based attacks are\nineffective for binary dynamic images captured by the dynamic vision sensor\n(DVS). While some approaches addressed the issue of invisible SGs through\nuniversal SGs, their SGs lack a correlation with the victim model, resulting in\nsub-optimal performance. Moreover, the imperceptibility of existing SNN-based\nbinary attacks is still insufficient. In this paper, we introduce an innovative\npotential-dependent surrogate gradient (PDSG) method to establish a robust\nconnection between the SG and the model, thereby enhancing the adaptability of\nadversarial attacks across various models with invisible SGs. Additionally, we\npropose the sparse dynamic attack (SDA) to effectively attack binary dynamic\nimages. Utilizing a generation-reduction paradigm, SDA can fully optimize the\nsparsity of adversarial perturbations. Experimental results demonstrate that\nour PDSG and SDA outperform state-of-the-art SNN-based attacks across various\nmodels and datasets. Specifically, our PDSG achieves 100% attack success rate\non ImageNet, and our SDA obtains 82% attack success rate by modifying only\n0.24% of the pixels on CIFAR10DVS. The code is available at\nhttps://github.com/ryime/PDSG-SDA .\n","authors":["Li Lun","Kunyu Feng","Qinglong Ni","Ling Liang","Yuan Wang","Ying Li","Dunshan Yu","Xiaoxin Cui"],"pdf_url":"https://arxiv.org/pdf/2503.03272v1.pdf","comment":"Accepted by CVPR 2025"},{"id":"http://arxiv.org/abs/2503.03270v1","updated":"2025-03-05T08:51:55Z","published":"2025-03-05T08:51:55Z","title":"Reduced Spatial Dependency for More General Video-level Deepfake\n  Detection","summary":"  As one of the prominent AI-generated content, Deepfake has raised significant\nsafety concerns. Although it has been demonstrated that temporal consistency\ncues offer better generalization capability, existing methods based on CNNs\ninevitably introduce spatial bias, which hinders the extraction of intrinsic\ntemporal features. To address this issue, we propose a novel method called\nSpatial Dependency Reduction (SDR), which integrates common temporal\nconsistency features from multiple spatially-perturbed clusters, to reduce the\ndependency of the model on spatial information. Specifically, we design\nmultiple Spatial Perturbation Branch (SPB) to construct spatially-perturbed\nfeature clusters. Subsequently, we utilize the theory of mutual information and\npropose a Task-Relevant Feature Integration (TRFI) module to capture temporal\nfeatures residing in similar latent space from these clusters. Finally, the\nintegrated feature is fed into a temporal transformer to capture long-range\ndependencies. Extensive benchmarks and ablation studies demonstrate the\neffectiveness and rationale of our approach.\n","authors":["Beilin Chu","Xuan Xu","Yufei Zhang","Weike You","Linna Zhou"],"pdf_url":"https://arxiv.org/pdf/2503.03270v1.pdf","comment":"5 pages, 2 figures. Accepted to ICASSP 2025"},{"id":"http://arxiv.org/abs/2503.03265v1","updated":"2025-03-05T08:47:36Z","published":"2025-03-05T08:47:36Z","title":"Optimizing for the Shortest Path in Denoising Diffusion Model","summary":"  In this research, we propose a novel denoising diffusion model based on\nshortest-path modeling that optimizes residual propagation to enhance both\ndenoising efficiency and quality.Drawing on Denoising Diffusion Implicit Models\n(DDIM) and insights from graph theory, our model, termed the Shortest Path\nDiffusion Model (ShortDF), treats the denoising process as a shortest-path\nproblem aimed at minimizing reconstruction error. By optimizing the initial\nresiduals, we improve the efficiency of the reverse diffusion process and the\nquality of the generated samples.Extensive experiments on multiple standard\nbenchmarks demonstrate that ShortDF significantly reduces diffusion time (or\nsteps) while enhancing the visual fidelity of generated samples compared to\nprior arts.This work, we suppose, paves the way for interactive diffusion-based\napplications and establishes a foundation for rapid data generation. Code is\navailable at https://github.com/UnicomAI/ShortDF.\n","authors":["Ping Chen","Xingpeng Zhang","Zhaoxiang Liu","Huan Hu","Xiang Liu","Kai Wang","Min Wang","Yanlin Qian","Shiguo Lian"],"pdf_url":"https://arxiv.org/pdf/2503.03265v1.pdf","comment":"Accepet by CVPR 2025 (10 pages, 6 figures)"},{"id":"http://arxiv.org/abs/2408.07246v3","updated":"2025-03-05T08:43:44Z","published":"2024-08-14T01:16:40Z","title":"ChemVLM: Exploring the Power of Multimodal Large Language Models in\n  Chemistry Area","summary":"  Large Language Models (LLMs) have achieved remarkable success and have been\napplied across various scientific fields, including chemistry. However, many\nchemical tasks require the processing of visual information, which cannot be\nsuccessfully handled by existing chemical LLMs. This brings a growing need for\nmodels capable of integrating multimodal information in the chemical domain. In\nthis paper, we introduce \\textbf{ChemVLM}, an open-source chemical multimodal\nlarge language model specifically designed for chemical applications. ChemVLM\nis trained on a carefully curated bilingual multimodal dataset that enhances\nits ability to understand both textual and visual chemical information,\nincluding molecular structures, reactions, and chemistry examination questions.\nWe develop three datasets for comprehensive evaluation, tailored to Chemical\nOptical Character Recognition (OCR), Multimodal Chemical Reasoning (MMCR), and\nMultimodal Molecule Understanding tasks. We benchmark ChemVLM against a range\nof open-source and proprietary multimodal large language models on various\ntasks. Experimental results demonstrate that ChemVLM achieves competitive\nperformance across all evaluated tasks. Our model can be found at\nhttps://huggingface.co/AI4Chem/ChemVLM-26B.\n","authors":["Junxian Li","Di Zhang","Xunzhi Wang","Zeying Hao","Jingdi Lei","Qian Tan","Cai Zhou","Wei Liu","Yaotian Yang","Xinrui Xiong","Weiyun Wang","Zhe Chen","Wenhai Wang","Wei Li","Shufei Zhang","Mao Su","Wanli Ouyang","Yuqiang Li","Dongzhan Zhou"],"pdf_url":"https://arxiv.org/pdf/2408.07246v3.pdf","comment":"11 pages, updated version"},{"id":"http://arxiv.org/abs/2503.03262v1","updated":"2025-03-05T08:38:51Z","published":"2025-03-05T08:38:51Z","title":"Trajectory Prediction for Autonomous Driving: Progress, Limitations, and\n  Future Directions","summary":"  As the potential for autonomous vehicles to be integrated on a large scale\ninto modern traffic systems continues to grow, ensuring safe navigation in\ndynamic environments is crucial for smooth integration. To guarantee safety and\nprevent collisions, autonomous vehicles must be capable of accurately\npredicting the trajectories of surrounding traffic agents. Over the past\ndecade, significant efforts from both academia and industry have been dedicated\nto designing solutions for precise trajectory forecasting. These efforts have\nproduced a diverse range of approaches, raising questions about the differences\nbetween these methods and whether trajectory prediction challenges have been\nfully addressed. This paper reviews a substantial portion of recent trajectory\nprediction methods and devises a taxonomy to classify existing solutions. A\ngeneral overview of the prediction pipeline is also provided, covering input\nand output modalities, modeling features, and prediction paradigms discussed in\nthe literature. In addition, the paper discusses active research areas within\ntrajectory prediction, addresses the posed research questions, and highlights\nthe remaining research gaps and challenges.\n","authors":["Nadya Abdel Madjid","Abdulrahman Ahmad","Murad Mebrahtu","Yousef Babaa","Abdelmoamen Nasser","Sumbal Malik","Bilal Hassan","Naoufel Werghi","Jorge Dias","Majid Khonji"],"pdf_url":"https://arxiv.org/pdf/2503.03262v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.05274v2","updated":"2025-03-05T08:36:27Z","published":"2024-09-17T10:08:37Z","title":"Scale-Invariant Object Detection by Adaptive Convolution with Unified\n  Global-Local Context","summary":"  Dense features are important for detecting minute objects in images.\nUnfortunately, despite the remarkable efficacy of the CNN models in multi-scale\nobject detection, CNN models often fail to detect smaller objects in images due\nto the loss of dense features during the pooling process. Atrous convolution\naddresses this issue by applying sparse kernels. However, sparse kernels often\ncan lose the multi-scale detection efficacy of the CNN model. In this paper, we\npropose an object detection model using a Switchable (adaptive) Atrous\nConvolutional Network (SAC-Net) based on the efficientDet model. A fixed atrous\nrate limits the performance of the CNN models in the convolutional layers. To\novercome this limitation, we introduce a switchable mechanism that allows for\ndynamically adjusting the atrous rate during the forward pass. The proposed\nSAC-Net encapsulates the benefits of both low-level and high-level features to\nachieve improved performance on multi-scale object detection tasks, without\nlosing the dense features. Further, we apply a depth-wise switchable atrous\nrate to the proposed network, to improve the scale-invariant features. Finally,\nwe apply global context on the proposed model. Our extensive experiments on\nbenchmark datasets demonstrate that the proposed SAC-Net outperforms the\nstate-of-the-art models by a significant margin in terms of accuracy.\n","authors":["Amrita Singh","Snehasis Mukherjee"],"pdf_url":"https://arxiv.org/pdf/2410.05274v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2408.06927v3","updated":"2025-03-05T08:35:41Z","published":"2024-08-13T14:29:00Z","title":"Breaking Class Barriers: Efficient Dataset Distillation via Inter-Class\n  Feature Compensator","summary":"  Dataset distillation has emerged as a technique aiming to condense\ninformative features from large, natural datasets into a compact and synthetic\nform. While recent advancements have refined this technique, its performance is\nbottlenecked by the prevailing class-specific synthesis paradigm. Under this\nparadigm, synthetic data is optimized exclusively for a pre-assigned one-hot\nlabel, creating an implicit class barrier in feature condensation. This leads\nto inefficient utilization of the distillation budget and oversight of\ninter-class feature distributions, which ultimately limits the effectiveness\nand efficiency, as demonstrated in our analysis. To overcome these constraints,\nthis paper presents the Inter-class Feature Compensator (INFER), an innovative\ndistillation approach that transcends the class-specific data-label framework\nwidely utilized in current dataset distillation methods. Specifically, INFER\nleverages a Universal Feature Compensator (UFC) to enhance feature integration\nacross classes, enabling the generation of multiple additional synthetic\ninstances from a single UFC input. This significantly improves the efficiency\nof the distillation budget. Moreover, INFER enriches inter-class interactions\nduring the distillation, thereby enhancing the effectiveness and\ngeneralizability of the distilled data. By allowing for the linear\ninterpolation of labels similar to those in the original dataset, INFER\nmeticulously optimizes the synthetic data and dramatically reduces the size of\nsoft labels in the synthetic dataset to almost zero, establishing a new\nbenchmark for efficiency and effectiveness in dataset distillation. In\npractice, INFER demonstrates state-of-the-art performance across benchmark\ndatasets. For instance, in the ipc = 50 setting on ImageNet-1k with the same\ncompression level, it outperforms SRe2L by 34.5% using ResNet18.\n","authors":["Xin Zhang","Jiawei Du","Ping Liu","Joey Tianyi Zhou"],"pdf_url":"https://arxiv.org/pdf/2408.06927v3.pdf","comment":"Accepted to ICLR 2025"},{"id":"http://arxiv.org/abs/2503.03259v1","updated":"2025-03-05T08:33:08Z","published":"2025-03-05T08:33:08Z","title":"BANet: Bilateral Aggregation Network for Mobile Stereo Matching","summary":"  State-of-the-art stereo matching methods typically use costly 3D convolutions\nto aggregate a full cost volume, but their computational demands make mobile\ndeployment challenging. Directly applying 2D convolutions for cost aggregation\noften results in edge blurring, detail loss, and mismatches in textureless\nregions. Some complex operations, like deformable convolutions and iterative\nwarping, can partially alleviate this issue; however, they are not\nmobile-friendly, limiting their deployment on mobile devices. In this paper, we\npresent a novel bilateral aggregation network (BANet) for mobile stereo\nmatching that produces high-quality results with sharp edges and fine details\nusing only 2D convolutions. Specifically, we first separate the full cost\nvolume into detailed and smooth volumes using a spatial attention map, then\nperform detailed and smooth aggregations accordingly, ultimately fusing both to\nobtain the final disparity map. Additionally, to accurately identify\nhigh-frequency detailed regions and low-frequency smooth/textureless regions,\nwe propose a new scale-aware spatial attention module. Experimental results\ndemonstrate that our BANet-2D significantly outperforms other mobile-friendly\nmethods, achieving 35.3\\% higher accuracy on the KITTI 2015 leaderboard than\nMobileStereoNet-2D, with faster runtime on mobile devices. The extended 3D\nversion, BANet-3D, achieves the highest accuracy among all real-time methods on\nhigh-end GPUs. Code: \\textcolor{magenta}{https://github.com/gangweiX/BANet}.\n","authors":["Gangwei Xu","Jiaxin Liu","Xianqi Wang","Junda Cheng","Yong Deng","Jinliang Zang","Yurui Chen","Xin Yang"],"pdf_url":"https://arxiv.org/pdf/2503.03259v1.pdf","comment":"12 pages"},{"id":"http://arxiv.org/abs/2503.03256v1","updated":"2025-03-05T08:20:16Z","published":"2025-03-05T08:20:16Z","title":"BAT: Learning Event-based Optical Flow with Bidirectional Adaptive\n  Temporal Correlation","summary":"  Event cameras deliver visual information characterized by a high dynamic\nrange and high temporal resolution, offering significant advantages in\nestimating optical flow for complex lighting conditions and fast-moving\nobjects. Current advanced optical flow methods for event cameras largely adopt\nestablished image-based frameworks. However, the spatial sparsity of event data\nlimits their performance. In this paper, we present BAT, an innovative\nframework that estimates event-based optical flow using bidirectional adaptive\ntemporal correlation. BAT includes three novel designs: 1) a bidirectional\ntemporal correlation that transforms bidirectional temporally dense motion cues\ninto spatially dense ones, enabling accurate and spatially dense optical flow\nestimation; 2) an adaptive temporal sampling strategy for maintaining temporal\nconsistency in correlation; 3) spatially adaptive temporal motion aggregation\nto efficiently and adaptively aggregate consistent target motion features into\nadjacent motion features while suppressing inconsistent ones. Our results rank\n$1^{st}$ on the DSEC-Flow benchmark, outperforming existing state-of-the-art\nmethods by a large margin while also exhibiting sharp edges and high-quality\ndetails. Notably, our BAT can accurately predict future optical flow using only\npast events, significantly outperforming E-RAFT's warm-start approach. Code:\n\\textcolor{magenta}{https://github.com/gangweiX/BAT}.\n","authors":["Gangwei Xu","Haotong Lin","Zhaoxing Zhang","Hongcheng Luo","Haiyang Sun","Xin Yang"],"pdf_url":"https://arxiv.org/pdf/2503.03256v1.pdf","comment":"10 pages"},{"id":"http://arxiv.org/abs/2503.03255v1","updated":"2025-03-05T08:15:31Z","published":"2025-03-05T08:15:31Z","title":"Computational Analysis of Degradation Modeling in Blind Panoramic Image\n  Quality Assessment","summary":"  Blind panoramic image quality assessment (BPIQA) has recently brought new\nchallenge to the visual quality community, due to the complex interaction\nbetween immersive content and human behavior. Although many efforts have been\nmade to advance BPIQA from both conducting psychophysical experiments and\ndesigning performance-driven objective algorithms, \\textit{limited content} and\n\\textit{few samples} in those closed sets inevitably would result in shaky\nconclusions, thereby hindering the development of BPIQA, we refer to it as the\n\\textit{easy-database} issue. In this paper, we present a sufficient\ncomputational analysis of degradation modeling in BPIQA to thoroughly explore\nthe \\textit{easy-database issue}, where we carefully design three types of\nexperiments via investigating the gap between BPIQA and blind image quality\nassessment (BIQA), the necessity of specific design in BPIQA models, and the\ngeneralization ability of BPIQA models. From extensive experiments, we find\nthat easy databases narrow the gap between the performance of BPIQA and BIQA\nmodels, which is unconducive to the development of BPIQA. And the easy\ndatabases make the BPIQA models be closed to saturation, therefore the\neffectiveness of the associated specific designs can not be well verified.\nBesides, the BPIQA models trained on our recently proposed databases with\ncomplicated degradation show better generalization ability. Thus, we believe\nthat much more efforts are highly desired to put into BPIQA from both\nsubjective viewpoint and objective viewpoint.\n","authors":["Jiebin Yan","Ziwen Tan","Jiale Rao","Lei Wu","Yifan Zuo","Yuming Fang"],"pdf_url":"https://arxiv.org/pdf/2503.03255v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2404.12020v4","updated":"2025-03-05T08:09:07Z","published":"2024-04-18T09:16:02Z","title":"Look, Listen, and Answer: Overcoming Biases for Audio-Visual Question\n  Answering","summary":"  Audio-Visual Question Answering (AVQA) is a complex multi-modal reasoning\ntask, demanding intelligent systems to accurately respond to natural language\nqueries based on audio-video input pairs. Nevertheless, prevalent AVQA\napproaches are prone to overlearning dataset biases, resulting in poor\nrobustness. Furthermore, current datasets may not provide a precise diagnostic\nfor these methods. To tackle these challenges, firstly, we propose a novel\ndataset, MUSIC-AVQA-R, crafted in two steps: rephrasing questions within the\ntest split of a public dataset (MUSIC-AVQA) and subsequently introducing\ndistribution shifts to split questions. The former leads to a large, diverse\ntest space, while the latter results in a comprehensive robustness evaluation\non rare, frequent, and overall questions. Secondly, we propose a robust\narchitecture that utilizes a multifaceted cycle collaborative debiasing\nstrategy to overcome bias learning. Experimental results show that this\narchitecture achieves state-of-the-art performance on MUSIC-AVQA-R, notably\nobtaining a significant improvement of 9.32%. Extensive ablation experiments\nare conducted on the two datasets mentioned to analyze the component\neffectiveness within the debiasing strategy. Additionally, we highlight the\nlimited robustness of existing multi-modal QA methods through the evaluation on\nour dataset. We also conduct experiments combining various baselines with our\nproposed strategy on two datasets to verify its plug-and-play capability. Our\ndataset and code are available at https://github.com/reml-group/MUSIC-AVQA-R.\n","authors":["Jie Ma","Min Hu","Pinghui Wang","Wangchun Sun","Lingyun Song","Hongbin Pei","Jun Liu","Youtian Du"],"pdf_url":"https://arxiv.org/pdf/2404.12020v4.pdf","comment":"Accepted by NeurIPS 2024"},{"id":"http://arxiv.org/abs/2503.03244v1","updated":"2025-03-05T07:52:52Z","published":"2025-03-05T07:52:52Z","title":"Two-Stream Thermal Imaging Fusion for Enhanced Time of Birth Detection\n  in Neonatal Care","summary":"  Around 10% of newborns require some help to initiate breathing, and 5\\% need\nventilation assistance. Accurate Time of Birth (ToB) documentation is essential\nfor optimizing neonatal care, as timely interventions are vital for proper\nresuscitation. However, current clinical methods for recording ToB often rely\non manual processes, which can be prone to inaccuracies. In this study, we\npresent a novel two-stream fusion system that combines the power of image and\nvideo analysis to accurately detect the ToB from thermal recordings in the\ndelivery room and operating theater. By integrating static and dynamic streams,\nour approach captures richer birth-related spatiotemporal features, leading to\nmore robust and precise ToB estimation. We demonstrate that this synergy\nbetween data modalities enhances performance over single-stream approaches. Our\nsystem achieves 95.7% precision and 84.8% recall in detecting birth within\nshort video clips. Additionally, with the help of a score aggregation module,\nit successfully identifies ToB in 100% of test cases, with a median absolute\nerror of 2 seconds and an absolute mean deviation of 4.5 seconds compared to\nmanual annotations.\n","authors":["Jorge Garca-Torres","yvind Meinich-Bache","Sara Brunner","Siren Rettedal","Vilde Kolstad","Kjersti Engan"],"pdf_url":"https://arxiv.org/pdf/2503.03244v1.pdf","comment":"Submitted to IEEE 25th International Conference on Digital Signal\n  Processing"},{"id":"http://arxiv.org/abs/2503.03236v1","updated":"2025-03-05T07:29:12Z","published":"2025-03-05T07:29:12Z","title":"GenColor: Generative Color-Concept Association in Visual Design","summary":"  Existing approaches for color-concept association typically rely on\nquery-based image referencing, and color extraction from image references.\nHowever, these approaches are effective only for common concepts, and are\nvulnerable to unstable image referencing and varying image conditions. Our\nformative study with designers underscores the need for primary-accent color\ncompositions and context-dependent colors (e.g., 'clear' vs. 'polluted' sky) in\ndesign. In response, we introduce a generative approach for mining semantically\nresonant colors leveraging images generated by text-to-image models. Our\ninsight is that contemporary text-to-image models can resemble visual patterns\nfrom large-scale real-world data. The framework comprises three stages: concept\ninstancing produces generative samples using diffusion models, text-guided\nimage segmentation identifies concept-relevant regions within the image, and\ncolor association extracts primarily accompanied by accent colors. Quantitative\ncomparisons with expert designs validate our approach's effectiveness, and we\ndemonstrate the applicability through cases in various design scenarios and a\ngallery.\n","authors":["Yihan Hou","Xingchen Zeng","Yusong Wang","Manling Yang","Xiaojiao Chen","Wei Zeng"],"pdf_url":"https://arxiv.org/pdf/2503.03236v1.pdf","comment":"19 pages, 16 figures. Accepted at CHI Conference on Human Factors in\n  Computing Systems (CHI'25), April 26-May 1, 2025, Yokohama, Japan"},{"id":"http://arxiv.org/abs/2411.13807v3","updated":"2025-03-05T07:24:34Z","published":"2024-11-21T03:13:30Z","title":"MagicDrive-V2: High-Resolution Long Video Generation for Autonomous\n  Driving with Adaptive Control","summary":"  The rapid advancement of diffusion models has greatly improved video\nsynthesis, especially in controllable video generation, which is vital for\napplications like autonomous driving. Although DiT with 3D VAE has become a\nstandard framework for video generation, it introduces challenges in\ncontrollable driving video generation, especially for geometry control,\nrendering existing control methods ineffective. To address these issues, we\npropose MagicDrive-V2, a novel approach that integrates the MVDiT block and\nspatial-temporal conditional encoding to enable multi-view video generation and\nprecise geometric control. Additionally, we introduce an efficient method for\nobtaining contextual descriptions for videos to support diverse textual\ncontrol, along with a progressive training strategy using mixed video data to\nenhance training efficiency and generalizability. Consequently, MagicDrive-V2\nenables multi-view driving video synthesis with $3.3\\times$ resolution and\n$4\\times$ frame count (compared to current SOTA), rich contextual control, and\ngeometric controls. Extensive experiments demonstrate MagicDrive-V2's ability,\nunlocking broader applications in autonomous driving.\n","authors":["Ruiyuan Gao","Kai Chen","Bo Xiao","Lanqing Hong","Zhenguo Li","Qiang Xu"],"pdf_url":"https://arxiv.org/pdf/2411.13807v3.pdf","comment":"Project Website: https://flymin.github.io/magicdrive-v2/"},{"id":"http://arxiv.org/abs/2412.09601v2","updated":"2025-03-05T07:06:15Z","published":"2024-12-12T18:59:11Z","title":"TimeRefine: Temporal Grounding with Time Refining Video LLM","summary":"  Video temporal grounding aims to localize relevant temporal boundaries in a\nvideo given a textual prompt. Recent work has focused on enabling Video LLMs to\nperform video temporal grounding via next-token prediction of temporal\ntimestamps. However, accurately localizing timestamps in videos remains\nchallenging for Video LLMs when relying solely on temporal token prediction.\nOur proposed TimeRefine addresses this challenge in two ways. First, instead of\ndirectly predicting the start and end timestamps, we reformulate the temporal\ngrounding task as a temporal refining task: the model first makes rough\npredictions and then refines them by predicting offsets to the target segment.\nThis refining process is repeated multiple times, through which the model\nprogressively self-improves its temporal localization accuracy. Second, to\nenhance the model's temporal perception capabilities, we incorporate an\nauxiliary prediction head that penalizes the model more if a predicted segment\ndeviates further from the ground truth, thus encouraging the model to make\ncloser and more accurate predictions. Our plug-and-play method can be\nintegrated into most LLM-based temporal grounding approaches. The experimental\nresults demonstrate that TimeRefine achieves 3.6% and 5.0% mIoU improvements on\nthe ActivityNet and Charades-STA datasets, respectively. Code and pretrained\nmodels will be released.\n","authors":["Xizi Wang","Feng Cheng","Ziyang Wang","Huiyu Wang","Md Mohaiminul Islam","Lorenzo Torresani","Mohit Bansal","Gedas Bertasius","David Crandall"],"pdf_url":"https://arxiv.org/pdf/2412.09601v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.03228v1","updated":"2025-03-05T06:56:42Z","published":"2025-03-05T06:56:42Z","title":"Path-Adaptive Matting for Efficient Inference Under Various\n  Computational Cost Constraints","summary":"  In this paper, we explore a novel image matting task aimed at achieving\nefficient inference under various computational cost constraints, specifically\nFLOP limitations, using a single matting network. Existing matting methods\nwhich have not explored scalable architectures or path-learning strategies,\nfail to tackle this challenge. To overcome these limitations, we introduce\nPath-Adaptive Matting (PAM), a framework that dynamically adjusts network paths\nbased on image contexts and computational cost constraints. We formulate the\ntraining of the computational cost-constrained matting network as a bilevel\noptimization problem, jointly optimizing the matting network and the path\nestimator. Building on this formalization, we design a path-adaptive matting\narchitecture by incorporating path selection layers and learnable connect\nlayers to estimate optimal paths and perform efficient inference within a\nunified network. Furthermore, we propose a performance-aware path-learning\nstrategy to generate path labels online by evaluating a few paths sampled from\nthe prior distribution of optimal paths and network estimations, enabling\nrobust and efficient online path learning. Experiments on five image matting\ndatasets demonstrate that the proposed PAM framework achieves competitive\nperformance across a range of computational cost constraints.\n","authors":["Qinglin Liu","Zonglin Li","Xiaoqian Lv","Xin Sun","Ru Li","Shengping Zhang"],"pdf_url":"https://arxiv.org/pdf/2503.03228v1.pdf","comment":"Accepted to AAAI 2025"},{"id":"http://arxiv.org/abs/2502.19908v2","updated":"2025-03-05T06:36:27Z","published":"2025-02-27T09:26:22Z","title":"CarPlanner: Consistent Auto-regressive Trajectory Planning for\n  Large-scale Reinforcement Learning in Autonomous Driving","summary":"  Trajectory planning is vital for autonomous driving, ensuring safe and\nefficient navigation in complex environments. While recent learning-based\nmethods, particularly reinforcement learning (RL), have shown promise in\nspecific scenarios, RL planners struggle with training inefficiencies and\nmanaging large-scale, real-world driving scenarios. In this paper, we introduce\n\\textbf{CarPlanner}, a \\textbf{C}onsistent \\textbf{a}uto-\\textbf{r}egressive\n\\textbf{Planner} that uses RL to generate multi-modal trajectories. The\nauto-regressive structure enables efficient large-scale RL training, while the\nincorporation of consistency ensures stable policy learning by maintaining\ncoherent temporal consistency across time steps. Moreover, CarPlanner employs a\ngeneration-selection framework with an expert-guided reward function and an\ninvariant-view module, simplifying RL training and enhancing policy\nperformance. Extensive analysis demonstrates that our proposed RL framework\neffectively addresses the challenges of training efficiency and performance\nenhancement, positioning CarPlanner as a promising solution for trajectory\nplanning in autonomous driving. To the best of our knowledge, we are the first\nto demonstrate that the RL-based planner can surpass both IL- and rule-based\nstate-of-the-arts (SOTAs) on the challenging large-scale real-world dataset\nnuPlan. Our proposed CarPlanner surpasses RL-, IL-, and rule-based SOTA\napproaches within this demanding dataset.\n","authors":["Dongkun Zhang","Jiaming Liang","Ke Guo","Sha Lu","Qi Wang","Rong Xiong","Zhenwei Miao","Yue Wang"],"pdf_url":"https://arxiv.org/pdf/2502.19908v2.pdf","comment":"CVPR 2025"},{"id":"http://arxiv.org/abs/2503.03222v1","updated":"2025-03-05T06:32:49Z","published":"2025-03-05T06:32:49Z","title":"Mocap-2-to-3: Lifting 2D Diffusion-Based Pretrained Models for 3D Motion\n  Capture","summary":"  Recovering absolute poses in the world coordinate system from monocular views\npresents significant challenges. Two primary issues arise in this context.\nFirstly, existing methods rely on 3D motion data for training, which requires\ncollection in limited environments. Acquiring such 3D labels for new actions in\na timely manner is impractical, severely restricting the model's generalization\ncapabilities. In contrast, 2D poses are far more accessible and easier to\nobtain. Secondly, estimating a person's absolute position in metric space from\na single viewpoint is inherently more complex. To address these challenges, we\nintroduce Mocap-2-to-3, a novel framework that decomposes intricate 3D motions\ninto 2D poses, leveraging 2D data to enhance 3D motion reconstruction in\ndiverse scenarios and accurately predict absolute positions in the world\ncoordinate system. We initially pretrain a single-view diffusion model with\nextensive 2D data, followed by fine-tuning a multi-view diffusion model for\nview consistency using publicly available 3D data. This strategy facilitates\nthe effective use of large-scale 2D data. Additionally, we propose an\ninnovative human motion representation that decouples local actions from global\nmovements and encodes geometric priors of the ground, ensuring the generative\nmodel learns accurate motion priors from 2D data. During inference, this allows\nfor the gradual recovery of global movements, resulting in more plausible\npositioning. We evaluate our model's performance on real-world datasets,\ndemonstrating superior accuracy in motion and absolute human positioning\ncompared to state-of-the-art methods, along with enhanced generalization and\nscalability. Our code will be made publicly available.\n","authors":["Zhumei Wang","Zechen Hu","Ruoxi Guo","Huaijin Pi","Ziyong Feng","Sida Peng","Xiaowei Zhou"],"pdf_url":"https://arxiv.org/pdf/2503.03222v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.03214v1","updated":"2025-03-05T06:16:13Z","published":"2025-03-05T06:16:13Z","title":"Rice Grain Size Measurement using Image Processing","summary":"  The rice grain quality can be determined from its size and chalkiness. The\ntraditional approach to measure the rice grain size involves manual inspection,\nwhich is inefficient and leads to inconsistent results. To address this issue,\nan image processing based approach is proposed and developed in this research.\nThe approach takes image of rice grains as input and outputs the number of rice\ngrains and size of each rice grain. The different steps, such as extraction of\nregion of interest, segmentation of rice grains, and sub-contours removal,\ninvolved in the proposed approach are discussed. The approach was tested on\nrice grain images captured from different height using mobile phone camera. The\nobtained results show that the proposed approach successfully detected 95\\% of\nthe rice grains and achieved 90\\% accuracy for length and width measurement.\n","authors":["Ankush Tyagi","Dhruv Motwani","Vipul K. Dabhi","Harshadkumar B. Prajapati"],"pdf_url":"https://arxiv.org/pdf/2503.03214v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.03206v1","updated":"2025-03-05T05:50:38Z","published":"2025-03-05T05:50:38Z","title":"An Analytical Theory of Power Law Spectral Bias in the Learning Dynamics\n  of Diffusion Models","summary":"  We developed an analytical framework for understanding how the learned\ndistribution evolves during diffusion model training. Leveraging the Gaussian\nequivalence principle, we derived exact solutions for the gradient-flow\ndynamics of weights in one- or two-layer linear denoiser settings with\narbitrary data. Remarkably, these solutions allowed us to derive the generated\ndistribution in closed form and its KL divergence through training. These\nanalytical results expose a pronounced power-law spectral bias, i.e., for\nweights and distributions, the convergence time of a mode follows an inverse\npower law of its variance. Empirical experiments on both Gaussian and image\ndatasets demonstrate that the power-law spectral bias remains robust even when\nusing deeper or convolutional architectures. Our results underscore the\nimportance of the data covariance in dictating the order and rate at which\ndiffusion models learn different modes of the data, providing potential\nexplanations for why earlier stopping could lead to incorrect details in image\ngenerative models.\n","authors":["Binxu Wang"],"pdf_url":"https://arxiv.org/pdf/2503.03206v1.pdf","comment":"50 pages, 10 figures. Preprint"},{"id":"http://arxiv.org/abs/2503.03204v1","updated":"2025-03-05T05:50:28Z","published":"2025-03-05T05:50:28Z","title":"Find Matching Faces Based On Face Parameters","summary":"  This paper presents an innovative approach that enables the user to find\nmatching faces based on the user-selected face parameters. Through gradio-based\nuser interface, the users can interactively select the face parameters they\nwant in their desired partner. These user-selected face parameters are\ntransformed into a text prompt which is used by the Text-To-Image generation\nmodel to generate a realistic face image. Further, the generated image along\nwith the images downloaded from the Jeevansathi.com are processed through face\ndetection and feature extraction model, which results in high dimensional\nvector embedding of 512 dimensions. The vector embeddings generated from the\ndownloaded images are stored into vector database. Now, the similarity search\nis carried out between the vector embedding of generated image and the stored\nvector embeddings. As a result, it displays the top five similar faces based on\nthe user-selected face parameters. This contribution holds a significant\npotential to turn into a high-quality personalized face matching tool.\n","authors":["Setu A. Bhatt","Harshadkumar B. Prajapati","Vipul K. Dabhi","Ankush Tyagi"],"pdf_url":"https://arxiv.org/pdf/2503.03204v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.03202v1","updated":"2025-03-05T05:46:08Z","published":"2025-03-05T05:46:08Z","title":"Variance-Aware Loss Scheduling for Multimodal Alignment in Low-Data\n  Settings","summary":"  Training vision-language models for image-text alignment typically requires\nlarge datasets to achieve robust performance. In low-data scenarios, standard\ncontrastive learning can struggle to align modalities effectively due to\noverfitting and unstable training dynamics. In this paper, we propose a\nvariance-aware loss scheduling approach that dynamically adjusts the weighting\nof the contrastive loss based on the statistical variability (uncertainty) in\nthe model's alignment predictions. Using a subset of the Flickr8k image-caption\ndataset to simulate limited data conditions, we demonstrate that our approach\nimproves image-text retrieval accuracy compared to a fixed-weight baseline. We\nalso compare against other adaptive weighting strategies (using output entropy\nand cosine similarity spread) and find that variance-aware scheduling provides\nthe best overall trade-off. Qualitatively, our method yields more distinct\nmultimodal embeddings as shown by t-SNE visualizations. Moreover, in a stress\ntest with noise-injected captions and images, the variance-guided loss proves\nmore robust, maintaining higher recall when random perturbations are\nintroduced. These results highlight the benefit of adaptive loss weighting for\nmultimodal alignment in low-data regimes.\n","authors":["Sneh Pillai"],"pdf_url":"https://arxiv.org/pdf/2503.03202v1.pdf","comment":"8 pages, 4 figures"},{"id":"http://arxiv.org/abs/2503.03200v1","updated":"2025-03-05T05:36:26Z","published":"2025-03-05T05:36:26Z","title":"Transformer-Based Spatio-Temporal Association of Apple Fruitlets","summary":"  In this paper, we present a transformer-based method to spatio-temporally\nassociate apple fruitlets in stereo-images collected on different days and from\ndifferent camera poses. State-of-the-art association methods in agriculture are\ndedicated towards matching larger crops using either high-resolution point\nclouds or temporally stable features, which are both difficult to obtain for\nsmaller fruit in the field. To address these challenges, we propose a\ntransformer-based architecture that encodes the shape and position of each\nfruitlet, and propagates and refines these features through a series of\ntransformer encoder layers with alternating self and cross-attention. We\ndemonstrate that our method is able to achieve an F1-score of 92.4% on data\ncollected in a commercial apple orchard and outperforms all baselines and\nablations.\n","authors":["Harry Freeman","George Kantor"],"pdf_url":"https://arxiv.org/pdf/2503.03200v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.03196v1","updated":"2025-03-05T05:30:22Z","published":"2025-03-05T05:30:22Z","title":"SpiritSight Agent: Advanced GUI Agent with One Look","summary":"  Graphical User Interface (GUI) agents show amazing abilities in assisting\nhuman-computer interaction, automating human user's navigation on digital\ndevices. An ideal GUI agent is expected to achieve high accuracy, low latency,\nand compatibility for different GUI platforms. Recent vision-based approaches\nhave shown promise by leveraging advanced Vision Language Models (VLMs). While\nthey generally meet the requirements of compatibility and low latency, these\nvision-based GUI agents tend to have low accuracy due to their limitations in\nelement grounding. To address this issue, we propose $\\textbf{SpiritSight}$, a\nvision-based, end-to-end GUI agent that excels in GUI navigation tasks across\nvarious GUI platforms. First, we create a multi-level, large-scale,\nhigh-quality GUI dataset called $\\textbf{GUI-Lasagne}$ using scalable methods,\nempowering SpiritSight with robust GUI understanding and grounding\ncapabilities. Second, we introduce the $\\textbf{Universal Block Parsing (UBP)}$\nmethod to resolve the ambiguity problem in dynamic high-resolution of visual\ninputs, further enhancing SpiritSight's ability to ground GUI objects. Through\nthese efforts, SpiritSight agent outperforms other advanced methods on diverse\nGUI benchmarks, demonstrating its superior capability and compatibility in GUI\nnavigation tasks. Models are available at\n$\\href{https://huggingface.co/SenseLLM/SpiritSight-Agent-8B}{this\\ URL}$.\n","authors":["Zhiyuan Huang","Ziming Cheng","Junting Pan","Zhaohui Hou","Mingjie Zhan"],"pdf_url":"https://arxiv.org/pdf/2503.03196v1.pdf","comment":"Paper accepted to CVPR 2025"},{"id":"http://arxiv.org/abs/2312.10892v3","updated":"2025-03-05T05:27:43Z","published":"2023-12-18T02:50:45Z","title":"Deep Learning-based MRI Reconstruction with Artificial Fourier Transform\n  Network (AFTNet)","summary":"  Deep complex-valued neural networks (CVNNs) provide a powerful way to\nleverage complex number operations and representations and have succeeded in\nseveral phase-based applications. However, previous networks have not fully\nexplored the impact of complex-valued networks in the frequency domain. Here,\nwe introduce a unified complex-valued deep learning framework-Artificial\nFourier Transform Network (AFTNet)-which combines domain-manifold learning and\nCVNNs. AFTNet can be readily used to solve image inverse problems in domain\ntransformation, especially for accelerated magnetic resonance imaging (MRI)\nreconstruction and other applications. While conventional methods typically\nutilize magnitude images or treat the real and imaginary components of k-space\ndata as separate channels, our approach directly processes raw k-space data in\nthe frequency domain, utilizing complex-valued operations. This allows for a\nmapping between the frequency (k-space) and image domain to be determined\nthrough cross-domain learning. We show that AFTNet achieves superior\naccelerated MRI reconstruction compared to existing approaches. Furthermore,\nour approach can be applied to various tasks, such as denoised magnetic\nresonance spectroscopy (MRS) reconstruction and datasets with various\ncontrasts. The AFTNet presented here is a valuable preprocessing component for\ndifferent preclinical studies and provides an innovative alternative for\nsolving inverse problems in imaging and spectroscopy. The code is available at:\nhttps://github.com/yanting-yang/AFT-Net.\n","authors":["Yanting Yang","Yiren Zhang","Zongyu Li","Jeffery Siyuan Tian","Matthieu Dagommer","Jia Guo"],"pdf_url":"https://arxiv.org/pdf/2312.10892v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2408.15503v5","updated":"2025-03-05T05:14:34Z","published":"2024-08-28T03:17:40Z","title":"RoboSense: Large-scale Dataset and Benchmark for Egocentric Robot\n  Perception and Navigation in Crowded and Unstructured Environments","summary":"  Reliable embodied perception from an egocentric perspective is challenging\nyet essential for autonomous navigation technology of intelligent mobile\nagents. With the growing demand of social robotics, near-field scene\nunderstanding becomes an important research topic in the areas of egocentric\nperceptual tasks related to navigation in both crowded and unstructured\nenvironments. Due to the complexity of environmental conditions and difficulty\nof surrounding obstacles owing to truncation and occlusion, the perception\ncapability under this circumstance is still inferior. To further enhance the\nintelligence of mobile robots, in this paper, we setup an egocentric\nmulti-sensor data collection platform based on 3 main types of sensors (Camera,\nLiDAR and Fisheye), which supports flexible sensor configurations to enable\ndynamic sight of view from ego-perspective, capturing either near or farther\nareas. Meanwhile, a large-scale multimodal dataset is constructed, named\nRoboSense, to facilitate egocentric robot perception. Specifically, RoboSense\ncontains more than 133K synchronized data with 1.4M 3D bounding box and IDs\nannotated in the full $360^{\\circ}$ view, forming 216K trajectories across 7.6K\ntemporal sequences. It has $270\\times$ and $18\\times$ as many annotations of\nsurrounding obstacles within near ranges as the previous datasets collected for\nautonomous driving scenarios such as KITTI and nuScenes. Moreover, we define a\nnovel matching criterion for near-field 3D perception and prediction metrics.\nBased on RoboSense, we formulate 6 popular tasks to facilitate the future\nresearch development, where the detailed analysis as well as benchmarks are\nalso provided accordingly. Data desensitization measures have been conducted\nfor privacy protection.\n","authors":["Haisheng Su","Feixiang Song","Cong Ma","Wei Wu","Junchi Yan"],"pdf_url":"https://arxiv.org/pdf/2408.15503v5.pdf","comment":"Accepted to CVPR2025"},{"id":"http://arxiv.org/abs/2503.03190v1","updated":"2025-03-05T05:13:53Z","published":"2025-03-05T05:13:53Z","title":"DSPNet: Dual-vision Scene Perception for Robust 3D Question Answering","summary":"  3D Question Answering (3D QA) requires the model to comprehensively\nunderstand its situated 3D scene described by the text, then reason about its\nsurrounding environment and answer a question under that situation. However,\nexisting methods usually rely on global scene perception from pure 3D point\nclouds and overlook the importance of rich local texture details from\nmulti-view images. Moreover, due to the inherent noise in camera poses and\ncomplex occlusions, there exists significant feature degradation and reduced\nfeature robustness problems when aligning 3D point cloud with multi-view\nimages. In this paper, we propose a Dual-vision Scene Perception Network\n(DSPNet), to comprehensively integrate multi-view and point cloud features to\nimprove robustness in 3D QA. Our Text-guided Multi-view Fusion (TGMF) module\nprioritizes image views that closely match the semantic content of the text. To\nadaptively fuse back-projected multi-view images with point cloud features, we\ndesign the Adaptive Dual-vision Perception (ADVP) module, enhancing 3D scene\ncomprehension. Additionally, our Multimodal Context-guided Reasoning (MCGR)\nmodule facilitates robust reasoning by integrating contextual information\nacross visual and linguistic modalities. Experimental results on SQA3D and\nScanQA datasets demonstrate the superiority of our DSPNet. Codes will be\navailable at https://github.com/LZ-CH/DSPNet.\n","authors":["Jingzhou Luo","Yang Liu","Weixing Chen","Zhen Li","Yaowei Wang","Guanbin Li","Liang Lin"],"pdf_url":"https://arxiv.org/pdf/2503.03190v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.03030v2","updated":"2025-03-05T04:37:07Z","published":"2024-10-03T22:24:54Z","title":"Dynamic Sparse Training versus Dense Training: The Unexpected Winner in\n  Image Corruption Robustness","summary":"  It is generally perceived that Dynamic Sparse Training opens the door to a\nnew era of scalability and efficiency for artificial neural networks at,\nperhaps, some costs in accuracy performance for the classification task. At the\nsame time, Dense Training is widely accepted as being the \"de facto\" approach\nto train artificial neural networks if one would like to maximize their\nrobustness against image corruption. In this paper, we question this general\npractice. Consequently, we claim that, contrary to what is commonly thought,\nthe Dynamic Sparse Training methods can consistently outperform Dense Training\nin terms of robustness accuracy, particularly if the efficiency aspect is not\nconsidered as a main objective (i.e., sparsity levels between 10% and up to\n50%), without adding (or even reducing) resource cost. We validate our claim on\ntwo types of data, images and videos, using several traditional and modern deep\nlearning architectures for computer vision and three widely studied Dynamic\nSparse Training algorithms. Our findings reveal a new yet-unknown benefit of\nDynamic Sparse Training and open new possibilities in improving deep learning\nrobustness beyond the current state of the art.\n","authors":["Boqian Wu","Qiao Xiao","Shunxin Wang","Nicola Strisciuglio","Mykola Pechenizkiy","Maurice van Keulen","Decebal Constantin Mocanu","Elena Mocanu"],"pdf_url":"https://arxiv.org/pdf/2410.03030v2.pdf","comment":"Accepted at ICLR 2025"},{"id":"http://arxiv.org/abs/2502.00931v3","updated":"2025-03-05T04:11:08Z","published":"2025-02-02T21:44:15Z","title":"VL-Nav: Real-time Vision-Language Navigation with Spatial Reasoning","summary":"  Vision-language navigation in unknown environments is crucial for mobile\nrobots. In scenarios such as household assistance and rescue, mobile robots\nneed to understand a human command, such as \"find a person wearing black\". We\npresent a novel vision-language navigation (VL-Nav) system that integrates\nefficient spatial reasoning on low-power robots. Unlike prior methods that rely\non a single image-level feature similarity to guide a robot, our method\nintegrates pixel-wise vision-language features with curiosity-driven\nexploration. This approach enables robust navigation to human-instructed\ninstances across diverse environments. We deploy VL-Nav on a four-wheel mobile\nrobot and evaluate its performance through comprehensive navigation tasks in\nboth indoor and outdoor environments, spanning different scales and semantic\ncomplexities. Remarkably, VL-Nav operates at a real-time frequency of 30 Hz\nwith a Jetson Orin NX, highlighting its ability to conduct efficient\nvision-language navigation. Results show that VL-Nav achieves an overall\nsuccess rate of 86.3%, outperforming previous methods by 44.15%.\n","authors":["Yi Du","Taimeng Fu","Zhuoqun Chen","Bowen Li","Shaoshu Su","Zhipeng Zhao","Chen Wang"],"pdf_url":"https://arxiv.org/pdf/2502.00931v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.03148v1","updated":"2025-03-05T03:42:59Z","published":"2025-03-05T03:42:59Z","title":"Partial Convolution Meets Visual Attention","summary":"  Designing an efficient and effective neural network has remained a prominent\ntopic in computer vision research. Depthwise onvolution (DWConv) is widely used\nin efficient CNNs or ViTs, but it needs frequent memory access during\ninference, which leads to low throughput. FasterNet attempts to introduce\npartial convolution (PConv) as an alternative to DWConv but compromises the\naccuracy due to underutilized channels. To remedy this shortcoming and consider\nthe redundancy between feature map channels, we introduce a novel Partial\nvisual ATtention mechanism (PAT) that can efficiently combine PConv with visual\nattention. Our exploration indicates that the partial attention mechanism can\ncompletely replace the full attention mechanism and reduce model parameters and\nFLOPs. Our PAT can derive three types of blocks: Partial Channel-Attention\nblock (PAT_ch), Partial Spatial-Attention block (PAT_sp) and Partial\nSelf-Attention block (PAT_sf). First, PAT_ch integrates the enhanced Gaussian\nchannel attention mechanism to infuse global distribution information into the\nuntouched channels of PConv. Second, we introduce the spatial-wise attention to\nthe MLP layer to further improve model accuracy. Finally, we replace PAT_ch in\nthe last stage with the self-attention mechanism to extend the global receptive\nfield. Building upon PAT, we propose a novel hybrid network family, named\nPATNet, which achieves superior top-1 accuracy and inference speed compared to\nFasterNet on ImageNet-1K classification and excel in both detection and\nsegmentation on the COCO dataset. Particularly, our PATNet-T2 achieves 1.3%\nhigher accuracy than FasterNet-T2, while exhibiting 25% higher GPU throughput\nand 24% lower CPU latency.\n","authors":["Haiduo Huang","Fuwei Yang","Dong Li","Ji Liu","Lu Tian","Jinzhang Peng","Pengju Ren","Emad Barsoum"],"pdf_url":"https://arxiv.org/pdf/2503.03148v1.pdf","comment":"arXiv admin note: substantial text overlap with arXiv:2502.01303"},{"id":"http://arxiv.org/abs/2503.03144v1","updated":"2025-03-05T03:37:41Z","published":"2025-03-05T03:37:41Z","title":"Temporal Separation with Entropy Regularization for Knowledge\n  Distillation in Spiking Neural Networks","summary":"  Spiking Neural Networks (SNNs), inspired by the human brain, offer\nsignificant computational efficiency through discrete spike-based information\ntransfer. Despite their potential to reduce inference energy consumption, a\nperformance gap persists between SNNs and Artificial Neural Networks (ANNs),\nprimarily due to current training methods and inherent model limitations. While\nrecent research has aimed to enhance SNN learning by employing knowledge\ndistillation (KD) from ANN teacher networks, traditional distillation\ntechniques often overlook the distinctive spatiotemporal properties of SNNs,\nthus failing to fully leverage their advantages. To overcome these challenge,\nwe propose a novel logit distillation method characterized by temporal\nseparation and entropy regularization. This approach improves existing SNN\ndistillation techniques by performing distillation learning on logits across\ndifferent time steps, rather than merely on aggregated output features.\nFurthermore, the integration of entropy regularization stabilizes model\noptimization and further boosts the performance. Extensive experimental results\nindicate that our method surpasses prior SNN distillation strategies, whether\nbased on logit distillation, feature distillation, or a combination of both.\nThe code will be available on GitHub.\n","authors":["Kairong Yu","Chengting Yu","Tianqing Zhang","Xiaochen Zhao","Shu Yang","Hongwei Wang","Qiang Zhang","Qi Xu"],"pdf_url":"https://arxiv.org/pdf/2503.03144v1.pdf","comment":"Accepted by CVPR 2025"},{"id":"http://arxiv.org/abs/2503.03141v1","updated":"2025-03-05T03:31:05Z","published":"2025-03-05T03:31:05Z","title":"Implicit U-KAN2.0: Dynamic, Efficient and Interpretable Medical Image\n  Segmentation","summary":"  Image segmentation is a fundamental task in both image analysis and medical\napplications. State-of-the-art methods predominantly rely on encoder-decoder\narchitectures with a U-shaped design, commonly referred to as U-Net. Recent\nadvancements integrating transformers and MLPs improve performance but still\nface key limitations, such as poor interpretability, difficulty handling\nintrinsic noise, and constrained expressiveness due to discrete layer\nstructures, often lacking a solid theoretical foundation.In this work, we\nintroduce Implicit U-KAN 2.0, a novel U-Net variant that adopts a two-phase\nencoder-decoder structure. In the SONO phase, we use a second-order neural\nordinary differential equation (NODEs), called the SONO block, for a more\nefficient, expressive, and theoretically grounded modeling approach. In the\nSONO-MultiKAN phase, we integrate the second-order NODEs and MultiKAN layer as\nthe core computational block to enhance interpretability and representation\npower. Our contributions are threefold. First, U-KAN 2.0 is an implicit deep\nneural network incorporating MultiKAN and second order NODEs, improving\ninterpretability and performance while reducing computational costs. Second, we\nprovide a theoretical analysis demonstrating that the approximation ability of\nthe MultiKAN block is independent of the input dimension. Third, we conduct\nextensive experiments on a variety of 2D and a single 3D dataset, demonstrating\nthat our model consistently outperforms existing segmentation networks.\n","authors":["Chun-Wun Cheng","Yining Zhao","Yanqi Cheng","Javier Montoya","Carola-Bibiane Schnlieb","Angelica I Aviles-Rivero"],"pdf_url":"https://arxiv.org/pdf/2503.03141v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2501.05272v2","updated":"2025-03-05T03:26:07Z","published":"2025-01-09T14:31:54Z","title":"Solving the Catastrophic Forgetting Problem in Generalized Category\n  Discovery","summary":"  Generalized Category Discovery (GCD) aims to identify a mix of known and\nnovel categories within unlabeled data sets, providing a more realistic setting\nfor image recognition. Essentially, GCD needs to remember existing patterns\nthoroughly to recognize novel categories. Recent state-of-the-art method SimGCD\ntransfers the knowledge from known-class data to the learning of novel classes\nthrough debiased learning. However, some patterns are catastrophically forgot\nduring adaptation and thus lead to poor performance in novel categories\nclassification. To address this issue, we propose a novel learning approach,\nLegoGCD, which is seamlessly integrated into previous methods to enhance the\ndiscrimination of novel classes while maintaining performance on previously\nencountered known classes. Specifically, we design two types of techniques\ntermed as Local Entropy Regularization (LER) and Dual-views Kullback Leibler\ndivergence constraint (DKL). The LER optimizes the distribution of potential\nknown class samples in unlabeled data, thus ensuring the preservation of\nknowledge related to known categories while learning novel classes. Meanwhile,\nDKL introduces Kullback Leibler divergence to encourage the model to produce a\nsimilar prediction distribution of two view samples from the same image. In\nthis way, it successfully avoids mismatched prediction and generates more\nreliable potential known class samples simultaneously. Extensive experiments\nvalidate that the proposed LegoGCD effectively addresses the known category\nforgetting issue across all datasets, eg, delivering a 7.74% and 2.51% accuracy\nboost on known and novel classes in CUB, respectively. Our code is available\nat: https://github.com/Cliffia123/LegoGCD.\n","authors":["Xinzi Cao","Xiawu Zheng","Guanhong Wang","Weijiang Yu","Yunhang Shen","Ke Li","Yutong Lu","Yonghong Tian"],"pdf_url":"https://arxiv.org/pdf/2501.05272v2.pdf","comment":"Accepted by CVPR 2024"},{"id":"http://arxiv.org/abs/2503.03132v1","updated":"2025-03-05T03:02:59Z","published":"2025-03-05T03:02:59Z","title":"Dynamic Neural Surfaces for Elastic 4D Shape Representation and Analysis","summary":"  We propose a novel framework for the statistical analysis of genus-zero 4D\nsurfaces, i.e., 3D surfaces that deform and evolve over time. This problem is\nparticularly challenging due to the arbitrary parameterizations of these\nsurfaces and their varying deformation speeds, necessitating effective\nspatiotemporal registration. Traditionally, 4D surfaces are discretized, in\nspace and time, before computing their spatiotemporal registrations, geodesics,\nand statistics. However, this approach may result in suboptimal solutions and,\nas we demonstrate in this paper, is not necessary. In contrast, we treat 4D\nsurfaces as continuous functions in both space and time. We introduce Dynamic\nSpherical Neural Surfaces (D-SNS), an efficient smooth and continuous\nspatiotemporal representation for genus-0 4D surfaces. We then demonstrate how\nto perform core 4D shape analysis tasks such as spatiotemporal registration,\ngeodesics computation, and mean 4D shape estimation, directly on these\ncontinuous representations without upfront discretization and meshing. By\nintegrating neural representations with classical Riemannian geometry and\nstatistical shape analysis techniques, we provide the building blocks for\nenabling full functional shape analysis. We demonstrate the efficiency of the\nframework on 4D human and face datasets. The source code and additional results\nare available at https://4d-dsns.github.io/DSNS/.\n","authors":["Awais Nizamani","Hamid Laga","Guanjin Wang","Farid Boussaid","Mohammed Bennamoun","Anuj Srivastava"],"pdf_url":"https://arxiv.org/pdf/2503.03132v1.pdf","comment":"22 pages, 23 figures, conference paper"},{"id":"http://arxiv.org/abs/2412.04814v3","updated":"2025-03-05T02:43:42Z","published":"2024-12-06T07:16:14Z","title":"LiFT: Leveraging Human Feedback for Text-to-Video Model Alignment","summary":"  Recent advances in text-to-video (T2V) generative models have shown\nimpressive capabilities. However, these models are still inadequate in aligning\nsynthesized videos with human preferences (e.g., accurately reflecting text\ndescriptions), which is particularly difficult to address, as human preferences\nare subjective and challenging to formalize as objective functions. Existing\nstudies train video quality assessment models that rely on human-annotated\nratings for video evaluation but overlook the reasoning behind evaluations,\nlimiting their ability to capture nuanced human criteria. Moreover, aligning\nT2V model using video-based human feedback remains unexplored. Therefore, this\npaper proposes LiFT, the first method designed to leverage human feedback for\nT2V model alignment. Specifically, we first construct a Human Rating Annotation\ndataset, LiFT-HRA, consisting of approximately 10k human annotations, each\nincluding a score and its corresponding rationale. Based on this, we train a\nreward model LiFT-Critic to learn reward function effectively, which serves as\na proxy for human judgment, measuring the alignment between given videos and\nhuman expectations. Lastly, we leverage the learned reward function to align\nthe T2V model by maximizing the reward-weighted likelihood. As a case study, we\napply our pipeline to CogVideoX-2B, showing that the fine-tuned model\noutperforms the CogVideoX-5B across all 16 metrics, highlighting the potential\nof human feedback in improving the alignment and quality of synthesized videos.\n","authors":["Yibin Wang","Zhiyu Tan","Junyan Wang","Xiaomeng Yang","Cheng Jin","Hao Li"],"pdf_url":"https://arxiv.org/pdf/2412.04814v3.pdf","comment":"Project page: https://codegoat24.github.io/LiFT"},{"id":"http://arxiv.org/abs/2502.17039v2","updated":"2025-03-05T02:33:16Z","published":"2025-02-24T10:46:28Z","title":"LCV2I: Communication-Efficient and High-Performance Collaborative\n  Perception Framework with Low-Resolution LiDAR","summary":"  Vehicle-to-Infrastructure (V2I) collaborative perception leverages data\ncollected by infrastructure's sensors to enhance vehicle perceptual\ncapabilities. LiDAR, as a commonly used sensor in cooperative perception, is\nwidely equipped in intelligent vehicles and infrastructure. However, its\nsuperior performance comes with a correspondingly high cost. To achieve\nlow-cost V2I, reducing the cost of LiDAR is crucial. Therefore, we study\nadopting low-resolution LiDAR on the vehicle to minimize cost as much as\npossible. However, simply reducing the resolution of vehicle's LiDAR results in\nsparse point clouds, making distant small objects even more blurred.\nAdditionally, traditional communication methods have relatively low bandwidth\nutilization efficiency. These factors pose challenges for us. To balance cost\nand perceptual accuracy, we propose a new collaborative perception framework,\nnamely LCV2I. LCV2I uses data collected from cameras and low-resolution LiDAR\nas input. It also employs feature offset correction modules and regional\nfeature enhancement algorithms to improve feature representation. Finally, we\nuse regional difference map and regional score map to assess the value of\ncollaboration content, thereby improving communication bandwidth efficiency. In\nsummary, our approach achieves high perceptual performance while substantially\nreducing the demand for high-resolution sensors on the vehicle. To evaluate\nthis algorithm, we conduct 3D object detection in the real-world scenario of\nDAIR-V2X, demonstrating that the performance of LCV2I consistently surpasses\ncurrently existing algorithms.\n","authors":["Xinxin Feng","Haoran Sun","Haifeng Zheng"],"pdf_url":"https://arxiv.org/pdf/2502.17039v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2405.16226v4","updated":"2025-03-05T02:30:54Z","published":"2024-05-25T13:34:16Z","title":"Detecting Adversarial Data using Perturbation Forgery","summary":"  As a defense strategy against adversarial attacks, adversarial detection aims\nto identify and filter out adversarial data from the data flow based on\ndiscrepancies in distribution and noise patterns between natural and\nadversarial data. Although previous detection methods achieve high performance\nin detecting gradient-based adversarial attacks, new attacks based on\ngenerative models with imbalanced and anisotropic noise patterns evade\ndetection. Even worse, the significant inference time overhead and limited\nperformance against unseen attacks make existing techniques impractical for\nreal-world use. In this paper, we explore the proximity relationship among\nadversarial noise distributions and demonstrate the existence of an open\ncovering for these distributions. By training on the open covering of\nadversarial noise distributions, a detector with strong generalization\nperformance against various types of unseen attacks can be developed. Based on\nthis insight, we heuristically propose Perturbation Forgery, which includes\nnoise distribution perturbation, sparse mask generation, and pseudo-adversarial\ndata production, to train an adversarial detector capable of detecting any\nunseen gradient-based, generative-based, and physical adversarial attacks.\nComprehensive experiments conducted on multiple general and facial datasets,\nwith a wide spectrum of attacks, validate the strong generalization of our\nmethod.\n","authors":["Qian Wang","Chen Li","Yuchen Luo","Hefei Ling","Shijuan Huang","Ruoxi Jia","Ning Yu"],"pdf_url":"https://arxiv.org/pdf/2405.16226v4.pdf","comment":"Accepted as a conference paper at CVPR 2025"},{"id":"http://arxiv.org/abs/2503.03115v1","updated":"2025-03-05T02:24:13Z","published":"2025-03-05T02:24:13Z","title":"NTR-Gaussian: Nighttime Dynamic Thermal Reconstruction with 4D Gaussian\n  Splatting Based on Thermodynamics","summary":"  Thermal infrared imaging offers the advantage of all-weather capability,\nenabling non-intrusive measurement of an object's surface temperature.\nConsequently, thermal infrared images are employed to reconstruct 3D models\nthat accurately reflect the temperature distribution of a scene, aiding in\napplications such as building monitoring and energy management. However,\nexisting approaches predominantly focus on static 3D reconstruction for a\nsingle time period, overlooking the impact of environmental factors on thermal\nradiation and failing to predict or analyze temperature variations over time.\nTo address these challenges, we propose the NTR-Gaussian method, which treats\ntemperature as a form of thermal radiation, incorporating elements like\nconvective heat transfer and radiative heat dissipation. Our approach utilizes\nneural networks to predict thermodynamic parameters such as emissivity,\nconvective heat transfer coefficient, and heat capacity. By integrating these\npredictions, we can accurately forecast thermal temperatures at various times\nthroughout a nighttime scene. Furthermore, we introduce a dynamic dataset\nspecifically for nighttime thermal imagery. Extensive experiments and\nevaluations demonstrate that NTR-Gaussian significantly outperforms comparison\nmethods in thermal reconstruction, achieving a predicted temperature error\nwithin 1 degree Celsius.\n","authors":["Kun Yang","Yuxiang Liu","Zeyu Cui","Yu Liu","Maojun Zhang","Shen Yan","Qing Wang"],"pdf_url":"https://arxiv.org/pdf/2503.03115v1.pdf","comment":"IEEE Conference on Computer Vision and Pattern Recognition 2025"},{"id":"http://arxiv.org/abs/2503.03111v1","updated":"2025-03-05T02:10:14Z","published":"2025-03-05T02:10:14Z","title":"An Improved Pure Fully Connected Neural Network for Rice Grain\n  Classification","summary":"  Rice is a staple food for a significant portion of the world's population,\nproviding essential nutrients and serving as a versatile in-gredient in a wide\nrange of culinary traditions. Recently, the use of deep learning has enabled\nautomated classification of rice, im-proving accuracy and efficiency. However,\nclassical models based on first-stage training may face difficulties in\ndistinguishing between rice varieties with similar external characteristics,\nthus leading to misclassifications. Considering the transparency and\nfeasibility of model, we selected and gradually improved pure fully connected\nneural network to achieve classification of rice grain. The dataset we used\ncontains both global and domestic rice images obtained from websites and\nlaboratories respectively. First, the training mode was changed from one-stage\ntraining to two-stage training, which significantly contributes to\ndistinguishing two similar types of rice. Secondly, the preprocessing method\nwas changed from random tilting to horizontal or vertical position cor-rection.\nAfter those two enhancements, the accuracy of our model increased notably from\n97% to 99%. In summary, two subtle methods proposed in this study can\nremarkably enhance the classification ability of deep learning models in terms\nof the classification of rice grain.\n","authors":["Wanke Xia","Ruoxin Peng","Haoqi Chu","Xinlei Zhu"],"pdf_url":"https://arxiv.org/pdf/2503.03111v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.03110v1","updated":"2025-03-05T02:10:04Z","published":"2025-03-05T02:10:04Z","title":"WarmFed: Federated Learning with Warm-Start for Globalization and\n  Personalization Via Personalized Diffusion Models","summary":"  Federated Learning (FL) stands as a prominent distributed learning paradigm\namong multiple clients to achieve a unified global model without privacy\nleakage. In contrast to FL, Personalized federated learning aims at serving for\neach client in achieving persoanlized model. However, previous FL frameworks\nhave grappled with a dilemma: the choice between developing a singular global\nmodel at the server to bolster globalization or nurturing personalized model at\nthe client to accommodate personalization. Instead of making trade-offs, this\npaper commences its discourse from the pre-trained initialization, obtaining\nresilient global information and facilitating the development of both global\nand personalized models. Specifically, we propose a novel method called WarmFed\nto achieve this. WarmFed customizes Warm-start through personalized diffusion\nmodels, which are generated by local efficient fine-tunining (LoRA). Building\nupon the Warm-Start, we advance a server-side fine-tuning strategy to derive\nthe global model, and propose a dynamic self-distillation (DSD) to procure more\nresilient personalized models simultaneously. Comprehensive experiments\nunderscore the substantial gains of our approach across both global and\npersonalized models, achieved within just one-shot and five communication(s).\n","authors":["Tao Feng","Jie Zhang","Xiangjian Li","Rong Huang","Huashan Liu","Zhijie Wang"],"pdf_url":"https://arxiv.org/pdf/2503.03110v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2412.15050v4","updated":"2025-03-05T02:09:23Z","published":"2024-12-19T16:57:45Z","title":"Uni-Renderer: Unifying Rendering and Inverse Rendering Via Dual Stream\n  Diffusion","summary":"  Rendering and inverse rendering are pivotal tasks in both computer vision and\ngraphics. The rendering equation is the core of the two tasks, as an ideal\nconditional distribution transfer function from intrinsic properties to RGB\nimages. Despite achieving promising results of existing rendering methods, they\nmerely approximate the ideal estimation for a specific scene and come with a\nhigh computational cost. Additionally, the inverse conditional distribution\ntransfer is intractable due to the inherent ambiguity. To address these\nchallenges, we propose a data-driven method that jointly models rendering and\ninverse rendering as two conditional generation tasks within a single diffusion\nframework. Inspired by UniDiffuser, we utilize two distinct time schedules to\nmodel both tasks, and with a tailored dual streaming module, we achieve\ncross-conditioning of two pre-trained diffusion models. This unified approach,\nnamed Uni-Renderer, allows the two processes to facilitate each other through a\ncycle-consistent constrain, mitigating ambiguity by enforcing consistency\nbetween intrinsic properties and rendered images. Combined with a meticulously\nprepared dataset, our method effectively decomposition of intrinsic properties\nand demonstrates a strong capability to recognize changes during rendering. We\nwill open-source our training and inference code to the public, fostering\nfurther research and development in this area.\n","authors":["Zhifei Chen","Tianshuo Xu","Wenhang Ge","Leyi Wu","Dongyu Yan","Jing He","Luozhou Wang","Lu Zeng","Shunsi Zhang","Yingcong Chen"],"pdf_url":"https://arxiv.org/pdf/2412.15050v4.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.01582v2","updated":"2025-03-05T02:02:19Z","published":"2025-03-03T14:23:37Z","title":"Category-level Meta-learned NeRF Priors for Efficient Object Mapping","summary":"  In 3D object mapping, category-level priors enable efficient object\nreconstruction and canonical pose estimation, requiring only a single prior per\nsemantic category (e.g., chair, book, laptop). Recently, DeepSDF has\npredominantly been used as a category-level shape prior, but it struggles to\nreconstruct sharp geometry and is computationally expensive. In contrast, NeRFs\ncapture fine details but have yet to be effectively integrated with\ncategory-level priors in a real-time multi-object mapping framework. To bridge\nthis gap, we introduce PRENOM, a Prior-based Efficient Neural Object Mapper\nthat integrates category-level priors with object-level NeRFs to enhance\nreconstruction efficiency while enabling canonical object pose estimation.\nPRENOM gets to know objects on a first-name basis by meta-learning on synthetic\nreconstruction tasks generated from open-source shape datasets. To account for\nobject category variations, it employs a multi-objective genetic algorithm to\noptimize the NeRF architecture for each category, balancing reconstruction\nquality and training time. Additionally, prior-based probabilistic ray sampling\ndirects sampling toward expected object regions, accelerating convergence and\nimproving reconstruction quality under constrained resources. Experimental\nresults on a low-end GPU highlight the ability of PRENOM to achieve\nhigh-quality reconstructions while maintaining computational feasibility.\nSpecifically, comparisons with prior-free NeRF-based approaches on a synthetic\ndataset show a 21% lower Chamfer distance, demonstrating better reconstruction\nquality. Furthermore, evaluations against other approaches using shape priors\non a noisy real-world dataset indicate a 13% improvement averaged across all\nreconstruction metrics, and comparable pose and size estimation accuracy, while\nbeing trained for 5x less time.\n","authors":["Saad Ejaz","Hriday Bavle","Laura Ribeiro","Holger Voos","Jose Luis Sanchez-Lopez"],"pdf_url":"https://arxiv.org/pdf/2503.01582v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2405.17859v3","updated":"2025-03-05T01:48:25Z","published":"2024-05-28T06:16:57Z","title":"Adapting Pre-Trained Vision Models for Novel Instance Detection and\n  Segmentation","summary":"  Novel Instance Detection and Segmentation (NIDS) aims at detecting and\nsegmenting novel object instances given a few examples of each instance. We\npropose a unified, simple, yet effective framework (NIDS-Net) comprising object\nproposal generation, embedding creation for both instance templates and\nproposal regions, and embedding matching for instance label assignment.\nLeveraging recent advancements in large vision methods, we utilize Grounding\nDINO and Segment Anything Model (SAM) to obtain object proposals with accurate\nbounding boxes and masks. Central to our approach is the generation of\nhigh-quality instance embeddings. We utilized foreground feature averages of\npatch embeddings from the DINOv2 ViT backbone, followed by refinement through a\nweight adapter mechanism that we introduce.\n  We show experimentally that our weight adapter can adjust the embeddings\nlocally within their feature space and effectively limit overfitting in the\nfew-shot setting. Furthermore, the weight adapter optimizes weights to enhance\nthe distinctiveness of instance embeddings during similarity computation. This\nmethodology enables a straightforward matching strategy that results in\nsignificant performance gains. Our framework surpasses current state-of-the-art\nmethods, demonstrating notable improvements in four detection datasets. In the\nsegmentation tasks on seven core datasets of the BOP challenge, our method\noutperforms the leading published RGB methods and remains competitive with the\nbest RGB-D method. We have also verified our method using real-world images\nfrom a Fetch robot and a RealSense camera. Project Page:\nhttps://irvlutd.github.io/NIDSNet/\n","authors":["Yangxiao Lu","Jishnu Jaykumar P","Yunhui Guo","Nicholas Ruozzi","Yu Xiang"],"pdf_url":"https://arxiv.org/pdf/2405.17859v3.pdf","comment":"Project Page: https://irvlutd.github.io/NIDSNet/"},{"id":"http://arxiv.org/abs/2503.03104v1","updated":"2025-03-05T01:41:59Z","published":"2025-03-05T01:41:59Z","title":"RVAFM: Re-parameterizing Vertical Attention Fusion Module for\n  Handwritten Paragraph Text Recognition","summary":"  Handwritten Paragraph Text Recognition (HPTR) is a challenging task in\nComputer Vision, requiring the transformation of a paragraph text image, rich\nin handwritten text, into text encoding sequences. One of the most advanced\nmodels for this task is Vertical Attention Network (VAN), which utilizes a\nVertical Attention Module (VAM) to implicitly segment paragraph text images\ninto text lines, thereby reducing the difficulty of the recognition task.\nHowever, from a network structure perspective, VAM is a single-branch module,\nwhich is less effective in learning compared to multi-branch modules. In this\npaper, we propose a new module, named Re-parameterizing Vertical Attention\nFusion Module (RVAFM), which incorporates structural re-parameterization\ntechniques. RVAFM decouples the structure of the module during training and\ninference stages. During training, it uses a multi-branch structure for more\neffective learning, and during inference, it uses a single-branch structure for\nfaster processing. The features learned by the multi-branch structure are fused\ninto the single-branch structure through a special fusion method named\nRe-parameterization Fusion (RF) without any loss of information. As a result,\nwe achieve a Character Error Rate (CER) of 4.44% and a Word Error Rate (WER) of\n14.37% on the IAM paragraph-level test set. Additionally, the inference speed\nis slightly faster than VAN.\n","authors":["Jinhui Zheng","Zhiquan Liu","Yain-Whar Si","Jianqing Li","Xinyuan Zhang","Xiaofan Li","Haozhi Huang","Xueyuan Gong"],"pdf_url":"https://arxiv.org/pdf/2503.03104v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2502.13524v3","updated":"2025-03-05T01:21:38Z","published":"2025-02-19T08:21:59Z","title":"MobileViM: A Light-weight and Dimension-independent Vision Mamba for 3D\n  Medical Image Analysis","summary":"  Efficient evaluation of three-dimensional (3D) medical images is crucial for\ndiagnostic and therapeutic practices in healthcare. Recent years have seen a\nsubstantial uptake in applying deep learning and computer vision to analyse and\ninterpret medical images. Traditional approaches, such as convolutional neural\nnetworks (CNNs) and vision transformers (ViTs), face significant computational\nchallenges, prompting the need for architectural advancements. Recent efforts\nhave led to the introduction of novel architectures like the ``Mamba'' model as\nalternative solutions to traditional CNNs or ViTs. The Mamba model excels in\nthe linear processing of one-dimensional data with low computational demands.\nHowever, Mamba's potential for 3D medical image analysis remains underexplored\nand could face significant computational challenges as the dimension increases.\nThis manuscript presents MobileViM, a streamlined architecture for efficient\nsegmentation of 3D medical images. In the MobileViM network, we invent a new\ndimension-independent mechanism and a dual-direction traversing approach to\nincorporate with a vision-Mamba-based framework. MobileViM also features a\ncross-scale bridging technique to improve efficiency and accuracy across\nvarious medical imaging modalities. With these enhancements, MobileViM achieves\nsegmentation speeds exceeding 90 frames per second (FPS) on a single graphics\nprocessing unit (i.e., NVIDIA RTX 4090). This performance is over 24 FPS faster\nthan the state-of-the-art deep learning models for processing 3D images with\nthe same computational resources. In addition, experimental evaluations\ndemonstrate that MobileViM delivers superior performance, with Dice similarity\nscores reaching 92.72%, 86.69%, 80.46%, and 77.43% for PENGWIN, BraTS2024,\nATLAS, and Toothfairy2 datasets, respectively, which significantly surpasses\nexisting models.\n","authors":["Wei Dai","Jun Liu"],"pdf_url":"https://arxiv.org/pdf/2502.13524v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2502.09795v2","updated":"2025-03-05T01:09:24Z","published":"2025-02-13T22:10:21Z","title":"Vision-based Geo-Localization of Future Mars Rotorcraft in Challenging\n  Illumination Conditions","summary":"  Planetary exploration using aerial assets has the potential for unprecedented\nscientific discoveries on Mars. While NASA's Mars helicopter Ingenuity proved\nflight in Martian atmosphere is possible, future Mars rotocrafts will require\nadvanced navigation capabilities for long-range flights. One such critical\ncapability is Map-based Localization (MbL) which registers an onboard image to\na reference map during flight in order to mitigate cumulative drift from visual\nodometry. However, significant illumination differences between rotocraft\nobservations and a reference map prove challenging for traditional MbL systems,\nrestricting the operational window of the vehicle. In this work, we investigate\na new MbL system and propose Geo-LoFTR, a geometry-aided deep learning model\nfor image registration that is more robust under large illumination differences\nthan prior models. The system is supported by a custom simulation framework\nthat uses real orbital maps to produce large amounts of realistic images of the\nMartian terrain. Comprehensive evaluations show that our proposed system\noutperforms prior MbL efforts in terms of localization accuracy under\nsignificant lighting and scale variations. Furthermore, we demonstrate the\nvalidity of our approach across a simulated Martian day.\n","authors":["Dario Pisanti","Robert Hewitt","Roland Brockers","Georgios Georgakis"],"pdf_url":"https://arxiv.org/pdf/2502.09795v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.03088v1","updated":"2025-03-05T01:04:45Z","published":"2025-03-05T01:04:45Z","title":"AHCPTQ: Accurate and Hardware-Compatible Post-Training Quantization for\n  Segment Anything Model","summary":"  The Segment Anything Model (SAM) has demonstrated strong versatility across\nvarious visual tasks. However, its large storage requirements and high\ncomputational cost pose challenges for practical deployment. Post-training\nquantization (PTQ) has emerged as an effective strategy for efficient\ndeployment, but we identify two key challenges in SAM that hinder the\neffectiveness of existing PTQ methods: the heavy-tailed and skewed distribution\nof post-GELU activations, and significant inter-channel variation in linear\nprojection activations. To address these challenges, we propose AHCPTQ, an\naccurate and hardware-efficient PTQ method for SAM. AHCPTQ introduces\nhardware-compatible Hybrid Log-Uniform Quantization (HLUQ) to manage post-GELU\nactivations, employing log2 quantization for dense small values and uniform\nquantization for sparse large values to enhance quantization resolution.\nAdditionally, AHCPTQ incorporates Channel-Aware Grouping (CAG) to mitigate\ninter-channel variation by progressively clustering activation channels with\nsimilar distributions, enabling them to share quantization parameters and\nimproving hardware efficiency. The combination of HLUQ and CAG not only\nenhances quantization effectiveness but also ensures compatibility with\nefficient hardware execution. For instance, under the W4A4 configuration on the\nSAM-L model, AHCPTQ achieves 36.6% mAP on instance segmentation with the DINO\ndetector, while achieving a 7.89x speedup and 8.64x energy efficiency over its\nfloating-point counterpart in FPGA implementation.\n","authors":["Wenlun Zhang","Shimpei Ando","Kentaro Yoshioka"],"pdf_url":"https://arxiv.org/pdf/2503.03088v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.01962v2","updated":"2025-03-05T00:41:20Z","published":"2024-10-02T19:10:23Z","title":"LS-HAR: Language Supervised Human Action Recognition with Salient\n  Fusion, Construction Sites as a Use-Case","summary":"  Detecting human actions is a crucial task for autonomous robots and vehicles,\noften requiring the integration of various data modalities for improved\naccuracy. In this study, we introduce a novel approach to Human Action\nRecognition (HAR) using language supervision named LS-HAR based on skeleton and\nvisual cues. Our method leverages a language model to guide the feature\nextraction process in the skeleton encoder. Specifically, we employ learnable\nprompts for the language model conditioned on the skeleton modality to optimize\nfeature representation. Furthermore, we propose a fusion mechanism that\ncombines dual-modality features using a salient fusion module, incorporating\nattention and transformer mechanisms to address the modalities' high\ndimensionality. This fusion process prioritizes informative video frames and\nbody joints, enhancing the recognition accuracy of human actions. Additionally,\nwe introduce a new dataset tailored for real-world robotic applications in\nconstruction sites, featuring visual, skeleton, and depth data modalities,\nnamed VolvoConstAct. This dataset serves to facilitate the training and\nevaluation of machine learning models to instruct autonomous construction\nmachines for performing necessary tasks in real-world construction sites. To\nevaluate our approach, we conduct experiments on our dataset as well as three\nwidely used public datasets: NTU-RGB+D, NTU-RGB+D 120, and NW-UCLA. Results\nreveal that our proposed method achieves promising performance across all\ndatasets, demonstrating its robustness and potential for various applications.\nThe code, dataset, and demonstration of real-machine experiments are available\nat: https://mmahdavian.github.io/ls_har/\n","authors":["Mohammad Mahdavian","Mohammad Loni","Ted Samuelsson","Mo Chen"],"pdf_url":"https://arxiv.org/pdf/2410.01962v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2407.17457v3","updated":"2025-03-05T00:32:49Z","published":"2024-07-24T17:50:00Z","title":"CSCPR: Cross-Source-Context Indoor RGB-D Place Recognition","summary":"  We extend our previous work, PoCo, and present a new algorithm,\nCross-Source-Context Place Recognition (CSCPR), for RGB-D indoor place\nrecognition that integrates global retrieval and reranking into an end-to-end\nmodel and keeps the consistency of using Context-of-Clusters (CoCs) for feature\nprocessing. Unlike prior approaches that primarily focus on the RGB domain for\nplace recognition reranking, CSCPR is designed to handle the RGB-D data. We\napply the CoCs to handle cross-sourced and cross-scaled RGB-D point clouds and\nintroduce two novel modules for reranking: the Self-Context Cluster (SCC) and\nthe Cross Source Context Cluster (CSCC), which enhance feature representation\nand match query-database pairs based on local features, respectively. We also\nrelease two new datasets, ScanNetIPR and ARKitIPR. Our experiments demonstrate\nthat CSCPR significantly outperforms state-of-the-art models on these datasets\nby at least 29.27% in Recall@1 on the ScanNet-PR dataset and 43.24% in the new\ndatasets. Code and datasets will be released.\n","authors":["Jing Liang","Zhuo Deng","Zheming Zhou","Min Sun","Omid Ghasemalizadeh","Cheng-Hao Kuo","Arnie Sen","Dinesh Manocha"],"pdf_url":"https://arxiv.org/pdf/2407.17457v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.03074v1","updated":"2025-03-05T00:27:32Z","published":"2025-03-05T00:27:32Z","title":"BEVDriver: Leveraging BEV Maps in LLMs for Robust Closed-Loop Driving","summary":"  Autonomous driving has the potential to set the stage for more efficient\nfuture mobility, requiring the research domain to establish trust through safe,\nreliable and transparent driving. Large Language Models (LLMs) possess\nreasoning capabilities and natural language understanding, presenting the\npotential to serve as generalized decision-makers for ego-motion planning that\ncan interact with humans and navigate environments designed for human drivers.\nWhile this research avenue is promising, current autonomous driving approaches\nare challenged by combining 3D spatial grounding and the reasoning and language\ncapabilities of LLMs. We introduce BEVDriver, an LLM-based model for end-to-end\nclosed-loop driving in CARLA that utilizes latent BEV features as perception\ninput. BEVDriver includes a BEV encoder to efficiently process multi-view\nimages and 3D LiDAR point clouds. Within a common latent space, the BEV\nfeatures are propagated through a Q-Former to align with natural language\ninstructions and passed to the LLM that predicts and plans precise future\ntrajectories while considering navigation instructions and critical scenarios.\nOn the LangAuto benchmark, our model reaches up to 18.9% higher performance on\nthe Driving Score compared to SoTA methods.\n","authors":["Katharina Winter","Mark Azer","Fabian B. Flohr"],"pdf_url":"https://arxiv.org/pdf/2503.03074v1.pdf","comment":"This work has been submitted to the IEEE for possible publication"},{"id":"http://arxiv.org/abs/2503.03068v1","updated":"2025-03-05T00:16:09Z","published":"2025-03-05T00:16:09Z","title":"Multi-View Depth Consistent Image Generation Using Generative AI Models:\n  Application on Architectural Design of University Buildings","summary":"  In the early stages of architectural design, shoebox models are typically\nused as a simplified representation of building structures but require\nextensive operations to transform them into detailed designs. Generative\nartificial intelligence (AI) provides a promising solution to automate this\ntransformation, but ensuring multi-view consistency remains a significant\nchallenge. To solve this issue, we propose a novel three-stage consistent image\ngeneration framework using generative AI models to generate architectural\ndesigns from shoebox model representations. The proposed method enhances\nstate-of-the-art image generation diffusion models to generate multi-view\nconsistent architectural images. We employ ControlNet as the backbone and\noptimize it to accommodate multi-view inputs of architectural shoebox models\ncaptured from predefined perspectives. To ensure stylistic and structural\nconsistency across multi-view images, we propose an image space loss module\nthat incorporates style loss, structural loss and angle alignment loss. We then\nuse depth estimation method to extract depth maps from the generated multi-view\nimages. Finally, we use the paired data of the architectural images and depth\nmaps as inputs to improve the multi-view consistency via the depth-aware 3D\nattention module. Experimental results demonstrate that the proposed framework\ncan generate multi-view architectural images with consistent style and\nstructural coherence from shoebox model inputs.\n","authors":["Xusheng Du","Ruihan Gui","Zhengyang Wang","Ye Zhang","Haoran Xie"],"pdf_url":"https://arxiv.org/pdf/2503.03068v1.pdf","comment":"10 pages, 7 figures, in Proceedings of CAADRIA2025"}],"Information Retrieval":[{"id":"http://arxiv.org/abs/2503.01711v3","updated":"2025-03-05T05:52:00Z","published":"2025-03-03T16:24:36Z","title":"MAPS: Motivation-Aware Personalized Search via LLM-Driven Consultation\n  Alignment","summary":"  Personalized product search aims to retrieve and rank items that match users'\npreferences and search intent. Despite their effectiveness, existing approaches\ntypically assume that users' query fully captures their real motivation.\nHowever, our analysis of a real-world e-commerce platform reveals that users\noften engage in relevant consultations before searching, indicating they refine\nintents through consultations based on motivation and need. The implied\nmotivation in consultations is a key enhancing factor for personalized search.\nThis unexplored area comes with new challenges including aligning contextual\nmotivations with concise queries, bridging the category-text gap, and filtering\nnoise within sequence history. To address these, we propose a Motivation-Aware\nPersonalized Search (MAPS) method. It embeds queries and consultations into a\nunified semantic space via LLMs, utilizes a Mixture of Attention Experts (MoAE)\nto prioritize critical semantics, and introduces dual alignment: (1)\ncontrastive learning aligns consultations, reviews, and product features; (2)\nbidirectional attention integrates motivation-aware embeddings with user\npreferences. Extensive experiments on real and synthetic data show MAPS\noutperforms existing methods in both retrieval and ranking tasks.\n","authors":["Weicong Qin","Yi Xu","Weijie Yu","Chenglei Shen","Ming He","Jianping Fan","Xiao Zhang","Jun Xu"],"pdf_url":"https://arxiv.org/pdf/2503.01711v3.pdf","comment":"added project repository & dataset URL"},{"id":"http://arxiv.org/abs/2503.01776v2","updated":"2025-03-05T17:51:09Z","published":"2025-03-03T17:59:48Z","title":"Beyond Matryoshka: Revisiting Sparse Coding for Adaptive Representation","summary":"  Many large-scale systems rely on high-quality deep representations\n(embeddings) to facilitate tasks like retrieval, search, and generative\nmodeling. Matryoshka Representation Learning (MRL) recently emerged as a\nsolution for adaptive embedding lengths, but it requires full model retraining\nand suffers from noticeable performance degradations at short lengths. In this\npaper, we show that sparse coding offers a compelling alternative for achieving\nadaptive representation with minimal overhead and higher fidelity. We propose\nContrastive Sparse Representation (CSR), a method that sparsifies pre-trained\nembeddings into a high-dimensional but selectively activated feature space. By\nleveraging lightweight autoencoding and task-aware contrastive objectives, CSR\npreserves semantic quality while allowing flexible, cost-effective inference at\ndifferent sparsity levels. Extensive experiments on image, text, and multimodal\nbenchmarks demonstrate that CSR consistently outperforms MRL in terms of both\naccuracy and retrieval speed-often by large margins-while also cutting training\ntime to a fraction of that required by MRL. Our results establish sparse coding\nas a powerful paradigm for adaptive representation learning in real-world\napplications where efficiency and fidelity are both paramount. Code is\navailable at https://github.com/neilwen987/CSR_Adaptive_Rep\n","authors":["Tiansheng Wen","Yifei Wang","Zequn Zeng","Zhong Peng","Yudi Su","Xinyang Liu","Bo Chen","Hongwei Liu","Stefanie Jegelka","Chenyu You"],"pdf_url":"https://arxiv.org/pdf/2503.01776v2.pdf","comment":"A novel sparse coding framework designed for learning adaptive\n  representation"},{"id":"http://arxiv.org/abs/2503.03687v1","updated":"2025-03-05T17:28:16Z","published":"2025-03-05T17:28:16Z","title":"Addressing Overprescribing Challenges: Fine-Tuning Large Language Models\n  for Medication Recommendation Tasks","summary":"  Medication recommendation systems have garnered attention within healthcare\nfor their potential to deliver personalized and efficacious drug combinations\nbased on patient's clinical data. However, existing methodologies encounter\nchallenges in adapting to diverse Electronic Health Records (EHR) systems and\neffectively utilizing unstructured data, resulting in limited generalization\ncapabilities and suboptimal performance. Recently, interest is growing in\nharnessing Large Language Models (LLMs) in the medical domain to support\nhealthcare professionals and enhance patient care. Despite the emergence of\nmedical LLMs and their promising results in tasks like medical question\nanswering, their practical applicability in clinical settings, particularly in\nmedication recommendation, often remains underexplored.\n  In this study, we evaluate both general-purpose and medical-specific LLMs for\nmedication recommendation tasks. Our findings reveal that LLMs frequently\nencounter the challenge of overprescribing, leading to heightened clinical\nrisks and diminished medication recommendation accuracy. To address this issue,\nwe propose Language-Assisted Medication Recommendation (LAMO), which employs a\nparameter-efficient fine-tuning approach to tailor open-source LLMs for optimal\nperformance in medication recommendation scenarios. LAMO leverages the wealth\nof clinical information within clinical notes, a resource often underutilized\nin traditional methodologies. As a result of our approach, LAMO outperforms\nprevious state-of-the-art methods by over 10% in internal validation accuracy.\nFurthermore, temporal and external validations demonstrate LAMO's robust\ngeneralization capabilities across various temporal and hospital contexts.\nAdditionally, an out-of-distribution medication recommendation experiment\ndemonstrates LAMO's remarkable accuracy even with medications outside the\ntraining data.\n","authors":["Zihao Zhao","Chenxiao Fan","Chongming Gao","Fuli Feng","Xiangnan He"],"pdf_url":"https://arxiv.org/pdf/2503.03687v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.03606v1","updated":"2025-03-05T15:42:37Z","published":"2025-03-05T15:42:37Z","title":"Decoupled Recommender Systems: Exploring Alternative Recommender\n  Ecosystem Designs","summary":"  Recommender ecosystems are an emerging subject of research. Such research\nexamines how the characteristics of algorithms, recommendation consumers, and\nitem providers influence system dynamics and long-term outcomes. One\narchitectural possibility that has not yet been widely explored in this line of\nresearch is the consequences of a configuration in which recommendation\nalgorithms are decoupled from the platforms they serve. This is sometimes\ncalled \"the friendly neighborhood algorithm store\" or \"middleware\" model. We\nare particularly interested in how such architectures might offer a range of\ndifferent distributions of utility across consumers, providers, and\nrecommendation platforms. In this paper, we create a model of a recommendation\necosystem that incorporates algorithm choice and examine the outcomes of such a\ndesign.\n","authors":["Anas Buhayh","Elizabeth McKinnie","Robin Burke"],"pdf_url":"https://arxiv.org/pdf/2503.03606v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.03524v1","updated":"2025-03-05T14:08:53Z","published":"2025-03-05T14:08:53Z","title":"Intrinsic and Extrinsic Factor Disentanglement for Recommendation in\n  Various Context Scenarios","summary":"  In recommender systems, the patterns of user behaviors (e.g., purchase,\nclick) may vary greatly in different contexts (e.g., time and location). This\nis because user behavior is jointly determined by two types of factors:\nintrinsic factors, which reflect consistent user preference, and extrinsic\nfactors, which reflect external incentives that may vary in different contexts.\nDifferentiating between intrinsic and extrinsic factors helps learn user\nbehaviors better. However, existing studies have only considered\ndifferentiating them from a single, pre-defined context (e.g., time or\nlocation), ignoring the fact that a user's extrinsic factors may be influenced\nby the interplay of various contexts at the same time. In this paper, we\npropose the Intrinsic-Extrinsic Disentangled Recommendation (IEDR) model, a\ngeneric framework that differentiates intrinsic from extrinsic factors\nconsidering various contexts simultaneously, enabling more accurate\ndifferentiation of factors and hence the improvement of recommendation\naccuracy. IEDR contains a context-invariant contrastive learning component to\ncapture intrinsic factors, and a disentanglement component to extract extrinsic\nfactors under the interplay of various contexts. The two components work\ntogether to achieve effective factor learning. Extensive experiments on\nreal-world datasets demonstrate IEDR's effectiveness in learning disentangled\nfactors and significantly improving recommendation accuracy by up to 4% in\nNDCG.\n","authors":["Yixin Su","Wei Jiang","Fangquan Lin","Cheng Yang","Sarah M. Erfani","Junhao Gan","Yunxiang Zhao","Ruixuan Li","Rui Zhang"],"pdf_url":"https://arxiv.org/pdf/2503.03524v1.pdf","comment":"32 pages, 13 figures, 11 tables. Accepted by Transactions of\n  Information Systems"},{"id":"http://arxiv.org/abs/2410.23841v2","updated":"2025-03-05T12:10:57Z","published":"2024-10-31T11:47:21Z","title":"Beyond Content Relevance: Evaluating Instruction Following in Retrieval\n  Models","summary":"  Instruction-following capabilities in LLMs have progressed significantly,\nenabling more complex user interactions through detailed prompts. However,\nretrieval systems have not matched these advances, most of them still relies on\ntraditional lexical and semantic matching techniques that fail to fully capture\nuser intent. Recent efforts have introduced instruction-aware retrieval models,\nbut these primarily focus on intrinsic content relevance, which neglects the\nimportance of customized preferences for broader document-level attributes.\nThis study evaluates the instruction-following capabilities of various\nretrieval models beyond content relevance, including LLM-based dense retrieval\nand reranking models. We develop InfoSearch, a novel retrieval evaluation\nbenchmark spanning six document-level attributes: Audience, Keyword, Format,\nLanguage, Length, and Source, and introduce novel metrics -- Strict Instruction\nCompliance Ratio (SICR) and Weighted Instruction Sensitivity Evaluation (WISE)\nto accurately assess the models' responsiveness to instructions. Our findings\nindicate that although fine-tuning models on instruction-aware retrieval\ndatasets and increasing model size enhance performance, most models still fall\nshort of instruction compliance.\n","authors":["Jianqun Zhou","Yuanlei Zheng","Wei Chen","Qianqian Zheng","Hui Su","Wei Zhang","Rui Meng","Xiaoyu Shen"],"pdf_url":"https://arxiv.org/pdf/2410.23841v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2502.09155v2","updated":"2025-03-05T07:48:05Z","published":"2025-02-13T10:36:17Z","title":"Use of Air Quality Sensor Network Data for Real-time Pollution-Aware POI\n  Suggestion","summary":"  This demo paper introduces AirSense-R, a privacy-preserving mobile\napplication that delivers real-time, pollution-aware recommendations for urban\npoints of interest (POIs). By merging live air quality data from AirSENCE\nsensor networks in Bari (Italy) and Cork (Ireland) with user preferences, the\nsystem enables health-conscious decision-making. It employs collaborative\nfiltering for personalization, federated learning for privacy, and a prediction\nengine to detect anomalies and interpolate sparse sensor data. The proposed\nsolution adapts dynamically to urban air quality while safeguarding user\nprivacy. The code and demonstration video are available at\nhttps://github.com/AirtownApp/Airtown-Application.git.\n","authors":["Giuseppe Fasano","Yashar Deldjoo","Tommaso di Noia","Bianca Lau","Sina Adham-Khiabani","Eric Morris","Xia Liu","Ganga Chinna Rao Devarapu","Liam O'Faolain"],"pdf_url":"https://arxiv.org/pdf/2502.09155v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.03165v1","updated":"2025-03-05T04:16:36Z","published":"2025-03-05T04:16:36Z","title":"A Predict-Then-Optimize Customer Allocation Framework for Online Fund\n  Recommendation","summary":"  With the rapid growth of online investment platforms, funds can be\ndistributed to individual customers online. The central issue is to match funds\nwith potential customers under constraints. Most mainstream platforms adopt the\nrecommendation formulation to tackle the problem. However, the traditional\nrecommendation regime has its inherent drawbacks when applying the\nfund-matching problem with multiple constraints. In this paper, we model the\nfund matching under the allocation formulation. We design PTOFA, a\nPredict-Then-Optimize Fund Allocation framework. This data-driven framework\nconsists of two stages, i.e., prediction and optimization, which aim to predict\nexpected revenue based on customer behavior and optimize the impression\nallocation to achieve the maximum revenue under the necessary constraints,\nrespectively. Extensive experiments on real-world datasets from an industrial\nonline investment platform validate the effectiveness and efficiency of our\nsolution. Additionally, the online A/B tests demonstrate PTOFA's effectiveness\nin the real-world fund recommendation scenario.\n","authors":["Xing Tang","Yunpeng Weng","Fuyuan Lyu","Dugang Liu","Xiuqiang He"],"pdf_url":"https://arxiv.org/pdf/2503.03165v1.pdf","comment":"Accepted by DASFAA 2025"},{"id":"http://arxiv.org/abs/2503.02589v2","updated":"2025-03-05T03:28:29Z","published":"2025-03-04T13:12:39Z","title":"MCiteBench: A Benchmark for Multimodal Citation Text Generation in MLLMs","summary":"  Multimodal Large Language Models (MLLMs) have advanced in integrating diverse\nmodalities but frequently suffer from hallucination. A promising solution to\nmitigate this issue is to generate text with citations, providing a transparent\nchain for verification. However, existing work primarily focuses on generating\ncitations for text-only content, overlooking the challenges and opportunities\nof multimodal contexts. To address this gap, we introduce MCiteBench, the first\nbenchmark designed to evaluate and analyze the multimodal citation text\ngeneration ability of MLLMs. Our benchmark comprises data derived from academic\npapers and review-rebuttal interactions, featuring diverse information sources\nand multimodal content. We comprehensively evaluate models from multiple\ndimensions, including citation quality, source reliability, and answer\naccuracy. Through extensive experiments, we observe that MLLMs struggle with\nmultimodal citation text generation. We also conduct deep analyses of models'\nperformance, revealing that the bottleneck lies in attributing the correct\nsources rather than understanding the multimodal content.\n","authors":["Caiyu Hu","Yikai Zhang","Tinghui Zhu","Yiwei Ye","Yanghua Xiao"],"pdf_url":"https://arxiv.org/pdf/2503.02589v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.02604v2","updated":"2025-03-05T02:48:49Z","published":"2024-10-03T15:45:15Z","title":"Long-Sequence Recommendation Models Need Decoupled Embeddings","summary":"  Lifelong user behavior sequences are crucial for capturing user interests and\npredicting user responses in modern recommendation systems. A two-stage\nparadigm is typically adopted to handle these long sequences: a subset of\nrelevant behaviors is first searched from the original long sequences via an\nattention mechanism in the first stage and then aggregated with the target item\nto construct a discriminative representation for prediction in the second\nstage. In this work, we identify and characterize, for the first time, a\nneglected deficiency in existing long-sequence recommendation models: a single\nset of embeddings struggles with learning both attention and representation,\nleading to interference between these two processes. Initial attempts to\naddress this issue with some common methods (e.g., linear projections -- a\ntechnique borrowed from language processing) proved ineffective, shedding light\non the unique challenges of recommendation models. To overcome this, we propose\nthe Decoupled Attention and Representation Embeddings (DARE) model, where two\ndistinct embedding tables are initialized and learned separately to fully\ndecouple attention and representation. Extensive experiments and analysis\ndemonstrate that DARE provides more accurate searches of correlated behaviors\nand outperforms baselines with AUC gains up to 0.9% on public datasets and\nnotable improvements on Tencent's advertising platform. Furthermore, decoupling\nembedding spaces allows us to reduce the attention embedding dimension and\naccelerate the search procedure by 50% without significant performance impact,\nenabling more efficient, high-performance online serving. Code in PyTorch for\nexperiments, including model analysis, is available at\nhttps://github.com/thuml/DARE.\n","authors":["Ningya Feng","Junwei Pan","Jialong Wu","Baixu Chen","Ximei Wang","Qian Li","Xian Hu","Jie Jiang","Mingsheng Long"],"pdf_url":"https://arxiv.org/pdf/2410.02604v2.pdf","comment":"ICLR 2025. First three authors contributed equally. Code is available\n  at https://github.com/thuml/DARE"},{"id":"http://arxiv.org/abs/2503.02603v2","updated":"2025-03-05T02:13:38Z","published":"2025-03-04T13:21:47Z","title":"OkraLong: A Flexible Retrieval-Augmented Framework for Long-Text Query\n  Processing","summary":"  Large Language Models (LLMs) encounter challenges in efficiently processing\nlong-text queries, as seen in applications like enterprise document analysis\nand financial report comprehension. While conventional solutions employ\nlong-context processing or Retrieval-Augmented Generation (RAG), they suffer\nfrom prohibitive input expenses or incomplete information. Recent advancements\nadopt context compression and dynamic retrieval loops, but still sacrifice\ncritical details or incur iterative costs. To address these limitations, we\npropose OkraLong, a novel framework that flexibly optimizes the entire\nprocessing workflow. Unlike prior static or coarse-grained adaptive strategies,\nOkraLong adopts fine-grained orchestration through three synergistic\ncomponents: analyzer, organizer and executor. The analyzer characterizes the\ntask states, which guide the organizer in dynamically scheduling the workflow.\nThe executor carries out the execution and generates the final answer.\nExperimental results demonstrate that OkraLong not only enhances answer\naccuracy but also achieves cost-effectiveness across a variety of datasets.\n","authors":["Yulong Hui","Yihao Liu","Yao Lu","Huanchen Zhang"],"pdf_url":"https://arxiv.org/pdf/2503.02603v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2409.11699v2","updated":"2025-03-05T23:46:26Z","published":"2024-09-18T04:43:41Z","title":"FLARE: Fusing Language Models and Collaborative Architectures for\n  Recommender Enhancement","summary":"  Recent proposals in recommender systems represent items with their textual\ndescription, using a large language model. They show better results on standard\nbenchmarks compared to an item ID-only model, such as Bert4Rec. In this work,\nwe revisit the often-used Bert4Rec baseline and show that with further tuning,\nBert4Rec significantly outperforms previously reported numbers, and in some\ndatasets, is competitive with state-of-the-art models.\n  With revised baselines for item ID-only models, this paper also establishes\nnew competitive results for architectures that combine IDs and textual\ndescriptions. We demonstrate this with Flare (Fusing Language models and\ncollaborative Architectures for Recommender Enhancement). Flare is a novel\nhybrid sequence recommender that integrates a language model with a\ncollaborative filtering model using a Perceiver network.\n  Prior studies focus evaluation on datasets with limited-corpus size, but many\ncommercially-applicable recommender systems common on the web must handle\nlarger corpora. We evaluate Flare on a more realistic dataset with a\nsignificantly larger item vocabulary, introducing new baselines for this\nsetting. This paper also showcases Flare's inherent ability to support\ncritiquing, enabling users to provide feedback and refine recommendations. We\nleverage critiquing as an evaluation method to assess the model's language\nunderstanding and its transferability to the recommendation task.\n","authors":["Liam Hebert","Marialena Kyriakidi","Hubert Pham","Krishna Sayana","James Pine","Sukhdeep Sodhi","Ambarish Jash"],"pdf_url":"https://arxiv.org/pdf/2409.11699v2.pdf","comment":null}],"Machine Learning":[{"id":"http://arxiv.org/abs/2503.02870v2","updated":"2025-03-05T04:41:11Z","published":"2025-03-04T18:47:54Z","title":"Multiaccuracy and Multicalibration via Proxy Groups","summary":"  As the use of predictive machine learning algorithms increases in high-stakes\ndecision-making, it is imperative that these algorithms are fair across\nsensitive groups. Unfortunately, measuring and enforcing fairness in real-world\napplications can be challenging due to missing or incomplete sensitive group\ndata. Proxy-sensitive attributes have been proposed as a practical and\neffective solution in these settings, but only for parity-based fairness\nnotions. Knowing how to evaluate and control for fairness with missing\nsensitive group data for newer and more flexible frameworks, such as\nmultiaccuracy and multicalibration, remains unexplored. In this work, we\naddress this gap by demonstrating that in the absence of sensitive group data,\nproxy-sensitive attributes can provably be used to derive actionable upper\nbounds on the true multiaccuracy and multicalibration, providing insights into\na model's potential worst-case fairness violations. Additionally, we show that\nadjusting models to satisfy multiaccuracy and multicalibration across\nproxy-sensitive attributes can significantly mitigate these violations for the\ntrue, but unknown, sensitive groups. Through several experiments on real-world\ndatasets, we illustrate that approximate multiaccuracy and multicalibration can\nbe achieved even when sensitive group information is incomplete or unavailable.\n","authors":["Beepul Bharti","Mary Versa Clemens-Sewall","Paul H. Yi","Jeremias Sulam"],"pdf_url":"https://arxiv.org/pdf/2503.02870v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.02745v2","updated":"2025-03-05T04:49:18Z","published":"2025-03-04T16:10:42Z","title":"ArcPro: Architectural Programs for Structured 3D Abstraction of Sparse\n  Points","summary":"  We introduce ArcPro, a novel learning framework built on architectural\nprograms to recover structured 3D abstractions from highly sparse and\nlow-quality point clouds. Specifically, we design a domain-specific language\n(DSL) to hierarchically represent building structures as a program, which can\nbe efficiently converted into a mesh. We bridge feedforward and inverse\nprocedural modeling by using a feedforward process for training data synthesis,\nallowing the network to make reverse predictions. We train an encoder-decoder\non the points-program pairs to establish a mapping from unstructured point\nclouds to architectural programs, where a 3D convolutional encoder extracts\npoint cloud features and a transformer decoder autoregressively predicts the\nprograms in a tokenized form. Inference by our method is highly efficient and\nproduces plausible and faithful 3D abstractions. Comprehensive experiments\ndemonstrate that ArcPro outperforms both traditional architectural proxy\nreconstruction and learning-based abstraction methods. We further explore its\npotential to work with multi-view image and natural language inputs.\n","authors":["Qirui Huang","Runze Zhang","Kangjun Liu","Minglun Gong","Hao Zhang","Hui Huang"],"pdf_url":"https://arxiv.org/pdf/2503.02745v2.pdf","comment":"CVPR 2025 (Patent Protected); Project page:\n  https://vcc.tech/research/2025/ArcPro"},{"id":"http://arxiv.org/abs/2407.01214v3","updated":"2025-03-05T07:02:28Z","published":"2024-07-01T11:59:59Z","title":"Revisiting Random Walks for Learning on Graphs","summary":"  We revisit a simple model class for machine learning on graphs, where a\nrandom walk on a graph produces a machine-readable record, and this record is\nprocessed by a deep neural network to directly make vertex-level or graph-level\npredictions. We call these stochastic machines random walk neural networks\n(RWNNs), and through principled analysis, show that we can design them to be\nisomorphism invariant while capable of universal approximation of graph\nfunctions in probability. A useful finding is that almost any kind of record of\nrandom walks guarantees probabilistic invariance as long as the vertices are\nanonymized. This enables us, for example, to record random walks in plain text\nand adopt a language model to read these text records to solve graph tasks. We\nfurther establish a parallelism to message passing neural networks using tools\nfrom Markov chain theory, and show that over-smoothing in message passing is\nalleviated by construction in RWNNs, while over-squashing manifests as\nprobabilistic under-reaching. We empirically demonstrate RWNNs on a range of\nproblems, verifying our theoretical analysis and demonstrating the use of\nlanguage models for separating strongly regular graphs where 3-WL test fails,\nand transductive classification on arXiv citation network. Code is available at\nhttps://github.com/jw9730/random-walk.\n","authors":["Jinwoo Kim","Olga Zaghen","Ayhan Suleymanzade","Youngmin Ryou","Seunghoon Hong"],"pdf_url":"https://arxiv.org/pdf/2407.01214v3.pdf","comment":"51 pages, 14 figures"},{"id":"http://arxiv.org/abs/2503.02445v2","updated":"2025-03-05T06:04:37Z","published":"2025-03-04T09:40:00Z","title":"BRIDGE: Bootstrapping Text to Control Time-Series Generation via\n  Multi-Agent Iterative Optimization and Diffusion Modelling","summary":"  Time-series Generation (TSG) is a prominent research area with broad\napplications in simulations, data augmentation, and counterfactual analysis.\nWhile existing methods have shown promise in unconditional single-domain TSG,\nreal-world applications demand for cross-domain approaches capable of\ncontrolled generation tailored to domain-specific constraints and\ninstance-level requirements. In this paper, we argue that text can provide\nsemantic insights, domain information and instance-specific temporal patterns,\nto guide and improve TSG. We introduce ``Text-Controlled TSG'', a task focused\non generating realistic time series by incorporating textual descriptions. To\naddress data scarcity in this setting, we propose a novel LLM-based Multi-Agent\nframework that synthesizes diverse, realistic text-to-TS datasets. Furthermore,\nwe introduce BRIDGE, a hybrid text-controlled TSG framework that integrates\nsemantic prototypes with text description for supporting domain-level guidance.\nThis approach achieves state-of-the-art generation fidelity on 11 of 12\ndatasets, and improves controllability by 12.52% on MSE and 6.34% MAE compared\nto no text input generation, highlighting its potential for generating tailored\ntime-series data.\n","authors":["Hao Li","Yu-Hao Huang","Chang Xu","Viktor Schlegel","Ren-He Jiang","Riza Batista-Navarro","Goran Nenadic","Jiang Bian"],"pdf_url":"https://arxiv.org/pdf/2503.02445v2.pdf","comment":"Preprint. Work in progress"},{"id":"http://arxiv.org/abs/2503.01478v3","updated":"2025-03-05T05:24:54Z","published":"2025-03-03T12:37:34Z","title":"SePer: Measure Retrieval Utility Through The Lens Of Semantic Perplexity\n  Reduction","summary":"  Large Language Models (LLMs) have demonstrated improved generation\nperformance by incorporating externally retrieved knowledge, a process known as\nretrieval-augmented generation (RAG). Despite the potential of this approach,\nexisting studies evaluate RAG effectiveness by 1) assessing retrieval and\ngeneration components jointly, which obscures retrieval's distinct\ncontribution, or 2) examining retrievers using traditional metrics such as\nNDCG, which creates a gap in understanding retrieval's true utility in the\noverall generation process. To address the above limitations, in this work, we\nintroduce an automatic evaluation method that measures retrieval quality\nthrough the lens of information gain within the RAG framework. Specifically, we\npropose Semantic Perplexity (SePer), a metric that captures the LLM's internal\nbelief about the correctness of the retrieved information. We quantify the\nutility of retrieval by the extent to which it reduces semantic perplexity\npost-retrieval. Extensive experiments demonstrate that SePer not only aligns\nclosely with human preferences but also offers a more precise and efficient\nevaluation of retrieval utility across diverse RAG scenarios.\n","authors":["Lu Dai","Yijie Xu","Jinhui Ye","Hao Liu","Hui Xiong"],"pdf_url":"https://arxiv.org/pdf/2503.01478v3.pdf","comment":"ICLR 2025 Spotlight"},{"id":"http://arxiv.org/abs/2503.02368v2","updated":"2025-03-05T09:12:25Z","published":"2025-03-04T07:49:10Z","title":"Iterative Value Function Optimization for Guided Decoding","summary":"  While Reinforcement Learning from Human Feedback (RLHF) has become the\npredominant method for controlling language model outputs, it suffers from high\ncomputational costs and training instability. Guided decoding, especially\nvalue-guided methods, offers a cost-effective alternative by controlling\noutputs without re-training models. However, the accuracy of the value function\nis crucial for value-guided decoding, as inaccuracies can lead to suboptimal\ndecision-making and degraded performance. Existing methods struggle with\naccurately estimating the optimal value function, leading to less effective\ncontrol. We propose Iterative Value Function Optimization, a novel framework\nthat addresses these limitations through two key components: Monte Carlo Value\nEstimation, which reduces estimation variance by exploring diverse\ntrajectories, and Iterative On-Policy Optimization, which progressively\nimproves value estimation through collecting trajectories from value-guided\npolicies. Extensive experiments on text summarization, multi-turn dialogue, and\ninstruction following demonstrate the effectiveness of value-guided decoding\napproaches in aligning language models. These approaches not only achieve\nalignment but also significantly reduce computational costs by leveraging\nprincipled value function optimization for efficient and effective control.\n","authors":["Zhenhua Liu","Lijun Li","Ruizhe Chen","Yuxian Jiang","Tong Zhu","Zhaochen Su","Wenliang Chen","Jing Shao"],"pdf_url":"https://arxiv.org/pdf/2503.02368v2.pdf","comment":"20 pages, 10 figures"},{"id":"http://arxiv.org/abs/2503.03750v1","updated":"2025-03-05T18:59:23Z","published":"2025-03-05T18:59:23Z","title":"The MASK Benchmark: Disentangling Honesty From Accuracy in AI Systems","summary":"  As large language models (LLMs) become more capable and agentic, the\nrequirement for trust in their outputs grows significantly, yet at the same\ntime concerns have been mounting that models may learn to lie in pursuit of\ntheir goals. To address these concerns, a body of work has emerged around the\nnotion of \"honesty\" in LLMs, along with interventions aimed at mitigating\ndeceptive behaviors. However, evaluations of honesty are currently highly\nlimited, with no benchmark combining large scale and applicability to all\nmodels. Moreover, many benchmarks claiming to measure honesty in fact simply\nmeasure accuracy--the correctness of a model's beliefs--in disguise. In this\nwork, we introduce a large-scale human-collected dataset for measuring honesty\ndirectly, allowing us to disentangle accuracy from honesty for the first time.\nAcross a diverse set of LLMs, we find that while larger models obtain higher\naccuracy on our benchmark, they do not become more honest. Surprisingly, while\nmost frontier LLMs obtain high scores on truthfulness benchmarks, we find a\nsubstantial propensity in frontier LLMs to lie when pressured to do so,\nresulting in low honesty scores on our benchmark. We find that simple methods,\nsuch as representation engineering interventions, can improve honesty. These\nresults underscore the growing need for robust evaluations and effective\ninterventions to ensure LLMs remain trustworthy.\n","authors":["Richard Ren","Arunim Agarwal","Mantas Mazeika","Cristina Menghini","Robert Vacareanu","Brad Kenstler","Mick Yang","Isabelle Barrass","Alice Gatti","Xuwang Yin","Eduardo Trevino","Matias Geralnik","Adam Khoja","Dean Lee","Summer Yue","Dan Hendrycks"],"pdf_url":"https://arxiv.org/pdf/2503.03750v1.pdf","comment":"Website: https://www.mask-benchmark.ai"},{"id":"http://arxiv.org/abs/2503.01048v3","updated":"2025-03-05T18:59:19Z","published":"2025-03-02T22:40:10Z","title":"Personalize Your LLM: Fake it then Align it","summary":"  Personalizing large language models (LLMs) is essential for delivering\ntailored interactions that improve user experience. Many existing\npersonalization methods require fine-tuning LLMs for each user, rendering them\nprohibitively expensive for widespread adoption. Although retrieval-based\napproaches offer a more compute-efficient alternative, they still depend on\nlarge, high-quality datasets that are not consistently available for all users.\nTo address this challenge, we propose CHAMELEON, a scalable and efficient\npersonalization approach that uses (1) self-generated personal preference data\nand (2) representation editing to enable quick and cost-effective\npersonalization. Our experiments on various tasks, including those from the\nLaMP personalization benchmark, show that CHAMELEON efficiently adapts models\nto personal preferences, improving instruction-tuned models and outperforms two\npersonalization baselines by an average of 40% across two model architectures.\n","authors":["Yijing Zhang","Dyah Adila","Changho Shin","Frederic Sala"],"pdf_url":"https://arxiv.org/pdf/2503.01048v3.pdf","comment":"NAACL 2025 Findings"},{"id":"http://arxiv.org/abs/2503.03747v1","updated":"2025-03-05T18:58:58Z","published":"2025-03-05T18:58:58Z","title":"PacketCLIP: Multi-Modal Embedding of Network Traffic and Language for\n  Cybersecurity Reasoning","summary":"  Traffic classification is vital for cybersecurity, yet encrypted traffic\nposes significant challenges. We present PacketCLIP, a multi-modal framework\ncombining packet data with natural language semantics through contrastive\npretraining and hierarchical Graph Neural Network (GNN) reasoning. PacketCLIP\nintegrates semantic reasoning with efficient classification, enabling robust\ndetection of anomalies in encrypted network flows. By aligning textual\ndescriptions with packet behaviors, it offers enhanced interpretability,\nscalability, and practical applicability across diverse security scenarios.\nPacketCLIP achieves a 95% mean AUC, outperforms baselines by 11.6%, and reduces\nmodel size by 92%, making it ideal for real-time anomaly detection. By bridging\nadvanced machine learning techniques and practical cybersecurity needs,\nPacketCLIP provides a foundation for scalable, efficient, and interpretable\nsolutions to tackle encrypted traffic classification and network intrusion\ndetection challenges in resource-constrained environments.\n","authors":["Ryozo Masukawa","Sanggeon Yun","Sungheon Jeong","Wenjun Huang","Yang Ni","Ian Bryant","Nathaniel D. Bastian","Mohsen Imani"],"pdf_url":"https://arxiv.org/pdf/2503.03747v1.pdf","comment":"7 pages, 7 figures"},{"id":"http://arxiv.org/abs/2503.03744v1","updated":"2025-03-05T18:56:48Z","published":"2025-03-05T18:56:48Z","title":"Constrained Gaussian Wasserstein Optimal Transport with Commutative\n  Covariance Matrices","summary":"  Optimal transport has found widespread applications in signal processing and\nmachine learning. Among its many equivalent formulations, optimal transport\nseeks to reconstruct a random variable/vector with a prescribed distribution at\nthe destination while minimizing the expected distortion relative to a given\nrandom variable/vector at the source. However, in practice, certain constraints\nmay render the optimal transport plan infeasible. In this work, we consider\nthree types of constraints: rate constraints, dimension constraints, and\nchannel constraints, motivated by perception-aware lossy compression,\ngenerative principal component analysis, and deep joint source-channel coding,\nrespectively. Special attenion is given to the setting termed Gaussian\nWasserstein optimal transport, where both the source and reconstruction\nvariables are multivariate Gaussian, and the end-to-end distortion is measured\nby the mean squared error. We derive explicit results for the minimum\nachievable mean squared error under the three aforementioned constraints when\nthe covariance matrices of the source and reconstruction variables commute.\n","authors":["Jun Chen","Jia Wang","Ruibin Li","Han Zhou","Wei Dong","Huan Liu","Yuanhao Yu"],"pdf_url":"https://arxiv.org/pdf/2503.03744v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.03736v1","updated":"2025-03-05T18:44:56Z","published":"2025-03-05T18:44:56Z","title":"Opportunistic Routing in Wireless Communications via Learnable\n  State-Augmented Policies","summary":"  This paper addresses the challenge of packet-based information routing in\nlarge-scale wireless communication networks. The problem is framed as a\nconstrained statistical learning task, where each network node operates using\nonly local information. Opportunistic routing exploits the broadcast nature of\nwireless communication to dynamically select optimal forwarding nodes, enabling\nthe information to reach the destination through multiple relay nodes\nsimultaneously. To solve this, we propose a State-Augmentation (SA) based\ndistributed optimization approach aimed at maximizing the total information\nhandled by the source nodes in the network. The problem formulation leverages\nGraph Neural Networks (GNNs), which perform graph convolutions based on the\ntopological connections between network nodes. Using an unsupervised learning\nparadigm, we extract routing policies from the GNN architecture, enabling\noptimal decisions for source nodes across various flows. Numerical experiments\ndemonstrate that the proposed method achieves superior performance when\ntraining a GNN-parameterized model, particularly when compared to baseline\nalgorithms. Additionally, applying the method to real-world network topologies\nand wireless ad-hoc network test beds validates its effectiveness, highlighting\nthe robustness and transferability of GNNs.\n","authors":["Sourajit Das","Navid NaderiAlizadeh","Rahul Mangharam","Alejandro Ribeiro"],"pdf_url":"https://arxiv.org/pdf/2503.03736v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.03730v1","updated":"2025-03-05T18:40:19Z","published":"2025-03-05T18:40:19Z","title":"Towards Understanding Distilled Reasoning Models: A Representational\n  Approach","summary":"  In this paper, we investigate how model distillation impacts the development\nof reasoning features in large language models (LLMs). To explore this, we\ntrain a crosscoder on Qwen-series models and their fine-tuned variants. Our\nresults suggest that the crosscoder learns features corresponding to various\ntypes of reasoning, including self-reflection and computation verification.\nMoreover, we observe that distilled models contain unique reasoning feature\ndirections, which could be used to steer the model into over-thinking or\nincisive-thinking mode. In particular, we perform analysis on four specific\nreasoning categories: (a) self-reflection, (b) deductive reasoning, (c)\nalternative reasoning, and (d) contrastive reasoning. Finally, we examine the\nchanges in feature geometry resulting from the distillation process and find\nindications that larger distilled models may develop more structured\nrepresentations, which correlate with enhanced distillation performance. By\nproviding insights into how distillation modifies the model, our study\ncontributes to enhancing the transparency and reliability of AI systems.\n","authors":["David D. Baek","Max Tegmark"],"pdf_url":"https://arxiv.org/pdf/2503.03730v1.pdf","comment":"13 pages, 11 figures"},{"id":"http://arxiv.org/abs/2503.03729v1","updated":"2025-03-05T18:37:52Z","published":"2025-03-05T18:37:52Z","title":"Graph-Augmented LSTM for Forecasting Sparse Anomalies in\n  Graph-Structured Time Series","summary":"  Detecting anomalies in time series data is a critical task across many\ndomains. The challenge intensifies when anomalies are sparse and the data are\nmultivariate with relational dependencies across sensors or nodes. Traditional\nunivariate anomaly detectors struggle to capture such cross-node dependencies,\nparticularly in sparse anomaly settings. To address this, we propose a\ngraph-augmented time series forecasting approach that explicitly integrates the\ngraph of relationships among time series into an LSTM forecasting model. This\nenables the model to detect rare anomalies that might otherwise go unnoticed in\npurely univariate approaches. We evaluate the approach on two benchmark\ndatasets - the Yahoo Webscope S5 anomaly dataset and the METR-LA traffic sensor\nnetwork - and compare the performance of the Graph-Augmented LSTM against\nLSTM-only, ARIMA, and Prophet baselines. Results demonstrate that the\ngraph-augmented model achieves significantly higher precision and recall,\nimproving F1-score by up to 10% over the best baseline\n","authors":["Sneh Pillai"],"pdf_url":"https://arxiv.org/pdf/2503.03729v1.pdf","comment":"12 pages"},{"id":"http://arxiv.org/abs/2410.09156v3","updated":"2025-03-05T18:36:02Z","published":"2024-10-11T18:02:46Z","title":"On Discriminative Probabilistic Modeling for Self-Supervised\n  Representation Learning","summary":"  We study the discriminative probabilistic modeling on a continuous domain for\nthe data prediction task of (multimodal) self-supervised representation\nlearning. To address the challenge of computing the integral in the partition\nfunction for each anchor data, we leverage the multiple importance sampling\n(MIS) technique for robust Monte Carlo integration, which can recover\nInfoNCE-based contrastive loss as a special case. Within this probabilistic\nmodeling framework, we conduct generalization error analysis to reveal the\nlimitation of current InfoNCE-based contrastive loss for self-supervised\nrepresentation learning and derive insights for developing better approaches by\nreducing the error of Monte Carlo integration. To this end, we propose a novel\nnon-parametric method for approximating the sum of conditional probability\ndensities required by MIS through convex optimization, yielding a new\ncontrastive objective for self-supervised representation learning. Moreover, we\ndesign an efficient algorithm for solving the proposed objective. We\nempirically compare our algorithm to representative baselines on the\ncontrastive image-language pretraining task. Experimental results on the CC3M\nand CC12M datasets demonstrate the superior overall performance of our\nalgorithm. Our code is available at https://github.com/bokun-wang/NUCLR.\n","authors":["Bokun Wang","Yunwen Lei","Yiming Ying","Tianbao Yang"],"pdf_url":"https://arxiv.org/pdf/2410.09156v3.pdf","comment":"To appear in ICLR 2025"},{"id":"http://arxiv.org/abs/2503.03724v1","updated":"2025-03-05T18:24:58Z","published":"2025-03-05T18:24:58Z","title":"Deep Causal Behavioral Policy Learning: Applications to Healthcare","summary":"  We present a deep learning-based approach to studying dynamic clinical\nbehavioral regimes in diverse non-randomized healthcare settings. Our proposed\nmethodology - deep causal behavioral policy learning (DC-BPL) - uses deep\nlearning algorithms to learn the distribution of high-dimensional clinical\naction paths, and identifies the causal link between these action paths and\npatient outcomes. Specifically, our approach: (1) identifies the causal effects\nof provider assignment on clinical outcomes; (2) learns the distribution of\nclinical actions a given provider would take given evolving patient\ninformation; (3) and combines these steps to identify the optimal provider for\na given patient type and emulate that provider's care decisions. Underlying\nthis strategy, we train a large clinical behavioral model (LCBM) on electronic\nhealth records data using a transformer architecture, and demonstrate its\nability to estimate clinical behavioral policies. We propose a novel\ninterpretation of a behavioral policy learned using the LCBM: that it is an\nefficient encoding of complex, often implicit, knowledge used to treat a\npatient. This allows us to learn a space of policies that are critical to a\nwide range of healthcare applications, in which the vast majority of clinical\nknowledge is acquired tacitly through years of practice and only a tiny\nfraction of information relevant to patient care is written down (e.g. in\ntextbooks, studies or standardized guidelines).\n","authors":["Jonas Knecht","Anna Zink","Jonathan Kolstad","Maya Petersen"],"pdf_url":"https://arxiv.org/pdf/2503.03724v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2404.14395v2","updated":"2025-03-05T18:17:28Z","published":"2024-04-22T17:55:56Z","title":"PARAMANU-GANITA: Can Small Math Language Models Rival with Large\n  Language Models on Mathematical Reasoning?","summary":"  In this paper, we study whether domain specific pretraining of small\ngenerative language models (SLM) from scratch with domain specialized tokenizer\nand Chain-of-Thought (CoT) instruction fine-tuning results in competitive\nperformance on mathematical reasoning compared to LLMs? Secondly, whether this\napproach is environmentally sustainable, highly cost efficient? To address\nthese research questions, we present Paramanu-Ganita, a 208 million-parameter\nnovel decoder-only Auto Regressive SLM on mathematics. We performed pretraining\nfrom scratch on 31.5 billion tokens for 170 A100 hours using a context size of\n4096 on a mixed mathematical corpus consisting of web pages, source code,\ntextbooks, CoT templatised StackOverflow QA pairs, and mathematical lecture\nnotes in LaTeX curated by us. We also trained a math and code specialised BPE\ntokenizer. We proposed and performed CoT instruction fine-tuning of\nParamanu-Ganita on the MetaMathQA dataset. Our model Paramanu-Ganita, despite\nbeing 34 times smaller than the 7B LLMs, outperforms generalist LLMs by\napproximately 30% points, and even math-specialised LLMs by 3-23% points in\nGSM8K test accuracy metric. On MATH benchmark, Paramanu-Ganita outperformed the\nvarious models by 6-8% points. On benchmarks like LogiQA, MMLU (high school,\ncollege level), and competitive exams level, AGIEVAL (AQuA-RAT, SAT-Math),\nParamanu-Ganita outperformed others by 1-4%. Our model is available at\nhttps://huggingface.co/gyanai/paramanu-ganita-208M-hf .\n","authors":["Mitodru Niyogi","Arnab Bhattacharya"],"pdf_url":"https://arxiv.org/pdf/2404.14395v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.00675v2","updated":"2025-03-05T18:14:25Z","published":"2024-03-01T17:08:30Z","title":"Reusing Historical Trajectories in Natural Policy Gradient via\n  Importance Sampling: Convergence and Convergence Rate","summary":"  Reinforcement learning provides a mathematical framework for learning-based\ncontrol, whose success largely depends on the amount of data it can utilize.\nThe efficient utilization of historical trajectories obtained from previous\npolicies is essential for expediting policy optimization. Empirical evidence\nhas shown that policy gradient methods based on importance sampling work well.\nHowever, existing literature often neglect the interdependence between\ntrajectories from different iterations, and the good empirical performance\nlacks a rigorous theoretical justification. In this paper, we study a variant\nof the natural policy gradient method with reusing historical trajectories via\nimportance sampling. We show that the bias of the proposed estimator of the\ngradient is asymptotically negligible, the resultant algorithm is convergent,\nand reusing past trajectories helps improve the convergence rate. We further\napply the proposed estimator to popular policy optimization algorithms such as\ntrust region policy optimization. Our theoretical results are verified on\nclassical benchmarks.\n","authors":["Yifan Lin","Yuhao Wang","Enlu Zhou"],"pdf_url":"https://arxiv.org/pdf/2403.00675v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2501.03888v3","updated":"2025-03-05T18:04:40Z","published":"2025-01-07T15:51:49Z","title":"Neural DNF-MT: A Neuro-symbolic Approach for Learning Interpretable and\n  Editable Policies","summary":"  Although deep reinforcement learning has been shown to be effective, the\nmodel's black-box nature presents barriers to direct policy interpretation. To\naddress this problem, we propose a neuro-symbolic approach called neural DNF-MT\nfor end-to-end policy learning. The differentiable nature of the neural DNF-MT\nmodel enables the use of deep actor-critic algorithms for training. At the same\ntime, its architecture is designed so that trained models can be directly\ntranslated into interpretable policies expressed as standard (bivalent or\nprobabilistic) logic programs. Moreover, additional layers can be included to\nextract abstract features from complex observations, acting as a form of\npredicate invention. The logic representations are highly interpretable, and we\nshow how the bivalent representations of deterministic policies can be edited\nand incorporated back into a neural model, facilitating manual intervention and\nadaptation of learned policies. We evaluate our approach on a range of tasks\nrequiring learning deterministic or stochastic behaviours from various forms of\nobservations. Our empirical results show that our neural DNF-MT model performs\nat the level of competing black-box methods whilst providing interpretable\npolicies.\n","authors":["Kexin Gu Baugh","Luke Dickens","Alessandra Russo"],"pdf_url":"https://arxiv.org/pdf/2501.03888v3.pdf","comment":"AAMAS 2025 (with Appendix)"},{"id":"http://arxiv.org/abs/2503.03715v1","updated":"2025-03-05T18:04:30Z","published":"2025-03-05T18:04:30Z","title":"Handling Uncertainty in Health Data using Generative Algorithms","summary":"  Understanding and managing uncertainty is crucial in machine learning,\nespecially in high-stakes domains like healthcare, where class imbalance can\nimpact predictions. This paper introduces RIGA, a novel pipeline that mitigates\nclass imbalance using generative AI. By converting tabular healthcare data into\nimages, RIGA leverages models like cGAN, VQVAE, and VQGAN to generate balanced\nsamples, improving classification performance. These representations are\nprocessed by CNNs and later transformed back into tabular format for seamless\nintegration. This approach enhances traditional classifiers like XGBoost,\nimproves Bayesian structure learning, and strengthens ML model robustness by\ngenerating realistic synthetic data for underrepresented classes.\n","authors":["Mahdi Arab Loodaricheh","Neh Majmudar","Anita Raja","Ansaf Salleb-Aouissi"],"pdf_url":"https://arxiv.org/pdf/2503.03715v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.03710v1","updated":"2025-03-05T18:01:05Z","published":"2025-03-05T18:01:05Z","title":"Improving LLM Safety Alignment with Dual-Objective Optimization","summary":"  Existing training-time safety alignment techniques for large language models\n(LLMs) remain vulnerable to jailbreak attacks. Direct preference optimization\n(DPO), a widely deployed alignment method, exhibits limitations in both\nexperimental and theoretical contexts as its loss function proves suboptimal\nfor refusal learning. Through gradient-based analysis, we identify these\nshortcomings and propose an improved safety alignment that disentangles DPO\nobjectives into two components: (1) robust refusal training, which encourages\nrefusal even when partial unsafe generations are produced, and (2) targeted\nunlearning of harmful knowledge. This approach significantly increases LLM\nrobustness against a wide range of jailbreak attacks, including prefilling,\nsuffix, and multi-turn attacks across both in-distribution and\nout-of-distribution scenarios. Furthermore, we introduce a method to emphasize\ncritical refusal tokens by incorporating a reward-based token-level weighting\nmechanism for refusal learning, which further improves the robustness against\nadversarial exploits. Our research also suggests that robustness to jailbreak\nattacks is correlated with token distribution shifts in the training process\nand internal representations of refusal and harmful tokens, offering valuable\ndirections for future research in LLM safety alignment. The code is available\nat https://github.com/wicai24/DOOR-Alignment\n","authors":["Xuandong Zhao","Will Cai","Tianneng Shi","David Huang","Licong Lin","Song Mei","Dawn Song"],"pdf_url":"https://arxiv.org/pdf/2503.03710v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.03707v1","updated":"2025-03-05T17:58:16Z","published":"2025-03-05T17:58:16Z","title":"Curating Demonstrations using Online Experience","summary":"  Many robot demonstration datasets contain heterogeneous demonstrations of\nvarying quality. This heterogeneity may benefit policy pre-training, but can\nhinder robot performance when used with a final imitation learning objective.\nIn particular, some strategies in the data may be less reliable than others or\nmay be underrepresented in the data, leading to poor performance when such\nstrategies are sampled at test time. Moreover, such unreliable or\nunderrepresented strategies can be difficult even for people to discern, and\nsifting through demonstration datasets is time-consuming and costly. On the\nother hand, policy performance when trained on such demonstrations can reflect\nthe reliability of different strategies. We thus propose for robots to\nself-curate based on online robot experience (Demo-SCORE). More specifically,\nwe train and cross-validate a classifier to discern successful policy roll-outs\nfrom unsuccessful ones and use the classifier to filter heterogeneous\ndemonstration datasets. Our experiments in simulation and the real world show\nthat Demo-SCORE can effectively identify suboptimal demonstrations without\nmanual curation. Notably, Demo-SCORE achieves over 15-35% higher absolute\nsuccess rate in the resulting policy compared to the base policy trained with\nall original demonstrations.\n","authors":["Annie S. Chen","Alec M. Lessing","Yuejiang Liu","Chelsea Finn"],"pdf_url":"https://arxiv.org/pdf/2503.03707v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.03705v1","updated":"2025-03-05T17:56:20Z","published":"2025-03-05T17:56:20Z","title":"Effective LLM Knowledge Learning via Model Generalization","summary":"  Large language models (LLMs) are trained on enormous documents that contain\nextensive world knowledge. However, it is still not well-understood how\nknowledge is acquired via autoregressive pre-training. This lack of\nunderstanding greatly hinders effective knowledge learning, especially for\ncontinued pretraining on up-to-date information, as this evolving information\noften lacks diverse repetitions like foundational knowledge. In this paper, we\nfocus on understanding and improving LLM knowledge learning. We found and\nverified that knowledge learning for LLMs can be deemed as an implicit\nsupervised task hidden in the autoregressive pre-training objective. Our\nfindings suggest that knowledge learning for LLMs would benefit from methods\ndesigned to improve generalization ability for supervised tasks. Based on our\nanalysis, we propose the formatting-based data augmentation to grow\nin-distribution samples, which does not present the risk of altering the facts\nembedded in documents as text paraphrasing. We also introduce sharpness-aware\nminimization as an effective optimization algorithm to better improve\ngeneralization. Moreover, our analysis and method can be readily extended to\ninstruction tuning. Extensive experiment results validate our findings and\ndemonstrate our methods' effectiveness in both continued pre-training and\ninstruction tuning. This paper offers new perspectives and insights to\ninterpret and design effective strategies for LLM knowledge learning.\n","authors":["Mingkang Zhu","Xi Chen","Zhongdao Wang","Bei Yu","Hengshuang Zhao","Jiaya Jia"],"pdf_url":"https://arxiv.org/pdf/2503.03705v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.03704v1","updated":"2025-03-05T17:53:24Z","published":"2025-03-05T17:53:24Z","title":"A Practical Memory Injection Attack against LLM Agents","summary":"  Agents based on large language models (LLMs) have demonstrated strong\ncapabilities in a wide range of complex, real-world applications. However, LLM\nagents with a compromised memory bank may easily produce harmful outputs when\nthe past records retrieved for demonstration are malicious. In this paper, we\npropose a novel Memory INJection Attack, MINJA, that enables the injection of\nmalicious records into the memory bank by only interacting with the agent via\nqueries and output observations. These malicious records are designed to elicit\na sequence of malicious reasoning steps leading to undesirable agent actions\nwhen executing the victim user's query. Specifically, we introduce a sequence\nof bridging steps to link the victim query to the malicious reasoning steps.\nDuring the injection of the malicious record, we propose an indication prompt\nto guide the agent to autonomously generate our designed bridging steps. We\nalso propose a progressive shortening strategy that gradually removes the\nindication prompt, such that the malicious record will be easily retrieved when\nprocessing the victim query comes after. Our extensive experiments across\ndiverse agents demonstrate the effectiveness of MINJA in compromising agent\nmemory. With minimal requirements for execution, MINJA enables any user to\ninfluence agent memory, highlighting practical risks of LLM agents.\n","authors":["Shen Dong","Shaocheng Xu","Pengfei He","Yige Li","Jiliang Tang","Tianming Liu","Hui Liu","Zhen Xiang"],"pdf_url":"https://arxiv.org/pdf/2503.03704v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.01776v2","updated":"2025-03-05T17:51:09Z","published":"2025-03-03T17:59:48Z","title":"Beyond Matryoshka: Revisiting Sparse Coding for Adaptive Representation","summary":"  Many large-scale systems rely on high-quality deep representations\n(embeddings) to facilitate tasks like retrieval, search, and generative\nmodeling. Matryoshka Representation Learning (MRL) recently emerged as a\nsolution for adaptive embedding lengths, but it requires full model retraining\nand suffers from noticeable performance degradations at short lengths. In this\npaper, we show that sparse coding offers a compelling alternative for achieving\nadaptive representation with minimal overhead and higher fidelity. We propose\nContrastive Sparse Representation (CSR), a method that sparsifies pre-trained\nembeddings into a high-dimensional but selectively activated feature space. By\nleveraging lightweight autoencoding and task-aware contrastive objectives, CSR\npreserves semantic quality while allowing flexible, cost-effective inference at\ndifferent sparsity levels. Extensive experiments on image, text, and multimodal\nbenchmarks demonstrate that CSR consistently outperforms MRL in terms of both\naccuracy and retrieval speed-often by large margins-while also cutting training\ntime to a fraction of that required by MRL. Our results establish sparse coding\nas a powerful paradigm for adaptive representation learning in real-world\napplications where efficiency and fidelity are both paramount. Code is\navailable at https://github.com/neilwen987/CSR_Adaptive_Rep\n","authors":["Tiansheng Wen","Yifei Wang","Zequn Zeng","Zhong Peng","Yudi Su","Xinyang Liu","Bo Chen","Hongwei Liu","Stefanie Jegelka","Chenyu You"],"pdf_url":"https://arxiv.org/pdf/2503.01776v2.pdf","comment":"A novel sparse coding framework designed for learning adaptive\n  representation"},{"id":"http://arxiv.org/abs/2503.03684v1","updated":"2025-03-05T17:25:20Z","published":"2025-03-05T17:25:20Z","title":"Towards Trustworthy Federated Learning","summary":"  This paper develops a comprehensive framework to address three critical\ntrustworthy challenges in federated learning (FL): robustness against Byzantine\nattacks, fairness, and privacy preservation. To improve the system's defense\nagainst Byzantine attacks that send malicious information to bias the system's\nperformance, we develop a Two-sided Norm Based Screening (TNBS) mechanism,\nwhich allows the central server to crop the gradients that have the l lowest\nnorms and h highest norms. TNBS functions as a screening tool to filter out\npotential malicious participants whose gradients are far from the honest ones.\nTo promote egalitarian fairness, we adopt the q-fair federated learning\n(q-FFL). Furthermore, we adopt a differential privacy-based scheme to prevent\nraw data at local clients from being inferred by curious parties. Convergence\nguarantees are provided for the proposed framework under different scenarios.\nExperimental results on real datasets demonstrate that the proposed framework\neffectively improves robustness and fairness while managing the trade-off\nbetween privacy and accuracy. This work appears to be the first study that\nexperimentally and theoretically addresses fairness, privacy, and robustness in\ntrustworthy FL.\n","authors":["Alina Basharat","Yijun Bian","Ping Xu","Zhi Tian"],"pdf_url":"https://arxiv.org/pdf/2503.03684v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2502.01777v2","updated":"2025-03-05T17:25:07Z","published":"2025-02-03T19:29:42Z","title":"CTC-DRO: Robust Optimization for Reducing Language Disparities in Speech\n  Recognition","summary":"  Modern deep learning models often achieve high overall performance, but\nconsistently fail on specific subgroups. Group distributionally robust\noptimization (group DRO) addresses this problem by minimizing the worst-group\nloss, but it fails when group losses misrepresent performance differences\nbetween groups. This is common in domains like speech, where the widely used\nconnectionist temporal classification (CTC) loss scales with input length and\nvaries with linguistic and acoustic properties, leading to spurious differences\nbetween group losses. We present CTC-DRO, which addresses the shortcomings of\nthe group DRO objective by smoothing the group weight update to prevent\noveremphasis on consistently high-loss groups, while using input length-matched\nbatching to mitigate CTC's scaling issues. We evaluate CTC-DRO on the task of\nmultilingual automatic speech recognition (ASR) across five language sets from\nthe ML-SUPERB 2.0 benchmark. CTC-DRO consistently outperforms group DRO and\nCTC-based baseline models, reducing the worst-language error by up to 47.1% and\nthe average error by up to 32.9%. CTC-DRO can be applied to ASR with minimal\ncomputational costs, and offers the potential for reducing group disparities in\nother domains with similar challenges.\n","authors":["Martijn Bartelds","Ananjan Nandi","Moussa Koulako Bala Doumbouya","Dan Jurafsky","Tatsunori Hashimoto","Karen Livescu"],"pdf_url":"https://arxiv.org/pdf/2502.01777v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.03676v1","updated":"2025-03-05T17:11:02Z","published":"2025-03-05T17:11:02Z","title":"Optimally Installing Strict Equilibria","summary":"  In this work, we develop a reward design framework for installing a desired\nbehavior as a strict equilibrium across standard solution concepts: dominant\nstrategy equilibrium, Nash equilibrium, correlated equilibrium, and coarse\ncorrelated equilibrium. We also extend our framework to capture the\nMarkov-perfect equivalents of each solution concept. Central to our framework\nis a comprehensive mathematical characterization of strictly installable, based\non the desired solution concept and the behavior's structure. These\ncharacterizations lead to efficient iterative algorithms, which we generalize\nto handle optimization objectives through linear programming. Finally, we\nexplore how our results generalize to bounded rational agents.\n","authors":["Jeremy McMahan","Young Wu","Yudong Chen","Xiaojin Zhu","Qiaomin Xie"],"pdf_url":"https://arxiv.org/pdf/2503.03676v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.17579v3","updated":"2025-03-05T17:09:46Z","published":"2024-10-23T06:08:45Z","title":"Bonsai: Gradient-free Graph Distillation for Node Classification","summary":"  Graph distillation has emerged as a promising avenue to enable scalable\ntraining of GNNs by compressing the training dataset while preserving essential\ngraph characteristics. Our study uncovers significant shortcomings in current\ngraph distillation techniques. First, the majority of the algorithms\nparadoxically require training on the full dataset to perform distillation.\nSecond, due to their gradient-emulating approach, these methods require fresh\ndistillation for any change in hyperparameters or GNN architecture, limiting\ntheir flexibility and reusability. Finally, they fail to achieve substantial\nsize reduction due to synthesizing fully-connected, edge-weighted graphs. To\naddress these challenges, we present Bonsai, a novel graph distillation method\nempowered by the observation that \\textit{computation trees} form the\nfundamental processing units of message-passing GNNs. Bonsai distills datasets\nby encoding a careful selection of \\textit{exemplar} trees that maximize the\nrepresentation of all computation trees in the training set. This unique\napproach imparts Bonsai as the first linear-time, model-agnostic graph\ndistillation algorithm for node classification that outperforms existing\nbaselines across $6$ real-world datasets on accuracy, while being $22$ times\nfaster on average. Bonsai is grounded in rigorous mathematical guarantees on\nthe adopted approximation strategies making it robust to GNN architectures,\ndatasets, and parameters.\n","authors":["Mridul Gupta","Samyak Jain","Vansh Ramani","Hariprasad Kodamana","Sayan Ranu"],"pdf_url":"https://arxiv.org/pdf/2410.17579v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2405.14131v3","updated":"2025-03-05T17:05:55Z","published":"2024-05-23T03:11:07Z","title":"Statistical Advantages of Perturbing Cosine Router in Mixture of Experts","summary":"  The cosine router in Mixture of Experts (MoE) has recently emerged as an\nattractive alternative to the conventional linear router. Indeed, the cosine\nrouter demonstrates favorable performance in image and language tasks and\nexhibits better ability to mitigate the representation collapse issue, which\noften leads to parameter redundancy and limited representation potentials.\nDespite its empirical success, a comprehensive analysis of the cosine router in\nMoE has been lacking. Considering the least square estimation of the cosine\nrouting MoE, we demonstrate that due to the intrinsic interaction of the model\nparameters in the cosine router via some partial differential equations,\nregardless of the structures of the experts, the estimation rates of experts\nand model parameters can be as slow as $\\mathcal{O}(1/\\log^{\\tau}(n))$ where\n$\\tau > 0$ is some constant and $n$ is the sample size. Surprisingly, these\npessimistic non-polynomial convergence rates can be circumvented by the widely\nused technique in practice to stabilize the cosine router -- simply adding\nnoises to the $\\ell^2$-norms in the cosine router, which we refer to as\n\\textit{perturbed cosine router}. Under the strongly identifiable settings of\nthe expert functions, we prove that the estimation rates for both the experts\nand model parameters under the perturbed cosine routing MoE are significantly\nimproved to polynomial rates. Finally, we conduct extensive simulation studies\nin both synthetic and real data settings to empirically validate our\ntheoretical results.\n","authors":["Huy Nguyen","Pedram Akbarian","Trang Pham","Trang Nguyen","Shujian Zhang","Nhat Ho"],"pdf_url":"https://arxiv.org/pdf/2405.14131v3.pdf","comment":"Accepted to ICLR 2025"},{"id":"http://arxiv.org/abs/2503.03666v1","updated":"2025-03-05T16:59:08Z","published":"2025-03-05T16:59:08Z","title":"Analogical Reasoning Inside Large Language Models: Concept Vectors and\n  the Limits of Abstraction","summary":"  Analogical reasoning relies on conceptual abstractions, but it is unclear\nwhether Large Language Models (LLMs) harbor such internal representations. We\nexplore distilled representations from LLM activations and find that function\nvectors (FVs; Todd et al., 2024) - compact representations for in-context\nlearning (ICL) tasks - are not invariant to simple input changes (e.g.,\nopen-ended vs. multiple-choice), suggesting they capture more than pure\nconcepts. Using representational similarity analysis (RSA), we localize a small\nset of attention heads that encode invariant concept vectors (CVs) for verbal\nconcepts like \"antonym\". These CVs function as feature detectors that operate\nindependently of the final output - meaning that a model may form a correct\ninternal representation yet still produce an incorrect output. Furthermore, CVs\ncan be used to causally guide model behaviour. However, for more abstract\nconcepts like \"previous\" and \"next\", we do not observe invariant linear\nrepresentations, a finding we link to generalizability issues LLMs display\nwithin these domains.\n","authors":["Gustaw Opieka","Hannes Rosenbusch","Claire E. Stevenson"],"pdf_url":"https://arxiv.org/pdf/2503.03666v1.pdf","comment":"Preprint"},{"id":"http://arxiv.org/abs/2409.07402v2","updated":"2025-03-05T16:48:23Z","published":"2024-09-11T16:42:22Z","title":"What to align in multimodal contrastive learning?","summary":"  Humans perceive the world through multisensory integration, blending the\ninformation of different modalities to adapt their behavior. Contrastive\nlearning offers an appealing solution for multimodal self-supervised learning.\nIndeed, by considering each modality as a different view of the same entity, it\nlearns to align features of different modalities in a shared representation\nspace. However, this approach is intrinsically limited as it only learns shared\nor redundant information between modalities, while multimodal interactions can\narise in other ways. In this work, we introduce CoMM, a Contrastive MultiModal\nlearning strategy that enables the communication between modalities in a single\nmultimodal space. Instead of imposing cross- or intra- modality constraints, we\npropose to align multimodal representations by maximizing the mutual\ninformation between augmented versions of these multimodal features. Our\ntheoretical analysis shows that shared, synergistic and unique terms of\ninformation naturally emerge from this formulation, allowing us to estimate\nmultimodal interactions beyond redundancy. We test CoMM both in a controlled\nand in a series of real-world settings: in the former, we demonstrate that CoMM\neffectively captures redundant, unique and synergistic information between\nmodalities. In the latter, CoMM learns complex multimodal interactions and\nachieves state-of-the-art results on the seven multimodal benchmarks. Code is\navailable at https://github.com/Duplums/CoMM\n","authors":["Benoit Dufumier","Javiera Castillo-Navarro","Devis Tuia","Jean-Philippe Thiran"],"pdf_url":"https://arxiv.org/pdf/2409.07402v2.pdf","comment":"ICLR 2025, 25 pages"},{"id":"http://arxiv.org/abs/2503.03660v1","updated":"2025-03-05T16:47:36Z","published":"2025-03-05T16:47:36Z","title":"Chunking the Critic: A Transformer-based Soft Actor-Critic with N-Step\n  Returns","summary":"  Soft Actor-Critic (SAC) critically depends on its critic network, which\ntypically evaluates a single state-action pair to guide policy updates. Using\nN-step returns is a common practice to reduce the bias in the target values of\nthe critic. However, using N-step returns can again introduce high variance and\nnecessitates importance sampling, often destabilizing training. Recent\nalgorithms have also explored action chunking-such as direct action repetition\nand movement primitives-to enhance exploration. In this paper, we propose a\nTransformer-based Critic Network for SAC that integrates the N-returns\nframework in a stable and efficient manner. Unlike approaches that perform\nchunking in the actor network, we feed chunked actions into the critic network\nto explore potential performance gains. Our architecture leverages the\nTransformer's ability to process sequential information, facilitating more\nrobust value estimation. Empirical results show that this method not only\nachieves efficient, stable training but also excels in sparse\nreward/multi-phase environments-traditionally a challenge for step-based\nmethods. These findings underscore the promise of combining Transformer-based\ncritics with N-returns to advance reinforcement learning performance\n","authors":["Dong Tian","Ge Li","Hongyi Zhou","Onur Celik","Gerhard Neumann"],"pdf_url":"https://arxiv.org/pdf/2503.03660v1.pdf","comment":"11 pages, 5 figures"},{"id":"http://arxiv.org/abs/2503.03659v1","updated":"2025-03-05T16:47:08Z","published":"2025-03-05T16:47:08Z","title":"Finite-sample valid prediction of future insurance claims in the\n  regression problem","summary":"  In the current insurance literature, prediction of insurance claims in the\nregression problem is often performed with a statistical model. This\nmodel-based approach may suffer from several drawbacks: (i) model\nmisspecification, (ii) selection effect, and (iii) lack of finite-sample\nvalidity. This article addresses these three issues simultaneously by employing\nconformal prediction-a general machine learning strategy for valid predictions.\nThe proposed method is both model-free and tuning-parameter-free. It also\nguarantees finite-sample validity at a pre-assigned coverage probability level.\n","authors":["Liang Hong"],"pdf_url":"https://arxiv.org/pdf/2503.03659v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.03656v1","updated":"2025-03-05T16:39:04Z","published":"2025-03-05T16:39:04Z","title":"Robust Learning of Diverse Code Edits","summary":"  Software engineering activities frequently involve edits to existing code.\nHowever, contemporary code language models (LMs) lack the ability to handle\ndiverse types of code-edit requirements. In this work, we attempt to overcome\nthis shortcoming through (1) a novel synthetic data generation pipeline and (2)\na robust model adaptation algorithm. Starting with seed code examples and\ndiverse editing criteria, our pipeline generates high-quality samples\ncomprising original and modified code, along with natural language instructions\nin different styles and verbosity. Today's code LMs come bundled with strong\nabilities, such as code generation and instruction following, which should not\nbe lost due to fine-tuning. To ensure this, we propose a novel adaptation\nalgorithm, SeleKT, that (a) leverages a dense gradient-based step to identify\nthe weights that are most important for code editing, and (b) does a sparse\nprojection onto the base model to avoid overfitting. Using our approach, we\nobtain a new series of models NextCoder (adapted from QwenCoder-2.5) that\nachieves strong results on five code-editing benchmarks, outperforming\ncomparable size models and even several larger ones. We show the generality of\nour approach on two model families (DeepSeekCoder and QwenCoder), compare\nagainst other fine-tuning approaches, and demonstrate robustness by showing\nretention of code generation abilities post adaptation.\n","authors":["Tushar Aggarwal","Swayam Singh","Abhijeet Awasthi","Aditya Kanade","Nagarajan Natarajan"],"pdf_url":"https://arxiv.org/pdf/2503.03656v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.00816v2","updated":"2025-03-05T16:36:05Z","published":"2024-10-28T08:10:21Z","title":"CycleResearcher: Improving Automated Research via Automated Review","summary":"  The automation of scientific discovery has been a long-standing goal within\nthe research community, driven by the potential to accelerate knowledge\ncreation. While significant progress has been made using commercial large\nlanguage models (LLMs) as research assistants or idea generators, the\npossibility of automating the entire research process with open-source LLMs\nremains largely unexplored. This paper explores the feasibility of using\nopen-source post-trained LLMs as autonomous agents capable of performing the\nfull cycle of automated research and review, from literature review and\nmanuscript preparation to peer review and paper refinement. Our iterative\npreference training framework consists of CycleResearcher, which conducts\nresearch tasks, and CycleReviewer, which simulates the peer review process,\nproviding iterative feedback via reinforcement learning. To train these models,\nwe develop two new datasets, Review-5k and Research-14k, reflecting real-world\nmachine learning research and peer review dynamics. Our results demonstrate\nthat CycleReviewer achieves promising performance with a 26.89\\% reduction in\nmean absolute error (MAE) compared to individual human reviewers in predicting\npaper scores, indicating the potential of LLMs to effectively assist\nexpert-level research evaluation. In research, the papers generated by the\nCycleResearcher model achieved a score of 5.36 in simulated peer reviews,\nshowing some competitiveness in terms of simulated review scores compared to\nthe preprint level of 5.24 from human experts, while still having room for\nimprovement compared to the accepted paper level of 5.69. This work represents\na significant step toward fully automated scientific inquiry, providing ethical\nsafeguards and exploring AI-driven research capabilities. The code, dataset and\nmodel weight are released at https://wengsyx.github.io/Researcher/\n","authors":["Yixuan Weng","Minjun Zhu","Guangsheng Bao","Hongbo Zhang","Jindong Wang","Yue Zhang","Linyi Yang"],"pdf_url":"https://arxiv.org/pdf/2411.00816v2.pdf","comment":"Accept in ICLR 2025"},{"id":"http://arxiv.org/abs/2503.03654v1","updated":"2025-03-05T16:32:47Z","published":"2025-03-05T16:32:47Z","title":"Improving Neutral Point of View Text Generation through\n  Parameter-Efficient Reinforcement Learning and a Small-Scale High-Quality\n  Dataset","summary":"  This paper describes the construction of a dataset and the evaluation of\ntraining methods to improve generative large language models' (LLMs) ability to\nanswer queries on sensitive topics with a Neutral Point of View (NPOV), i.e.,\nto provide significantly more informative, diverse and impartial answers. The\ndataset, the SHQ-NPOV dataset, comprises 300 high-quality, human-written\nquadruplets: a query on a sensitive topic, an answer, an NPOV rating, and a set\nof links to source texts elaborating the various points of view. The first key\ncontribution of this paper is a new methodology to create such datasets through\niterative rounds of human peer-critique and annotator training, which we\nrelease alongside the dataset. The second key contribution is the\nidentification of a highly effective training regime for parameter-efficient\nreinforcement learning (PE-RL) to improve NPOV generation. We compare and\nextensively evaluate PE-RL and multiple baselines-including LoRA finetuning (a\nstrong baseline), SFT and RLHF.\n  PE-RL not only improves on overall NPOV quality compared to the strongest\nbaseline ($97.06\\%\\rightarrow 99.08\\%$), but also scores much higher on\nfeatures linguists identify as key to separating good answers from the best\nanswers ($60.25\\%\\rightarrow 85.21\\%$ for presence of supportive details,\n$68.74\\%\\rightarrow 91.43\\%$ for absence of oversimplification). A qualitative\nanalysis corroborates this. Finally, our evaluation finds no statistical\ndifferences between results on topics that appear in the training dataset and\nthose on separated evaluation topics, which provides strong evidence that our\napproach to training PE-RL exhibits very effective out of topic generalization.\n","authors":["Jessica Hoffmann","Christiane Ahlheim","Zac Yu","Aria Walfrand","Jarvis Jin","Marie Tano","Ahmad Beirami","Erin van Liemt","Nithum Thain","Hakim Sidahmed","Lucas Dixon"],"pdf_url":"https://arxiv.org/pdf/2503.03654v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.03649v1","updated":"2025-03-05T16:25:58Z","published":"2025-03-05T16:25:58Z","title":"Limits of nonlinear and dispersive fiber propagation for photonic\n  extreme learning","summary":"  We report a generalized nonlinear Schr\\\"odinger equation simulation model of\nan extreme learning machine based on optical fiber propagation. Using\nhandwritten digit classification as a benchmark, we study how accuracy depends\non propagation dynamics, as well as parameters governing spectral encoding,\nreadout, and noise. Test accuracies of over 91% and 93% are found for\npropagation in the anomalous and normal dispersion regimes respectively. Our\nsimulation results also suggest that quantum noise on the input pulses\nintroduces an intrinsic penalty to ELM performance.\n","authors":["Andrei V. Ermolaev","Mathilde Hary","Lev Leybov","Piotr Ryczkowski","Anas Skalli","Daniel Brunner","Gory Genty","John M. Dudley"],"pdf_url":"https://arxiv.org/pdf/2503.03649v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.03634v1","updated":"2025-03-05T16:14:43Z","published":"2025-03-05T16:14:43Z","title":"Feature Matching Intervention: Leveraging Observational Data for Causal\n  Representation Learning","summary":"  A major challenge in causal discovery from observational data is the absence\nof perfect interventions, making it difficult to distinguish causal features\nfrom spurious ones. We propose an innovative approach, Feature Matching\nIntervention (FMI), which uses a matching procedure to mimic perfect\ninterventions. We define causal latent graphs, extending structural causal\nmodels to latent feature space, providing a framework that connects FMI with\ncausal graph learning. Our feature matching procedure emulates perfect\ninterventions within these causal latent graphs. Theoretical results\ndemonstrate that FMI exhibits strong out-of-distribution (OOD)\ngeneralizability. Experiments further highlight FMI's superior performance in\neffectively identifying causal features solely from observational data.\n","authors":["Haoze Li","Jun Xie"],"pdf_url":"https://arxiv.org/pdf/2503.03634v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2502.09647v2","updated":"2025-03-05T16:14:16Z","published":"2025-02-11T00:04:32Z","title":"Unveiling Simplicities of Attention: Adaptive Long-Context Head\n  Identification","summary":"  The ability to process long contexts is crucial for many natural language\nprocessing tasks, yet it remains a significant challenge. While substantial\nprogress has been made in enhancing the efficiency of attention mechanisms,\nthere is still a gap in understanding how attention heads function in\nlong-context settings. In this paper, we observe that while certain heads\nconsistently attend to local information only, others swing between attending\nto local and long-context information depending on the query. This raises the\nquestion: can we identify which heads require long-context information to\npredict the next token accurately? We demonstrate that it's possible to predict\nwhich heads are crucial for long-context processing using only local keys. The\ncore idea here is to exploit a simple model for the long-context scores via\nsecond moment approximations. These findings unveil simple properties of\nattention in the context of long sequences, and open the door to potentially\nsignificant gains in efficiency.\n","authors":["Konstantin Donhauser","Charles Arnal","Mohammad Pezeshki","Vivien Cabannes","David Lopez-Paz","Kartik Ahuja"],"pdf_url":"https://arxiv.org/pdf/2502.09647v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2502.10650v2","updated":"2025-03-05T16:11:42Z","published":"2025-02-15T03:03:09Z","title":"Generative Adversarial Networks for High-Dimensional Item Factor\n  Analysis: A Deep Adversarial Learning Algorithm","summary":"  Advances in deep learning and representation learning have transformed item\nfactor analysis (IFA) in the item response theory (IRT) literature by enabling\nmore efficient and accurate parameter estimation. Variational Autoencoders\n(VAEs) have been one of the most impactful techniques in modeling\nhigh-dimensional latent variables in this context. However, the limited\nexpressiveness of the inference model based on traditional VAEs can still\nhinder the estimation performance. We introduce Adversarial Variational Bayes\n(AVB) algorithms as an improvement to VAEs for IFA with improved flexibility\nand accuracy. By bridging the strengths of VAEs and Generative Adversarial\nNetworks (GANs), AVB incorporates an auxiliary discriminator network to reframe\nthe estimation process as a two-player adversarial game and removes the\nrestrictive assumption of standard normal distributions in the inference model.\nTheoretically, AVB can achieve similar or higher likelihood compared to VAEs. A\nfurther enhanced algorithm, Importance-weighted Adversarial Variational Bayes\n(IWAVB) is proposed and compared with Importance-weighted Autoencoders (IWAE).\nIn an exploratory analysis of empirical data, IWAVB demonstrated superior\nexpressiveness by achieving a higher likelihood compared to IWAE. In\nconfirmatory analysis with simulated data, IWAVB achieved similar mean-square\nerror results to IWAE while consistently achieving higher likelihoods. When\nlatent variables followed a multimodal distribution, IWAVB outperformed IWAE.\nWith its innovative use of GANs, IWAVB is shown to have the potential to extend\nIFA to handle large-scale data, facilitating the potential integration of\npsychometrics and multimodal data analysis.\n","authors":["Nanyu Luo","Feng Ji"],"pdf_url":"https://arxiv.org/pdf/2502.10650v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.12126v2","updated":"2025-03-05T16:08:49Z","published":"2024-11-18T23:34:07Z","title":"MMBind: Unleashing the Potential of Distributed and Heterogeneous Data\n  for Multimodal Learning in IoT","summary":"  Multimodal sensing systems are increasingly prevalent in various real-world\napplications. Most existing multimodal learning approaches heavily rely on\ntraining with a large amount of synchronized, complete multimodal data.\nHowever, such a setting is impractical in real-world IoT sensing applications\nwhere data is typically collected by distributed nodes with heterogeneous data\nmodalities, and is also rarely labeled. In this paper, we propose MMBind, a new\ndata binding approach for multimodal learning on distributed and heterogeneous\nIoT data. The key idea of MMBind is to construct a pseudo-paired multimodal\ndataset for model training by binding data from disparate sources and\nincomplete modalities through a sufficiently descriptive shared modality. We\nalso propose a weighted contrastive learning approach to handle domain shifts\namong disparate data, coupled with an adaptive multimodal learning architecture\ncapable of training models with heterogeneous modality combinations.\nEvaluations on ten real-world multimodal datasets highlight that MMBind\noutperforms state-of-the-art baselines under varying degrees of data\nincompleteness and domain shift, and holds promise for advancing multimodal\nfoundation model training in IoT applications\\footnote (The source code is\navailable via https://github.com/nesl/multimodal-bind).\n","authors":["Xiaomin Ouyang","Jason Wu","Tomoyoshi Kimura","Yihan Lin","Gunjan Verma","Tarek Abdelzaher","Mani Srivastava"],"pdf_url":"https://arxiv.org/pdf/2411.12126v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2502.13921v2","updated":"2025-03-05T16:07:23Z","published":"2025-02-19T17:53:59Z","title":"Exploring Code Language Models for Automated HLS-based Hardware\n  Generation: Benchmark, Infrastructure and Analysis","summary":"  Recent advances in code generation have illuminated the potential of\nemploying large language models (LLMs) for general-purpose programming\nlanguages such as Python and C++, opening new opportunities for automating\nsoftware development and enhancing programmer productivity. The potential of\nLLMs in software programming has sparked significant interest in exploring\nautomated hardware generation and automation. Although preliminary endeavors\nhave been made to adopt LLMs in generating hardware description languages\n(HDLs), several challenges persist in this direction. First, the volume of\navailable HDL training data is substantially smaller compared to that for\nsoftware programming languages. Second, the pre-trained LLMs, mainly tailored\nfor software code, tend to produce HDL designs that are more error-prone.\nThird, the generation of HDL requires a significantly higher number of tokens\ncompared to software programming, leading to inefficiencies in cost and energy\nconsumption. To tackle these challenges, this paper explores leveraging LLMs to\ngenerate High-Level Synthesis (HLS)-based hardware design. Although code\ngeneration for domain-specific programming languages is not new in the\nliterature, we aim to provide experimental results, insights, benchmarks, and\nevaluation infrastructure to investigate the suitability of HLS over low-level\nHDLs for LLM-assisted hardware design generation. To achieve this, we first\nfinetune pre-trained models for HLS-based hardware generation, using a\ncollected dataset with text prompts and corresponding reference HLS designs. An\nLLM-assisted framework is then proposed to automate end-to-end hardware code\ngeneration, which also investigates the impact of chain-of-thought and feedback\nloops promoting techniques on HLS-design generation. Limited by the timeframe\nof this research, we plan to evaluate more advanced reasoning models in the\nfuture.\n","authors":["Jiahao Gai","Hao Mark Chen","Zhican Wang","Hongyu Zhou","Wanru Zhao","Nicholas Lane","Hongxiang Fan"],"pdf_url":"https://arxiv.org/pdf/2502.13921v2.pdf","comment":"Paper accepted by ASP-DAC'25"},{"id":"http://arxiv.org/abs/2409.06615v5","updated":"2025-03-05T16:07:20Z","published":"2024-09-10T16:11:57Z","title":"One-Shot Imitation under Mismatched Execution","summary":"  Human demonstrations as prompts are a powerful way to program robots to do\nlong-horizon manipulation tasks. However, translating these demonstrations into\nrobot-executable actions presents significant challenges due to execution\nmismatches in movement styles and physical capabilities. Existing methods\neither depend on human-robot paired data, which is infeasible to scale, or rely\nheavily on frame-level visual similarities that often break down in practice.\nTo address these challenges, we propose RHyME, a novel framework that\nautomatically aligns human and robot task executions using optimal transport\ncosts. Given long-horizon robot demonstrations, RHyME synthesizes semantically\nequivalent human videos by retrieving and composing short-horizon human clips.\nThis approach facilitates effective policy training without the need for paired\ndata. RHyME successfully imitates a range of cross-embodiment demonstrators,\nboth in simulation and with a real human hand, achieving over 50\\% increase in\ntask success compared to previous methods. We release our code and datasets at\nhttps://portal-cornell.github.io/rhyme/.\n","authors":["Kushal Kedia","Prithwish Dan","Angela Chao","Maximus Adrian Pace","Sanjiban Choudhury"],"pdf_url":"https://arxiv.org/pdf/2409.06615v5.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.03625v1","updated":"2025-03-05T16:05:26Z","published":"2025-03-05T16:05:26Z","title":"Deterministic Global Optimization of the Acquisition Function in\n  Bayesian Optimization: To Do or Not To Do?","summary":"  Bayesian Optimization (BO) with Gaussian Processes relies on optimizing an\nacquisition function to determine sampling. We investigate the advantages and\ndisadvantages of using a deterministic global solver (MAiNGO) compared to\nconventional local and stochastic global solvers (L-BFGS-B and multi-start,\nrespectively) for the optimization of the acquisition function. For CPU\nefficiency, we set a time limit for MAiNGO, taking the best point as optimal.\nWe perform repeated numerical experiments, initially using the Muller-Brown\npotential as a benchmark function, utilizing the lower confidence bound\nacquisition function; we further validate our findings with three alternative\nbenchmark functions. Statistical analysis reveals that when the acquisition\nfunction is more exploitative (as opposed to exploratory), BO with MAiNGO\nconverges in fewer iterations than with the local solvers. However, when the\ndataset lacks diversity, or when the acquisition function is overly\nexploitative, BO with MAiNGO, compared to the local solvers, is more likely to\nconverge to a local rather than a global ly near-optimal solution of the\nblack-box function. L-BFGS-B and multi-start mitigate this risk in BO by\nintroducing stochasticity in the selection of the next sampling point, which\nenhances the exploration of uncharted regions in the search space and reduces\ndependence on acquisition function hyperparameters. Ultimately, suboptimal\noptimization of poorly chosen acquisition functions may be preferable to their\noptimal solution. When the acquisition function is more exploratory, BO with\nMAiNGO, multi-start, and L-BFGS-B achieve comparable probabilities of\nconvergence to a globally near-optimal solution (although BO with MAiNGO may\nrequire more iterations to converge under these conditions).\n","authors":["Anastasia Georgiou","Daniel Jungen","Luise Kaven","Verena Hunstig","Constantine Frangakis","Ioannis Kevrekidis","Alexander Mitsos"],"pdf_url":"https://arxiv.org/pdf/2503.03625v1.pdf","comment":"32 pages, 7 figures, 7 tables"},{"id":"http://arxiv.org/abs/2503.03622v1","updated":"2025-03-05T16:02:09Z","published":"2025-03-05T16:02:09Z","title":"It's My Data Too: Private ML for Datasets with Multi-User Training\n  Examples","summary":"  We initiate a study of algorithms for model training with user-level\ndifferential privacy (DP), where each example may be attributed to multiple\nusers, which we call the multi-attribution model. We first provide a carefully\nchosen definition of user-level DP under the multi-attribution model. Training\nin the multi-attribution model is facilitated by solving the contribution\nbounding problem, i.e. the problem of selecting a subset of the dataset for\nwhich each user is associated with a limited number of examples. We propose a\ngreedy baseline algorithm for the contribution bounding problem. We then\nempirically study this algorithm for a synthetic logistic regression task and a\ntransformer training task, including studying variants of this baseline\nalgorithm that optimize the subset chosen using different techniques and\ncriteria. We find that the baseline algorithm remains competitive with its\nvariants in most settings, and build a better understanding of the practical\nimportance of a bias-variance tradeoff inherent in solutions to the\ncontribution bounding problem.\n","authors":["Arun Ganesh","Ryan McKenna","Brendan McMahan","Adam Smith","Fan Wu"],"pdf_url":"https://arxiv.org/pdf/2503.03622v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2407.06712v4","updated":"2025-03-05T15:40:42Z","published":"2024-07-09T09:39:45Z","title":"MDP Geometry, Normalization and Reward Balancing Solvers","summary":"  We present a new geometric interpretation of Markov Decision Processes (MDPs)\nwith a natural normalization procedure that allows us to adjust the value\nfunction at each state without altering the advantage of any action with\nrespect to any policy. This advantage-preserving transformation of the MDP\nmotivates a class of algorithms which we call Reward Balancing, which solve\nMDPs by iterating through these transformations, until an approximately optimal\npolicy can be trivially found. We provide a convergence analysis of several\nalgorithms in this class, in particular showing that for MDPs for unknown\ntransition probabilities we can improve upon state-of-the-art sample complexity\nresults.\n","authors":["Arsenii Mustafin","Aleksei Pakharev","Alex Olshevsky","Ioannis Ch. Paschalidis"],"pdf_url":"https://arxiv.org/pdf/2407.06712v4.pdf","comment":"AISTATS 2025 camera-ready version"},{"id":"http://arxiv.org/abs/2501.06058v3","updated":"2025-03-05T15:37:52Z","published":"2025-01-10T15:39:39Z","title":"Capability-Aware Shared Hypernetworks for Flexible Heterogeneous\n  Multi-Robot Coordination","summary":"  Recent advances have enabled heterogeneous multi-robot teams to learn complex\nand effective coordination. However, existing architectural designs that\nsupport heterogeneous teams tend to force a trade-off between expressivity and\nefficiency. Some attempt to encode diverse behaviors within a single shared\narchitecture by appending the input with an ID unique to each robot or robot\ntype. These designs improve sample and parameter efficiency but tend to limit\nbehavioral diversity. Others use a separate policy for each robot, enabling\ngreater diversity at the cost of efficiency and generalization. We view these\ntwo designs as ends of a spectrum and explore a middle-ground approach that\nenables efficient learning of diverse behaviors. Inspired by work in transfer\nlearning and meta RL, and building upon prior work in trait-based task\nallocation, we propose Capability-Aware Shared Hypernetworks (CASH), a\ngeneral-purpose soft weight sharing architecture that uses hypernetworks to\nenable a single architecture to dynamically adapt to each robot and the current\ncontext. Intuitively, CASH encodes shared decision making strategies that can\nbe adapted to each robot based on local observations and the robots' individual\nand collective capabilities (e.g., speed and payload). CASH explicitly captures\nthe impact of capabilities on collective behavior, enabling zero-shot\ngeneralization to unseen robots or team compositions. We conducted experiments\nacross four heterogeneous coordination tasks and three learning paradigms\n(imitation learning, value-based, and policy-gradient RL) using SOTA\nmulti-robot simulation (JaxMARL) and hardware (Robotarium) platforms. Across\nall conditions, CASH generates appropriately diverse behaviors and outperforms\nbaseline architectures in task performance and sample efficiency during\ntraining and zero-shot generalization while utilizing 60%-80% fewer learnable\nparameters.\n","authors":["Kevin Fu","Shalin Jain","Pierce Howell","Harish Ravichandar"],"pdf_url":"https://arxiv.org/pdf/2501.06058v3.pdf","comment":"16 pages, 8 figures, equal authorship between Kevin Fu and Shalin\n  Jain"},{"id":"http://arxiv.org/abs/2409.16720v2","updated":"2025-03-05T15:35:47Z","published":"2024-09-25T08:09:52Z","title":"Dashing for the Golden Snitch: Multi-Drone Time-Optimal Motion Planning\n  with Multi-Agent Reinforcement Learning","summary":"  Recent innovations in autonomous drones have facilitated time-optimal flight\nin single-drone configurations, and enhanced maneuverability in multi-drone\nsystems by applying optimal control and learning-based methods. However, few\nstudies have achieved time-optimal motion planning for multi-drone systems,\nparticularly during highly agile maneuvers or in dynamic scenarios. This paper\npresents a decentralized policy network using multi-agent reinforcement\nlearning for time-optimal multi-drone flight. To strike a balance between\nflight efficiency and collision avoidance, we introduce a soft collision-free\nmechanism inspired by optimization-based methods. By customizing PPO in a\ncentralized training, decentralized execution (CTDE) fashion, we unlock higher\nefficiency and stability in training while ensuring lightweight implementation.\nExtensive simulations show that, despite slight performance trade-offs compared\nto single-drone systems, our multi-drone approach maintains near-time-optimal\nperformance with a low collision rate. Real-world experiments validate our\nmethod, with two quadrotors using the same network as in simulation achieving a\nmaximum speed of 13.65 m/s and a maximum body rate of 13.4 rad/s in a 5.5 m *\n5.5 m * 2.0 m space across various tracks, relying entirely on onboard\ncomputation.\n","authors":["Xian Wang","Jin Zhou","Yuanli Feng","Jiahao Mei","Jiming Chen","Shuo Li"],"pdf_url":"https://arxiv.org/pdf/2409.16720v2.pdf","comment":"v2: 7 pages, 6 figures; terminology corrected, algorithmic and\n  equation descriptions revised, references added"},{"id":"http://arxiv.org/abs/2405.15389v3","updated":"2025-03-05T15:35:35Z","published":"2024-05-24T09:41:06Z","title":"Beyond Canonicalization: How Tensorial Messages Improve Equivariant\n  Message Passing","summary":"  In numerous applications of geometric deep learning, the studied systems\nexhibit spatial symmetries and it is desirable to enforce these. For the\nsymmetry of global rotations and reflections, this means that the model should\nbe equivariant with respect to the transformations that form the group of\n$\\mathrm O(d)$. While many approaches for equivariant message passing require\nspecialized architectures, including non-standard normalization layers or\nnon-linearities, we here present a framework based on local reference frames\n(\"local canonicalization\") which can be integrated with any architecture\nwithout restrictions. We enhance equivariant message passing based on local\ncanonicalization by introducing tensorial messages to communicate geometric\ninformation consistently between different local coordinate frames. Our\nframework applies to message passing on geometric data in Euclidean spaces of\narbitrary dimension. We explicitly show how our approach can be adapted to make\na popular existing point cloud architecture equivariant. We demonstrate the\nsuperiority of tensorial messages and achieve state-of-the-art results on\nnormal vector regression and competitive results on other standard 3D point\ncloud tasks.\n","authors":["Peter Lippmann","Gerrit Gerhartz","Roman Remme","Fred A. Hamprecht"],"pdf_url":"https://arxiv.org/pdf/2405.15389v3.pdf","comment":"To be published in proceedings of ICLR 2025"},{"id":"http://arxiv.org/abs/2412.00980v2","updated":"2025-03-05T15:32:01Z","published":"2024-12-01T22:04:12Z","title":"Incentivizing Truthful Collaboration in Heterogeneous Federated Learning","summary":"  Federated learning (FL) is a distributed collaborative learning method, where\nmultiple clients learn together by sharing gradient updates instead of raw\ndata. However, it is well-known that FL is vulnerable to manipulated updates\nfrom clients. In this work we study the impact of data heterogeneity on\nclients' incentives to manipulate their updates. First, we present\nheterogeneous collaborative learning scenarios where a client can modify their\nupdates to be better off, and show that these manipulations can lead to\ndiminishing model performance. To prevent such modifications, we formulate a\ngame in which clients may misreport their gradient updates in order to \"steer\"\nthe server model to their advantage. We develop a payment rule that provably\ndisincentivizes sending modified updates under the FedSGD protocol. We derive\nexplicit bounds on the clients' payments and the convergence rate of the global\nmodel, which allows us to study the trade-off between heterogeneity, payments\nand convergence. Finally, we provide an experimental evaluation of the\neffectiveness of our payment rule in the FedSGD, median-based aggregation\nFedSGD and FedAvg protocols on three tasks in computer vision and natural\nlanguage processing. In all cases we find that our scheme successfully\ndisincentivizes modifications.\n","authors":["Dimitar Chakarov","Nikita Tsoy","Kristian Minchev","Nikola Konstantinov"],"pdf_url":"https://arxiv.org/pdf/2412.00980v2.pdf","comment":"29 pages, 8 figures"},{"id":"http://arxiv.org/abs/2503.03595v1","updated":"2025-03-05T15:28:50Z","published":"2025-03-05T15:28:50Z","title":"Towards Understanding Text Hallucination of Diffusion Models via Local\n  Generation Bias","summary":"  Score-based diffusion models have achieved incredible performance in\ngenerating realistic images, audio, and video data. While these models produce\nhigh-quality samples with impressive details, they often introduce unrealistic\nartifacts, such as distorted fingers or hallucinated texts with no meaning.\nThis paper focuses on textual hallucinations, where diffusion models correctly\ngenerate individual symbols but assemble them in a nonsensical manner. Through\nexperimental probing, we consistently observe that such phenomenon is\nattributed it to the network's local generation bias. Denoising networks tend\nto produce outputs that rely heavily on highly correlated local regions,\nparticularly when different dimensions of the data distribution are nearly\npairwise independent. This behavior leads to a generation process that\ndecomposes the global distribution into separate, independent distributions for\neach symbol, ultimately failing to capture the global structure, including\nunderlying grammar. Intriguingly, this bias persists across various denoising\nnetwork architectures including MLP and transformers which have the structure\nto model global dependency. These findings also provide insights into\nunderstanding other types of hallucinations, extending beyond text, as a result\nof implicit biases in the denoising models. Additionally, we theoretically\nanalyze the training dynamics for a specific case involving a two-layer MLP\nlearning parity points on a hypercube, offering an explanation of its\nunderlying mechanism.\n","authors":["Rui Lu","Runzhe Wang","Kaifeng Lyu","Xitai Jiang","Gao Huang","Mengdi Wang"],"pdf_url":"https://arxiv.org/pdf/2503.03595v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2501.01999v2","updated":"2025-03-05T15:26:17Z","published":"2025-01-01T07:00:41Z","title":"On the Utility of Equivariance and Symmetry Breaking in Deep Learning\n  Architectures on Point Clouds","summary":"  This paper explores the key factors that influence the performance of models\nworking with point clouds, across different tasks of varying geometric\ncomplexity. In this work, we explore the trade-offs between flexibility and\nweight-sharing introduced by equivariant layers, assessing when equivariance\nboosts or detracts from performance. It is often argued that providing more\ninformation as input improves a model's performance. However, if this\nadditional information breaks certain properties, such as $\\SE(3)$\nequivariance, does it remain beneficial? We identify the key aspects of\nequivariant and non-equivariant architectures that drive success in different\ntasks by benchmarking them on segmentation, regression, and generation tasks\nacross multiple datasets with increasing complexity. We observe a positive\nimpact of equivariance, which becomes more pronounced with increasing task\ncomplexity, even when strict equivariance is not required.\n","authors":["Sharvaree Vadgama","Mohammad Mohaiminul Islam","Domas Buracus","Christian Shewmake","Erik Bekkers"],"pdf_url":"https://arxiv.org/pdf/2501.01999v2.pdf","comment":"19 pages, 4 figures"},{"id":"http://arxiv.org/abs/2503.03588v1","updated":"2025-03-05T15:24:11Z","published":"2025-03-05T15:24:11Z","title":"PowerAttention: Exponentially Scaling of Receptive Fields for Effective\n  Sparse Attention","summary":"  Large Language Models (LLMs) face efficiency bottlenecks due to the quadratic\ncomplexity of the attention mechanism when processing long contexts. Sparse\nattention methods offer a promising solution, but existing approaches often\nsuffer from incomplete effective context and/or require complex implementation\nof pipeline. We present a comprehensive analysis of sparse attention for\nautoregressive LLMs from the respective of receptive field, recognize the\nsuboptimal nature of existing methods for expanding the receptive field, and\nintroduce PowerAttention, a novel sparse attention design that facilitates\neffective and complete context extension through the theoretical analysis.\nPowerAttention achieves exponential receptive field growth in $d$-layer LLMs,\nallowing each output token to attend to $2^d$ tokens, ensuring completeness and\ncontinuity of the receptive field. Experiments demonstrate that PowerAttention\noutperforms existing static sparse attention methods by $5\\sim 40\\%$,\nespecially on tasks demanding long-range dependencies like Passkey Retrieval\nand RULER, while maintaining a comparable time complexity to sliding window\nattention. Efficiency evaluations further highlight PowerAttention's superior\nspeedup in both prefilling and decoding phases compared with dynamic sparse\nattentions and full attention ($3.0\\times$ faster on 128K context), making it a\nhighly effective and user-friendly solution for processing long sequences in\nLLMs.\n","authors":["Lida Chen","Dong Xu","Chenxin An","Xintao Wang","Yikai Zhang","Jiangjie Chen","Zujie Liang","Feng Wei","Jiaqing Liang","Yanghua Xiao","Wei Wang"],"pdf_url":"https://arxiv.org/pdf/2503.03588v1.pdf","comment":"for associated code, see https://github.com/w568w/PowerAttention"},{"id":"http://arxiv.org/abs/2503.03579v1","updated":"2025-03-05T15:13:54Z","published":"2025-03-05T15:13:54Z","title":"A Generative System for Robot-to-Human Handovers: from Intent Inference\n  to Spatial Configuration Imagery","summary":"  We propose a novel system for robot-to-human object handover that emulates\nhuman coworker interactions. Unlike most existing studies that focus primarily\non grasping strategies and motion planning, our system focus on 1. inferring\nhuman handover intents, 2. imagining spatial handover configuration. The first\none integrates multimodal perception-combining visual and verbal cues-to infer\nhuman intent. The second one using a diffusion-based model to generate the\nhandover configuration, involving the spacial relationship among robot's\ngripper, the object, and the human hand, thereby mimicking the cognitive\nprocess of motor imagery. Experimental results demonstrate that our approach\neffectively interprets human cues and achieves fluent, human-like handovers,\noffering a promising solution for collaborative robotics. Code, videos, and\ndata are available at: https://i3handover.github.io.\n","authors":["Hanxin Zhang","Abdulqader Dhafer","Zhou Daniel Hao","Hongbiao Dong"],"pdf_url":"https://arxiv.org/pdf/2503.03579v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2502.12395v2","updated":"2025-03-05T15:10:51Z","published":"2025-02-18T00:06:40Z","title":"Efficient Neural SDE Training using Wiener-Space Cubature","summary":"  A neural stochastic differential equation (SDE) is an SDE with drift and\ndiffusion terms parametrized by neural networks. The training procedure for\nneural SDEs consists of optimizing the SDE vector field (neural network)\nparameters to minimize the expected value of an objective functional on\ninfinite-dimensional path-space. Existing training techniques focus on methods\nto efficiently compute path-wise gradients of the objective functional with\nrespect to these parameters, then pair this with Monte-Carlo simulation to\nestimate the expectation, and stochastic gradient descent to optimize. In this\nwork we introduce a novel training technique which bypasses and improves upon\nMonte-Carlo simulation; we extend results in the theory of Wiener-space\ncubature to approximate the expected objective functional by a weighted sum of\ndeterministic ODE solutions. This allows us to compute gradients by efficient\nODE adjoint methods. Furthermore, we exploit a high-order recombination scheme\nto drastically reduce the number of ODE solutions necessary to achieve a\nreasonable approximation. We show that this Wiener-space cubature approach can\nsurpass the O(1/sqrt(n)) rate of Monte-Carlo simulation, or the O(log(n)/n)\nrate of quasi-Monte-Carlo, to achieve a O(1/n) rate under reasonable\nassumptions.\n","authors":["Luke Snow","Vikram Krishnamurthy"],"pdf_url":"https://arxiv.org/pdf/2502.12395v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.03576v1","updated":"2025-03-05T15:02:46Z","published":"2025-03-05T15:02:46Z","title":"Optimal Decision Tree Pruning Revisited: Algorithms and Complexity","summary":"  We present a comprehensive classical and parameterized complexity analysis of\ndecision tree pruning operations, extending recent research on the complexity\nof learning small decision trees. Thereby, we offer new insights into the\ncomputational challenges of decision tree simplification, a crucial aspect of\ndeveloping interpretable and efficient machine learning models. We focus on\nfundamental pruning operations of subtree replacement and raising, which are\nused in heuristics. Surprisingly, while optimal pruning can be performed in\npolynomial time for subtree replacement, the problem is NP-complete for subtree\nraising. Therefore, we identify parameters and combinations thereof that lead\nto fixed-parameter tractability or hardness, establishing a precise borderline\nbetween these complexity classes. For example, while subtree raising is hard\nfor small domain size $D$ or number $d$ of features, it can be solved in\n$D^{2d} \\cdot |I|^{O(1)}$ time, where $|I|$ is the input size. We complement\nour theoretical findings with preliminary experimental results, demonstrating\nthe practical implications of our analysis.\n","authors":["Juha Harviainen","Frank Sommer","Manuel Sorge","Stefan Szeider"],"pdf_url":"https://arxiv.org/pdf/2503.03576v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.03574v1","updated":"2025-03-05T15:01:56Z","published":"2025-03-05T15:01:56Z","title":"Olympus: A Jumping Quadruped for Planetary Exploration Utilizing\n  Reinforcement Learning for In-Flight Attitude Control","summary":"  Exploring planetary bodies with lower gravity, such as the moon and Mars,\nallows legged robots to utilize jumping as an efficient form of locomotion thus\ngiving them a valuable advantage over traditional rovers for exploration.\nMotivated by this fact, this paper presents the design, simulation, and\nlearning-based \"in-flight\" attitude control of Olympus, a jumping legged robot\ntailored to the gravity of Mars. First, the design requirements are outlined\nfollowed by detailing how simulation enabled optimizing the robot's design -\nfrom its legs to the overall configuration - towards high vertical jumping,\nforward jumping distance, and in-flight attitude reorientation. Subsequently,\nthe reinforcement learning policy used to track desired in-flight attitude\nmaneuvers is presented. Successfully crossing the sim2real gap, extensive\nexperimental studies of attitude reorientation tests are demonstrated.\n","authors":["Jrgen Anker Olsen","Grzegorz Malczyk","Kostas Alexis"],"pdf_url":"https://arxiv.org/pdf/2503.03574v1.pdf","comment":"7 pages, 6 figures, Accepted to the IEEE International Conference on\n  Robotics and Automation (ICRA) 2025"},{"id":"http://arxiv.org/abs/2503.03571v1","updated":"2025-03-05T15:00:39Z","published":"2025-03-05T15:00:39Z","title":"Domain Consistent Industrial Decarbonisation of Global Coal Power Plants","summary":"  Machine learning and optimisation techniques (MLOPT) hold significant\npotential to accelerate the decarbonisation of industrial systems by enabling\ndata-driven operational improvements. However, the practical application of\nMLOPT in industrial settings is often hindered by a lack of domain compliance\nand system-specific consistency, resulting in suboptimal solutions with limited\nreal-world applicability. To address this challenge, we propose a novel\nhuman-in-the-loop (HITL) constraint-based optimisation framework that\nintegrates domain expertise with data-driven methods, ensuring solutions are\nboth technically sound and operationally feasible. We demonstrate the efficacy\nof this framework through a case study focused on enhancing the thermal\nefficiency and reducing the turbine heat rate of a 660 MW supercritical\ncoal-fired power plant. By embedding domain knowledge as constraints within the\noptimisation process, our approach yields solutions that align with the plant's\noperational patterns and are seamlessly integrated into its control systems.\nEmpirical validation confirms a mean improvement in thermal efficiency of\n0.64\\% and a mean reduction in turbine heat rate of 93 kJ/kWh. Scaling our\nanalysis to 59 global coal power plants with comparable capacity and fuel type,\nwe estimate a cumulative lifetime reduction of 156.4 million tons of carbon\nemissions. These results underscore the transformative potential of our\nHITL-MLOPT framework in delivering domain-compliant, implementable solutions\nfor industrial decarbonisation, offering a scalable pathway to mitigate the\nenvironmental impact of coal-based power generation worldwide.\n","authors":["Waqar Muhammad Ashraf","Vivek Dua","Ramit Debnath"],"pdf_url":"https://arxiv.org/pdf/2503.03571v1.pdf","comment":"6 figures. 17 pages"},{"id":"http://arxiv.org/abs/2503.03565v1","updated":"2025-03-05T14:53:32Z","published":"2025-03-05T14:53:32Z","title":"Probabilistic Insights for Efficient Exploration Strategies in\n  Reinforcement Learning","summary":"  We investigate efficient exploration strategies of environments with unknown\nstochastic dynamics and sparse rewards. Specifically, we analyze first the\nimpact of parallel simulations on the probability of reaching rare states\nwithin a finite time budget. Using simplified models based on random walks and\nL\\'evy processes, we provide analytical results that demonstrate a phase\ntransition in reaching probabilities as a function of the number of parallel\nsimulations. We identify an optimal number of parallel simulations that\nbalances exploration diversity and time allocation. Additionally, we analyze a\nrestarting mechanism that exponentially enhances the probability of success by\nredirecting efforts toward more promising regions of the state space. Our\nfindings contribute to a more qualitative and quantitative theory of some\nexploration schemes in reinforcement learning, offering insights into\ndeveloping more efficient strategies for environments characterized by rare\nevents.\n","authors":["Ernesto Garcia","Paola Bermolen","Matthieu Jonckheere","Seva Shneer"],"pdf_url":"https://arxiv.org/pdf/2503.03565v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.03561v1","updated":"2025-03-05T14:49:06Z","published":"2025-03-05T14:49:06Z","title":"Transformer-Based Power Optimization for Max-Min Fairness in Cell-Free\n  Massive MIMO","summary":"  Power allocation is an important task in wireless communication networks.\nClassical optimization algorithms and deep learning methods, while effective in\nsmall and static scenarios, become either computationally demanding or\nunsuitable for large and dynamic networks with varying user loads. This letter\nexplores the potential of transformer-based deep learning models to address\nthese challenges. We propose a transformer neural network to jointly predict\noptimal uplink and downlink power using only user and access point positions.\nThe max-min fairness problem in cell-free massive multiple input multiple\noutput systems is considered. Numerical results show that the trained model\nprovides near-optimal performance and adapts to varying numbers of users and\naccess points without retraining, additional processing, or updating its neural\nnetwork architecture. This demonstrates the effectiveness of the proposed model\nin achieving robust and flexible power allocation for dynamic networks.\n","authors":["Irched Chafaa","Giacomo Bacci","Luca Sanguinetti"],"pdf_url":"https://arxiv.org/pdf/2503.03561v1.pdf","comment":"5 pages, IEEE WCL, 4 FIGURES"},{"id":"http://arxiv.org/abs/2407.16205v5","updated":"2025-03-05T14:43:33Z","published":"2024-07-23T06:14:41Z","title":"LLMs can be Dangerous Reasoners: Analyzing-based Jailbreak Attack on\n  Large Language Models","summary":"  The rapid development of Large Language Models (LLMs) has brought significant\nadvancements across various tasks. However, despite these achievements, LLMs\nstill exhibit inherent safety vulnerabilities, especially when confronted with\njailbreak attacks. Existing jailbreak methods suffer from two main limitations:\nreliance on complicated prompt engineering and iterative optimization, which\nlead to low attack success rate (ASR) and attack efficiency (AE). In this work,\nwe propose an efficient jailbreak attack method, Analyzing-based Jailbreak\n(ABJ), which leverages the advanced reasoning capability of LLMs to\nautonomously generate harmful content, revealing their underlying safety\nvulnerabilities during complex reasoning process. We conduct comprehensive\nexperiments on ABJ across various open-source and closed-source LLMs. In\nparticular, ABJ achieves high ASR (82.1% on GPT-4o-2024-11-20) with exceptional\nAE among all target LLMs, showcasing its remarkable attack effectiveness,\ntransferability, and efficiency. Our findings underscore the urgent need to\nprioritize and improve the safety of LLMs to mitigate the risks of misuse.\n","authors":["Shi Lin","Hongming Yang","Dingyang Lin","Rongchang Li","Xun Wang","Changting Lin","Wenpeng Xing","Meng Han"],"pdf_url":"https://arxiv.org/pdf/2407.16205v5.pdf","comment":null},{"id":"http://arxiv.org/abs/2502.07115v3","updated":"2025-03-05T14:43:01Z","published":"2025-02-10T23:11:44Z","title":"Online Scheduling for LLM Inference with KV Cache Constraints","summary":"  Large Language Model (LLM) inference, where a trained model generates text\none word at a time in response to user prompts, is a computationally intensive\nprocess requiring efficient scheduling to optimize latency and resource\nutilization. A key challenge in LLM inference is the management of the\nKey-Value (KV) cache, which reduces redundant computations but introduces\nmemory constraints. In this work, we model LLM inference with KV cache\nconstraints theoretically and propose novel batching and scheduling algorithms\nthat minimize inference latency while effectively managing the KV cache's\nmemory.\n  We analyze both semi-online and fully online scheduling models, and our\nresults are threefold. First, we provide a polynomial-time algorithm that\nachieves exact optimality in terms of average latency in the semi-online prompt\narrival model. Second, in the fully online case with a stochastic prompt\narrival, we introduce an efficient online scheduling algorithm with constant\nregret. Third, we prove that no algorithm (deterministic or randomized) can\nachieve a constant competitive ratio in fully online adversarial settings. Our\nempirical evaluations on a public LLM inference dataset, using the Llama-70B\nmodel on A100 GPUs, show that our approach significantly outperforms benchmark\nalgorithms used currently in practice, achieving lower latency while reducing\nenergy consumption. Overall, our results offer a path toward more sustainable\nand cost-effective LLM deployment.\n","authors":["Patrick Jaillet","Jiashuo Jiang","Chara Podimata","Zijie Zhou"],"pdf_url":"https://arxiv.org/pdf/2502.07115v3.pdf","comment":"Will add a lemma in the proof of Theorem 5.3 to make the statement\n  and proof more rigorous"},{"id":"http://arxiv.org/abs/2503.03548v1","updated":"2025-03-05T14:32:32Z","published":"2025-03-05T14:32:32Z","title":"Simulation-Based Performance Evaluation of 3D Object Detection Methods\n  with Deep Learning for a LiDAR Point Cloud Dataset in a SOTIF-related Use\n  Case","summary":"  Safety of the Intended Functionality (SOTIF) addresses sensor performance\nlimitations and deep learning-based object detection insufficiencies to ensure\nthe intended functionality of Automated Driving Systems (ADS). This paper\npresents a methodology examining the adaptability and performance evaluation of\nthe 3D object detection methods on a LiDAR point cloud dataset generated by\nsimulating a SOTIF-related Use Case. The major contributions of this paper\ninclude defining and modelling a SOTIF-related Use Case with 21 diverse weather\nconditions and generating a LiDAR point cloud dataset suitable for application\nof 3D object detection methods. The dataset consists of 547 frames,\nencompassing clear, cloudy, rainy weather conditions, corresponding to\ndifferent times of the day, including noon, sunset, and night. Employing\nMMDetection3D and OpenPCDET toolkits, the performance of State-of-the-Art\n(SOTA) 3D object detection methods is evaluated and compared by testing the\npre-trained Deep Learning (DL) models on the generated dataset using Average\nPrecision (AP) and Recall metrics.\n","authors":["Milin Patel","Rolf Jung"],"pdf_url":"https://arxiv.org/pdf/2503.03548v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.03545v1","updated":"2025-03-05T14:28:38Z","published":"2025-03-05T14:28:38Z","title":"Revisiting the Role of Relearning in Semantic Dementia","summary":"  Patients with semantic dementia (SD) present with remarkably consistent\natrophy of neurons in the anterior temporal lobe and behavioural impairments,\nsuch as graded loss of category knowledge. While relearning of lost knowledge\nhas been shown in acute brain injuries such as stroke, it has not been widely\nsupported in chronic cognitive diseases such as SD. Previous research has shown\nthat deep linear artificial neural networks exhibit stages of semantic learning\nakin to humans. Here, we use a deep linear network to test the hypothesis that\nrelearning during disease progression rather than particular atrophy cause the\nspecific behavioural patterns associated with SD. After training the network to\ngenerate the common semantic features of various hierarchically organised\nobjects, neurons are successively deleted to mimic atrophy while retraining the\nmodel. The model with relearning and deleted neurons reproduced errors specific\nto SD, including prototyping errors and cross-category confusions. This\nsuggests that relearning is necessary for artificial neural networks to\nreproduce the behavioural patterns associated with SD in the absence of\n\\textit{output} non-linearities. Our results support a theory of SD progression\nthat results from continuous relearning of lost information. Future research\nshould revisit the role of relearning as a contributing factor to cognitive\ndiseases.\n","authors":["Devon Jarvis","Verena Klar","Richard Klein","Benjamin Rosman","Andrew Saxe"],"pdf_url":"https://arxiv.org/pdf/2503.03545v1.pdf","comment":"3 pages, 2 figures, presented at the Cognitive Computational\n  Neuroscience Conference (CCN) 2023"},{"id":"http://arxiv.org/abs/2409.16502v2","updated":"2025-03-05T14:11:44Z","published":"2024-09-24T23:18:32Z","title":"GSplatLoc: Grounding Keypoint Descriptors into 3D Gaussian Splatting for\n  Improved Visual Localization","summary":"  Although various visual localization approaches exist, such as scene\ncoordinate regression and camera pose regression, these methods often struggle\nwith optimization complexity or limited accuracy. To address these challenges,\nwe explore the use of novel view synthesis techniques, particularly 3D Gaussian\nSplatting (3DGS), which enables the compact encoding of both 3D geometry and\nscene appearance. We propose a two-stage procedure that integrates dense and\nrobust keypoint descriptors from the lightweight XFeat feature extractor into\n3DGS, enhancing performance in both indoor and outdoor environments. The coarse\npose estimates are directly obtained via 2D-3D correspondences between the 3DGS\nrepresentation and query image descriptors. In the second stage, the initial\npose estimate is refined by minimizing the rendering-based photometric warp\nloss. Benchmarking on widely used indoor and outdoor datasets demonstrates\nimprovements over recent neural rendering-based localization methods, such as\nNeRFMatch and PNeRFLoc.\n","authors":["Gennady Sidorov","Malik Mohrat","Denis Gridusov","Ruslan Rakhimov","Sergey Kolyubin"],"pdf_url":"https://arxiv.org/pdf/2409.16502v2.pdf","comment":"Project website at https://gsplatloc.github.io/"},{"id":"http://arxiv.org/abs/2503.03524v1","updated":"2025-03-05T14:08:53Z","published":"2025-03-05T14:08:53Z","title":"Intrinsic and Extrinsic Factor Disentanglement for Recommendation in\n  Various Context Scenarios","summary":"  In recommender systems, the patterns of user behaviors (e.g., purchase,\nclick) may vary greatly in different contexts (e.g., time and location). This\nis because user behavior is jointly determined by two types of factors:\nintrinsic factors, which reflect consistent user preference, and extrinsic\nfactors, which reflect external incentives that may vary in different contexts.\nDifferentiating between intrinsic and extrinsic factors helps learn user\nbehaviors better. However, existing studies have only considered\ndifferentiating them from a single, pre-defined context (e.g., time or\nlocation), ignoring the fact that a user's extrinsic factors may be influenced\nby the interplay of various contexts at the same time. In this paper, we\npropose the Intrinsic-Extrinsic Disentangled Recommendation (IEDR) model, a\ngeneric framework that differentiates intrinsic from extrinsic factors\nconsidering various contexts simultaneously, enabling more accurate\ndifferentiation of factors and hence the improvement of recommendation\naccuracy. IEDR contains a context-invariant contrastive learning component to\ncapture intrinsic factors, and a disentanglement component to extract extrinsic\nfactors under the interplay of various contexts. The two components work\ntogether to achieve effective factor learning. Extensive experiments on\nreal-world datasets demonstrate IEDR's effectiveness in learning disentangled\nfactors and significantly improving recommendation accuracy by up to 4% in\nNDCG.\n","authors":["Yixin Su","Wei Jiang","Fangquan Lin","Cheng Yang","Sarah M. Erfani","Junhao Gan","Yunxiang Zhao","Ruixuan Li","Rui Zhang"],"pdf_url":"https://arxiv.org/pdf/2503.03524v1.pdf","comment":"32 pages, 13 figures, 11 tables. Accepted by Transactions of\n  Information Systems"},{"id":"http://arxiv.org/abs/2503.03523v1","updated":"2025-03-05T14:07:29Z","published":"2025-03-05T14:07:29Z","title":"O-RAN xApps Conflict Management using Graph Convolutional Networks","summary":"  Open Radio Access Network (O-RAN) adopts a flexible, open, and virtualized\nstructure with standardized interfaces, reducing dependency on a single\nsupplier. Conflict management in O-RAN refers to the process of identifying and\nresolving conflicts between network applications. xApps are applications\ndeployed at the RAN Intelligent Controller (RIC) that leverage advanced AI/ML\nalgorithms to make dynamic decisions for network optimization. The lack of a\nunified mechanism to coordinate and prioritize the actions of different\napplications can create three types of conflicts (direct, indirect, and\nimplicit). In our paper, we introduce a novel data-driven GCN-based method\ncalled Graph-based xApps Conflict and Root Cause Analysis Engine (GRACE) based\non Graph Convolutional Network (GCN). It detects three types of conflicts\n(direct, indirect, and implicit) and pinpoints the root causes (xApps). GRACE\ncaptures the complex and hidden dependencies among the xApps, the controlled\nparameters, and the KPIs in O-RAN to detect possible conflicts. Then, it\nidentifies the root causes (xApps) contributing to the detected conflicts. The\nproposed method was tested on highly imbalanced datasets where the number of\nconflict instances ranges from 40% to 10%. The model is tested in a setting\nthat simulates real-world scenarios where conflicts are rare to assess its\nperformance and generalizability. Experimental results demonstrate an\nexceptional performance, achieving a high F1-score greater than 98% for all the\ncase studies.\n","authors":["Maryam Al Shami","Jun Yan","Emmanuel Thepie Fapi"],"pdf_url":"https://arxiv.org/pdf/2503.03523v1.pdf","comment":"9 pages, 10 figures"},{"id":"http://arxiv.org/abs/2412.18180v3","updated":"2025-03-05T14:05:29Z","published":"2024-12-24T05:34:05Z","title":"PCM Selector: Penalized Covariate-Mediator Selection Operator for\n  Evaluating Linear Causal Effects","summary":"  For a data-generating process for random variables that can be described with\na linear structural equation model, we consider a situation in which (i) a set\nof covariates satisfying the back-door criterion cannot be observed or (ii)\nsuch a set can be observed, but standard statistical estimation methods cannot\nbe applied to estimate causal effects because of\nmulticollinearity/high-dimensional data problems. We propose a novel two-stage\npenalized regression approach, the penalized covariate-mediator selection\noperator (PCM Selector), to estimate the causal effects in such scenarios.\nUnlike existing penalized regression analyses, when a set of intermediate\nvariables is available, PCM Selector provides a consistent or less biased\nestimator of the causal effect. In addition, PCM Selector provides a variable\nselection procedure for intermediate variables to obtain better estimation\naccuracy of the causal effects than does the back-door criterion.\n","authors":["Hisayoshi Nanmo","Manabu Kuroki"],"pdf_url":"https://arxiv.org/pdf/2412.18180v3.pdf","comment":"Accepted by AAAI 2025"},{"id":"http://arxiv.org/abs/2503.01431v2","updated":"2025-03-05T14:04:46Z","published":"2025-03-03T11:34:27Z","title":"How simple can you go? An off-the-shelf transformer approach to\n  molecular dynamics","summary":"  Most current neural networks for molecular dynamics (MD) include physical\ninductive biases, resulting in specialized and complex architectures. This is\nin contrast to most other machine learning domains, where specialist approaches\nare increasingly replaced by general-purpose architectures trained on vast\ndatasets. In line with this trend, several recent studies have questioned the\nnecessity of architectural features commonly found in MD models, such as\nbuilt-in rotational equivariance or energy conservation. In this work, we\ncontribute to the ongoing discussion by evaluating the performance of an MD\nmodel with as few specialized architectural features as possible. We present a\nrecipe for MD using an Edge Transformer, an \"off-the-shelf'' transformer\narchitecture that has been minimally modified for the MD domain, termed MD-ET.\nOur model implements neither built-in equivariance nor energy conservation. We\nuse a simple supervised pre-training scheme on $\\sim$30 million molecular\nstructures from the QCML database. Using this \"off-the-shelf'' approach, we\nshow state-of-the-art results on several benchmarks after fine-tuning for a\nsmall number of steps. Additionally, we examine the effects of being only\napproximately equivariant and energy conserving for MD simulations, proposing a\nnovel method for distinguishing the errors resulting from non-equivariance from\nother sources of inaccuracies like numerical rounding errors. While our model\nexhibits runaway energy increases on larger structures, we show approximately\nenergy-conserving NVE simulations for a range of small structures.\n","authors":["Max Eissler","Tim Korjakow","Stefan Ganscha","Oliver T. Unke","Klaus-Robert Mller","Stefan Gugler"],"pdf_url":"https://arxiv.org/pdf/2503.01431v2.pdf","comment":"21 pages, code at https://github.com/mx-e/simple-md"},{"id":"http://arxiv.org/abs/2503.03515v1","updated":"2025-03-05T14:01:17Z","published":"2025-03-05T14:01:17Z","title":"DO-IQS: Dynamics-Aware Offline Inverse Q-Learning for Optimal Stopping\n  with Unknown Gain Functions","summary":"  We consider Inverse Optimal Stopping (IOS) problem where, based on stopped\nexpert trajectories, one aims to recover the optimal stopping region through\ncontinuation and stopping gain functions approximation. The uniqueness of the\nstopping region allows the use of IOS in real-world applications with safety\nconcerns. While current state-of-the-art inverse reinforcement learning methods\nrecover both a Q-function and the corresponding optimal policy, they fail to\naccount for specific challenges posed by optimal stopping problems. These\ninclude data sparsity near the stopping region, non-Markovian nature of the\ncontinuation gain, a proper treatment of boundary conditions, the need for a\nstable offline approach for risk-sensitive applications, and a lack of a\nquality evaluation metric. These challenges are addressed with the proposed\nDynamics-Aware Offline Inverse Q-Learning for Optimal Stopping (DO-IQS), which\nincorporates temporal information by approximating the cumulative continuation\ngain together with the world dynamics and the Q-function without querying to\nthe environment. Moreover, a confidence-based oversampling approach is proposed\nto treat the data sparsity problem. We demonstrate the performance of our\nmodels on real and artificial data including an optimal intervention for\ncritical events problem.\n","authors":["Anna Kuchko"],"pdf_url":"https://arxiv.org/pdf/2503.03515v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.05459v2","updated":"2025-03-05T13:57:56Z","published":"2024-10-07T19:45:09Z","title":"From Sparse Dependence to Sparse Attention: Unveiling How\n  Chain-of-Thought Enhances Transformer Sample Efficiency","summary":"  Chain-of-thought (CoT) significantly enhances the reasoning performance of\nlarge language models (LLM). While current theoretical studies often attribute\nthis improvement to increased expressiveness and computational capacity, we\nargue that expressiveness is not the primary limitation in the LLM regime, as\ncurrent large models will fail on simple tasks. Using a parity-learning setup,\nwe demonstrate that CoT can substantially improve sample efficiency even when\nthe representation power is sufficient. Specifically, with CoT, a transformer\ncan learn the function within polynomial samples, whereas without CoT, the\nrequired sample size is exponential. Additionally, we show that CoT simplifies\nthe learning process by introducing sparse sequential dependencies among input\ntokens, and leads to a sparse and interpretable attention. We validate our\ntheoretical analysis with both synthetic and real-world experiments, confirming\nthat sparsity in attention layers is a key factor of the improvement induced by\nCoT.\n","authors":["Kaiyue Wen","Huaqing Zhang","Hongzhou Lin","Jingzhao Zhang"],"pdf_url":"https://arxiv.org/pdf/2410.05459v2.pdf","comment":"43 pages,11 figures"},{"id":"http://arxiv.org/abs/2503.03512v1","updated":"2025-03-05T13:57:48Z","published":"2025-03-05T13:57:48Z","title":"An Aspect Extraction Framework using Different Embedding Types, Learning\n  Models, and Dependency Structure","summary":"  Aspect-based sentiment analysis has gained significant attention in recent\nyears due to its ability to provide fine-grained insights for sentiment\nexpressions related to specific features of entities. An important component of\naspect-based sentiment analysis is aspect extraction, which involves\nidentifying and extracting aspect terms from text. Effective aspect extraction\nserves as the foundation for accurate sentiment analysis at the aspect level.\nIn this paper, we propose aspect extraction models that use different types of\nembeddings for words and part-of-speech tags and that combine several learning\nmodels. We also propose tree positional encoding that is based on dependency\nparsing output to capture better the aspect positions in sentences. In\naddition, a new aspect extraction dataset is built for Turkish by machine\ntranslating an English dataset in a controlled setting. The experiments\nconducted on two Turkish datasets showed that the proposed models mostly\noutperform the studies that use the same datasets, and incorporating tree\npositional encoding increases the performance of the models.\n","authors":["Ali Erkan","Tunga Gngr"],"pdf_url":"https://arxiv.org/pdf/2503.03512v1.pdf","comment":"Aspect-based Sentiment Analysis, Aspect Extraction, Natural Language\n  Processing, Machine Learning, Deep Neural Networks, Turkish"},{"id":"http://arxiv.org/abs/2503.03506v1","updated":"2025-03-05T13:54:13Z","published":"2025-03-05T13:54:13Z","title":"Rethinking Synthetic Data definitions: A privacy driven approach","summary":"  Synthetic data is gaining traction as a cost-effective solution for the\nincreasing data demands of AI development and can be generated either from\nexisting knowledge or derived data captured from real-world events. The source\nof the synthetic data generation and the technique used significantly impacts\nits residual privacy risk and therefore its opportunity for sharing.\nTraditional classification of synthetic data types no longer fit the newer\ngeneration techniques and there is a need to better align the classification\nwith practical needs. We suggest a new way of grouping synthetic data types\nthat better supports privacy evaluations to aid regulatory policymaking. Our\nnovel classification provides flexibility to new advancements like deep\ngenerative methods and offers a more practical framework for future\napplications.\n","authors":["Vibeke Binz Vallevik","Serena Elizabeth Marshall","Aleksandar Babic","Jan Franz Nygaard"],"pdf_url":"https://arxiv.org/pdf/2503.03506v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.03503v1","updated":"2025-03-05T13:47:55Z","published":"2025-03-05T13:47:55Z","title":"Collaborative Expert LLMs Guided Multi-Objective Molecular Optimization","summary":"  Molecular optimization is a crucial yet complex and time-intensive process\nthat often acts as a bottleneck for drug development. Traditional methods rely\nheavily on trial and error, making multi-objective optimization both\ntime-consuming and resource-intensive. Current AI-based methods have shown\nlimited success in handling multi-objective optimization tasks, hampering their\npractical utilization. To address this challenge, we present MultiMol, a\ncollaborative large language model (LLM) system designed to guide\nmulti-objective molecular optimization. MultiMol comprises two agents,\nincluding a data-driven worker agent and a literature-guided research agent.\nThe data-driven worker agent is a large language model being fine-tuned to\nlearn how to generate optimized molecules considering multiple objectives,\nwhile the literature-guided research agent is responsible for searching\ntask-related literature to find useful prior knowledge that facilitates\nidentifying the most promising optimized candidates. In evaluations across six\nmulti-objective optimization tasks, MultiMol significantly outperforms existing\nmethods, achieving a 82.30% success rate, in sharp contrast to the 27.50%\nsuccess rate of current strongest methods. To further validate its practical\nimpact, we tested MultiMol on two real-world challenges. First, we enhanced the\nselectivity of Xanthine Amine Congener (XAC), a promiscuous ligand that binds\nboth A1R and A2AR, successfully biasing it towards A1R. Second, we improved the\nbioavailability of Saquinavir, an HIV-1 protease inhibitor with known\nbioavailability limitations. Overall, these results indicate that MultiMol\nrepresents a highly promising approach for multi-objective molecular\noptimization, holding great potential to accelerate the drug development\nprocess and contribute to the advancement of pharmaceutical research.\n","authors":["Jiajun Yu","Yizhen Zheng","Huan Yee Koh","Shirui Pan","Tianyue Wang","Haishuai Wang"],"pdf_url":"https://arxiv.org/pdf/2503.03503v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.03499v1","updated":"2025-03-05T13:44:42Z","published":"2025-03-05T13:44:42Z","title":"State-offset Tuning: State-based Parameter-Efficient Fine-Tuning for\n  State Space Models","summary":"  State Space Models (SSMs) have emerged as efficient alternatives to\nTransformers, mitigating their quadratic computational cost. However, the\napplication of Parameter-Efficient Fine-Tuning (PEFT) methods to SSMs remains\nlargely unexplored. In particular, prompt-based methods like Prompt Tuning and\nPrefix-Tuning, which are widely used in Transformers, do not perform well on\nSSMs. To address this, we propose state-based methods as a superior alternative\nto prompt-based methods. This new family of methods naturally stems from the\narchitectural characteristics of SSMs. State-based methods adjust state-related\nfeatures directly instead of depending on external prompts. Furthermore, we\nintroduce a novel state-based PEFT method: State-offset Tuning. At every\ntimestep, our method directly affects the state at the current step, leading to\nmore effective adaptation. Through extensive experiments across diverse\ndatasets, we demonstrate the effectiveness of our method. Code is available at\nhttps://github.com/furiosa-ai/ssm-state-tuning.\n","authors":["Wonjun Kang","Kevin Galim","Yuchen Zeng","Minjae Lee","Hyung Il Koo","Nam Ik Cho"],"pdf_url":"https://arxiv.org/pdf/2503.03499v1.pdf","comment":"Code is available at https://github.com/furiosa-ai/ssm-state-tuning"},{"id":"http://arxiv.org/abs/2503.03489v1","updated":"2025-03-05T13:29:23Z","published":"2025-03-05T13:29:23Z","title":"Federated Learning for Predicting Mild Cognitive Impairment to Dementia\n  Conversion","summary":"  Dementia is a progressive condition that impairs an individual's cognitive\nhealth and daily functioning, with mild cognitive impairment (MCI) often\nserving as its precursor. The prediction of MCI to dementia conversion has been\nwell studied, but previous studies have almost always focused on traditional\nMachine Learning (ML) based methods that require sharing sensitive clinical\ninformation to train predictive models. This study proposes a privacy-enhancing\nsolution using Federated Learning (FL) to train predictive models for MCI to\ndementia conversion without sharing sensitive data, leveraging socio\ndemographic and cognitive measures. We simulated and compared two network\narchitectures, Peer to Peer (P2P) and client-server, to enable collaborative\nlearning. Our results demonstrated that FL had comparable predictive\nperformance to centralized ML, and each clinical site showed similar\nperformance without sharing local data. Moreover, the predictive performance of\nFL models was superior to site specific models trained without collaboration.\nThis work highlights that FL can eliminate the need for data sharing without\ncompromising model efficacy.\n","authors":["Gaurang Sharma","Elaheh Moradi","Juha Pajula","Mika Hilvo","Jussi Tohka"],"pdf_url":"https://arxiv.org/pdf/2503.03489v1.pdf","comment":"This work has been submitted to the IEEE for possible publication"},{"id":"http://arxiv.org/abs/2412.18355v2","updated":"2025-03-05T13:25:09Z","published":"2024-12-24T11:35:40Z","title":"Handling Spatial-Temporal Data Heterogeneity for Federated Continual\n  Learning via Tail Anchor","summary":"  Federated continual learning (FCL) allows each client to continually update\nits knowledge from task streams, enhancing the applicability of federated\nlearning in real-world scenarios. However, FCL needs to address not only\nspatial data heterogeneity between clients but also temporal data heterogeneity\nbetween tasks. In this paper, empirical experiments demonstrate that such\ninput-level heterogeneity significantly affects the model's internal parameters\nand outputs, leading to severe spatial-temporal catastrophic forgetting of\nlocal and previous knowledge. To this end, we propose Federated Tail Anchor\n(FedTA) to mix trainable Tail Anchor with the frozen output features to adjust\ntheir position in the feature space, thereby overcoming parameter-forgetting\nand output-forgetting. Three novel components are also included: Input\nEnhancement for improving the performance of pre-trained models on downstream\ntasks; Selective Input Knowledge Fusion for fusion of heterogeneous local\nknowledge on the server; and Best Global Prototype Selection for finding the\nbest anchor point for each class in the feature space. Extensive experiments\ndemonstrate that FedTA not only outperforms existing FCL methods but also\neffectively preserves the relative positions of features.\n","authors":["Hao Yu","Xin Yang","Le Zhang","Hanlin Gu","Tianrui Li","Lixin Fan","Qiang Yang"],"pdf_url":"https://arxiv.org/pdf/2412.18355v2.pdf","comment":"This paper is accepted by CVPR 2025"},{"id":"http://arxiv.org/abs/2503.03486v1","updated":"2025-03-05T13:24:58Z","published":"2025-03-05T13:24:58Z","title":"Differentially Private Learners for Heterogeneous Treatment Effects","summary":"  Patient data is widely used to estimate heterogeneous treatment effects and\nthus understand the effectiveness and safety of drugs. Yet, patient data\nincludes highly sensitive information that must be kept private. In this work,\nwe aim to estimate the conditional average treatment effect (CATE) from\nobservational data under differential privacy. Specifically, we present\nDP-CATE, a novel framework for CATE estimation that is Neyman-orthogonal and\nfurther ensures differential privacy of the estimates. Our framework is highly\ngeneral: it applies to any two-stage CATE meta-learner with a Neyman-orthogonal\nloss function, and any machine learning model can be used for nuisance\nestimation. We further provide an extension of our DP-CATE, where we employ\nRKHS regression to release the complete CATE function while ensuring\ndifferential privacy. We demonstrate our DP-CATE across various experiments\nusing synthetic and real-world datasets. To the best of our knowledge, we are\nthe first to provide a framework for CATE estimation that is Neyman-orthogonal\nand differentially private.\n","authors":["Maresa Schrder","Valentyn Melnychuk","Stefan Feuerriegel"],"pdf_url":"https://arxiv.org/pdf/2503.03486v1.pdf","comment":"Published at ICLR 2025"},{"id":"http://arxiv.org/abs/2503.03485v1","updated":"2025-03-05T13:24:57Z","published":"2025-03-05T13:24:57Z","title":"TEDDY: A Family Of Foundation Models For Understanding Single Cell\n  Biology","summary":"  Understanding the biological mechanism of disease is critical for medicine,\nand in particular drug discovery. AI-powered analysis of genome-scale\nbiological data hold great potential in this regard. The increasing\navailability of single-cell RNA sequencing data has enabled the development of\nlarge foundation models for disease biology. However, existing foundation\nmodels either do not improve or only modestly improve over task-specific models\nin downstream applications. Here, we explored two avenues for improving the\nstate-of-the-art. First, we scaled the pre-training dataset to 116 million\ncells, which is larger than those used by previous models. Second, we leveraged\nthe availability of large-scale biological annotations as a form of supervision\nduring pre-training. We trained the TEDDY family of models comprising six\ntransformer-based state-of-the-art single-cell foundation models with 70\nmillion, 160 million, and 400 million parameters. We vetted our models on two\ndownstream evaluation tasks -- identifying the underlying disease state of\nheld-out donors not seen during training and distinguishing healthy cells from\ndiseased ones for disease conditions and donors not seen during training.\nScaling experiments showed that performance improved predictably with both data\nvolume and parameter count. Our models showed substantial improvement over\nexisting work on the first task and more muted improvements on the second.\n","authors":["Alexis Chevalier","Soumya Ghosh","Urvi Awasthi","James Watkins","Julia Bieniewska","Nichita Mitrea","Olga Kotova","Kirill Shkura","Andrew Noble","Michael Steinbaugh","Julien Delile","Christoph Meier","Leonid Zhukov","Iya Khalil","Srayanta Mukherjee","Judith Mueller"],"pdf_url":"https://arxiv.org/pdf/2503.03485v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2502.20475v2","updated":"2025-03-05T13:22:47Z","published":"2025-02-27T19:23:15Z","title":"Promote, Suppress, Iterate: How Language Models Answer One-to-Many\n  Factual Queries","summary":"  To answer one-to-many factual queries (e.g., listing cities of a country), a\nlanguage model (LM) must simultaneously recall knowledge and avoid repeating\nprevious answers. How are these two subtasks implemented and integrated\ninternally? Across multiple datasets and models, we identify a\npromote-then-suppress mechanism: the model first recalls all answers, and then\nsuppresses previously generated ones. Specifically, LMs use both the subject\nand previous answer tokens to perform knowledge recall, with attention\npropagating subject information and MLPs promoting the answers. Then, attention\nattends to and suppresses previous answer tokens, while MLPs amplify the\nsuppression signal. Our mechanism is corroborated by extensive experimental\nevidence: in addition to using early decoding and causal tracing, we analyze\nhow components use different tokens by introducing both Token Lens, which\ndecodes aggregated attention updates from specified tokens, and a knockout\nmethod that analyzes changes in MLP outputs after removing attention to\nspecified tokens. Overall, we provide new insights into how LMs' internal\ncomponents interact with different input tokens to support complex factual\nrecall. Code is available at\nhttps://github.com/Lorenayannnnn/how-lms-answer-one-to-many-factual-queries.\n","authors":["Tianyi Lorena Yan","Robin Jia"],"pdf_url":"https://arxiv.org/pdf/2502.20475v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2501.02393v3","updated":"2025-03-05T13:19:16Z","published":"2025-01-04T22:30:21Z","title":"Graph-Aware Isomorphic Attention for Adaptive Dynamics in Transformers","summary":"  We present an approach to modifying Transformer architectures by integrating\ngraph-aware relational reasoning into the attention mechanism, merging concepts\nfrom graph neural networks and language modeling. Building on the inherent\nconnection between attention and graph theory, we reformulate the Transformer's\nattention mechanism as a graph operation and propose Graph-Aware Isomorphic\nAttention. This method leverages advanced graph modeling strategies, including\nGraph Isomorphism Networks (GIN) and Principal Neighborhood Aggregation (PNA),\nto enrich the representation of relational structures. Our approach captures\ncomplex dependencies and generalizes across tasks, as evidenced by a reduced\ngeneralization gap and improved learning performance. Additionally, we expand\nthe concept of graph-aware attention to introduce Sparse GIN-Attention, a\nfine-tuning approach that employs sparse GINs. By interpreting attention\nmatrices as sparse adjacency graphs, this technique enhances the adaptability\nof pre-trained foundational models with minimal computational overhead,\nendowing them with graph-aware capabilities. Sparse GIN-Attention fine-tuning\nachieves improved training dynamics and better generalization compared to\nalternative methods like low-rank adaption (LoRA). We discuss latent graph-like\nstructures within traditional attention mechanisms, offering a new lens through\nwhich Transformers can be understood. By evolving Transformers as hierarchical\nGIN models for relational reasoning. This perspective suggests profound\nimplications for foundational model development, enabling the design of\narchitectures that dynamically adapt to both local and global dependencies.\nApplications in bioinformatics, materials science, language modeling, and\nbeyond could benefit from this synthesis of relational and sequential data\nmodeling, setting the stage for interpretable and generalizable modeling\nstrategies.\n","authors":["Markus J. Buehler"],"pdf_url":"https://arxiv.org/pdf/2501.02393v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2310.14848v2","updated":"2025-03-05T12:52:30Z","published":"2023-10-23T12:15:23Z","title":"Zero-Knowledge Proof-based Verifiable Decentralized Machine Learning in\n  Communication Network: A Comprehensive Survey","summary":"  Over recent decades, machine learning has significantly advanced network\ncommunication, enabling improved decision-making, user behavior analysis, and\nfault detection. Decentralized approaches, where participants exchange\ncomputation results instead of raw private data, mitigate these risks but\nintroduce challenges related to trust and verifiability. A critical issue\narises: How can one ensure the integrity and validity of computation results\nshared by other participants? Existing survey articles predominantly address\nsecurity and privacy concerns in decentralized machine learning, whereas this\nsurvey uniquely highlights the emerging issue of verifiability. Recognizing the\ncritical role of zero-knowledge proofs in ensuring verifiability, we present a\ncomprehensive review of Zero-Knowledge Proof-based Verifiable Machine Learning\n(ZKP-VML). To clarify the research problem, we present a definition of ZKP-VML\nconsisting of four algorithms, along with several corresponding key security\nproperties. Besides, we provide an overview of the current research landscape\nby systematically organizing the research timeline and categorizing existing\nschemes based on their security properties. Furthermore, through an in-depth\nanalysis of each existing scheme, we summarize their technical contributions\nand optimization strategies, aiming to uncover common design principles\nunderlying ZKP-VML schemes. Building on the reviews and analysis presented, we\nidentify current research challenges and suggest future research directions. To\nthe best of our knowledge, this is the most comprehensive survey to date on\nverifiable decentralized machine learning and ZKP-VML.\n","authors":["Zhibo Xing","Zijian Zhang","Ziang Zhang","Zhen Li","Meng Li","Jiamou Liu","Zongyang Zhang","Yi Zhao","Qi Sun","Liehuang Zhu","Giovanni Russello"],"pdf_url":"https://arxiv.org/pdf/2310.14848v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.03462v1","updated":"2025-03-05T12:52:14Z","published":"2025-03-05T12:52:14Z","title":"Open-Source Large Language Models as Multilingual Crowdworkers:\n  Synthesizing Open-Domain Dialogues in Several Languages With No Examples in\n  Targets and No Machine Translation","summary":"  The prevailing paradigm in the domain of Open-Domain Dialogue agents\npredominantly focuses on the English language, encompassing both models and\ndatasets. Furthermore, the financial and temporal investments required for\ncrowdsourcing such datasets for finetuning are substantial, particularly when\nmultiple languages are involved. Fortunately, advancements in Large Language\nModels (LLMs) have unveiled a plethora of possibilities across diverse tasks.\nSpecifically, instruction-tuning has enabled LLMs to execute tasks based on\nnatural language instructions, occasionally surpassing the performance of human\ncrowdworkers. Additionally, these models possess the capability to function in\nvarious languages within a single thread. Consequently, to generate new samples\nin different languages, we propose leveraging these capabilities to replicate\nthe data collection process. We introduce a pipeline for generating Open-Domain\nDialogue data in multiple Target Languages using LLMs, with demonstrations\nprovided in a unique Source Language. By eschewing explicit Machine Translation\nin this approach, we enhance the adherence to language-specific nuances. We\napply this methodology to the PersonaChat dataset. To enhance the openness of\ngenerated dialogues and mimic real life scenarii, we added the notion of speech\nevents corresponding to the type of conversation the speakers are involved in\nand also that of common ground which represents the premises of a conversation.\n","authors":["Ahmed Njifenjou","Virgile Sucal","Bassam Jabaian","Fabrice Lefvre"],"pdf_url":"https://arxiv.org/pdf/2503.03462v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.03454v1","updated":"2025-03-05T12:40:34Z","published":"2025-03-05T12:40:34Z","title":"Data Poisoning Attacks to Locally Differentially Private Range Query\n  Protocols","summary":"  Trajectory data, which tracks movements through geographic locations, is\ncrucial for improving real-world applications. However, collecting such\nsensitive data raises considerable privacy concerns. Local differential privacy\n(LDP) offers a solution by allowing individuals to locally perturb their\ntrajectory data before sharing it. Despite its privacy benefits, LDP protocols\nare vulnerable to data poisoning attacks, where attackers inject fake data to\nmanipulate aggregated results. In this work, we make the first attempt to\nanalyze vulnerabilities in several representative LDP trajectory protocols. We\npropose \\textsc{TraP}, a heuristic algorithm for data \\underline{P}oisoning\nattacks using a prefix-suffix method to optimize fake \\underline{Tra}jectory\nselection, significantly reducing computational complexity. Our experimental\nresults demonstrate that our attack can substantially increase target pattern\noccurrences in the perturbed trajectory dataset with few fake users. This study\nunderscores the urgent need for robust defenses and better protocol designs to\nsafeguard LDP trajectory data against malicious manipulation.\n","authors":["I-Jung Hsu","Chih-Hsun Lin","Chia-Mu Yu","Sy-Yen Kuo","Chun-Ying Huang"],"pdf_url":"https://arxiv.org/pdf/2503.03454v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.03443v1","updated":"2025-03-05T12:24:12Z","published":"2025-03-05T12:24:12Z","title":"Conceptualizing Uncertainty","summary":"  Uncertainty in machine learning refers to the degree of confidence or lack\nthereof in a model's predictions. While uncertainty quantification methods\nexist, explanations of uncertainty, especially in high-dimensional settings,\nremain an open challenge. Existing work focuses on feature attribution\napproaches which are restricted to local explanations. Understanding\nuncertainty, its origins, and characteristics on a global scale is crucial for\nenhancing interpretability and trust in a model's predictions. In this work, we\npropose to explain the uncertainty in high-dimensional data classification\nsettings by means of concept activation vectors which give rise to local and\nglobal explanations of uncertainty. We demonstrate the utility of the generated\nexplanations by leveraging them to refine and improve our model.\n","authors":["Isaac Roberts","Alexander Schulz","Sarah Schroeder","Fabian Hinder","Barbara Hammer"],"pdf_url":"https://arxiv.org/pdf/2503.03443v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.03438v1","updated":"2025-03-05T12:13:08Z","published":"2025-03-05T12:13:08Z","title":"Gradient Deconfliction via Orthogonal Projections onto Subspaces For\n  Multi-task Learning","summary":"  Although multi-task learning (MTL) has been a preferred approach and\nsuccessfully applied in many real-world scenarios, MTL models are not\nguaranteed to outperform single-task models on all tasks mainly due to the\nnegative effects of conflicting gradients among the tasks. In this paper, we\nfully examine the influence of conflicting gradients and further emphasize the\nimportance and advantages of achieving non-conflicting gradients which allows\nsimple but effective trade-off strategies among the tasks with stable\nperformance. Based on our findings, we propose the Gradient Deconfliction via\nOrthogonal Projections onto Subspaces (GradOPS) spanned by other task-specific\ngradients. Our method not only solves all conflicts among the tasks, but can\nalso effectively search for diverse solutions towards different trade-off\npreferences among the tasks. Theoretical analysis on convergence is provided,\nand performance of our algorithm is fully testified on multiple benchmarks in\nvarious domains. Results demonstrate that our method can effectively find\nmultiple state-of-the-art solutions with different trade-off strategies among\nthe tasks on multiple datasets.\n","authors":["Shijie Zhu","Hui Zhao","Tianshu Wu","Pengjie Wang","Hongbo Deng","Jian Xu","Bo Zheng"],"pdf_url":"https://arxiv.org/pdf/2503.03438v1.pdf","comment":"WSDM 2025"},{"id":"http://arxiv.org/abs/2503.00578v2","updated":"2025-03-05T12:00:38Z","published":"2025-03-01T18:00:41Z","title":"Channel-Attentive Graph Neural Networks","summary":"  Graph Neural Networks (GNNs) set the state-of-the-art in representation\nlearning for graph-structured data. They are used in many domains, from online\nsocial networks to complex molecules. Most GNNs leverage the message-passing\nparadigm and achieve strong performances on various tasks. However, the\nmessage-passing mechanism used in most models suffers from over-smoothing as a\nGNN's depth increases. The over-smoothing degrades GNN's performance due to the\nincreased similarity between the representations of unrelated nodes. This study\nproposes an adaptive channel-wise message-passing approach to alleviate the\nover-smoothing. The proposed model, Channel-Attentive GNN, learns how to attend\nto neighboring nodes and their feature channels. Thus, much diverse information\ncan be transferred between nodes during message-passing. Experiments with\nwidely used benchmark datasets show that the proposed model is more resistant\nto over-smoothing than baselines and achieves state-of-the-art performances for\nvarious graphs with strong heterophily. Our code is at\nhttps://github.com/ALLab-Boun/CHAT-GNN.\n","authors":["Turul Hasan Karabulut","nci M. Bayta"],"pdf_url":"https://arxiv.org/pdf/2503.00578v2.pdf","comment":"Published as a conference paper at IEEE International Conference on\n  Data Mining 2024"},{"id":"http://arxiv.org/abs/2503.03426v1","updated":"2025-03-05T11:59:31Z","published":"2025-03-05T11:59:31Z","title":"Early-Stopped Mirror Descent for Linear Regression over Convex Bodies","summary":"  Early-stopped iterative optimization methods are widely used as alternatives\nto explicit regularization, and direct comparisons between early-stopping and\nexplicit regularization have been established for many optimization geometries.\nHowever, most analyses depend heavily on the specific properties of the\noptimization geometry or strong convexity of the empirical objective, and it\nremains unclear whether early-stopping could ever be less statistically\nefficient than explicit regularization for some particular shape constraint,\nespecially in the overparameterized regime. To address this question, we study\nthe setting of high-dimensional linear regression under additive Gaussian noise\nwhen the ground truth is assumed to lie in a known convex body and the task is\nto minimize the in-sample mean squared error. Our main result shows that for\nany convex body and any design matrix, up to an absolute constant factor, the\nworst-case risk of unconstrained early-stopped mirror descent with an\nappropriate potential is at most that of the least squares estimator\nconstrained to the convex body. We achieve this by constructing algorithmic\nregularizers based on the Minkowski functional of the convex body.\n","authors":["Tobias Wegel","Gil Kur","Patrick Rebeschini"],"pdf_url":"https://arxiv.org/pdf/2503.03426v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.00735v3","updated":"2025-03-05T11:50:24Z","published":"2025-03-02T05:16:43Z","title":"LADDER: Self-Improving LLMs Through Recursive Problem Decomposition","summary":"  We introduce LADDER (Learning through Autonomous Difficulty-Driven Example\nRecursion), a framework which enables Large Language Models to autonomously\nimprove their problem-solving capabilities through self-guided learning by\nrecursively generating and solving progressively simpler variants of complex\nproblems. Unlike prior approaches that require curated datasets or human\nfeedback, LADDER leverages a model's own capabilities to generate easier\nquestion variants. We demonstrate LADDER's effectiveness in the subject of\nmathematical integration, improving Llama 3.2 3B's accuracy from 1% to 82% on\nundergraduate-level problems and enabling Qwen2.5 7B Deepseek-R1 Distilled to\nachieve 73% on the MIT Integration Bee qualifying examination. We also\nintroduce TTRL (Test-Time Reinforcement Learning), where we perform\nreinforcement learning on variants of test problems at inference time. TTRL\nenables Qwen2.5 7B Deepseek-R1 Distilled to achieve a state-of-the-art score of\n90% on the MIT Integration Bee qualifying examination, surpassing OpenAI o1's\nperformance. These results show how self-directed strategic learning can\nachieve significant capability improvements without relying on architectural\nscaling or human supervision.\n","authors":["Toby Simonds","Akira Yoshiyama"],"pdf_url":"https://arxiv.org/pdf/2503.00735v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2412.18377v3","updated":"2025-03-05T11:49:36Z","published":"2024-12-24T12:03:36Z","title":"ChaI-TeA: A Benchmark for Evaluating Autocompletion of Interactions with\n  LLM-based Chatbots","summary":"  The rise of LLMs has deflected a growing portion of human-computer\ninteractions towards LLM-based chatbots. The remarkable abilities of these\nmodels allow users to interact using long, diverse natural language text\ncovering a wide range of topics and styles. Phrasing these messages is a time\nand effort consuming task, calling for an autocomplete solution to assist\nusers. We introduce the task of chatbot interaction autocomplete. We present\nChaI-TeA: CHat InTEraction Autocomplete; An autcomplete evaluation framework\nfor LLM-based chatbot interactions. The framework includes a formal definition\nof the task, coupled with suitable datasets and metrics. We use the framework\nto evaluate After formally defining the task along with suitable datasets and\nmetrics, we test 9 models on the defined auto completion task, finding that\nwhile current off-the-shelf models perform fairly, there is still much room for\nimprovement, mainly in ranking of the generated suggestions. We provide\ninsights for practitioners working on this task and open new research\ndirections for researchers in the field. We release our framework to serve as a\nfoundation for future research.\n","authors":["Shani Goren","Oren Kalinsky","Tomer Stav","Yuri Rapoport","Yaron Fairstein","Ram Yazdi","Nachshon Cohen","Alexander Libov","Guy Kushilevitz"],"pdf_url":"https://arxiv.org/pdf/2412.18377v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.03418v1","updated":"2025-03-05T11:47:41Z","published":"2025-03-05T11:47:41Z","title":"Simplicial SMOTE: Oversampling Solution to the Imbalanced Learning\n  Problem","summary":"  SMOTE (Synthetic Minority Oversampling Technique) is the established\ngeometric approach to random oversampling to balance classes in the imbalanced\nlearning problem, followed by many extensions. Its idea is to introduce\nsynthetic data points of the minor class, with each new point being the convex\ncombination of an existing data point and one of its k-nearest neighbors. In\nthis paper, by viewing SMOTE as sampling from the edges of a geometric\nneighborhood graph and borrowing tools from the topological data analysis, we\npropose a novel technique, Simplicial SMOTE, that samples from the simplices of\na geometric neighborhood simplicial complex. A new synthetic point is defined\nby the barycentric coordinates w.r.t. a simplex spanned by an arbitrary number\nof data points being sufficiently close rather than a pair. Such a replacement\nof the geometric data model results in better coverage of the underlying data\ndistribution compared to existing geometric sampling methods and allows the\ngeneration of synthetic points of the minority class closer to the majority\nclass on the decision boundary. We experimentally demonstrate that our\nSimplicial SMOTE outperforms several popular geometric sampling methods,\nincluding the original SMOTE. Moreover, we show that simplicial sampling can be\neasily integrated into existing SMOTE extensions. We generalize and evaluate\nsimplicial extensions of the classic Borderline SMOTE, Safe-level SMOTE, and\nADASYN algorithms, all of which outperform their graph-based counterparts.\n","authors":["Oleg Kachan","Andrey Savchenko","Gleb Gusev"],"pdf_url":"https://arxiv.org/pdf/2503.03418v1.pdf","comment":"Accepted at KDD 2025 (research track)"},{"id":"http://arxiv.org/abs/2412.14566v2","updated":"2025-03-05T11:38:00Z","published":"2024-12-19T06:35:54Z","title":"AIArena: A Blockchain-Based Decentralized AI Training Platform","summary":"  The rapid advancement of AI has underscored critical challenges in its\ndevelopment and implementation, largely due to centralized control by a few\nmajor corporations. This concentration of power intensifies biases within AI\nmodels, resulting from inadequate governance and oversight mechanisms.\nAdditionally, it limits public involvement and heightens concerns about the\nintegrity of model generation. Such monopolistic control over data and AI\noutputs threatens both innovation and fair data usage, as users inadvertently\ncontribute data that primarily benefits these corporations. In this work, we\npropose AIArena, a blockchain-based decentralized AI training platform designed\nto democratize AI development and alignment through on-chain incentive\nmechanisms. AIArena fosters an open and collaborative environment where\nparticipants can contribute models and computing resources. Its on-chain\nconsensus mechanism ensures fair rewards for participants based on their\ncontributions. We instantiate and implement AIArena on the public Base\nblockchain Sepolia testnet, and the evaluation results demonstrate the\nfeasibility of AIArena in real-world applications.\n","authors":["Zhipeng Wang","Rui Sun","Elizabeth Lui","Tuo Zhou","Yizhe Wen","Jiahao Sun"],"pdf_url":"https://arxiv.org/pdf/2412.14566v2.pdf","comment":"Camera ready version. Accepted by the ACM Web Conference (WWW), 2025"},{"id":"http://arxiv.org/abs/2408.09838v2","updated":"2025-03-05T11:27:17Z","published":"2024-08-19T09:33:31Z","title":"Mitigating the Stability-Plasticity Dilemma in Adaptive Train Scheduling\n  with Curriculum-Driven Continual DQN Expansion","summary":"  A continual learning agent builds on previous experiences to develop\nincreasingly complex behaviors by adapting to non-stationary and dynamic\nenvironments while preserving previously acquired knowledge. However, scaling\nthese systems presents significant challenges, particularly in balancing the\npreservation of previous policies with the adaptation of new ones to current\nenvironments. This balance, known as the stability-plasticity dilemma, is\nespecially pronounced in complex multi-agent domains such as the train\nscheduling problem, where environmental and agent behaviors are constantly\nchanging, and the search space is vast. In this work, we propose addressing\nthese challenges in the train scheduling problem using curriculum learning. We\ndesign a curriculum with adjacent skills that build on each other to improve\ngeneralization performance. Introducing a curriculum with distinct tasks\nintroduces non-stationarity, which we address by proposing a new algorithm:\nContinual Deep Q-Network (DQN) Expansion (CDE). Our approach dynamically\ngenerates and adjusts Q-function subspaces to handle environmental changes and\ntask requirements. CDE mitigates catastrophic forgetting through EWC while\nensuring high plasticity using adaptive rational activation functions.\nExperimental results demonstrate significant improvements in learning\nefficiency and adaptability compared to RL baselines and other adapted methods\nfor continual learning, highlighting the potential of our method in managing\nthe stability-plasticity dilemma in the adaptive train scheduling setting.\n","authors":["Achref Jaziri","Etienne Knzel","Visvanathan Ramesh"],"pdf_url":"https://arxiv.org/pdf/2408.09838v2.pdf","comment":"9 Pages, 2 Figures"},{"id":"http://arxiv.org/abs/2503.03401v1","updated":"2025-03-05T11:24:55Z","published":"2025-03-05T11:24:55Z","title":"Evolutionary Prediction Games","summary":"  When users decide whether to use a system based on the quality of predictions\nthey receive, learning has the capacity to shape the population of users it\nserves - for better or worse. This work aims to study the long-term\nimplications of this process through the lens of evolutionary game theory. We\nintroduce and study evolutionary prediction games, designed to capture the role\nof learning as a driver of natural selection between groups of users, and hence\na determinant of evolutionary outcomes. Our main theoretical results show that:\n(i) in settings with unlimited data and compute, learning tends to reinforce\nthe survival of the fittest, and (ii) in more realistic settings, opportunities\nfor coexistence emerge. We analyze these opportunities in terms of their\nstability and feasibility, present several mechanisms that can sustain their\nexistence, and empirically demonstrate our findings using real and synthetic\ndata.\n","authors":["Eden Saig","Nir Rosenfeld"],"pdf_url":"https://arxiv.org/pdf/2503.03401v1.pdf","comment":"Comments are welcome"},{"id":"http://arxiv.org/abs/2503.03399v1","updated":"2025-03-05T11:21:37Z","published":"2025-03-05T11:21:37Z","title":"Predicting Practically? Domain Generalization for Predictive Analytics\n  in Real-world Environments","summary":"  Predictive machine learning models are widely used in customer relationship\nmanagement (CRM) to forecast customer behaviors and support decision-making.\nHowever, the dynamic nature of customer behaviors often results in significant\ndistribution shifts between training data and serving data, leading to\nperformance degradation in predictive models. Domain generalization, which aims\nto train models that can generalize to unseen environments without prior\nknowledge of their distributions, has become a critical area of research. In\nthis work, we propose a novel domain generalization method tailored to handle\ncomplex distribution shifts, encompassing both covariate and concept shifts.\nOur method builds upon the Distributionally Robust Optimization framework,\noptimizing model performance over a set of hypothetical worst-case\ndistributions rather than relying solely on the training data. Through\nsimulation experiments, we demonstrate the working mechanism of the proposed\nmethod. We also conduct experiments on a real-world customer churn dataset, and\nvalidate its effectiveness in both temporal and spatial generalization\nsettings. Finally, we discuss the broader implications of our method for\nadvancing Information Systems (IS) design research, particularly in building\nrobust predictive models for dynamic managerial environments.\n","authors":["Hanyu Duan","Yi Yang","Ahmed Abbasi","Kar Yan Tam"],"pdf_url":"https://arxiv.org/pdf/2503.03399v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.12972v2","updated":"2025-03-05T11:18:41Z","published":"2024-11-20T01:54:52Z","title":"UniFlow: A Foundation Model for Unified Urban Spatio-Temporal Flow\n  Prediction","summary":"  Urban spatio-temporal flow prediction, encompassing traffic flows and crowd\nflows, is crucial for optimizing city infrastructure and managing traffic and\nemergency responses. Traditional approaches have relied on separate models\ntailored to either grid-based data, representing cities as uniform cells, or\ngraph-based data, modeling cities as networks of nodes and edges. In this\npaper, we build UniFlow, a foundational model for general urban flow prediction\nthat unifies both grid-based and graphbased data. We first design a multi-view\nspatio-temporal patching mechanism to standardize different data into a\nconsistent sequential format and then introduce a spatio-temporal transformer\narchitecture to capture complex correlations and dynamics. To leverage shared\nspatio-temporal patterns across different data types and facilitate effective\ncross-learning, we propose SpatioTemporal Memory Retrieval Augmentation\n(ST-MRA). By creating structured memory modules to store shared spatio-temporal\npatterns, ST-MRA enhances predictions through adaptive memory retrieval.\nExtensive experiments demonstrate that UniFlow outperforms existing models in\nboth grid-based and graph-based flow prediction, excelling particularly in\nscenarios with limited data availability, showcasing its superior performance\nand broad applicability. The datasets and code implementation have been\nreleased on https://github.com/YuanYuan98/UniFlow.\n","authors":["Yuan Yuan","Jingtao Ding","Chonghua Han","Depeng Jin","Yong Li"],"pdf_url":"https://arxiv.org/pdf/2411.12972v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.03391v1","updated":"2025-03-05T11:12:40Z","published":"2025-03-05T11:12:40Z","title":"Multi-Agent DRL for Queue-Aware Task Offloading in Hierarchical\n  MEC-Enabled Air-Ground Networks","summary":"  Mobile edge computing (MEC)-enabled air-ground networks are a key component\nof 6G, employing aerial base stations (ABSs) such as unmanned aerial vehicles\n(UAVs) and high-altitude platform stations (HAPS) to provide dynamic services\nto ground IoT devices (IoTDs). These IoTDs support real-time applications\n(e.g., multimedia and Metaverse services) that demand high computational\nresources and strict quality of service (QoS) guarantees in terms of latency\nand task queue management. Given their limited energy and processing\ncapabilities, IoTDs rely on UAVs and HAPS to offload tasks for distributed\nprocessing, forming a multi-tier MEC system. This paper tackles the overall\nenergy minimization problem in MEC-enabled air-ground integrated networks\n(MAGIN) by jointly optimizing UAV trajectories, computing resource allocation,\nand queue-aware task offloading decisions. The optimization is challenging due\nto the nonconvex, nonlinear nature of this hierarchical system, which renders\ntraditional methods ineffective. We reformulate the problem as a multi-agent\nMarkov decision process (MDP) with continuous action spaces and heterogeneous\nagents, and propose a novel variant of multi-agent proximal policy optimization\nwith a Beta distribution (MAPPO-BD) to solve it. Extensive simulations show\nthat MAPPO-BD outperforms baseline schemes, achieving superior energy savings\nand efficient resource management in MAGIN while meeting queue delay and edge\ncomputing constraints.\n","authors":["Muhammet Hevesli","Abegaz Mohammed Seid","Aiman Erbad","Mohamed Abdallah"],"pdf_url":"https://arxiv.org/pdf/2503.03391v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2502.19166v2","updated":"2025-03-05T11:09:06Z","published":"2025-02-26T14:19:49Z","title":"CodeIF: Benchmarking the Instruction-Following Capabilities of Large\n  Language Models for Code Generation","summary":"  With the rapid advancement of Large Language Models (LLMs), the demand for\nrobust instruction-following capabilities in code generation tasks has grown\nsignificantly. Code generation not only facilitates faster prototyping and\nautomated testing, but also augments developer efficiency through improved\nmaintainability and reusability of code. In this paper, we introduce CodeIF,\nthe first benchmark specifically designed to assess the abilities of LLMs to\nadhere to task-oriented instructions within diverse code generation scenarios.\nCodeIF encompasses a broad range of tasks, including function synthesis, error\ndebugging, algorithmic refactoring, and code explanation, thereby providing a\ncomprehensive suite to evaluate model performance across varying complexity\nlevels and programming domains. We conduct extensive experiments with LLMs,\nanalyzing their strengths and limitations in meeting the demands of these\ntasks. The experimental results offer valuable insights into how well current\nmodels align with human instructions, as well as the extent to which they can\ngenerate consistent, maintainable, and contextually relevant code. Our findings\nnot only underscore the critical role that instruction-following LLMs can play\nin modern software development, but also illuminate pathways for future\nresearch aimed at enhancing their adaptability, reliability, and overall\neffectiveness in automated code generation.\n","authors":["Kaiwen Yan","Hongcheng Guo","Xuanqing Shi","Jingyi Xu","Yaonan Gu","Zhoujun Li"],"pdf_url":"https://arxiv.org/pdf/2502.19166v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2206.09453v2","updated":"2025-03-05T11:04:58Z","published":"2022-06-19T17:13:58Z","title":"Bounding Evidence and Estimating Log-Likelihood in VAE","summary":"  Many crucial problems in deep learning and statistical inference are caused\nby a variational gap, i.e., a difference between model evidence\n(log-likelihood) and evidence lower bound (ELBO). In particular, in a classical\nVAE setting that involves training via an ELBO cost function, it is difficult\nto provide a robust comparison of the effects of training between models, since\nwe do not know a log-likelihood of data (but only its lower bound). In this\npaper, to deal with this problem, we introduce a general and effective upper\nbound, which allows us to efficiently approximate the evidence of data. We\nprovide extensive theoretical and experimental studies of our approach,\nincluding its comparison to the other state-of-the-art upper bounds, as well as\nits application as a tool for the evaluation of models that were trained on\nvarious lower bounds.\n","authors":["ukasz Struski","Marcin Mazur","Pawe Batorski","Przemysaw Spurek","Jacek Tabor"],"pdf_url":"https://arxiv.org/pdf/2206.09453v2.pdf","comment":"Paper accepted for AISTATS 2023"},{"id":"http://arxiv.org/abs/2503.03384v1","updated":"2025-03-05T11:02:29Z","published":"2025-03-05T11:02:29Z","title":"GNNMerge: Merging of GNN Models Without Accessing Training Data","summary":"  Model merging has gained prominence in machine learning as a method to\nintegrate multiple trained models into a single model without accessing the\noriginal training data. While existing approaches have demonstrated success in\ndomains such as computer vision and NLP, their application to Graph Neural\nNetworks (GNNs) remains unexplored. These methods often rely on the assumption\nof shared initialization, which is seldom applicable to GNNs. In this work, we\nundertake the first benchmarking study of model merging algorithms for GNNs,\nrevealing their limited effectiveness in this context. To address these\nchallenges, we propose GNNMerge, which utilizes a task-agnostic node embedding\nalignment strategy to merge GNNs. Furthermore, we establish that under a mild\nrelaxation, the proposed optimization objective admits direct analytical\nsolutions for widely used GNN architectures, significantly enhancing its\ncomputational efficiency. Empirical evaluations across diverse datasets, tasks,\nand architectures establish GNNMerge to be up to 24% more accurate than\nexisting methods while delivering over 2 orders of magnitude speed-up compared\nto training from scratch.\n","authors":["Vipul Garg","Ishita Thakre","Sayan Ranu"],"pdf_url":"https://arxiv.org/pdf/2503.03384v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.03382v1","updated":"2025-03-05T10:57:34Z","published":"2025-03-05T10:57:34Z","title":"Paths and Ambient Spaces in Neural Loss Landscapes","summary":"  Understanding the structure of neural network loss surfaces, particularly the\nemergence of low-loss tunnels, is critical for advancing neural network theory\nand practice. In this paper, we propose a novel approach to directly embed loss\ntunnels into the loss landscape of neural networks. Exploring the properties of\nthese loss tunnels offers new insights into their length and structure and\nsheds light on some common misconceptions. We then apply our approach to\nBayesian neural networks, where we improve subspace inference by identifying\npitfalls and proposing a more natural prior that better guides the sampling\nprocedure.\n","authors":["Daniel Dold","Julius Kobialka","Nicolai Palm","Emanuel Sommer","David Rgamer","Oliver Drr"],"pdf_url":"https://arxiv.org/pdf/2503.03382v1.pdf","comment":"9 pages, Accepted at AISTATS 2025"},{"id":"http://arxiv.org/abs/2411.15692v2","updated":"2025-03-05T10:54:30Z","published":"2024-11-24T03:06:59Z","title":"DrugAgent: Automating AI-aided Drug Discovery Programming through LLM\n  Multi-Agent Collaboration","summary":"  Recent progress in Large Language Models (LLMs) has drawn attention to their\npotential for accelerating drug discovery. However, a central problem remains:\ntranslating theoretical ideas into robust implementations in the highly\nspecialized context of pharmaceutical research. This limitation prevents\npractitioners from making full use of the latest AI developments in drug\ndiscovery. To address this challenge, we introduce DrugAgent, a multi-agent\nframework that automates machine learning (ML) programming for drug discovery\ntasks. DrugAgent employs an LLM Planner that formulates high-level ideas and an\nLLM Instructor that identifies and integrates domain knowledge when\nimplementing those ideas. We present case studies on three representative drug\ndiscovery tasks. Our results show that DrugAgent consistently outperforms\nleading baselines, including a relative improvement of 4.92% in ROC-AUC\ncompared to ReAct for drug-target interaction (DTI). DrugAgent is publicly\navailable at https://anonymous.4open.science/r/drugagent-5C42/.\n","authors":["Sizhe Liu","Yizhou Lu","Siyu Chen","Xiyang Hu","Jieyu Zhao","Yingzhou Lu","Yue Zhao"],"pdf_url":"https://arxiv.org/pdf/2411.15692v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2502.15425v4","updated":"2025-03-05T10:48:42Z","published":"2025-02-21T12:52:16Z","title":"TAG: A Decentralized Framework for Multi-Agent Hierarchical\n  Reinforcement Learning","summary":"  Hierarchical organization is fundamental to biological systems and human\nsocieties, yet artificial intelligence systems often rely on monolithic\narchitectures that limit adaptability and scalability. Current hierarchical\nreinforcement learning (HRL) approaches typically restrict hierarchies to two\nlevels or require centralized training, which limits their practical\napplicability. We introduce TAME Agent Framework (TAG), a framework for\nconstructing fully decentralized hierarchical multi-agent systems. TAG enables\nhierarchies of arbitrary depth through a novel LevelEnv concept, which\nabstracts each hierarchy level as the environment for the agents above it. This\napproach standardizes information flow between levels while preserving loose\ncoupling, allowing for seamless integration of diverse agent types. We\ndemonstrate the effectiveness of TAG by implementing hierarchical architectures\nthat combine different RL agents across multiple levels, achieving improved\nperformance over classical multi-agent RL baselines on standard benchmarks. Our\nresults show that decentralized hierarchical organization enhances both\nlearning speed and final performance, positioning TAG as a promising direction\nfor scalable multi-agent systems.\n","authors":["Giuseppe Paolo","Abdelhakim Benechehab","Hamza Cherkaoui","Albert Thomas","Balzs Kgl"],"pdf_url":"https://arxiv.org/pdf/2502.15425v4.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.03565v2","updated":"2025-03-05T10:47:17Z","published":"2024-10-04T16:15:31Z","title":"Exploration Implies Data Augmentation: Reachability and Generalisation\n  in Contextual MDPs","summary":"  In the zero-shot policy transfer (ZSPT) setting for contextual Markov\ndecision processes (MDP), agents train on a fixed set of contexts and must\ngeneralise to new ones. Recent work has argued and demonstrated that increased\nexploration can improve this generalisation, by training on more states in the\ntraining contexts. In this paper, we demonstrate that training on more states\ncan indeed improve generalisation, but can come at a cost of reducing the\naccuracy of the learned value function which should not benefit generalisation.\nWe introduce reachability in the ZSPT setting to define which states/contexts\nrequire generalisation and explain why exploration can improve it. We\nhypothesise and demonstrate that using exploration to increase the agent's\ncoverage while also increasing the accuracy improves generalisation even more.\nInspired by this, we propose a method Explore-Go that implements an exploration\nphase at the beginning of each episode, which can be combined with existing on-\nand off-policy RL algorithms and significantly improves generalisation even in\npartially observable MDPs. We demonstrate the effectiveness of Explore-Go when\ncombined with several popular algorithms and show an increase in generalisation\nperformance across several environments. With this, we hope to provide\npractitioners with a simple modification that can improve the generalisation of\ntheir agents.\n","authors":["Max Weltevrede","Caroline Horsch","Matthijs T. J. Spaan","Wendelin Bhmer"],"pdf_url":"https://arxiv.org/pdf/2410.03565v2.pdf","comment":"arXiv admin note: text overlap with arXiv:2406.08069"},{"id":"http://arxiv.org/abs/2503.03372v1","updated":"2025-03-05T10:47:06Z","published":"2025-03-05T10:47:06Z","title":"A Novel Multi-Criteria Local Latin Hypercube Refinement System for\n  Commutation Angle Improvement in IPMSMs","summary":"  The commutation angle is defined as the angle between the fundamental of the\nmotor phase current and the fundamental of the back-EMF. It can be utilised to\nprovide a compensating effect in IPMSMs. This is due to the reluctance torque\ncomponent being dependent on the commutation angle of the phase current even\nbefore entering the extended speed range. A real-time maximum torque per\ncurrent and voltage strategy is demonstrated to find the trajectory and optimum\ncommutation angles, gamma, where the level of accuracy depends on the\napplication and available computational speed. A magnet volume reduction using\na novel multi-criteria local Latin hypercube refinement (MLHR) sampling system\nis also presented to improve the optimisation process. The proposed new\ntechnique minimises the magnet mass to motor torque density whilst maintaining\na similar phase current level. A mapping of gamma allows the determination of\nthe optimum angles, as shown in this paper. The 3rd generation Toyota Prius\nIPMSM is considered as the reference motor, where the rotor configuration is\naltered to allow for an individual assessment.\n","authors":["Pedram Asef","Mouloud Denai","Johannes J. H. Paulides","Bruno Ricardo Marques","Andrew Lapthorn"],"pdf_url":"https://arxiv.org/pdf/2503.03372v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2409.02772v2","updated":"2025-03-05T10:42:53Z","published":"2024-09-04T14:51:36Z","title":"Unifying Causal Representation Learning with the Invariance Principle","summary":"  Causal representation learning (CRL) aims at recovering latent causal\nvariables from high-dimensional observations to solve causal downstream tasks,\nsuch as predicting the effect of new interventions or more robust\nclassification. A plethora of methods have been developed, each tackling\ncarefully crafted problem settings that lead to different types of\nidentifiability. These different settings are widely assumed to be important\nbecause they are often linked to different rungs of Pearl's causal hierarchy,\neven though this correspondence is not always exact. This work shows that\ninstead of strictly conforming to this hierarchical mapping, many causal\nrepresentation learning approaches methodologically align their representations\nwith inherent data symmetries. Identification of causal variables is guided by\ninvariance principles that are not necessarily causal. This result allows us to\nunify many existing approaches in a single method that can mix and match\ndifferent assumptions, including non-causal ones, based on the invariance\nrelevant to the problem at hand. It also significantly benefits applicability,\nwhich we demonstrate by improving treatment effect estimation on real-world\nhigh-dimensional ecological data. Overall, this paper clarifies the role of\ncausal assumptions in the discovery of causal variables and shifts the focus to\npreserving data symmetries.\n","authors":["Dingling Yao","Dario Rancati","Riccardo Cadei","Marco Fumero","Francesco Locatello"],"pdf_url":"https://arxiv.org/pdf/2409.02772v2.pdf","comment":"ICLR2025 Camera ready"},{"id":"http://arxiv.org/abs/2503.03360v1","updated":"2025-03-05T10:40:09Z","published":"2025-03-05T10:40:09Z","title":"Transformers for molecular property prediction: Domain adaptation\n  efficiently improves performance","summary":"  Most of the current transformer-based chemical language models are\npre-trained on millions to billions of molecules. However, the improvement from\nsuch scaling in dataset size is not confidently linked to improved molecular\nproperty prediction. The aim of this study is to investigate and overcome some\nof the limitations of transformer models in predicting molecular properties.\nSpecifically, we examine the impact of pre-training dataset size and diversity\non the performance of transformer models and investigate the use of domain\nadaptation as a technique for improving model performance. First, our findings\nindicate that increasing pretraining dataset size beyond 400K molecules from\nthe GuacaMol dataset does not result in a significant improvement on four ADME\nendpoints, namely, solubility, permeability, microsomal stability, and plasma\nprotein binding. Second, our results demonstrate that using domain adaptation\nby further training the transformer model on a small set of domain-relevant\nmolecules, i.e., a few hundred to a few thousand, using multi-task regression\nof physicochemical properties was sufficient to significantly improve\nperformance for three out of the four investigated ADME endpoints (P-value <\n0.001). Finally, we observe that a model pre-trained on 400K molecules and\ndomain adopted on a few hundred/thousand molecules performs similarly (P-value\n> 0.05) to more complicated transformer models like MolBERT(pre-trained on 1.3M\nmolecules) and MolFormer (pre-trained on 100M molecules). A comparison to a\nrandom forest model trained on basic physicochemical properties showed similar\nperformance to the examined transformer models. We believe that current\ntransformer models can be improved through further systematic analysis of\npre-training and downstream data, pre-training objectives, and scaling laws,\nultimately leading to better and more helpful models.\n","authors":["Afnan Sultan","Max Rausch-Dupont","Shahrukh Khan","Olga Kalinina","Andrea Volkamer","Dietrich Klakow"],"pdf_url":"https://arxiv.org/pdf/2503.03360v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.03355v1","updated":"2025-03-05T10:37:51Z","published":"2025-03-05T10:37:51Z","title":"Video Super-Resolution: All You Need is a Video Diffusion Model","summary":"  We present a generic video super-resolution algorithm in this paper, based on\nthe Diffusion Posterior Sampling framework with an unconditional video\ngeneration model in latent space. The video generation model, a diffusion\ntransformer, functions as a space-time model. We argue that a powerful model,\nwhich learns the physics of the real world, can easily handle various kinds of\nmotion patterns as prior knowledge, thus eliminating the need for explicit\nestimation of optical flows or motion parameters for pixel alignment.\nFurthermore, a single instance of the proposed video diffusion transformer\nmodel can adapt to different sampling conditions without re-training. Due to\nlimited computational resources and training data, our experiments provide\nempirical evidence of the algorithm's strong super-resolution capabilities\nusing synthetic data.\n","authors":["Zhihao Zhan","Wang Pang","Xiang Zhu","Yechao Bai"],"pdf_url":"https://arxiv.org/pdf/2503.03355v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2405.18222v2","updated":"2025-03-05T10:17:25Z","published":"2024-05-28T14:30:07Z","title":"From Learning to Optimize to Learning Optimization Algorithms","summary":"  Towards designing learned optimization algorithms that are usable beyond\ntheir training setting, we identify key principles that classical algorithms\nobey, but have up to now, not been used for Learning to Optimize (L2O).\nFollowing these principles, we provide a general design pipeline, taking into\naccount data, architecture and learning strategy, and thereby enabling a\nsynergy between classical optimization and L2O, resulting in a philosophy of\nLearning Optimization Algorithms. As a consequence our learned algorithms\nperform well far beyond problems from the training distribution. We demonstrate\nthe success of these novel principles by designing a new learning-enhanced BFGS\nalgorithm and provide numerical experiments evidencing its adaptation to many\nsettings at test time.\n","authors":["Camille Castera","Peter Ochs"],"pdf_url":"https://arxiv.org/pdf/2405.18222v2.pdf","comment":"To appear at AISTATS 2025"},{"id":"http://arxiv.org/abs/2405.19036v2","updated":"2025-03-05T10:15:19Z","published":"2024-05-29T12:23:48Z","title":"State Space Models are Provably Comparable to Transformers in Dynamic\n  Token Selection","summary":"  Deep neural networks based on state space models (SSMs) are attracting\nsignificant attention in sequence modeling since their computational cost is\nmuch smaller than that of Transformers. While the capabilities of SSMs have\nbeen demonstrated through experiments in various tasks, theoretical\nunderstanding of SSMs is still limited. In particular, most theoretical studies\ndiscuss the capabilities of SSM layers without nonlinear layers, and there is a\nlack of discussion on their combination with nonlinear layers. In this paper,\nwe explore the capabilities of SSMs combined with fully connected neural\nnetworks, and show that they are comparable to Transformers in extracting the\nessential tokens depending on the input. As concrete examples, we consider two\nsynthetic tasks, which are challenging for a single SSM layer, and demonstrate\nthat SSMs combined with nonlinear layers can efficiently solve these tasks.\nFurthermore, we study the nonparametric regression task, and prove that the\nability of SSMs is equivalent to that of Transformers in estimating functions\nbelonging to a certain class.\n","authors":["Naoki Nishikawa","Taiji Suzuki"],"pdf_url":"https://arxiv.org/pdf/2405.19036v2.pdf","comment":"43 pages, 7 figures"},{"id":"http://arxiv.org/abs/2407.05704v2","updated":"2025-03-05T10:07:22Z","published":"2024-07-08T08:06:45Z","title":"Narrowing the Gap between Adversarial and Stochastic MDPs via Policy\n  Optimization","summary":"  We consider the problem of learning in adversarial Markov decision processes\n[MDPs] with an oblivious adversary in a full-information setting. The agent\ninteracts with an environment during $T$ episodes, each of which consists of\n$H$ stages, and each episode is evaluated with respect to a reward function\nthat will be revealed only at the end of the episode. We propose an algorithm,\ncalled APO-MVP, that achieves a regret bound of order\n$\\tilde{\\mathcal{O}}(\\mathrm{poly}(H)\\sqrt{SAT})$, where $S$ and $A$ are sizes\nof the state and action spaces, respectively. This result improves upon the\nbest-known regret bound by a factor of $\\sqrt{S}$, bridging the gap between\nadversarial and stochastic MDPs, and matching the minimax lower bound\n$\\Omega(\\sqrt{H^3SAT})$ as far as the dependencies in $S,A,T$ are concerned.\nThe proposed algorithm and analysis completely avoid the typical tool given by\noccupancy measures; instead, it performs policy optimization based only on\ndynamic programming and on a black-box online linear optimization strategy run\nover estimated advantage functions, making it easy to implement. The analysis\nleverages two recent techniques: policy optimization based on online linear\noptimization strategies (Jonckheere et al., 2023) and a refined martingale\nanalysis of the impact on values of estimating transitions kernels (Zhang et\nal., 2023).\n","authors":["Daniil Tiapkin","Evgenii Chzhen","Gilles Stoltz"],"pdf_url":"https://arxiv.org/pdf/2407.05704v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.03331v1","updated":"2025-03-05T10:03:59Z","published":"2025-03-05T10:03:59Z","title":"Leap: Inductive Link Prediction via Learnable TopologyAugmentation","summary":"  Link prediction is a crucial task in many downstream applications of graph\nmachine learning. To this end, Graph Neural Network (GNN) is a widely used\ntechnique for link prediction, mainly in transductive settings, where the goal\nis to predict missing links between existing nodes. However, many real-life\napplications require an inductive setting that accommodates for new nodes,\ncoming into an existing graph. Thus, recently inductive link prediction has\nattracted considerable attention, and a multi-layer perceptron (MLP) is the\npopular choice of most studies to learn node representations. However, these\napproaches have limited expressivity and do not fully capture the graph's\nstructural signal. Therefore, in this work we propose LEAP, an inductive link\nprediction method based on LEArnable toPology augmentation. Unlike previous\nmethods, LEAP models the inductive bias from both the structure and node\nfeatures, and hence is more expressive. To the best of our knowledge, this is\nthe first attempt to provide structural contexts for new nodes via learnable\naugmentation in inductive settings. Extensive experiments on seven real-world\nhomogeneous and heterogeneous graphs demonstrates that LEAP significantly\nsurpasses SOTA methods. The improvements are up to 22\\% and 17\\% in terms of\nAUC and average precision, respectively. The code and datasets are available on\nGitHub (https://github.com/AhmedESamy/LEAP/)\n","authors":["Ahmed E. Samy","Zekarias T. Kefato","Sarunas Girdzijauskas"],"pdf_url":"https://arxiv.org/pdf/2503.03331v1.pdf","comment":"published in Machine Learning, Optimization, and Data Science,\n  Springer Nature Switzerland"},{"id":"http://arxiv.org/abs/2412.00497v2","updated":"2025-03-05T09:59:23Z","published":"2024-11-30T14:43:00Z","title":"Distributed Differentially Private Data Analytics via Secure Sketching","summary":"  We introduce the linear-transformation model, a distributed model of\ndifferentially private data analysis. Clients have access to a trusted platform\ncapable of applying a public matrix to their inputs. Such computations can be\nsecurely distributed across multiple servers using simple and efficient secure\nmultiparty computation techniques.\n  The linear-transformation model serves as an intermediate model between the\nhighly expressive central model and the minimal local model. In the central\nmodel, clients have access to a trusted platform capable of applying any\nfunction to their inputs. However, this expressiveness comes at a cost, as it\nis often prohibitively expensive to distribute such computations, leading to\nthe central model typically being implemented by a single trusted server. In\ncontrast, the local model assumes no trusted platform, which forces clients to\nadd significant noise to their data. The linear-transformation model avoids the\nsingle point of failure for privacy present in the central model, while also\nmitigating the high noise required in the local model.\n  We demonstrate that linear transformations are very useful for differential\nprivacy, allowing for the computation of linear sketches of input data. These\nsketches largely preserve utility for tasks such as private low-rank\napproximation and private ridge regression, while introducing only minimal\nerror, critically independent of the number of clients.\n","authors":["Jakob Burkhardt","Hannah Keller","Claudio Orlandi","Chris Schwiegelshohn"],"pdf_url":"https://arxiv.org/pdf/2412.00497v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.14425v3","updated":"2025-03-05T09:54:52Z","published":"2024-03-21T14:28:43Z","title":"Task-optimal data-driven surrogate models for eNMPC via differentiable\n  simulation and optimization","summary":"  Mechanistic dynamic process models may be too computationally expensive to be\nusable as part of a real-time capable predictive controller. We present a\nmethod for end-to-end learning of Koopman surrogate models for optimal\nperformance in a specific control task. In contrast to previous contributions\nthat employ standard reinforcement learning (RL) algorithms, we use a training\nalgorithm that exploits the differentiability of environments based on\nmechanistic simulation models to aid the policy optimization. We evaluate the\nperformance of our method by comparing it to that of other training algorithms\non an existing economic nonlinear model predictive control (eNMPC) case study\nof a continuous stirred-tank reactor (CSTR) model. Compared to the benchmark\nmethods, our method produces similar economic performance while eliminating\nconstraint violations. Thus, for this case study, our method outperforms the\nothers and offers a promising path toward more performant controllers that\nemploy dynamic surrogate models.\n","authors":["Daniel Mayfrank","Na Young Ahn","Alexander Mitsos","Manuel Dahmen"],"pdf_url":"https://arxiv.org/pdf/2403.14425v3.pdf","comment":"8 pages, 4 figures, 1 table"},{"id":"http://arxiv.org/abs/2502.07780v3","updated":"2025-03-05T09:50:16Z","published":"2025-02-11T18:59:35Z","title":"DarwinLM: Evolutionary Structured Pruning of Large Language Models","summary":"  Large Language Models (LLMs) have achieved significant success across various\nNLP tasks. However, their massive computational costs limit their widespread\nuse, particularly in real-time applications. Structured pruning offers an\neffective solution by compressing models and directly providing end-to-end\nspeed improvements, regardless of the hardware environment. Meanwhile,\ndifferent components of the model exhibit varying sensitivities towards\npruning, calling for non-uniform model compression. However, a pruning method\nshould not only identify a capable substructure, but also account for\npost-compression training. To this end, we propose DarwinLM, a method for\ntraining-aware structured pruning. DarwinLM builds upon an evolutionary search\nprocess, generating multiple offspring models in each generation through\nmutation, and selecting the fittest for survival. To assess the effect of\npost-training, we incorporate a lightweight, multistep training process within\nthe offspring population, progressively increasing the number of tokens and\neliminating poorly performing models in each selection stage. We validate our\nmethod through extensive experiments on Llama-2-7B, Llama-3.1-8B and\nQwen-2.5-14B-Instruct, achieving state-of-the-art performance for structured\npruning. For instance, DarwinLM surpasses ShearedLlama while requiring 5x less\ntraining data during post-compression training. Code is at:\nhttps://github.com/IST-DASLab/DarwinLM\n","authors":["Shengkun Tang","Oliver Sieberling","Eldar Kurtic","Zhiqiang Shen","Dan Alistarh"],"pdf_url":"https://arxiv.org/pdf/2502.07780v3.pdf","comment":"Code: https://github.com/IST-DASLab/DarwinLM"},{"id":"http://arxiv.org/abs/2503.03313v1","updated":"2025-03-05T09:45:22Z","published":"2025-03-05T09:45:22Z","title":"LLM as GNN: Graph Vocabulary Learning for Text-Attributed Graph\n  Foundation Models","summary":"  Text-Attributed Graphs (TAGs), where each node is associated with text\ndescriptions, are ubiquitous in real-world scenarios. They typically exhibit\ndistinctive structure and domain-specific knowledge, motivating the development\nof a Graph Foundation Model (GFM) that generalizes across diverse graphs and\ntasks. Despite large efforts to integrate Large Language Models (LLMs) and\nGraph Neural Networks (GNNs) for TAGs, existing approaches suffer from\ndecoupled architectures with two-stage alignment, limiting their synergistic\npotential. Even worse, existing methods assign out-of-vocabulary (OOV) tokens\nto graph nodes, leading to graph-specific semantics, token explosion, and\nincompatibility with task-oriented prompt templates, which hinders cross-graph\nand cross-task transferability. To address these challenges, we propose\nPromptGFM, a versatile GFM for TAGs grounded in graph vocabulary learning.\nPromptGFM comprises two key components: (1) Graph Understanding Module, which\nexplicitly prompts LLMs to replicate the finest GNN workflow within the text\nspace, facilitating seamless GNN-LLM integration and elegant graph-text\nalignment; (2) Graph Inference Module, which establishes a language-based graph\nvocabulary ensuring expressiveness, transferability, and scalability, enabling\nreadable instructions for LLM fine-tuning. Extensive experiments demonstrate\nour superiority and transferability across diverse graphs and tasks. The code\nis available at this: https://github.com/agiresearch/PromptGFM.\n","authors":["Xi Zhu","Haochen Xue","Ziwei Zhao","Wujiang Xu","Jingyuan Huang","Minghao Guo","Qifan Wang","Kaixiong Zhou","Yongfeng Zhang"],"pdf_url":"https://arxiv.org/pdf/2503.03313v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.03302v1","updated":"2025-03-05T09:36:57Z","published":"2025-03-05T09:36:57Z","title":"Differential Machine Learning for Time Series Prediction","summary":"  Accurate time series prediction is challenging due to the inherent\nnonlinearity and sensitivity to initial conditions. We propose a novel approach\nthat enhances neural network predictions through differential learning, which\ninvolves training models on both the original time series and its differential\nseries. Specifically, we develop a differential long short-term memory\n(Diff-LSTM) network that uses a shared LSTM cell to simultaneously process both\ndata streams, effectively capturing intrinsic patterns and temporal dynamics.\nEvaluated on the Mackey-Glass, Lorenz, and R\\\"ossler chaotic time series, as\nwell as a real-world financial dataset from ACI Worldwide Inc., our results\ndemonstrate that the Diff- LSTM network outperforms prevalent models such as\nrecurrent neural networks, convolutional neural networks, and bidirectional and\nencoder-decoder LSTM networks in both short-term and long-term predictions.\nThis framework offers a promising solution for enhancing time series\nprediction, even when comprehensive knowledge of the underlying dynamics of the\ntime series is not fully available.\n","authors":["Akash Yadav","Eulalia Nualart"],"pdf_url":"https://arxiv.org/pdf/2503.03302v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2210.09126v3","updated":"2025-03-05T09:30:22Z","published":"2022-10-17T14:19:52Z","title":"Verifiable and Provably Secure Machine Unlearning","summary":"  Machine unlearning aims to remove points from the training dataset of a\nmachine learning model after training: e.g., when a user requests their data to\nbe deleted. While many unlearning methods have been proposed, none of them\nenable users to audit the procedure. Furthermore, recent work shows a user is\nunable to verify whether their data was unlearnt from an inspection of the\nmodel parameter alone. Rather than reasoning about parameters, we propose to\nview verifiable unlearning as a security problem. To this end, we present the\nfirst cryptographic definition of verifiable unlearning to formally capture the\nguarantees of an unlearning system. In this framework, the server first\ncomputes a proof that the model was trained on a dataset D. Given a user's data\npoint d requested to be deleted, the server updates the model using an\nunlearning algorithm. It then provides a proof of the correct execution of\nunlearning and that d is not part of D', where D' is the new training dataset\n(i.e., d has been removed). Our framework is generally applicable to different\nunlearning techniques that we abstract as admissible functions. We instantiate\na protocol in the framework, based on cryptographic assumptions, using SNARKs\nand hash chains. Finally, we implement the protocol for three different\nunlearning techniques and validate its feasibility for linear regression,\nlogistic regression, and neural networks.\n","authors":["Thorsten Eisenhofer","Doreen Riepel","Varun Chandrasekaran","Esha Ghosh","Olga Ohrimenko","Nicolas Papernot"],"pdf_url":"https://arxiv.org/pdf/2210.09126v3.pdf","comment":"Accepted at IEEE SaTML2025"},{"id":"http://arxiv.org/abs/2501.18945v2","updated":"2025-03-05T09:13:02Z","published":"2025-01-31T08:08:32Z","title":"Solving Inverse Problem for Multi-armed Bandits via Convex Optimization","summary":"  We consider the inverse problem of multi-armed bandits (IMAB) that are widely\nused in neuroscience and psychology research for behavior modelling. We first\nshow that the IMAB problem is not convex in general, but can be relaxed to a\nconvex problem via variable transformation. Based on this result, we propose a\ntwo-step sequential heuristic for (approximately) solving the IMAB problem. We\ndiscuss a condition where our method provides global solution to the IMAB\nproblem with certificate, as well as approximations to further save computing\ntime. Numerical experiments indicate that our heuristic method is more robust\nthan directly solving the IMAB problem via repeated local optimization, and can\nachieve the performance of Monte Carlo methods within a significantly decreased\nrunning time. We provide the implementation of our method based on CVXPY, which\nallows straightforward application by users not well versed in convex\noptimization.\n","authors":["Hao Zhu","Joschka Boedecker"],"pdf_url":"https://arxiv.org/pdf/2501.18945v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.03285v1","updated":"2025-03-05T09:12:16Z","published":"2025-03-05T09:12:16Z","title":"Enhancing Vietnamese VQA through Curriculum Learning on Raw and\n  Augmented Text Representations","summary":"  Visual Question Answering (VQA) is a multimodal task requiring reasoning\nacross textual and visual inputs, which becomes particularly challenging in\nlow-resource languages like Vietnamese due to linguistic variability and the\nlack of high-quality datasets. Traditional methods often rely heavily on\nextensive annotated datasets, computationally expensive pipelines, and large\npre-trained models, specifically in the domain of Vietnamese VQA, limiting\ntheir applicability in such scenarios. To address these limitations, we propose\na training framework that combines a paraphrase-based feature augmentation\nmodule with a dynamic curriculum learning strategy. Explicitly, augmented\nsamples are considered \"easy\" while raw samples are regarded as \"hard\". The\nframework then utilizes a mechanism that dynamically adjusts the ratio of easy\nto hard samples during training, progressively modifying the same dataset to\nincrease its difficulty level. By enabling gradual adaptation to task\ncomplexity, this approach helps the Vietnamese VQA model generalize well, thus\nimproving overall performance. Experimental results show consistent\nimprovements on the OpenViVQA dataset and mixed outcomes on the ViVQA dataset,\nhighlighting both the potential and challenges of our approach in advancing VQA\nfor Vietnamese language.\n","authors":["Khoi Anh Nguyen","Linh Yen Vu","Thang Dinh Duong","Thuan Nguyen Duong","Huy Thanh Nguyen","Vinh Quang Dinh"],"pdf_url":"https://arxiv.org/pdf/2503.03285v1.pdf","comment":"10 pages, 3 figures, AAAI-25 Workshop on Document Understanding and\n  Intelligence"},{"id":"http://arxiv.org/abs/2503.03283v1","updated":"2025-03-05T09:09:01Z","published":"2025-03-05T09:09:01Z","title":"Exploring specialization and sensitivity of convolutional neural\n  networks in the context of simultaneous image augmentations","summary":"  Drawing parallels with the way biological networks are studied, we adapt the\ntreatment--control paradigm to explainable artificial intelligence research and\nenrich it through multi-parametric input alterations. In this study, we propose\na framework for investigating the internal inference impacted by input data\naugmentations. The internal changes in network operation are reflected in\nactivation changes measured by variance, which can be decomposed into\ncomponents related to each augmentation, employing Sobol indices and Shapley\nvalues. These quantities enable one to visualize sensitivity to different\nvariables and use them for guided masking of activations. In addition, we\nintroduce a way of single-class sensitivity analysis where the candidates are\nfiltered according to their matching to prediction bias generated by targeted\ndamaging of the activations. Relying on the observed parallels, we assume that\nthe developed framework can potentially be transferred to studying biological\nneural networks in complex environments.\n","authors":["Pavel Kharyuk","Sergey Matveev","Ivan Oseledets"],"pdf_url":"https://arxiv.org/pdf/2503.03283v1.pdf","comment":"26 pages; main text: 5 figures, 4 tables; appendix: 4 sections, 3\n  tables; supplementary: 7 files (figures S1-S6: packed as 7z archive, S7:\n  single pdf file)"},{"id":"http://arxiv.org/abs/2410.17967v2","updated":"2025-03-05T09:05:23Z","published":"2024-10-23T15:34:11Z","title":"POMDP-Driven Cognitive Massive MIMO Radar: Joint Target\n  Detection-Tracking In Unknown Disturbances","summary":"  The joint detection and tracking of a moving target embedded in an unknown\ndisturbance represents a key feature that motivates the development of the\ncognitive radar paradigm. Building upon recent advancements in robust target\ndetection with multiple-input multiple-output (MIMO) radars, this work explores\nthe application of a Partially Observable Markov Decision Process (POMDP)\nframework to enhance the tracking and detection tasks in a statistically\nunknown environment. In the POMDP setup, the radar system is considered as an\nintelligent agent that continuously senses the surrounding environment,\noptimizing its actions to maximize the probability of detection $(P_D)$ and\nimprove the target position and velocity estimation, all this while keeping a\nconstant probability of false alarm $(P_{FA})$. The proposed approach employs\nan online algorithm that does not require any apriori knowledge of the noise\nstatistics, and it relies on a much more general observation model than the\ntraditional range-azimuth-elevation model employed by conventional tracking\nalgorithms. Simulation results clearly show substantial performance improvement\nof the POMDP-based algorithm compared to the State-Action-Reward-State-Action\n(SARSA)-based one that has been recently investigated in the context of massive\nMIMO (MMIMO) radar systems.\n","authors":["Imad Bouhou","Stefano Fortunati","Leila Gharsalli","Alexandre Renaux"],"pdf_url":"https://arxiv.org/pdf/2410.17967v2.pdf","comment":"The paper has been submitted to ieee Transactions on radar systems"},{"id":"http://arxiv.org/abs/2503.03276v1","updated":"2025-03-05T08:59:06Z","published":"2025-03-05T08:59:06Z","title":"TrafficKAN-GCN: Graph Convolutional-based Kolmogorov-Arnold Network for\n  Traffic Flow Optimization","summary":"  Urban traffic optimization is critical for improving transportation\nefficiency and alleviating congestion, particularly in large-scale dynamic\nnetworks. Traditional methods, such as Dijkstra's and Floyd's algorithms,\nprovide effective solutions in static settings, but they struggle with the\nspatial-temporal complexity of real-world traffic flows. In this work, we\npropose TrafficKAN-GCN, a hybrid deep learning framework combining\nKolmogorov-Arnold Networks (KAN) with Graph Convolutional Networks (GCN),\ndesigned to enhance urban traffic flow optimization. By integrating KAN's\nadaptive nonlinear function approximation with GCN's spatial graph learning\ncapabilities, TrafficKAN-GCN captures both complex traffic patterns and\ntopological dependencies. We evaluate the proposed framework using real-world\ntraffic data from the Baltimore Metropolitan area. Compared with baseline\nmodels such as MLP-GCN, standard GCN, and Transformer-based approaches,\nTrafficKAN-GCN achieves competitive prediction accuracy while demonstrating\nimproved robustness in handling noisy and irregular traffic data. Our\nexperiments further highlight the framework's ability to redistribute traffic\nflow, mitigate congestion, and adapt to disruptive events, such as the Francis\nScott Key Bridge collapse. This study contributes to the growing body of work\non hybrid graph learning for intelligent transportation systems, highlighting\nthe potential of combining KAN and GCN for real-time traffic optimization.\nFuture work will focus on reducing computational overhead and integrating\nTransformer-based temporal modeling for enhanced long-term traffic prediction.\nThe proposed TrafficKAN-GCN framework offers a promising direction for\ndata-driven urban mobility management, balancing predictive accuracy,\nrobustness, and computational efficiency.\n","authors":["Jiayi Zhang","Yiming Zhang","Yuan Zheng","Yuchen Wang","Jinjiang You","Yuchen Xu","Wenxing Jiang","Soumyabrata Dev"],"pdf_url":"https://arxiv.org/pdf/2503.03276v1.pdf","comment":"21 pages, 14 figures"},{"id":"http://arxiv.org/abs/2503.03274v1","updated":"2025-03-05T08:56:26Z","published":"2025-03-05T08:56:26Z","title":"Benchmarking Dynamic SLO Compliance in Distributed Computing Continuum\n  Systems","summary":"  Ensuring Service Level Objectives (SLOs) in large-scale architectures, such\nas Distributed Computing Continuum Systems (DCCS), is challenging due to their\nheterogeneous nature and varying service requirements across different devices\nand applications. Additionally, unpredictable workloads and resource\nlimitations lead to fluctuating performance and violated SLOs. To improve SLO\ncompliance in DCCS, one possibility is to apply machine learning; however, the\ndesign choices are often left to the developer. To that extent, we provide a\nbenchmark of Active Inference -- an emerging method from neuroscience --\nagainst three established reinforcement learning algorithms (Deep Q-Network,\nAdvantage Actor-Critic, and Proximal Policy Optimization). We consider a\nrealistic DCCS use case: an edge device running a video conferencing\napplication alongside a WebSocket server streaming videos. Using one of the\nrespective algorithms, we continuously monitor key performance metrics, such as\nlatency and bandwidth usage, to dynamically adjust parameters -- including the\nnumber of streams, frame rate, and resolution -- to optimize service quality\nand user experience. To test algorithms' adaptability to constant system\nchanges, we simulate dynamically changing SLOs and both instant and gradual\ndata-shift scenarios, such as network bandwidth limitations and fluctuating\ndevice thermal states. Although the evaluated algorithms all showed advantages\nand limitations, our findings demonstrate that Active Inference is a promising\napproach for ensuring SLO compliance in DCCS, offering lower memory usage,\nstable CPU utilization, and fast convergence.\n","authors":["Alfreds Lapkovskis","Boris Sedlak","Sindri Magnsson","Schahram Dustdar","Praveen Kumar Donta"],"pdf_url":"https://arxiv.org/pdf/2503.03274v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.03269v1","updated":"2025-03-05T08:50:53Z","published":"2025-03-05T08:50:53Z","title":"Conformal Transformations for Symmetric Power Transformers","summary":"  Transformers with linear attention offer significant computational advantages\nover softmax-based transformers but often suffer from degraded performance. The\nsymmetric power (sympow) transformer, a particular type of linear transformer,\naddresses some of this performance gap by leveraging symmetric tensor\nembeddings, achieving comparable performance to softmax transformers. However,\nthe finite capacity of the recurrent state in sympow transformers limits their\nability to retain information, leading to performance degradation when scaling\nthe training or evaluation context length. To address this issue, we propose\nthe conformal-sympow transformer, which dynamically frees up capacity using\ndata-dependent multiplicative gating and adaptively stores information using\ndata-dependent rotary embeddings. Preliminary experiments on the LongCrawl64\ndataset demonstrate that conformal-sympow overcomes the limitations of sympow\ntransformers, achieving robust performance across scaled training and\nevaluation contexts.\n","authors":["Saurabh Kumar","Jacob Buckman","Carles Gelada","Sean Zhang"],"pdf_url":"https://arxiv.org/pdf/2503.03269v1.pdf","comment":"SCOPE Workshop at ICLR 2025"},{"id":"http://arxiv.org/abs/2412.06464v2","updated":"2025-03-05T08:47:27Z","published":"2024-12-09T13:09:04Z","title":"Gated Delta Networks: Improving Mamba2 with Delta Rule","summary":"  Linear Transformers have gained attention as efficient alternatives to\nstandard Transformers, but their performance in retrieval and long-context\ntasks has been limited. To address these limitations, recent work has explored\ntwo distinct mechanisms: gating for adaptive memory control and the delta\nupdate rule for precise memory modifications. We observe that these mechanisms\nare complementary: gating enables rapid memory erasure while the delta rule\nfacilitates targeted updates. Building on this insight, we introduce the gated\ndelta rule and develop a parallel training algorithm optimized for modern\nhardware. Our proposed architecture, Gated DeltaNet, consistently surpasses\nexisting models like Mamba2 and DeltaNet across multiple benchmarks, including\nlanguage modeling, common-sense reasoning, in-context retrieval, length\nextrapolation, and long-context understanding. We further enhance performance\nby developing hybrid architectures that combine Gated DeltaNet layers with\nsliding window attention or Mamba2 layers, achieving both improved training\nefficiency and superior task performance.\n","authors":["Songlin Yang","Jan Kautz","Ali Hatamizadeh"],"pdf_url":"https://arxiv.org/pdf/2412.06464v2.pdf","comment":"ICLR 2025 camera ready"},{"id":"http://arxiv.org/abs/2408.07246v3","updated":"2025-03-05T08:43:44Z","published":"2024-08-14T01:16:40Z","title":"ChemVLM: Exploring the Power of Multimodal Large Language Models in\n  Chemistry Area","summary":"  Large Language Models (LLMs) have achieved remarkable success and have been\napplied across various scientific fields, including chemistry. However, many\nchemical tasks require the processing of visual information, which cannot be\nsuccessfully handled by existing chemical LLMs. This brings a growing need for\nmodels capable of integrating multimodal information in the chemical domain. In\nthis paper, we introduce \\textbf{ChemVLM}, an open-source chemical multimodal\nlarge language model specifically designed for chemical applications. ChemVLM\nis trained on a carefully curated bilingual multimodal dataset that enhances\nits ability to understand both textual and visual chemical information,\nincluding molecular structures, reactions, and chemistry examination questions.\nWe develop three datasets for comprehensive evaluation, tailored to Chemical\nOptical Character Recognition (OCR), Multimodal Chemical Reasoning (MMCR), and\nMultimodal Molecule Understanding tasks. We benchmark ChemVLM against a range\nof open-source and proprietary multimodal large language models on various\ntasks. Experimental results demonstrate that ChemVLM achieves competitive\nperformance across all evaluated tasks. Our model can be found at\nhttps://huggingface.co/AI4Chem/ChemVLM-26B.\n","authors":["Junxian Li","Di Zhang","Xunzhi Wang","Zeying Hao","Jingdi Lei","Qian Tan","Cai Zhou","Wei Liu","Yaotian Yang","Xinrui Xiong","Weiyun Wang","Zhe Chen","Wenhai Wang","Wei Li","Shufei Zhang","Mao Su","Wanli Ouyang","Yuqiang Li","Dongzhan Zhou"],"pdf_url":"https://arxiv.org/pdf/2408.07246v3.pdf","comment":"11 pages, updated version"},{"id":"http://arxiv.org/abs/2502.16232v2","updated":"2025-03-05T08:42:40Z","published":"2025-02-22T14:04:23Z","title":"Flow-based Bayesian filtering for high-dimensional nonlinear stochastic\n  dynamical systems","summary":"  Bayesian filtering for high-dimensional nonlinear stochastic dynamical\nsystems is a fundamental yet challenging problem in many fields of science and\nengineering. Existing methods face significant obstacles: Gaussian-based\nfilters struggle with non-Gaussian distributions, while sequential Monte Carlo\nmethods are computationally intensive and prone to particle degeneracy in high\ndimensions. Although generative models in machine learning have made\nsignificant progress in modeling high-dimensional non-Gaussian distributions,\ntheir inefficiency in online updating limits their applicability to filtering\nproblems. To address these challenges, we propose a flow-based Bayesian filter\n(FBF) that integrates normalizing flows to construct a novel latent linear\nstate-space model with Gaussian filtering distributions. This framework\nfacilitates efficient density estimation and sampling using invertible\ntransformations provided by normalizing flows, and it enables the construction\nof filters in a data-driven manner, without requiring prior knowledge of system\ndynamics or observation models. Numerical experiments demonstrate the superior\naccuracy and efficiency of FBF.\n","authors":["Xintong Wang","Xiaofei Guan","Ling Guo","Hao Wu"],"pdf_url":"https://arxiv.org/pdf/2502.16232v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.03262v1","updated":"2025-03-05T08:38:51Z","published":"2025-03-05T08:38:51Z","title":"Trajectory Prediction for Autonomous Driving: Progress, Limitations, and\n  Future Directions","summary":"  As the potential for autonomous vehicles to be integrated on a large scale\ninto modern traffic systems continues to grow, ensuring safe navigation in\ndynamic environments is crucial for smooth integration. To guarantee safety and\nprevent collisions, autonomous vehicles must be capable of accurately\npredicting the trajectories of surrounding traffic agents. Over the past\ndecade, significant efforts from both academia and industry have been dedicated\nto designing solutions for precise trajectory forecasting. These efforts have\nproduced a diverse range of approaches, raising questions about the differences\nbetween these methods and whether trajectory prediction challenges have been\nfully addressed. This paper reviews a substantial portion of recent trajectory\nprediction methods and devises a taxonomy to classify existing solutions. A\ngeneral overview of the prediction pipeline is also provided, covering input\nand output modalities, modeling features, and prediction paradigms discussed in\nthe literature. In addition, the paper discusses active research areas within\ntrajectory prediction, addresses the posed research questions, and highlights\nthe remaining research gaps and challenges.\n","authors":["Nadya Abdel Madjid","Abdulrahman Ahmad","Murad Mebrahtu","Yousef Babaa","Abdelmoamen Nasser","Sumbal Malik","Bilal Hassan","Naoufel Werghi","Jorge Dias","Majid Khonji"],"pdf_url":"https://arxiv.org/pdf/2503.03262v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2412.04910v3","updated":"2025-03-05T08:37:17Z","published":"2024-12-06T10:05:10Z","title":"Learning High-Degree Parities: The Crucial Role of the Initialization","summary":"  Parities have become a standard benchmark for evaluating learning algorithms.\nRecent works show that regular neural networks trained by gradient descent can\nefficiently learn degree $k$ parities on uniform inputs for constant $k$, but\nfail to do so when $k$ and $d-k$ grow with $d$ (here $d$ is the ambient\ndimension). However, the case where $k=d-O_d(1)$ (almost-full parities),\nincluding the degree $d$ parity (the full parity), has remained unsettled. This\npaper shows that for gradient descent on regular neural networks, learnability\ndepends on the initial weight distribution. On one hand, the discrete\nRademacher initialization enables efficient learning of almost-full parities,\nwhile on the other hand, its Gaussian perturbation with large enough constant\nstandard deviation $\\sigma$ prevents it. The positive result for almost-full\nparities is shown to hold up to $\\sigma=O(d^{-1})$, pointing to questions about\na sharper threshold phenomenon. Unlike statistical query (SQ) learning, where a\nsingleton function class like the full parity is trivially learnable, our\nnegative result applies to a fixed function and relies on an initial gradient\nalignment measure of potential broader relevance to neural networks learning.\n","authors":["Emmanuel Abbe","Elisabetta Cornacchia","Jan Hza","Donald Kougang-Yombi"],"pdf_url":"https://arxiv.org/pdf/2412.04910v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2408.06927v3","updated":"2025-03-05T08:35:41Z","published":"2024-08-13T14:29:00Z","title":"Breaking Class Barriers: Efficient Dataset Distillation via Inter-Class\n  Feature Compensator","summary":"  Dataset distillation has emerged as a technique aiming to condense\ninformative features from large, natural datasets into a compact and synthetic\nform. While recent advancements have refined this technique, its performance is\nbottlenecked by the prevailing class-specific synthesis paradigm. Under this\nparadigm, synthetic data is optimized exclusively for a pre-assigned one-hot\nlabel, creating an implicit class barrier in feature condensation. This leads\nto inefficient utilization of the distillation budget and oversight of\ninter-class feature distributions, which ultimately limits the effectiveness\nand efficiency, as demonstrated in our analysis. To overcome these constraints,\nthis paper presents the Inter-class Feature Compensator (INFER), an innovative\ndistillation approach that transcends the class-specific data-label framework\nwidely utilized in current dataset distillation methods. Specifically, INFER\nleverages a Universal Feature Compensator (UFC) to enhance feature integration\nacross classes, enabling the generation of multiple additional synthetic\ninstances from a single UFC input. This significantly improves the efficiency\nof the distillation budget. Moreover, INFER enriches inter-class interactions\nduring the distillation, thereby enhancing the effectiveness and\ngeneralizability of the distilled data. By allowing for the linear\ninterpolation of labels similar to those in the original dataset, INFER\nmeticulously optimizes the synthetic data and dramatically reduces the size of\nsoft labels in the synthetic dataset to almost zero, establishing a new\nbenchmark for efficiency and effectiveness in dataset distillation. In\npractice, INFER demonstrates state-of-the-art performance across benchmark\ndatasets. For instance, in the ipc = 50 setting on ImageNet-1k with the same\ncompression level, it outperforms SRe2L by 34.5% using ResNet18.\n","authors":["Xin Zhang","Jiawei Du","Ping Liu","Joey Tianyi Zhou"],"pdf_url":"https://arxiv.org/pdf/2408.06927v3.pdf","comment":"Accepted to ICLR 2025"},{"id":"http://arxiv.org/abs/2305.15759v6","updated":"2025-03-05T08:34:25Z","published":"2023-05-25T06:18:31Z","title":"DP-LDMs: Differentially Private Latent Diffusion Models","summary":"  Diffusion models (DMs) are one of the most widely used generative models for\nproducing high quality images. However, a flurry of recent papers points out\nthat DMs are least private forms of image generators, by extracting a\nsignificant number of near-identical replicas of training images from DMs.\nExisting privacy-enhancing techniques for DMs, unfortunately, do not provide a\ngood privacy-utility tradeoff. In this paper, we aim to improve the current\nstate of DMs with differential privacy (DP) by adopting the $\\textit{Latent}$\nDiffusion Models (LDMs). LDMs are equipped with powerful pre-trained\nautoencoders that map the high-dimensional pixels into lower-dimensional latent\nrepresentations, in which DMs are trained, yielding a more efficient and fast\ntraining of DMs. Rather than fine-tuning the entire LDMs, we fine-tune only the\n$\\textit{attention}$ modules of LDMs with DP-SGD, reducing the number of\ntrainable parameters by roughly $90\\%$ and achieving a better privacy-accuracy\ntrade-off. Our approach allows us to generate realistic, high-dimensional\nimages (256x256) conditioned on text prompts with DP guarantees, which, to the\nbest of our knowledge, has not been attempted before. Our approach provides a\npromising direction for training more powerful, yet training-efficient\ndifferentially private DMs, producing high-quality DP images. Our code is\navailable at https://anonymous.4open.science/r/DP-LDM-4525.\n","authors":["Michael F. Liu","Saiyue Lyu","Margarita Vinaroz","Mijung Park"],"pdf_url":"https://arxiv.org/pdf/2305.15759v6.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.03258v1","updated":"2025-03-05T08:28:11Z","published":"2025-03-05T08:28:11Z","title":"Exploring the Potential of Large Language Models as Predictors in\n  Dynamic Text-Attributed Graphs","summary":"  With the rise of large language models (LLMs), there has been growing\ninterest in Graph Foundation Models (GFMs) for graph-based tasks. By leveraging\nLLMs as predictors, GFMs have demonstrated impressive generalizability across\nvarious tasks and datasets. However, existing research on LLMs as predictors\nhas predominantly focused on static graphs, leaving their potential in dynamic\ngraph prediction unexplored. In this work, we pioneer using LLMs for predictive\ntasks on dynamic graphs. We identify two key challenges: the constraints\nimposed by context length when processing large-scale historical data and the\nsignificant variability in domain characteristics, both of which complicate the\ndevelopment of a unified predictor. To address these challenges, we propose the\nGraphAgent-Dynamic (GAD) Framework, a multi-agent system that leverages\ncollaborative LLMs. In contrast to using a single LLM as the predictor, GAD\nincorporates global and local summary agents to generate domain-specific\nknowledge, enhancing its transferability across domains. Additionally,\nknowledge reflection agents enable adaptive updates to GAD's knowledge,\nmaintaining a unified and self-consistent architecture. In experiments, GAD\ndemonstrates performance comparable to or even exceeds that of full-supervised\ngraph neural networks without dataset-specific training. Finally, to enhance\nthe task-specific performance of LLM-based predictors, we discuss potential\nimprovements, such as dataset-specific fine-tuning to LLMs. By developing\ntailored strategies for different tasks, we provide new insights for the future\ndesign of LLM-based predictors.\n","authors":["Runlin Lei","Jiarui Ji","Haipeng Ding","Lu Yi","Zhewei Wei","Yongchao Liu","Chuntao Hong"],"pdf_url":"https://arxiv.org/pdf/2503.03258v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2402.01669v2","updated":"2025-03-05T08:23:02Z","published":"2024-01-16T13:41:00Z","title":"Improved Performances and Motivation in Intelligent Tutoring Systems:\n  Combining Machine Learning and Learner Choice","summary":"  Large class sizes challenge personalized learning in schools, prompting the\nuse of educational technologies such as intelligent tutoring systems. To\naddress this, we present an AI-driven personalization system, called ZPDES,\nbased on the Learning Progress Hypothesis - modeling curiosity-driven learning\n- and multi-armed bandit techniques. It sequences exercises that maximize\nlearning progress for each student. While previous studies demonstrated its\nefficacy in enhancing learning compared to hand-made curricula, its impact on\nstudent motivation remained unexplored. Furthermore, ZPDES previously lacked\nfeatures allowing student choice, a limitation in agency that conflicts with\nits foundation on models of curiosity-driven learning. This study investigates\nhow integrating choice, as a gamification element unrelated to exercise\ndifficulty, affects both learning outcomes and motivation. We conducted an\nextensive field study (265 7-8 years old children, RCT design), comparing ZPDES\nwith and without choice against a hand-designed curriculum. Results show that\nZPDES improves both learning performance and the learning experience. Moreover\nadding choice to ZPDES enhances intrinsic motivation and further strengthens\nits learning benefits. In contrast, incorporating choice into a fixed, linear\ncurriculum negatively impacts learning outcomes. These findings highlight that\nthe intrinsic motivation elicited by choice (gamification) is beneficial only\nwhen paired with an adaptive personalized learning system. This insight is\ncritical as gamified features become increasingly prevalent in educational\ntechnologies.\n","authors":["Benjamin Clment","Hlne Sauzon","Didier Roy","Pierre-Yves Oudeyer"],"pdf_url":"https://arxiv.org/pdf/2402.01669v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.01297v2","updated":"2025-03-05T08:03:39Z","published":"2025-03-03T08:33:35Z","title":"Regularization-based Framework for Quantization-, Fault- and\n  Variability-Aware Training","summary":"  Efficient inference is critical for deploying deep learning models on edge AI\ndevices. Low-bit quantization (e.g., 3- and 4-bit) with fixed-point arithmetic\nimproves efficiency, while low-power memory technologies like analog\nnonvolatile memory enable further gains. However, these methods introduce\nnon-ideal hardware behavior, including bit faults and device-to-device\nvariability. We propose a regularization-based quantization-aware training\n(QAT) framework that supports fixed, learnable step-size, and learnable\nnon-uniform quantization, achieving competitive results on CIFAR-10 and\nImageNet. Our method also extends to Spiking Neural Networks (SNNs),\ndemonstrating strong performance on 4-bit networks on CIFAR10-DVS and N-Caltech\n101. Beyond quantization, our framework enables fault and variability-aware\nfine-tuning, mitigating stuck-at faults (fixed weight bits) and device\nresistance variability. Compared to prior fault-aware training, our approach\nsignificantly improves performance recovery under upto 20% bit-fault rate and\n40% device-to-device variability. Our results establish a generalizable\nframework for quantization and robustness-aware training, enhancing efficiency\nand reliability in low-power, non-ideal hardware.\n","authors":["Anmol Biswas","Raghav Singhal","Sivakumar Elangovan","Shreyas Sabnis","Udayan Ganguly"],"pdf_url":"https://arxiv.org/pdf/2503.01297v2.pdf","comment":"AB and RS contributed equally to this work. A version of this paper\n  accepted at MLNCP @ NeuRIPS '24"},{"id":"http://arxiv.org/abs/2503.03245v1","updated":"2025-03-05T07:53:39Z","published":"2025-03-05T07:53:39Z","title":"Less is more? Rewards in RL for Cyber Defence","summary":"  The last few years has seen an explosion of interest in autonomous cyber\ndefence agents based on deep reinforcement learning. Such agents are typically\ntrained in a cyber gym environment, also known as a cyber simulator, at least\n32 of which have already been built. Most, if not all cyber gyms provide dense\n\"scaffolded\" reward functions which combine many penalties or incentives for a\nrange of (un)desirable states and costly actions. Whilst dense rewards help\nalleviate the challenge of exploring complex environments, yielding seemingly\neffective strategies from relatively few environment steps; they are also known\nto bias the solutions an agent can find, potentially towards suboptimal\nsolutions. Sparse rewards could offer preferable or more effective solutions\nand have been overlooked by cyber gyms to date. In this work we set out to\nevaluate whether sparse reward functions might enable training more effective\ncyber defence agents. Towards this goal we first break down several evaluation\nlimitations in existing work by proposing a ground truth evaluation score that\ngoes beyond the standard RL paradigm used to train and evaluate agents. By\nadapting a well-established cyber gym to accommodate our methodology and ground\ntruth score, we propose and evaluate two sparse reward mechanisms and compare\nthem with a typical dense reward. Our evaluation considers a range of network\nsizes, from 2 to 50 nodes, and both reactive and proactive defensive actions.\nOur results show that sparse rewards, particularly positive reinforcement for\nan uncompromised network state, enable the training of more effective cyber\ndefence agents. Furthermore, we show that sparse rewards provide more stable\ntraining than dense rewards, and that both effectiveness and training stability\nare robust to a variety of cyber environment considerations.\n","authors":["Elizabeth Bates","Chris Hicks","Vasilios Mavroudis"],"pdf_url":"https://arxiv.org/pdf/2503.03245v1.pdf","comment":"4 Pages"},{"id":"http://arxiv.org/abs/2503.03241v1","updated":"2025-03-05T07:47:57Z","published":"2025-03-05T07:47:57Z","title":"Structural Entropy Guided Unsupervised Graph Out-Of-Distribution\n  Detection","summary":"  With the emerging of huge amount of unlabeled data, unsupervised\nout-of-distribution (OOD) detection is vital for ensuring the reliability of\ngraph neural networks (GNNs) by identifying OOD samples from in-distribution\n(ID) ones during testing, where encountering novel or unknown data is\ninevitable. Existing methods often suffer from compromised performance due to\nredundant information in graph structures, which impairs their ability to\neffectively differentiate between ID and OOD data. To address this challenge,\nwe propose SEGO, an unsupervised framework that integrates structural entropy\ninto OOD detection regarding graph classification. Specifically, within the\narchitecture of contrastive learning, SEGO introduces an anchor view in the\nform of coding tree by minimizing structural entropy. The obtained coding tree\neffectively removes redundant information from graphs while preserving\nessential structural information, enabling the capture of distinct graph\npatterns between ID and OOD samples. Furthermore, we present a multi-grained\ncontrastive learning scheme at local, global, and tree levels using triplet\nviews, where coding trees with essential information serve as the anchor view.\nExtensive experiments on real-world datasets validate the effectiveness of\nSEGO, demonstrating superior performance over state-of-the-art baselines in OOD\ndetection. Specifically, our method achieves the best performance on 9 out of\n10 dataset pairs, with an average improvement of 3.7\\% on OOD detection\ndatasets, significantly surpassing the best competitor by 10.8\\% on the\nFreeSolv/ToxCast dataset pair.\n","authors":["Yue Hou","He Zhu","Ruomei Liu","Yingke Su","Jinxiang Xia","Junran Wu","Ke Xu"],"pdf_url":"https://arxiv.org/pdf/2503.03241v1.pdf","comment":"Accepted by AAAI 2025 (The 39th Annual AAAI Conference on Artificial\n  Intelligence)"},{"id":"http://arxiv.org/abs/2503.03239v1","updated":"2025-03-05T07:45:56Z","published":"2025-03-05T07:45:56Z","title":"PAIR: A Novel Large Language Model-Guided Selection Strategy for\n  Evolutionary Algorithms","summary":"  Evolutionary Algorithms (EAs) employ random or simplistic selection methods,\nlimiting their exploration of solution spaces and convergence to optimal\nsolutions. The randomness in performing crossover or mutations may limit the\nmodel's ability to evolve efficiently. This paper introduces Preference-Aligned\nIndividual Reciprocity (PAIR), a novel selection approach leveraging Large\nLanguage Models to emulate human-like mate selection, thereby introducing\nintelligence to the pairing process in EAs. PAIR prompts an LLM to evaluate\nindividuals within a population based on genetic diversity, fitness level, and\ncrossover compatibility, guiding more informed pairing decisions. We evaluated\nPAIR against a baseline method called LLM-driven EA (LMEA), published recently.\nResults indicate that PAIR significantly outperforms LMEA across various TSP\ninstances, achieving lower optimality gaps and improved convergence. This\nperformance is especially noticeable when combined with the flash thinking\nmodel, demonstrating increased population diversity to escape local optima. In\ngeneral, PAIR provides a new strategy in the area of in-context learning for\nLLM-driven selection in EAs via sophisticated preference modelling, paving the\nway for improved solutions and further studies into LLM-guided optimization.\n","authors":["Shady Ali","Mahmoud Ashraf","Seif Hegazy","Fatty Salem","Hoda Mokhtar","Mohamed Medhat Gaber","Mohamed Taher Alrefaie"],"pdf_url":"https://arxiv.org/pdf/2503.03239v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.03237v1","updated":"2025-03-05T07:31:06Z","published":"2025-03-05T07:31:06Z","title":"Prediction of Halo Coronal Mass Ejections Using SDO/HMI Vector Magnetic\n  Data Products and a Transformer Model","summary":"  We present a transformer model, named DeepHalo, to predict the occurrence of\nhalo coronal mass ejections (CMEs). Our model takes as input an active region\n(AR) and a profile, where the profile contains a time series of data samples in\nthe AR that are collected 24 hours before the beginning of a day, and predicts\nwhether the AR would produce a halo CME during that day. Each data sample\ncontains physical parameters, or features, derived from photospheric vector\nmagnetic field data taken by the Helioseismic and Magnetic Imager (HMI) on\nboard the Solar Dynamics Observatory (SDO). We survey and match CME events in\nthe Space Weather Database Of Notification, Knowledge, Information (DONKI) and\nLarge Angle and Spectrometric Coronagraph (LASCO) CME Catalog, and compile a\nlist of CMEs including halo CMEs and non-halo CMEs associated with ARs in the\nperiod between November 2010 and August 2023. We use the information gathered\nabove to build the labels (positive versus negative) of the data samples and\nprofiles at hand, where the labels are needed for machine learning.\nExperimental results show that DeepHalo with a true skill statistics (TSS)\nscore of 0.907 outperforms a closely related long short-term memory network\nwith a TSS score of 0.821. To our knowledge, this is the first time that the\ntransformer model has been used for halo CME prediction.\n","authors":["Hongyang Zhang","Ju Jing","Jason T. L. Wang","Haimin Wang","Yasser Abduallah","Yan Xu","Khalid A. Alobaid","Hameedullah Farooki","Vasyl Yurchyshyn"],"pdf_url":"https://arxiv.org/pdf/2503.03237v1.pdf","comment":"13 pages, 8 figures"},{"id":"http://arxiv.org/abs/2412.17107v3","updated":"2025-03-05T07:29:42Z","published":"2024-12-22T17:39:32Z","title":"Grams: Gradient Descent with Adaptive Momentum Scaling","summary":"  We introduce $\\mathbf{G}$radient Descent with $\\mathbf{A}$daptive\n$\\mathbf{M}$omentum $\\mathbf{S}$caling ($\\mathbf{Grams}$), a novel optimization\nalgorithm that decouples the direction and magnitude of parameter updates in\ndeep learning. Unlike traditional optimizers that directly integrate momentum\ninto updates, Grams separates the update direction, derived from current\ngradients, from momentum, which is used solely for adaptive magnitude scaling.\nThis approach enables Grams to achieve improved loss descent compared to\nstate-of-the-art cautious and momentum-based optimizers. We theoretically\ndemonstrate that Grams descents faster than other state-of-the-art optimizers\nand establish a global convergence guarantee for Grams. We also validate its\neffectiveness through extensive empirical evaluations. The results demonstrate\nGrams' superior performance, including faster convergence and better\ngeneralization, compared to widely-used optimizers such as Adam, Lion, and\ntheir cautious variants. Our results highlight Grams' potential as a\ntransformative approach for efficiently training and fine-tuning large language\nmodels. Code is available at https://github.com/Gunale0926/Grams.\n","authors":["Yang Cao","Xiaoyu Li","Zhao Song"],"pdf_url":"https://arxiv.org/pdf/2412.17107v3.pdf","comment":"SCOPE Workshop @ ICLR 2025"},{"id":"http://arxiv.org/abs/2502.17543v2","updated":"2025-03-05T06:53:52Z","published":"2025-02-24T18:56:58Z","title":"Training a Generally Curious Agent","summary":"  Efficient exploration is essential for intelligent systems interacting with\ntheir environment, but existing language models often fall short in scenarios\nthat require strategic information gathering. In this paper, we present\nPAPRIKA, a fine-tuning approach that enables language models to develop general\ndecision-making capabilities that are not confined to particular environments.\nBy training on synthetic interaction data from different tasks that require\ndiverse strategies, PAPRIKA teaches models to explore and adapt their behavior\non a new task based on environment feedback in-context without more gradient\nupdates. Experimental results show that models fine-tuned with PAPRIKA can\neffectively transfer their learned decision-making capabilities to entirely\nunseen tasks without additional training. Unlike traditional training, our\napproach's primary bottleneck lies in sampling useful interaction data instead\nof model updates. To improve sample efficiency, we propose a curriculum\nlearning strategy that prioritizes sampling trajectories from tasks with high\nlearning potential. These results suggest a promising path towards AI systems\nthat can autonomously solve novel sequential decision-making problems that\nrequire interactions with the external world.\n","authors":["Fahim Tajwar","Yiding Jiang","Abitha Thankaraj","Sumaita Sadia Rahman","J Zico Kolter","Jeff Schneider","Ruslan Salakhutdinov"],"pdf_url":"https://arxiv.org/pdf/2502.17543v2.pdf","comment":"Project Website: https://paprika-llm.github.io"},{"id":"http://arxiv.org/abs/2407.10341v5","updated":"2025-03-05T06:53:17Z","published":"2024-07-14T21:41:29Z","title":"Affordance-Guided Reinforcement Learning via Visual Prompting","summary":"  Robots equipped with reinforcement learning (RL) have the potential to learn\na wide range of skills solely from a reward signal. However, obtaining a robust\nand dense reward signal for general manipulation tasks remains a challenge.\nExisting learning-based approaches require significant data, such as human\ndemonstrations of success and failure, to learn task-specific reward functions.\nRecently, there is also a growing adoption of large multi-modal foundation\nmodels for robotics that can perform visual reasoning in physical contexts and\ngenerate coarse robot motions for manipulation tasks. Motivated by this range\nof capability, in this work, we present Keypoint-based Affordance Guidance for\nImprovements (KAGI), a method leveraging rewards shaped by vision-language\nmodels (VLMs) for autonomous RL. State-of-the-art VLMs have demonstrated\nimpressive reasoning about affordances through keypoints in zero-shot, and we\nuse these to define dense rewards that guide autonomous robotic learning. On\nreal-world manipulation tasks specified by natural language descriptions, KAGI\nimproves the sample efficiency of autonomous RL and enables successful task\ncompletion in 30K online fine-tuning steps. Additionally, we demonstrate the\nrobustness of KAGI to reductions in the number of in-domain demonstrations used\nfor pre-training, reaching similar performance in 45K online fine-tuning steps.\nProject website: https://sites.google.com/view/affordance-guided-rl\n","authors":["Olivia Y. Lee","Annie Xie","Kuan Fang","Karl Pertsch","Chelsea Finn"],"pdf_url":"https://arxiv.org/pdf/2407.10341v5.pdf","comment":"8 pages, 6 figures. Robotics: Science and Systems (RSS) 2024, Task\n  Specification for General-Purpose Intelligent Robots & Lifelong Robot\n  Learning Workshops"},{"id":"http://arxiv.org/abs/2304.04172v2","updated":"2025-03-05T06:51:11Z","published":"2023-04-09T06:18:34Z","title":"$^2$-SGD: Stable Stochastic Optimization via a Double Momentum\n  Mechanism","summary":"  We consider stochastic convex optimization problems where the objective is an\nexpectation over smooth functions. For this setting we suggest a novel gradient\nestimate that combines two recent mechanism that are related to notion of\nmomentum. Then, we design an SGD-style algorithm as well as an accelerated\nversion that make use of this new estimator, and demonstrate the robustness of\nthese new approaches to the choice of the learning rate. Concretely, we show\nthat these approaches obtain the optimal convergence rates for both noiseless\nand noisy case with the same choice of fixed learning rate. Moreover, for the\nnoisy case we show that these approaches achieve the same optimal bound for a\nvery wide range of learning rates.\n","authors":["Tehila Dahan","Kfir Y. Levy"],"pdf_url":"https://arxiv.org/pdf/2304.04172v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2502.19908v2","updated":"2025-03-05T06:36:27Z","published":"2025-02-27T09:26:22Z","title":"CarPlanner: Consistent Auto-regressive Trajectory Planning for\n  Large-scale Reinforcement Learning in Autonomous Driving","summary":"  Trajectory planning is vital for autonomous driving, ensuring safe and\nefficient navigation in complex environments. While recent learning-based\nmethods, particularly reinforcement learning (RL), have shown promise in\nspecific scenarios, RL planners struggle with training inefficiencies and\nmanaging large-scale, real-world driving scenarios. In this paper, we introduce\n\\textbf{CarPlanner}, a \\textbf{C}onsistent \\textbf{a}uto-\\textbf{r}egressive\n\\textbf{Planner} that uses RL to generate multi-modal trajectories. The\nauto-regressive structure enables efficient large-scale RL training, while the\nincorporation of consistency ensures stable policy learning by maintaining\ncoherent temporal consistency across time steps. Moreover, CarPlanner employs a\ngeneration-selection framework with an expert-guided reward function and an\ninvariant-view module, simplifying RL training and enhancing policy\nperformance. Extensive analysis demonstrates that our proposed RL framework\neffectively addresses the challenges of training efficiency and performance\nenhancement, positioning CarPlanner as a promising solution for trajectory\nplanning in autonomous driving. To the best of our knowledge, we are the first\nto demonstrate that the RL-based planner can surpass both IL- and rule-based\nstate-of-the-arts (SOTAs) on the challenging large-scale real-world dataset\nnuPlan. Our proposed CarPlanner surpasses RL-, IL-, and rule-based SOTA\napproaches within this demanding dataset.\n","authors":["Dongkun Zhang","Jiaming Liang","Ke Guo","Sha Lu","Qi Wang","Rong Xiong","Zhenwei Miao","Yue Wang"],"pdf_url":"https://arxiv.org/pdf/2502.19908v2.pdf","comment":"CVPR 2025"},{"id":"http://arxiv.org/abs/2409.14494v3","updated":"2025-03-05T06:32:04Z","published":"2024-09-13T19:14:18Z","title":"CPT-Boosted Wav2vec2.0: Towards Noise Robust Speech Recognition for\n  Classroom Environments","summary":"  Creating Automatic Speech Recognition (ASR) systems that are robust and\nresilient to classroom conditions is paramount to the development of AI tools\nto aid teachers and students. In this work, we study the efficacy of continued\npretraining (CPT) in adapting Wav2vec2.0 to the classroom domain. We show that\nCPT is a powerful tool in that regard and reduces the Word Error Rate (WER) of\nWav2vec2.0-based models by upwards of 10%. More specifically, CPT improves the\nmodel's robustness to different noises, microphones and classroom conditions.\n","authors":["Ahmed Adel Attia","Dorottya Demszky","Tolulope Ogunremi","Jing Liu","Carol Espy-Wilson"],"pdf_url":"https://arxiv.org/pdf/2409.14494v3.pdf","comment":"arXiv admin note: substantial text overlap with arXiv:2405.13018"},{"id":"http://arxiv.org/abs/2503.03213v1","updated":"2025-03-05T06:11:24Z","published":"2025-03-05T06:11:24Z","title":"Convergence Rates for Softmax Gating Mixture of Experts","summary":"  Mixture of experts (MoE) has recently emerged as an effective framework to\nadvance the efficiency and scalability of machine learning models by softly\ndividing complex tasks among multiple specialized sub-models termed experts.\nCentral to the success of MoE is an adaptive softmax gating mechanism which\ntakes responsibility for determining the relevance of each expert to a given\ninput and then dynamically assigning experts their respective weights. Despite\nits widespread use in practice, a comprehensive study on the effects of the\nsoftmax gating on the MoE has been lacking in the literature. To bridge this\ngap in this paper, we perform a convergence analysis of parameter estimation\nand expert estimation under the MoE equipped with the standard softmax gating\nor its variants, including a dense-to-sparse gating and a hierarchical softmax\ngating, respectively. Furthermore, our theories also provide useful insights\ninto the design of sample-efficient expert structures. In particular, we\ndemonstrate that it requires polynomially many data points to estimate experts\nsatisfying our proposed \\emph{strong identifiability} condition, namely a\ncommonly used two-layer feed-forward network. In stark contrast, estimating\nlinear experts, which violate the strong identifiability condition,\nnecessitates exponentially many data points as a result of intrinsic parameter\ninteractions expressed in the language of partial differential equations. All\nthe theoretical results are substantiated with a rigorous guarantee.\n","authors":["Huy Nguyen","Nhat Ho","Alessandro Rinaldo"],"pdf_url":"https://arxiv.org/pdf/2503.03213v1.pdf","comment":"Section 2 of this work comes from our previous paper titled \"On Least\n  Square Estimation in Softmax Gating Mixture of Experts\" and published at the\n  ICML 2024"},{"id":"http://arxiv.org/abs/2503.03211v1","updated":"2025-03-05T06:06:16Z","published":"2025-03-05T06:06:16Z","title":"NodeReg: Mitigating the Imbalance and Distribution Shift Effects in\n  Semi-Supervised Node Classification via Norm Consistency","summary":"  Aggregating information from neighboring nodes benefits graph neural networks\n(GNNs) in semi-supervised node classification tasks. Nevertheless, this\nmechanism also renders nodes susceptible to the influence of their neighbors.\nFor instance, this will occur when the neighboring nodes are imbalanced or the\nneighboring nodes contain noise, which can even affect the GNN's ability to\ngeneralize out of distribution. We find that ensuring the consistency of the\nnorm for node representations can significantly reduce the impact of these two\nissues on GNNs. To this end, we propose a regularized optimization method\ncalled NodeReg that enforces the consistency of node representation norms. This\nmethod is simple but effective and satisfies Lipschitz continuity, thus\nfacilitating stable optimization and significantly improving semi-supervised\nnode classification performance under the above two scenarios. To illustrate,\nin the imbalance scenario, when training a GCN with an imbalance ratio of 0.1,\nNodeReg outperforms the most competitive baselines by 1.4%-25.9% in F1 score\nacross five public datasets. Similarly, in the distribution shift scenario,\nNodeReg outperforms the most competitive baseline by 1.4%-3.1% in accuracy.\n","authors":["Shenzhi Yang","Jun Xia","Jingbo Zhou","Xingkai Yao","Xiaofang Zhang"],"pdf_url":"https://arxiv.org/pdf/2503.03211v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2409.15866v3","updated":"2025-03-05T05:55:45Z","published":"2024-09-24T08:40:04Z","title":"Online Planning for Multi-UAV Pursuit-Evasion in Unknown Environments\n  Using Deep Reinforcement Learning","summary":"  Multi-UAV pursuit-evasion, where pursuers aim to capture evaders, poses a key\nchallenge for UAV swarm intelligence. Multi-agent reinforcement learning (MARL)\nhas demonstrated potential in modeling cooperative behaviors, but most RL-based\napproaches remain constrained to simplified simulations with limited dynamics\nor fixed scenarios. Previous attempts to deploy RL policy to real-world\npursuit-evasion are largely restricted to two-dimensional scenarios, such as\nground vehicles or UAVs at fixed altitudes. In this paper, we address multi-UAV\npursuit-evasion by considering UAV dynamics and physical constraints. We\nintroduce an evader prediction-enhanced network to tackle partial observability\nin cooperative strategy learning. Additionally, we propose an adaptive\nenvironment generator within MARL training, enabling higher exploration\nefficiency and better policy generalization across diverse scenarios.\nSimulations show our method significantly outperforms all baselines in\nchallenging scenarios, generalizing to unseen scenarios with a 100% capture\nrate. Finally, we derive a feasible policy via a two-stage reward refinement\nand deploy the policy on real quadrotors in a zero-shot manner. To our\nknowledge, this is the first work to derive and deploy an RL-based policy using\ncollective thrust and body rates control commands for multi-UAV pursuit-evasion\nin unknown environments. The open-source code and videos are available at\nhttps://sites.google.com/view/pursuit-evasion-rl.\n","authors":["Jiayu Chen","Chao Yu","Guosheng Li","Wenhao Tang","Shilong Ji","Xinyi Yang","Botian Xu","Huazhong Yang","Yu Wang"],"pdf_url":"https://arxiv.org/pdf/2409.15866v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.03206v1","updated":"2025-03-05T05:50:38Z","published":"2025-03-05T05:50:38Z","title":"An Analytical Theory of Power Law Spectral Bias in the Learning Dynamics\n  of Diffusion Models","summary":"  We developed an analytical framework for understanding how the learned\ndistribution evolves during diffusion model training. Leveraging the Gaussian\nequivalence principle, we derived exact solutions for the gradient-flow\ndynamics of weights in one- or two-layer linear denoiser settings with\narbitrary data. Remarkably, these solutions allowed us to derive the generated\ndistribution in closed form and its KL divergence through training. These\nanalytical results expose a pronounced power-law spectral bias, i.e., for\nweights and distributions, the convergence time of a mode follows an inverse\npower law of its variance. Empirical experiments on both Gaussian and image\ndatasets demonstrate that the power-law spectral bias remains robust even when\nusing deeper or convolutional architectures. Our results underscore the\nimportance of the data covariance in dictating the order and rate at which\ndiffusion models learn different modes of the data, providing potential\nexplanations for why earlier stopping could lead to incorrect details in image\ngenerative models.\n","authors":["Binxu Wang"],"pdf_url":"https://arxiv.org/pdf/2503.03206v1.pdf","comment":"50 pages, 10 figures. Preprint"},{"id":"http://arxiv.org/abs/2411.16746v3","updated":"2025-03-05T05:34:47Z","published":"2024-11-23T20:41:24Z","title":"LoBAM: LoRA-Based Backdoor Attack on Model Merging","summary":"  Model merging is an emerging technique that integrates multiple models\nfine-tuned on different tasks to create a versatile model that excels in\nmultiple domains. This scheme, in the meantime, may open up backdoor attack\nopportunities where one single malicious model can jeopardize the integrity of\nthe merged model. Existing works try to demonstrate the risk of such attacks by\nassuming substantial computational resources, focusing on cases where the\nattacker can fully fine-tune the pre-trained model. Such an assumption,\nhowever, may not be feasible given the increasing size of machine learning\nmodels. In practice where resources are limited and the attacker can only\nemploy techniques like Low-Rank Adaptation (LoRA) to produce the malicious\nmodel, it remains unclear whether the attack can still work and pose threats.\nIn this work, we first identify that the attack efficacy is significantly\ndiminished when using LoRA for fine-tuning. Then, we propose LoBAM, a method\nthat yields high attack success rate with minimal training resources. The key\nidea of LoBAM is to amplify the malicious weights in an intelligent way that\neffectively enhances the attack efficacy. We demonstrate that our design can\nlead to improved attack success rate through extensive empirical experiments\nacross various model merging scenarios. Moreover, we show that our method is\nhighly stealthy and is difficult to detect and defend against.\n","authors":["Ming Yin","Jingyang Zhang","Jingwei Sun","Minghong Fang","Hai Li","Yiran Chen"],"pdf_url":"https://arxiv.org/pdf/2411.16746v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.03197v1","updated":"2025-03-05T05:30:26Z","published":"2025-03-05T05:30:26Z","title":"Directly Follows Graphs Go Predictive Process Monitoring With Graph\n  Neural Networks","summary":"  In the past years, predictive process monitoring (PPM) techniques based on\nartificial neural networks have evolved as a method to monitor the future\nbehavior of business processes. Existing approaches mostly focus on\ninterpreting the processes as sequences, so-called traces, and feeding them to\nneural architectures designed to operate on sequential data such as recurrent\nneural networks (RNNs) or transformers. In this study, we investigate an\nalternative way to perform PPM: by transforming each process in its\ndirectly-follows-graph (DFG) representation we are able to apply graph neural\nnetworks (GNNs) for the prediction tasks. By this, we aim to develop models\nthat are more suitable for complex processes that are long and contain an\nabundance of loops. In particular, we present different ways to create DFG\nrepresentations depending on the particular GNN we use. The tested GNNs range\nfrom classical node-based to novel edge-based architectures. Further, we\ninvestigate the possibility of using multi-graphs. By these steps, we aim to\ndesign graph representations that minimize the information loss when\ntransforming traces into graphs.\n","authors":["Attila Lischka","Simon Rauch","Oliver Stritzel"],"pdf_url":"https://arxiv.org/pdf/2503.03197v1.pdf","comment":"10 pages, 4 figures, 3 tables"},{"id":"http://arxiv.org/abs/2503.03195v1","updated":"2025-03-05T05:25:54Z","published":"2025-03-05T05:25:54Z","title":"Online Bidding under RoS Constraints without Knowing the Value","summary":"  We consider the problem of bidding in online advertising, where an advertiser\naims to maximize value while adhering to budget and Return-on-Spend (RoS)\nconstraints. Unlike prior work that assumes knowledge of the value generated by\nwinning each impression ({e.g.,} conversions), we address the more realistic\nsetting where the advertiser must simultaneously learn the optimal bidding\nstrategy and the value of each impression opportunity. This introduces a\nchallenging exploration-exploitation dilemma: the advertiser must balance\nexploring different bids to estimate impression values with exploiting current\nknowledge to bid effectively. To address this, we propose a novel Upper\nConfidence Bound (UCB)-style algorithm that carefully manages this trade-off.\nVia a rigorous theoretical analysis, we prove that our algorithm achieves\n$\\widetilde{O}(\\sqrt{T\\log(|\\mathcal{B}|T)})$ regret and constraint violation,\nwhere $T$ is the number of bidding rounds and $\\mathcal{B}$ is the domain of\npossible bids. This establishes the first optimal regret and constraint\nviolation bounds for bidding in the online setting with unknown impression\nvalues. Moreover, our algorithm is computationally efficient and simple to\nimplement. We validate our theoretical findings through experiments on\nsynthetic data, demonstrating that our algorithm exhibits strong empirical\nperformance compared to existing approaches.\n","authors":["Sushant Vijayan","Zhe Feng","Swati Padmanabhan","Karthikeyan Shanmugam","Arun Suggala","Di Wang"],"pdf_url":"https://arxiv.org/pdf/2503.03195v1.pdf","comment":null}]},"2025-03-06T00:00:00Z":{"Computation and Language":[{"id":"http://arxiv.org/abs/2503.03459v2","updated":"2025-03-06T03:32:45Z","published":"2025-03-05T12:49:44Z","title":"Unified Mind Model: Reimagining Autonomous Agents in the LLM Era","summary":"  Large language models (LLMs) have recently demonstrated remarkable\ncapabilities across domains, tasks, and languages (e.g., ChatGPT and GPT-4),\nreviving the research of general autonomous agents with human-like cognitive\nabilities. Such human-level agents require semantic comprehension and\ninstruction-following capabilities, which exactly fall into the strengths of\nLLMs. Although there have been several initial attempts to build human-level\nagents based on LLMs, the theoretical foundation remains a challenging open\nproblem. In this paper, we propose a novel theoretical cognitive architecture,\nthe Unified Mind Model (UMM), which offers guidance to facilitate the rapid\ncreation of autonomous agents with human-level cognitive abilities.\nSpecifically, our UMM starts with the global workspace theory and further\nleverage LLMs to enable the agent with various cognitive abilities, such as\nmulti-modal perception, planning, reasoning, tool use, learning, memory,\nreflection and motivation. Building upon UMM, we then develop an agent-building\nengine, MindOS, which allows users to quickly create domain-/task-specific\nautonomous agents without any programming effort.\n","authors":["Pengbo Hu","Xiang Ying"],"pdf_url":"https://arxiv.org/pdf/2503.03459v2.pdf","comment":"18 pages"},{"id":"http://arxiv.org/abs/2408.14153v3","updated":"2025-03-06T09:00:18Z","published":"2024-08-26T09:55:34Z","title":"Explaining Caption-Image Interactions in CLIP models with Second-Order\n  Attributions","summary":"  Dual encoder architectures like CLIP models map two types of inputs into a\nshared embedding space and predict similarities between them. Despite their\nsuccess, it is, however, not understood how these models compare their two\ninputs. Common first-order feature-attribution methods can only provide limited\ninsights into dual-encoders since their predictions depend on\nfeature-interactions rather than on individual features. In this paper, we\nfirst derive a second-order method enabling the attribution of predictions by\nany differentiable dual encoder onto feature-interactions between its inputs.\nSecond, we apply our method to CLIP models and show that they learn\nfine-grained correspondences between parts of captions and regions in images.\nThey match objects across input modes also account for mismatches. This\nvisual-linguistic grounding ability, however, varies heavily between object\nclasses and exhibits pronounced out-of-domain effects. We can identify\nindividual errors as well as systematic failure categories including object\ncoverage, unusual scenes and correlated contexts.\n","authors":["Lucas Mller","Pascal Tilli","Ngoc Thang Vu","Sebastian Pad"],"pdf_url":"https://arxiv.org/pdf/2408.14153v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2412.06464v3","updated":"2025-03-06T06:57:34Z","published":"2024-12-09T13:09:04Z","title":"Gated Delta Networks: Improving Mamba2 with Delta Rule","summary":"  Linear Transformers have gained attention as efficient alternatives to\nstandard Transformers, but their performance in retrieval and long-context\ntasks has been limited. To address these limitations, recent work has explored\ntwo distinct mechanisms: gating for adaptive memory control and the delta\nupdate rule for precise memory modifications. We observe that these mechanisms\nare complementary: gating enables rapid memory erasure while the delta rule\nfacilitates targeted updates. Building on this insight, we introduce the gated\ndelta rule and develop a parallel training algorithm optimized for modern\nhardware. Our proposed architecture, Gated DeltaNet, consistently surpasses\nexisting models like Mamba2 and DeltaNet across multiple benchmarks, including\nlanguage modeling, common-sense reasoning, in-context retrieval, length\nextrapolation, and long-context understanding. We further enhance performance\nby developing hybrid architectures that combine Gated DeltaNet layers with\nsliding window attention or Mamba2 layers, achieving both improved training\nefficiency and superior task performance.\n","authors":["Songlin Yang","Jan Kautz","Ali Hatamizadeh"],"pdf_url":"https://arxiv.org/pdf/2412.06464v3.pdf","comment":"ICLR 2025 camera ready"},{"id":"http://arxiv.org/abs/2503.04725v1","updated":"2025-03-06T18:59:48Z","published":"2025-03-06T18:59:48Z","title":"L$^2$M: Mutual Information Scaling Law for Long-Context Language\n  Modeling","summary":"  We rigorously establish a bipartite mutual information scaling law in natural\nlanguage that governs long-range dependencies. This scaling law, which we show\nis distinct from and scales independently of the conventional two-point mutual\ninformation, is the key to understanding long-context language modeling. Using\nthis scaling law, we formulate the Long-context Language Modeling (L$^2$M)\ncondition, which relates a model's capacity for effective long context length\nmodeling to the scaling of its latent state size for storing past information.\nOur results are validated through experiments on both transformers and state\nspace models. This work establishes a theoretical foundation that guides the\ndevelopment of large language models toward longer context lengths.\n","authors":["Zhuo Chen","Oriol Mayn i Comas","Zhuotao Jin","Di Luo","Marin Soljai"],"pdf_url":"https://arxiv.org/pdf/2503.04725v1.pdf","comment":"29 pages, 12 figures, 1 table"},{"id":"http://arxiv.org/abs/2503.04724v1","updated":"2025-03-06T18:59:38Z","published":"2025-03-06T18:59:38Z","title":"LLMVoX: Autoregressive Streaming Text-to-Speech Model for Any LLM","summary":"  Recent advancements in speech-to-speech dialogue systems leverage LLMs for\nmultimodal interactions, yet they remain hindered by fine-tuning requirements,\nhigh computational overhead, and text-speech misalignment. Existing\nspeech-enabled LLMs often degrade conversational quality by modifying the LLM,\nthereby compromising its linguistic capabilities. In contrast, we propose\nLLMVoX, a lightweight 30M-parameter, LLM-agnostic, autoregressive streaming TTS\nsystem that generates high-quality speech with low latency, while fully\npreserving the capabilities of the base LLM. Our approach achieves a\nsignificantly lower Word Error Rate compared to speech-enabled LLMs, while\noperating at comparable latency and UTMOS score. By decoupling speech synthesis\nfrom LLM processing via a multi-queue token streaming system, LLMVoX supports\nseamless, infinite-length dialogues. Its plug-and-play design also facilitates\nextension to various tasks with different backbones. Furthermore, LLMVoX\ngeneralizes to new languages with only dataset adaptation, attaining a low\nCharacter Error Rate on an Arabic speech task. Additionally, we have integrated\nLLMVoX with a Vision-Language Model to create an omni-model with speech, text,\nand vision capabilities, without requiring additional multimodal training. Our\ncode base and project page is available at https://mbzuai-oryx.github.io/LLMVoX .\n","authors":["Sambal Shikhar","Mohammed Irfan Kurpath","Sahal Shaji Mullappilly","Jean Lahoud","Fahad Khan","Rao Muhammad Anwer","Salman Khan","Hisham Cholakkal"],"pdf_url":"https://arxiv.org/pdf/2503.04724v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.04723v1","updated":"2025-03-06T18:59:37Z","published":"2025-03-06T18:59:37Z","title":"Shifting Long-Context LLMs Research from Input to Output","summary":"  Recent advancements in long-context Large Language Models (LLMs) have\nprimarily concentrated on processing extended input contexts, resulting in\nsignificant strides in long-context comprehension. However, the equally\ncritical aspect of generating long-form outputs has received comparatively less\nattention. This paper advocates for a paradigm shift in NLP research toward\naddressing the challenges of long-output generation. Tasks such as novel\nwriting, long-term planning, and complex reasoning require models to understand\nextensive contexts and produce coherent, contextually rich, and logically\nconsistent extended text. These demands highlight a critical gap in current LLM\ncapabilities. We underscore the importance of this under-explored domain and\ncall for focused efforts to develop foundational LLMs tailored for generating\nhigh-quality, long-form outputs, which hold immense potential for real-world\napplications.\n","authors":["Yuhao Wu","Yushi Bai","Zhiqing Hu","Shangqing Tu","Ming Shan Hee","Juanzi Li","Roy Ka-Wei Lee"],"pdf_url":"https://arxiv.org/pdf/2503.04723v1.pdf","comment":"Preprint"},{"id":"http://arxiv.org/abs/2503.04722v1","updated":"2025-03-06T18:59:23Z","published":"2025-03-06T18:59:23Z","title":"Enough Coin Flips Can Make LLMs Act Bayesian","summary":"  Large language models (LLMs) exhibit the ability to generalize given few-shot\nexamples in their input prompt, an emergent capability known as in-context\nlearning (ICL). We investigate whether LLMs utilize ICL to perform structured\nreasoning in ways that are consistent with a Bayesian framework or rely on\npattern matching. Using a controlled setting of biased coin flips, we find\nthat: (1) LLMs often possess biased priors, causing initial divergence in\nzero-shot settings, (2) in-context evidence outweighs explicit bias\ninstructions, (3) LLMs broadly follow Bayesian posterior updates, with\ndeviations primarily due to miscalibrated priors rather than flawed updates,\nand (4) attention magnitude has negligible effect on Bayesian inference. With\nsufficient demonstrations of biased coin flips via ICL, LLMs update their\npriors in a Bayesian manner.\n","authors":["Ritwik Gupta","Rodolfo Corona","Jiaxin Ge","Eric Wang","Dan Klein","Trevor Darrell","David M. Chan"],"pdf_url":"https://arxiv.org/pdf/2503.04722v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.04721v1","updated":"2025-03-06T18:59:16Z","published":"2025-03-06T18:59:16Z","title":"Full-Duplex-Bench: A Benchmark to Evaluate Full-duplex Spoken Dialogue\n  Models on Turn-taking Capabilities","summary":"  Spoken dialogue modeling introduces unique challenges beyond text-based\nlanguage modeling, demanding robust turn-taking, backchanneling, and real-time\ninteraction. Although most Spoken Dialogue Models (SDMs) rely on half-duplex\nprocessing (handling speech one turn at a time), emerging full-duplex SDMs can\nlisten and speak simultaneously, enabling more natural and engaging\nconversations. However, current evaluations of such models remain limited,\noften focusing on turn-based metrics or high-level corpus analyses (e.g., turn\ngaps, pauses). To address this gap, we present Full-Duplex-Bench, a new\nbenchmark that systematically evaluates key conversational behaviors: pause\nhandling, backchanneling, turn-taking, and interruption management. Our\nframework uses automatic metrics for consistent and reproducible assessments of\nSDMs' interactive performance. By offering an open and standardized evaluation\nbenchmark, we aim to advance spoken dialogue modeling and encourage the\ndevelopment of more interactive and natural dialogue systems.\n","authors":["Guan-Ting Lin","Jiachen Lian","Tingle Li","Qirui Wang","Gopala Anumanchipalli","Alexander H. Liu","Hung-yi Lee"],"pdf_url":"https://arxiv.org/pdf/2503.04721v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.11807v7","updated":"2025-03-06T18:58:23Z","published":"2024-03-18T14:04:47Z","title":"How Far Are We on the Decision-Making of LLMs? Evaluating LLMs' Gaming\n  Ability in Multi-Agent Environments","summary":"  Decision-making is a complex process requiring diverse abilities, making it\nan excellent framework for evaluating Large Language Models (LLMs). Researchers\nhave examined LLMs' decision-making through the lens of Game Theory. However,\nexisting evaluation mainly focus on two-player scenarios where an LLM competes\nagainst another. Additionally, previous benchmarks suffer from test set leakage\ndue to their static design. We introduce GAMA($\\gamma$)-Bench, a new framework\nfor evaluating LLMs' Gaming Ability in Multi-Agent environments. It includes\neight classical game theory scenarios and a dynamic scoring scheme specially\ndesigned to quantitatively assess LLMs' performance. $\\gamma$-Bench allows\nflexible game settings and adapts the scoring system to different game\nparameters, enabling comprehensive evaluation of robustness, generalizability,\nand strategies for improvement. Our results indicate that GPT-3.5 demonstrates\nstrong robustness but limited generalizability, which can be enhanced using\nmethods like Chain-of-Thought. We also evaluate 13 LLMs from 6 model families,\nincluding GPT-3.5, GPT-4, Gemini, LLaMA-3.1, Mixtral, and Qwen-2.\nGemini-1.5-Pro outperforms others, scoring of $69.8$ out of $100$, followed by\nLLaMA-3.1-70B ($65.9$) and Mixtral-8x22B ($62.4$). Our code and experimental\nresults are publicly available at https://github.com/CUHK-ARISE/GAMABench.\n","authors":["Jen-tse Huang","Eric John Li","Man Ho Lam","Tian Liang","Wenxuan Wang","Youliang Yuan","Wenxiang Jiao","Xing Wang","Zhaopeng Tu","Michael R. Lyu"],"pdf_url":"https://arxiv.org/pdf/2403.11807v7.pdf","comment":"Accepted to ICLR 2025; 11 pages of main text; 26 pages of appendices;\n  Included models: GPT-3.5-{0613, 1106, 0125}, GPT-4-0125, GPT-4o-0806,\n  Gemini-{1.0, 1.5)-Pro, LLaMA-3.1-{7, 70, 405}B, Mixtral-8x{7, 22}B,\n  Qwen-2-72B"},{"id":"http://arxiv.org/abs/2503.04713v1","updated":"2025-03-06T18:57:40Z","published":"2025-03-06T18:57:40Z","title":"Scaling Rich Style-Prompted Text-to-Speech Datasets","summary":"  We introduce Paralinguistic Speech Captions (ParaSpeechCaps), a large-scale\ndataset that annotates speech utterances with rich style captions. While rich\nabstract tags (e.g. guttural, nasal, pained) have been explored in small-scale\nhuman-annotated datasets, existing large-scale datasets only cover basic tags\n(e.g. low-pitched, slow, loud). We combine off-the-shelf text and speech\nembedders, classifiers and an audio language model to automatically scale rich\ntag annotations for the first time. ParaSpeechCaps covers a total of 59 style\ntags, including both speaker-level intrinsic tags and utterance-level\nsituational tags. It consists of 342 hours of human-labelled data (PSC-Base)\nand 2427 hours of automatically annotated data (PSC-Scaled). We finetune\nParler-TTS, an open-source style-prompted TTS model, on ParaSpeechCaps, and\nachieve improved style consistency (+7.9% Consistency MOS) and speech quality\n(+15.5% Naturalness MOS) over the best performing baseline that combines\nexisting rich style tag datasets. We ablate several of our dataset design\nchoices to lay the foundation for future work in this space. Our dataset,\nmodels and code are released at https://github.com/ajd12342/paraspeechcaps .\n","authors":["Anuj Diwan","Zhisheng Zheng","David Harwath","Eunsol Choi"],"pdf_url":"https://arxiv.org/pdf/2503.04713v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.04697v1","updated":"2025-03-06T18:43:29Z","published":"2025-03-06T18:43:29Z","title":"L1: Controlling How Long A Reasoning Model Thinks With Reinforcement\n  Learning","summary":"  Reasoning language models have shown an uncanny ability to improve\nperformance at test-time by ``thinking longer''-that is, by generating longer\nchain-of-thought sequences and hence using more compute. However, the length of\ntheir chain-of-thought reasoning is not controllable, making it impossible to\nallocate test-time compute to achieve a desired level of performance. We\nintroduce Length Controlled Policy Optimization (LCPO), a simple reinforcement\nlearning method that optimizes for accuracy and adherence to user-specified\nlength constraints. We use LCPO to train L1, a reasoning language model that\nproduces outputs satisfying a length constraint given in its prompt. L1's\nlength control allows for smoothly trading off computational cost and accuracy\non a wide range of tasks, and outperforms the state-of-the-art S1 method for\nlength control. Furthermore, we uncover an unexpected short chain-of-thought\ncapability in models trained with LCPO. For instance, our 1.5B L1 model\nsurpasses GPT-4o at equal reasoning lengths. Overall, LCPO enables precise\ncontrol over reasoning length, allowing for fine-grained allocation of\ntest-time compute and accuracy. We release code and models at\nhttps://www.cmu-l3.github.io/l1\n","authors":["Pranjal Aggarwal","Sean Welleck"],"pdf_url":"https://arxiv.org/pdf/2503.04697v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.02694v3","updated":"2025-03-06T18:41:54Z","published":"2024-10-03T17:20:11Z","title":"HELMET: How to Evaluate Long-Context Language Models Effectively and\n  Thoroughly","summary":"  Many benchmarks exist for evaluating long-context language models (LCLMs),\nyet developers often rely on synthetic tasks such as needle-in-a-haystack\n(NIAH) or an arbitrary subset of tasks. However, it remains unclear whether\nthese benchmarks reflect the diverse downstream applications of LCLMs, and such\ninconsistencies further complicate model comparison. We investigate the\nunderlying reasons behind these practices and find that existing benchmarks\noften provide noisy signals due to limited coverage of applications,\ninsufficient context lengths, unreliable metrics, and incompatibility with base\nmodels. In this work, we introduce HELMET (How to Evaluate Long-context Models\nEffectively and Thoroughly), a comprehensive benchmark encompassing seven\ndiverse, application-centric categories. We also address several issues in\nprevious benchmarks by adding controllable lengths up to 128K tokens,\nmodel-based evaluation for reliable metrics, and few-shot prompting for\nrobustly evaluating base models. Consequently, we demonstrate that HELMET\noffers more reliable and consistent rankings of frontier LCLMs. Through a\ncomprehensive study of 59 LCLMs, we find that (1) synthetic tasks like NIAH do\nnot reliably predict downstream performance; (2) the diverse categories in\nHELMET exhibit distinct trends and low correlations with each other; and (3)\nwhile most LCLMs achieve perfect NIAH scores, open-source models significantly\nlag behind closed ones when tasks require full-context reasoning or following\ncomplex instructions -- the gap widens as length increases. Finally, we\nrecommend using our RAG tasks for fast model development, as they are easy to\nrun and better predict other downstream performance; ultimately, we advocate\nfor a holistic evaluation across diverse tasks.\n","authors":["Howard Yen","Tianyu Gao","Minmin Hou","Ke Ding","Daniel Fleischer","Peter Izsak","Moshe Wasserblat","Danqi Chen"],"pdf_url":"https://arxiv.org/pdf/2410.02694v3.pdf","comment":"ICLR 2025. Project page: https://princeton-nlp.github.io/HELMET/"},{"id":"http://arxiv.org/abs/2503.04693v1","updated":"2025-03-06T18:40:00Z","published":"2025-03-06T18:40:00Z","title":"UIPE: Enhancing LLM Unlearning by Removing Knowledge Related to\n  Forgetting Targets","summary":"  Large Language Models (LLMs) inevitably acquire harmful information during\ntraining on massive datasets. LLM unlearning aims to eliminate the influence of\nsuch harmful information while maintaining the model's overall performance.\nExisting unlearning methods, represented by gradient ascent-based approaches,\nprimarily focus on forgetting target data while overlooking the crucial impact\nof logically related knowledge on the effectiveness of unlearning. In this\npaper, through both theoretical and experimental analyses, we first demonstrate\nthat a key reason for the suboptimal unlearning performance is that models can\nreconstruct the target content through reasoning with logically related\nknowledge. To address this issue, we propose Unlearning Improvement via\nParameter Extrapolation (UIPE), a method that removes knowledge highly\ncorrelated with the forgetting targets. Experimental results show that UIPE\nsignificantly enhances the performance of various mainstream LLM unlearning\nmethods on the TOFU benchmark.\n","authors":["Wenyu Wang","Mengqi Zhang","Xiaotian Ye","Zhaochun Ren","Zhumin Chen","Pengjie Ren"],"pdf_url":"https://arxiv.org/pdf/2503.04693v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.04691v1","updated":"2025-03-06T18:35:39Z","published":"2025-03-06T18:35:39Z","title":"Quantifying the Reasoning Abilities of LLMs on Real-world Clinical Cases","summary":"  The latest reasoning-enhanced large language models (reasoning LLMs), such as\nDeepSeek-R1 and OpenAI-o3, have demonstrated remarkable success. However, the\napplication of such reasoning enhancements to the highly professional medical\ndomain has not been clearly evaluated, particularly regarding with not only\nassessing the final generation but also examining the quality of their\nreasoning processes. In this study, we present MedR-Bench, a reasoning-focused\nmedical evaluation benchmark comprising 1,453 structured patient cases with\nreasoning references mined from case reports. Our benchmark spans 13 body\nsystems and 10 specialty disorders, encompassing both common and rare diseases.\nIn our evaluation, we introduce a versatile framework consisting of three\ncritical clinical stages: assessment recommendation, diagnostic\ndecision-making, and treatment planning, comprehensively capturing the LLMs'\nperformance across the entire patient journey in healthcare. For metrics, we\npropose a novel agentic system, Reasoning Evaluator, designed to automate and\nobjectively quantify free-text reasoning responses in a scalable manner from\nthe perspectives of efficiency, factuality, and completeness by dynamically\nsearching and performing cross-referencing checks. As a result, we assess five\nstate-of-the-art reasoning LLMs, including DeepSeek-R1, OpenAI-o3-mini, and\nothers. Our results reveal that current LLMs can handle relatively simple\ndiagnostic tasks with sufficient critical assessment results, achieving\naccuracy generally over 85%. However, they still struggle with more complex\ntasks, such as assessment recommendation and treatment planning. In reasoning,\ntheir reasoning processes are generally reliable, with factuality scores\nexceeding 90%, though they often omit critical reasoning steps. Our study\nclearly reveals further development directions for current clinical LLMs.\n","authors":["Pengcheng Qiu","Chaoyi Wu","Shuyu Liu","Weike Zhao","Ya Zhang","Yanfeng Wang","Weidi Xie"],"pdf_url":"https://arxiv.org/pdf/2503.04691v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.04685v1","updated":"2025-03-06T18:27:41Z","published":"2025-03-06T18:27:41Z","title":"DIMSUM: Discourse in Mathematical Reasoning as a Supervision Module","summary":"  We look at reasoning on GSM8k, a dataset of short texts presenting primary\nschool, math problems. We find, with Mirzadeh et al. (2024), that current LLM\nprogress on the data set may not be explained by better reasoning but by\nexposure to a broader pretraining data distribution. We then introduce a novel\ninformation source for helping models with less data or inferior training\nreason better: discourse structure. We show that discourse structure improves\nperformance for models like Llama2 13b by up to 160%. Even for models that have\nmost likely memorized the data set, adding discourse structural information to\nthe model still improves predictions and dramatically improves large model\nperformance on out of distribution examples.\n","authors":["Krish Sharma","Niyar R Barman","Nicholas Asher","Akshay Chaturvedi"],"pdf_url":"https://arxiv.org/pdf/2503.04685v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.04675v1","updated":"2025-03-06T18:12:33Z","published":"2025-03-06T18:12:33Z","title":"LLM-guided Plan and Retrieval: A Strategic Alignment for Interpretable\n  User Satisfaction Estimation in Dialogue","summary":"  Understanding user satisfaction with conversational systems, known as User\nSatisfaction Estimation (USE), is essential for assessing dialogue quality and\nenhancing user experiences. However, existing methods for USE face challenges\ndue to limited understanding of underlying reasons for user dissatisfaction and\nthe high costs of annotating user intentions. To address these challenges, we\npropose PRAISE (Plan and Retrieval Alignment for Interpretable Satisfaction\nEstimation), an interpretable framework for effective user satisfaction\nprediction. PRAISE operates through three key modules. The Strategy Planner\ndevelops strategies, which are natural language criteria for classifying user\nsatisfaction. The Feature Retriever then incorporates knowledge on user\nsatisfaction from Large Language Models (LLMs) and retrieves relevance features\nfrom utterances. Finally, the Score Analyzer evaluates strategy predictions and\nclassifies user satisfaction. Experimental results demonstrate that PRAISE\nachieves state-of-the-art performance on three benchmarks for the USE task.\nBeyond its superior performance, PRAISE offers additional benefits. It enhances\ninterpretability by providing instance-level explanations through effective\nalignment of utterances with strategies. Moreover, PRAISE operates more\nefficiently than existing approaches by eliminating the need for LLMs during\nthe inference phase.\n","authors":["Sangyeop Kim","Sohhyung Park","Jaewon Jung","Jinseok Kim","Sungzoon Cho"],"pdf_url":"https://arxiv.org/pdf/2503.04675v1.pdf","comment":"Accepted by NAACL 2025"},{"id":"http://arxiv.org/abs/2502.02067v2","updated":"2025-03-06T18:09:38Z","published":"2025-02-04T07:32:39Z","title":"AdaptBot: Combining LLM with Knowledge Graphs and Human Input for\n  Generic-to-Specific Task Decomposition and Knowledge Refinement","summary":"  An embodied agent assisting humans is often asked to complete new tasks, and\nthere may not be sufficient time or labeled examples to train the agent to\nperform these new tasks. Large Language Models (LLMs) trained on considerable\nknowledge across many domains can be used to predict a sequence of abstract\nactions for completing such tasks, although the agent may not be able to\nexecute this sequence due to task-, agent-, or domain-specific constraints. Our\nframework addresses these challenges by leveraging the generic predictions\nprovided by LLM and the prior domain knowledge encoded in a Knowledge Graph\n(KG), enabling an agent to quickly adapt to new tasks. The robot also solicits\nand uses human input as needed to refine its existing knowledge. Based on\nexperimental evaluation in the context of cooking and cleaning tasks in\nsimulation domains, we demonstrate that the interplay between LLM, KG, and\nhuman input leads to substantial performance gains compared with just using the\nLLM. Project website{\\S}: https://sssshivvvv.github.io/adaptbot/\n","authors":["Shivam Singh","Karthik Swaminathan","Nabanita Dash","Ramandeep Singh","Snehasis Banerjee","Mohan Sridharan","Madhava Krishna"],"pdf_url":"https://arxiv.org/pdf/2502.02067v2.pdf","comment":"Accepted to IEEE International Conference on Robotics and Automation\n  (ICRA) 2025"},{"id":"http://arxiv.org/abs/2503.04667v1","updated":"2025-03-06T17:59:51Z","published":"2025-03-06T17:59:51Z","title":"An Information-theoretic Multi-task Representation Learning Framework\n  for Natural Language Understanding","summary":"  This paper proposes a new principled multi-task representation learning\nframework (InfoMTL) to extract noise-invariant sufficient representations for\nall tasks. It ensures sufficiency of shared representations for all tasks and\nmitigates the negative effect of redundant features, which can enhance language\nunderstanding of pre-trained language models (PLMs) under the multi-task\nparadigm. Firstly, a shared information maximization principle is proposed to\nlearn more sufficient shared representations for all target tasks. It can avoid\nthe insufficiency issue arising from representation compression in the\nmulti-task paradigm. Secondly, a task-specific information minimization\nprinciple is designed to mitigate the negative effect of potential redundant\nfeatures in the input for each task. It can compress task-irrelevant redundant\ninformation and preserve necessary information relevant to the target for\nmulti-task prediction. Experiments on six classification benchmarks show that\nour method outperforms 12 comparative multi-task methods under the same\nmulti-task settings, especially in data-constrained and noisy scenarios.\nExtensive experiments demonstrate that the learned representations are more\nsufficient, data-efficient, and robust.\n","authors":["Dou Hu","Lingwei Wei","Wei Zhou","Songlin Hu"],"pdf_url":"https://arxiv.org/pdf/2503.04667v1.pdf","comment":"11 pages, accepted to AAAI 2025 (main conference), the code is\n  available at https://github.com/zerohd4869/InfoMTL"},{"id":"http://arxiv.org/abs/2502.16600v4","updated":"2025-03-06T17:56:40Z","published":"2025-02-23T15:00:53Z","title":"Diagnosing Moral Reasoning Acquisition in Language Models: Pragmatics\n  and Generalization","summary":"  Ensuring that Large Language Models (LLMs) return just responses which adhere\nto societal values is crucial for their broader application. Prior research has\nshown that LLMs often fail to perform satisfactorily on tasks requiring moral\ncognizance, such as ethics-based judgments. While current approaches have\nfocused on fine-tuning LLMs with curated datasets to improve their capabilities\non such tasks, choosing the optimal learning paradigm to enhance the ethical\nresponses of LLMs remains an open research debate. In this work, we aim to\naddress this fundamental question: can current learning paradigms enable LLMs\nto acquire sufficient moral reasoning capabilities? Drawing from distributional\nsemantics theory and the pragmatic nature of moral discourse, our analysis\nindicates that performance improvements follow a mechanism similar to that of\nsemantic-level tasks, and therefore remain affected by the pragmatic nature of\nmorals latent in discourse, a phenomenon we name the pragmatic dilemma. We\nconclude that this pragmatic dilemma imposes significant limitations on the\ngeneralization ability of current learning paradigms, making it the primary\nbottleneck for moral reasoning acquisition in LLMs.\n","authors":["Guangliang Liu","Lei Jiang","Xitong Zhang","Kristen Marie Johnson"],"pdf_url":"https://arxiv.org/pdf/2502.16600v4.pdf","comment":null},{"id":"http://arxiv.org/abs/2406.00799v6","updated":"2025-03-06T17:43:10Z","published":"2024-06-02T16:53:21Z","title":"Get my drift? Catching LLM Task Drift with Activation Deltas","summary":"  LLMs are commonly used in retrieval-augmented applications to execute user\ninstructions based on data from external sources. For example, modern search\nengines use LLMs to answer queries based on relevant search results; email\nplugins summarize emails by processing their content through an LLM. However,\nthe potentially untrusted provenance of these data sources can lead to prompt\ninjection attacks, where the LLM is manipulated by natural language\ninstructions embedded in the external data, causing it to deviate from the\nuser's original instruction(s). We define this deviation as task drift. Task\ndrift is a significant concern as it allows attackers to exfiltrate data or\ninfluence the LLM's output for other users. We study LLM activations as a\nsolution to detect task drift, showing that activation deltas - the difference\nin activations before and after processing external data - are strongly\ncorrelated with this phenomenon. Through two probing methods, we demonstrate\nthat a simple linear classifier can detect drift with near-perfect ROC AUC on\nan out-of-distribution test set. We evaluate these methods by making minimal\nassumptions about how users' tasks, system prompts, and attacks can be phrased.\nWe observe that this approach generalizes surprisingly well to unseen task\ndomains, such as prompt injections, jailbreaks, and malicious instructions,\nwithout being trained on any of these attacks. Interestingly, the fact that\nthis solution does not require any modifications to the LLM (e.g.,\nfine-tuning), as well as its compatibility with existing meta-prompting\nsolutions, makes it cost-efficient and easy to deploy. To encourage further\nresearch on activation-based task inspection, decoding, and interpretability,\nwe release our large-scale TaskTracker toolkit, featuring a dataset of over\n500K instances, representations from six SoTA language models, and a suite of\ninspection tools.\n","authors":["Sahar Abdelnabi","Aideen Fay","Giovanni Cherubin","Ahmed Salem","Mario Fritz","Andrew Paverd"],"pdf_url":"https://arxiv.org/pdf/2406.00799v6.pdf","comment":"SaTML 2025"},{"id":"http://arxiv.org/abs/2503.04647v1","updated":"2025-03-06T17:33:01Z","published":"2025-03-06T17:33:01Z","title":"Implicit Cross-Lingual Rewarding for Efficient Multilingual Preference\n  Alignment","summary":"  Direct Preference Optimization (DPO) has become a prominent method for\naligning Large Language Models (LLMs) with human preferences. While DPO has\nenabled significant progress in aligning English LLMs, multilingual preference\nalignment is hampered by data scarcity. To address this, we propose a novel\napproach that $\\textit{captures}$ learned preferences from well-aligned English\nmodels by implicit rewards and $\\textit{transfers}$ them to other languages\nthrough iterative training. Specifically, we derive an implicit reward model\nfrom the logits of an English DPO-aligned model and its corresponding reference\nmodel. This reward model is then leveraged to annotate preference relations in\ncross-lingual instruction-following pairs, using English instructions to\nevaluate multilingual responses. The annotated data is subsequently used for\nmultilingual DPO fine-tuning, facilitating preference knowledge transfer from\nEnglish to other languages. Fine-tuning Llama3 for two iterations resulted in a\n12.72% average improvement in Win Rate and a 5.97% increase in Length Control\nWin Rate across all training languages on the X-AlpacaEval leaderboard. Our\nfindings demonstrate that leveraging existing English-aligned models can enable\nefficient and effective multilingual preference alignment, significantly\nreducing the need for extensive multilingual preference data. The code is\navailable at https://github.com/ZNLP/Implicit-Cross-Lingual-Rewarding\n","authors":["Wen Yang","Junhong Wu","Chen Wang","Chengqing Zong","Jiajun Zhang"],"pdf_url":"https://arxiv.org/pdf/2503.04647v1.pdf","comment":"Work in progress"},{"id":"http://arxiv.org/abs/2503.04644v1","updated":"2025-03-06T17:32:22Z","published":"2025-03-06T17:32:22Z","title":"IFIR: A Comprehensive Benchmark for Evaluating Instruction-Following in\n  Expert-Domain Information Retrieval","summary":"  We introduce IFIR, the first comprehensive benchmark designed to evaluate\ninstruction-following information retrieval (IR) in expert domains. IFIR\nincludes 2,426 high-quality examples and covers eight subsets across four\nspecialized domains: finance, law, healthcare, and science literature. Each\nsubset addresses one or more domain-specific retrieval tasks, replicating\nreal-world scenarios where customized instructions are critical. IFIR enables a\ndetailed analysis of instruction-following retrieval capabilities by\nincorporating instructions at different levels of complexity. We also propose a\nnovel LLM-based evaluation method to provide a more precise and reliable\nassessment of model performance in following instructions. Through extensive\nexperiments on 15 frontier retrieval models, including those based on LLMs, our\nresults reveal that current models face significant challenges in effectively\nfollowing complex, domain-specific instructions. We further provide in-depth\nanalyses to highlight these limitations, offering valuable insights to guide\nfuture advancements in retriever development.\n","authors":["Tingyu Song","Guo Gan","Mingsheng Shang","Yilun Zhao"],"pdf_url":"https://arxiv.org/pdf/2503.04644v1.pdf","comment":"NAACL 2025 Main"},{"id":"http://arxiv.org/abs/2503.04636v1","updated":"2025-03-06T17:24:06Z","published":"2025-03-06T17:24:06Z","title":"Mark Your LLM: Detecting the Misuse of Open-Source Large Language Models\n  via Watermarking","summary":"  As open-source large language models (LLMs) like Llama3 become more capable,\nit is crucial to develop watermarking techniques to detect their potential\nmisuse. Existing watermarking methods either add watermarks during LLM\ninference, which is unsuitable for open-source LLMs, or primarily target\nclassification LLMs rather than recent generative LLMs. Adapting these\nwatermarks to open-source LLMs for misuse detection remains an open challenge.\nThis work defines two misuse scenarios for open-source LLMs: intellectual\nproperty (IP) violation and LLM Usage Violation. Then, we explore the\napplication of inference-time watermark distillation and backdoor watermarking\nin these contexts. We propose comprehensive evaluation methods to assess the\nimpact of various real-world further fine-tuning scenarios on watermarks and\nthe effect of these watermarks on LLM performance. Our experiments reveal that\nbackdoor watermarking could effectively detect IP Violation, while\ninference-time watermark distillation is applicable in both scenarios but less\nrobust to further fine-tuning and has a more significant impact on LLM\nperformance compared to backdoor watermarking. Exploring more advanced\nwatermarking methods for open-source LLMs to detect their misuse should be an\nimportant future direction.\n","authors":["Yijie Xu","Aiwei Liu","Xuming Hu","Lijie Wen","Hui Xiong"],"pdf_url":"https://arxiv.org/pdf/2503.04636v1.pdf","comment":"Accepted by the 1st Workshop on GenAI Watermarking, collocated with\n  ICLR 2025"},{"id":"http://arxiv.org/abs/2503.04629v1","updated":"2025-03-06T17:15:48Z","published":"2025-03-06T17:15:48Z","title":"SurveyForge: On the Outline Heuristics, Memory-Driven Generation, and\n  Multi-dimensional Evaluation for Automated Survey Writing","summary":"  Survey paper plays a crucial role in scientific research, especially given\nthe rapid growth of research publications. Recently, researchers have begun\nusing LLMs to automate survey generation for better efficiency. However, the\nquality gap between LLM-generated surveys and those written by human remains\nsignificant, particularly in terms of outline quality and citation accuracy. To\nclose these gaps, we introduce SurveyForge, which first generates the outline\nby analyzing the logical structure of human-written outlines and referring to\nthe retrieved domain-related articles. Subsequently, leveraging high-quality\npapers retrieved from memory by our scholar navigation agent, SurveyForge can\nautomatically generate and refine the content of the generated article.\nMoreover, to achieve a comprehensive evaluation, we construct SurveyBench,\nwhich includes 100 human-written survey papers for win-rate comparison and\nassesses AI-generated survey papers across three dimensions: reference,\noutline, and content quality. Experiments demonstrate that SurveyForge can\noutperform previous works such as AutoSurvey.\n","authors":["Xiangchao Yan","Shiyang Feng","Jiakang Yuan","Renqiu Xia","Bin Wang","Bo Zhang","Lei Bai"],"pdf_url":"https://arxiv.org/pdf/2503.04629v1.pdf","comment":"Code and dataset are available for downloading at:\n  https://github.com/Alpha-Innovator/SurveyForge 22 pages, 10 figures"},{"id":"http://arxiv.org/abs/2503.04625v1","updated":"2025-03-06T17:11:51Z","published":"2025-03-06T17:11:51Z","title":"START: Self-taught Reasoner with Tools","summary":"  Large reasoning models (LRMs) like OpenAI-o1 and DeepSeek-R1 have\ndemonstrated remarkable capabilities in complex reasoning tasks through the\nutilization of long Chain-of-thought (CoT). However, these models often suffer\nfrom hallucinations and inefficiencies due to their reliance solely on internal\nreasoning processes. In this paper, we introduce START (Self-Taught Reasoner\nwith Tools), a novel tool-integrated long CoT reasoning LLM that significantly\nenhances reasoning capabilities by leveraging external tools. Through code\nexecution, START is capable of performing complex computations, self-checking,\nexploring diverse methods, and self-debugging, thereby addressing the\nlimitations of LRMs. The core innovation of START lies in its self-learning\nframework, which comprises two key techniques: 1) Hint-infer: We demonstrate\nthat inserting artificially designed hints (e.g., ``Wait, maybe using Python\nhere is a good idea.'') during the inference process of a LRM effectively\nstimulates its ability to utilize external tools without the need for any\ndemonstration data. Hint-infer can also serve as a simple and effective\nsequential test-time scaling method; 2) Hint Rejection Sampling Fine-Tuning\n(Hint-RFT): Hint-RFT combines Hint-infer and RFT by scoring, filtering, and\nmodifying the reasoning trajectories with tool invocation generated by a LRM\nvia Hint-infer, followed by fine-tuning the LRM. Through this framework, we\nhave fine-tuned the QwQ-32B model to achieve START. On PhD-level science QA\n(GPQA), competition-level math benchmarks (AMC23, AIME24, AIME25), and the\ncompetition-level code benchmark (LiveCodeBench), START achieves accuracy rates\nof 63.6%, 95.0%, 66.7%, 47.1%, and 47.3%, respectively. It significantly\noutperforms the base QwQ-32B and achieves performance comparable to the\nstate-of-the-art open-weight model R1-Distill-Qwen-32B and the proprietary\nmodel o1-Preview.\n","authors":["Chengpeng Li","Mingfeng Xue","Zhenru Zhang","Jiaxi Yang","Beichen Zhang","Xiang Wang","Bowen Yu","Binyuan Hui","Junyang Lin","Dayiheng Liu"],"pdf_url":"https://arxiv.org/pdf/2503.04625v1.pdf","comment":"38 pages, 5 figures and 6 tables"},{"id":"http://arxiv.org/abs/2503.04619v1","updated":"2025-03-06T17:05:33Z","published":"2025-03-06T17:05:33Z","title":"SynGraph: A Dynamic Graph-LLM Synthesis Framework for Sparse Streaming\n  User Sentiment Modeling","summary":"  User reviews on e-commerce platforms exhibit dynamic sentiment patterns\ndriven by temporal and contextual factors. Traditional sentiment analysis\nmethods focus on static reviews, failing to capture the evolving temporal\nrelationship between user sentiment rating and textual content. Sentiment\nanalysis on streaming reviews addresses this limitation by modeling and\npredicting the temporal evolution of user sentiments. However, it suffers from\ndata sparsity, manifesting in temporal, spatial, and combined forms. In this\npaper, we introduce SynGraph, a novel framework designed to address data\nsparsity in sentiment analysis on streaming reviews. SynGraph alleviates data\nsparsity by categorizing users into mid-tail, long-tail, and extreme scenarios\nand incorporating LLM-augmented enhancements within a dynamic graph-based\nstructure. Experiments on real-world datasets demonstrate its effectiveness in\naddressing sparsity and improving sentiment modeling in streaming reviews.\n","authors":["Xin Zhang","Qiyu Wei","Yingjie Zhu","Linhai Zhang","Deyu Zhou","Sophia Ananiadou"],"pdf_url":"https://arxiv.org/pdf/2503.04619v1.pdf","comment":"18 pages, 17 figures"},{"id":"http://arxiv.org/abs/2503.04618v1","updated":"2025-03-06T17:03:17Z","published":"2025-03-06T17:03:17Z","title":"Better Process Supervision with Bi-directional Rewarding Signals","summary":"  Process supervision, i.e., evaluating each step, is critical for complex\nlarge language model (LLM) reasoning and test-time searching with increased\ninference compute. Existing approaches, represented by process reward models\n(PRMs), primarily focus on rewarding signals up to the current step, exhibiting\na one-directional nature and lacking a mechanism to model the distance to the\nfinal target. To address this problem, we draw inspiration from the A*\nalgorithm, which states that an effective supervisory signal should\nsimultaneously consider the incurred cost and the estimated cost for reaching\nthe target. Building on this key insight, we introduce BiRM, a novel process\nsupervision model that not only evaluates the correctness of previous steps but\nalso models the probability of future success. We conduct extensive experiments\non mathematical reasoning tasks and demonstrate that BiRM provides more precise\nevaluations of LLM reasoning steps, achieving an improvement of 3.1% on\nGaokao2023 over PRM under the Best-of-N sampling method. Besides, in\nsearch-based strategies, BiRM provides more comprehensive guidance and\noutperforms ORM by 5.0% and PRM by 3.8% respectively on MATH-500.\n","authors":["Wenxiang Chen","Wei He","Zhiheng Xi","Honglin Guo","Boyang Hong","Jiazheng Zhang","Rui Zheng","Nijun Li","Tao Gui","Yun Li","Qi Zhang","Xuanjing Huang"],"pdf_url":"https://arxiv.org/pdf/2503.04618v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.04615v1","updated":"2025-03-06T16:59:18Z","published":"2025-03-06T16:59:18Z","title":"HalluCounter: Reference-free LLM Hallucination Detection in the Wild!","summary":"  Response consistency-based, reference-free hallucination detection (RFHD)\nmethods do not depend on internal model states, such as generation\nprobabilities or gradients, which Grey-box models typically rely on but are\ninaccessible in closed-source LLMs. However, their inability to capture\nquery-response alignment patterns often results in lower detection accuracy.\nAdditionally, the lack of large-scale benchmark datasets spanning diverse\ndomains remains a challenge, as most existing datasets are limited in size and\nscope. To this end, we propose HalluCounter, a novel reference-free\nhallucination detection method that utilizes both response-response and\nquery-response consistency and alignment patterns. This enables the training of\na classifier that detects hallucinations and provides a confidence score and an\noptimal response for user queries. Furthermore, we introduce HalluCounterEval,\na benchmark dataset comprising both synthetically generated and human-curated\nsamples across multiple domains. Our method outperforms state-of-the-art\napproaches by a significant margin, achieving over 90\\% average confidence in\nhallucination detection across datasets.\n","authors":["Ashok Urlana","Gopichand Kanumolu","Charaka Vinayak Kumar","Bala Mallikarjunarao Garlapati","Rahul Mishra"],"pdf_url":"https://arxiv.org/pdf/2503.04615v1.pdf","comment":"30 pages, 4 figures"},{"id":"http://arxiv.org/abs/2503.04611v1","updated":"2025-03-06T16:57:26Z","published":"2025-03-06T16:57:26Z","title":"Towards Data-Efficient Language Models: A Child-Inspired Approach to\n  Language Learning","summary":"  In this work, we explain our approach employed in the BabyLM Challenge, which\nuses various methods of training language models (LMs) with significantly less\ndata compared to traditional large language models (LLMs) and are inspired by\nhow human children learn. While a human child is exposed to far less linguistic\ninput than an LLM, they still achieve remarkable language understanding and\ngeneration abilities. To this end, we develop a model trained on a curated\ndataset consisting of 10 million words, primarily sourced from child-directed\ntranscripts. The 2024 BabyLM Challenge initial dataset of 10M words is filtered\nto 8.5M. Next, it is supplemented with a randomly selected subset of TVR\ndataset consisting of 1.5M words of television dialogues. The latter dataset\nensures that similar to children, the model is also exposed to language through\nmedia. Furthermore, we reduce the vocabulary size to 32,000 tokens, aligning it\nwith the limited vocabulary of children in the early stages of language\nacquisition. We use curriculum learning and is able to match the baseline on\ncertain benchmarks while surpassing the baseline on others. Additionally,\nincorporating common LLM training datasets, such as MADLAD-400, degrades\nperformance. These findings underscore the importance of dataset selection,\nvocabulary scaling, and curriculum learning in creating more data-efficient\nlanguage models that better mimic human learning processes.\n","authors":["Mohammad Amin Ghanizadeh","Mohammad Javad Dousti"],"pdf_url":"https://arxiv.org/pdf/2503.04611v1.pdf","comment":"5 pages"},{"id":"http://arxiv.org/abs/2503.04606v1","updated":"2025-03-06T16:53:14Z","published":"2025-03-06T16:53:14Z","title":"The Best of Both Worlds: Integrating Language Models and Diffusion\n  Models for Video Generation","summary":"  Recent advancements in text-to-video (T2V) generation have been driven by two\ncompeting paradigms: autoregressive language models and diffusion models.\nHowever, each paradigm has intrinsic limitations: language models struggle with\nvisual quality and error accumulation, while diffusion models lack semantic\nunderstanding and causal modeling. In this work, we propose LanDiff, a hybrid\nframework that synergizes the strengths of both paradigms through\ncoarse-to-fine generation. Our architecture introduces three key innovations:\n(1) a semantic tokenizer that compresses 3D visual features into compact 1D\ndiscrete representations through efficient semantic compression, achieving a\n$\\sim$14,000$\\times$ compression ratio; (2) a language model that generates\nsemantic tokens with high-level semantic relationships; (3) a streaming\ndiffusion model that refines coarse semantics into high-fidelity videos.\nExperiments show that LanDiff, a 5B model, achieves a score of 85.43 on the\nVBench T2V benchmark, surpassing the state-of-the-art open-source models\nHunyuan Video (13B) and other commercial models such as Sora, Keling, and\nHailuo. Furthermore, our model also achieves state-of-the-art performance in\nlong video generation, surpassing other open-source models in this field. Our\ndemo can be viewed at https://landiff.github.io/.\n","authors":["Aoxiong Yin","Kai Shen","Yichong Leng","Xu Tan","Xinyu Zhou","Juncheng Li","Siliang Tang"],"pdf_url":"https://arxiv.org/pdf/2503.04606v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.04598v1","updated":"2025-03-06T16:40:48Z","published":"2025-03-06T16:40:48Z","title":"HybridNorm: Towards Stable and Efficient Transformer Training via Hybrid\n  Normalization","summary":"  Transformers have become the de facto architecture for a wide range of\nmachine learning tasks, particularly in large language models (LLMs). Despite\ntheir remarkable performance, challenges remain in training deep transformer\nnetworks, especially regarding the location of layer normalization. While\nPre-Norm structures facilitate easier training due to their more prominent\nidentity path, they often yield suboptimal performance compared to Post-Norm.\nIn this paper, we propose $\\textbf{HybridNorm}$, a straightforward yet\neffective hybrid normalization strategy that integrates the advantages of both\nPre-Norm and Post-Norm approaches. Specifically, HybridNorm employs QKV\nnormalization within the attention mechanism and Post-Norm in the feed-forward\nnetwork (FFN) of each transformer block. This design not only stabilizes\ntraining but also enhances performance, particularly in the context of LLMs.\nComprehensive experiments in both dense and sparse architectures show that\nHybridNorm consistently outperforms both Pre-Norm and Post-Norm approaches,\nachieving state-of-the-art results across various benchmarks. These findings\nhighlight the potential of HybridNorm as a more stable and effective technique\nfor improving the training and performance of deep transformer models. %Code\nwill be made publicly available. Code is available at\nhttps://github.com/BryceZhuo/HybridNorm.\n","authors":["Zhijian Zhuo","Yutao Zeng","Ya Wang","Sijun Zhang","Jian Yang","Xiaoqing Li","Xun Zhou","Jinwen Ma"],"pdf_url":"https://arxiv.org/pdf/2503.04598v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.00053v3","updated":"2025-03-06T16:28:55Z","published":"2024-10-30T19:09:02Z","title":"ACC-Collab: An Actor-Critic Approach to Multi-Agent LLM Collaboration","summary":"  Large language models (LLMs) have demonstrated a remarkable ability to serve\nas general-purpose tools for various language-based tasks. Recent works have\ndemonstrated that the efficacy of such models can be improved through iterative\ndialog between multiple models. While these paradigms show promise in improving\nmodel efficacy, most works in this area treat collaboration as an emergent\nbehavior, rather than a learned behavior. In doing so, current multi-agent\nframeworks rely on collaborative behaviors to have been sufficiently trained\ninto off-the-shelf models. To address this limitation, we propose ACC-Collab,\nan Actor-Critic based learning framework to produce a two-agent team (an\nactor-agent and a critic-agent) specialized in collaboration. We demonstrate\nthat ACC-Collab outperforms SotA multi-agent techniques on a wide array of\nbenchmarks.\n","authors":["Andrew Estornell","Jean-Francois Ton","Yuanshun Yao","Yang Liu"],"pdf_url":"https://arxiv.org/pdf/2411.00053v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.02972v2","updated":"2025-03-06T16:16:07Z","published":"2025-03-04T19:57:47Z","title":"LINGOLY-TOO: Disentangling Memorisation from Reasoning with Linguistic\n  Templatisation and Orthographic Obfuscation","summary":"  Assessing the reasoning capabilities of large language models (LLMs) is\nsusceptible to overestimation due to data exposure of evaluation benchmarks. We\nintroduce a framework for producing linguistic reasoning problems that reduces\nthe effect of memorisation in model performance estimates and apply this\nframework to develop LINGOLY-TOO, a challenging benchmark for linguistic\nreasoning. By developing orthographic templates, we dynamically obfuscate the\nwriting systems of real languages to generate numerousquestion variations.\nThese variations preserve the reasoning steps required for each solution while\nreducing the likelihood of specific problem instances appearing in model\ntraining data. Our experiments demonstrate that frontier models, including\nClaud 3.7 Sonnet, o1-preview and DeepSeek R1, struggle with advanced reasoning.\nOur analysis also shows that LLMs exhibit noticeable variance in accuracy\nacross permutations of the same problem, and on average perform better on\nquestions appearing in their original orthography. Our findings highlight the\nopaque nature of response generation in LLMs and provide evidence that prior\ndata exposure contributes to over estimating the reasoning capabilities of\nfrontier models.\n","authors":["Jude Khouja","Karolina Korgul","Simi Hellsten","Lingyi Yang","Vlad Neacs","Harry Mayne","Ryan Kearns","Andrew Bean","Adam Mahdi"],"pdf_url":"https://arxiv.org/pdf/2503.02972v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2502.17504v2","updated":"2025-03-06T16:14:45Z","published":"2025-02-21T19:22:10Z","title":"Protein Large Language Models: A Comprehensive Survey","summary":"  Protein-specific large language models (Protein LLMs) are revolutionizing\nprotein science by enabling more efficient protein structure prediction,\nfunction annotation, and design. While existing surveys focus on specific\naspects or applications, this work provides the first comprehensive overview of\nProtein LLMs, covering their architectures, training datasets, evaluation\nmetrics, and diverse applications. Through a systematic analysis of over 100\narticles, we propose a structured taxonomy of state-of-the-art Protein LLMs,\nanalyze how they leverage large-scale protein sequence data for improved\naccuracy, and explore their potential in advancing protein engineering and\nbiomedical research. Additionally, we discuss key challenges and future\ndirections, positioning Protein LLMs as essential tools for scientific\ndiscovery in protein science. Resources are maintained at\nhttps://github.com/Yijia-Xiao/Protein-LLM-Survey.\n","authors":["Yijia Xiao","Wanjia Zhao","Junkai Zhang","Yiqiao Jin","Han Zhang","Zhicheng Ren","Renliang Sun","Haixin Wang","Guancheng Wan","Pan Lu","Xiao Luo","Yu Zhang","James Zou","Yizhou Sun","Wei Wang"],"pdf_url":"https://arxiv.org/pdf/2502.17504v2.pdf","comment":"24 pages, 4 figures, 5 tables"},{"id":"http://arxiv.org/abs/2404.12464v9","updated":"2025-03-06T16:13:04Z","published":"2024-04-18T18:48:50Z","title":"NormAd: A Framework for Measuring the Cultural Adaptability of Large\n  Language Models","summary":"  To be effectively and safely deployed to global user populations, large\nlanguage models (LLMs) may need to adapt outputs to user values and cultures,\nnot just know about them. We introduce NormAd, an evaluation framework to\nassess LLMs' cultural adaptability, specifically measuring their ability to\njudge social acceptability across varying levels of cultural norm specificity,\nfrom abstract values to explicit social norms. As an instantiation of our\nframework, we create NormAd-Eti, a benchmark of 2.6k situational descriptions\nrepresenting social-etiquette related cultural norms from 75 countries. Through\ncomprehensive experiments on NormAd-Eti, we find that LLMs struggle to\naccurately judge social acceptability across these varying degrees of cultural\ncontexts and show stronger adaptability to English-centric cultures over those\nfrom the Global South. Even in the simplest setting where the relevant social\nnorms are provided, the best LLMs' performance (< 82\\%) lags behind humans (>\n95\\%). In settings with abstract values and country information, model\nperformance drops substantially (< 60\\%), while human accuracy remains high (>\n90\\%). Furthermore, we find that models are better at recognizing socially\nacceptable versus unacceptable situations. Our findings showcase the current\npitfalls in socio-cultural reasoning of LLMs which hinder their adaptability\nfor global audiences.\n","authors":["Abhinav Rao","Akhila Yerukola","Vishwa Shah","Katharina Reinecke","Maarten Sap"],"pdf_url":"https://arxiv.org/pdf/2404.12464v9.pdf","comment":"Accepted at NAACL 2025"},{"id":"http://arxiv.org/abs/2503.01804v2","updated":"2025-03-06T16:07:43Z","published":"2025-03-03T18:33:46Z","title":"$\\texttt{SEM-CTRL}$: Semantically Controlled Decoding","summary":"  Ensuring both syntactic and semantic correctness in Large Language Model\n(LLM) outputs remains a significant challenge, despite being critical for\nreal-world deployment. In this paper, we introduce $\\texttt{SEM-CTRL}$, a\nunified approach that enforces rich context-sensitive constraints and task- and\ninstance-specific semantics directly on an LLM decoder. Our approach integrates\ntoken-level MCTS, which is guided by specific syntactic and semantic\nconstraints. The constraints over the desired outputs are expressed using\nAnswer Set Grammars -- a logic-based formalism that generalizes\ncontext-sensitive grammars while incorporating background knowledge to\nrepresent task-specific semantics. We show that our approach guarantees correct\ncompletions for any off-the-shelf LLM without the need for fine-tuning. We\nevaluate $\\texttt{SEM-CTRL}$ on a range of tasks, including synthetic grammar\nsynthesis, combinatorial reasoning, and planning. Our results demonstrate that\n$\\texttt{SEM-CTRL}$ allows small pre-trained LLMs to efficiently outperform\nlarger variants and state-of-the-art reasoning models (e.g., o1-preview) while\nsimultaneously guaranteeing solution correctness.\n","authors":["Mohammad Albinhassan","Pranava Madhyastha","Alessandra Russo"],"pdf_url":"https://arxiv.org/pdf/2503.01804v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.00153v2","updated":"2025-03-06T15:50:28Z","published":"2024-09-30T18:52:53Z","title":"Beyond Single Concept Vector: Modeling Concept Subspace in LLMs with\n  Gaussian Distribution","summary":"  Probing learned concepts in large language models (LLMs) is crucial for\nunderstanding how semantic knowledge is encoded internally. Training linear\nclassifiers on probing tasks is a principle approach to denote the vector of a\ncertain concept in the representation space. However, the single vector\nidentified for a concept varies with both data and training, making it less\nrobust and weakening its effectiveness in real-world applications. To address\nthis challenge, we propose an approach to approximate the subspace representing\na specific concept. Built on linear probing classifiers, we extend the concept\nvectors into Gaussian Concept Subspace (GCS). We demonstrate GCS's\neffectiveness through measuring its faithfulness and plausibility across\nmultiple LLMs with different sizes and architectures. Additionally, we use\nrepresentation intervention tasks to showcase its efficacy in real-world\napplications such as emotion steering. Experimental results indicate that GCS\nconcept vectors have the potential to balance steering performance and\nmaintaining the fluency in natural language generation tasks.\n","authors":["Haiyan Zhao","Heng Zhao","Bo Shen","Ali Payani","Fan Yang","Mengnan Du"],"pdf_url":"https://arxiv.org/pdf/2410.00153v2.pdf","comment":"Accepted by ICLR 2025"},{"id":"http://arxiv.org/abs/2503.04556v1","updated":"2025-03-06T15:47:19Z","published":"2025-03-06T15:47:19Z","title":"Compositional Causal Reasoning Evaluation in Language Models","summary":"  Causal reasoning and compositional reasoning are two core aspirations in\ngenerative AI. Measuring the extent of these behaviors requires principled\nevaluation methods. We explore a unified perspective that considers both\nbehaviors simultaneously, termed compositional causal reasoning (CCR): the\nability to infer how causal measures compose and, equivalently, how causal\nquantities propagate through graphs. We instantiate a framework for the\nsystematic evaluation of CCR for the average treatment effect and the\nprobability of necessity and sufficiency. As proof of concept, we demonstrate\nthe design of CCR tasks for language models in the LLama, Phi, and GPT\nfamilies. On a math word problem, our framework revealed a range of\ntaxonomically distinct error patterns. Additionally, CCR errors increased with\nthe complexity of causal paths for all models except o1.\n","authors":["Jacqueline R. M. A. Maasch","Alihan Hyk","Xinnuo Xu","Aditya V. Nori","Javier Gonzalez"],"pdf_url":"https://arxiv.org/pdf/2503.04556v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2502.09990v2","updated":"2025-03-06T15:38:31Z","published":"2025-02-14T08:22:51Z","title":"X-Boundary: Establishing Exact Safety Boundary to Shield LLMs from\n  Multi-Turn Jailbreaks without Compromising Usability","summary":"  Despite the rapid development of safety alignment techniques for LLMs,\ndefending against multi-turn jailbreaks is still a challenging task. In this\npaper, we conduct a comprehensive comparison, revealing that some existing\ndefense methods can improve the robustness of LLMs against multi-turn\njailbreaks but compromise usability, i.e., reducing general capabilities or\ncausing the over-refusal problem. From the perspective of mechanism\ninterpretability of LLMs, we discover that these methods fail to establish a\nboundary that exactly distinguishes safe and harmful feature representations.\nTherefore, boundary-safe representations close to harmful representations are\ninevitably disrupted, leading to a decline in usability. To address this issue,\nwe propose X-Boundary to push harmful representations away from boundary-safe\nrepresentations and obtain an exact distinction boundary. In this way, harmful\nrepresentations can be precisely erased without disrupting safe ones.\nExperimental results show that X-Boundary achieves state-of-the-art defense\nperformance against multi-turn jailbreaks, while reducing the over-refusal rate\nby about 20% and maintaining nearly complete general capability. Furthermore,\nwe theoretically prove and empirically verify that X-Boundary can accelerate\nthe convergence process during training. Please see our code at:\nhttps://github.com/AI45Lab/X-Boundary.\n","authors":["Xiaoya Lu","Dongrui Liu","Yi Yu","Luxin Xu","Jing Shao"],"pdf_url":"https://arxiv.org/pdf/2502.09990v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.04554v1","updated":"2025-03-06T15:37:31Z","published":"2025-03-06T15:37:31Z","title":"Compositional Translation: A Novel LLM-based Approach for Low-resource\n  Machine Translation","summary":"  The ability of generative large language models (LLMs) to perform in-context\nlearning has given rise to a large body of research into how best to prompt\nmodels for various natural language processing tasks. Machine Translation (MT)\nhas been shown to benefit from in-context examples, in particular when they are\nsemantically similar to the sentence to translate. In this paper, we propose a\nnew LLM-based translation paradigm, compositional translation, to replace naive\nfew-shot MT with similarity-based demonstrations. An LLM is used to decompose a\nsentence into simpler phrases, and then to translate each phrase with the help\nof retrieved demonstrations. Finally, the LLM is prompted to translate the\ninitial sentence with the help of the self-generated phrase-translation pairs.\nOur intuition is that this approach should improve translation because these\nshorter phrases should be intrinsically easier to translate and easier to match\nwith relevant examples. This is especially beneficial in low-resource\nscenarios, and more generally whenever the selection pool is small or out of\ndomain. We show that compositional translation boosts LLM translation\nperformance on a wide range of popular MT benchmarks, including FLORES 200,\nNTREX 128 and TICO-19. Code and outputs are available at\nhttps://github.com/ArmelRandy/compositional-translation\n","authors":["Armel Zebaze","Benot Sagot","Rachel Bawden"],"pdf_url":"https://arxiv.org/pdf/2503.04554v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2502.20984v2","updated":"2025-03-06T15:36:48Z","published":"2025-02-28T11:52:02Z","title":"UoR-NCL at SemEval-2025 Task 1: Using Generative LLMs and CLIP Models\n  for Multilingual Multimodal Idiomaticity Representation","summary":"  SemEval-2025 Task 1 focuses on ranking images based on their alignment with a\ngiven nominal compound that may carry idiomatic meaning in both English and\nBrazilian Portuguese. To address this challenge, this work uses generative\nlarge language models (LLMs) and multilingual CLIP models to enhance idiomatic\ncompound representations. LLMs generate idiomatic meanings for potentially\nidiomatic compounds, enriching their semantic interpretation. These meanings\nare then encoded using multilingual CLIP models, serving as representations for\nimage ranking. Contrastive learning and data augmentation techniques are\napplied to fine-tune these embeddings for improved performance. Experimental\nresults show that multimodal representations extracted through this method\noutperformed those based solely on the original nominal compounds. The\nfine-tuning approach shows promising outcomes but is less effective than using\nembeddings without fine-tuning. The source code used in this paper is available\nat https://github.com/tongwu17/SemEval-2025-Task1-UoR-NCL.\n","authors":["Thanet Markchom","Tong Wu","Liting Huang","Huizhi Liang"],"pdf_url":"https://arxiv.org/pdf/2502.20984v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.04548v1","updated":"2025-03-06T15:34:27Z","published":"2025-03-06T15:34:27Z","title":"An Empirical Study on Eliciting and Improving R1-like Reasoning Models","summary":"  In this report, we present the third technical report on the development of\nslow-thinking models as part of the STILL project. As the technical pathway\nbecomes clearer, scaling RL training has become a central technique for\nimplementing such reasoning models. We systematically experiment with and\ndocument the effects of various factors influencing RL training, conducting\nexperiments on both base models and fine-tuned models. Specifically, we\ndemonstrate that our RL training approach consistently improves the Qwen2.5-32B\nbase models, enhancing both response length and test accuracy. Furthermore, we\nshow that even when a model like DeepSeek-R1-Distill-Qwen-1.5B has already\nachieved a high performance level, it can be further refined through RL\ntraining, reaching an accuracy of 39.33% on AIME 2024. Beyond RL training, we\nalso explore the use of tool manipulation, finding that it significantly boosts\nthe reasoning performance of large reasoning models. This approach achieves a\nremarkable accuracy of 86.67% with greedy search on AIME 2024, underscoring its\neffectiveness in enhancing model capabilities. We release our resources at the\nSTILL project website: https://github.com/RUCAIBox/Slow_Thinking_with_LLMs.\n","authors":["Zhipeng Chen","Yingqian Min","Beichen Zhang","Jie Chen","Jinhao Jiang","Daixuan Cheng","Wayne Xin Zhao","Zheng Liu","Xu Miao","Yang Lu","Lei Fang","Zhongyuan Wang","Ji-Rong Wen"],"pdf_url":"https://arxiv.org/pdf/2503.04548v1.pdf","comment":"Technical Report on Slow Thinking with LLMs: Part III"},{"id":"http://arxiv.org/abs/2503.04543v1","updated":"2025-03-06T15:29:13Z","published":"2025-03-06T15:29:13Z","title":"Keeping Yourself is Important in Downstream Tuning Multimodal Large\n  Language Model","summary":"  Multi-modal Large Language Models (MLLMs) integrate visual and linguistic\nreasoning to address complex tasks such as image captioning and visual question\nanswering. While MLLMs demonstrate remarkable versatility, MLLMs appears\nlimited performance on special applications. But tuning MLLMs for downstream\ntasks encounters two key challenges: Task-Expert Specialization, where\ndistribution shifts between pre-training and target datasets constrain target\nperformance, and Open-World Stabilization, where catastrophic forgetting erases\nthe model general knowledge. In this work, we systematically review recent\nadvancements in MLLM tuning methodologies, classifying them into three\nparadigms: (I) Selective Tuning, (II) Additive Tuning, and (III)\nReparameterization Tuning. Furthermore, we benchmark these tuning strategies\nacross popular MLLM architectures and diverse downstream tasks to establish\nstandardized evaluation analysis and systematic tuning principles. Finally, we\nhighlight several open challenges in this domain and propose future research\ndirections. To facilitate ongoing progress in this rapidly evolving field, we\nprovide a public repository that continuously tracks developments:\nhttps://github.com/WenkeHuang/Awesome-MLLM-Tuning.\n","authors":["Wenke Huang","Jian Liang","Xianda Guo","Yiyang Fang","Guancheng Wan","Xuankun Rong","Chi Wen","Zekun Shi","Qingyun Li","Didi Zhu","Yanbiao Ma","Ke Liang","Bin Yang","He Li","Jiawei Shao","Mang Ye","Bo Du"],"pdf_url":"https://arxiv.org/pdf/2503.04543v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.07180v5","updated":"2025-03-06T15:26:56Z","published":"2024-11-11T17:57:30Z","title":"Gumbel Counterfactual Generation From Language Models","summary":"  Understanding and manipulating the causal generation mechanisms in language\nmodels is essential for controlling their behavior. Previous work has primarily\nrelied on techniques such as representation surgery -- e.g., model ablations or\nmanipulation of linear subspaces tied to specific concepts -- to\n\\emph{intervene} on these models. To understand the impact of interventions\nprecisely, it is useful to examine \\emph{counterfactuals} -- e.g., how a given\nsentence would have appeared had it been generated by the model following a\nspecific intervention. We highlight that counterfactual reasoning is\nconceptually distinct from interventions, as articulated in Pearl's causal\nhierarchy. Based on this observation, we propose a framework for generating\ntrue string counterfactuals by reformulating language models as a structural\nequation model using the Gumbel-max trick, which we called Gumbel\ncounterfactual generation. This reformulation allows us to model the joint\ndistribution over original strings and their counterfactuals resulting from the\nsame instantiation of the sampling noise. We develop an algorithm based on\nhindsight Gumbel sampling that allows us to infer the latent noise variables\nand generate counterfactuals of observed strings. Our experiments demonstrate\nthat the approach produces meaningful counterfactuals while at the same time\nshowing that commonly used intervention techniques have considerable undesired\nside effects.\n","authors":["Shauli Ravfogel","Anej Svete","Vsteinn Snbjarnarson","Ryan Cotterell"],"pdf_url":"https://arxiv.org/pdf/2411.07180v5.pdf","comment":"Accepted in ICLR 2025"},{"id":"http://arxiv.org/abs/2411.12580v2","updated":"2025-03-06T15:14:17Z","published":"2024-11-19T15:47:12Z","title":"Procedural Knowledge in Pretraining Drives Reasoning in Large Language\n  Models","summary":"  The capabilities and limitations of Large Language Models have been sketched\nout in great detail in recent years, providing an intriguing yet conflicting\npicture. On the one hand, LLMs demonstrate a general ability to solve problems.\nOn the other hand, they show surprising reasoning gaps when compared to humans,\ncasting doubt on the robustness of their generalisation strategies. The sheer\nvolume of data used in the design of LLMs has precluded us from applying the\nmethod traditionally used to measure generalisation: train-test set separation.\nTo overcome this, we study what kind of generalisation strategies LLMs employ\nwhen performing reasoning tasks by investigating the pretraining data they rely\non. For two models of different sizes (7B and 35B) and 2.5B of their\npretraining tokens, we identify what documents influence the model outputs for\nthree simple mathematical reasoning tasks and contrast this to the data that\nare influential for answering factual questions. We find that, while the models\nrely on mostly distinct sets of data for each factual question, a document\noften has a similar influence across different reasoning questions within the\nsame task, indicating the presence of procedural knowledge. We further find\nthat the answers to factual questions often show up in the most influential\ndata. However, for reasoning questions the answers usually do not show up as\nhighly influential, nor do the answers to the intermediate reasoning steps.\nWhen we characterise the top ranked documents for the reasoning questions\nqualitatively, we confirm that the influential documents often contain\nprocedural knowledge, like demonstrating how to obtain a solution using\nformulae or code. Our findings indicate that the approach to reasoning the\nmodels use is unlike retrieval, and more like a generalisable strategy that\nsynthesises procedural knowledge from documents doing a similar form of\nreasoning.\n","authors":["Laura Ruis","Maximilian Mozes","Juhan Bae","Siddhartha Rao Kamalakara","Dwarak Talupuru","Acyr Locatelli","Robert Kirk","Tim Rocktschel","Edward Grefenstette","Max Bartolo"],"pdf_url":"https://arxiv.org/pdf/2411.12580v2.pdf","comment":"Published at ICLR 2025"},{"id":"http://arxiv.org/abs/2503.00367v2","updated":"2025-03-06T15:08:32Z","published":"2025-03-01T06:29:00Z","title":"Approaching the Limits to EFL Writing Enhancement with AI-generated Text\n  and Diverse Learners","summary":"  Generative artificial intelligence (AI) chatbots, such as ChatGPT, are\nreshaping how English as a foreign language (EFL) students write since students\ncan compose texts by integrating their own words with AI-generated text. This\nstudy investigated how 59 Hong Kong secondary school students with varying\nlevels of academic achievement interacted with AI-generated text to compose a\nfeature article, exploring whether any interaction patterns benefited the\noverall quality of the article. Through content analysis, multiple linear\nregression and cluster analysis, we found the overall number of words --\nwhether AI- or human-generated -- is the main predictor of writing quality.\nHowever, the impact varies by students' competence to write independently, for\ninstance, by using their own words accurately and coherently to compose a text,\nand to follow specific interaction patterns with AI-generated text. Therefore,\nalthough composing texts with human words and AI-generated text may become\nprevalent in EFL writing classrooms, without educators' careful attention to\nEFL writing pedagogy and AI literacy, high-achieving students stand to benefit\nmore from using AI-generated text than low-achieving students.\n","authors":["David James Woo","Hengky Susanto","Chi Ho Yeung","Kai Guo"],"pdf_url":"https://arxiv.org/pdf/2503.00367v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.04490v1","updated":"2025-03-06T14:38:20Z","published":"2025-03-06T14:38:20Z","title":"Large Language Models in Bioinformatics: A Survey","summary":"  Large Language Models (LLMs) are revolutionizing bioinformatics, enabling\nadvanced analysis of DNA, RNA, proteins, and single-cell data. This survey\nprovides a systematic review of recent advancements, focusing on genomic\nsequence modeling, RNA structure prediction, protein function inference, and\nsingle-cell transcriptomics. Meanwhile, we also discuss several key challenges,\nincluding data scarcity, computational complexity, and cross-omics integration,\nand explore future directions such as multimodal learning, hybrid AI models,\nand clinical applications. By offering a comprehensive perspective, this paper\nunderscores the transformative potential of LLMs in driving innovations in\nbioinformatics and precision medicine.\n","authors":["Zhenyu Wang","Zikang Wang","Jiyue Jiang","Pengan Chen","Xiangyu Shi","Yu Li"],"pdf_url":"https://arxiv.org/pdf/2503.04490v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.04482v1","updated":"2025-03-06T14:30:55Z","published":"2025-03-06T14:30:55Z","title":"Generalized Interpolating Discrete Diffusion","summary":"  While state-of-the-art language models achieve impressive results through\nnext-token prediction, they have inherent limitations such as the inability to\nrevise already generated tokens. This has prompted exploration of alternative\napproaches such as discrete diffusion. However, masked diffusion, which has\nemerged as a popular choice due to its simplicity and effectiveness,\nreintroduces this inability to revise words. To overcome this, we generalize\nmasked diffusion and derive the theoretical backbone of a family of general\ninterpolating discrete diffusion (GIDD) processes offering greater flexibility\nin the design of the noising processes. Leveraging a novel diffusion ELBO, we\nachieve compute-matched state-of-the-art performance in diffusion language\nmodeling. Exploiting GIDD's flexibility, we explore a hybrid approach combining\nmasking and uniform noise, leading to improved sample quality and unlocking the\nability for the model to correct its own mistakes, an area where autoregressive\nmodels notoriously have struggled. Our code and models are open-source:\nhttps://github.com/dvruette/gidd/\n","authors":["Dimitri von Rtte","Janis Fluri","Yuhui Ding","Antonio Orvieto","Bernhard Schlkopf","Thomas Hofmann"],"pdf_url":"https://arxiv.org/pdf/2503.04482v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.04463v1","updated":"2025-03-06T14:15:07Z","published":"2025-03-06T14:15:07Z","title":"Guiding LLMs to Generate High-Fidelity and High-Quality Counterfactual\n  Explanations for Text Classification","summary":"  The need for interpretability in deep learning has driven interest in\ncounterfactual explanations, which identify minimal changes to an instance that\nchange a model's prediction. Current counterfactual (CF) generation methods\nrequire task-specific fine-tuning and produce low-quality text. Large Language\nModels (LLMs), though effective for high-quality text generation, struggle with\nlabel-flipping counterfactuals (i.e., counterfactuals that change the\nprediction) without fine-tuning. We introduce two simple classifier-guided\napproaches to support counterfactual generation by LLMs, eliminating the need\nfor fine-tuning while preserving the strengths of LLMs. Despite their\nsimplicity, our methods outperform state-of-the-art counterfactual generation\nmethods and are effective across different LLMs, highlighting the benefits of\nguiding counterfactual generation by LLMs with classifier information. We\nfurther show that data augmentation by our generated CFs can improve a\nclassifier's robustness. Our analysis reveals a critical issue in\ncounterfactual generation by LLMs: LLMs rely on parametric knowledge rather\nthan faithfully following the classifier.\n","authors":["Van Bach Nguyen","Christin Seifert","Jrg Schltterer"],"pdf_url":"https://arxiv.org/pdf/2503.04463v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.04449v1","updated":"2025-03-06T14:04:30Z","published":"2025-03-06T14:04:30Z","title":"Quantifying patterns of punctuation in modern Chinese prose","summary":"  Recent research shows that punctuation patterns in texts exhibit universal\nfeatures across languages. Analysis of Western classical literature reveals\nthat the distribution of spaces between punctuation marks aligns with a\ndiscrete Weibull distribution, typically used in survival analysis. By\nextending this analysis to Chinese literature represented here by three notable\ncontemporary works, it is shown that Zipf's law applies to Chinese texts\nsimilarly to Western texts, where punctuation patterns also improve adherence\nto the law. Additionally, the distance distribution between punctuation marks\nin Chinese texts follows the Weibull model, though larger spacing is less\nfrequent than in English translations. Sentence-ending punctuation,\nrepresenting sentence length, diverges more from this pattern, reflecting\ngreater flexibility in sentence length. This variability supports the formation\nof complex, multifractal sentence structures, particularly evident in Gao\nXingjian's \"Soul Mountain\". These findings demonstrate that both Chinese and\nWestern texts share universal punctuation and word distribution patterns,\nunderscoring their broad applicability across languages.\n","authors":["Micha Dolina","Jakub Dec","Stanisaw Drod","Jarosaw Kwapie","Jin Liu","Tomasz Stanisz"],"pdf_url":"https://arxiv.org/pdf/2503.04449v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.04439v1","updated":"2025-03-06T13:55:33Z","published":"2025-03-06T13:55:33Z","title":"A Dataset for Analysing News Framing in Chinese Media","summary":"  Framing is an essential device in news reporting, allowing the writer to\ninfluence public perceptions of current affairs. While there are existing\nautomatic news framing detection datasets in various languages, none of them\nfocus on news framing in the Chinese language which has complex character\nmeanings and unique linguistic features. This study introduces the first\nChinese News Framing dataset, to be used as either a stand-alone dataset or a\nsupplementary resource to the SemEval-2023 task 3 dataset. We detail its\ncreation and we run baseline experiments to highlight the need for such a\ndataset and create benchmarks for future research, providing results obtained\nthrough fine-tuning XLM-RoBERTa-Base and using GPT-4o in the zero-shot setting.\nWe find that GPT-4o performs significantly worse than fine-tuned XLM-RoBERTa\nacross all languages. For the Chinese language, we obtain an F1-micro (the\nperformance metric for SemEval task 3, subtask 2) score of 0.719 using only\nsamples from our Chinese News Framing dataset and a score of 0.753 when we\naugment the SemEval dataset with Chinese news framing samples. With positive\nnews frame detection results, this dataset is a valuable resource for detecting\nnews frames in the Chinese language and is a valuable supplement to the\nSemEval-2023 task 3 dataset.\n","authors":["Owen Cook","Yida Mu","Xinye Yang","Xingyi Song","Kalina Bontcheva"],"pdf_url":"https://arxiv.org/pdf/2503.04439v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2501.13959v2","updated":"2025-03-06T13:51:24Z","published":"2025-01-21T06:32:25Z","title":"Assisting Mathematical Formalization with A Learning-based Premise\n  Retriever","summary":"  Premise selection is a crucial yet challenging step in mathematical\nformalization, especially for users with limited experience. Due to the lack of\navailable formalization projects, existing approaches that leverage language\nmodels often suffer from data scarcity. In this work, we introduce an\ninnovative method for training a premise retriever to support the formalization\nof mathematics. Our approach employs a BERT model to embed proof states and\npremises into a shared latent space. The retrieval model is trained within a\ncontrastive learning framework and incorporates a domain-specific tokenizer\nalong with a fine-grained similarity computation method. Experimental results\nshow that our model is highly competitive compared to existing baselines,\nachieving strong performance while requiring fewer computational resources.\nPerformance is further enhanced through the integration of a re-ranking module.\nTo streamline the formalization process, we will release a search engine that\nenables users to query Mathlib theorems directly using proof states,\nsignificantly improving accessibility and efficiency. Codes are available at\nhttps://github.com/ruc-ai4math/Premise-Retrieval.\n","authors":["Yicheng Tao","Haotian Liu","Shanwen Wang","Hongteng Xu"],"pdf_url":"https://arxiv.org/pdf/2501.13959v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.07978v4","updated":"2025-03-06T13:29:24Z","published":"2023-11-14T08:10:14Z","title":"AfroBench: How Good are Large Language Models on African Languages?","summary":"  Large-scale multilingual evaluations, such as MEGA, often include only a\nhandful of African languages due to the scarcity of high-quality evaluation\ndata and the limited discoverability of existing African datasets. This lack of\nrepresentation hinders comprehensive LLM evaluation across a diverse range of\nlanguages and tasks. To address these challenges, we introduce AfroBench -- a\nmulti-task benchmark for evaluating the performance of LLMs across 64 African\nlanguages, 15 tasks and 22 datasets. AfroBench consists of nine natural\nlanguage understanding datasets, six text generation datasets, six knowledge\nand question answering tasks, and one mathematical reasoning task. We present\nresults comparing the performance of prompting LLMs to fine-tuned baselines\nbased on BERT and T5-style models. Our results suggest large gaps in\nperformance between high-resource languages, such as English, and African\nlanguages across most tasks; but performance also varies based on the\navailability of monolingual data resources. Our findings confirm that\nperformance on African languages continues to remain a hurdle for current LLMs,\nunderscoring the need for additional efforts to close this gap.\n  https://mcgill-nlp.github.io/AfroBench/\n","authors":["Jessica Ojo","Odunayo Ogundepo","Akintunde Oladipo","Kelechi Ogueji","Jimmy Lin","Pontus Stenetorp","David Ifeoluwa Adelani"],"pdf_url":"https://arxiv.org/pdf/2311.07978v4.pdf","comment":"Under review"},{"id":"http://arxiv.org/abs/2503.04421v1","updated":"2025-03-06T13:26:58Z","published":"2025-03-06T13:26:58Z","title":"Revisiting the Othello World Model Hypothesis","summary":"  Li et al. (2023) used the Othello board game as a test case for the ability\nof GPT-2 to induce world models, and were followed up by Nanda et al. (2023b).\nWe briefly discuss the original experiments, expanding them to include more\nlanguage models with more comprehensive probing. Specifically, we analyze\nsequences of Othello board states and train the model to predict the next move\nbased on previous moves. We evaluate seven language models (GPT-2, T5, Bart,\nFlan-T5, Mistral, LLaMA-2, and Qwen2.5) on the Othello task and conclude that\nthese models not only learn to play Othello, but also induce the Othello board\nlayout. We find that all models achieve up to 99% accuracy in unsupervised\ngrounding and exhibit high similarity in the board features they learned. This\nprovides considerably stronger evidence for the Othello World Model Hypothesis\nthan previous works.\n","authors":["Yifei Yuan","Anders Sgaard"],"pdf_url":"https://arxiv.org/pdf/2503.04421v1.pdf","comment":"ICLR World Models Workshop"},{"id":"http://arxiv.org/abs/2503.04413v1","updated":"2025-03-06T13:10:57Z","published":"2025-03-06T13:10:57Z","title":"Can Large Language Models Predict Antimicrobial Resistance Gene?","summary":"  This study demonstrates that generative large language models can be utilized\nin a more flexible manner for DNA sequence analysis and classification tasks\ncompared to traditional transformer encoder-based models. While recent\nencoder-based models such as DNABERT and Nucleotide Transformer have shown\nsignificant performance in DNA sequence classification, transformer\ndecoder-based generative models have not yet been extensively explored in this\nfield. This study evaluates how effectively generative Large Language Models\nhandle DNA sequences with various labels and analyzes performance changes when\nadditional textual information is provided. Experiments were conducted on\nantimicrobial resistance genes, and the results show that generative Large\nLanguage Models can offer comparable or potentially better predictions,\ndemonstrating flexibility and accuracy when incorporating both sequence and\ntextual information. The code and data used in this work are available at the\nfollowing GitHub repository: https://github.com/biocomgit/llm4dna.\n","authors":["Hyunwoo Yoo"],"pdf_url":"https://arxiv.org/pdf/2503.04413v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.04405v1","updated":"2025-03-06T12:59:11Z","published":"2025-03-06T12:59:11Z","title":"Comparative Study of Zero-Shot Cross-Lingual Transfer for Bodo POS and\n  NER Tagging Using Gemini 2.0 Flash Thinking Experimental Model","summary":"  Named Entity Recognition (NER) and Part-of-Speech (POS) tagging are critical\ntasks for Natural Language Processing (NLP), yet their availability for\nlow-resource languages (LRLs) like Bodo remains limited. This article presents\na comparative empirical study investigating the effectiveness of Google's\nGemini 2.0 Flash Thinking Experiment model for zero-shot cross-lingual transfer\nof POS and NER tagging to Bodo. We explore two distinct methodologies: (1)\ndirect translation of English sentences to Bodo followed by tag transfer, and\n(2) prompt-based tag transfer on parallel English-Bodo sentence pairs. Both\nmethods leverage the machine translation and cross-lingual understanding\ncapabilities of Gemini 2.0 Flash Thinking Experiment to project English POS and\nNER annotations onto Bodo text in CONLL-2003 format. Our findings reveal the\ncapabilities and limitations of each approach, demonstrating that while both\nmethods show promise for bootstrapping Bodo NLP, prompt-based transfer exhibits\nsuperior performance, particularly for NER. We provide a detailed analysis of\nthe results, highlighting the impact of translation quality, grammatical\ndivergences, and the inherent challenges of zero-shot cross-lingual transfer.\nThe article concludes by discussing future research directions, emphasizing the\nneed for hybrid approaches, few-shot fine-tuning, and the development of\ndedicated Bodo NLP resources to achieve high-accuracy POS and NER tagging for\nthis low-resource language.\n","authors":["Sanjib Narzary","Bihung Brahma","Haradip Mahilary","Mahananda Brahma","Bidisha Som","Sukumar Nandi"],"pdf_url":"https://arxiv.org/pdf/2503.04405v1.pdf","comment":"Submitted to SpringerNature MTAP journal. This article has not been\n  reviewed yet. Submitting for public review!"},{"id":"http://arxiv.org/abs/2406.12753v2","updated":"2025-03-06T12:55:25Z","published":"2024-06-18T16:20:53Z","title":"OlympicArena: Benchmarking Multi-discipline Cognitive Reasoning for\n  Superintelligent AI","summary":"  The evolution of Artificial Intelligence (AI) has been significantly\naccelerated by advancements in Large Language Models (LLMs) and Large\nMultimodal Models (LMMs), gradually showcasing potential cognitive reasoning\nabilities in problem-solving and scientific discovery (i.e., AI4Science) once\nexclusive to human intellect. To comprehensively evaluate current models'\nperformance in cognitive reasoning abilities, we introduce OlympicArena, which\nincludes 11,163 bilingual problems across both text-only and interleaved\ntext-image modalities. These challenges encompass a wide range of disciplines\nspanning seven fields and 62 international Olympic competitions, rigorously\nexamined for data leakage. We argue that the challenges in Olympic competition\nproblems are ideal for evaluating AI's cognitive reasoning due to their\ncomplexity and interdisciplinary nature, which are essential for tackling\ncomplex scientific challenges and facilitating discoveries. Beyond evaluating\nperformance across various disciplines using answer-only criteria, we conduct\ndetailed experiments and analyses from multiple perspectives. We delve into the\nmodels' cognitive reasoning abilities, their performance across different\nmodalities, and their outcomes in process-level evaluations, which are vital\nfor tasks requiring complex reasoning with lengthy solutions. Our extensive\nevaluations reveal that even advanced models like GPT-4o only achieve a 39.97%\noverall accuracy, illustrating current AI limitations in complex reasoning and\nmultimodal integration. Through the OlympicArena, we aim to advance AI towards\nsuperintelligence, equipping it to address more complex challenges in science\nand beyond. We also provide a comprehensive set of resources to support AI\nresearch, including a benchmark dataset, an open-source annotation platform, a\ndetailed evaluation tool, and a leaderboard with automatic submission features.\n","authors":["Zhen Huang","Zengzhi Wang","Shijie Xia","Xuefeng Li","Haoyang Zou","Ruijie Xu","Run-Ze Fan","Lyumanshan Ye","Ethan Chern","Yixin Ye","Yikai Zhang","Yuqing Yang","Ting Wu","Binjie Wang","Shichao Sun","Yang Xiao","Yiyuan Li","Fan Zhou","Steffi Chern","Yiwei Qin","Yan Ma","Jiadi Su","Yixiu Liu","Yuxiang Zheng","Shaoting Zhang","Dahua Lin","Yu Qiao","Pengfei Liu"],"pdf_url":"https://arxiv.org/pdf/2406.12753v2.pdf","comment":"Accepted by NeurIPS 2024"},{"id":"http://arxiv.org/abs/2404.05569v3","updated":"2025-03-06T12:54:37Z","published":"2024-04-08T14:43:13Z","title":"360$^\\circ$REA: Towards A Reusable Experience Accumulation with\n  360 Assessment for Multi-Agent System","summary":"  Large language model agents have demonstrated remarkable advancements across\nvarious complex tasks. Recent works focus on optimizing the agent team or\nemploying self-reflection to iteratively solve complex tasks. Since these\nagents are all based on the same LLM, only conducting self-evaluation or\nremoving underperforming agents does not substantively enhance the capability\nof the agents. We argue that a comprehensive evaluation and accumulating\nexperience from evaluation feedback is an effective approach to improving\nsystem performance. In this paper, we propose Reusable Experience Accumulation\nwith 360$^\\circ$ Assessment (360$^\\circ$REA), a hierarchical multi-agent\nframework inspired by corporate organizational practices. The framework employs\na novel 360$^\\circ$ performance assessment method for multi-perspective\nperformance evaluation with fine-grained assessment. To enhance the capability\nof agents in addressing complex tasks, we introduce dual-level experience pool\nfor agents to accumulate experience through fine-grained assessment. Extensive\nexperiments on complex task datasets demonstrate the effectiveness of\n360$^\\circ$REA.\n","authors":["Shen Gao","Hao Li","Chengrui Huang","Quan Tu","Zhiliang Tian","Minlie Huang","Shuo Shang"],"pdf_url":"https://arxiv.org/pdf/2404.05569v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2502.20742v2","updated":"2025-03-06T12:50:44Z","published":"2025-02-28T05:47:34Z","title":"Structured Preference Optimization for Vision-Language Long-Horizon Task\n  Planning","summary":"  Existing methods for vision-language task planning excel in short-horizon\ntasks but often fall short in complex, long-horizon planning within dynamic\nenvironments. These challenges primarily arise from the difficulty of\neffectively training models to produce high-quality reasoning processes for\nlong-horizon tasks. To address this, we propose Structured Preference\nOptimization (SPO), which aims to enhance reasoning and action selection in\nlong-horizon task planning through structured preference evaluation and\noptimized training strategies. Specifically, SPO introduces: 1)\nPreference-Based Scoring and Optimization, which systematically evaluates\nreasoning chains based on task relevance, visual grounding, and historical\nconsistency; and 2) Curriculum-Guided Training, where the model progressively\nadapts from simple to complex tasks, improving its generalization ability in\nlong-horizon scenarios and enhancing reasoning robustness. To advance research\nin vision-language long-horizon task planning, we introduce ExtendaBench, a\ncomprehensive benchmark covering 1,509 tasks across VirtualHome and Habitat\n2.0, categorized into ultra-short, short, medium, and long tasks. Experimental\nresults demonstrate that SPO significantly improves reasoning quality and final\ndecision accuracy, outperforming prior methods on long-horizon tasks and\nunderscoring the effectiveness of preference-driven optimization in\nvision-language task planning. Specifically, SPO achieves a +5.98% GCR and\n+4.68% SR improvement in VirtualHome and a +3.30% GCR and +2.11% SR improvement\nin Habitat over the best-performing baselines.\n","authors":["Xiwen Liang","Min Lin","Weiqi Ruan","Rongtao Xu","Yuecheng Liu","Jiaqi Chen","Bingqian Lin","Yuzheng Zhuang","Xiaodan Liang"],"pdf_url":"https://arxiv.org/pdf/2502.20742v2.pdf","comment":"18 pages"},{"id":"http://arxiv.org/abs/2503.04396v1","updated":"2025-03-06T12:50:14Z","published":"2025-03-06T12:50:14Z","title":"TableLoRA: Low-rank Adaptation on Table Structure Understanding for\n  Large Language Models","summary":"  Tabular data are crucial in many fields and their understanding by large\nlanguage models (LLMs) under high parameter efficiency paradigm is important.\nHowever, directly applying parameter-efficient fine-tuning (PEFT) techniques to\ntabular tasks presents significant challenges, particularly in terms of better\ntable serialization and the representation of two-dimensional structured\ninformation within a one-dimensional sequence. To address this, we propose\nTableLoRA, a module designed to improve LLMs' understanding of table structure\nduring PEFT. It incorporates special tokens for serializing tables with special\ntoken encoder and uses 2D LoRA to encode low-rank information on cell\npositions. Experiments on four tabular-related datasets demonstrate that\nTableLoRA consistently outperforms vanilla LoRA and surpasses various table\nencoding methods tested in control experiments. These findings reveal that\nTableLoRA, as a table-specific LoRA, enhances the ability of LLMs to process\ntabular data effectively, especially in low-parameter settings, demonstrating\nits potential as a robust solution for handling table-related tasks.\n","authors":["Xinyi He","Yihao Liu","Mengyu Zhou","Yeye He","Haoyu Dong","Shi Han","Zejian Yuan","Dongmei Zhang"],"pdf_url":"https://arxiv.org/pdf/2503.04396v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.04395v1","updated":"2025-03-06T12:47:54Z","published":"2025-03-06T12:47:54Z","title":"Shaping Shared Languages: Human and Large Language Models' Inductive\n  Biases in Emergent Communication","summary":"  Languages are shaped by the inductive biases of their users. Using a\nclassical referential game, we investigate how artificial languages evolve when\noptimised for inductive biases in humans and large language models (LLMs) via\nHuman-Human, LLM-LLM and Human-LLM experiments. We show that referentially\ngrounded vocabularies emerge that enable reliable communication in all\nconditions, even when humans and LLMs collaborate. Comparisons between\nconditions reveal that languages optimised for LLMs subtly differ from those\noptimised for humans. Interestingly, interactions between humans and LLMs\nalleviate these differences and result in vocabularies which are more\nhuman-like than LLM-like. These findings advance our understanding of how\ninductive biases in LLMs play a role in the dynamic nature of human language\nand contribute to maintaining alignment in human and machine communication. In\nparticular, our work underscores the need to think of new methods that include\nhuman interaction in the training processes of LLMs, and shows that using\ncommunicative success as a reward signal can be a fruitful, novel direction.\n","authors":["Tom Kouwenhoven","Max Peeperkorn","Roy de Kleijn","Tessa Verhoef"],"pdf_url":"https://arxiv.org/pdf/2503.04395v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.21083v2","updated":"2025-03-06T12:38:42Z","published":"2024-10-28T14:48:05Z","title":"Stealthy Jailbreak Attacks on Large Language Models via Benign Data\n  Mirroring","summary":"  Large language model (LLM) safety is a critical issue, with numerous studies\nemploying red team testing to enhance model security. Among these, jailbreak\nmethods explore potential vulnerabilities by crafting malicious prompts that\ninduce model outputs contrary to safety alignments. Existing black-box\njailbreak methods often rely on model feedback, repeatedly submitting queries\nwith detectable malicious instructions during the attack search process.\nAlthough these approaches are effective, the attacks may be intercepted by\ncontent moderators during the search process. We propose an improved transfer\nattack method that guides malicious prompt construction by locally training a\nmirror model of the target black-box model through benign data distillation.\nThis method offers enhanced stealth, as it does not involve submitting\nidentifiable malicious instructions to the target model during the search\nphase. Our approach achieved a maximum attack success rate of 92%, or a\nbalanced value of 80% with an average of 1.5 detectable jailbreak queries per\nsample against GPT-3.5 Turbo on a subset of AdvBench. These results underscore\nthe need for more robust defense mechanisms.\n","authors":["Honglin Mu","Han He","Yuxin Zhou","Yunlong Feng","Yang Xu","Libo Qin","Xiaoming Shi","Zeming Liu","Xudong Han","Qi Shi","Qingfu Zhu","Wanxiang Che"],"pdf_url":"https://arxiv.org/pdf/2410.21083v2.pdf","comment":"Accepted by NAACL 2025"},{"id":"http://arxiv.org/abs/2503.04388v1","updated":"2025-03-06T12:38:17Z","published":"2025-03-06T12:38:17Z","title":"More Documents, Same Length: Isolating the Challenge of Multiple\n  Documents in RAG","summary":"  Retrieval-augmented generation (RAG) provides LLMs with relevant documents.\nAlthough previous studies noted that retrieving many documents can degrade\nperformance, they did not isolate how the quantity of documents affects\nperformance while controlling for context length. We evaluate various language\nmodels on custom datasets derived from a multi-hop QA task. We keep the context\nlength and position of relevant information constant while varying the number\nof documents, and find that increasing the document count in RAG settings poses\nsignificant challenges for LLMs. Additionally, our results indicate that\nprocessing multiple documents is a separate challenge from handling long\ncontexts. We also make the datasets and code available:\nhttps://github.com/shaharl6000/MoreDocsSameLen .\n","authors":["Shahar Levy","Nir Mazor","Lihi Shalmon","Michael Hassid","Gabriel Stanovsky"],"pdf_url":"https://arxiv.org/pdf/2503.04388v1.pdf","comment":"Preprint"},{"id":"http://arxiv.org/abs/2503.04381v1","updated":"2025-03-06T12:33:20Z","published":"2025-03-06T12:33:20Z","title":"TRACT: Regression-Aware Fine-tuning Meets Chain-of-Thought Reasoning for\n  LLM-as-a-Judge","summary":"  The LLM-as-a-judge paradigm uses large language models (LLMs) for automated\ntext evaluation, where a numerical assessment is assigned by an LLM to the\ninput text following scoring rubrics. Existing methods for LLM-as-a-judge use\ncross-entropy (CE) loss for fine-tuning, which neglects the numeric nature of\nscore prediction. Recent work addresses numerical prediction limitations of LLM\nfine-tuning through regression-aware fine-tuning, which, however, does not\nconsider chain-of-thought (CoT) reasoning for score prediction. In this paper,\nwe introduce TRACT (Two-stage Regression-Aware fine-tuning with CoT), a method\ncombining CoT reasoning with regression-aware training. TRACT consists of two\nstages: first, seed LLM is fine-tuned to generate CoTs, which serve as\nsupervision for the second stage fine-tuning. The training objective of TRACT\ncombines the CE loss for learning the CoT reasoning capabilities, and the\nregression-aware loss for the score prediction. Experiments across four\nLLM-as-a-judge datasets and two LLMs show that TRACT significantly outperforms\nexisting methods. Extensive ablation studies validate the importance of each\ncomponent in TRACT.\n","authors":["Cheng-Han Chiang","Hung-yi Lee","Michal Lukasik"],"pdf_url":"https://arxiv.org/pdf/2503.04381v1.pdf","comment":"Codes and models are available at https://github.com/d223302/TRACT"},{"id":"http://arxiv.org/abs/2503.04378v1","updated":"2025-03-06T12:30:24Z","published":"2025-03-06T12:30:24Z","title":"Dedicated Feedback and Edit Models Empower Inference-Time Scaling for\n  Open-Ended General-Domain Tasks","summary":"  Inference-Time Scaling has been critical to the success of recent models such\nas OpenAI o1 and DeepSeek R1. However, many techniques used to train models for\ninference-time scaling require tasks to have answers that can be verified,\nlimiting their application to domains such as math, coding and logical\nreasoning. We take inspiration from how humans make first attempts, ask for\ndetailed feedback from others and make improvements based on such feedback\nacross a wide spectrum of open-ended endeavors. To this end, we collect data\nfor and train dedicated Feedback and Edit Models that are capable of performing\ninference-time scaling for open-ended general-domain tasks. In our setup, one\nmodel generates an initial response, which are given feedback by a second\nmodel, that are then used by a third model to edit the response. We show that\nperformance on Arena Hard, a benchmark strongly predictive of Chatbot Arena Elo\ncan be boosted by scaling the number of initial response drafts, effective\nfeedback and edited responses. When scaled optimally, our setup based on 70B\nmodels from the Llama 3 family can reach SoTA performance on Arena Hard at 92.7\nas of 5 Mar 2025, surpassing OpenAI o1-preview-2024-09-12 with 90.4 and\nDeepSeek R1 with 92.3.\n","authors":["Zhilin Wang","Jiaqi Zeng","Olivier Delalleau","Daniel Egert","Ellie Evans","Hoo-Chang Shin","Felipe Soares","Yi Dong","Oleksii Kuchaiev"],"pdf_url":"https://arxiv.org/pdf/2503.04378v1.pdf","comment":"22 pages, 2 figures"},{"id":"http://arxiv.org/abs/2503.01346v2","updated":"2025-03-06T12:27:24Z","published":"2025-03-03T09:37:33Z","title":"SRAG: Structured Retrieval-Augmented Generation for Multi-Entity\n  Question Answering over Wikipedia Graph","summary":"  Multi-entity question answering (MEQA) poses significant challenges for large\nlanguage models (LLMs), which often struggle to consolidate scattered\ninformation across multiple documents. An example question might be \"What is\nthe distribution of IEEE Fellows among various fields of study?\", which\nrequires retrieving information from diverse sources e.g., Wikipedia pages. The\neffectiveness of current retrieval-augmented generation (RAG) methods is\nlimited by the LLMs' capacity to aggregate insights from numerous pages. To\naddress this gap, this paper introduces a structured RAG (SRAG) framework that\nsystematically organizes extracted entities into relational tables (e.g.,\ntabulating entities with schema columns like \"name\" and \"field of study\") and\nthen apply table-based reasoning techniques. Our approach decouples retrieval\nand reasoning, enabling LLMs to focus on structured data analysis rather than\nraw text aggregation. Extensive experiments on Wikipedia-based multi-entity QA\ntasks demonstrate that SRAG significantly outperforms state-of-the-art\nlong-context LLMs and RAG solutions, achieving a 29.6% improvement in accuracy.\nThe results underscore the efficacy of structuring unstructured data to enhance\nLLMs' reasoning capabilities.\n","authors":["Teng Lin","Yizhang Zhu","Yuyu Luo","Nan Tang"],"pdf_url":"https://arxiv.org/pdf/2503.01346v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.04372v1","updated":"2025-03-06T12:16:14Z","published":"2025-03-06T12:16:14Z","title":"Assumed Identities: Quantifying Gender Bias in Machine Translation of\n  Ambiguous Occupational Terms","summary":"  Machine Translation (MT) systems frequently encounter ambiguous scenarios\nwhere they must assign gender to certain occupations when translating without\nexplicit guidance or contextual cues. While individual translations in such\ncases may not be inherently biased, systematic patterns-such as the repeated\nassociation of certain professions with specific genders-can emerge, reflecting\nand perpetuating societal stereotypes. This ambiguity challenges traditional\ninstance-level single-answer evaluation approaches, as no single gold standard\ntranslation exists. To address this, we propose an approach that evaluates\ngender bias through aggregated model responses. Specifically, we introduce a\nmethodology to detect gender imbalances between source texts and translations,\na benchmarking dataset with ambiguous English inputs, and probability-based\nmetrics to quantify a model's divergence from normative standards or reference\ndistributions.\n","authors":["Orfeas Menis Mastromichalakis","Giorgos Filandrianos","Maria Symeonaki","Giorgos Stamou"],"pdf_url":"https://arxiv.org/pdf/2503.04372v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.04369v1","updated":"2025-03-06T12:14:45Z","published":"2025-03-06T12:14:45Z","title":"Lost in Literalism: How Supervised Training Shapes Translationese in\n  LLMs","summary":"  Large language models (LLMs) have achieved remarkable success in machine\ntranslation, demonstrating impressive performance across diverse languages.\nHowever, translationese, characterized by overly literal and unnatural\ntranslations, remains a persistent challenge in LLM-based translation systems.\nDespite their pre-training on vast corpora of natural utterances, LLMs exhibit\ntranslationese errors and generate unexpected unnatural translations, stemming\nfrom biases introduced during supervised fine-tuning (SFT). In this work, we\nsystematically evaluate the prevalence of translationese in LLM-generated\ntranslations and investigate its roots during supervised training. We introduce\nmethods to mitigate these biases, including polishing golden references and\nfiltering unnatural training instances. Empirical evaluations demonstrate that\nthese approaches significantly reduce translationese while improving\ntranslation naturalness, validated by human evaluations and automatic metrics.\nOur findings highlight the need for training-aware adjustments to optimize LLM\ntranslation outputs, paving the way for more fluent and\ntarget-language-consistent translations. We release the data and code at\nhttps://github.com/yafuly/LLM_Translationese.\n","authors":["Yafu Li","Ronghao Zhang","Zhilin Wang","Huajian Zhang","Leyang Cui","Yongjing Yin","Tong Xiao","Yue Zhang"],"pdf_url":"https://arxiv.org/pdf/2503.04369v1.pdf","comment":"19 pages;"},{"id":"http://arxiv.org/abs/2410.01257v2","updated":"2025-03-06T12:13:14Z","published":"2024-10-02T06:05:52Z","title":"HelpSteer2-Preference: Complementing Ratings with Preferences","summary":"  Reward models are critical for aligning models to follow instructions, and\nare typically trained following one of two popular paradigms: Bradley-Terry\nstyle or Regression style. However, there is a lack of evidence that either\napproach is better than the other, when adequately matched for data. This is\nprimarily because these approaches require data collected in different (but\nincompatible) formats, meaning that adequately matched data is not available in\nexisting public datasets. To tackle this problem, we release preference\nannotations (designed for Bradley-Terry training) to complement existing\nratings (designed for Regression style training) in the HelpSteer2 dataset. To\nimprove data interpretability, preference annotations are accompanied with\nhuman-written justifications. Using this data, we conduct the first\nhead-to-head comparison of Bradley-Terry and Regression models when adequately\nmatched for data. Based on insights derived from such a comparison, we propose\na novel approach to combine Bradley-Terry and Regression reward modeling. A\nLlama-3.1-70B-Instruct model tuned with this approach scores 94.1 on\nRewardBench, emerging top of more than 140 reward models as of 1 Oct 2024. This\nreward model can then be used with REINFORCE algorithm (RLHF) to align an\nInstruct model to reach 85.0 on Arena Hard, which is No. 1 as of 1 Oct 2024. We\nopen-source this dataset (CC-BY-4.0 license) at\nhttps://huggingface.co/datasets/nvidia/HelpSteer2#preferences-new -- 1-oct-2024\nand openly release the trained Reward and Instruct models at\nhttps://huggingface.co/nvidia/Llama-3.1-Nemotron-70B-Reward and\nhttps://huggingface.co/nvidia/Llama-3.1-Nemotron-70B-Instruct\n","authors":["Zhilin Wang","Alexander Bukharin","Olivier Delalleau","Daniel Egert","Gerald Shen","Jiaqi Zeng","Oleksii Kuchaiev","Yi Dong"],"pdf_url":"https://arxiv.org/pdf/2410.01257v2.pdf","comment":"Accepted to ICLR 2025; 28 pages, 3 figures"},{"id":"http://arxiv.org/abs/2503.04360v1","updated":"2025-03-06T12:04:29Z","published":"2025-03-06T12:04:29Z","title":"Exploring the Multilingual NLG Evaluation Abilities of LLM-Based\n  Evaluators","summary":"  Previous research has shown that LLMs have potential in multilingual NLG\nevaluation tasks. However, existing research has not fully explored the\ndifferences in the evaluation capabilities of LLMs across different languages.\nTo this end, this study provides a comprehensive analysis of the multilingual\nevaluation performance of 10 recent LLMs, spanning high-resource and\nlow-resource languages through correlation analysis, perturbation attacks, and\nfine-tuning. We found that 1) excluding the reference answer from the prompt\nand using large-parameter LLM-based evaluators leads to better performance\nacross various languages; 2) most LLM-based evaluators show a higher\ncorrelation with human judgments in high-resource languages than in\nlow-resource languages; 3) in the languages where they are most sensitive to\nsuch attacks, they also tend to exhibit the highest correlation with human\njudgments; and 4) fine-tuning with data from a particular language yields a\nbroadly consistent enhancement in the model's evaluation performance across\ndiverse languages. Our findings highlight the imbalance in LLMs'evaluation\ncapabilities across different languages and suggest that low-resource language\nscenarios deserve more attention.\n","authors":["Jiayi Chang","Mingqi Gao","Xinyu Hu","Xiaojun Wan"],"pdf_url":"https://arxiv.org/pdf/2503.04360v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.04355v1","updated":"2025-03-06T11:59:55Z","published":"2025-03-06T11:59:55Z","title":"Layer-Specific Scaling of Positional Encodings for Superior Long-Context\n  Modeling","summary":"  Although large language models (LLMs) have achieved significant progress in\nhandling long-context inputs, they still suffer from the ``lost-in-the-middle''\nproblem, where crucial information in the middle of the context is often\nunderrepresented or lost. Our extensive experiments reveal that this issue may\narise from the rapid long-term decay in Rotary Position Embedding (RoPE). To\naddress this problem, we propose a layer-specific positional encoding scaling\nmethod that assigns distinct scaling factors to each layer, slowing down the\ndecay rate caused by RoPE to make the model pay more attention to the middle\ncontext. A specially designed genetic algorithm is employed to efficiently\nselect the optimal scaling factors for each layer by incorporating Bezier\ncurves to reduce the search space. Through comprehensive experimentation, we\ndemonstrate that our method significantly alleviates the ``lost-in-the-middle''\nproblem. Our approach results in an average accuracy improvement of up to 20%\non the Key-Value Retrieval dataset. Furthermore, we show that layer-specific\ninterpolation, as opposed to uniform interpolation across all layers, enhances\nthe model's extrapolation capabilities when combined with PI and Dynamic-NTK\npositional encoding schemes.\n","authors":["Zhenghua Wang","Yiran Ding","Changze Lv","Zhibo Xu","Tianlong Li","Tianyuan Shi","Xiaoqing Zheng","Xuanjing Huang"],"pdf_url":"https://arxiv.org/pdf/2503.04355v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2501.03479v2","updated":"2025-03-06T11:46:49Z","published":"2025-01-07T02:47:59Z","title":"Women, Infamous, and Exotic Beings: What Honorific Usages in Wikipedia\n  Reveal about the Socio-Cultural Norms","summary":"  Honorifics serve as powerful linguistic markers that reflect social\nhierarchies and cultural values. This paper presents a large-scale,\ncross-linguistic exploration of usage of honorific pronouns in Bengali and\nHindi Wikipedia articles, shedding light on how socio-cultural factors shape\nlanguage. Using LLM (GPT-4o), we annotated 10, 000 articles of real and\nfictional beings in each language for several sociodemographic features such as\ngender, age, fame, and exoticness, and the use of honorifics. We find that\nacross all feature combinations, use of honorifics is consistently more common\nin Bengali than Hindi. For both languages, the use non-honorific pronouns is\nmore commonly observed for infamous, juvenile, and exotic beings. Notably, we\nobserve a gender bias in use of honorifics in Hindi, with men being more\ncommonly referred to with honorifics than women.\n","authors":["Sourabrata Mukherjee","Soumya Teotia","Sougata Saha","Monojit Choudhury"],"pdf_url":"https://arxiv.org/pdf/2501.03479v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.18640v2","updated":"2025-03-06T11:45:40Z","published":"2024-10-24T11:06:29Z","title":"Weak-to-Strong Preference Optimization: Stealing Reward from Weak\n  Aligned Model","summary":"  Aligning language models (LMs) with human preferences has become a key area\nof research, enabling these models to meet diverse user needs better. Inspired\nby weak-to-strong generalization, where a strong LM fine-tuned on labels\ngenerated by a weaker model can consistently outperform its weak supervisor, we\nextend this idea to model alignment. In this work, we observe that the\nalignment behavior in weaker models can be effectively transferred to stronger\nmodels and even exhibit an amplification effect. Based on this insight, we\npropose a method called Weak-to-Strong Preference Optimization (WSPO), which\nachieves strong model alignment by learning the distribution differences before\nand after the alignment of the weak model. Experiments demonstrate that WSPO\ndelivers outstanding performance, improving the win rate of Qwen2-7B-Instruct\non Arena-Hard from 39.70 to 49.60, achieving a remarkable 47.04\nlength-controlled win rate on AlpacaEval 2, and scoring 7.33 on MT-bench. Our\nresults suggest that using the weak model to elicit a strong model with a high\nalignment ability is feasible.\n","authors":["Wenhong Zhu","Zhiwei He","Xiaofeng Wang","Pengfei Liu","Rui Wang"],"pdf_url":"https://arxiv.org/pdf/2410.18640v2.pdf","comment":"ICLR 2025(Spotlight)"},{"id":"http://arxiv.org/abs/2503.04346v1","updated":"2025-03-06T11:42:03Z","published":"2025-03-06T11:42:03Z","title":"Adding Alignment Control to Language Models","summary":"  Post-training alignment has increasingly become a crucial factor in enhancing\nthe usability of language models (LMs). However, the strength of alignment\nvaries depending on individual preferences. This paper proposes a method to\nincorporate alignment control into a single model, referred to as CLM. This\napproach adds one identity layer preceding the initial layers and performs\npreference learning only on this layer to map unaligned input token embeddings\ninto the aligned space. Experimental results demonstrate that this efficient\nfine-tuning method performs comparable to full fine-tuning. During inference,\nthe input embeddings are processed through the aligned and unaligned layers,\nwhich are then merged through the interpolation coefficient. By controlling\nthis parameter, the alignment exhibits a clear interpolation and extrapolation\nphenomenon.\n","authors":["Wenhong Zhu","Weinan Zhang","Rui Wang"],"pdf_url":"https://arxiv.org/pdf/2503.04346v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.04338v1","updated":"2025-03-06T11:34:49Z","published":"2025-03-06T11:34:49Z","title":"In-depth Analysis of Graph-based RAG in a Unified Framework","summary":"  Graph-based Retrieval-Augmented Generation (RAG) has proven effective in\nintegrating external knowledge into large language models (LLMs), improving\ntheir factual accuracy, adaptability, interpretability, and trustworthiness. A\nnumber of graph-based RAG methods have been proposed in the literature.\nHowever, these methods have not been systematically and comprehensively\ncompared under the same experimental settings. In this paper, we first\nsummarize a unified framework to incorporate all graph-based RAG methods from a\nhigh-level perspective. We then extensively compare representative graph-based\nRAG methods over a range of questing-answering (QA) datasets -- from specific\nquestions to abstract questions -- and examine the effectiveness of all\nmethods, providing a thorough analysis of graph-based RAG approaches. As a\nbyproduct of our experimental analysis, we are also able to identify new\nvariants of the graph-based RAG methods over specific QA and abstract QA tasks\nrespectively, by combining existing techniques, which outperform the\nstate-of-the-art methods. Finally, based on these findings, we offer promising\nresearch opportunities. We believe that a deeper understanding of the behavior\nof existing methods can provide new valuable insights for future research.\n","authors":["Yingli Zhou","Yaodong Su","Youran Sun","Shu Wang","Taotao Wang","Runyuan He","Yongwei Zhang","Sicong Liang","Xilin Liu","Yuchi Ma","Yixiang Fang"],"pdf_url":"https://arxiv.org/pdf/2503.04338v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.04328v1","updated":"2025-03-06T11:27:55Z","published":"2025-03-06T11:27:55Z","title":"Solving Word-Sense Disambiguation and Word-Sense Induction with\n  Dictionary Examples","summary":"  Many less-resourced languages struggle with a lack of large, task-specific\ndatasets that are required for solving relevant tasks with modern\ntransformer-based large language models (LLMs). On the other hand, many\nlinguistic resources, such as dictionaries, are rarely used in this context\ndespite their large information contents. We show how LLMs can be used to\nextend existing language resources in less-resourced languages for two\nimportant tasks: word-sense disambiguation (WSD) and word-sense induction\n(WSI). We approach the two tasks through the related but much more accessible\nword-in-context (WiC) task where, given a pair of sentences and a target word,\na classification model is tasked with predicting whether the sense of a given\nword differs between sentences. We demonstrate that a well-trained model for\nthis task can distinguish between different word senses and can be adapted to\nsolve the WSD and WSI tasks. The advantage of using the WiC task, instead of\ndirectly predicting senses, is that the WiC task does not need pre-constructed\nsense inventories with a sufficient number of examples for each sense, which\nare rarely available in less-resourced languages. We show that sentence pairs\nfor the WiC task can be successfully generated from dictionary examples using\nLLMs. The resulting prediction models outperform existing models on WiC, WSD,\nand WSI tasks. We demonstrate our methodology on the Slovene language, where a\nmonolingual dictionary is available, but word-sense resources are tiny.\n","authors":["Tadej kvorc","Marko Robnik-ikonja"],"pdf_url":"https://arxiv.org/pdf/2503.04328v1.pdf","comment":"12 pages, 1 figure"},{"id":"http://arxiv.org/abs/2502.15109v2","updated":"2025-03-06T11:07:48Z","published":"2025-02-21T00:05:40Z","title":"Social Genome: Grounded Social Reasoning Abilities of Multimodal Models","summary":"  Social reasoning abilities are crucial for AI systems to effectively\ninterpret and respond to multimodal human communication and interaction within\nsocial contexts. We introduce Social Genome, the first benchmark for\nfine-grained, grounded social reasoning abilities of multimodal models. Social\nGenome contains 272 videos of interactions and 1,486 human-annotated reasoning\ntraces related to inferences about these interactions. These traces contain\n5,777 reasoning steps that reference evidence from visual cues, verbal cues,\nvocal cues, and external knowledge (contextual knowledge external to videos).\nSocial Genome is also the first modeling challenge to study external knowledge\nin social reasoning. Social Genome computes metrics to holistically evaluate\nsemantic and structural qualities of model-generated social reasoning traces.\nWe demonstrate the utility of Social Genome through experiments with\nstate-of-the-art models, identifying performance gaps and opportunities for\nfuture research to improve the grounded social reasoning abilities of\nmultimodal models.\n","authors":["Leena Mathur","Marian Qian","Paul Pu Liang","Louis-Philippe Morency"],"pdf_url":"https://arxiv.org/pdf/2502.15109v2.pdf","comment":"Under Review, 22 pages"},{"id":"http://arxiv.org/abs/2503.03417v2","updated":"2025-03-06T11:00:35Z","published":"2025-03-05T11:47:32Z","title":"When Claims Evolve: Evaluating and Enhancing the Robustness of Embedding\n  Models Against Misinformation Edits","summary":"  Online misinformation remains a critical challenge, and fact-checkers\nincreasingly rely on embedding-based methods to retrieve relevant fact-checks.\nYet, when debunked claims reappear in edited forms, the performance of these\nmethods is unclear. In this work, we introduce a taxonomy of six common\nreal-world misinformation edits and propose a perturbation framework that\ngenerates valid, natural claim variations. Our multi-stage retrieval evaluation\nreveals that standard embedding models struggle with user-introduced edits,\nwhile LLM-distilled embeddings offer improved robustness at a higher\ncomputational cost. Although a strong reranker helps mitigate some issues, it\ncannot fully compensate for first-stage retrieval gaps. Addressing these\nretrieval gaps, our train- and inference-time mitigation approaches enhance\nin-domain robustness by up to 17 percentage points and boost out-of-domain\ngeneralization by 10 percentage points over baseline models. Overall, our\nfindings provide practical improvements to claim-matching systems, enabling\nmore reliable fact-checking of evolving misinformation.\n","authors":["Jabez Magomere","Emanuele La Malfa","Manuel Tonneau","Ashkan Kazemi","Scott Hale"],"pdf_url":"https://arxiv.org/pdf/2503.03417v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.04305v1","updated":"2025-03-06T10:46:15Z","published":"2025-03-06T10:46:15Z","title":"Computational Law: Datasets, Benchmarks, and Ontologies","summary":"  Recent developments in computer science and artificial intelligence have also\ncontributed to the legal domain, as revealed by the number and range of related\npublications and applications. Machine and deep learning models require\nconsiderable amount of domain-specific data for training and comparison\npurposes, in order to attain high-performance in the legal domain.\nAdditionally, semantic resources such as ontologies are valuable for building\nlarge-scale computational legal systems, in addition to ensuring\ninteroperability of such systems. Considering these aspects, we present an\nup-to-date review of the literature on datasets, benchmarks, and ontologies\nproposed for computational law. We believe that this comprehensive and recent\nreview will help researchers and practitioners when developing and testing\napproaches and systems for computational law.\n","authors":["Dilek Kk","Fazli Can"],"pdf_url":"https://arxiv.org/pdf/2503.04305v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2405.01924v2","updated":"2025-03-06T10:39:48Z","published":"2024-05-03T08:34:13Z","title":"Semi-Parametric Retrieval via Binary Bag-of-Tokens Index","summary":"  Information retrieval has transitioned from standalone systems into essential\ncomponents across broader applications, with indexing efficiency,\ncost-effectiveness, and freshness becoming increasingly critical yet often\noverlooked. In this paper, we introduce SemI-parametric Disentangled Retrieval\n(SiDR), a bi-encoder retrieval framework that decouples retrieval index from\nneural parameters to enable efficient, low-cost, and parameter-agnostic\nindexing for emerging use cases. Specifically, in addition to using embeddings\nas indexes like existing neural retrieval methods, SiDR supports a\nnon-parametric tokenization index for search, achieving BM25-like indexing\ncomplexity with significantly better effectiveness. Our comprehensive\nevaluation across 16 retrieval benchmarks demonstrates that SiDR outperforms\nboth neural and term-based retrieval baselines under the same indexing\nworkload: (i) When using an embedding-based index, SiDR exceeds the performance\nof conventional neural retrievers while maintaining similar training\ncomplexity; (ii) When using a tokenization-based index, SiDR drastically\nreduces indexing cost and time, matching the complexity of traditional\nterm-based retrieval, while consistently outperforming BM25 on all in-domain\ndatasets; (iii) Additionally, we introduce a late parametric mechanism that\nmatches BM25 index preparation time while outperforming other neural retrieval\nbaselines in effectiveness.\n","authors":["Jiawei Zhou","Li Dong","Furu Wei","Lei Chen"],"pdf_url":"https://arxiv.org/pdf/2405.01924v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.04279v1","updated":"2025-03-06T10:07:51Z","published":"2025-03-06T10:07:51Z","title":"Dual-Class Prompt Generation: Enhancing Indonesian Gender-Based Hate\n  Speech Detection through Data Augmentation","summary":"  Detecting gender-based hate speech in Indonesian social media remains\nchallenging due to limited labeled datasets. While binary hate speech\nclassification has advanced, a more granular category like gender-targeted hate\nspeech is understudied because of class imbalance issues. This paper addresses\nthis gap by comparing three data augmentation techniques for Indonesian\ngender-based hate speech detection. We evaluate backtranslation, single-class\nprompt generation (using only hate speech examples), and our proposed\ndual-class prompt generation (using both hate speech and non-hate speech\nexamples). Experiments show all augmentation methods improve classification\nperformance, with our dual-class approach achieving the best results (88.5%\naccuracy, 88.1% F1-score using Random Forest). Semantic similarity analysis\nreveals dual-class prompt generation produces the most novel content, while\nT-SNE visualizations confirm these samples occupy distinct feature space\nregions while maintaining class characteristics. Our findings suggest that\nincorporating examples from both classes helps language models generate more\ndiverse yet representative samples, effectively addressing limited data\nchallenges in specialized hate speech detection.\n","authors":["Muhammad Amien Ibrahim"," Faisal","Tora Sangputra Yopie Winarto","Zefanya Delvin Sulistiya"],"pdf_url":"https://arxiv.org/pdf/2503.04279v1.pdf","comment":"Accepted to the 8th World Conference on Computing and Communication\n  Technologies (WCCCT 2025)"},{"id":"http://arxiv.org/abs/2503.04271v1","updated":"2025-03-06T10:02:25Z","published":"2025-03-06T10:02:25Z","title":"On Fact and Frequency: LLM Responses to Misinformation Expressed with\n  Uncertainty","summary":"  We study LLM judgments of misinformation expressed with uncertainty. Our\nexperiments study the response of three widely used LLMs (GPT-4o, LlaMA3,\nDeepSeek-v2) to misinformation propositions that have been verified false and\nthen are transformed into uncertain statements according to an uncertainty\ntypology. Our results show that after transformation, LLMs change their\nfactchecking classification from false to not-false in 25% of the cases.\nAnalysis reveals that the change cannot be explained by predictors to which\nhumans are expected to be sensitive, i.e., modality, linguistic cues, or\nargumentation strategy. The exception is doxastic transformations, which use\nlinguistic cue phrases such as \"It is believed ...\".To gain further insight, we\nprompt the LLM to make another judgment about the transformed misinformation\nstatements that is not related to truth value. Specifically, we study LLM\nestimates of the frequency with which people make the uncertain statement. We\nfind a small but significant correlation between judgment of fact and\nestimation of frequency.\n","authors":["Yana van de Sande","Gunes Aar","Thabo van Woudenberg","Martha Larson"],"pdf_url":"https://arxiv.org/pdf/2503.04271v1.pdf","comment":"4 pages, 1 figure, 3 tables, conference"},{"id":"http://arxiv.org/abs/2503.04240v1","updated":"2025-03-06T09:21:54Z","published":"2025-03-06T09:21:54Z","title":"DiffPO: Diffusion-styled Preference Optimization for Efficient\n  Inference-Time Alignment of Large Language Models","summary":"  Inference-time alignment provides an efficient alternative for aligning LLMs\nwith humans. However, these approaches still face challenges, such as limited\nscalability due to policy-specific value functions and latency during the\ninference phase. In this paper, we propose a novel approach, Diffusion-styled\nPreference Optimization (\\model), which provides an efficient and\npolicy-agnostic solution for aligning LLMs with humans. By directly performing\nalignment at sentence level, \\model~avoids the time latency associated with\ntoken-level generation. Designed as a plug-and-play module, \\model~can be\nseamlessly integrated with various base models to enhance their alignment.\nExtensive experiments on AlpacaEval 2, MT-bench, and HH-RLHF demonstrate that\n\\model~achieves superior alignment performance across various settings,\nachieving a favorable trade-off between alignment quality and inference-time\nlatency. Furthermore, \\model~demonstrates model-agnostic scalability,\nsignificantly improving the performance of large models such as Llama-3-70B.\n","authors":["Ruizhe Chen","Wenhao Chai","Zhifei Yang","Xiaotian Zhang","Joey Tianyi Zhou","Tony Quek","Soujanya Poria","Zuozhu Liu"],"pdf_url":"https://arxiv.org/pdf/2503.04240v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.04232v1","updated":"2025-03-06T09:14:02Z","published":"2025-03-06T09:14:02Z","title":"Tgea: An error-annotated dataset and benchmark tasks for text generation\n  from pretrained language models","summary":"  In order to deeply understand the capability of pretrained language models in\ntext generation and conduct a diagnostic evaluation, we propose TGEA, an\nerror-annotated dataset with multiple benchmark tasks for text generation from\npretrained language models (PLMs). We use carefully selected prompt words to\nguide GPT-2 to generate candidate sentences, from which we select 47K for error\nannotation. Crowdsourced workers manually check each of these sentences and\ndetect 12k erroneous sentences. We create an error taxonomy to cover 24 types\nof errors occurring in these erroneous sentences according to the nature of\nerrors with respect to linguistics and knowledge (eg, common sense). For each\nerroneous span in PLM-generated sentences, we also detect another span that is\nclosely associated with it. Each error is hence manually labeled with\ncomprehensive annotations, including the span of the error, the associated\nspan, minimal correction to the error, the type of the error, and rationale\nbehind the error. Apart from the fully annotated dataset, we also present a\ndetailed description of the data collection procedure, statistics and analysis\nof the dataset. This is the first dataset with comprehensive annotations for\nPLM-generated texts, which facilitates the diagnostic evaluation of PLM-based\ntext generation. Furthermore, we use TGEA as a benchmark dataset and propose a\nseries of automatic diagnosis tasks, including error detection, error type\nclassification, associated span detection, error rationale generation, to\nfurther promote future study on the automatic error detection and correction on\ntexts generated by pretrained language models.\n","authors":["Jie He","Bo Peng","Yi Liao","Qun Liu","Deyi Xiong"],"pdf_url":"https://arxiv.org/pdf/2503.04232v1.pdf","comment":"ACL 2021"},{"id":"http://arxiv.org/abs/2503.04222v1","updated":"2025-03-06T09:03:36Z","published":"2025-03-06T09:03:36Z","title":"FuseChat-3.0: Preference Optimization Meets Heterogeneous Model Fusion","summary":"  We introduce FuseChat-3.0, a suite of large language models (LLMs) developed\nby integrating the strengths of heterogeneous source LLMs into more compact\ntarget LLMs. Our source models include the powerful Gemma-2-27B-it,\nMistral-Large-Instruct-2407, Qwen-2.5-72B-Instruct, and Llama-3.1-70B-Instruct.\nFor target models, we focus on three widely-used smaller\nvariants-Llama-3.1-8B-Instruct, Gemma-2-9B-it, and Qwen-2.5-7B-Instruct-along\nwith two ultra-compact options, Llama-3.2-3B-Instruct and\nLlama-3.2-1B-Instruct. To leverage the diverse capabilities of these source\nmodels, we develop a specialized data construction protocol tailored to various\ntasks and domains. The FuseChat-3.0 training pipeline consists of two key\nstages: (1) supervised fine-tuning (SFT) to align the target and source model\ndistributions, and (2) Direct Preference Optimization (DPO) to apply\npreferences from multiple source LLMs to fine-tune the target model. The\nresulting FuseChat-3.0 models exhibit significant performance gains across\ntasks such as instruction following, general knowledge, mathematics, and\ncoding. As illustrated in Figure 1, using Llama-3.1-8B-Instruct as the target\nmodel, our fusion approach achieves an average improvement of 6.8 points across\n14 benchmarks. Moreover, it demonstrates remarkable gains of 37.1 points and\n30.1 points on the instruction-following benchmarks AlpacaEval-2 and\nArena-Hard, respectively. Our code, models, and datasets are available at\nhttps://github.com/SLIT-AI/FuseChat-3.0.\n","authors":["Ziyi Yang","Fanqi Wan","Longguang Zhong","Canbin Huang","Guosheng Liang","Xiaojun Quan"],"pdf_url":"https://arxiv.org/pdf/2503.04222v1.pdf","comment":"Technical report"},{"id":"http://arxiv.org/abs/2503.02495v2","updated":"2025-03-06T08:51:47Z","published":"2025-03-04T11:01:25Z","title":"Union of Experts: Adapting Hierarchical Routing to Equivalently\n  Decomposed Transformer","summary":"  We propose Union-of-Experts (UoE), which decomposes transformer into an\nequitant group of experts, and then implement selective routing on input data\nand experts. Our approach advances MoE design with four key innovations: (1) We\nconducted equitant expert decomposition on both MLP blocks and attention blocks\nbased on matrix partition in tensor parallelism. (2) We developed two routing\nparadigms: patch-wise data selection and expert selection, to apply routing\nacross different levels. (3) We design the architecture of UoE model, including\nSelective Multi-Head Attention (SMHA) and Union-of-MLP-Experts (UoME). (4) We\ndevelop parallel implementation of UoE's routing and computation operation, and\noptimize efficiency based on the hardware processing analysis. The experiments\ndemonstrate that the UoE model surpass Full Attention, state-of-art MoEs and\nefficient transformers (including the model architecture of recently proposed\nDeepSeek-V3) in several tasks across image and natural language domains. In\nlanguage modeling tasks, we achieve an average reduction of 2.38 in perplexity\ncompared to the best-performed MoE method with an average of 76% FLOPs. In Long\nRange Arena benchmark, we recorded an average score that is at least 0.68%\nhigher than all comparison models including Full Attention, MoEs, and\ntransformer variants, with only 50% FLOPs of the best MoE method. In image\nclassification, our model yielded an average accuracy improvement of 1.75% than\nthe best model while maintaining comparable FLOPs. The source codes are\navailable at https://github.com/YujiaoYang-work/UoE.\n","authors":["Yujiao Yang","Jing Lian","Linhui Li"],"pdf_url":"https://arxiv.org/pdf/2503.02495v2.pdf","comment":"17 pages"},{"id":"http://arxiv.org/abs/2410.07009v2","updated":"2025-03-06T08:51:05Z","published":"2024-10-09T15:52:48Z","title":"Pap2Pat: Benchmarking Outline-Guided Long-Text Patent Generation with\n  Patent-Paper Pairs","summary":"  Dealing with long and highly complex technical text is a challenge for Large\nLanguage Models (LLMs), which still have to unfold their potential in\nsupporting expensive and timeintensive processes like patent drafting. Within\npatents, the description constitutes more than 90% of the document on average.\nYet, its automatic generation remains understudied. When drafting patent\napplications, patent attorneys typically receive invention reports (IRs), which\nare usually confidential, hindering research on LLM-supported patent drafting.\nOften, prepublication research papers serve as IRs. We leverage this duality to\nbuild PAP2PAT, an open and realistic benchmark for patent drafting consisting\nof 1.8k patent-paper pairs describing the same inventions. To address the\ncomplex longdocument patent generation task, we propose chunk-based\noutline-guided generation using the research paper as invention specification.\nOur extensive evaluation using PAP2PAT and a human case study show that LLMs\ncan effectively leverage information from the paper, but still struggle to\nprovide the necessary level of detail. Fine-tuning leads to more patent-style\nlanguage, but also to more hallucination. We release our data and code\nhttps://github.com/boschresearch/Pap2Pat.\n","authors":["Valentin Knappich","Simon Razniewski","Anna Htty","Annemarie Friedrich"],"pdf_url":"https://arxiv.org/pdf/2410.07009v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.04201v1","updated":"2025-03-06T08:28:44Z","published":"2025-03-06T08:28:44Z","title":"Knowledge-Decoupled Synergetic Learning: An MLLM based Collaborative\n  Approach to Few-shot Multimodal Dialogue Intention Recognition","summary":"  Few-shot multimodal dialogue intention recognition is a critical challenge in\nthe e-commerce domainn. Previous methods have primarily enhanced model\nclassification capabilities through post-training techniques. However, our\nanalysis reveals that training for few-shot multimodal dialogue intention\nrecognition involves two interconnected tasks, leading to a seesaw effect in\nmulti-task learning. This phenomenon is attributed to knowledge interference\nstemming from the superposition of weight matrix updates during the training\nprocess. To address these challenges, we propose Knowledge-Decoupled Synergetic\nLearning (KDSL), which mitigates these issues by utilizing smaller models to\ntransform knowledge into interpretable rules, while applying the post-training\nof larger models. By facilitating collaboration between the large and small\nmultimodal large language models for prediction, our approach demonstrates\nsignificant improvements. Notably, we achieve outstanding results on two real\nTaobao datasets, with enhancements of 6.37\\% and 6.28\\% in online weighted F1\nscores compared to the state-of-the-art method, thereby validating the efficacy\nof our framework.\n","authors":["Bin Chen","Yu Zhang","Hongfei Ye","Ziyi Huang","Hongyang Chen"],"pdf_url":"https://arxiv.org/pdf/2503.04201v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2409.12106v3","updated":"2025-03-06T08:18:50Z","published":"2024-09-18T16:26:22Z","title":"Measuring Human and AI Values Based on Generative Psychometrics with\n  Large Language Models","summary":"  Human values and their measurement are long-standing interdisciplinary\ninquiry. Recent advances in AI have sparked renewed interest in this area, with\nlarge language models (LLMs) emerging as both tools and subjects of value\nmeasurement. This work introduces Generative Psychometrics for Values (GPV), an\nLLM-based, data-driven value measurement paradigm, theoretically grounded in\ntext-revealed selective perceptions. The core idea is to dynamically parse\nunstructured texts into perceptions akin to static stimuli in traditional\npsychometrics, measure the value orientations they reveal, and aggregate the\nresults. Applying GPV to human-authored blogs, we demonstrate its stability,\nvalidity, and superiority over prior psychological tools. Then, extending GPV\nto LLM value measurement, we advance the current art with 1) a psychometric\nmethodology that measures LLM values based on their scalable and free-form\noutputs, enabling context-specific measurement; 2) a comparative analysis of\nmeasurement paradigms, indicating response biases of prior methods; and 3) an\nattempt to bridge LLM values and their safety, revealing the predictive power\nof different value systems and the impacts of various values on LLM safety.\nThrough interdisciplinary efforts, we aim to leverage AI for next-generation\npsychometrics and psychometrics for value-aligned AI.\n","authors":["Haoran Ye","Yuhang Xie","Yuanyi Ren","Hanjun Fang","Xin Zhang","Guojie Song"],"pdf_url":"https://arxiv.org/pdf/2409.12106v3.pdf","comment":"Accepted at AAAI 2025"},{"id":"http://arxiv.org/abs/2503.04188v1","updated":"2025-03-06T08:03:51Z","published":"2025-03-06T08:03:51Z","title":"Measuring temporal effects of agent knowledge by date-controlled tool\n  use","summary":"  Temporal progression is an integral part of knowledge accumulation and\nupdate. Web search is frequently adopted as grounding for agent knowledge, yet\nits inappropriate configuration affects the quality of agent responses. Here,\nwe construct a tool-based out-of-sample testing framework to measure the\nknowledge variability of large language model (LLM) agents from distinct\ndate-controlled tools (DCTs). We demonstrate the temporal effects of an LLM\nagent as a writing assistant, which can use web search to help complete\nscientific publication abstracts. We show that temporal effects of the search\nengine translates into tool-dependent agent performance but can be alleviated\nwith base model choice and explicit reasoning instructions such as\nchain-of-thought prompting. Our results indicate that agent evaluation should\ntake a dynamical view and account for the temporal influence of tools and the\nupdates of external resources.\n","authors":["R. Patrick Xian","Qiming Cui","Stefan Bauer","Reza Abbasi-Asl"],"pdf_url":"https://arxiv.org/pdf/2503.04188v1.pdf","comment":"comments welcome"},{"id":"http://arxiv.org/abs/2503.04184v1","updated":"2025-03-06T07:53:24Z","published":"2025-03-06T07:53:24Z","title":"Large-Scale AI in Telecom: Charting the Roadmap for Innovation,\n  Scalability, and Enhanced Digital Experiences","summary":"  This white paper discusses the role of large-scale AI in the\ntelecommunications industry, with a specific focus on the potential of\ngenerative AI to revolutionize network functions and user experiences,\nespecially in the context of 6G systems. It highlights the development and\ndeployment of Large Telecom Models (LTMs), which are tailored AI models\ndesigned to address the complex challenges faced by modern telecom networks.\nThe paper covers a wide range of topics, from the architecture and deployment\nstrategies of LTMs to their applications in network management, resource\nallocation, and optimization. It also explores the regulatory, ethical, and\nstandardization considerations for LTMs, offering insights into their future\nintegration into telecom infrastructure. The goal is to provide a comprehensive\nroadmap for the adoption of LTMs to enhance scalability, performance, and\nuser-centric innovation in telecom networks.\n","authors":["Adnan Shahid","Adrian Kliks","Ahmed Al-Tahmeesschi","Ahmed Elbakary","Alexandros Nikou","Ali Maatouk","Ali Mokh","Amirreza Kazemi","Antonio De Domenico","Athanasios Karapantelakis","Bo Cheng","Bo Yang","Bohao Wang","Carlo Fischione","Chao Zhang","Chaouki Ben Issaid","Chau Yuen","Chenghui Peng","Chongwen Huang","Christina Chaccour","Christo Kurisummoottil Thomas","Dheeraj Sharma","Dimitris Kalogiros","Dusit Niyato","Eli De Poorter","Elissa Mhanna","Emilio Calvanese Strinati","Faouzi Bader","Fathi Abdeldayem","Fei Wang","Fenghao Zhu","Gianluca Fontanesi","Giovanni Geraci","Haibo Zhou","Hakimeh Purmehdi","Hamed Ahmadi","Hang Zou","Hongyang Du","Hoon Lee","Howard H. Yang","Iacopo Poli","Igor Carron","Ilias Chatzistefanidis","Inkyu Lee","Ioannis Pitsiorlas","Jaron Fontaine","Jiajun Wu","Jie Zeng","Jinan Li","Jinane Karam","Johny Gemayel","Juan Deng","Julien Frison","Kaibin Huang","Kehai Qiu","Keith Ball","Kezhi Wang","Kun Guo","Leandros Tassiulas","Lecorve Gwenole","Liexiang Yue","Lina Bariah","Louis Powell","Marcin Dryjanski","Maria Amparo Canaveras Galdon","Marios Kountouris","Maryam Hafeez","Maxime Elkael","Mehdi Bennis","Mehdi Boudjelli","Meiling Dai","Merouane Debbah","Michele Polese","Mohamad Assaad","Mohamed Benzaghta","Mohammad Al Refai","Moussab Djerrab","Mubeen Syed","Muhammad Amir","Na Yan","Najla Alkaabi","Nan Li","Nassim Sehad","Navid Nikaein","Omar Hashash","Pawel Sroka","Qianqian Yang","Qiyang Zhao","Rasoul Nikbakht Silab","Rex Ying","Roberto Morabito","Rongpeng Li","Ryad Madi","Salah Eddine El Ayoubi","Salvatore D'Oro","Samson Lasaulce","Serveh Shalmashi","Sige Liu","Sihem Cherrared","Swarna Bindu Chetty","Swastika Dutta","Syed A. R. Zaidi","Tianjiao Chen","Timothy Murphy","Tommaso Melodia","Tony Q. S. Quek","Vishnu Ram","Walid Saad","Wassim Hamidouche","Weilong Chen","Xiaoou Liu","Xiaoxue Yu","Xijun Wang","Xingyu Shang","Xinquan Wang","Xuelin Cao","Yang Su","Yanping Liang","Yansha Deng","Yifan Yang","Yingping Cui","Yu Sun","Yuxuan Chen","Yvan Pointurier","Zeinab Nehme","Zeinab Nezami","Zhaohui Yang","Zhaoyang Zhang","Zhe Liu","Zhenyu Yang","Zhu Han","Zhuang Zhou","Zihan Chen","Zirui Chen","Zitao Shuai"],"pdf_url":"https://arxiv.org/pdf/2503.04184v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.04176v1","updated":"2025-03-06T07:44:17Z","published":"2025-03-06T07:44:17Z","title":"TIMER: Temporal Instruction Modeling and Evaluation for Longitudinal\n  Clinical Records","summary":"  Large language models (LLMs) have emerged as promising tools for assisting in\nmedical tasks, yet processing Electronic Health Records (EHRs) presents unique\nchallenges due to their longitudinal nature. While LLMs' capabilities to\nperform medical tasks continue to improve, their ability to reason over\ntemporal dependencies across multiple patient visits and time frames remains\nunexplored. We introduce TIMER (Temporal Instruction Modeling and Evaluation\nfor Longitudinal Clinical Records), a framework that incorporate\ninstruction-response pairs grounding to different parts of a patient's record\nas a critical dimension in both instruction evaluation and tuning for\nlongitudinal clinical records. We develop TIMER-Bench, the first time-aware\nbenchmark that evaluates temporal reasoning capabilities over longitudinal\nEHRs, as well as TIMER-Instruct, an instruction-tuning methodology for LLMs to\nlearn reasoning over time. We demonstrate that models fine-tuned with\nTIMER-Instruct improve performance by 7.3% on human-generated benchmarks and\n9.2% on TIMER-Bench, indicating that temporal instruction-tuning improves model\nperformance for reasoning over EHR.\n","authors":["Hejie Cui","Alyssa Unell","Bowen Chen","Jason Alan Fries","Emily Alsentzer","Sanmi Koyejo","Nigam Shah"],"pdf_url":"https://arxiv.org/pdf/2503.04176v1.pdf","comment":"Preprint"},{"id":"http://arxiv.org/abs/2405.02318v3","updated":"2025-03-06T07:29:44Z","published":"2024-04-18T00:20:48Z","title":"Autoformalizing Natural Language to First-Order Logic: A Case Study in\n  Logical Fallacy Detection","summary":"  Translating natural language into formal language such as First-Order Logic\n(FOL) is a foundational challenge in NLP with wide-ranging applications in\nautomated reasoning, misinformation tracking, and knowledge validation. In this\npaper, we introduce Natural Language to First-Order Logic (NL2FOL), a framework\nto autoformalize natural language to FOL step by step using Large Language\nModels (LLMs). Our approach addresses key challenges in this translation\nprocess, including the integration of implicit background knowledge. By\nleveraging structured representations generated by NL2FOL, we use\nSatisfiability Modulo Theory (SMT) solvers to reason about the logical validity\nof natural language statements. We present logical fallacy detection as a case\nstudy to evaluate the efficacy of NL2FOL. Being neurosymbolic, our approach\nalso provides interpretable insights into the reasoning process and\ndemonstrates robustness without requiring model fine-tuning or labeled training\ndata. Our framework achieves strong performance on multiple datasets. On the\nLOGIC dataset, NL2FOL achieves an F1-score of 78%, while generalizing\neffectively to the LOGICCLIMATE dataset with an F1-score of 80%.\n","authors":["Abhinav Lalwani","Tasha Kim","Lovish Chopra","Christopher Hahn","Zhijing Jin","Mrinmaya Sachan"],"pdf_url":"https://arxiv.org/pdf/2405.02318v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2502.13681v2","updated":"2025-03-06T07:17:09Z","published":"2025-02-19T12:51:35Z","title":"An LLM-based Agent for Reliable Docker Environment Configuration","summary":"  Environment configuration is a critical yet time-consuming step in software\ndevelopment, especially when dealing with unfamiliar code repositories. While\nLarge Language Models (LLMs) demonstrate the potential to accomplish software\nengineering tasks, existing methods for environment configuration often rely on\nmanual efforts or fragile scripts, leading to inefficiencies and unreliable\noutcomes. We introduce Repo2Run, the first LLM-based agent designed to fully\nautomate environment configuration and generate executable Dockerfiles for\narbitrary Python repositories. We address two major challenges: (1) enabling\nthe LLM agent to configure environments within isolated Docker containers, and\n(2) ensuring the successful configuration process is recorded and accurately\ntransferred to a Dockerfile without error. To achieve this, we propose atomic\nconfiguration synthesis, featuring a dual-environment architecture (internal\nand external environment) with a rollback mechanism to prevent environment\n\"pollution\" from failed commands, guaranteeing atomic execution (execute fully\nor not at all) and a Dockerfile generator to transfer successful configuration\nsteps into runnable Dockerfiles. We evaluate Repo2Run~on our proposed benchmark\nof 420 recent Python repositories with unit tests, where it achieves an 86.0%\nsuccess rate, outperforming the best baseline by 63.9%. Repo2Run is available\nat https://github.com/bytedance/Repo2Run.\n","authors":["Ruida Hu","Chao Peng","Xinchen Wang","Cuiyun Gao"],"pdf_url":"https://arxiv.org/pdf/2502.13681v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.04155v1","updated":"2025-03-06T07:06:46Z","published":"2025-03-06T07:06:46Z","title":"BPQA Dataset: Evaluating How Well Language Models Leverage Blood\n  Pressures to Answer Biomedical Questions","summary":"  Clinical measurements such as blood pressures and respiration rates are\ncritical in diagnosing and monitoring patient outcomes. It is an important\ncomponent of biomedical data, which can be used to train transformer-based\nlanguage models (LMs) for improving healthcare delivery. It is, however,\nunclear whether LMs can effectively interpret and use clinical measurements. We\ninvestigate two questions: First, can LMs effectively leverage clinical\nmeasurements to answer related medical questions? Second, how to enhance an\nLM's performance on medical question-answering (QA) tasks that involve\nmeasurements? We performed a case study on blood pressure readings (BPs), a\nvital sign routinely monitored by medical professionals. We evaluated the\nperformance of four LMs: BERT, BioBERT, MedAlpaca, and GPT-3.5, on our newly\ndeveloped dataset, BPQA (Blood Pressure Question Answering). BPQA contains\n$100$ medical QA pairs that were verified by medical students and designed to\nrely on BPs . We found that GPT-3.5 and MedAlpaca (larger and medium sized LMs)\nbenefit more from the inclusion of BPs than BERT and BioBERT (small sized LMs).\nFurther, augmenting measurements with labels improves the performance of\nBioBERT and Medalpaca (domain specific LMs), suggesting that retrieval may be\nuseful for improving domain-specific LMs.\n","authors":["Chi Hang","Ruiqi Deng","Lavender Yao Jiang","Zihao Yang","Anton Alyakin","Daniel Alber","Eric Karl Oermann"],"pdf_url":"https://arxiv.org/pdf/2503.04155v1.pdf","comment":"9 pages"},{"id":"http://arxiv.org/abs/2502.18878v2","updated":"2025-03-06T07:06:40Z","published":"2025-02-26T06:45:29Z","title":"Learning to Generate Structured Output with Schema Reinforcement\n  Learning","summary":"  This study investigates the structured generation capabilities of large\nlanguage models (LLMs), focusing on producing valid JSON outputs against a\ngiven schema. Despite the widespread use of JSON in integrating language models\nwith programs, there is a lack of comprehensive analysis and benchmarking of\nthese capabilities. We explore various aspects of JSON generation, such as\nstructure understanding, escaping, and natural language description, to\ndetermine how to assess and enable LLMs to generate valid responses. Building\nupon this, we propose SchemaBench features around 40K different JSON schemas to\nobtain and assess models' abilities in generating valid JSON. We find that the\nlatest LLMs are still struggling to generate a valid JSON string. Moreover, we\ndemonstrate that incorporating reinforcement learning with a Fine-grained\nSchema Validator can further enhance models' understanding of JSON schema,\nleading to improved performance. Our models demonstrate significant improvement\nin both generating JSON outputs and downstream tasks.\n","authors":["Yaxi Lu","Haolun Li","Xin Cong","Zhong Zhang","Yesai Wu","Yankai Lin","Zhiyuan Liu","Fangming Liu","Maosong Sun"],"pdf_url":"https://arxiv.org/pdf/2502.18878v2.pdf","comment":"8 pages, 4 figures"},{"id":"http://arxiv.org/abs/2503.04150v1","updated":"2025-03-06T06:59:09Z","published":"2025-03-06T06:59:09Z","title":"Ticktack : Long Span Temporal Alignment of Large Language Models\n  Leveraging Sexagenary Cycle Time Expression","summary":"  Large language models (LLMs) suffer from temporal misalignment issues\nespecially across long span of time. The issue arises from knowing that LLMs\nare trained on large amounts of data where temporal information is rather\nsparse over long times, such as thousands of years, resulting in insufficient\nlearning or catastrophic forgetting by the LLMs. This paper proposes a\nmethodology named \"Ticktack\" for addressing the LLM's long-time span\nmisalignment in a yearly setting. Specifically, we first propose to utilize the\nsexagenary year expression instead of the Gregorian year expression employed by\nLLMs, achieving a more uniform distribution in yearly granularity. Then, we\nemploy polar coordinates to model the sexagenary cycle of 60 terms and the year\norder within each term, with additional temporal encoding to ensure LLMs\nunderstand them. Finally, we present a temporal representational alignment\napproach for post-training LLMs that effectively distinguishes time points with\nrelevant knowledge, hence improving performance on time-related tasks,\nparticularly over a long period. We also create a long time span benchmark for\nevaluation. Experimental results prove the effectiveness of our proposal.\n","authors":["Xue Han","Qian Hu","Yitong Wang","Wenchun Gao","Lianlian Zhang","Qing Wang","Lijun Mei","Chao Deng","Junlan Feng"],"pdf_url":"https://arxiv.org/pdf/2503.04150v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.04149v1","updated":"2025-03-06T06:56:59Z","published":"2025-03-06T06:56:59Z","title":"Dynamic Benchmarking of Reasoning Capabilities in Code Large Language\n  Models Under Data Contamination","summary":"  The rapid evolution of code largelanguage models underscores the need for\neffective and transparent benchmarking of their reasoning capabilities.\nHowever, the current benchmarking approach heavily depends on publicly\navailable, human-created datasets. The widespread use of these fixed benchmark\ndatasets makes the benchmarking process to be static and thus particularly\nsusceptible to data contamination, an unavoidable consequence of the extensive\ndata collection processes used to train Code LLMs. Existing approaches that\naddress data contamination often suffer from human effort limitations and\nimbalanced problem complexity. To tackle these challenges, we propose \\tool, a\nnovel benchmarking suite for evaluating Code LLMs under potential data\ncontamination. Given a seed programming problem, \\tool employs multiple agents\nto extract and modify the context without altering the core logic, generating\nsemantically equivalent variations. We introduce a dynamic data generation\nmethods and conduct empirical studies on two seed datasets across 21 Code LLMs.\nResults show that \\tool effectively benchmarks reasoning capabilities under\ncontamination risks while generating diverse problem sets to ensure consistent\nand reliable evaluations.\n","authors":["Simin Chen","Pranav Pusarla","Baishakhi Ray"],"pdf_url":"https://arxiv.org/pdf/2503.04149v1.pdf","comment":"https://codekaleidoscope.github.io/dycodeeval.html"},{"id":"http://arxiv.org/abs/2406.01145v2","updated":"2025-03-06T06:49:04Z","published":"2024-06-03T09:38:28Z","title":"Dual Reasoning: A GNN-LLM Collaborative Framework for Knowledge Graph\n  Question Answering","summary":"  Large Language Models (LLMs) excel at intuitive, implicit reasoning. Guiding\nLLMs to construct thought chains can enhance their deliberate reasoning\nabilities, but also faces challenges such as hallucination. Knowledge Graphs\n(KGs) can provide explicit structured knowledge for LLMs to alleviate these\nissues. However, existing KG-enhanced methods often overlook explicit graph\nlearning, making it challenging to efficiently provide precise reasoning chains\nfor LLMs. Following dual-process theory, we propose Dual-Reasoning (DualR), a\nnovel framework that integrates an external system based on Graph Neural\nNetwork (GNN) for explicit reasoning on KGs, complementing the implicit\nreasoning of LLMs through externalized reasoning chains. DualR designs an\nLLM-empowered GNN module for explicit learning on KGs, efficiently extracting\nhigh-quality reasoning chains. These reasoning chains are then refined to a\nknowledge-enhanced multiple-choice prompt, guiding a frozen LLM to reason\nthoughtfully for final answer determination. Extensive experiments on three\nbenchmark KGQA datasets demonstrate that DualR achieves state-of-the-art\nperformance while maintaining high efficiency and interpretability.\n","authors":["Guangyi Liu","Yongqi Zhang","Yong Li","Quanming Yao"],"pdf_url":"https://arxiv.org/pdf/2406.01145v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2502.12767v2","updated":"2025-03-06T06:41:40Z","published":"2025-02-18T11:31:52Z","title":"R2-KG: General-Purpose Dual-Agent Framework for Reliable Reasoning on\n  Knowledge Graphs","summary":"  Recent studies have combined Large Language Models (LLMs) with Knowledge\nGraphs (KGs) to enhance reasoning, improving inference accuracy without\nadditional training while mitigating hallucination. However, existing\nframeworks are often rigid, struggling to adapt to KG or task changes. They\nalso rely heavily on powerful LLMs for reliable (i.e., trustworthy) reasoning.\nTo address this, We introduce R2-KG, a plug-and-play, dual-agent framework that\nseparates reasoning into two roles: an Operator (a low-capacity LLM) that\ngathers evidence and a Supervisor (a high-capacity LLM) that makes final\njudgments. This design is cost-efficient for LLM inference while still\nmaintaining strong reasoning accuracy. Additionally, R2-KG employs an\nAbstention mechanism, generating answers only when sufficient evidence is\ncollected from KG, which significantly enhances reliability. Experiments across\nmultiple KG-based reasoning tasks show that R2-KG consistently outperforms\nbaselines in both accuracy and reliability, regardless of the inherent\ncapability of LLMs used as the Operator. Further experiments reveal that the\nsingle-agent version of R2-KG, equipped with a strict self-consistency\nstrategy, achieves significantly higher-than-baseline reliability while\nreducing inference cost. However, it also leads to a higher abstention rate in\ncomplex KGs. Our findings establish R2-KG as a flexible and cost-effective\nsolution for KG-based reasoning. It reduces reliance on high-capacity LLMs\nwhile ensuring trustworthy inference.\n","authors":["Sumin Jo","Junseong Choi","Jiho Kim","Edward Choi"],"pdf_url":"https://arxiv.org/pdf/2502.12767v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.17635v2","updated":"2025-03-06T06:39:56Z","published":"2024-10-23T07:53:29Z","title":"Markov Chain of Thought for Efficient Mathematical Reasoning","summary":"  Chain of Thought (CoT) of multi-step benefits from the logical structure of\nthe reasoning steps and task-specific actions, significantly enhancing the\nmathematical reasoning capabilities of large language models. As the prevalence\nof long CoT, the number of reasoning steps exceeds manageable token limits and\nleads to higher computational demands. Inspired by the fundamental logic of\nhuman cognition, \"derive, then reduce\", we conceptualize the standard\nmulti-step CoT as a novel Markov Chain of Thought (MCoT). In this study, we\nconsider the mathematical reasoning task, defining each reasoning step as text\naccompanied by a Python code snippet. To facilitate a longer reasoning path,\nself-correction is enabled through interactions with the code interpreter. Our\nMCoT aims to compress previous reasoning steps into a simplified question,\nenabling efficient next-step inference without relying on a lengthy KV cache.\nIn our experiments, we curate the $\\texttt{MCoTInstruct}$ dataset, and the\nempirical results indicate that MCoT not only significantly enhances efficiency\nbut also maintains comparable accuracy. While much remains to be explored, this\nwork paves the way for exploring the long CoT reasoning abilities of LLMs. The\ncode is available at https://github.com/james-yw/Markov-Chain-of-Thought\n","authors":["Wen Yang","Minpeng Liao","Kai Fan"],"pdf_url":"https://arxiv.org/pdf/2410.17635v2.pdf","comment":"Camera ready version for NAACL 2025 Main"},{"id":"http://arxiv.org/abs/2503.04141v1","updated":"2025-03-06T06:39:25Z","published":"2025-03-06T06:39:25Z","title":"HEISIR: Hierarchical Expansion of Inverted Semantic Indexing for\n  Training-free Retrieval of Conversational Data using LLMs","summary":"  The growth of conversational AI services has increased demand for effective\ninformation retrieval from dialogue data. However, existing methods often face\nchallenges in capturing semantic intent or require extensive labeling and\nfine-tuning. This paper introduces HEISIR (Hierarchical Expansion of Inverted\nSemantic Indexing for Retrieval), a novel framework that enhances semantic\nunderstanding in conversational data retrieval through optimized data\ningestion, eliminating the need for resource-intensive labeling or model\nadaptation. HEISIR implements a two-step process: (1) Hierarchical Triplets\nFormulation and (2) Adjunct Augmentation, creating semantic indices consisting\nof Subject-Verb-Object-Adjunct (SVOA) quadruplets. This structured\nrepresentation effectively captures the underlying semantic information from\ndialogue content. HEISIR achieves high retrieval performance while maintaining\nlow latency during the actual retrieval process. Our experimental results\ndemonstrate that HEISIR outperforms fine-tuned models across various embedding\ntypes and language models. Beyond improving retrieval capabilities, HEISIR also\noffers opportunities for intent and topic analysis in conversational data,\nproviding a versatile solution for dialogue systems.\n","authors":["Sangyeop Kim","Hangyeul Lee","Yohan Lee"],"pdf_url":"https://arxiv.org/pdf/2503.04141v1.pdf","comment":"Accepted by NAACL 2025 (Findings)"},{"id":"http://arxiv.org/abs/2502.14074v2","updated":"2025-03-06T06:32:54Z","published":"2025-02-19T19:59:16Z","title":"Investigating Non-Transitivity in LLM-as-a-Judge","summary":"  Automatic evaluation methods based on large language models (LLMs) are\nemerging as the standard tool for assessing the instruction-following abilities\nof LLM-based agents. The most common method in this paradigm, pairwise\ncomparisons with a baseline model, critically depends on the assumption of\ntransitive preferences. However, the validity of this assumption remains\nlargely unexplored. In this study, we investigate the presence of\nnon-transitivity within the AlpacaEval framework and analyze its effects on\nmodel rankings. We find that LLM judges exhibit non-transitive preferences,\nleading to rankings that are sensitive to the choice of the baseline model. To\nmitigate this issue, we show that round-robin tournaments combined with\nBradley-Terry models of preference can produce more reliable rankings. Notably,\nour method increases both the Spearman correlation and the Kendall correlation\nwith Chatbot Arena (95.0% -> 96.4% and 82.1% -> 86.3% respectively). To address\nthe computational cost of round-robin tournaments, we propose Swiss-Wise\nIterative Matchmaking (Swim) tournaments, using a dynamic matching strategy to\ncapture the benefits of round-robin tournaments while maintaining computational\nefficiency.\n","authors":["Yi Xu","Laura Ruis","Tim Rocktschel","Robert Kirk"],"pdf_url":"https://arxiv.org/pdf/2502.14074v2.pdf","comment":"8 pages, 6 figures, 2 tables (30 pages, 11 figures, 8 tables\n  including references and appendices)"},{"id":"http://arxiv.org/abs/2503.04135v1","updated":"2025-03-06T06:28:36Z","published":"2025-03-06T06:28:36Z","title":"Biological Sequence with Language Model Prompting: A Survey","summary":"  Large Language models (LLMs) have emerged as powerful tools for addressing\nchallenges across diverse domains. Notably, recent studies have demonstrated\nthat large language models significantly enhance the efficiency of biomolecular\nanalysis and synthesis, attracting widespread attention from academics and\nmedicine. In this paper, we systematically investigate the application of\nprompt-based methods with LLMs to biological sequences, including DNA, RNA,\nproteins, and drug discovery tasks. Specifically, we focus on how prompt\nengineering enables LLMs to tackle domain-specific problems, such as promoter\nsequence prediction, protein structure modeling, and drug-target binding\naffinity prediction, often with limited labeled data. Furthermore, our\ndiscussion highlights the transformative potential of prompting in\nbioinformatics while addressing key challenges such as data scarcity,\nmultimodal fusion, and computational resource limitations. Our aim is for this\npaper to function both as a foundational primer for newcomers and a catalyst\nfor continued innovation within this dynamic field of study.\n","authors":["Jiyue Jiang","Zikang Wang","Yuheng Shan","Heyan Chai","Jiayi Li","Zixian Ma","Xinrui Zhang","Yu Li"],"pdf_url":"https://arxiv.org/pdf/2503.04135v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.18104v2","updated":"2025-03-06T05:54:29Z","published":"2024-11-27T07:32:56Z","title":"Training and Evaluating Language Models with Template-based Data\n  Generation","summary":"  The rapid advancement of large language models (LLMs) such as GPT-3, PaLM,\nand Llama has significantly transformed natural language processing, showcasing\nremarkable capabilities in understanding and generating language. However,\nthese models often struggle with tasks requiring complex reasoning,\nparticularly in mathematical problem-solving, due in part to the scarcity of\nlarge-scale, high-quality, domain-specific datasets necessary for training\nsophisticated reasoning abilities. To address this limitation, we introduce\nTemplate-based Data Generation (TDG), a novel approach that leverages LLMs\n(GPT-4) to automatically generate parameterized meta-templates, which are then\nused to synthesize a vast array of high-quality problems and solutions.\nLeveraging TDG, we create TemplateMath Part I: TemplateGSM, a dataset\ncomprising over 7 million synthetically generated grade school math\nproblems--each accompanied by code-based and natural language solutions--with\nthe potential to generate an effectively unlimited number more. This dataset\nalleviates the scarcity of large-scale mathematical datasets and serves as a\nvaluable resource for pre-training, fine-tuning, and evaluating LLMs in\nmathematical reasoning. Our method not only enables the generation of virtually\ninfinite data but also elevates data augmentation to a new level by using GPT-4\nfor meta-template generation, ensuring diverse and high-quality problem\nstructures. The TemplateMath Part I: TemplateGSM dataset is publicly available\nat https://huggingface.co/datasets/math-ai/TemplateGSM. The code is available\nat https://github.com/iiis-ai/TemplateMath.\n","authors":["Yifan Zhang"],"pdf_url":"https://arxiv.org/pdf/2411.18104v2.pdf","comment":"9 pages, 2 figures"},{"id":"http://arxiv.org/abs/2409.07055v2","updated":"2025-03-06T05:48:54Z","published":"2024-09-11T07:01:08Z","title":"Legal Fact Prediction: The Missing Piece in Legal Judgment Prediction","summary":"  Legal judgment prediction (LJP), which enables litigants and their lawyers to\nforecast judgment outcomes and refine litigation strategies, has emerged as a\ncrucial legal NLP task. Existing studies typically utilize legal facts, i.e.,\nfacts that have been established by evidence and determined by the judge, to\npredict the judgment. However, legal facts are often difficult to obtain in the\nearly stages of litigation, significantly limiting the practical applicability\nof fact-based LJP. To address this limitation, we propose a novel legal NLP\ntask: \\textit{legal fact prediction} (LFP), which takes the evidence submitted\nby litigants for trial as input to predict legal facts, thereby empowering\nfact-based LJP technologies to perform prediction in the absence of\nground-truth legal facts. We also propose the first benchmark dataset,\nLFPBench, for evaluating the LFP task. Our extensive experiments on LFPBench\ndemonstrate the effectiveness of LFP-empowered LJP and highlight promising\nresearch directions for LFP. Our code and data are available at\nhttps://github.com/HPRCEST/LFPBench.\n","authors":["Junkai Liu","Yujie Tong","Hui Huang","Bowen Zheng","Yiran Hu","Peicheng Wu","Chuan Xiao","Makoto Onizuka","Muyun Yang","Shuyuan Zheng"],"pdf_url":"https://arxiv.org/pdf/2409.07055v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.02398v2","updated":"2025-03-06T05:46:40Z","published":"2024-11-04T18:59:51Z","title":"Prompting with Phonemes: Enhancing LLMs' Multilinguality for Non-Latin\n  Script Languages","summary":"  Although multilingual LLMs have achieved remarkable performance across\nbenchmarks, we find they continue to underperform on non-Latin script languages\nacross contemporary LLM families. This discrepancy arises from the fact that\nLLMs are pretrained with orthographic scripts, which are dominated by Latin\ncharacters that obscure their shared phonology with non-Latin scripts. We\npropose leveraging phonemic transcriptions as complementary signals to induce\nscript-invariant representations. Our study demonstrates that integrating\nphonemic signals improves performance across both non-Latin and Latin script\nlanguages, with a particularly significant impact on closing the performance\ngap between the two. Through detailed experiments, we show that phonemic and\northographic scripts retrieve distinct examples for in-context learning (ICL).\nThis motivates our proposed Mixed-ICL retrieval strategy, where further\naggregation from both leads to our significant performance improvements for\nboth Latin script languages (up to 12.6%) and non-Latin script languages (up to\n15.1%) compared to randomized ICL retrieval.\n","authors":["Hoang H Nguyen","Khyati Mahajan","Vikas Yadav","Julian Salazar","Philip S. Yu","Masoud Hashemi","Rishabh Maheshwary"],"pdf_url":"https://arxiv.org/pdf/2411.02398v2.pdf","comment":"Accepted for NAACL 2025 (Main Conference)"},{"id":"http://arxiv.org/abs/2503.04113v1","updated":"2025-03-06T05:43:35Z","published":"2025-03-06T05:43:35Z","title":"Uncovering Gaps in How Humans and LLMs Interpret Subjective Language","summary":"  Humans often rely on subjective natural language to direct language models\n(LLMs); for example, users might instruct the LLM to write an enthusiastic\nblogpost, while developers might train models to be helpful and harmless using\nLLM-based edits. The LLM's operational semantics of such subjective phrases --\nhow it adjusts its behavior when each phrase is included in the prompt -- thus\ndictates how aligned it is with human intent. In this work, we uncover\ninstances of misalignment between LLMs' actual operational semantics and what\nhumans expect. Our method, TED (thesaurus error detector), first constructs a\nthesaurus that captures whether two phrases have similar operational semantics\naccording to the LLM. It then elicits failures by unearthing disagreements\nbetween this thesaurus and a human-constructed reference. TED routinely\nproduces surprising instances of misalignment; for example, Mistral 7B Instruct\nproduces more harassing outputs when it edits text to be witty, and Llama 3 8B\nInstruct produces dishonest articles when instructed to make the articles\nenthusiastic. Our results demonstrate that humans can uncover unexpected LLM\nbehavior by scrutinizing relationships between abstract concepts, without\nsupervising outputs directly.\n","authors":["Erik Jones","Arjun Patrawala","Jacob Steinhardt"],"pdf_url":"https://arxiv.org/pdf/2503.04113v1.pdf","comment":"Published at ICLR 2025"},{"id":"http://arxiv.org/abs/2502.07272v2","updated":"2025-03-06T05:41:32Z","published":"2025-02-11T05:39:49Z","title":"GENERator: A Long-Context Generative Genomic Foundation Model","summary":"  Advancements in DNA sequencing technologies have significantly improved our\nability to decode genomic sequences. However, the prediction and interpretation\nof these sequences remain challenging due to the intricate nature of genetic\nmaterial. Large language models (LLMs) have introduced new opportunities for\nbiological sequence analysis. Recent developments in genomic language models\nhave underscored the potential of LLMs in deciphering DNA sequences.\nNonetheless, existing models often face limitations in robustness and\napplication scope, primarily due to constraints in model structure and training\ndata scale. To address these limitations, we present GENERator, a generative\ngenomic foundation model featuring a context length of 98k base pairs (bp) and\n1.2B parameters. Trained on an expansive dataset comprising 386B bp of\neukaryotic DNA, the GENERator demonstrates state-of-the-art performance across\nboth established and newly proposed benchmarks. The model adheres to the\ncentral dogma of molecular biology, accurately generating protein-coding\nsequences that translate into proteins structurally analogous to known\nfamilies. It also shows significant promise in sequence optimization,\nparticularly through the prompt-responsive generation of enhancer sequences\nwith specific activity profiles. These capabilities position the GENERator as a\npivotal tool for genomic research and biotechnological advancement, enhancing\nour ability to interpret and predict complex biological systems and enabling\nprecise genomic interventions. Implementation details and supplementary\nresources are available at https://github.com/GenerTeam/GENERator.\n","authors":["Wei Wu","Qiuyi Li","Mingyang Li","Kun Fu","Fuli Feng","Jieping Ye","Hui Xiong","Zheng Wang"],"pdf_url":"https://arxiv.org/pdf/2502.07272v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2405.20680v5","updated":"2025-03-06T05:34:13Z","published":"2024-05-31T08:22:49Z","title":"Unraveling and Mitigating Retriever Inconsistencies in\n  Retrieval-Augmented Large Language Models","summary":"  Although Retrieval-Augmented Large Language Models (RALMs) demonstrate their\nsuperiority in terms of factuality, they do not consistently outperform the\noriginal retrieval-free Language Models (LMs). Our experiments reveal that this\nexample-level performance inconsistency exists not only between\nretrieval-augmented and retrieval-free LM but also among different retrievers.\nTo understand this phenomenon, we investigate the degeneration behavior of\nRALMs and theoretically decompose it into four categories. Further analysis\nbased on our decomposition reveals that the innate difference in knowledge\nsources and the unpredictable degeneration of the reader model contribute most\nto the inconsistency. Drawing from our analysis, we introduce Ensemble of\nRetrievers (EoR), a trainable framework that can adaptively retrieve from\ndifferent knowledge sources and effectively decrease unpredictable reader\nerrors. Our experiments on Open Domain Question Answering show that EoR\nsubstantially improves performance over the RALM with a single retriever by\nconsiderably reducing inconsistent behaviors.\n","authors":["Mingda Li","Xinyu Li","Yifan Chen","Wenfeng Xuan","Weinan Zhang"],"pdf_url":"https://arxiv.org/pdf/2405.20680v5.pdf","comment":"ACL 2024 (findings)"},{"id":"http://arxiv.org/abs/2503.04104v1","updated":"2025-03-06T05:25:43Z","published":"2025-03-06T05:25:43Z","title":"LLMs Can Generate a Better Answer by Aggregating Their Own Responses","summary":"  Large Language Models (LLMs) have shown remarkable capabilities across tasks,\nyet they often require additional prompting techniques when facing complex\nproblems. While approaches like self-correction and response selection have\nemerged as popular solutions, recent studies have shown these methods perform\npoorly when relying on the LLM itself to provide feedback or selection\ncriteria. We argue this limitation stems from the fact that common LLM\npost-training procedures lack explicit supervision for discriminative judgment\ntasks. In this paper, we propose Generative Self-Aggregation (GSA), a novel\nprompting method that improves answer quality without requiring the model's\ndiscriminative capabilities. GSA first samples multiple diverse responses from\nthe LLM, then aggregates them to obtain an improved solution. Unlike previous\napproaches, our method does not require the LLM to correct errors or compare\nresponse quality; instead, it leverages the model's generative abilities to\nsynthesize a new response based on the context of multiple samples. While GSA\nshares similarities with the self-consistency (SC) approach for response\naggregation, SC requires specific verifiable tokens to enable majority voting.\nIn contrast, our approach is more general and can be applied to open-ended\ntasks. Empirical evaluation demonstrates that GSA effectively improves response\nquality across various tasks, including mathematical reasoning, knowledge-based\nproblems, and open-ended generation tasks such as code synthesis and\nconversational responses.\n","authors":["Zichong Li","Xinyu Feng","Yuheng Cai","Zixuan Zhang","Tianyi Liu","Chen Liang","Weizhu Chen","Haoyu Wang","Tuo Zhao"],"pdf_url":"https://arxiv.org/pdf/2503.04104v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.04099v1","updated":"2025-03-06T05:15:34Z","published":"2025-03-06T05:15:34Z","title":"Disparities in LLM Reasoning Accuracy and Explanations: A Case Study on\n  African American English","summary":"  Large Language Models (LLMs) have demonstrated remarkable capabilities in\nreasoning tasks, leading to their widespread deployment. However, recent\nstudies have highlighted concerning biases in these models, particularly in\ntheir handling of dialectal variations like African American English (AAE). In\nthis work, we systematically investigate dialectal disparities in LLM reasoning\ntasks. We develop an experimental framework comparing LLM performance given\nStandard American English (SAE) and AAE prompts, combining LLM-based dialect\nconversion with established linguistic analyses. We find that LLMs consistently\nproduce less accurate responses and simpler reasoning chains and explanations\nfor AAE inputs compared to equivalent SAE questions, with disparities most\npronounced in social science and humanities domains. These findings highlight\nsystematic differences in how LLMs process and reason about different language\nvarieties, raising important questions about the development and deployment of\nthese systems in our multilingual and multidialectal world. Our code repository\nis publicly available at https://github.com/Runtaozhou/dialect_bias_eval.\n","authors":["Runtao Zhou","Guangya Wan","Saadia Gabriel","Sheng Li","Alexander J Gates","Maarten Sap","Thomas Hartvigsen"],"pdf_url":"https://arxiv.org/pdf/2503.04099v1.pdf","comment":"ARR Under Review, First two authors contribute equally"},{"id":"http://arxiv.org/abs/2503.04095v1","updated":"2025-03-06T05:08:40Z","published":"2025-03-06T05:08:40Z","title":"Chart-HQA: A Benchmark for Hypothetical Question Answering in Charts","summary":"  Multimodal Large Language Models (MLLMs) have garnered significant attention\nfor their strong visual-semantic understanding. Most existing chart benchmarks\nevaluate MLLMs' ability to parse information from charts to answer\nquestions.However, they overlook the inherent output biases of MLLMs, where\nmodels rely on their parametric memory to answer questions rather than\ngenuinely understanding the chart content. To address this limitation, we\nintroduce a novel Chart Hypothetical Question Answering (HQA) task, which\nimposes assumptions on the same question to compel models to engage in\ncounterfactual reasoning based on the chart content. Furthermore, we introduce\nHAI, a human-AI interactive data synthesis approach that leverages the\nefficient text-editing capabilities of LLMs alongside human expert knowledge to\ngenerate diverse and high-quality HQA data at a low cost. Using HAI, we\nconstruct Chart-HQA, a challenging benchmark synthesized from publicly\navailable data sources. Evaluation results on 18 MLLMs of varying model sizes\nreveal that current models face significant generalization challenges and\nexhibit imbalanced reasoning performance on the HQA task.\n","authors":["Xiangnan Chen","Yuancheng Fang","Qian Xiao","Juncheng Li","Jun Lin","Siliang Tang","Yi Yang","Yueting Zhuang"],"pdf_url":"https://arxiv.org/pdf/2503.04095v1.pdf","comment":"Under review"},{"id":"http://arxiv.org/abs/2501.17399v2","updated":"2025-03-06T04:41:56Z","published":"2025-01-29T03:29:24Z","title":"MultiChallenge: A Realistic Multi-Turn Conversation Evaluation Benchmark\n  Challenging to Frontier LLMs","summary":"  We present MultiChallenge, a pioneering benchmark evaluating large language\nmodels (LLMs) on conducting multi-turn conversations with human users, a\ncrucial yet underexamined capability for their applications. MultiChallenge\nidentifies four categories of challenges in multi-turn conversations that are\nnot only common and realistic among current human-LLM interactions, but are\nalso challenging to all current frontier LLMs. All 4 challenges require\naccurate instruction-following, context allocation, and in-context reasoning at\nthe same time. We also develop LLM as judge with instance-level rubrics to\nfacilitate an automatic evaluation method with fair agreement with experienced\nhuman raters. Despite achieving near-perfect scores on existing multi-turn\nevaluation benchmarks, all frontier models have less than 50% accuracy on\nMultiChallenge, with the top-performing Claude 3.5 Sonnet (June 2024) achieving\njust a 41.4% average accuracy.\n","authors":["Ved Sirdeshmukh","Kaustubh Deshpande","Johannes Mols","Lifeng Jin","Ed-Yeremai Cardona","Dean Lee","Jeremy Kritz","Willow Primack","Summer Yue","Chen Xing"],"pdf_url":"https://arxiv.org/pdf/2501.17399v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2405.15683v3","updated":"2025-03-06T03:59:59Z","published":"2024-05-24T16:21:59Z","title":"Visual Description Grounding Reduces Hallucinations and Boosts Reasoning\n  in LVLMs","summary":"  Large Vision-Language Models (LVLMs) often produce responses that misalign\nwith factual information, a phenomenon known as hallucinations. While\nhallucinations are well-studied, the exact causes behind them remain\nunderexplored. In this paper, we first investigate the root causes of\nhallucinations in LVLMs. Our findings reveal that existing mitigation\ntechniques primarily reduce hallucinations for visual recognition prompts-those\nthat require simple descriptions of visual elements-but fail for cognitive\nprompts that demand deliberate reasoning. We identify the core issue as a lack\nof true visual perception in LVLMs: although they can accurately recognize\nvisual elements, they struggle to fully interpret these elements in the context\nof the input prompt and effectively link this recognition to their internal\nknowledge, which is critical for reasoning. To address this gap, we introduce\nVisual Description Grounded Decoding (VDGD), a simple, robust, and\ntraining-free method designed to enhance visual perception and improve\nreasoning capabilities in LVLMs. VDGD works by first generating a detailed\ndescription of the image and appending it as a prefix to the instruction.\nDuring response generation, tokens are sampled based on their KL divergence to\nthe description, favoring candidates with lower divergence. Experimental\nresults on multiple visual reasoning benchmarks and LVLMs demonstrate that VDGD\nconsistently outperforms existing baselines 2% - 33%. Finally, we introduce\nVaLLu, a benchmark designed for comprehensive evaluation of the cognitive\ncapabilities of LVLMs.\n","authors":["Sreyan Ghosh","Chandra Kiran Reddy Evuru","Sonal Kumar","Utkarsh Tyagi","Oriol Nieto","Zeyu Jin","Dinesh Manocha"],"pdf_url":"https://arxiv.org/pdf/2405.15683v3.pdf","comment":"Accepted to ICLR 2025. Project: https://sreyan88.github.io/VDGD/"},{"id":"http://arxiv.org/abs/2503.04065v1","updated":"2025-03-06T03:43:21Z","published":"2025-03-06T03:43:21Z","title":"PP-DocBee: Improving Multimodal Document Understanding Through a Bag of\n  Tricks","summary":"  With the rapid advancement of digitalization, various document images are\nbeing applied more extensively in production and daily life, and there is an\nincreasingly urgent need for fast and accurate parsing of the content in\ndocument images. Therefore, this report presents PP-DocBee, a novel multimodal\nlarge language model designed for end-to-end document image understanding.\nFirst, we develop a data synthesis strategy tailored to document scenarios in\nwhich we build a diverse dataset to improve the model generalization. Then, we\napply a few training techniques, including dynamic proportional sampling, data\npreprocessing, and OCR postprocessing strategies. Extensive evaluations\ndemonstrate the superior performance of PP-DocBee, achieving state-of-the-art\nresults on English document understanding benchmarks and even outperforming\nexisting open source and commercial models in Chinese document understanding.\nThe source code and pre-trained models are publicly available at\n\\href{https://github.com/PaddlePaddle/PaddleMIX}{https://github.com/PaddlePaddle/PaddleMIX}.\n","authors":["Feng Ni","Kui Huang","Yao Lu","Wenyu Lv","Guanzhong Wang","Zeyu Chen","Yi Liu"],"pdf_url":"https://arxiv.org/pdf/2503.04065v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.04064v1","updated":"2025-03-06T03:41:47Z","published":"2025-03-06T03:41:47Z","title":"Uncovering inequalities in new knowledge learning by large language\n  models across different languages","summary":"  As large language models (LLMs) gradually become integral tools for problem\nsolving in daily life worldwide, understanding linguistic inequality is\nbecoming increasingly important. Existing research has primarily focused on\nstatic analyses that assess the disparities in the existing knowledge and\ncapabilities of LLMs across languages. However, LLMs are continuously evolving,\nacquiring new knowledge to generate up-to-date, domain-specific responses.\nInvestigating linguistic inequalities within this dynamic process is,\ntherefore, also essential. In this paper, we explore inequalities in new\nknowledge learning by LLMs across different languages and four key dimensions:\neffectiveness, transferability, prioritization, and robustness. Through\nextensive experiments under two settings (in-context learning and fine-tuning)\nusing both proprietary and open-source models, we demonstrate that low-resource\nlanguages consistently face disadvantages across all four dimensions. By\nshedding light on these disparities, we aim to raise awareness of linguistic\ninequalities in LLMs' new knowledge learning, fostering the development of more\ninclusive and equitable future LLMs.\n","authors":["Chenglong Wang","Haoyu Tang","Xiyuan Yang","Yueqi Xie","Jina Suh","Sunayana Sitaram","Junming Huang","Yu Xie","Zhaoya Gong","Xing Xie","Fangzhao Wu"],"pdf_url":"https://arxiv.org/pdf/2503.04064v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.02365v2","updated":"2025-03-06T03:29:31Z","published":"2025-03-04T07:45:45Z","title":"EchoQA: A Large Collection of Instruction Tuning Data for Echocardiogram\n  Reports","summary":"  We introduce a novel question-answering (QA) dataset using echocardiogram\nreports sourced from the Medical Information Mart for Intensive Care database.\nThis dataset is specifically designed to enhance QA systems in cardiology,\nconsisting of 771,244 QA pairs addressing a wide array of cardiac abnormalities\nand their severity. We compare large language models (LLMs), including\nopen-source and biomedical-specific models for zero-shot evaluation, and\nclosed-source models for zero-shot and three-shot evaluation. Our results show\nthat fine-tuning LLMs improves performance across various QA metrics,\nvalidating the value of our dataset. Clinicians also qualitatively evaluate the\nbest-performing model to assess the LLM responses for correctness. Further, we\nconduct fine-grained fairness audits to assess the bias-performance trade-off\nof LLMs across various social determinants of health. Our objective is to\npropel the field forward by establishing a benchmark for LLM AI agents aimed at\nsupporting clinicians with cardiac differential diagnoses, thereby reducing the\ndocumentation burden that contributes to clinician burnout and enabling\nhealthcare professionals to focus more on patient care.\n","authors":["Lama Moukheiber","Mira Moukheiber","Dana Moukheiiber","Jae-Woo Ju","Hyung-Chul Lee"],"pdf_url":"https://arxiv.org/pdf/2503.02365v2.pdf","comment":"NeurIPS SafeGenAI 2024"},{"id":"http://arxiv.org/abs/2401.08392v4","updated":"2025-03-06T03:27:02Z","published":"2024-01-16T14:33:09Z","title":"DoraemonGPT: Toward Understanding Dynamic Scenes with Large Language\n  Models (Exemplified as A Video Agent)","summary":"  Recent LLM-driven visual agents mainly focus on solving image-based tasks,\nwhich limits their ability to understand dynamic scenes, making it far from\nreal-life applications like guiding students in laboratory experiments and\nidentifying their mistakes. Hence, this paper explores DoraemonGPT, a\ncomprehensive and conceptually elegant system driven by LLMs to understand\ndynamic scenes. Considering the video modality better reflects the\never-changing nature of real-world scenarios, we exemplify DoraemonGPT as a\nvideo agent. Given a video with a question/task, DoraemonGPT begins by\nconverting the input video into a symbolic memory that stores task-related\nattributes. This structured representation allows for spatial-temporal querying\nand reasoning by well-designed sub-task tools, resulting in concise\nintermediate results. Recognizing that LLMs have limited internal knowledge\nwhen it comes to specialized domains (e.g., analyzing the scientific principles\nunderlying experiments), we incorporate plug-and-play tools to assess external\nknowledge and address tasks across different domains. Moreover, a novel\nLLM-driven planner based on Monte Carlo Tree Search is introduced to explore\nthe large planning space for scheduling various tools. The planner iteratively\nfinds feasible solutions by backpropagating the result's reward, and multiple\nsolutions can be summarized into an improved final answer. We extensively\nevaluate DoraemonGPT's effectiveness on three benchmarks and several\nin-the-wild scenarios. The code will be released at\nhttps://github.com/z-x-yang/DoraemonGPT.\n","authors":["Zongxin Yang","Guikun Chen","Xiaodi Li","Wenguan Wang","Yi Yang"],"pdf_url":"https://arxiv.org/pdf/2401.08392v4.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.06916v2","updated":"2025-03-06T03:04:44Z","published":"2024-10-09T14:15:30Z","title":"SWIFT: On-the-Fly Self-Speculative Decoding for LLM Inference\n  Acceleration","summary":"  Speculative decoding (SD) has emerged as a widely used paradigm to accelerate\nLLM inference without compromising quality. It works by first employing a\ncompact model to draft multiple tokens efficiently and then using the target\nLLM to verify them in parallel. While this technique has achieved notable\nspeedups, most existing approaches necessitate either additional parameters or\nextensive training to construct effective draft models, thereby restricting\ntheir applicability across different LLMs and tasks. To address this\nlimitation, we explore a novel plug-and-play SD solution with layer-skipping,\nwhich skips intermediate layers of the target LLM as the compact draft model.\nOur analysis reveals that LLMs exhibit great potential for self-acceleration\nthrough layer sparsity and the task-specific nature of this sparsity. Building\non these insights, we introduce SWIFT, an on-the-fly self-speculative decoding\nalgorithm that adaptively selects intermediate layers of LLMs to skip during\ninference. SWIFT does not require auxiliary models or additional training,\nmaking it a plug-and-play solution for accelerating LLM inference across\ndiverse input data streams. Our extensive experiments across a wide range of\nmodels and downstream tasks demonstrate that SWIFT can achieve over a 1.3x-1.6x\nspeedup while preserving the original distribution of the generated text. We\nrelease our code in https://github.com/hemingkx/SWIFT.\n","authors":["Heming Xia","Yongqi Li","Jun Zhang","Cunxiao Du","Wenjie Li"],"pdf_url":"https://arxiv.org/pdf/2410.06916v2.pdf","comment":"ICLR 2025, camera-ready version"},{"id":"http://arxiv.org/abs/2408.15176v2","updated":"2025-03-06T02:45:08Z","published":"2024-08-27T16:18:51Z","title":"Unifying Multitrack Music Arrangement via Reconstruction Fine-Tuning and\n  Efficient Tokenization","summary":"  Automatic music arrangement streamlines the creation of musical variants for\ncomposers and arrangers, reducing reliance on extensive music expertise.\nHowever, existing methods suffer from inefficient tokenization,\nunderutilization of pre-trained music language models (LMs), and suboptimal\nfidelity and coherence in generated arrangements. This paper introduces an\nefficient multitrack music tokenizer for unconditional and conditional symbolic\nmusic generation, along with a unified sequence-to-sequence reconstruction\nfine-tuning objective for pre-trained music LMs that balances task-specific\nneeds with coherence constraints. Our approach achieves state-of-the-art\nresults on band arrangement, piano reduction, and drum arrangement, surpassing\ntask-specific models in both objective metrics and perceptual quality.\nAdditionally, we demonstrate that generative pretraining significantly\ncontributes to the performance across these arrangement tasks, especially when\nhandling long segments with complex alignment.\n","authors":["Longshen Ou","Jingwei Zhao","Ziyu Wang","Gus Xia","Ye Wang"],"pdf_url":"https://arxiv.org/pdf/2408.15176v2.pdf","comment":"Submitted to IJCAI 2025"},{"id":"http://arxiv.org/abs/2406.10292v3","updated":"2025-03-06T02:41:55Z","published":"2024-06-13T04:23:35Z","title":"Automatically Labeling Clinical Trial Outcomes: A Large-Scale Benchmark\n  for Drug Development","summary":"  Background The cost of drug discovery and development is substantial, with\nclinical trial outcomes playing a critical role in regulatory approval and\npatient care. However, access to large-scale, high-quality clinical trial\noutcome data remains limited, hindering advancements in predictive modeling and\nevidence-based decision-making.\n  Methods We present the Clinical Trial Outcome (CTO) benchmark, a fully\nreproducible, large-scale repository encompassing approximately 125,000 drug\nand biologics trials. CTO integrates large language model (LLM) interpretations\nof publications, trial phase progression tracking, sentiment analysis from news\nsources, stock price movements of trial sponsors, and additional trial-related\nmetrics. Furthermore, we manually annotated a dataset of clinical trials\nconducted between 2020 and 2024 to enhance the quality and reliability of\noutcome labels.\n  Results The trial outcome labels in the CTO benchmark agree strongly with\nexpert annotations, achieving an F1 score of 94 for Phase 3 trials and 91\nacross all phases. Additionally, benchmarking standard machine learning models\non our manually annotated dataset revealed distribution shifts in recent\ntrials, underscoring the necessity of continuously updated labeling approaches.\n  Conclusions By analyzing CTO's performance on recent clinical trials, we\ndemonstrate the ongoing need for high-quality, up-to-date trial outcome labels.\nWe publicly release the CTO knowledge base and annotated labels at\nhttps://chufangao.github.io/CTOD, with regular updates to support research on\nclinical trial outcomes and inform data-driven improvements in drug\ndevelopment.\n","authors":["Chufan Gao","Jathurshan Pradeepkumar","Trisha Das","Shivashankar Thati","Jimeng Sun"],"pdf_url":"https://arxiv.org/pdf/2406.10292v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.04036v1","updated":"2025-03-06T02:40:51Z","published":"2025-03-06T02:40:51Z","title":"Robust Data Watermarking in Language Models by Injecting Fictitious\n  Knowledge","summary":"  Data watermarking in language models injects traceable signals, such as\nspecific token sequences or stylistic patterns, into copyrighted text, allowing\ncopyright holders to track and verify training data ownership. Previous data\nwatermarking techniques primarily focus on effective memorization after\npretraining, while overlooking challenges that arise in other stages of the LLM\npipeline, such as the risk of watermark filtering during data preprocessing, or\npotential forgetting through post-training, or verification difficulties due to\nAPI-only access. We propose a novel data watermarking approach that injects\ncoherent and plausible yet fictitious knowledge into training data using\ngenerated passages describing a fictitious entity and its associated\nattributes. Our watermarks are designed to be memorized by the LLM through\nseamlessly integrating in its training data, making them harder to detect\nlexically during preprocessing.We demonstrate that our watermarks can be\neffectively memorized by LLMs, and that increasing our watermarks' density,\nlength, and diversity of attributes strengthens their memorization. We further\nshow that our watermarks remain robust throughout LLM development, maintaining\ntheir effectiveness after continual pretraining and supervised finetuning.\nFinally, we show that our data watermarks can be evaluated even under API-only\naccess via question answering.\n","authors":["Xinyue Cui","Johnny Tian-Zheng Wei","Swabha Swayamdipta","Robin Jia"],"pdf_url":"https://arxiv.org/pdf/2503.04036v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.04013v1","updated":"2025-03-06T02:01:59Z","published":"2025-03-06T02:01:59Z","title":"Benchmarking Large Language Models on Multiple Tasks in Bioinformatics\n  NLP with Prompting","summary":"  Large language models (LLMs) have become important tools in solving\nbiological problems, offering improvements in accuracy and adaptability over\nconventional methods. Several benchmarks have been proposed to evaluate the\nperformance of these LLMs. However, current benchmarks can hardly evaluate the\nperformance of these models across diverse tasks effectively. In this paper, we\nintroduce a comprehensive prompting-based benchmarking framework, termed\nBio-benchmark, which includes 30 key bioinformatics tasks covering areas such\nas proteins, RNA, drugs, electronic health records, and traditional Chinese\nmedicine. Using this benchmark, we evaluate six mainstream LLMs, including\nGPT-4o and Llama-3.1-70b, etc., using 0-shot and few-shot Chain-of-Thought\n(CoT) settings without fine-tuning to reveal their intrinsic capabilities. To\nimprove the efficiency of our evaluations, we demonstrate BioFinder, a new tool\nfor extracting answers from LLM responses, which increases extraction accuracy\nby round 30% compared to existing methods. Our benchmark results show the\nbiological tasks suitable for current LLMs and identify specific areas\nrequiring enhancement. Furthermore, we propose targeted prompt engineering\nstrategies for optimizing LLM performance in these contexts. Based on these\nfindings, we provide recommendations for the development of more robust LLMs\ntailored for various biological applications. This work offers a comprehensive\nevaluation framework and robust tools to support the application of LLMs in\nbioinformatics.\n","authors":["Jiyue Jiang","Pengan Chen","Jiuming Wang","Dongchen He","Ziqin Wei","Liang Hong","Licheng Zong","Sheng Wang","Qinze Yu","Zixian Ma","Yanyu Chen","Yimin Fan","Xiangyu Shi","Jiawei Sun","Chuan Wu","Yu Li"],"pdf_url":"https://arxiv.org/pdf/2503.04013v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2502.20490v2","updated":"2025-03-06T00:59:40Z","published":"2025-02-27T19:54:16Z","title":"EgoNormia: Benchmarking Physical Social Norm Understanding","summary":"  Human activity is moderated by norms. However, machines are often trained\nwithout explicit supervision on norm understanding and reasoning, especially\nwhen the norms are grounded in a physical and social context. To improve and\nevaluate the normative reasoning capability of vision-language models (VLMs),\nwe present EgoNormia $\\|\\epsilon\\|$, consisting of 1,853 ego-centric videos of\nhuman interactions, each of which has two related questions evaluating both the\nprediction and justification of normative actions. The normative actions\nencompass seven categories: safety, privacy, proxemics, politeness,\ncooperation, coordination/proactivity, and communication/legibility. To compile\nthis dataset at scale, we propose a novel pipeline leveraging video sampling,\nautomatic answer generation, filtering, and human validation. Our work\ndemonstrates that current state-of-the-art vision-language models lack robust\nnorm understanding, scoring a maximum of 45% on EgoNormia (versus a human bench\nof 92%). Our analysis of performance in each dimension highlights the\nsignificant risks of safety, privacy, and the lack of collaboration and\ncommunication capability when applied to real-world agents. We additionally\nshow that through a retrieval-based generation method, it is possible to use\nEgoNormia to enhance normative reasoning in VLMs.\n","authors":["MohammadHossein Rezaei","Yicheng Fu","Phil Cuvin","Caleb Ziems","Yanzhe Zhang","Hao Zhu","Diyi Yang"],"pdf_url":"https://arxiv.org/pdf/2502.20490v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.02163v2","updated":"2025-03-06T00:58:55Z","published":"2024-10-03T03:06:42Z","title":"Adversarial Decoding: Generating Readable Documents for Adversarial\n  Objectives","summary":"  We design, implement, and evaluate adversarial decoding, a new, generic text\ngeneration technique that produces readable documents for different adversarial\nobjectives. Prior methods either produce easily detectable gibberish, or cannot\nhandle objectives that include embedding similarity. In particular, they only\nwork for direct attacks (such as jailbreaking) and cannot produce adversarial\ntext for realistic indirect injection, e.g., documents that (1) are retrieved\nin RAG systems in response to broad classes of queries, and also (2)\nadversarially influence subsequent generation. We also show that fluency (low\nperplexity) is not sufficient to evade filtering. We measure the effectiveness\nof adversarial decoding for different objectives, including RAG poisoning,\njailbreaking, and evasion of defensive filters, and demonstrate that it\noutperforms existing methods while producing readable adversarial documents.\n","authors":["Collin Zhang","Tingwei Zhang","Vitaly Shmatikov"],"pdf_url":"https://arxiv.org/pdf/2410.02163v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2502.17651v3","updated":"2025-03-06T00:45:00Z","published":"2025-02-24T21:01:39Z","title":"METAL: A Multi-Agent Framework for Chart Generation with Test-Time\n  Scaling","summary":"  Chart generation aims to generate code to produce charts satisfying the\ndesired visual properties, e.g., texts, layout, color, and type. It has great\npotential to empower the automatic professional report generation in financial\nanalysis, research presentation, education, and healthcare. In this work, we\nbuild a vision-language model (VLM) based multi-agent framework for effective\nautomatic chart generation. Generating high-quality charts requires both strong\nvisual design skills and precise coding capabilities that embed the desired\nvisual properties into code. Such a complex multi-modal reasoning process is\ndifficult for direct prompting of VLMs. To resolve these challenges, we propose\nMETAL, a multi-agent framework that decomposes the task of chart generation\ninto the iterative collaboration among specialized agents. METAL achieves 5.2%\nimprovement over the current best result in the chart generation task. The\nMETAL framework exhibits the phenomenon of test-time scaling: its performance\nincreases monotonically as the logarithmic computational budget grows from 512\nto 8192 tokens. In addition, we find that separating different modalities\nduring the critique process of METAL boosts the self-correction capability of\nVLMs in the multimodal context.\n","authors":["Bingxuan Li","Yiwei Wang","Jiuxiang Gu","Kai-Wei Chang","Nanyun Peng"],"pdf_url":"https://arxiv.org/pdf/2502.17651v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2502.16457v2","updated":"2025-03-06T00:40:18Z","published":"2025-02-23T06:16:23Z","title":"Towards Fully-Automated Materials Discovery via Large-Scale Synthesis\n  Dataset and Expert-Level LLM-as-a-Judge","summary":"  Materials synthesis is vital for innovations such as energy storage,\ncatalysis, electronics, and biomedical devices. Yet, the process relies heavily\non empirical, trial-and-error methods guided by expert intuition. Our work aims\nto support the materials science community by providing a practical,\ndata-driven resource. We have curated a comprehensive dataset of 17K\nexpert-verified synthesis recipes from open-access literature, which forms the\nbasis of our newly developed benchmark, AlchemyBench. AlchemyBench offers an\nend-to-end framework that supports research in large language models applied to\nsynthesis prediction. It encompasses key tasks, including raw materials and\nequipment prediction, synthesis procedure generation, and characterization\noutcome forecasting. We propose an LLM-as-a-Judge framework that leverages\nlarge language models for automated evaluation, demonstrating strong\nstatistical agreement with expert assessments. Overall, our contributions offer\na supportive foundation for exploring the capabilities of LLMs in predicting\nand guiding materials synthesis, ultimately paving the way for more efficient\nexperimental design and accelerated innovation in materials science.\n","authors":["Heegyu Kim","Taeyang Jeon","Seungtaek Choi","Ji Hoon Hong","Dong Won Jeon","Sung Beom Cho","Ga-Yeon Baek","Kyung-Won Kwak","Dong-Hee Lee","Sun-Jin Choi","Jisu Bae","Chihoon Lee","Yunseo Kim","Jinsung Park","Hyunsouk Cho"],"pdf_url":"https://arxiv.org/pdf/2502.16457v2.pdf","comment":"under review"},{"id":"http://arxiv.org/abs/2503.03987v1","updated":"2025-03-06T00:19:54Z","published":"2025-03-06T00:19:54Z","title":"RetinalGPT: A Retinal Clinical Preference Conversational Assistant\n  Powered by Large Vision-Language Models","summary":"  Recently, Multimodal Large Language Models (MLLMs) have gained significant\nattention for their remarkable ability to process and analyze non-textual data,\nsuch as images, videos, and audio. Notably, several adaptations of\ngeneral-domain MLLMs to the medical field have been explored, including\nLLaVA-Med. However, these medical adaptations remain insufficiently advanced in\nunderstanding and interpreting retinal images. In contrast, medical experts\nemphasize the importance of quantitative analyses for disease detection and\ninterpretation. This underscores a gap between general-domain and\nmedical-domain MLLMs: while general-domain MLLMs excel in broad applications,\nthey lack the specialized knowledge necessary for precise diagnostic and\ninterpretative tasks in the medical field. To address these challenges, we\nintroduce \\textit{RetinalGPT}, a multimodal conversational assistant for\nclinically preferred quantitative analysis of retinal images. Specifically, we\nachieve this by compiling a large retinal image dataset, developing a novel\ndata pipeline, and employing customized visual instruction tuning to enhance\nboth retinal analysis and enrich medical knowledge. In particular, RetinalGPT\noutperforms MLLM in the generic domain by a large margin in the diagnosis of\nretinal diseases in 8 benchmark retinal datasets. Beyond disease diagnosis,\nRetinalGPT features quantitative analyses and lesion localization, representing\na pioneering step in leveraging LLMs for an interpretable and end-to-end\nclinical research framework. The code is available at\nhttps://github.com/Retinal-Research/RetinalGPT\n","authors":["Wenhui Zhu","Xin Li","Xiwen Chen","Peijie Qiu","Vamsi Krishna Vasa","Xuanzhao Dong","Yanxi Chen","Natasha Lepore","Oana Dumitrascu","Yi Su","Yalin Wang"],"pdf_url":"https://arxiv.org/pdf/2503.03987v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.03983v1","updated":"2025-03-06T00:10:26Z","published":"2025-03-06T00:10:26Z","title":"Audio Flamingo 2: An Audio-Language Model with Long-Audio Understanding\n  and Expert Reasoning Abilities","summary":"  Understanding and reasoning over non-speech sounds and music are crucial for\nboth humans and AI agents to interact effectively with their environments. In\nthis paper, we introduce Audio Flamingo 2 (AF2), an Audio-Language Model (ALM)\nwith advanced audio understanding and reasoning capabilities. AF2 leverages (i)\na custom CLAP model, (ii) synthetic Audio QA data for fine-grained audio\nreasoning, and (iii) a multi-stage curriculum learning strategy. AF2 achieves\nstate-of-the-art performance with only a 3B parameter small language model,\nsurpassing large open-source and proprietary models across over 20 benchmarks.\nNext, for the first time, we extend audio understanding to long audio segments\n(30 secs to 5 mins) and propose LongAudio, a large and novel dataset for\ntraining ALMs on long audio captioning and question-answering tasks.\nFine-tuning AF2 on LongAudio leads to exceptional performance on our proposed\nLongAudioBench, an expert annotated benchmark for evaluating ALMs on long audio\nunderstanding capabilities. We conduct extensive ablation studies to confirm\nthe efficacy of our approach. Project Website:\nhttps://research.nvidia.com/labs/adlr/AF2/.\n","authors":["Sreyan Ghosh","Zhifeng Kong","Sonal Kumar","S Sakshi","Jaehyeon Kim","Wei Ping","Rafael Valle","Dinesh Manocha","Bryan Catanzaro"],"pdf_url":"https://arxiv.org/pdf/2503.03983v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.03979v1","updated":"2025-03-06T00:03:55Z","published":"2025-03-06T00:03:55Z","title":"ReasonGraph: Visualisation of Reasoning Paths","summary":"  Large Language Models (LLMs) reasoning processes are challenging to analyze\ndue to their complexity and the lack of organized visualization tools. We\npresent ReasonGraph, a web-based platform for visualizing and analyzing LLM\nreasoning processes. It supports both sequential and tree-based reasoning\nmethods while integrating with major LLM providers and over fifty\nstate-of-the-art models. ReasonGraph incorporates an intuitive UI with meta\nreasoning method selection, configurable visualization parameters, and a\nmodular framework that facilitates efficient extension. Our evaluation shows\nhigh parsing reliability, efficient processing, and strong usability across\nvarious downstream applications. By providing a unified visualization\nframework, ReasonGraph reduces cognitive load in analyzing complex reasoning\npaths, improves error detection in logical processes, and enables more\neffective development of LLM-based applications. The platform is open-source,\npromoting accessibility and reproducibility in LLM reasoning analysis.\n","authors":["Zongqian Li","Ehsan Shareghi","Nigel Collier"],"pdf_url":"https://arxiv.org/pdf/2503.03979v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.05050v1","updated":"2025-03-06T23:59:50Z","published":"2025-03-06T23:59:50Z","title":"A Unified Framework with Novel Metrics for Evaluating the Effectiveness\n  of XAI Techniques in LLMs","summary":"  The increasing complexity of LLMs presents significant challenges to their\ntransparency and interpretability, necessitating the use of eXplainable AI\n(XAI) techniques to enhance trustworthiness and usability. This study\nintroduces a comprehensive evaluation framework with four novel metrics for\nassessing the effectiveness of five XAI techniques across five LLMs and two\ndownstream tasks. We apply this framework to evaluate several XAI techniques\nLIME, SHAP, Integrated Gradients, Layer-wise Relevance Propagation (LRP), and\nAttention Mechanism Visualization (AMV) using the IMDB Movie Reviews and Tweet\nSentiment Extraction datasets. The evaluation focuses on four key metrics:\nHuman-reasoning Agreement (HA), Robustness, Consistency, and Contrastivity. Our\nresults show that LIME consistently achieves high scores across multiple LLMs\nand evaluation metrics, while AMV demonstrates superior Robustness and\nnear-perfect Consistency. LRP excels in Contrastivity, particularly with more\ncomplex models. Our findings provide valuable insights into the strengths and\nlimitations of different XAI methods, offering guidance for developing and\nselecting appropriate XAI techniques for LLMs.\n","authors":["Melkamu Abay Mersha","Mesay Gemeda Yigezu","Hassan shakil","Ali Al shami","Sanghyun Byun","Jugal Kalita"],"pdf_url":"https://arxiv.org/pdf/2503.05050v1.pdf","comment":"arXiv admin note: substantial text overlap with arXiv:2501.15374"},{"id":"http://arxiv.org/abs/2503.05049v1","updated":"2025-03-06T23:58:01Z","published":"2025-03-06T23:58:01Z","title":"Dynamic-KGQA: A Scalable Framework for Generating Adaptive Question\n  Answering Datasets","summary":"  As question answering (QA) systems advance alongside the rapid evolution of\nfoundation models, the need for robust, adaptable, and large-scale evaluation\nbenchmarks becomes increasingly critical. Traditional QA benchmarks are often\nstatic and publicly available, making them susceptible to data contamination\nand memorization by large language models (LLMs). Consequently, static\nbenchmarks may overestimate model generalization and hinder a reliable\nassessment of real-world performance. In this work, we introduce Dynamic-KGQA,\na scalable framework for generating adaptive QA datasets from knowledge graphs\n(KGs), designed to mitigate memorization risks while maintaining statistical\nconsistency across iterations. Unlike fixed benchmarks, Dynamic-KGQA generates\na new dataset variant on every run while preserving the underlying\ndistribution, enabling fair and reproducible evaluations. Furthermore, our\nframework provides fine-grained control over dataset characteristics,\nsupporting domain-specific and topic-focused QA dataset generation.\nAdditionally, Dynamic-KGQA produces compact, semantically coherent subgraphs\nthat facilitate both training and evaluation of KGQA models, enhancing their\nability to leverage structured knowledge effectively. To align with existing\nevaluation protocols, we also provide static large-scale train/test/validation\nsplits, ensuring comparability with prior methods. By introducing a dynamic,\ncustomizable benchmarking paradigm, Dynamic-KGQA enables a more rigorous and\nadaptable evaluation of QA systems.\n","authors":["Preetam Prabhu Srikar Dammu","Himanshu Naidu","Chirag Shah"],"pdf_url":"https://arxiv.org/pdf/2503.05049v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2406.03068v2","updated":"2025-03-06T23:55:51Z","published":"2024-06-05T08:51:08Z","title":"Distributional Associations vs In-Context Reasoning: A Study of\n  Feed-forward and Attention Layers","summary":"  Large language models have been successful at tasks involving basic forms of\nin-context reasoning, such as generating coherent language, as well as storing\nvast amounts of knowledge. At the core of the Transformer architecture behind\nsuch models are feed-forward and attention layers, which are often associated\nto knowledge and reasoning, respectively. In this paper, we study this\ndistinction empirically and theoretically in a controlled synthetic setting\nwhere certain next-token predictions involve both distributional and in-context\ninformation. We find that feed-forward layers tend to learn simple\ndistributional associations such as bigrams, while attention layers focus on\nin-context reasoning. Our theoretical analysis identifies the noise in the\ngradients as a key factor behind this discrepancy. Finally, we illustrate how\nsimilar disparities emerge in pre-trained models through ablations on the\nPythia model family on simple reasoning tasks.\n","authors":["Lei Chen","Joan Bruna","Alberto Bietti"],"pdf_url":"https://arxiv.org/pdf/2406.03068v2.pdf","comment":"ICLR 2025"},{"id":"http://arxiv.org/abs/2503.05047v1","updated":"2025-03-06T23:49:30Z","published":"2025-03-06T23:49:30Z","title":"Biases in Large Language Model-Elicited Text: A Case Study in Natural\n  Language Inference","summary":"  We test whether NLP datasets created with Large Language Models (LLMs)\ncontain annotation artifacts and social biases like NLP datasets elicited from\ncrowd-source workers. We recreate a portion of the Stanford Natural Language\nInference corpus using GPT-4, Llama-2 70b for Chat, and Mistral 7b Instruct. We\ntrain hypothesis-only classifiers to determine whether LLM-elicited NLI\ndatasets contain annotation artifacts. Next, we use pointwise mutual\ninformation to identify the words in each dataset that are associated with\ngender, race, and age-related terms. On our LLM-generated NLI datasets,\nfine-tuned BERT hypothesis-only classifiers achieve between 86-96% accuracy.\nOur analyses further characterize the annotation artifacts and stereotypical\nbiases in LLM-generated datasets.\n","authors":["Grace Proebsting","Adam Poliak"],"pdf_url":"https://arxiv.org/pdf/2503.05047v1.pdf","comment":"arXiv admin note: substantial text overlap with arXiv:2410.08996"},{"id":"http://arxiv.org/abs/2502.19784v2","updated":"2025-03-06T23:45:51Z","published":"2025-02-27T05:48:51Z","title":"NaijaNLP: A Survey of Nigerian Low-Resource Languages","summary":"  With over 500 languages in Nigeria, three languages -- Hausa, Yor\\`ub\\'a and\nIgbo -- spoken by over 175 million people, account for about 60% of the spoken\nlanguages. However, these languages are categorised as low-resource due to\ninsufficient resources to support tasks in computational linguistics. Several\nresearch efforts and initiatives have been presented, however, a coherent\nunderstanding of the state of Natural Language Processing (NLP) - from\ngrammatical formalisation to linguistic resources that support complex tasks\nsuch as language understanding and generation is lacking. This study presents\nthe first comprehensive review of advancements in low-resource NLP (LR-NLP)\nresearch across the three major Nigerian languages (NaijaNLP). We\nquantitatively assess the available linguistic resources and identify key\nchallenges. Although a growing body of literature addresses various NLP\ndownstream tasks in Hausa, Igbo, and Yor\\`ub\\'a, only about 25.1% of the\nreviewed studies contribute new linguistic resources. This finding highlights a\npersistent reliance on repurposing existing data rather than generating novel,\nhigh-quality resources. Additionally, language-specific challenges, such as the\naccurate representation of diacritics, remain under-explored. To advance\nNaijaNLP and LR-NLP more broadly, we emphasise the need for intensified efforts\nin resource enrichment, comprehensive annotation, and the development of open\ncollaborative initiatives.\n","authors":["Isa Inuwa-Dutse"],"pdf_url":"https://arxiv.org/pdf/2502.19784v2.pdf","comment":"35 pages, 2 figures, 4 tables"},{"id":"http://arxiv.org/abs/2503.05042v1","updated":"2025-03-06T23:37:05Z","published":"2025-03-06T23:37:05Z","title":"Provably Correct Automata Embeddings for Optimal Automata-Conditioned\n  Reinforcement Learning","summary":"  Automata-conditioned reinforcement learning (RL) has given promising results\nfor learning multi-task policies capable of performing temporally extended\nobjectives given at runtime, done by pretraining and freezing automata\nembeddings prior to training the downstream policy. However, no theoretical\nguarantees were given. This work provides a theoretical framework for the\nautomata-conditioned RL problem and shows that it is probably approximately\ncorrect learnable. We then present a technique for learning provably correct\nautomata embeddings, guaranteeing optimal multi-task policy learning. Our\nexperimental evaluation confirms these theoretical results.\n","authors":["Beyazit Yalcinkaya","Niklas Lauffer","Marcell Vazquez-Chanlatte","Sanjit A. Seshia"],"pdf_url":"https://arxiv.org/pdf/2503.05042v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.05037v1","updated":"2025-03-06T23:23:13Z","published":"2025-03-06T23:23:13Z","title":"Collapse of Dense Retrievers: Short, Early, and Literal Biases\n  Outranking Factual Evidence","summary":"  Dense retrieval models are commonly used in Information Retrieval (IR)\napplications, such as Retrieval-Augmented Generation (RAG). Since they often\nserve as the first step in these systems, their robustness is critical to avoid\nfailures. In this work, by repurposing a relation extraction dataset (e.g.\nRe-DocRED), we design controlled experiments to quantify the impact of\nheuristic biases, such as favoring shorter documents, in retrievers like\nDragon+ and Contriever. Our findings reveal significant vulnerabilities:\nretrievers often rely on superficial patterns like over-prioritizing document\nbeginnings, shorter documents, repeated entities, and literal matches.\nAdditionally, they tend to overlook whether the document contains the query's\nanswer, lacking deep semantic understanding. Notably, when multiple biases\ncombine, models exhibit catastrophic performance degradation, selecting the\nanswer-containing document in less than 3% of cases over a biased document\nwithout the answer. Furthermore, we show that these biases have direct\nconsequences for downstream applications like RAG, where retrieval-preferred\ndocuments can mislead LLMs, resulting in a 34% performance drop than not\nproviding any documents at all.\n","authors":["Mohsen Fayyaz","Ali Modarressi","Hinrich Schuetze","Nanyun Peng"],"pdf_url":"https://arxiv.org/pdf/2503.05037v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.05029v1","updated":"2025-03-06T22:55:01Z","published":"2025-03-06T22:55:01Z","title":"Continual Pre-training of MoEs: How robust is your router?","summary":"  Sparsely-activated Mixture of Experts (MoE) transformers are promising\narchitectures for foundation models. Compared to dense transformers that\nrequire the same amount of floating point operations (FLOPs) per forward pass,\nMoEs benefit from improved sample efficiency at training time and achieve much\nstronger performance. Many closed-source and open-source frontier language\nmodels have thus adopted an MoE architecture. Naturally, practitioners will\nwant to extend the capabilities of these models with large amounts of newly\ncollected data without completely re-training them. Prior work has shown that a\nsimple combination of replay and learning rate re-warming and re-decaying can\nenable the continual pre-training (CPT) of dense decoder-only transformers with\nminimal performance degradation compared to full re-training. In the case of\ndecoder-only MoE transformers, however, it is unclear how the routing algorithm\nwill impact continual pre-training performance: 1) do the MoE transformer's\nrouters exacerbate forgetting relative to a dense model?; 2) do the routers\nmaintain a balanced load on previous distributions after CPT?; 3) are the same\nstrategies applied to dense models sufficient to continually pre-train MoE\nLLMs? In what follows, we conduct a large-scale (>2B parameter switch and\nDeepSeek MoE LLMs trained for 600B tokens) empirical study across four MoE\ntransformers to answer these questions. Our results establish a surprising\nrobustness to distribution shifts for both Sinkhorn-Balanced and\nZ-and-Aux-loss-balanced routing algorithms, even in MoEs continually\npre-trained without replay. Moreover, we show that MoE LLMs maintain their\nsample efficiency (relative to a FLOP-matched dense model) during CPT and that\nthey can match the performance of a fully re-trained MoE at a fraction of the\ncost.\n","authors":["Benjamin Thrien","Charles-tienne Joseph","Zain Sarwar","Ashwinee Panda","Anirban Das","Shi-Xiong Zhang","Stephen Rawls","Sambit Sahu","Eugene Belilovsky","Irina Rish"],"pdf_url":"https://arxiv.org/pdf/2503.05029v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.05021v1","updated":"2025-03-06T22:47:45Z","published":"2025-03-06T22:47:45Z","title":"Safety is Not Only About Refusal: Reasoning-Enhanced Fine-tuning for\n  Interpretable LLM Safety","summary":"  Large Language Models (LLMs) are vulnerable to jailbreak attacks that exploit\nweaknesses in traditional safety alignment, which often relies on rigid refusal\nheuristics or representation engineering to block harmful outputs. While they\nare effective for direct adversarial attacks, they fall short of broader safety\nchallenges requiring nuanced, context-aware decision-making. To address this,\nwe propose Reasoning-enhanced Finetuning for interpretable LLM Safety\n(Rational), a novel framework that trains models to engage in explicit safe\nreasoning before response. Fine-tuned models leverage the extensive pretraining\nknowledge in self-generated reasoning to bootstrap their own safety through\nstructured reasoning, internalizing context-sensitive decision-making. Our\nfindings suggest that safety extends beyond refusal, requiring context\nawareness for more robust, interpretable, and adaptive responses. Reasoning is\nnot only a core capability of LLMs but also a fundamental mechanism for LLM\nsafety. Rational employs reasoning-enhanced fine-tuning, allowing it to reject\nharmful prompts while providing meaningful and context-aware responses in\ncomplex scenarios.\n","authors":["Yuyou Zhang","Miao Li","William Han","Yihang Yao","Zhepeng Cen","Ding Zhao"],"pdf_url":"https://arxiv.org/pdf/2503.05021v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.05010v1","updated":"2025-03-06T22:23:07Z","published":"2025-03-06T22:23:07Z","title":"Leveraging Domain Knowledge at Inference Time for LLM Translation:\n  Retrieval versus Generation","summary":"  While large language models (LLMs) have been increasingly adopted for machine\ntranslation (MT), their performance for specialist domains such as medicine and\nlaw remains an open challenge. Prior work has shown that LLMs can be\ndomain-adapted at test-time by retrieving targeted few-shot demonstrations or\nterminologies for inclusion in the prompt. Meanwhile, for general-purpose LLM\nMT, recent studies have found some success in generating similarly useful\ndomain knowledge from an LLM itself, prior to translation. Our work studies\ndomain-adapted MT with LLMs through a careful prompting setup, finding that\ndemonstrations consistently outperform terminology, and retrieval consistently\noutperforms generation. We find that generating demonstrations with weaker\nmodels can close the gap with larger model's zero-shot performance. Given the\neffectiveness of demonstrations, we perform detailed analyses to understand\ntheir value. We find that domain-specificity is particularly important, and\nthat the popular multi-domain benchmark is testing adaptation to a particular\nwriting style more so than to a specific domain.\n","authors":["Bryan Li","Jiaming Luo","Eleftheria Briakou","Colin Cherry"],"pdf_url":"https://arxiv.org/pdf/2503.05010v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.01829v2","updated":"2025-03-06T22:13:20Z","published":"2025-03-03T18:53:21Z","title":"Persuade Me if You Can: A Framework for Evaluating Persuasion\n  Effectiveness and Susceptibility Among Large Language Models","summary":"  Large Language Models (LLMs) demonstrate persuasive capabilities that rival\nhuman-level persuasion. While these capabilities can be used for social good,\nthey also present risks of potential misuse. Moreover, LLMs' susceptibility to\npersuasion raises concerns about alignment with ethical principles. To study\nthese dynamics, we introduce Persuade Me If You Can (PMIYC), an automated\nframework for evaluating persuasion through multi-agent interactions. Here,\nPersuader agents engage in multi-turn conversations with the Persuadee agents,\nallowing us to measure LLMs' persuasive effectiveness and their susceptibility\nto persuasion. We conduct comprehensive evaluations across diverse LLMs,\nensuring each model is assessed against others in both subjective and\nmisinformation contexts. We validate the efficacy of our framework through\nhuman evaluations and show alignment with prior work. PMIYC offers a scalable\nalternative to human annotation for studying persuasion in LLMs. Through PMIYC,\nwe find that Llama-3.3-70B and GPT-4o exhibit similar persuasive effectiveness,\noutperforming Claude 3 Haiku by 30%. However, GPT-4o demonstrates over 50%\ngreater resistance to persuasion for misinformation compared to Llama-3.3-70B.\nThese findings provide empirical insights into the persuasive dynamics of LLMs\nand contribute to the development of safer AI systems.\n","authors":["Nimet Beyza Bozdag","Shuhaib Mehri","Gokhan Tur","Dilek Hakkani-Tr"],"pdf_url":"https://arxiv.org/pdf/2503.01829v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.05005v1","updated":"2025-03-06T22:09:55Z","published":"2025-03-06T22:09:55Z","title":"Balcony: A Lightweight Approach to Dynamic Inference of Generative\n  Language Models","summary":"  Deploying large language models (LLMs) in real-world applications is often\nhindered by strict computational and latency constraints. While dynamic\ninference offers the flexibility to adjust model behavior based on varying\nresource budgets, existing methods are frequently limited by hardware\ninefficiencies or performance degradation. In this paper, we introduce Balcony,\na simple yet highly effective framework for depth-based dynamic inference. By\nfreezing the pretrained LLM and inserting additional transformer layers at\nselected exit points, Balcony maintains the full model's performance while\nenabling real-time adaptation to different computational budgets. These\nadditional layers are trained using a straightforward self-distillation loss,\naligning the sub-model outputs with those of the full model. This approach\nrequires significantly fewer training tokens and tunable parameters,\ndrastically reducing computational costs compared to prior methods. When\napplied to the LLaMA3-8B model, using only 0.2% of the original pretraining\ndata, Balcony achieves minimal performance degradation while enabling\nsignificant speedups. Remarkably, we show that Balcony outperforms\nstate-of-the-art methods such as Flextron and Layerskip as well as other\nleading compression techniques on multiple models and at various scales, across\na variety of benchmarks.\n","authors":["Benyamin Jamialahmadi","Parsa Kavehzadeh","Mehdi Rezagholizadeh","Parsa Farinneya","Hossein Rajabzadeh","Aref Jafari","Boxing Chen","Marzieh Tahaei"],"pdf_url":"https://arxiv.org/pdf/2503.05005v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.04996v1","updated":"2025-03-06T21:53:49Z","published":"2025-03-06T21:53:49Z","title":"HieroLM: Egyptian Hieroglyph Recovery with Next Word Prediction Language\n  Model","summary":"  Egyptian hieroglyphs are found on numerous ancient Egyptian artifacts, but it\nis common that they are blurry or even missing due to erosion. Existing efforts\nto restore blurry hieroglyphs adopt computer vision techniques such as CNNs and\nmodel hieroglyph recovery as an image classification task, which suffers from\ntwo major limitations: (i) They cannot handle severely damaged or completely\nmissing hieroglyphs. (ii) They make predictions based on a single hieroglyph\nwithout considering contextual and grammatical information. This paper proposes\na novel approach to model hieroglyph recovery as a next word prediction task\nand use language models to address it. We compare the performance of different\nSOTA language models and choose LSTM as the architecture of our HieroLM due to\nthe strong local affinity of semantics in Egyptian hieroglyph texts.\nExperiments show that HieroLM achieves over 44% accuracy and maintains notable\nperformance on multi-shot predictions and scarce data, which makes it a\npragmatic tool to assist scholars in inferring missing hieroglyphs. It can also\ncomplement CV-based models to significantly reduce perplexity in recognizing\nblurry hieroglyphs. Our code is available at\nhttps://github.com/Rick-Cai/HieroLM/.\n","authors":["Xuheng Cai","Erica Zhang"],"pdf_url":"https://arxiv.org/pdf/2503.04996v1.pdf","comment":"Accepted at LaTeCH-CLfL 2025 @ NAACL 2025"},{"id":"http://arxiv.org/abs/2410.20513v5","updated":"2025-03-06T21:52:23Z","published":"2024-10-27T16:52:21Z","title":"Self-correction is Not An Innate Capability in Large Language Models: A\n  Case Study of Moral Self-correction","summary":"  Though there has been intensive attention to the self-correction capability\nof Large Language Models (LLMs), conclusions regarding its effectiveness remain\nvaried. In this paper, we investigate a fundamental question: is moral\nself-correction an innate capability in LLMs? To explore this, we conduct (1) a\nmechanistic analysis of how key components of self-correction, such as\nChain-of-Thought (CoT) reasoning and external feedback, interact to enable\nmoral self-correction; and (2) a behavioral analysis of LLMs' ability to\ndistinguish between desired and undesired outputs, introducing a\nself-distinguish framework. Our mechanistic analysis reveals that LLMs struggle\nto effectively leverage helpful feedback, and conflicts can arise between\nfeedback and CoT reasoning. These limitations suggest that LLMs fail to\nidentify useful contextual information, instead prioritizing their own internal\nknowledge. Additionally, our behavioral analysis indicates that LLMs struggle\nto differentiate among their own outputs. Based on these empirical findings\nacross two analytical dimensions, mechanism and behavior, we argue that moral\nself-correction is not an innate capability of LLMs.\n","authors":["Guangliang Liu","Zimo Qi","Xitong Zhang","Lu Cheng","Kristen Marie Johnson"],"pdf_url":"https://arxiv.org/pdf/2410.20513v5.pdf","comment":null},{"id":"http://arxiv.org/abs/2502.19320v2","updated":"2025-03-06T21:49:11Z","published":"2025-02-26T17:13:19Z","title":"Shh, don't say that! Domain Certification in LLMs","summary":"  Large language models (LLMs) are often deployed to perform constrained tasks,\nwith narrow domains. For example, customer support bots can be built on top of\nLLMs, relying on their broad language understanding and capabilities to enhance\nperformance. However, these LLMs are adversarially susceptible, potentially\ngenerating outputs outside the intended domain. To formalize, assess, and\nmitigate this risk, we introduce domain certification; a guarantee that\naccurately characterizes the out-of-domain behavior of language models. We then\npropose a simple yet effective approach, which we call VALID that provides\nadversarial bounds as a certificate. Finally, we evaluate our method across a\ndiverse set of datasets, demonstrating that it yields meaningful certificates,\nwhich bound the probability of out-of-domain samples tightly with minimum\npenalty to refusal behavior.\n","authors":["Cornelius Emde","Alasdair Paren","Preetham Arvind","Maxime Kayser","Tom Rainforth","Thomas Lukasiewicz","Bernard Ghanem","Philip H. S. Torr","Adel Bibi"],"pdf_url":"https://arxiv.org/pdf/2502.19320v2.pdf","comment":"10 pages, includes appendix Published in International Conference on\n  Learning Representations (ICLR) 2025"},{"id":"http://arxiv.org/abs/2503.04992v1","updated":"2025-03-06T21:42:35Z","published":"2025-03-06T21:42:35Z","title":"Wanda++: Pruning Large Language Models via Regional Gradients","summary":"  Large Language Models (LLMs) pruning seeks to remove unimportant weights for\ninference speedup with minimal performance impact. However, existing methods\noften suffer from performance loss without full-model sparsity-aware\nfine-tuning. This paper presents Wanda++, a novel pruning framework that\noutperforms the state-of-the-art methods by utilizing decoder-block-level\n\\textbf{regional} gradients. Specifically, Wanda++ improves the pruning score\nwith regional gradients for the first time and proposes an efficient regional\noptimization method to minimize pruning-induced output discrepancies between\nthe dense and sparse decoder output. Notably, Wanda++ improves perplexity by up\nto 32\\% over Wanda in the language modeling task and generalizes effectively to\ndownstream tasks. Further experiments indicate our proposed method is\northogonal to sparsity-aware fine-tuning, where Wanda++ can be combined with\nLoRA fine-tuning to achieve a similar perplexity improvement as the Wanda\nmethod. The proposed method is lightweight, pruning a 7B LLaMA model in under\n10 minutes on a single NVIDIA H100 GPU.\n","authors":["Yifan Yang","Kai Zhen","Bhavana Ganesh","Aram Galstyan","Goeric Huybrechts","Markus Mller","Jonas M. Kbler","Rupak Vignesh Swaminathan","Athanasios Mouchtaris","Sravan Babu Bodapati","Nathan Susanj","Zheng Zhang","Jack FitzGerald","Abhishek Kumar"],"pdf_url":"https://arxiv.org/pdf/2503.04992v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.04990v1","updated":"2025-03-06T21:39:42Z","published":"2025-03-06T21:39:42Z","title":"DP-GTR: Differentially Private Prompt Protection via Group Text\n  Rewriting","summary":"  Prompt privacy is crucial, especially when using online large language models\n(LLMs), due to the sensitive information often contained within prompts. While\nLLMs can enhance prompt privacy through text rewriting, existing methods\nprimarily focus on document-level rewriting, neglecting the rich,\nmulti-granular representations of text. This limitation restricts LLM\nutilization to specific tasks, overlooking their generalization and in-context\nlearning capabilities, thus hindering practical application. To address this\ngap, we introduce DP-GTR, a novel three-stage framework that leverages local\ndifferential privacy (DP) and the composition theorem via group text rewriting.\nDP-GTR is the first framework to integrate both document-level and word-level\ninformation while exploiting in-context learning to simultaneously improve\nprivacy and utility, effectively bridging local and global DP mechanisms at the\nindividual data point level. Experiments on CommonSense QA and DocVQA\ndemonstrate that DP-GTR outperforms existing approaches, achieving a superior\nprivacy-utility trade-off. Furthermore, our framework is compatible with\nexisting rewriting techniques, serving as a plug-in to enhance privacy\nprotection. Our code is publicly available at\nhttps://github.com/FatShion-FTD/DP-GTR for reproducibility.\n","authors":["Mingchen Li","Heng Fan","Song Fu","Junhua Ding","Yunhe Feng"],"pdf_url":"https://arxiv.org/pdf/2503.04990v1.pdf","comment":"8 pages, 3 figures, 1 table"},{"id":"http://arxiv.org/abs/2503.04989v1","updated":"2025-03-06T21:35:24Z","published":"2025-03-06T21:35:24Z","title":"Application of integrated gradients explainability to sociopsychological\n  semantic markers","summary":"  Classification of textual data in terms of sentiment, or more nuanced\nsociopsychological markers (e.g., agency), is now a popular approach commonly\napplied at the sentence level. In this paper, we exploit the integrated\ngradient (IG) method to capture the classification output at the word level,\nrevealing which words actually contribute to the classification process. This\napproach improves explainability and provides in-depth insights into the text.\nWe focus on sociopsychological markers beyond sentiment and investigate how to\neffectively train IG in agency, one of the very few markers for which a\nverified deep learning classifier, BERTAgent, is currently available.\nPerformance and system parameters are carefully tested, alternatives to the IG\napproach are evaluated, and the usefulness of the result is verified in a\nrelevant application scenario. The method is also applied in a scenario where\nonly a small labeled dataset is available, with the aim of exploiting IG to\nidentify the salient words that contribute to building the different classes\nthat relate to relevant sociopsychological markers. To achieve this, an\nuncommon training procedure that encourages overfitting is employed to enhance\nthe distinctiveness of each class. The results are analyzed through the lens of\nsocial psychology, offering valuable insights.\n","authors":["Ali Aghababaei","Jan Nikadon","Magdalena Formanowicz","Maria Laura Bettinsoli","Carmen Cervone","Caterina Suitner","Tomaso Erseghe"],"pdf_url":"https://arxiv.org/pdf/2503.04989v1.pdf","comment":"Submitted to IEEE Trans. on Affective Computing"},{"id":"http://arxiv.org/abs/2503.04982v1","updated":"2025-03-06T21:21:18Z","published":"2025-03-06T21:21:18Z","title":"LVLM-Compress-Bench: Benchmarking the Broader Impact of Large\n  Vision-Language Model Compression","summary":"  Despite recent efforts in understanding the compression impact on large\nlanguage models (LLMs) in terms of their downstream task performance and\ntrustworthiness on relatively simpler uni-modal benchmarks (for example,\nquestion answering, common sense reasoning), their detailed study on\nmulti-modal Large Vision-Language Models (LVLMs) is yet to be unveiled. Towards\nmitigating this gap, we present LVLM-Compress-Bench, a framework to first\nthoroughly study the broad impact of compression on the generative performance\nof LVLMs with multi-modal input driven tasks. In specific, we consider two\nmajor classes of compression for autoregressive models, namely KV cache and\nweight compression, for the dynamically growing intermediate cache and static\nweights, respectively.\n  We use four LVLM variants of the popular LLaVA framework to present our\nanalysis via integrating various state-of-the-art KV and weight compression\nmethods including uniform, outlier-reduced, and group quantization for the KV\ncache and weights. With this framework we demonstrate on ten different\nmulti-modal datasets with different capabilities including recognition,\nknowledge, language generation, spatial awareness, visual reasoning,\nhallucination and visual illusion identification, toxicity, stereotypes and\nbias. In specific, our framework demonstrates the compression impact on both\ngeneral and ethically critical metrics leveraging a combination of real world\nand synthetic datasets to encompass diverse societal intersectional attributes.\nExtensive experimental evaluations yield diverse and intriguing observations on\nthe behavior of LVLMs at different quantization budget of KV and weights, in\nboth maintaining and losing performance as compared to the baseline model with\nFP16 data format.\n  Code will be open-sourced at\nhttps://github.com/opengear-project/LVLM-compress-bench.\n","authors":["Souvik Kundu","Anahita Bhiwandiwalla","Sungduk Yu","Phillip Howard","Tiep Le","Sharath Nittur Sridhar","David Cobbley","Hao Kang","Vasudev Lal"],"pdf_url":"https://arxiv.org/pdf/2503.04982v1.pdf","comment":"This work has been accepted to NAACL 2025"},{"id":"http://arxiv.org/abs/2503.04973v1","updated":"2025-03-06T21:07:41Z","published":"2025-03-06T21:07:41Z","title":"Beyond RAG: Task-Aware KV Cache Compression for Comprehensive Knowledge\n  Reasoning","summary":"  Incorporating external knowledge in large language models (LLMs) enhances\ntheir utility across diverse applications, but existing methods have\ntrade-offs. Retrieval-Augmented Generation (RAG) fetches evidence via\nsimilarity search, but key information may fall outside top ranked results.\nLong-context models can process multiple documents but are computationally\nexpensive and limited by context window size. Inspired by students condensing\nstudy material for open-book exams, we propose task-aware key-value (KV) cache\ncompression, which compresses external knowledge in a zero- or few-shot setup.\nThis enables LLMs to reason efficiently over a compacted representation of all\nrelevant information. Experiments show our approach outperforms both RAG and\ntask-agnostic compression methods. On LongBench v2, it improves accuracy by up\nto 7 absolute points over RAG with a 30x compression rate, while reducing\ninference latency from 0.43s to 0.16s. A synthetic dataset highlights that RAG\nperforms well when sparse evidence suffices, whereas task-aware compression is\nsuperior for broad knowledge tasks.\n","authors":["Giulio Corallo","Orion Weller","Fabio Petroni","Paolo Papotti"],"pdf_url":"https://arxiv.org/pdf/2503.04973v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.04972v1","updated":"2025-03-06T21:06:35Z","published":"2025-03-06T21:06:35Z","title":"Evaluating Answer Reranking Strategies in Time-sensitive Question\n  Answering","summary":"  Despite advancements in state-of-the-art models and information retrieval\ntechniques, current systems still struggle to handle temporal information and\nto correctly answer detailed questions about past events. In this paper, we\ninvestigate the impact of temporal characteristics of answers in Question\nAnswering (QA) by exploring several simple answer selection techniques. Our\nfindings emphasize the role of temporal features in selecting the most relevant\nanswers from diachronic document collections and highlight differences between\nexplicit and implicit temporal questions.\n","authors":["Mehmet Kardan","Bhawna Piryani","Adam Jatowt"],"pdf_url":"https://arxiv.org/pdf/2503.04972v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.14473v4","updated":"2025-03-06T20:49:51Z","published":"2024-11-18T21:28:00Z","title":"Large Language Model for Qualitative Research -- A Systematic Mapping\n  Study","summary":"  The exponential growth of text-based data in domains such as healthcare,\neducation, and social sciences has outpaced the capacity of traditional\nqualitative analysis methods, which are time-intensive and prone to\nsubjectivity. Large Language Models (LLMs), powered by advanced generative AI,\nhave emerged as transformative tools capable of automating and enhancing\nqualitative analysis. This study systematically maps the literature on the use\nof LLMs for qualitative research, exploring their application contexts,\nconfigurations, methodologies, and evaluation metrics. Findings reveal that\nLLMs are utilized across diverse fields, demonstrating the potential to\nautomate processes traditionally requiring extensive human input. However,\nchallenges such as reliance on prompt engineering, occasional inaccuracies, and\ncontextual limitations remain significant barriers. This research highlights\nopportunities for integrating LLMs with human expertise, improving model\nrobustness, and refining evaluation methodologies. By synthesizing trends and\nidentifying research gaps, this study aims to guide future innovations in the\napplication of LLMs for qualitative analysis.\n","authors":["Cau Ferreira Barros","Bruna Borges Azevedo","Valdemar Vicente Graciano Neto","Mohamad Kassab","Marcos Kalinowski","Hugo Alexandre D. do Nascimento","Michelle C. G. S. P. Bandeira"],"pdf_url":"https://arxiv.org/pdf/2411.14473v4.pdf","comment":"8 pages, includes 1 figures and 3 tables. Submitted and Accepted to\n  the WSESE 2025 ICSE Workshop"},{"id":"http://arxiv.org/abs/2503.04959v1","updated":"2025-03-06T20:46:43Z","published":"2025-03-06T20:46:43Z","title":"DB-Explore: Automated Database Exploration and Instruction Synthesis for\n  Text-to-SQL","summary":"  Recent text-to-SQL systems powered by large language models (LLMs) have\ndemonstrated remarkable performance in translating natural language queries\ninto SQL. However, these systems often struggle with complex database\nstructures and domain-specific queries, as they primarily focus on enhancing\nlogical reasoning and SQL syntax while overlooking the critical need for\ncomprehensive database understanding. To address this limitation, we propose\nDB-Explore, a novel framework that systematically aligns LLMs with database\nknowledge through automated exploration and instruction synthesis. DB-Explore\nconstructs database graphs to capture complex relational schemas, leverages\nGPT-4 to systematically mine structural patterns and semantic knowledge, and\nsynthesizes instructions to distill this knowledge for efficient fine-tuning of\nLLMs. Our framework enables comprehensive database understanding through\ndiverse sampling strategies and automated instruction generation, bridging the\ngap between database structures and language models. Experiments conducted on\nthe SPIDER and BIRD benchmarks validate the effectiveness of DB-Explore,\nachieving an execution accuracy of 52.1% on BIRD and 84.0% on SPIDER. Notably,\nour open-source implementation, based on the Qwen2.5-coder-7B model,\noutperforms multiple GPT-4-driven text-to-SQL systems in comparative\nevaluations, and achieves near state-of-the-art performance with minimal\ncomputational cost.\n","authors":["Haoyuan Ma","Yongliang Shen","Hengwei Liu","Wenqi Zhang","Haolei Xu","Qiuying Peng","Jun Wang","Weiming Lu"],"pdf_url":"https://arxiv.org/pdf/2503.04959v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.04957v1","updated":"2025-03-06T20:43:14Z","published":"2025-03-06T20:43:14Z","title":"SafeArena: Evaluating the Safety of Autonomous Web Agents","summary":"  LLM-based agents are becoming increasingly proficient at solving web-based\ntasks. With this capability comes a greater risk of misuse for malicious\npurposes, such as posting misinformation in an online forum or selling illicit\nsubstances on a website. To evaluate these risks, we propose SafeArena, the\nfirst benchmark to focus on the deliberate misuse of web agents. SafeArena\ncomprises 250 safe and 250 harmful tasks across four websites. We classify the\nharmful tasks into five harm categories -- misinformation, illegal activity,\nharassment, cybercrime, and social bias, designed to assess realistic misuses\nof web agents. We evaluate leading LLM-based web agents, including GPT-4o,\nClaude-3.5 Sonnet, Qwen-2-VL 72B, and Llama-3.2 90B, on our benchmark. To\nsystematically assess their susceptibility to harmful tasks, we introduce the\nAgent Risk Assessment framework that categorizes agent behavior across four\nrisk levels. We find agents are surprisingly compliant with malicious requests,\nwith GPT-4o and Qwen-2 completing 34.7% and 27.3% of harmful requests,\nrespectively. Our findings highlight the urgent need for safety alignment\nprocedures for web agents. Our benchmark is available here:\nhttps://safearena.github.io\n","authors":["Ada Defne Tur","Nicholas Meade","Xing Han L","Alejandra Zambrano","Arkil Patel","Esin Durmus","Spandana Gella","Karolina Staczak","Siva Reddy"],"pdf_url":"https://arxiv.org/pdf/2503.04957v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.04945v1","updated":"2025-03-06T20:19:38Z","published":"2025-03-06T20:19:38Z","title":"Collaborative Evaluation of Deepfake Text with Deliberation-Enhancing\n  Dialogue Systems","summary":"  The proliferation of generative models has presented significant challenges\nin distinguishing authentic human-authored content from deepfake content.\nCollaborative human efforts, augmented by AI tools, present a promising\nsolution. In this study, we explore the potential of DeepFakeDeLiBot, a\ndeliberation-enhancing chatbot, to support groups in detecting deepfake text.\nOur findings reveal that group-based problem-solving significantly improves the\naccuracy of identifying machine-generated paragraphs compared to individual\nefforts. While engagement with DeepFakeDeLiBot does not yield substantial\nperformance gains overall, it enhances group dynamics by fostering greater\nparticipant engagement, consensus building, and the frequency and diversity of\nreasoning-based utterances. Additionally, participants with higher perceived\neffectiveness of group collaboration exhibited performance benefits from\nDeepFakeDeLiBot. These findings underscore the potential of deliberative\nchatbots in fostering interactive and productive group dynamics while ensuring\naccuracy in collaborative deepfake text detection. \\textit{Dataset and source\ncode used in this study will be made publicly available upon acceptance of the\nmanuscript.\n","authors":["Jooyoung Lee","Xiaochen Zhu","Georgi Karadzhov","Tom Stafford","Andreas Vlachos","Dongwon Lee"],"pdf_url":"https://arxiv.org/pdf/2503.04945v1.pdf","comment":"15"},{"id":"http://arxiv.org/abs/2503.04940v1","updated":"2025-03-06T20:15:51Z","published":"2025-03-06T20:15:51Z","title":"VQEL: Enabling Self-Developed Symbolic Language in Agents through Vector\n  Quantization in Emergent Language Games","summary":"  In the field of emergent language, efforts have traditionally focused on\ndeveloping communication protocols through interactions between agents in\nreferential games. However, the aspect of internal language learning, where\nlanguage serves not only as a communicative tool with others but also as a\nmeans for individual thinking, self-reflection, and problem-solving remains\nunderexplored. Developing a language through self-play, without another agent's\ninvolvement, poses a unique challenge. It requires an agent to craft symbolic\nrepresentations and train them using direct gradient methods. The challenge\nhere is that if an agent attempts to learn symbolic representations through\nself-play using conventional modeling and techniques such as REINFORCE, the\nsolution will offer no advantage over previous multi-agent approaches. We\nintroduce VQEL, a novel method that incorporates Vector Quantization into the\nagents' architecture, enabling them to autonomously invent and develop discrete\nsymbolic representations in a self-play referential game. Following the\nself-play phase, agents can enhance their language through reinforcement\nlearning and interactions with other agents in the mutual-play phase. Our\nexperiments across various datasets demonstrate that VQEL not only outperforms\nthe traditional REINFORCE method but also benefits from improved control and\nreduced susceptibility to collapse, thanks to the incorporation of vector\nquantization.\n","authors":["Mohammad Mahdi Samiei Paqaleh","Mahdieh Soleymani Baghshah"],"pdf_url":"https://arxiv.org/pdf/2503.04940v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.04930v1","updated":"2025-03-06T20:02:19Z","published":"2025-03-06T20:02:19Z","title":"HILGEN: Hierarchically-Informed Data Generation for Biomedical NER Using\n  Knowledgebases and Large Language Models","summary":"  We present HILGEN, a Hierarchically-Informed Data Generation approach that\ncombines domain knowledge from the Unified Medical Language System (UMLS) with\nsynthetic data generated by large language models (LLMs), specifically GPT-3.5.\nOur approach leverages UMLS's hierarchical structure to expand training data\nwith related concepts, while incorporating contextual information from LLMs\nthrough targeted prompts aimed at automatically generating synthetic examples\nfor sparsely occurring named entities. The performance of the HILGEN approach\nwas evaluated across four biomedical NER datasets (MIMIC III, BC5CDR,\nNCBI-Disease, and Med-Mentions) using BERT-Large and DANN (Data Augmentation\nwith Nearest Neighbor Classifier) models, applying various data generation\nstrategies, including UMLS, GPT-3.5, and their best ensemble. For the\nBERT-Large model, incorporating UMLS led to an average F1 score improvement of\n40.36%, while using GPT-3.5 resulted in a comparable average increase of\n40.52%. The Best-Ensemble approach using BERT-Large achieved the highest\nimprovement, with an average increase of 42.29%. DANN model's F1 score improved\nby 22.74% on average using the UMLS-only approach. The GPT-3.5-based method\nresulted in a 21.53% increase, and the Best-Ensemble DANN model showed a more\nnotable improvement, with an average increase of 25.03%. Our proposed HILGEN\napproach improves NER performance in few-shot settings without requiring\nadditional manually annotated data. Our experiments demonstrate that an\neffective strategy for optimizing biomedical NER is to combine biomedical\nknowledge curated in the past, such as the UMLS, and generative LLMs to create\nsynthetic training instances. Our future research will focus on exploring\nadditional innovative synthetic data generation strategies for further\nimproving NER performance.\n","authors":["Yao Ge","Yuting Guo","Sudeshna Das","Swati Rajwal","Selen Bozkurt","Abeed Sarker"],"pdf_url":"https://arxiv.org/pdf/2503.04930v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.04910v1","updated":"2025-03-06T19:10:57Z","published":"2025-03-06T19:10:57Z","title":"Maximizing Signal in Human-Model Preference Alignment","summary":"  The emergence of powerful LLMs has led to a paradigm shift in Natural\nLanguage Understanding and Natural Language Generation. The properties that\nmake LLMs so valuable for these tasks -- creativity, ability to produce fluent\nspeech, and ability to quickly and effectively abstract information from large\ncorpora -- also present new challenges to evaluating their outputs. The rush to\nmarket has led teams to fall back on quick, cost-effective automatic\nevaluations which offer value, but do not obviate the need for human judgments\nin model training and evaluation. This paper argues that in cases in which end\nusers need to agree with the decisions made by ML models -- e.g. in toxicity\ndetection or extraction of main points for summarization -- models should be\ntrained and evaluated on data that represent the preferences of those users. We\nsupport this argument by explicating the role of human feedback in labeling and\njudgment tasks for model training and evaluation. First, we propose methods for\ndisentangling noise from signal in labeling tasks. Then we show that noise in\nlabeling disagreement can be minimized by adhering to proven methodological\nbest practices, while signal can be maximized to play an integral role in model\ntraining and evaluation tasks. Finally, we illustrate best practices by\nproviding a case study in which two guardrails classifiers are evaluated using\nhuman judgments to align final model behavior to user preferences. We aim for\nthis paper to provide researchers and professionals with guidelines to\nintegrating human judgments into their ML and generative AI evaluation toolkit,\nparticularly when working toward achieving accurate and unbiased features that\nalign with users' needs and expectations.\n","authors":["Kelsey Kraus","Margaret Kroll"],"pdf_url":"https://arxiv.org/pdf/2503.04910v1.pdf","comment":"Presented at AAAI 2025, special track on AI Alignment"}],"Computer Vision and Pattern Recognition":[{"id":"http://arxiv.org/abs/2412.17741v5","updated":"2025-03-06T04:11:30Z","published":"2024-12-23T17:44:05Z","title":"Reasoning to Attend: Try to Understand How <SEG> Token Works","summary":"  Current Large Multimodal Models (LMMs) empowered visual grounding typically\nrely on $\\texttt{<SEG>}$ tokens as a text prompt to jointly optimize the\nvision-language model (e.g., LLaVA) and the downstream task-specific model\n(e.g., SAM). However, we observe that little research has looked into how it\nworks.In this work, we first visualize the similarity maps, which are obtained\nby computing the semantic similarity between the $\\texttt{<SEG>}$ token and the\nimage token embeddings derived from the last hidden layer in both the LLaVA\nencoder and SAM decoder. Intriguingly, we have found that a striking\nconsistency holds in terms of activation responses in the similarity map, which\nreveals that what the $\\texttt{<SEG>}$ token contributes to is semantic\nsimilarity within image-text pairs. Specifically, the $\\texttt{<SEG>}$ token, a\nplaceholder expanded in text vocabulary, extensively queries among individual\ntokenized image patches to match the semantics of an object from text to the\npaired image, while the Large Language Models (LLMs) are being fine-tuned. Upon\nthe above findings, we present READ, which facilitates LMMs' resilient\n$\\textbf{REA}$soning capability of where to atten$\\textbf{D}$ under the\nguidance of highly activated points borrowed from similarity maps. Remarkably,\nREAD features an intuitive design, Similarity as Points module (SasP), which\ncan be seamlessly applied to $\\texttt{<SEG>}$-like paradigms in a plug-and-play\nfashion. Also, extensive experiments have been conducted on ReasonSeg and\nRefCOCO(+/g) datasets. To validate whether READ suffers from catastrophic\nforgetting of previous skills after fine-tuning, we further assess its\ngeneration ability on an augmented FP-RefCOCO(+/g) dataset. All codes and\nmodels are publicly available at https://github.com/rui-qian/READ.\n","authors":["Rui Qian","Xin Yin","Dejing Dou"],"pdf_url":"https://arxiv.org/pdf/2412.17741v5.pdf","comment":"This work has been accepted to CVPR 2025, please refer to\n  https://github.com/rui-qian/READ"},{"id":"http://arxiv.org/abs/2503.03562v2","updated":"2025-03-06T03:06:58Z","published":"2025-03-05T14:49:08Z","title":"Towards Visual Discrimination and Reasoning of Real-World Physical\n  Dynamics: Physics-Grounded Anomaly Detection","summary":"  Humans detect real-world object anomalies by perceiving, interacting, and\nreasoning based on object-conditioned physical knowledge. The long-term goal of\nIndustrial Anomaly Detection (IAD) is to enable machines to autonomously\nreplicate this skill. However, current IAD algorithms are largely developed and\ntested on static, semantically simple datasets, which diverge from real-world\nscenarios where physical understanding and reasoning are essential. To bridge\nthis gap, we introduce the Physics Anomaly Detection (Phys-AD) dataset, the\nfirst large-scale, real-world, physics-grounded video dataset for industrial\nanomaly detection. Collected using a real robot arm and motor, Phys-AD provides\na diverse set of dynamic, semantically rich scenarios. The dataset includes\nmore than 6400 videos across 22 real-world object categories, interacting with\nrobot arms and motors, and exhibits 47 types of anomalies. Anomaly detection in\nPhys-AD requires visual reasoning, combining both physical knowledge and video\ncontent to determine object abnormality. We benchmark state-of-the-art anomaly\ndetection methods under three settings: unsupervised AD, weakly-supervised AD,\nand video-understanding AD, highlighting their limitations in handling\nphysics-grounded anomalies. Additionally, we introduce the Physics Anomaly\nExplanation (PAEval) metric, designed to assess the ability of visual-language\nfoundation models to not only detect anomalies but also provide accurate\nexplanations for their underlying physical causes. Our dataset and benchmark\nwill be publicly available.\n","authors":["Wenqiao Li","Yao Gu","Xintao Chen","Xiaohao Xu","Ming Hu","Xiaonan Huang","Yingna Wu"],"pdf_url":"https://arxiv.org/pdf/2503.03562v2.pdf","comment":"Accepted by CVPR 2025"},{"id":"http://arxiv.org/abs/2503.03465v2","updated":"2025-03-06T02:55:33Z","published":"2025-03-05T12:56:33Z","title":"DTU-Net: A Multi-Scale Dilated Transformer Network for Nonlinear\n  Hyperspectral Unmixing","summary":"  Transformers have shown significant success in hyperspectral unmixing (HU).\nHowever, challenges remain. While multi-scale and long-range spatial\ncorrelations are essential in unmixing tasks, current Transformer-based\nunmixing networks, built on Vision Transformer (ViT) or Swin-Transformer,\nstruggle to capture them effectively. Additionally, current Transformer-based\nunmixing networks rely on the linear mixing model, which lacks the flexibility\nto accommodate scenarios where nonlinear effects are significant. To address\nthese limitations, we propose a multi-scale Dilated Transformer-based unmixing\nnetwork for nonlinear HU (DTU-Net). The encoder employs two branches. The first\none performs multi-scale spatial feature extraction using Multi-Scale Dilated\nAttention (MSDA) in the Dilated Transformer, which varies dilation rates across\nattention heads to capture long-range and multi-scale spatial correlations. The\nsecond one performs spectral feature extraction utilizing 3D-CNNs with channel\nattention. The outputs from both branches are then fused to integrate\nmulti-scale spatial and spectral information, which is subsequently transformed\nto estimate the abundances. The decoder is designed to accommodate both linear\nand nonlinear mixing scenarios. Its interpretability is enhanced by explicitly\nmodeling the relationships between endmembers, abundances, and nonlinear\ncoefficients in accordance with the polynomial post-nonlinear mixing model\n(PPNMM). Experiments on synthetic and real datasets validate the effectiveness\nof the proposed DTU-Net compared to PPNMM-derived methods and several advanced\nunmixing networks.\n","authors":["ChenTong Wang","Jincheng Gao","Fei Zhu","Abderrahim Halimi","Cdric Richard"],"pdf_url":"https://arxiv.org/pdf/2503.03465v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2408.14153v3","updated":"2025-03-06T09:00:18Z","published":"2024-08-26T09:55:34Z","title":"Explaining Caption-Image Interactions in CLIP models with Second-Order\n  Attributions","summary":"  Dual encoder architectures like CLIP models map two types of inputs into a\nshared embedding space and predict similarities between them. Despite their\nsuccess, it is, however, not understood how these models compare their two\ninputs. Common first-order feature-attribution methods can only provide limited\ninsights into dual-encoders since their predictions depend on\nfeature-interactions rather than on individual features. In this paper, we\nfirst derive a second-order method enabling the attribution of predictions by\nany differentiable dual encoder onto feature-interactions between its inputs.\nSecond, we apply our method to CLIP models and show that they learn\nfine-grained correspondences between parts of captions and regions in images.\nThey match objects across input modes also account for mismatches. This\nvisual-linguistic grounding ability, however, varies heavily between object\nclasses and exhibits pronounced out-of-domain effects. We can identify\nindividual errors as well as systematic failure categories including object\ncoverage, unusual scenes and correlated contexts.\n","authors":["Lucas Mller","Pascal Tilli","Ngoc Thang Vu","Sebastian Pad"],"pdf_url":"https://arxiv.org/pdf/2408.14153v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.03265v2","updated":"2025-03-06T01:46:21Z","published":"2025-03-05T08:47:36Z","title":"Optimizing for the Shortest Path in Denoising Diffusion Model","summary":"  In this research, we propose a novel denoising diffusion model based on\nshortest-path modeling that optimizes residual propagation to enhance both\ndenoising efficiency and quality. Drawing on Denoising Diffusion Implicit\nModels (DDIM) and insights from graph theory, our model, termed the Shortest\nPath Diffusion Model (ShortDF), treats the denoising process as a shortest-path\nproblem aimed at minimizing reconstruction error. By optimizing the initial\nresiduals, we improve the efficiency of the reverse diffusion process and the\nquality of the generated samples. Extensive experiments on multiple standard\nbenchmarks demonstrate that ShortDF significantly reduces diffusion time (or\nsteps) while enhancing the visual fidelity of generated samples compared to\nprior arts. This work, we suppose, paves the way for interactive\ndiffusion-based applications and establishes a foundation for rapid data\ngeneration. Code is available at https://github.com/UnicomAI/ShortDF\n","authors":["Ping Chen","Xingpeng Zhang","Zhaoxiang Liu","Huan Hu","Xiang Liu","Kai Wang","Min Wang","Yanlin Qian","Shiguo Lian"],"pdf_url":"https://arxiv.org/pdf/2503.03265v2.pdf","comment":"Accepet by CVPR 2025 (10 pages, 6 figures)"},{"id":"http://arxiv.org/abs/2503.03190v2","updated":"2025-03-06T03:32:56Z","published":"2025-03-05T05:13:53Z","title":"DSPNet: Dual-vision Scene Perception for Robust 3D Question Answering","summary":"  3D Question Answering (3D QA) requires the model to comprehensively\nunderstand its situated 3D scene described by the text, then reason about its\nsurrounding environment and answer a question under that situation. However,\nexisting methods usually rely on global scene perception from pure 3D point\nclouds and overlook the importance of rich local texture details from\nmulti-view images. Moreover, due to the inherent noise in camera poses and\ncomplex occlusions, there exists significant feature degradation and reduced\nfeature robustness problems when aligning 3D point cloud with multi-view\nimages. In this paper, we propose a Dual-vision Scene Perception Network\n(DSPNet), to comprehensively integrate multi-view and point cloud features to\nimprove robustness in 3D QA. Our Text-guided Multi-view Fusion (TGMF) module\nprioritizes image views that closely match the semantic content of the text. To\nadaptively fuse back-projected multi-view images with point cloud features, we\ndesign the Adaptive Dual-vision Perception (ADVP) module, enhancing 3D scene\ncomprehension. Additionally, our Multimodal Context-guided Reasoning (MCGR)\nmodule facilitates robust reasoning by integrating contextual information\nacross visual and linguistic modalities. Experimental results on SQA3D and\nScanQA datasets demonstrate the superiority of our DSPNet. Codes will be\navailable at https://github.com/LZ-CH/DSPNet.\n","authors":["Jingzhou Luo","Yang Liu","Weixing Chen","Zhen Li","Yaowei Wang","Guanbin Li","Liang Lin"],"pdf_url":"https://arxiv.org/pdf/2503.03190v2.pdf","comment":"Accepted by CVPR 2025"},{"id":"http://arxiv.org/abs/2503.04720v1","updated":"2025-03-06T18:59:06Z","published":"2025-03-06T18:59:06Z","title":"FluidNexus: 3D Fluid Reconstruction and Prediction from a Single Video","summary":"  We study reconstructing and predicting 3D fluid appearance and velocity from\na single video. Current methods require multi-view videos for fluid\nreconstruction. We present FluidNexus, a novel framework that bridges video\ngeneration and physics simulation to tackle this task. Our key insight is to\nsynthesize multiple novel-view videos as references for reconstruction.\nFluidNexus consists of two key components: (1) a novel-view video synthesizer\nthat combines frame-wise view synthesis with video diffusion refinement for\ngenerating realistic videos, and (2) a physics-integrated particle\nrepresentation coupling differentiable simulation and rendering to\nsimultaneously facilitate 3D fluid reconstruction and prediction. To evaluate\nour approach, we collect two new real-world fluid datasets featuring textured\nbackgrounds and object interactions. Our method enables dynamic novel view\nsynthesis, future prediction, and interaction simulation from a single fluid\nvideo. Project website: https://yuegao.me/FluidNexus.\n","authors":["Yue Gao","Hong-Xing Yu","Bo Zhu","Jiajun Wu"],"pdf_url":"https://arxiv.org/pdf/2503.04720v1.pdf","comment":"CVPR 2025. Project website: https://yuegao.me/FluidNexus"},{"id":"http://arxiv.org/abs/2503.04718v1","updated":"2025-03-06T18:58:45Z","published":"2025-03-06T18:58:45Z","title":"Floxels: Fast Unsupervised Voxel Based Scene Flow Estimation","summary":"  Scene flow estimation is a foundational task for many robotic applications,\nincluding robust dynamic object detection, automatic labeling, and sensor\nsynchronization. Two types of approaches to the problem have evolved: 1)\nSupervised and 2) optimization-based methods. Supervised methods are fast\nduring inference and achieve high-quality results, however, they are limited by\nthe need for large amounts of labeled training data and are susceptible to\ndomain gaps. In contrast, unsupervised test-time optimization methods do not\nface the problem of domain gaps but usually suffer from substantial runtime,\nexhibit artifacts, or fail to converge to the right solution. In this work, we\nmitigate several limitations of existing optimization-based methods. To this\nend, we 1) introduce a simple voxel grid-based model that improves over the\nstandard MLP-based formulation in multiple dimensions and 2) introduce a new\nmultiframe loss formulation. 3) We combine both contributions in our new\nmethod, termed Floxels. On the Argoverse 2 benchmark, Floxels is surpassed only\nby EulerFlow among unsupervised methods while achieving comparable performance\nat a fraction of the computational cost. Floxels achieves a massive speedup of\nmore than ~60 - 140x over EulerFlow, reducing the runtime from a day to 10\nminutes per sequence. Over the faster but low-quality baseline, NSFP, Floxels\nachieves a speedup of ~14x.\n","authors":["David T. Hoffmann","Syed Haseeb Raza","Hanqiu Jiang","Denis Tananaev","Steffen Klingenhoefer","Martin Meinke"],"pdf_url":"https://arxiv.org/pdf/2503.04718v1.pdf","comment":"Accepted at CVPR 2025"},{"id":"http://arxiv.org/abs/2503.04707v1","updated":"2025-03-06T18:55:21Z","published":"2025-03-06T18:55:21Z","title":"Iris Style Transfer: Enhancing Iris Recognition with Style Features and\n  Privacy Preservation through Neural Style Transfer","summary":"  Iris texture is widely regarded as a gold standard biometric modality for\nauthentication and identification. The demand for robust iris recognition\nmethods, coupled with growing security and privacy concerns regarding iris\nattacks, has escalated recently. Inspired by neural style transfer, an advanced\ntechnique that leverages neural networks to separate content and style\nfeatures, we hypothesize that iris texture's style features provide a reliable\nfoundation for recognition and are more resilient to variations like rotation\nand perspective shifts than traditional approaches. Our experimental results\nsupport this hypothesis, showing a significantly higher classification accuracy\ncompared to conventional features. Further, we propose using neural style\ntransfer to mask identifiable iris style features, ensuring the protection of\nsensitive biometric information while maintaining the utility of eye images for\ntasks like eye segmentation and gaze estimation. This work opens new avenues\nfor iris-oriented, secure, and privacy-aware biometric systems.\n","authors":["Mengdi Wang","Efe Bozkir","Enkelejda Kasneci"],"pdf_url":"https://arxiv.org/pdf/2503.04707v1.pdf","comment":"14 pages main paper, 4 pages appendix"},{"id":"http://arxiv.org/abs/2503.04698v1","updated":"2025-03-06T18:46:10Z","published":"2025-03-06T18:46:10Z","title":"DEAL-YOLO: Drone-based Efficient Animal Localization using YOLO","summary":"  Although advances in deep learning and aerial surveillance technology are\nimproving wildlife conservation efforts, complex and erratic environmental\nconditions still pose a problem, requiring innovative solutions for\ncost-effective small animal detection. This work introduces DEAL-YOLO, a novel\napproach that improves small object detection in Unmanned Aerial Vehicle (UAV)\nimages by using multi-objective loss functions like Wise IoU (WIoU) and\nNormalized Wasserstein Distance (NWD), which prioritize pixels near the centre\nof the bounding box, ensuring smoother localization and reducing abrupt\ndeviations. Additionally, the model is optimized through efficient feature\nextraction with Linear Deformable (LD) convolutions, enhancing accuracy while\nmaintaining computational efficiency. The Scaled Sequence Feature Fusion (SSFF)\nmodule enhances object detection by effectively capturing inter-scale\nrelationships, improving feature representation, and boosting metrics through\noptimized multiscale fusion. Comparison with baseline models reveals high\nefficacy with up to 69.5\\% fewer parameters compared to vanilla Yolov8-N,\nhighlighting the robustness of the proposed modifications. Through this\napproach, our paper aims to facilitate the detection of endangered species,\nanimal population analysis, habitat monitoring, biodiversity research, and\nvarious other applications that enrich wildlife conservation efforts. DEAL-YOLO\nemploys a two-stage inference paradigm for object detection, refining selected\nregions to improve localization and confidence. This approach enhances\nperformance, especially for small instances with low objectness scores.\n","authors":["Aditya Prashant Naidu","Hem Gosalia","Ishaan Gakhar","Shaurya Singh Rathore","Krish Didwania","Ujjwal Verma"],"pdf_url":"https://arxiv.org/pdf/2503.04698v1.pdf","comment":"Accepted as a Poster at the ML4RS Workshop at ICLR 2025"},{"id":"http://arxiv.org/abs/2503.04688v1","updated":"2025-03-06T18:31:41Z","published":"2025-03-06T18:31:41Z","title":"Teach YOLO to Remember: A Self-Distillation Approach for Continual\n  Object Detection","summary":"  Real-time object detectors like YOLO achieve exceptional performance when\ntrained on large datasets for multiple epochs. However, in real-world scenarios\nwhere data arrives incrementally, neural networks suffer from catastrophic\nforgetting, leading to a loss of previously learned knowledge. To address this,\nprior research has explored strategies for Class Incremental Learning (CIL) in\nContinual Learning for Object Detection (CLOD), with most approaches focusing\non two-stage object detectors. However, existing work suggests that Learning\nwithout Forgetting (LwF) may be ineffective for one-stage anchor-free detectors\nlike YOLO due to noisy regression outputs, which risk transferring corrupted\nknowledge. In this work, we introduce YOLO LwF, a self-distillation approach\ntailored for YOLO-based continual object detection. We demonstrate that when\ncoupled with a replay memory, YOLO LwF significantly mitigates forgetting.\nCompared to previous approaches, it achieves state-of-the-art performance,\nimproving mAP by +2.1% and +2.9% on the VOC and COCO benchmarks, respectively.\n","authors":["Riccardo De Monte","Davide Dalle Pezze","Gian Antonio Susto"],"pdf_url":"https://arxiv.org/pdf/2503.04688v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2502.12360v2","updated":"2025-03-06T18:07:00Z","published":"2025-02-17T22:50:45Z","title":"Detecting Systematic Weaknesses in Vision Models along Predefined\n  Human-Understandable Dimensions","summary":"  Slice discovery methods (SDMs) are prominent algorithms for finding\nsystematic weaknesses in DNNs. They identify top-k semantically coherent\nslices/subsets of data where a DNN-under-test has low performance. For being\ndirectly useful, slices should be aligned with human-understandable and\nrelevant dimensions, which, for example, are defined by safety and domain\nexperts as part of the operational design domain (ODD). While SDMs can be\napplied effectively on structured data, their application on image data is\ncomplicated by the lack of semantic metadata. To address these issues, we\npresent an algorithm that combines foundation models for zero-shot image\nclassification to generate semantic metadata with methods for combinatorial\nsearch to find systematic weaknesses in images. In contrast to existing\napproaches, ours identifies weak slices that are in line with pre-defined\nhuman-understandable dimensions. As the algorithm includes foundation models,\nits intermediate and final results may not always be exact. Therefore, we\ninclude an approach to address the impact of noisy metadata. We validate our\nalgorithm on both synthetic and real-world datasets, demonstrating its ability\nto recover human-understandable systematic weaknesses. Furthermore, using our\napproach, we identify systematic weaknesses of multiple pre-trained and\npublicly available state-of-the-art computer vision DNNs.\n","authors":["Sujan Sai Gannamaneni","Rohil Prakash Rao","Michael Mock","Maram Akila","Stefan Wrobel"],"pdf_url":"https://arxiv.org/pdf/2502.12360v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.04666v1","updated":"2025-03-06T17:59:29Z","published":"2025-03-06T17:59:29Z","title":"What Are You Doing? A Closer Look at Controllable Human Video Generation","summary":"  High-quality benchmarks are crucial for driving progress in machine learning\nresearch. However, despite the growing interest in video generation, there is\nno comprehensive dataset to evaluate human generation. Humans can perform a\nwide variety of actions and interactions, but existing datasets, like TikTok\nand TED-Talks, lack the diversity and complexity to fully capture the\ncapabilities of video generation models. We close this gap by introducing `What\nAre You Doing?' (WYD): a new benchmark for fine-grained evaluation of\ncontrollable image-to-video generation of humans. WYD consists of 1{,}544\ncaptioned videos that have been meticulously collected and annotated with 56\nfine-grained categories. These allow us to systematically measure performance\nacross 9 aspects of human generation, including actions, interactions and\nmotion. We also propose and validate automatic metrics that leverage our\nannotations and better capture human evaluations. Equipped with our dataset and\nmetrics, we perform in-depth analyses of seven state-of-the-art models in\ncontrollable image-to-video generation, showing how WYD provides novel insights\nabout the capabilities of these models. We release our data and code to drive\nforward progress in human video generation modeling at\nhttps://github.com/google-deepmind/wyd-benchmark.\n","authors":["Emanuele Bugliarello","Anurag Arnab","Roni Paiss","Pieter-Jan Kindermans","Cordelia Schmid"],"pdf_url":"https://arxiv.org/pdf/2503.04666v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.04665v1","updated":"2025-03-06T17:58:55Z","published":"2025-03-06T17:58:55Z","title":"Implicit Neural Representation for Video and Image Super-Resolution","summary":"  We present a novel approach for super-resolution that utilizes implicit\nneural representation (INR) to effectively reconstruct and enhance\nlow-resolution videos and images. By leveraging the capacity of neural networks\nto implicitly encode spatial and temporal features, our method facilitates\nhigh-resolution reconstruction using only low-resolution inputs and a 3D\nhigh-resolution grid. This results in an efficient solution for both image and\nvideo super-resolution. Our proposed method, SR-INR, maintains consistent\ndetails across frames and images, achieving impressive temporal stability\nwithout relying on the computationally intensive optical flow or motion\nestimation typically used in other video super-resolution techniques. The\nsimplicity of our approach contrasts with the complexity of many existing\nmethods, making it both effective and efficient. Experimental evaluations show\nthat SR-INR delivers results on par with or superior to state-of-the-art\nsuper-resolution methods, while maintaining a more straightforward structure\nand reduced computational demands. These findings highlight the potential of\nimplicit neural representations as a powerful tool for reconstructing\nhigh-quality, temporally consistent video and image signals from low-resolution\ndata.\n","authors":["Mary Aiyetigbo","Wanqi Yuan","Feng Luo","Nianyi Li"],"pdf_url":"https://arxiv.org/pdf/2503.04665v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2502.09696v2","updated":"2025-03-06T17:45:33Z","published":"2025-02-13T18:59:11Z","title":"ZeroBench: An Impossible Visual Benchmark for Contemporary Large\n  Multimodal Models","summary":"  Large Multimodal Models (LMMs) exhibit major shortfalls when interpreting\nimages and, by some measures, have poorer spatial cognition than small children\nor animals. Despite this, they attain high scores on many popular visual\nbenchmarks, with headroom rapidly eroded by an ongoing surge of model progress.\nTo address this, there is a pressing need for difficult benchmarks that remain\nrelevant for longer. We take this idea to its limit by introducing ZeroBench-a\nlightweight visual reasoning benchmark that is entirely impossible for\ncontemporary frontier LMMs. Our benchmark consists of 100 manually curated\nquestions and 334 less difficult subquestions. We evaluate 20 LMMs on\nZeroBench, all of which score 0.0%, and rigorously analyse the errors. To\nencourage progress in visual understanding, we publicly release ZeroBench.\n","authors":["Jonathan Roberts","Mohammad Reza Taesiri","Ansh Sharma","Akash Gupta","Samuel Roberts","Ioana Croitoru","Simion-Vlad Bogolin","Jialu Tang","Florian Langer","Vyas Raina","Vatsal Raina","Hanyi Xiong","Vishaal Udandarao","Jingyi Lu","Shiyang Chen","Sam Purkis","Tianshuo Yan","Wenye Lin","Gyungin Shin","Qiaochu Yang","Anh Totti Nguyen","David I. Atkinson","Aaditya Baranwal","Alexandru Coca","Mikah Dang","Sebastian Dziadzio","Jakob D. Kunz","Kaiqu Liang","Alexander Lo","Brian Pulfer","Steven Walton","Charig Yang","Kai Han","Samuel Albanie"],"pdf_url":"https://arxiv.org/pdf/2502.09696v2.pdf","comment":"20 pages, 13 figures"},{"id":"http://arxiv.org/abs/2503.04653v1","updated":"2025-03-06T17:43:03Z","published":"2025-03-06T17:43:03Z","title":"RadIR: A Scalable Framework for Multi-Grained Medical Image Retrieval\n  via Radiology Report Mining","summary":"  Developing advanced medical imaging retrieval systems is challenging due to\nthe varying definitions of `similar images' across different medical contexts.\nThis challenge is compounded by the lack of large-scale, high-quality medical\nimaging retrieval datasets and benchmarks. In this paper, we propose a novel\nmethodology that leverages dense radiology reports to define image-wise\nsimilarity ordering at multiple granularities in a scalable and fully automatic\nmanner. Using this approach, we construct two comprehensive medical imaging\nretrieval datasets: MIMIC-IR for Chest X-rays and CTRATE-IR for CT scans,\nproviding detailed image-image ranking annotations conditioned on diverse\nanatomical structures. Furthermore, we develop two retrieval systems, RadIR-CXR\nand model-ChestCT, which demonstrate superior performance in traditional\nimage-image and image-report retrieval tasks. These systems also enable\nflexible, effective image retrieval conditioned on specific anatomical\nstructures described in text, achieving state-of-the-art results on 77 out of\n78 metrics.\n","authors":["Tengfei Zhang","Ziheng Zhao","Chaoyi Wu","Xiao Zhou","Ya Zhang","Yangfeng Wang","Weidi Xie"],"pdf_url":"https://arxiv.org/pdf/2503.04653v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.04649v1","updated":"2025-03-06T17:35:37Z","published":"2025-03-06T17:35:37Z","title":"Transferable Foundation Models for Geometric Tasks on Point Cloud\n  Representations: Geometric Neural Operators","summary":"  We introduce methods for obtaining pretrained Geometric Neural Operators\n(GNPs) that can serve as basal foundation models for use in obtaining geometric\nfeatures. These can be used within data processing pipelines for machine\nlearning tasks and numerical methods. We show how our GNPs can be trained to\nlearn robust latent representations for the differential geometry of\npoint-clouds to provide estimates of metric, curvature, and other shape-related\nfeatures. We demonstrate how our pre-trained GNPs can be used (i) to estimate\nthe geometric properties of surfaces of arbitrary shape and topologies with\nrobustness in the presence of noise, (ii) to approximate solutions of geometric\npartial differential equations (PDEs) on manifolds, and (iii) to solve\nequations for shape deformations such as curvature driven flows. We also\nrelease a package of the codes and weights for using our pre-trained GNPs for\nprocessing point cloud representations. This allows for incorporating our\npre-trained GNPs as components for reuse within existing and new data\nprocessing pipelines. The GNPs also can be used as part of numerical solvers\ninvolving geometry or as part of methods for performing inference and other\ngeometric tasks.\n","authors":["Blaine Quackenbush","Paul J. Atzberger"],"pdf_url":"https://arxiv.org/pdf/2503.04649v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2501.04873v2","updated":"2025-03-06T17:35:19Z","published":"2025-01-08T23:07:10Z","title":"Back Home: A Machine Learning Approach to Seashell Classification and\n  Ecosystem Restoration","summary":"  In Costa Rica, an average of 5 tons of seashells are extracted from\necosystems annually. Confiscated seashells, cannot be returned to their\necosystems due to the lack of origin recognition. To address this issue, we\ndeveloped a convolutional neural network (CNN) specifically for seashell\nidentification. We built a dataset from scratch, consisting of approximately\n19000 images from the Pacific and Caribbean coasts. Using this dataset, the\nmodel achieved a classification accuracy exceeding 85%. The model has been\nintegrated into a user-friendly application, which has classified over 36,000\nseashells to date, delivering real-time results within 3 seconds per image. To\nfurther enhance the system's accuracy, an anomaly detection mechanism was\nincorporated to filter out irrelevant or anomalous inputs, ensuring only valid\nseashell images are processed.\n","authors":["Alexander Valverde","Luis Solano"],"pdf_url":"https://arxiv.org/pdf/2501.04873v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.04643v1","updated":"2025-03-06T17:32:15Z","published":"2025-03-06T17:32:15Z","title":"Adaptive Prototype Learning for Multimodal Cancer Survival Analysis","summary":"  Leveraging multimodal data, particularly the integration of whole-slide\nhistology images (WSIs) and transcriptomic profiles, holds great promise for\nimproving cancer survival prediction. However, excessive redundancy in\nmultimodal data can degrade model performance. In this paper, we propose\nAdaptive Prototype Learning (APL), a novel and effective approach for\nmultimodal cancer survival analysis. APL adaptively learns representative\nprototypes in a data-driven manner, reducing redundancy while preserving\ncritical information. Our method employs two sets of learnable query vectors\nthat serve as a bridge between high-dimensional representations and survival\nprediction, capturing task-relevant features. Additionally, we introduce a\nmultimodal mixed self-attention mechanism to enable cross-modal interactions,\nfurther enhancing information fusion. Extensive experiments on five benchmark\ncancer datasets demonstrate the superiority of our approach over existing\nmethods. The code is available at https://github.com/HongLiuuuuu/APL.\n","authors":["Hong Liu","Haosen Yang","Federica Eduati","Josien P. W. Pluim","Mitko Veta"],"pdf_url":"https://arxiv.org/pdf/2503.04643v1.pdf","comment":"10 pages, 3 figures"},{"id":"http://arxiv.org/abs/2503.04641v1","updated":"2025-03-06T17:31:43Z","published":"2025-03-06T17:31:43Z","title":"Simulating the Real World: A Unified Survey of Multimodal Generative\n  Models","summary":"  Understanding and replicating the real world is a critical challenge in\nArtificial General Intelligence (AGI) research. To achieve this, many existing\napproaches, such as world models, aim to capture the fundamental principles\ngoverning the physical world, enabling more accurate simulations and meaningful\ninteractions. However, current methods often treat different modalities,\nincluding 2D (images), videos, 3D, and 4D representations, as independent\ndomains, overlooking their interdependencies. Additionally, these methods\ntypically focus on isolated dimensions of reality without systematically\nintegrating their connections. In this survey, we present a unified survey for\nmultimodal generative models that investigate the progression of data\ndimensionality in real-world simulation. Specifically, this survey starts from\n2D generation (appearance), then moves to video (appearance+dynamics) and 3D\ngeneration (appearance+geometry), and finally culminates in 4D generation that\nintegrate all dimensions. To the best of our knowledge, this is the first\nattempt to systematically unify the study of 2D, video, 3D and 4D generation\nwithin a single framework. To guide future research, we provide a comprehensive\nreview of datasets, evaluation metrics and future directions, and fostering\ninsights for newcomers. This survey serves as a bridge to advance the study of\nmultimodal generative models and real-world simulation within a unified\nframework.\n","authors":["Yuqi Hu","Longguang Wang","Xian Liu","Ling-Hao Chen","Yuwei Guo","Yukai Shi","Ce Liu","Anyi Rao","Zeyu Wang","Hui Xiong"],"pdf_url":"https://arxiv.org/pdf/2503.04641v1.pdf","comment":"Repository for the related papers at\n  https://github.com/ALEEEHU/World-Simulator"},{"id":"http://arxiv.org/abs/2503.04639v1","updated":"2025-03-06T17:28:48Z","published":"2025-03-06T17:28:48Z","title":"Enhancing SAM with Efficient Prompting and Preference Optimization for\n  Semi-supervised Medical Image Segmentation","summary":"  Foundational models such as the Segment Anything Model (SAM) are gaining\ntraction in medical imaging segmentation, supporting multiple downstream tasks.\nHowever, such models are supervised in nature, still relying on large annotated\ndatasets or prompts supplied by experts. Conventional techniques such as active\nlearning to alleviate such limitations are limited in scope and still\nnecessitate continuous human involvement and complex domain knowledge for label\nrefinement or establishing reward ground truth. To address these challenges, we\npropose an enhanced Segment Anything Model (SAM) framework that utilizes\nannotation-efficient prompts generated in a fully unsupervised fashion, while\nstill capturing essential semantic, location, and shape information through\ncontrastive language-image pretraining and visual question answering. We adopt\nthe direct preference optimization technique to design an optimal policy that\nenables the model to generate high-fidelity segmentations with simple ratings\nor rankings provided by a virtual annotator simulating the human annotation\nprocess. State-of-the-art performance of our framework in tasks such as lung\nsegmentation, breast tumor segmentation, and organ segmentation across various\nmodalities, including X-ray, ultrasound, and abdominal CT, justifies its\neffectiveness in low-annotation data scenarios.\n","authors":["Aishik Konwer","Zhijian Yang","Erhan Bas","Cao Xiao","Prateek Prasanna","Parminder Bhatia","Taha Kass-Hout"],"pdf_url":"https://arxiv.org/pdf/2503.04639v1.pdf","comment":"Accepted to CVPR 2025"},{"id":"http://arxiv.org/abs/2503.04635v1","updated":"2025-03-06T17:23:55Z","published":"2025-03-06T17:23:55Z","title":"3HANDS Dataset: Learning from Humans for Generating Naturalistic\n  Handovers with Supernumerary Robotic Limbs","summary":"  Supernumerary robotic limbs (SRLs) are robotic structures integrated closely\nwith the user's body, which augment human physical capabilities and necessitate\nseamless, naturalistic human-machine interaction. For effective assistance in\nphysical tasks, enabling SRLs to hand over objects to humans is crucial. Yet,\ndesigning heuristic-based policies for robots is time-consuming, difficult to\ngeneralize across tasks, and results in less human-like motion. When trained\nwith proper datasets, generative models are powerful alternatives for creating\nnaturalistic handover motions. We introduce 3HANDS, a novel dataset of object\nhandover interactions between a participant performing a daily activity and\nanother participant enacting a hip-mounted SRL in a naturalistic manner. 3HANDS\ncaptures the unique characteristics of SRL interactions: operating in intimate\npersonal space with asymmetric object origins, implicit motion synchronization,\nand the user's engagement in a primary task during the handover. To demonstrate\nthe effectiveness of our dataset, we present three models: one that generates\nnaturalistic handover trajectories, another that determines the appropriate\nhandover endpoints, and a third that predicts the moment to initiate a\nhandover. In a user study (N=10), we compare the handover interaction performed\nwith our method compared to a baseline. The findings show that our method was\nperceived as significantly more natural, less physically demanding, and more\ncomfortable.\n","authors":["Artin Saberpour Abadian","Yi-Chi Liao","Ata Otaran","Rishabh Dabral","Marie Muehlhaus","Christian Theobalt","Martin Schmitz","Jrgen Steimle"],"pdf_url":"https://arxiv.org/pdf/2503.04635v1.pdf","comment":"CHI '25"},{"id":"http://arxiv.org/abs/2503.04634v1","updated":"2025-03-06T17:21:12Z","published":"2025-03-06T17:21:12Z","title":"PathoPainter: Augmenting Histopathology Segmentation via Tumor-aware\n  Inpainting","summary":"  Tumor segmentation plays a critical role in histopathology, but it requires\ncostly, fine-grained image-mask pairs annotated by pathologists. Thus,\nsynthesizing histopathology data to expand the dataset is highly desirable.\nPrevious works suffer from inaccuracies and limited diversity in image-mask\npairs, both of which affect training segmentation, particularly in small-scale\ndatasets and the inherently complex nature of histopathology images. To address\nthis challenge, we propose PathoPainter, which reformulates image-mask pair\ngeneration as a tumor inpainting task. Specifically, our approach preserves the\nbackground while inpainting the tumor region, ensuring precise alignment\nbetween the generated image and its corresponding mask. To enhance dataset\ndiversity while maintaining biological plausibility, we incorporate a sampling\nmechanism that conditions tumor inpainting on regional embeddings from a\ndifferent image. Additionally, we introduce a filtering strategy to exclude\nuncertain synthetic regions, further improving the quality of the generated\ndata. Our comprehensive evaluation spans multiple datasets featuring diverse\ntumor types and various training data scales. As a result, segmentation\nimproved significantly with our synthetic data, surpassing existing\nsegmentation data synthesis approaches, e.g., 75.69% -> 77.69% on CAMELYON16.\nThe code is available at https://github.com/HongLiuuuuu/PathoPainter.\n","authors":["Hong Liu","Haosen Yang","Evi M. C. Huijben","Mark Schuiveling","Ruisheng Su","Josien P. W. Pluim","Mitko Veta"],"pdf_url":"https://arxiv.org/pdf/2503.04634v1.pdf","comment":"10 pages, 3 figures"},{"id":"http://arxiv.org/abs/2503.00897v3","updated":"2025-03-06T17:19:22Z","published":"2025-03-02T13:43:53Z","title":"A Simple and Effective Reinforcement Learning Method for Text-to-Image\n  Diffusion Fine-tuning","summary":"  Reinforcement learning (RL)-based fine-tuning has emerged as a powerful\napproach for aligning diffusion models with black-box objectives. Proximal\npolicy optimization (PPO) is the most popular choice of method for policy\noptimization. While effective in terms of performance, PPO is highly sensitive\nto hyper-parameters and involves substantial computational overhead. REINFORCE,\non the other hand, mitigates some computational complexities such as high\nmemory overhead and sensitive hyper-parameter tuning, but has suboptimal\nperformance due to high-variance and sample inefficiency. While the variance of\nthe REINFORCE can be reduced by sampling multiple actions per input prompt and\nusing a baseline correction term, it still suffers from sample inefficiency. To\naddress these challenges, we systematically analyze the\nefficiency-effectiveness trade-off between REINFORCE and PPO, and propose\nleave-one-out PPO (LOOP), a novel RL for diffusion fine-tuning method. LOOP\ncombines variance reduction techniques from REINFORCE, such as sampling\nmultiple actions per input prompt and a baseline correction term, with the\nrobustness and sample efficiency of PPO via clipping and importance sampling.\nOur results demonstrate that LOOP effectively improves diffusion models on\nvarious black-box objectives, and achieves a better balance between\ncomputational efficiency and performance.\n","authors":["Shashank Gupta","Chaitanya Ahuja","Tsung-Yu Lin","Sreya Dutta Roy","Harrie Oosterhuis","Maarten de Rijke","Satya Narayan Shukla"],"pdf_url":"https://arxiv.org/pdf/2503.00897v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2405.12833v2","updated":"2025-03-06T17:18:49Z","published":"2024-05-21T14:37:35Z","title":"A Survey of Deep Learning-based Radiology Report Generation Using\n  Multimodal Data","summary":"  Automatic radiology report generation can alleviate the workload for\nphysicians and minimize regional disparities in medical resources, therefore\nbecoming an important topic in the medical image analysis field. It is a\nchallenging task, as the computational model needs to mimic physicians to\nobtain information from multi-modal input data (i.e., medical images, clinical\ninformation, medical knowledge, etc.), and produce comprehensive and accurate\nreports. Recently, numerous works have emerged to address this issue using\ndeep-learning-based methods, such as transformers, contrastive learning, and\nknowledge-base construction. This survey summarizes the key techniques\ndeveloped in the most recent works and proposes a general workflow for\ndeep-learning-based report generation with five main components, including\nmulti-modality data acquisition, data preparation, feature learning, feature\nfusion and interaction, and report generation. The state-of-the-art methods for\neach of these components are highlighted. Additionally, we summarize the latest\ndevelopments in large model-based methods and model explainability, along with\npublic datasets, evaluation methods, current challenges, and future directions\nin this field. We have also conducted a quantitative comparison between\ndifferent methods in the same experimental setting. This is the most up-to-date\nsurvey that focuses on multi-modality inputs and data fusion for radiology\nreport generation. The aim is to provide comprehensive and rich information for\nresearchers interested in automatic clinical report generation and medical\nimage analysis, especially when using multimodal inputs, and to assist them in\ndeveloping new algorithms to advance the field.\n","authors":["Xinyi Wang","Grazziela Figueredo","Ruizhe Li","Wei Emma Zhang","Weitong Chen","Xin Chen"],"pdf_url":"https://arxiv.org/pdf/2405.12833v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2409.11919v3","updated":"2025-03-06T17:12:48Z","published":"2024-09-18T12:32:25Z","title":"LLM-wrapper: Black-Box Semantic-Aware Adaptation of Vision-Language\n  Models for Referring Expression Comprehension","summary":"  Vision Language Models (VLMs) have demonstrated remarkable capabilities in\nvarious open-vocabulary tasks, yet their zero-shot performance lags behind\ntask-specific fine-tuned models, particularly in complex tasks like Referring\nExpression Comprehension (REC). Fine-tuning usually requires 'white-box' access\nto the model's architecture and weights, which is not always feasible due to\nproprietary or privacy concerns. In this work, we propose LLM-wrapper, a method\nfor 'black-box' adaptation of VLMs for the REC task using Large Language Models\n(LLMs). LLM-wrapper capitalizes on the reasoning abilities of LLMs, improved\nwith a light fine-tuning, to select the most relevant bounding box matching the\nreferring expression, from candidates generated by a zero-shot black-box VLM.\nOur approach offers several advantages: it enables the adaptation of\nclosed-source models without needing access to their internal workings, it is\nversatile as it works with any VLM, it transfers to new VLMs and datasets, and\nit allows for the adaptation of an ensemble of VLMs. We evaluate LLM-wrapper on\nmultiple datasets using different VLMs and LLMs, demonstrating significant\nperformance improvements and highlighting the versatility of our method. While\nLLM-wrapper is not meant to directly compete with standard white-box\nfine-tuning, it offers a practical and effective alternative for black-box VLM\nadaptation. Code and checkpoints are available at\nhttps://github.com/valeoai/LLM_wrapper .\n","authors":["Amaia Cardiel","Eloi Zablocki","Elias Ramzi","Oriane Simoni","Matthieu Cord"],"pdf_url":"https://arxiv.org/pdf/2409.11919v3.pdf","comment":"LLM-wrapper (v3) is published as a conference paper at ICLR 2025. (v1\n  was presented at EVAL-FoMo workshop, ECCV 2024.)"},{"id":"http://arxiv.org/abs/2410.05116v2","updated":"2025-03-06T17:11:55Z","published":"2024-10-07T15:12:01Z","title":"Human-Feedback Efficient Reinforcement Learning for Online Diffusion\n  Model Finetuning","summary":"  Controllable generation through Stable Diffusion (SD) fine-tuning aims to\nimprove fidelity, safety, and alignment with human guidance. Existing\nreinforcement learning from human feedback methods usually rely on predefined\nheuristic reward functions or pretrained reward models built on large-scale\ndatasets, limiting their applicability to scenarios where collecting such data\nis costly or difficult. To effectively and efficiently utilize human feedback,\nwe develop a framework, HERO, which leverages online human feedback collected\non the fly during model learning. Specifically, HERO features two key\nmechanisms: (1) Feedback-Aligned Representation Learning, an online training\nmethod that captures human feedback and provides informative learning signals\nfor fine-tuning, and (2) Feedback-Guided Image Generation, which involves\ngenerating images from SD's refined initialization samples, enabling faster\nconvergence towards the evaluator's intent. We demonstrate that HERO is 4x more\nefficient in online feedback for body part anomaly correction compared to the\nbest existing method. Additionally, experiments show that HERO can effectively\nhandle tasks like reasoning, counting, personalization, and reducing NSFW\ncontent with only 0.5K online feedback.\n","authors":["Ayano Hiranaka","Shang-Fu Chen","Chieh-Hsin Lai","Dongjun Kim","Naoki Murata","Takashi Shibuya","Wei-Hsiang Liao","Shao-Hua Sun","Yuki Mitsufuji"],"pdf_url":"https://arxiv.org/pdf/2410.05116v2.pdf","comment":"Published in International Conference on Learning Representations\n  (ICLR) 2025"},{"id":"http://arxiv.org/abs/2503.02394v3","updated":"2025-03-06T17:10:24Z","published":"2025-03-04T08:35:01Z","title":"BHViT: Binarized Hybrid Vision Transformer","summary":"  Model binarization has made significant progress in enabling real-time and\nenergy-efficient computation for convolutional neural networks (CNN), offering\na potential solution to the deployment challenges faced by Vision Transformers\n(ViTs) on edge devices. However, due to the structural differences between CNN\nand Transformer architectures, simply applying binary CNN strategies to the ViT\nmodels will lead to a significant performance drop. To tackle this challenge,\nwe propose BHViT, a binarization-friendly hybrid ViT architecture and its full\nbinarization model with the guidance of three important observations.\nInitially, BHViT utilizes the local information interaction and hierarchical\nfeature aggregation technique from coarse to fine levels to address redundant\ncomputations stemming from excessive tokens. Then, a novel module based on\nshift operations is proposed to enhance the performance of the binary\nMultilayer Perceptron (MLP) module without significantly increasing\ncomputational overhead. In addition, an innovative attention matrix\nbinarization method based on quantization decomposition is proposed to evaluate\nthe token's importance in the binarized attention matrix. Finally, we propose a\nregularization loss to address the inadequate optimization caused by the\nincompatibility between the weight oscillation in the binary layers and the\nAdam Optimizer. Extensive experimental results demonstrate that our proposed\nalgorithm achieves SOTA performance among binary ViT methods.\n","authors":["Tian Gao","Zhiyuan Zhang","Yu Zhang","Huajun Liu","Kaijie Yin","Chengzhong Xu","Hui Kong"],"pdf_url":"https://arxiv.org/pdf/2503.02394v3.pdf","comment":"Accepted by CVPR2025"},{"id":"http://arxiv.org/abs/2407.18125v3","updated":"2025-03-06T17:03:35Z","published":"2024-07-25T15:32:59Z","title":"Self-supervised pre-training with diffusion model for few-shot landmark\n  detection in x-ray images","summary":"  Deep neural networks have been extensively applied in the medical domain for\nvarious tasks, including image classification, segmentation, and landmark\ndetection. However, their application is often hindered by data scarcity, both\nin terms of available annotations and images. This study introduces a novel\napplication of denoising diffusion probabilistic models (DDPMs) to the landmark\ndetection task, specifically addressing the challenge of limited annotated data\nin x-ray imaging. Our key innovation lies in leveraging DDPMs for\nself-supervised pre-training in landmark detection, a previously unexplored\napproach in this domain. This method enables accurate landmark detection with\nminimal annotated training data (as few as 50 images), surpassing both ImageNet\nsupervised pre-training and traditional self-supervised techniques across three\npopular x-ray benchmark datasets. To our knowledge, this work represents the\nfirst application of diffusion models for self-supervised learning in landmark\ndetection, which may offer a valuable pre-training approach in few-shot\nregimes, for mitigating data scarcity.\n","authors":["Roberto Di Via","Francesca Odone","Vito Paolo Pastore"],"pdf_url":"https://arxiv.org/pdf/2407.18125v3.pdf","comment":"Accepted at WACV 2025"},{"id":"http://arxiv.org/abs/2503.04606v1","updated":"2025-03-06T16:53:14Z","published":"2025-03-06T16:53:14Z","title":"The Best of Both Worlds: Integrating Language Models and Diffusion\n  Models for Video Generation","summary":"  Recent advancements in text-to-video (T2V) generation have been driven by two\ncompeting paradigms: autoregressive language models and diffusion models.\nHowever, each paradigm has intrinsic limitations: language models struggle with\nvisual quality and error accumulation, while diffusion models lack semantic\nunderstanding and causal modeling. In this work, we propose LanDiff, a hybrid\nframework that synergizes the strengths of both paradigms through\ncoarse-to-fine generation. Our architecture introduces three key innovations:\n(1) a semantic tokenizer that compresses 3D visual features into compact 1D\ndiscrete representations through efficient semantic compression, achieving a\n$\\sim$14,000$\\times$ compression ratio; (2) a language model that generates\nsemantic tokens with high-level semantic relationships; (3) a streaming\ndiffusion model that refines coarse semantics into high-fidelity videos.\nExperiments show that LanDiff, a 5B model, achieves a score of 85.43 on the\nVBench T2V benchmark, surpassing the state-of-the-art open-source models\nHunyuan Video (13B) and other commercial models such as Sora, Keling, and\nHailuo. Furthermore, our model also achieves state-of-the-art performance in\nlong video generation, surpassing other open-source models in this field. Our\ndemo can be viewed at https://landiff.github.io/.\n","authors":["Aoxiong Yin","Kai Shen","Yichong Leng","Xu Tan","Xinyu Zhou","Juncheng Li","Siliang Tang"],"pdf_url":"https://arxiv.org/pdf/2503.04606v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.17494v4","updated":"2025-03-06T16:43:10Z","published":"2024-10-23T01:25:25Z","title":"Enhancing Multimodal Medical Image Classification using Cross-Graph\n  Modal Contrastive Learning","summary":"  The classification of medical images is a pivotal aspect of disease\ndiagnosis, often enhanced by deep learning techniques. However, traditional\napproaches typically focus on unimodal medical image data, neglecting the\nintegration of diverse non-image patient data. This paper proposes a novel\nCross-Graph Modal Contrastive Learning (CGMCL) framework for multimodal\nstructured data from different data domains to improve medical image\nclassification. The model effectively integrates both image and non-image data\nby constructing cross-modality graphs and leveraging contrastive learning to\nalign multimodal features in a shared latent space. An inter-modality feature\nscaling module further optimizes the representation learning process by\nreducing the gap between heterogeneous modalities. The proposed approach is\nevaluated on two datasets: a Parkinson's disease (PD) dataset and a public\nmelanoma dataset. Results demonstrate that CGMCL outperforms conventional\nunimodal methods in accuracy, interpretability, and early disease prediction.\nAdditionally, the method shows superior performance in multi-class melanoma\nclassification. The CGMCL framework provides valuable insights into medical\nimage classification while offering improved disease interpretability and\npredictive capabilities.\n","authors":["Jun-En Ding","Chien-Chin Hsu","Chi-Hsiang Chu","Shuqiang Wang","Feng Liu"],"pdf_url":"https://arxiv.org/pdf/2410.17494v4.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.04592v1","updated":"2025-03-06T16:31:34Z","published":"2025-03-06T16:31:34Z","title":"A Benchmark for Multi-Lingual Vision-Language Learning in Remote Sensing\n  Image Captioning","summary":"  Remote Sensing Image Captioning (RSIC) is a cross-modal field bridging vision\nand language, aimed at automatically generating natural language descriptions\nof features and scenes in remote sensing imagery. Despite significant advances\nin developing sophisticated methods and large-scale datasets for training\nvision-language models (VLMs), two critical challenges persist: the scarcity of\nnon-English descriptive datasets and the lack of multilingual capability\nevaluation for models. These limitations fundamentally impede the progress and\npractical deployment of RSIC, particularly in the era of large VLMs. To address\nthese challenges, this paper presents several significant contributions to the\nfield. First, we introduce and analyze BRSIC (Bilingual Remote Sensing Image\nCaptioning), a comprehensive bilingual dataset that enriches three established\nEnglish RSIC datasets with Chinese descriptions, encompassing 13,634 images\npaired with 68,170 bilingual captions. Building upon this foundation, we\ndevelop a systematic evaluation framework that addresses the prevalent\ninconsistency in evaluation protocols, enabling rigorous assessment of model\nperformance through standardized retraining procedures on BRSIC. Furthermore,\nwe present an extensive empirical study of eight state-of-the-art large\nvision-language models (LVLMs), examining their capabilities across multiple\nparadigms including zero-shot inference, supervised fine-tuning, and\nmulti-lingual training. This comprehensive evaluation provides crucial insights\ninto the strengths and limitations of current LVLMs in handling multilingual\nremote sensing tasks. Additionally, our cross-dataset transfer experiments\nreveal interesting findings. The code and data will be available at\nhttps://github.com/mrazhou/BRSIC.\n","authors":["Qing Zhou","Tao Yang","Junyu Gao","Weiping Ni","Junzheng Wu","Qi Wang"],"pdf_url":"https://arxiv.org/pdf/2503.04592v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.03663v2","updated":"2025-03-06T16:25:37Z","published":"2025-03-05T16:52:34Z","title":"LION-FS: Fast & Slow Video-Language Thinker as Online Video Assistant","summary":"  First-person video assistants are highly anticipated to enhance our daily\nlives through online video dialogue. However, existing online video assistants\noften sacrifice assistant efficacy for real-time efficiency by processing\nlow-frame-rate videos with coarse-grained visual features.To overcome the\ntrade-off between efficacy and efficiency, we propose \"Fast & Slow\nVideo-Language Thinker\" as an onLIne videO assistaNt, LION-FS, achieving\nreal-time, proactive, temporally accurate, and contextually precise responses.\nLION-FS adopts a two-stage optimization strategy: 1)Fast Path: Routing-Based\nResponse Determination evaluates frame-by-frame whether an immediate response\nis necessary. To enhance response determination accuracy and handle higher\nframe-rate inputs efficiently, we employ Token Aggregation Routing to\ndynamically fuse spatiotemporal features without increasing token numbers,\nwhile utilizing Token Dropping Routing to eliminate redundant features. 2)Slow\nPath: Multi-granularity Keyframe Augmentation optimizes keyframes during\nresponse generation. To provide comprehensive and detailed responses beyond\natomic actions constrained by training data, fine-grained spatial features and\nhuman-environment interaction features are extracted through multi-granular\npooling. These features are further integrated into a meticulously designed\nmultimodal Thinking Template to guide more precise response generation.\nComprehensive evaluations on online video tasks demonstrate that LION-FS\nachieves state-of-the-art efficacy and efficiency.\n","authors":["Wei Li","Bing Hu","Rui Shao","Leyang Shen","Liqiang Nie"],"pdf_url":"https://arxiv.org/pdf/2503.03663v2.pdf","comment":"Accept to CVPR 2025, Project page:\n  https://github.com/JiuTian-VL/LION-FS"},{"id":"http://arxiv.org/abs/2503.04565v1","updated":"2025-03-06T15:53:42Z","published":"2025-03-06T15:53:42Z","title":"Omnidirectional Multi-Object Tracking","summary":"  Panoramic imagery, with its 360{\\deg} field of view, offers comprehensive\ninformation to support Multi-Object Tracking (MOT) in capturing spatial and\ntemporal relationships of surrounding objects. However, most MOT algorithms are\ntailored for pinhole images with limited views, impairing their effectiveness\nin panoramic settings. Additionally, panoramic image distortions, such as\nresolution loss, geometric deformation, and uneven lighting, hinder direct\nadaptation of existing MOT methods, leading to significant performance\ndegradation. To address these challenges, we propose OmniTrack, an\nomnidirectional MOT framework that incorporates Tracklet Management to\nintroduce temporal cues, FlexiTrack Instances for object localization and\nassociation, and the CircularStatE Module to alleviate image and geometric\ndistortions. This integration enables tracking in large field-of-view\nscenarios, even under rapid sensor motion. To mitigate the lack of panoramic\nMOT datasets, we introduce the QuadTrack dataset--a comprehensive panoramic\ndataset collected by a quadruped robot, featuring diverse challenges such as\nwide fields of view, intense motion, and complex environments. Extensive\nexperiments on the public JRDB dataset and the newly introduced QuadTrack\nbenchmark demonstrate the state-of-the-art performance of the proposed\nframework. OmniTrack achieves a HOTA score of 26.92% on JRDB, representing an\nimprovement of 3.43%, and further achieves 23.45% on QuadTrack, surpassing the\nbaseline by 6.81%. The dataset and code will be made publicly available at\nhttps://github.com/xifen523/OmniTrack.\n","authors":["Kai Luo","Hao Shi","Sheng Wu","Fei Teng","Mengfei Duan","Chang Huang","Yuhang Wang","Kaiwei Wang","Kailun Yang"],"pdf_url":"https://arxiv.org/pdf/2503.04565v1.pdf","comment":"Accepted to CVPR 2025. The dataset and code will be made publicly\n  available at https://github.com/xifen523/OmniTrack"},{"id":"http://arxiv.org/abs/2502.09990v2","updated":"2025-03-06T15:38:31Z","published":"2025-02-14T08:22:51Z","title":"X-Boundary: Establishing Exact Safety Boundary to Shield LLMs from\n  Multi-Turn Jailbreaks without Compromising Usability","summary":"  Despite the rapid development of safety alignment techniques for LLMs,\ndefending against multi-turn jailbreaks is still a challenging task. In this\npaper, we conduct a comprehensive comparison, revealing that some existing\ndefense methods can improve the robustness of LLMs against multi-turn\njailbreaks but compromise usability, i.e., reducing general capabilities or\ncausing the over-refusal problem. From the perspective of mechanism\ninterpretability of LLMs, we discover that these methods fail to establish a\nboundary that exactly distinguishes safe and harmful feature representations.\nTherefore, boundary-safe representations close to harmful representations are\ninevitably disrupted, leading to a decline in usability. To address this issue,\nwe propose X-Boundary to push harmful representations away from boundary-safe\nrepresentations and obtain an exact distinction boundary. In this way, harmful\nrepresentations can be precisely erased without disrupting safe ones.\nExperimental results show that X-Boundary achieves state-of-the-art defense\nperformance against multi-turn jailbreaks, while reducing the over-refusal rate\nby about 20% and maintaining nearly complete general capability. Furthermore,\nwe theoretically prove and empirically verify that X-Boundary can accelerate\nthe convergence process during training. Please see our code at:\nhttps://github.com/AI45Lab/X-Boundary.\n","authors":["Xiaoya Lu","Dongrui Liu","Yi Yu","Luxin Xu","Jing Shao"],"pdf_url":"https://arxiv.org/pdf/2502.09990v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.04545v1","updated":"2025-03-06T15:33:19Z","published":"2025-03-06T15:33:19Z","title":"ViT-VS: On the Applicability of Pretrained Vision Transformer Features\n  for Generalizable Visual Servoing","summary":"  Visual servoing enables robots to precisely position their end-effector\nrelative to a target object. While classical methods rely on hand-crafted\nfeatures and thus are universally applicable without task-specific training,\nthey often struggle with occlusions and environmental variations, whereas\nlearning-based approaches improve robustness but typically require extensive\ntraining. We present a visual servoing approach that leverages pretrained\nvision transformers for semantic feature extraction, combining the advantages\nof both paradigms while also being able to generalize beyond the provided\nsample. Our approach achieves full convergence in unperturbed scenarios and\nsurpasses classical image-based visual servoing by up to 31.2\\% relative\nimprovement in perturbed scenarios. Even the convergence rates of\nlearning-based methods are matched despite requiring no task- or\nobject-specific training. Real-world evaluations confirm robust performance in\nend-effector positioning, industrial box manipulation, and grasping of unseen\nobjects using only a reference from the same category. Our code and simulation\nenvironment are available at: https://alessandroscherl.github.io/ViT-VS/\n","authors":["Alessandro Scherl","Stefan Thalhammer","Bernhard Neuberger","Wilfried Wber","Jos Graca-Rodrguez"],"pdf_url":"https://arxiv.org/pdf/2503.04545v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.00299v2","updated":"2025-03-06T15:32:33Z","published":"2024-10-01T00:43:45Z","title":"GSPR: Multimodal Place Recognition Using 3D Gaussian Splatting for\n  Autonomous Driving","summary":"  Place recognition is a crucial component that enables autonomous vehicles to\nobtain localization results in GPS-denied environments. In recent years,\nmultimodal place recognition methods have gained increasing attention. They\novercome the weaknesses of unimodal sensor systems by leveraging complementary\ninformation from different modalities. However, most existing methods explore\ncross-modality correlations through feature-level or descriptor-level fusion,\nsuffering from a lack of interpretability. Conversely, the recently proposed 3D\nGaussian Splatting provides a new perspective on multimodal fusion by\nharmonizing different modalities into an explicit scene representation. In this\npaper, we propose a 3D Gaussian Splatting-based multimodal place recognition\nnetwork dubbed GSPR. It explicitly combines multi-view RGB images and LiDAR\npoint clouds into a spatio-temporally unified scene representation with the\nproposed Multimodal Gaussian Splatting. A network composed of 3D graph\nconvolution and transformer is designed to extract spatio-temporal features and\nglobal descriptors from the Gaussian scenes for place recognition. Extensive\nevaluations on three datasets demonstrate that our method can effectively\nleverage complementary strengths of both multi-view cameras and LiDAR,\nachieving SOTA place recognition performance while maintaining solid\ngeneralization ability. Our open-source code will be released at\nhttps://github.com/QiZS-BIT/GSPR.\n","authors":["Zhangshuo Qi","Junyi Ma","Jingyi Xu","Zijie Zhou","Luqi Cheng","Guangming Xiong"],"pdf_url":"https://arxiv.org/pdf/2410.00299v2.pdf","comment":"8 pages, 6 figures"},{"id":"http://arxiv.org/abs/2412.07775v2","updated":"2025-03-06T15:15:58Z","published":"2024-12-10T18:59:58Z","title":"Efficient Diversity-Preserving Diffusion Alignment via Gradient-Informed\n  GFlowNets","summary":"  While one commonly trains large diffusion models by collecting datasets on\ntarget downstream tasks, it is often desired to align and finetune pretrained\ndiffusion models with some reward functions that are either designed by experts\nor learned from small-scale datasets. Existing post-training methods for reward\nfinetuning of diffusion models typically suffer from lack of diversity in\ngenerated samples, lack of prior preservation, and/or slow convergence in\nfinetuning. Inspired by recent successes in generative flow networks\n(GFlowNets), a class of probabilistic models that sample with the unnormalized\ndensity of a reward function, we propose a novel GFlowNet method dubbed\nNabla-GFlowNet (abbreviated as \\methodname), the first GFlowNet method that\nleverages the rich signal in reward gradients, together with an objective\ncalled \\graddb plus its variant \\resgraddb designed for prior-preserving\ndiffusion finetuning. We show that our proposed method achieves fast yet\ndiversity- and prior-preserving finetuning of Stable Diffusion, a large-scale\ntext-conditioned image diffusion model, on different realistic reward\nfunctions.\n","authors":["Zhen Liu","Tim Z. Xiao","Weiyang Liu","Yoshua Bengio","Dinghuai Zhang"],"pdf_url":"https://arxiv.org/pdf/2412.07775v2.pdf","comment":"Technical Report (35 pages, 31 figures), Accepted at ICLR 2025"},{"id":"http://arxiv.org/abs/2503.04522v1","updated":"2025-03-06T15:08:34Z","published":"2025-03-06T15:08:34Z","title":"In-Context Reverse Classification Accuracy: Efficient Estimation of\n  Segmentation Quality without Ground-Truth","summary":"  Assessing the quality of automatic image segmentation is crucial in clinical\npractice, but often very challenging due to the limited availability of ground\ntruth annotations. In this paper, we introduce In-Context Reverse\nClassification Accuracy (In-Context RCA), a novel framework for automatically\nestimating segmentation quality in the absence of ground-truth annotations. By\nleveraging recent in-context learning segmentation models and incorporating\nretrieval-augmentation techniques to select the most relevant reference images,\nour approach enables efficient quality estimation with minimal reference data.\nValidated across diverse medical imaging modalities, our method demonstrates\nrobust performance and computational efficiency, offering a promising solution\nfor automated quality control in clinical workflows, where fast and reliable\nsegmentation assessment is essential. The code is available at\nhttps://github.com/mcosarinsky/In-Context-RCA.\n","authors":["Matias Cosarinsky","Ramiro Billot","Lucas Mansilla","Gabriel Gimenez","Nicolas Gaggin","Guanghui Fu","Enzo Ferrante"],"pdf_url":"https://arxiv.org/pdf/2503.04522v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2502.05874v2","updated":"2025-03-06T15:02:33Z","published":"2025-02-09T12:23:40Z","title":"MMGDreamer: Mixed-Modality Graph for Geometry-Controllable 3D Indoor\n  Scene Generation","summary":"  Controllable 3D scene generation has extensive applications in virtual\nreality and interior design, where the generated scenes should exhibit high\nlevels of realism and controllability in terms of geometry. Scene graphs\nprovide a suitable data representation that facilitates these applications.\nHowever, current graph-based methods for scene generation are constrained to\ntext-based inputs and exhibit insufficient adaptability to flexible user\ninputs, hindering the ability to precisely control object geometry. To address\nthis issue, we propose MMGDreamer, a dual-branch diffusion model for scene\ngeneration that incorporates a novel Mixed-Modality Graph, visual enhancement\nmodule, and relation predictor. The mixed-modality graph allows object nodes to\nintegrate textual and visual modalities, with optional relationships between\nnodes. It enhances adaptability to flexible user inputs and enables meticulous\ncontrol over the geometry of objects in the generated scenes. The visual\nenhancement module enriches the visual fidelity of text-only nodes by\nconstructing visual representations using text embeddings. Furthermore, our\nrelation predictor leverages node representations to infer absent relationships\nbetween nodes, resulting in more coherent scene layouts. Extensive experimental\nresults demonstrate that MMGDreamer exhibits superior control of object\ngeometry, achieving state-of-the-art scene generation performance. Project\npage: https://yangzhifeio.github.io/project/MMGDreamer.\n","authors":["Zhifei Yang","Keyang Lu","Chao Zhang","Jiaxing Qi","Hanqi Jiang","Ruifei Ma","Shenglin Yin","Yifan Xu","Mingzhe Xing","Zhen Xiao","Jieyi Long","Xiangde Liu","Guangyao Zhai"],"pdf_url":"https://arxiv.org/pdf/2502.05874v2.pdf","comment":"Accepted by AAAI 2025 Main Track"},{"id":"http://arxiv.org/abs/2503.04513v1","updated":"2025-03-06T14:59:38Z","published":"2025-03-06T14:59:38Z","title":"A Novel Solution for Drone Photogrammetry with Low-overlap Aerial Images\n  using Monocular Depth Estimation","summary":"  Low-overlap aerial imagery poses significant challenges to traditional\nphotogrammetric methods, which rely heavily on high image overlap to produce\naccurate and complete mapping products. In this study, we propose a novel\nworkflow based on monocular depth estimation to address the limitations of\nconventional techniques. Our method leverages tie points obtained from aerial\ntriangulation to establish a relationship between monocular depth and metric\ndepth, thus transforming the original depth map into a metric depth map,\nenabling the generation of dense depth information and the comprehensive\nreconstruction of the scene. For the experiments, a high-overlap drone dataset\ncontaining 296 images is processed using Metashape to generate depth maps and\nDSMs as ground truth. Subsequently, we create a low-overlap dataset by\nselecting 20 images for experimental evaluation. Results demonstrate that while\nthe recovered depth maps and resulting DSMs achieve meter-level accuracy, they\nprovide significantly better completeness compared to traditional methods,\nparticularly in regions covered by single images. This study showcases the\npotential of monocular depth estimation in low-overlap aerial photogrammetry.\n","authors":["Jiageng Zhong","Qi Zhou","Ming Li","Armin Gruen","Xuan Liao"],"pdf_url":"https://arxiv.org/pdf/2503.04513v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.04504v1","updated":"2025-03-06T14:52:34Z","published":"2025-03-06T14:52:34Z","title":"AnyAnomaly: Zero-Shot Customizable Video Anomaly Detection with LVLM","summary":"  Video anomaly detection (VAD) is crucial for video analysis and surveillance\nin computer vision. However, existing VAD models rely on learned normal\npatterns, which makes them difficult to apply to diverse environments.\nConsequently, users should retrain models or develop separate AI models for new\nenvironments, which requires expertise in machine learning, high-performance\nhardware, and extensive data collection, limiting the practical usability of\nVAD. To address these challenges, this study proposes customizable video\nanomaly detection (C-VAD) technique and the AnyAnomaly model. C-VAD considers\nuser-defined text as an abnormal event and detects frames containing a\nspecified event in a video. We effectively implemented AnyAnomaly using a\ncontext-aware visual question answering without fine-tuning the large vision\nlanguage model. To validate the effectiveness of the proposed model, we\nconstructed C-VAD datasets and demonstrated the superiority of AnyAnomaly.\nFurthermore, our approach showed competitive performance on VAD benchmark\ndatasets, achieving state-of-the-art results on the UBnormal dataset and\noutperforming other methods in generalization across all datasets. Our code is\navailable online at github.com/SkiddieAhn/Paper-AnyAnomaly.\n","authors":["Sunghyun Ahn","Youngwan Jo","Kijung Lee","Sein Kwon","Inpyo Hong","Sanghyun Park"],"pdf_url":"https://arxiv.org/pdf/2503.04504v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2502.01262v2","updated":"2025-03-06T14:50:58Z","published":"2025-02-03T11:36:01Z","title":"FSPGD: Rethinking Black-box Attacks on Semantic Segmentation","summary":"  Transferability, the ability of adversarial examples crafted for one model to\ndeceive other models, is crucial for black-box attacks. Despite advancements in\nattack methods for semantic segmentation, transferability remains limited,\nreducing their effectiveness in real-world applications. To address this, we\nintroduce the Feature Similarity Projected Gradient Descent (FSPGD) attack, a\nnovel black-box approach that enhances both attack performance and\ntransferability. Unlike conventional segmentation attacks that rely on output\npredictions for gradient calculation, FSPGD computes gradients from\nintermediate layer features. Specifically, our method introduces a loss\nfunction that targets local information by comparing features between clean\nimages and adversarial examples, while also disrupting contextual information\nby accounting for spatial relationships between objects. Experiments on Pascal\nVOC 2012 and Cityscapes datasets demonstrate that FSPGD achieves superior\ntransferability and attack performance, establishing a new state-of-the-art\nbenchmark. Code is available at https://github.com/KU-AIVS/FSPGD.\n","authors":["Eun-Sol Park","MiSo Park","Seung Park","Yong-Goo Shin"],"pdf_url":"https://arxiv.org/pdf/2502.01262v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.04501v1","updated":"2025-03-06T14:50:17Z","published":"2025-03-06T14:50:17Z","title":"IMFine: 3D Inpainting via Geometry-guided Multi-view Refinement","summary":"  Current 3D inpainting and object removal methods are largely limited to\nfront-facing scenes, facing substantial challenges when applied to diverse,\n\"unconstrained\" scenes where the camera orientation and trajectory are\nunrestricted. To bridge this gap, we introduce a novel approach that produces\ninpainted 3D scenes with consistent visual quality and coherent underlying\ngeometry across both front-facing and unconstrained scenes. Specifically, we\npropose a robust 3D inpainting pipeline that incorporates geometric priors and\na multi-view refinement network trained via test-time adaptation, building on a\npre-trained image inpainting model. Additionally, we develop a novel inpainting\nmask detection technique to derive targeted inpainting masks from object masks,\nboosting the performance in handling unconstrained scenes. To validate the\nefficacy of our approach, we create a challenging and diverse benchmark that\nspans a wide range of scenes. Comprehensive experiments demonstrate that our\nproposed method substantially outperforms existing state-of-the-art approaches.\n","authors":["Zhihao Shi","Dong Huo","Yuhongze Zhou","Kejia Yin","Yan Min","Juwei Lu","Xinxin Zuo"],"pdf_url":"https://arxiv.org/pdf/2503.04501v1.pdf","comment":"Accepted at CVPR 2025,\n  \\href{https://xinxinzuo2353.github.io/imfine/}{Project Page}"},{"id":"http://arxiv.org/abs/2503.04500v1","updated":"2025-03-06T14:49:28Z","published":"2025-03-06T14:49:28Z","title":"ReynoldsFlow: Exquisite Flow Estimation via Reynolds Transport Theorem","summary":"  Optical flow is a fundamental technique for motion estimation, widely applied\nin video stabilization, interpolation, and object tracking. Recent advancements\nin artificial intelligence (AI) have enabled deep learning models to leverage\noptical flow as an important feature for motion analysis. However, traditional\noptical flow methods rely on restrictive assumptions, such as brightness\nconstancy and slow motion constraints, limiting their effectiveness in complex\nscenes. Deep learning-based approaches require extensive training on large\ndomain-specific datasets, making them computationally demanding. Furthermore,\noptical flow is typically visualized in the HSV color space, which introduces\nnonlinear distortions when converted to RGB and is highly sensitive to noise,\ndegrading motion representation accuracy. These limitations inherently\nconstrain the performance of downstream models, potentially hindering object\ntracking and motion analysis tasks. To address these challenges, we propose\nReynolds flow, a novel training-free flow estimation inspired by the Reynolds\ntransport theorem, offering a principled approach to modeling complex motion\ndynamics. Beyond the conventional HSV-based visualization, denoted\nReynoldsFlow, we introduce an alternative representation, ReynoldsFlow+,\ndesigned to improve flow visualization. We evaluate ReynoldsFlow and\nReynoldsFlow+ across three video-based benchmarks: tiny object detection on\nUAVDB, infrared object detection on Anti-UAV, and pose estimation on GolfDB.\nExperimental results demonstrate that networks trained with ReynoldsFlow+\nachieve state-of-the-art (SOTA) performance, exhibiting improved robustness and\nefficiency across all tasks.\n","authors":["Yu-Hsi Chen","Chin-Tien Wu"],"pdf_url":"https://arxiv.org/pdf/2503.04500v1.pdf","comment":"10 pages, 3 figures, 3 tables"},{"id":"http://arxiv.org/abs/2503.04499v1","updated":"2025-03-06T14:48:25Z","published":"2025-03-06T14:48:25Z","title":"Spatial regularisation for improved accuracy and interpretability in\n  keypoint-based registration","summary":"  Unsupervised registration strategies bypass requirements in ground truth\ntransforms or segmentations by optimising similarity metrics between fixed and\nmoved volumes. Among these methods, a recent subclass of approaches based on\nunsupervised keypoint detection stand out as very promising for\ninterpretability. Specifically, these methods train a network to predict\nfeature maps for fixed and moving images, from which explainable centres of\nmass are computed to obtain point clouds, that are then aligned in closed-form.\nHowever, the features returned by the network often yield spatially diffuse\npatterns that are hard to interpret, thus undermining the purpose of\nkeypoint-based registration. Here, we propose a three-fold loss to regularise\nthe spatial distribution of the features. First, we use the KL divergence to\nmodel features as point spread functions that we interpret as probabilistic\nkeypoints. Then, we sharpen the spatial distributions of these features to\nincrease the precision of the detected landmarks. Finally, we introduce a new\nrepulsive loss across keypoints to encourage spatial diversity. Overall, our\nloss considerably improves the interpretability of the features, which now\ncorrespond to precise and anatomically meaningful landmarks. We demonstrate our\nthree-fold loss in foetal rigid motion tracking and brain MRI affine\nregistration tasks, where it not only outperforms state-of-the-art unsupervised\nstrategies, but also bridges the gap with state-of-the-art supervised methods.\nOur code is available at https://github.com/BenBillot/spatial_regularisation.\n","authors":["Benjamin Billot","Ramya Muthukrishnan","Esra Abaci-Turk","Ellen P. Grant","Nicholas Ayache","Herv Delingette","Polina Golland"],"pdf_url":"https://arxiv.org/pdf/2503.04499v1.pdf","comment":"under review"},{"id":"http://arxiv.org/abs/2503.04496v1","updated":"2025-03-06T14:44:25Z","published":"2025-03-06T14:44:25Z","title":"Learning Object Placement Programs for Indoor Scene Synthesis with\n  Iterative Self Training","summary":"  Data driven and autoregressive indoor scene synthesis systems generate indoor\nscenes automatically by suggesting and then placing objects one at a time.\nEmpirical observations show that current systems tend to produce incomplete\nnext object location distributions. We introduce a system which addresses this\nproblem. We design a Domain Specific Language (DSL) that specifies functional\nconstraints. Programs from our language take as input a partial scene and\nobject to place. Upon execution they predict possible object placements. We\ndesign a generative model which writes these programs automatically. Available\n3D scene datasets do not contain programs to train on, so we build upon\nprevious work in unsupervised program induction to introduce a new program\nbootstrapping algorithm. In order to quantify our empirical observations we\nintroduce a new evaluation procedure which captures how well a system models\nper-object location distributions. We ask human annotators to label all the\npossible places an object can go in a scene and show that our system produces\nper-object location distributions more consistent with human annotators. Our\nsystem also generates indoor scenes of comparable quality to previous systems\nand while previous systems degrade in performance when training data is sparse,\nour system does not degrade to the same degree.\n","authors":["Adrian Chang","Kai Wang","Yuanbo Li","Manolis Savva","Angel X. Chang","Daniel Ritchie"],"pdf_url":"https://arxiv.org/pdf/2503.04496v1.pdf","comment":"21 pages, 20 figures Subjects: Graphics (cs.GR), Computer Vision and\n  Pattern Recognition (cs.CV), Machine Learning (cs.LG)"},{"id":"http://arxiv.org/abs/2412.04842v3","updated":"2025-03-06T14:40:15Z","published":"2024-12-06T08:27:53Z","title":"UniMLVG: Unified Framework for Multi-view Long Video Generation with\n  Comprehensive Control Capabilities for Autonomous Driving","summary":"  The creation of diverse and realistic driving scenarios has become essential\nto enhance perception and planning capabilities of the autonomous driving\nsystem. However, generating long-duration, surround-view consistent driving\nvideos remains a significant challenge. To address this, we present UniMLVG, a\nunified framework designed to generate extended street multi-perspective videos\nunder precise control. By integrating single- and multi-view driving videos\ninto the training data, our approach updates a DiT-based diffusion model\nequipped with cross-frame and cross-view modules across three stages with multi\ntraining objectives, substantially boosting the diversity and quality of\ngenerated visual content. Importantly, we propose an innovative explicit\nviewpoint modeling approach for multi-view video generation to effectively\nimprove motion transition consistency. Capable of handling various input\nreference formats (e.g., text, images, or video), our UniMLVG generates\nhigh-quality multi-view videos according to the corresponding condition\nconstraints such as 3D bounding boxes or frame-level text descriptions.\nCompared to the best models with similar capabilities, our framework achieves\nimprovements of 48.2% in FID and 35.2% in FVD.\n","authors":["Rui Chen","Zehuan Wu","Yichen Liu","Yuxin Guo","Jingcheng Ni","Haifeng Xia","Siyu Xia"],"pdf_url":"https://arxiv.org/pdf/2412.04842v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.03222v2","updated":"2025-03-06T14:32:49Z","published":"2025-03-05T06:32:49Z","title":"Mocap-2-to-3: Lifting 2D Diffusion-Based Pretrained Models for 3D Motion\n  Capture","summary":"  Recovering absolute poses in the world coordinate system from monocular views\npresents significant challenges. Two primary issues arise in this context.\nFirstly, existing methods rely on 3D motion data for training, which requires\ncollection in limited environments. Acquiring such 3D labels for new actions in\na timely manner is impractical, severely restricting the model's generalization\ncapabilities. In contrast, 2D poses are far more accessible and easier to\nobtain. Secondly, estimating a person's absolute position in metric space from\na single viewpoint is inherently more complex. To address these challenges, we\nintroduce Mocap-2-to-3, a novel framework that decomposes intricate 3D motions\ninto 2D poses, leveraging 2D data to enhance 3D motion reconstruction in\ndiverse scenarios and accurately predict absolute positions in the world\ncoordinate system. We initially pretrain a single-view diffusion model with\nextensive 2D data, followed by fine-tuning a multi-view diffusion model for\nview consistency using publicly available 3D data. This strategy facilitates\nthe effective use of large-scale 2D data. Additionally, we propose an\ninnovative human motion representation that decouples local actions from global\nmovements and encodes geometric priors of the ground, ensuring the generative\nmodel learns accurate motion priors from 2D data. During inference, this allows\nfor the gradual recovery of global movements, resulting in more plausible\npositioning. We evaluate our model's performance on real-world datasets,\ndemonstrating superior accuracy in motion and absolute human positioning\ncompared to state-of-the-art methods, along with enhanced generalization and\nscalability. Our code will be made publicly available.\n","authors":["Zhumei Wang","Zechen Hu","Ruoxi Guo","Huaijin Pi","Ziyong Feng","Sida Peng","Xiaowei Zhou"],"pdf_url":"https://arxiv.org/pdf/2503.03222v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.04478v1","updated":"2025-03-06T14:28:17Z","published":"2025-03-06T14:28:17Z","title":"Semantic Alignment of Unimodal Medical Text and Vision Representations","summary":"  General-purpose AI models, particularly those designed for text and vision,\ndemonstrate impressive versatility across a wide range of deep-learning tasks.\nHowever, they often underperform in specialised domains like medical imaging,\nwhere domain-specific solutions or alternative knowledge transfer approaches\nare typically required. Recent studies have noted that general-purpose models\ncan exhibit similar latent spaces when processing semantically related data,\nalthough this alignment does not occur naturally. Building on this insight, it\nhas been shown that applying a simple transformation - at most affine -\nestimated from a subset of semantically corresponding samples, known as\nanchors, enables model stitching across diverse training paradigms,\narchitectures, and modalities. In this paper, we explore how semantic alignment\n- estimating transformations between anchors - can bridge general-purpose AI\nwith specialised medical knowledge. Using multiple public chest X-ray datasets,\nwe demonstrate that model stitching across model architectures allows general\nmodels to integrate domain-specific knowledge without additional training,\nleading to improved performance on medical tasks. Furthermore, we introduce a\nnovel zero-shot classification approach for unimodal vision encoders that\nleverages semantic alignment across modalities. Our results show that our\nmethod not only outperforms general multimodal models but also approaches the\nperformance levels of fully trained, medical-specific multimodal solutions\n","authors":["Maxime Di Folco","Emily Chan","Marta Hasny","Cosmin I. Bercea","Julia A. Schnabel"],"pdf_url":"https://arxiv.org/pdf/2503.04478v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2502.13524v4","updated":"2025-03-06T14:27:12Z","published":"2025-02-19T08:21:59Z","title":"MobileViM: A Light-weight and Dimension-independent Vision Mamba for 3D\n  Medical Image Analysis","summary":"  Efficient evaluation of three-dimensional (3D) medical images is crucial for\ndiagnostic and therapeutic practices in healthcare. Recent years have seen a\nsubstantial uptake in applying deep learning and computer vision to analyse and\ninterpret medical images. Traditional approaches, such as convolutional neural\nnetworks (CNNs) and vision transformers (ViTs), face significant computational\nchallenges, prompting the need for architectural advancements. Recent efforts\nhave led to the introduction of novel architectures like the ``Mamba'' model as\nalternative solutions to traditional CNNs or ViTs. The Mamba model excels in\nthe linear processing of one-dimensional data with low computational demands.\nHowever, Mamba's potential for 3D medical image analysis remains underexplored\nand could face significant computational challenges as the dimension increases.\nThis manuscript presents MobileViM, a streamlined architecture for efficient\nsegmentation of 3D medical images. In the MobileViM network, we invent a new\ndimension-independent mechanism and a dual-direction traversing approach to\nincorporate with a vision-Mamba-based framework. MobileViM also features a\ncross-scale bridging technique to improve efficiency and accuracy across\nvarious medical imaging modalities. With these enhancements, MobileViM achieves\nsegmentation speeds exceeding 90 frames per second (FPS) on a single graphics\nprocessing unit (i.e., NVIDIA RTX 4090). This performance is over 24 FPS faster\nthan the state-of-the-art deep learning models for processing 3D images with\nthe same computational resources. In addition, experimental evaluations\ndemonstrate that MobileViM delivers superior performance, with Dice similarity\nscores reaching 92.72%, 86.69%, 80.46%, and 77.43% for PENGWIN, BraTS2024,\nATLAS, and Toothfairy2 datasets, respectively, which significantly surpasses\nexisting models.\n","authors":["Wei Dai","Jun Liu"],"pdf_url":"https://arxiv.org/pdf/2502.13524v4.pdf","comment":"The corresponding author disagrees with the manuscript submitted to\n  arXiv"},{"id":"http://arxiv.org/abs/2503.04475v1","updated":"2025-03-06T14:24:22Z","published":"2025-03-06T14:24:22Z","title":"ForestLPR: LiDAR Place Recognition in Forests Attentioning Multiple BEV\n  Density Images","summary":"  Place recognition is essential to maintain global consistency in large-scale\nlocalization systems. While research in urban environments has progressed\nsignificantly using LiDARs or cameras, applications in natural forest-like\nenvironments remain largely under-explored. Furthermore, forests present\nparticular challenges due to high self-similarity and substantial variations in\nvegetation growth over time. In this work, we propose a robust LiDAR-based\nplace recognition method for natural forests, ForestLPR. We hypothesize that a\nset of cross-sectional images of the forest's geometry at different heights\ncontains the information needed to recognize revisiting a place. The\ncross-sectional images are represented by \\ac{bev} density images of horizontal\nslices of the point cloud at different heights. Our approach utilizes a visual\ntransformer as the shared backbone to produce sets of local descriptors and\nintroduces a multi-BEV interaction module to attend to information at different\nheights adaptively. It is followed by an aggregation layer that produces a\nrotation-invariant place descriptor. We evaluated the efficacy of our method\nextensively on real-world data from public benchmarks as well as robotic\ndatasets and compared it against the state-of-the-art (SOTA) methods. The\nresults indicate that ForestLPR has consistently good performance on all\nevaluations and achieves an average increase of 7.38\\% and 9.11\\% on Recall@1\nover the closest competitor on intra-sequence loop closure detection and\ninter-sequence re-localization, respectively, validating our hypothesis\n","authors":["Yanqing Shen","Turcan Tuna","Marco Hutter","Cesar Cadena","Nanning Zheng"],"pdf_url":"https://arxiv.org/pdf/2503.04475v1.pdf","comment":"accepted by CVPR2025"},{"id":"http://arxiv.org/abs/2503.04470v1","updated":"2025-03-06T14:21:43Z","published":"2025-03-06T14:21:43Z","title":"Gate-Shift-Pose: Enhancing Action Recognition in Sports with Skeleton\n  Information","summary":"  This paper introduces Gate-Shift-Pose, an enhanced version of Gate-Shift-Fuse\nnetworks, designed for athlete fall classification in figure skating by\nintegrating skeleton pose data alongside RGB frames. We evaluate two fusion\nstrategies: early-fusion, which combines RGB frames with Gaussian heatmaps of\npose keypoints at the input stage, and late-fusion, which employs a\nmulti-stream architecture with attention mechanisms to combine RGB and pose\nfeatures. Experiments on the FR-FS dataset demonstrate that Gate-Shift-Pose\nsignificantly outperforms the RGB-only baseline, improving accuracy by up to\n40% with ResNet18 and 20% with ResNet50. Early-fusion achieves the highest\naccuracy (98.08%) with ResNet50, leveraging the model's capacity for effective\nmultimodal integration, while late-fusion is better suited for lighter\nbackbones like ResNet18. These results highlight the potential of multimodal\narchitectures for sports action recognition and the critical role of skeleton\npose information in capturing complex motion patterns.\n","authors":["Edoardo Bianchi","Oswald Lanz"],"pdf_url":"https://arxiv.org/pdf/2503.04470v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.04459v1","updated":"2025-03-06T14:11:46Z","published":"2025-03-06T14:11:46Z","title":"Question-Aware Gaussian Experts for Audio-Visual Question Answering","summary":"  Audio-Visual Question Answering (AVQA) requires not only question-based\nmultimodal reasoning but also precise temporal grounding to capture subtle\ndynamics for accurate prediction. However, existing methods mainly use question\ninformation implicitly, limiting focus on question-specific details.\nFurthermore, most studies rely on uniform frame sampling, which can miss key\nquestion-relevant frames. Although recent Top-K frame selection methods aim to\naddress this, their discrete nature still overlooks fine-grained temporal\ndetails. This paper proposes \\textbf{QA-TIGER}, a novel framework that\nexplicitly incorporates question information and models continuous temporal\ndynamics. Our key idea is to use Gaussian-based modeling to adaptively focus on\nboth consecutive and non-consecutive frames based on the question, while\nexplicitly injecting question information and applying progressive refinement.\nWe leverage a Mixture of Experts (MoE) to flexibly implement multiple Gaussian\nmodels, activating temporal experts specifically tailored to the question.\nExtensive experiments on multiple AVQA benchmarks show that QA-TIGER\nconsistently achieves state-of-the-art performance. Code is available at\nhttps://github.com/AIM-SKKU/QA-TIGER\n","authors":["Hongyeob Kim","Inyoung Jung","Dayoon Suh","Youjia Zhang","Sangmin Lee","Sungeun Hong"],"pdf_url":"https://arxiv.org/pdf/2503.04459v1.pdf","comment":"CVPR 2025. Project page at https://aim-skku.github.io/QA-TIGER/"},{"id":"http://arxiv.org/abs/2503.04457v1","updated":"2025-03-06T14:11:00Z","published":"2025-03-06T14:11:00Z","title":"TPC: Cross-Temporal Prediction Connection for Vision-Language Model\n  Hallucination Reduction","summary":"  Vision-language models (VLMs) have achieved remarkable advancements,\ncapitalizing on the impressive capabilities of large language models (LLMs)\nacross diverse tasks. Despite this, a critical challenge known as hallucination\noccurs when models overconfidently describe objects or attributes absent from\nthe image, a problem exacerbated by the tendency of VLMs to rely on linguistic\npriors. This limitation reduces model reliability in high-stakes applications.\nIn this work, we have observed the characteristic of logits' continuity\nconsistency enhancement and introduced a straightforward and efficient method,\nCross-Temporal Prediction Connection (TPC), designed to enhance the semantic\nconsistency of logits by connecting them temporally across timesteps. TPC\namplifies information flow and improves coherence, effectively reducing\nhallucination. Extensive experiments show that TPC surpasses existing\nrepresentatives, delivering superior performance in both accuracy and\nefficiency while maintaining robustness in open-ended text generation tasks.\n","authors":["Chao Wang","Weiwei Fu","Yang Zhou"],"pdf_url":"https://arxiv.org/pdf/2503.04457v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.04452v1","updated":"2025-03-06T14:06:35Z","published":"2025-03-06T14:06:35Z","title":"A lightweight model FDM-YOLO for small target improvement based on\n  YOLOv8","summary":"  Small targets are particularly difficult to detect due to their low pixel\ncount, complex backgrounds, and varying shooting angles, which make it hard for\nmodels to extract effective features. While some large-scale models offer high\naccuracy, their long inference times make them unsuitable for real-time\ndeployment on edge devices. On the other hand, models designed for low\ncomputational power often suffer from poor detection accuracy. This paper\nfocuses on small target detection and explores methods for object detection\nunder low computational constraints. Building on the YOLOv8 model, we propose a\nnew network architecture called FDM-YOLO. Our research includes the following\nkey contributions: We introduce FDM-YOLO by analyzing the output of the YOLOv8\ndetection head. We add a highresolution layer and remove the large target\ndetection layer to better handle small targets. Based on PConv, we propose a\nlightweight network structure called Fast-C2f, which is integrated into the PAN\nmodule of the model. To mitigate the accuracy loss caused by model\nlightweighting, we employ dynamic upsampling (Dysample) and a lightweight EMA\nattention mechanism.The FDM-YOLO model was validated on the Visdrone dataset,\nachieving a 38% reduction in parameter count and improving the Map0.5 score\nfrom 38.4% to 42.5%, all while maintaining nearly the same inference speed.\nThis demonstrates the effectiveness of our approach in balancing accuracy and\nefficiency for edge device deployment.\n","authors":["Xuerui Zhang"],"pdf_url":"https://arxiv.org/pdf/2503.04452v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2312.04484v3","updated":"2025-03-06T14:06:24Z","published":"2023-12-07T17:59:53Z","title":"FRNet: Frustum-Range Networks for Scalable LiDAR Segmentation","summary":"  LiDAR segmentation has become a crucial component of advanced autonomous\ndriving systems. Recent range-view LiDAR segmentation approaches show promise\nfor real-time processing. However, they inevitably suffer from corrupted\ncontextual information and rely heavily on post-processing techniques for\nprediction refinement. In this work, we propose FRNet, a simple yet powerful\nmethod aimed at restoring the contextual information of range image pixels\nusing corresponding frustum LiDAR points. First, a frustum feature encoder\nmodule is used to extract per-point features within the frustum region, which\npreserves scene consistency and is critical for point-level predictions. Next,\na frustum-point fusion module is introduced to update per-point features\nhierarchically, enabling each point to extract more surrounding information\nthrough the frustum features. Finally, a head fusion module is used to fuse\nfeatures at different levels for final semantic predictions. Extensive\nexperiments conducted on four popular LiDAR segmentation benchmarks under\nvarious task setups demonstrate the superiority of FRNet. Notably, FRNet\nachieves 73.3% and 82.5% mIoU scores on the testing sets of SemanticKITTI and\nnuScenes. While achieving competitive performance, FRNet operates 5 times\nfaster than state-of-the-art approaches. Such high efficiency opens up new\npossibilities for more scalable LiDAR segmentation. The code has been made\npublicly available at https://github.com/Xiangxu-0103/FRNet.\n","authors":["Xiang Xu","Lingdong Kong","Hui Shuai","Qingshan Liu"],"pdf_url":"https://arxiv.org/pdf/2312.04484v3.pdf","comment":"TIP 2025; 18 pages, 11 figures, 14 tables; Code at\n  https://github.com/Xiangxu-0103/FRNet"},{"id":"http://arxiv.org/abs/2407.13304v3","updated":"2025-03-06T14:06:01Z","published":"2024-07-18T09:07:23Z","title":"A Dataset and Benchmark for Shape Completion of Fruits for Agricultural\n  Robotics","summary":"  As the world population is expected to reach 10 billion by 2050, our\nagricultural production system needs to double its productivity despite a\ndecline of human workforce in the agricultural sector. Autonomous robotic\nsystems are one promising pathway to increase productivity by taking over\nlabor-intensive manual tasks like fruit picking. To be effective, such systems\nneed to monitor and interact with plants and fruits precisely, which is\nchallenging due to the cluttered nature of agricultural environments causing,\nfor example, strong occlusions. Thus, being able to estimate the complete 3D\nshapes of objects in presence of occlusions is crucial for automating\noperations such as fruit harvesting. In this paper, we propose the first\npublicly available 3D shape completion dataset for agricultural vision systems.\nWe provide an RGB-D dataset for estimating the 3D shape of fruits.\nSpecifically, our dataset contains RGB-D frames of single sweet peppers in lab\nconditions but also in a commercial greenhouse. For each fruit, we additionally\ncollected high-precision point clouds that we use as ground truth. For\nacquiring the ground truth shape, we developed a measuring process that allows\nus to record data of real sweet pepper plants, both in the lab and in the\ngreenhouse with high precision, and determine the shape of the sensed fruits.\nWe release our dataset, consisting of almost 7,000 RGB-D frames belonging to\nmore than 100 different fruits. We provide segmented RGB-D frames, with camera\nintrinsics to easily obtain colored point clouds, together with the\ncorresponding high-precision, occlusion-free point clouds obtained with a\nhigh-precision laser scanner. We additionally enable evaluation of shape\ncompletion approaches on a hidden test set through a public challenge on a\nbenchmark server.\n","authors":["Federico Magistri","Thomas Lbe","Elias Marks","Sumanth Nagulavancha","Yue Pan","Claus Smitt","Lasse Klingbeil","Michael Halstead","Heiner Kuhlmann","Chris McCool","Jens Behley","Cyrill Stachniss"],"pdf_url":"https://arxiv.org/pdf/2407.13304v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.04444v1","updated":"2025-03-06T14:00:59Z","published":"2025-03-06T14:00:59Z","title":"ToFu: Visual Tokens Reduction via Fusion for Multi-modal, Multi-patch,\n  Multi-image Task","summary":"  Large Multimodal Models (LMMs) are powerful tools that are capable of\nreasoning and understanding multimodal information beyond text and language.\nDespite their entrenched impact, the development of LMMs is hindered by the\nhigher computational requirements compared to their unimodal counterparts. One\nof the main causes of this is the large amount of tokens needed to encode the\nvisual input, which is especially evident for multi-image multimodal tasks.\nRecent approaches to reduce visual tokens depend on the visual encoder\narchitecture, require fine-tuning the LLM to maintain the performance, and only\nconsider single-image scenarios. To address these limitations, we propose ToFu,\na visual encoder-agnostic, training-free Token Fusion strategy that combines\nredundant visual tokens of LMMs for high-resolution, multi-image, tasks. The\ncore intuition behind our method is straightforward yet effective: preserve\ndistinctive tokens while combining similar ones. We achieve this by\nsequentially examining visual tokens and deciding whether to merge them with\nothers or keep them as separate entities. We validate our approach on the\nwell-established LLaVA-Interleave Bench, which covers challenging multi-image\ntasks. In addition, we push to the extreme our method by testing it on a\nnewly-created benchmark, ComPairs, focused on multi-image comparisons where a\nlarger amount of images and visual tokens are inputted to the LMMs. Our\nextensive analysis, considering several LMM architectures, demonstrates the\nbenefits of our approach both in terms of efficiency and performance gain.\n","authors":["Vittorio Pippi","Matthieu Guillaumin","Silvia Cascianelli","Rita Cucchiara","Maximilian Jaritz","Loris Bazzani"],"pdf_url":"https://arxiv.org/pdf/2503.04444v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.04441v1","updated":"2025-03-06T13:56:48Z","published":"2025-03-06T13:56:48Z","title":"EvidMTL: Evidential Multi-Task Learning for Uncertainty-Aware Semantic\n  Surface Mapping from Monocular RGB Images","summary":"  For scene understanding in unstructured environments, an accurate and\nuncertainty-aware metric-semantic mapping is required to enable informed action\nselection by autonomous systems.Existing mapping methods often suffer from\noverconfident semantic predictions, and sparse and noisy depth sensing, leading\nto inconsistent map representations. In this paper, we therefore introduce\nEvidMTL, a multi-task learning framework that uses evidential heads for depth\nestimation and semantic segmentation, enabling uncertainty-aware inference from\nmonocular RGB images. To enable uncertainty-calibrated evidential multi-task\nlearning, we propose a novel evidential depth loss function that jointly\noptimizes the belief strength of the depth prediction in conjunction with\nevidential segmentation loss. Building on this, we present EvidKimera, an\nuncertainty-aware semantic surface mapping framework, which uses evidential\ndepth and semantics prediction for improved 3D metric-semantic consistency. We\ntrain and evaluate EvidMTL on the NYUDepthV2 and assess its zero-shot\nperformance on ScanNetV2, demonstrating superior uncertainty estimation\ncompared to conventional approaches while maintaining comparable depth\nestimation and semantic segmentation. In zero-shot mapping tests on ScanNetV2,\nEvidKimera outperforms Kimera in semantic surface mapping accuracy and\nconsistency, highlighting the benefits of uncertainty-aware mapping and\nunderscoring its potential for real-world robotic applications.\n","authors":["Rohit Menon","Nils Dengler","Sicong Pan","Gokul Krishna Chenchani","Maren Bennewitz"],"pdf_url":"https://arxiv.org/pdf/2503.04441v1.pdf","comment":"Submitted to IROS 2025 Conference"},{"id":"http://arxiv.org/abs/2503.03272v2","updated":"2025-03-06T13:49:46Z","published":"2025-03-05T08:52:55Z","title":"Towards Effective and Sparse Adversarial Attack on Spiking Neural\n  Networks via Breaking Invisible Surrogate Gradients","summary":"  Spiking neural networks (SNNs) have shown their competence in handling\nspatial-temporal event-based data with low energy consumption. Similar to\nconventional artificial neural networks (ANNs), SNNs are also vulnerable to\ngradient-based adversarial attacks, wherein gradients are calculated by\nspatial-temporal back-propagation (STBP) and surrogate gradients (SGs).\nHowever, the SGs may be invisible for an inference-only model as they do not\ninfluence the inference results, and current gradient-based attacks are\nineffective for binary dynamic images captured by the dynamic vision sensor\n(DVS). While some approaches addressed the issue of invisible SGs through\nuniversal SGs, their SGs lack a correlation with the victim model, resulting in\nsub-optimal performance. Moreover, the imperceptibility of existing SNN-based\nbinary attacks is still insufficient. In this paper, we introduce an innovative\npotential-dependent surrogate gradient (PDSG) method to establish a robust\nconnection between the SG and the model, thereby enhancing the adaptability of\nadversarial attacks across various models with invisible SGs. Additionally, we\npropose the sparse dynamic attack (SDA) to effectively attack binary dynamic\nimages. Utilizing a generation-reduction paradigm, SDA can fully optimize the\nsparsity of adversarial perturbations. Experimental results demonstrate that\nour PDSG and SDA outperform state-of-the-art SNN-based attacks across various\nmodels and datasets. Specifically, our PDSG achieves 100% attack success rate\non ImageNet, and our SDA obtains 82% attack success rate by modifying only\n0.24% of the pixels on CIFAR10DVS. The code is available at\nhttps://github.com/ryime/PDSG-SDA .\n","authors":["Li Lun","Kunyu Feng","Qinglong Ni","Ling Liang","Yuan Wang","Ying Li","Dunshan Yu","Xiaoxin Cui"],"pdf_url":"https://arxiv.org/pdf/2503.03272v2.pdf","comment":"Accepted by CVPR 2025"},{"id":"http://arxiv.org/abs/2503.04420v1","updated":"2025-03-06T13:23:03Z","published":"2025-03-06T13:23:03Z","title":"PointsToWood: A deep learning framework for complete canopy leaf-wood\n  segmentation of TLS data across diverse European forests","summary":"  Point clouds from Terrestrial Laser Scanning (TLS) are an increasingly\npopular source of data for studying plant structure and function but typically\nrequire extensive manual processing to extract ecologically important\ninformation. One key task is the accurate semantic segmentation of different\nplant material within point clouds, particularly wood and leaves, which is\nrequired to understand plant productivity, architecture and physiology.\nExisting automated semantic segmentation methods are primarily developed for\nsingle ecosystem types, and whilst they show good accuracy for biomass\nassessment from the trunk and large branches, often perform less well within\nthe crown. In this study, we demonstrate a new framework that uses a deep\nlearning architecture newly developed from PointNet and pointNEXT for\nprocessing 3D point clouds to provide a reliable semantic segmentation of wood\nand leaf in TLS point clouds from the tree base to branch tips, trained on data\nfrom diverse mature European forests. Our model uses meticulously labelled data\ncombined with voxel-based sampling, neighbourhood rescaling, and a novel gated\nreflectance integration module embedded throughout the feature extraction\nlayers. We evaluate its performance across open datasets from boreal,\ntemperate, Mediterranean and tropical regions, encompassing diverse ecosystem\ntypes and sensor characteristics. Our results show consistent outperformance\nagainst the most widely used PointNet based approach for leaf/wood segmentation\non our high-density TLS dataset collected across diverse mixed forest plots\nacross all major biomes in Europe. We also find consistently strong performance\ntested on others open data from China, Eastern Cameroon, Germany and Finland,\ncollected using both time-of-flight and phase-shift sensors, showcasing the\ntransferability of our model to a wide range of ecosystems and sensors.\n","authors":["Harry J. F. Owen","Matthew J. A. Allen","Stuart W. D. Grieve","Phill Wilkes","Emily R. Lines"],"pdf_url":"https://arxiv.org/pdf/2503.04420v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2409.08388v2","updated":"2025-03-06T13:19:58Z","published":"2024-09-12T20:34:34Z","title":"Continual Learning in 3D Point Clouds: Employing Spectral Techniques for\n  Exemplar Selection","summary":"  We introduce a novel framework for Continual Learning in 3D object\nclassification. Our approach, CL3D, is based on the selection of prototypes\nfrom each class using spectral clustering. For non-Euclidean data such as point\nclouds, spectral clustering can be employed as long as one can define a\ndistance measure between pairs of samples. Choosing the appropriate distance\nmeasure enables us to leverage 3D geometric characteristics to identify\nrepresentative prototypes for each class. We explore the effectiveness of\nclustering in the input space (3D points), local feature space\n(1024-dimensional points), and global feature space. We conduct experiments on\nthe ModelNet40, ShapeNet, and ScanNet datasets, achieving state-of-the-art\naccuracy exclusively through the use of input space features. By leveraging the\ncombined input, local, and global features, we have improved the\nstate-of-the-art on ModelNet and ShapeNet, utilizing nearly half the memory\nused by competing approaches. For the challenging ScanNet dataset, our method\nenhances accuracy by 4.1% while consuming just 28% of the memory used by our\ncompetitors, demonstrating the scalability of our approach.\n","authors":["Hossein Resani","Behrooz Nasihatkon","Mohammadreza Alimoradi Jazi"],"pdf_url":"https://arxiv.org/pdf/2409.08388v2.pdf","comment":"Accepted to WACV 2025, Tucson, Arizona, USA"},{"id":"http://arxiv.org/abs/2503.04416v1","updated":"2025-03-06T13:18:37Z","published":"2025-03-06T13:18:37Z","title":"Learning Transformer-based World Models with Contrastive Predictive\n  Coding","summary":"  The DreamerV3 algorithm recently obtained remarkable performance across\ndiverse environment domains by learning an accurate world model based on\nRecurrent Neural Networks (RNNs). Following the success of model-based\nreinforcement learning algorithms and the rapid adoption of the Transformer\narchitecture for its superior training efficiency and favorable scaling\nproperties, recent works such as STORM have proposed replacing RNN-based world\nmodels with Transformer-based world models using masked self-attention.\nHowever, despite the improved training efficiency of these methods, their\nimpact on performance remains limited compared to the Dreamer algorithm,\nstruggling to learn competitive Transformer-based world models. In this work,\nwe show that the next state prediction objective adopted in previous approaches\nis insufficient to fully exploit the representation capabilities of\nTransformers. We propose to extend world model predictions to longer time\nhorizons by introducing TWISTER (Transformer-based World model wIth contraSTivE\nRepresentations), a world model using action-conditioned Contrastive Predictive\nCoding to learn high-level temporal feature representations and improve the\nagent performance. TWISTER achieves a human-normalized mean score of 162% on\nthe Atari 100k benchmark, setting a new record among state-of-the-art methods\nthat do not employ look-ahead search.\n","authors":["Maxime Burchi","Radu Timofte"],"pdf_url":"https://arxiv.org/pdf/2503.04416v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2405.03420v2","updated":"2025-03-06T12:52:29Z","published":"2024-05-06T12:40:15Z","title":"Implantable Adaptive Cells: A Novel Enhancement for Pre-Trained U-Nets\n  in Medical Image Segmentation","summary":"  This paper introduces a novel approach to enhance the performance of\npre-trained neural networks in medical image segmentation using gradient-based\nNeural Architecture Search (NAS) methods. We present the concept of Implantable\nAdaptive Cell (IAC), small modules identified through Partially-Connected DARTS\nbased approach, designed to be injected into the skip connections of an\nexisting and already trained U-shaped model. Unlike traditional NAS methods,\nour approach refines existing architectures without full retraining.\nExperiments on four medical datasets with MRI and CT images show consistent\naccuracy improvements on various U-Net configurations, with segmentation\naccuracy gain by approximately 5 percentage points across all validation\ndatasets, with improvements reaching up to 11\\%pt in the best-performing cases.\nThe findings of this study not only offer a cost-effective alternative to the\ncomplete overhaul of complex models for performance upgrades but also indicate\nthe potential applicability of our method to other architectures and problem\ndomains.\n","authors":["Emil Benedykciuk","Marcin Denkowski","Grzegorz Wjcik"],"pdf_url":"https://arxiv.org/pdf/2405.03420v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2502.20742v2","updated":"2025-03-06T12:50:44Z","published":"2025-02-28T05:47:34Z","title":"Structured Preference Optimization for Vision-Language Long-Horizon Task\n  Planning","summary":"  Existing methods for vision-language task planning excel in short-horizon\ntasks but often fall short in complex, long-horizon planning within dynamic\nenvironments. These challenges primarily arise from the difficulty of\neffectively training models to produce high-quality reasoning processes for\nlong-horizon tasks. To address this, we propose Structured Preference\nOptimization (SPO), which aims to enhance reasoning and action selection in\nlong-horizon task planning through structured preference evaluation and\noptimized training strategies. Specifically, SPO introduces: 1)\nPreference-Based Scoring and Optimization, which systematically evaluates\nreasoning chains based on task relevance, visual grounding, and historical\nconsistency; and 2) Curriculum-Guided Training, where the model progressively\nadapts from simple to complex tasks, improving its generalization ability in\nlong-horizon scenarios and enhancing reasoning robustness. To advance research\nin vision-language long-horizon task planning, we introduce ExtendaBench, a\ncomprehensive benchmark covering 1,509 tasks across VirtualHome and Habitat\n2.0, categorized into ultra-short, short, medium, and long tasks. Experimental\nresults demonstrate that SPO significantly improves reasoning quality and final\ndecision accuracy, outperforming prior methods on long-horizon tasks and\nunderscoring the effectiveness of preference-driven optimization in\nvision-language task planning. Specifically, SPO achieves a +5.98% GCR and\n+4.68% SR improvement in VirtualHome and a +3.30% GCR and +2.11% SR improvement\nin Habitat over the best-performing baselines.\n","authors":["Xiwen Liang","Min Lin","Weiqi Ruan","Rongtao Xu","Yuecheng Liu","Jiaqi Chen","Bingqian Lin","Yuzheng Zhuang","Xiaodan Liang"],"pdf_url":"https://arxiv.org/pdf/2502.20742v2.pdf","comment":"18 pages"},{"id":"http://arxiv.org/abs/2503.03285v2","updated":"2025-03-06T12:42:37Z","published":"2025-03-05T09:12:16Z","title":"Enhancing Vietnamese VQA through Curriculum Learning on Raw and\n  Augmented Text Representations","summary":"  Visual Question Answering (VQA) is a multimodal task requiring reasoning\nacross textual and visual inputs, which becomes particularly challenging in\nlow-resource languages like Vietnamese due to linguistic variability and the\nlack of high-quality datasets. Traditional methods often rely heavily on\nextensive annotated datasets, computationally expensive pipelines, and large\npre-trained models, specifically in the domain of Vietnamese VQA, limiting\ntheir applicability in such scenarios. To address these limitations, we propose\na training framework that combines a paraphrase-based feature augmentation\nmodule with a dynamic curriculum learning strategy. Explicitly, augmented\nsamples are considered \"easy\" while raw samples are regarded as \"hard\". The\nframework then utilizes a mechanism that dynamically adjusts the ratio of easy\nto hard samples during training, progressively modifying the same dataset to\nincrease its difficulty level. By enabling gradual adaptation to task\ncomplexity, this approach helps the Vietnamese VQA model generalize well, thus\nimproving overall performance. Experimental results show consistent\nimprovements on the OpenViVQA dataset and mixed outcomes on the ViVQA dataset,\nhighlighting both the potential and challenges of our approach in advancing VQA\nfor Vietnamese language.\n","authors":["Khoi Anh Nguyen","Linh Yen Vu","Thang Dinh Duong","Thuan Nguyen Duong","Huy Thanh Nguyen","Vinh Quang Dinh"],"pdf_url":"https://arxiv.org/pdf/2503.03285v2.pdf","comment":"10 pages, 3 figures, AAAI-25 Workshop on Document Understanding and\n  Intelligence"},{"id":"http://arxiv.org/abs/2503.04385v1","updated":"2025-03-06T12:36:35Z","published":"2025-03-06T12:36:35Z","title":"Scale-Invariant Adversarial Attack against Arbitrary-scale\n  Super-resolution","summary":"  The advent of local continuous image function (LIIF) has garnered significant\nattention for arbitrary-scale super-resolution (SR) techniques. However, while\nthe vulnerabilities of fixed-scale SR have been assessed, the robustness of\ncontinuous representation-based arbitrary-scale SR against adversarial attacks\nremains an area warranting further exploration. The elaborately designed\nadversarial attacks for fixed-scale SR are scale-dependent, which will cause\ntime-consuming and memory-consuming problems when applied to arbitrary-scale\nSR. To address this concern, we propose a simple yet effective\n``scale-invariant'' SR adversarial attack method with good transferability,\ntermed SIAGT. Specifically, we propose to construct resource-saving attacks by\nexploiting finite discrete points of continuous representation. In addition, we\nformulate a coordinate-dependent loss to enhance the cross-model\ntransferability of the attack. The attack can significantly deteriorate the SR\nimages while introducing imperceptible distortion to the targeted\nlow-resolution (LR) images. Experiments carried out on three popular LIIF-based\nSR approaches and four classical SR datasets show remarkable attack performance\nand transferability of SIAGT.\n","authors":["Yihao Huang","Xin Luo","Qing Guo","Felix Juefei-Xu","Xiaojun Jia","Weikai Miao","Geguang Pu","Yang Liu"],"pdf_url":"https://arxiv.org/pdf/2503.04385v1.pdf","comment":"15 pages, accepted by TIFS 2025"},{"id":"http://arxiv.org/abs/2503.04376v1","updated":"2025-03-06T12:27:58Z","published":"2025-03-06T12:27:58Z","title":"MIDAS: Modeling Ground-Truth Distributions with Dark Knowledge for\n  Domain Generalized Stereo Matching","summary":"  Despite the significant advances in domain generalized stereo matching,\nexisting methods still exhibit domain-specific preferences when transferring\nfrom synthetic to real domains, hindering their practical applications in\ncomplex and diverse scenarios. The probability distributions predicted by the\nstereo network naturally encode rich similarity and uncertainty information.\nInspired by this observation, we propose to extract these two types of dark\nknowledge from the pre-trained network to model intuitive multi-modal\nground-truth distributions for both edge and non-edge regions. To mitigate the\ninherent domain preferences of a single network, we adopt network ensemble and\nfurther distinguish between objective and biased knowledge in the Laplace\nparameter space. Finally, the objective knowledge and the original disparity\nlabels are jointly modeled as a mixture of Laplacians to provide fine-grained\nsupervision for the stereo network training. Extensive experiments demonstrate\nthat: 1) Our method is generic and effectively improves the generalization of\nexisting networks. 2) PCWNet with our method achieves the state-of-the-art\ngeneralization performance on both KITTI 2015 and 2012 datasets. 3) Our method\noutperforms existing methods in comprehensive ranking across four popular\nreal-world datasets.\n","authors":["Peng Xu","Zhiyu Xiang","Jingyun Fu","Tianyu Pu","Hanzhi Zhong","Eryun Liu"],"pdf_url":"https://arxiv.org/pdf/2503.04376v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2409.08824v3","updated":"2025-03-06T12:26:08Z","published":"2024-09-13T13:37:33Z","title":"Pathfinder for Low-altitude Aircraft with Binary Neural Network","summary":"  A prior global topological map (e.g., the OpenStreetMap, OSM) can boost the\nperformance of autonomous mapping by a ground mobile robot. However, the prior\nmap is usually incomplete due to lacking labeling in partial paths. To solve\nthis problem, this paper proposes an OSM maker using airborne sensors carried\nby low-altitude aircraft, where the core of the OSM maker is a novel efficient\npathfinder approach based on LiDAR and camera data, i.e., a binary dual-stream\nroad segmentation model. Specifically, a multi-scale feature extraction based\non the UNet architecture is implemented for images and point clouds. To reduce\nthe effect caused by the sparsity of point cloud, an attention-guided gated\nblock is designed to integrate image and point-cloud features. To optimize the\nmodel for edge deployment that significantly reduces storage footprint and\ncomputational demands, we propose a binarization streamline to each model\ncomponent, including a variant of vision transformer (ViT) architecture as the\nencoder of the image branch, and new focal and perception losses to optimize\nthe model training. The experimental results on two datasets demonstrate that\nour pathfinder method achieves SOTA accuracy with high efficiency in finding\npaths from the low-level airborne sensors, and we can create complete OSM prior\nmaps based on the segmented road skeletons. Code and data are available at:\n\\href{https://github.com/IMRL/Pathfinder}{https://github.com/IMRL/Pathfinder}.\n","authors":["Kaijie Yin","Tian Gao","Hui Kong"],"pdf_url":"https://arxiv.org/pdf/2409.08824v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2502.16532v2","updated":"2025-03-06T12:19:59Z","published":"2025-02-23T10:48:11Z","title":"Deep unrolling for learning optimal spatially varying regularisation\n  parameters for Total Generalised Variation","summary":"  We extend a recently introduced deep unrolling framework for learning\nspatially varying regularisation parameters in inverse imaging problems to the\ncase of Total Generalised Variation (TGV). The framework combines a deep\nconvolutional neural network (CNN) inferring the two spatially varying TGV\nparameters with an unrolled algorithmic scheme that solves the corresponding\nvariational problem. The two subnetworks are jointly trained end-to-end in a\nsupervised fashion and as such the CNN learns to compute those parameters that\ndrive the reconstructed images as close to the ground truth as possible.\nNumerical results in image denoising and MRI reconstruction show a significant\nqualitative and quantitative improvement compared to the best TGV scalar\nparameter case as well as to other approaches employing spatially varying\nparameters computed by unsupervised methods. We also observe that the inferred\nspatially varying parameter maps have a consistent structure near the image\nedges, asking for further theoretical investigations. In particular, the\nparameter that weighs the first-order TGV term has a triple-edge structure with\nalternating high-low-high values whereas the one that weighs the second-order\nterm attains small values in a large neighbourhood around the edges.\n","authors":["Thanh Trung Vu","Andreas Kofler","Kostas Papafitsoros"],"pdf_url":"https://arxiv.org/pdf/2502.16532v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2409.10329v2","updated":"2025-03-06T12:16:09Z","published":"2024-09-16T14:39:15Z","title":"InfoDisent: Explainability of Image Classification Models by Information\n  Disentanglement","summary":"  In this work, we introduce InfoDisent, a hybrid approach to explainability\nbased on the information bottleneck principle. InfoDisent enables the\ndisentanglement of information in the final layer of any pretrained model into\natomic concepts, which can be interpreted as prototypical parts. This approach\nmerges the flexibility of post-hoc methods with the concept-level modeling\ncapabilities of self-explainable neural networks, such as ProtoPNets. We\ndemonstrate the effectiveness of InfoDisent through computational experiments\nand user studies across various datasets using modern backbones such as ViTs\nand convolutional networks. Notably, InfoDisent generalizes the prototypical\nparts approach to novel domains (ImageNet).\n","authors":["ukasz Struski","Dawid Rymarczyk","Jacek Tabor"],"pdf_url":"https://arxiv.org/pdf/2409.10329v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2408.01334v3","updated":"2025-03-06T11:59:11Z","published":"2024-08-02T15:32:42Z","title":"A Backbone for Long-Horizon Robot Task Understanding","summary":"  End-to-end robot learning, particularly for long-horizon tasks, often results\nin unpredictable outcomes and poor generalization. To address these challenges,\nwe propose a novel Therblig-Based Backbone Framework (TBBF) as a fundamental\nstructure to enhance interpretability, data efficiency, and generalization in\nrobotic systems. TBBF utilizes expert demonstrations to enable therblig-level\ntask decomposition, facilitate efficient action-object mapping, and generate\nadaptive trajectories for new scenarios. The approach consists of two stages:\noffline training and online testing. During the offline training stage, we\ndeveloped the Meta-RGate SynerFusion (MGSF) network for accurate therblig\nsegmentation across various tasks. In the online testing stage, after a\none-shot demonstration of a new task is collected, our MGSF network extracts\nhigh-level knowledge, which is then encoded into the image using Action\nRegistration (ActionREG). Additionally, Large Language Model (LLM)-Alignment\nPolicy for Visual Correction (LAP-VC) is employed to ensure precise action\nregistration, facilitating trajectory transfer in novel robot scenarios.\nExperimental results validate these methods, achieving 94.37% recall in\ntherblig segmentation and success rates of 94.4% and 80% in real-world online\nrobot testing for simple and complex scenarios, respectively. Supplementary\nmaterial is available at:\nhttps://sites.google.com/view/therbligsbasedbackbone/home\n","authors":["Xiaoshuai Chen","Wei Chen","Dongmyoung Lee","Yukun Ge","Nicolas Rojas","Petar Kormushev"],"pdf_url":"https://arxiv.org/pdf/2408.01334v3.pdf","comment":"8 pages, 8 figures. This work has been published by IEEE Robotics and\n  Automation Letters (RA-L)"},{"id":"http://arxiv.org/abs/2503.04353v1","updated":"2025-03-06T11:55:44Z","published":"2025-03-06T11:55:44Z","title":"ObjMST: An Object-Focused Multimodal Style Transfer Framework","summary":"  We propose ObjMST, an object-focused multimodal style transfer framework that\nprovides separate style supervision for salient objects and surrounding\nelements while addressing alignment issues in multimodal representation\nlearning. Existing image-text multimodal style transfer methods face the\nfollowing challenges: (1) generating non-aligned and inconsistent multimodal\nstyle representations; and (2) content mismatch, where identical style patterns\nare applied to both salient objects and their surrounding elements. Our\napproach mitigates these issues by: (1) introducing a Style-Specific Masked\nDirectional CLIP Loss, which ensures consistent and aligned style\nrepresentations for both salient objects and their surroundings; and (2)\nincorporating a salient-to-key mapping mechanism for stylizing salient objects,\nfollowed by image harmonization to seamlessly blend the stylized objects with\ntheir environment. We validate the effectiveness of ObjMST through experiments,\nusing both quantitative metrics and qualitative visual evaluations of the\nstylized outputs. Our code is available at:\nhttps://github.com/chandagrover/ObjMST.\n","authors":["Chanda Grover Kamra","Indra Deep Mastan","Debayan Gupta"],"pdf_url":"https://arxiv.org/pdf/2503.04353v1.pdf","comment":"8 pages, 8 Figures, 3 Tables"},{"id":"http://arxiv.org/abs/2503.04351v1","updated":"2025-03-06T11:49:43Z","published":"2025-03-06T11:49:43Z","title":"PLMP -- Point-Line Minimal Problems for Projective SfM","summary":"  We completely classify all minimal problems for Structure-from-Motion (SfM)\nwhere arrangements of points and lines are fully observed by multiple\nuncalibrated pinhole cameras. We find 291 minimal problems, 73 of which have\nunique solutions and can thus be solved linearly. Two of the linear problems\nallow an arbitrary number of views, while all other minimal problems have at\nmost 9 cameras. All minimal problems have at most 7 points and at most 12\nlines. We compute the number of solutions of each minimal problem, as this\ngives a measurement of the problem's intrinsic difficulty, and find that these\nnumber are relatively low (e.g., when comparing with minimal problems for\ncalibrated cameras). Finally, by exploring stabilizer subgroups of\nsubarrangements, we develop a geometric and systematic way to 1) factorize\nminimal problems into smaller problems, 2) identify minimal problems in\nunderconstrained problems, and 3) formally prove non-minimality.\n","authors":["Kim Kiehn","Albin Ahlbck","Kathln Kohn"],"pdf_url":"https://arxiv.org/pdf/2503.04351v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.04344v1","updated":"2025-03-06T11:41:36Z","published":"2025-03-06T11:41:36Z","title":"LEDiT: Your Length-Extrapolatable Diffusion Transformer without\n  Positional Encoding","summary":"  Diffusion transformers(DiTs) struggle to generate images at resolutions\nhigher than their training resolutions. The primary obstacle is that the\nexplicit positional encodings(PE), such as RoPE, need extrapolation which\ndegrades performance when the inference resolution differs from training. In\nthis paper, we propose a Length-Extrapolatable Diffusion Transformer(LEDiT), a\nsimple yet powerful architecture to overcome this limitation. LEDiT needs no\nexplicit PEs, thereby avoiding extrapolation. The key innovations of LEDiT are\nintroducing causal attention to implicitly impart global positional information\nto tokens, while enhancing locality to precisely distinguish adjacent tokens.\nExperiments on 256x256 and 512x512 ImageNet show that LEDiT can scale the\ninference resolution to 512x512 and 1024x1024, respectively, while achieving\nbetter image quality compared to current state-of-the-art length extrapolation\nmethods(NTK-aware, YaRN). Moreover, LEDiT achieves strong extrapolation\nperformance with just 100K steps of fine-tuning on a pretrained DiT,\ndemonstrating its potential for integration into existing text-to-image DiTs.\n","authors":["Shen Zhang","Yaning Tan","Siyuan Liang","Linze Li","Ge Wu","Yuhao Chen","Shuheng Li","Zhenyu Zhao","Caihua Chen","Jiajun Liang","Yao Tang"],"pdf_url":"https://arxiv.org/pdf/2503.04344v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.03644v2","updated":"2025-03-06T11:36:33Z","published":"2025-03-05T16:20:53Z","title":"DongbaMIE: A Multimodal Information Extraction Dataset for Evaluating\n  Semantic Understanding of Dongba Pictograms","summary":"  Dongba pictographs are the only pictographs still in use in the world. They\nhave pictorial ideographic features, and their symbols carry rich cultural and\ncontextual information. Due to the lack of relevant datasets, existing research\nhas difficulty in advancing the study of semantic understanding of Dongba\npictographs. To this end, we propose DongbaMIE, the first multimodal dataset\nfor semantic understanding and extraction of Dongba pictographs. The dataset\nconsists of Dongba pictograph images and their corresponding Chinese semantic\nannotations. It contains 23,530 sentence-level and 2,539 paragraph-level\nimages, covering four semantic dimensions: objects, actions, relations, and\nattributes. We systematically evaluate the GPT-4o, Gemini-2.0, and Qwen2-VL\nmodels. Experimental results show that the F1 scores of GPT-4o and Gemini in\nthe best object extraction are only 3.16 and 3.11 respectively. The F1 score of\nQwen2-VL after supervised fine-tuning is only 11.49. These results suggest that\ncurrent large multimodal models still face significant challenges in accurately\nrecognizing the diverse semantic information in Dongba pictographs. The dataset\ncan be obtained from this URL.\n","authors":["Xiaojun Bi","Shuo Li","Ziyue Wang","Fuwen Luo","Weizheng Qiao","Lu Han","Ziwei Sun","Peng Li","Yang Liu"],"pdf_url":"https://arxiv.org/pdf/2503.03644v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.04333v1","updated":"2025-03-06T11:31:08Z","published":"2025-03-06T11:31:08Z","title":"GaussianVideo: Efficient Video Representation and Compression by\n  Gaussian Splatting","summary":"  Implicit Neural Representation for Videos (NeRV) has introduced a novel\nparadigm for video representation and compression, outperforming traditional\ncodecs. As model size grows, however, slow encoding and decoding speed and high\nmemory consumption hinder its application in practice. To address these\nlimitations, we propose a new video representation and compression method based\non 2D Gaussian Splatting to efficiently handle video data. Our proposed\ndeformable 2D Gaussian Splatting dynamically adapts the transformation of 2D\nGaussians at each frame, significantly reducing memory cost. Equipped with a\nmulti-plane-based spatiotemporal encoder and a lightweight decoder, it predicts\nchanges in color, coordinates, and shape of initialized Gaussians, given the\ntime step. By leveraging temporal gradients, our model effectively captures\ntemporal redundancy at negligible cost, significantly enhancing video\nrepresentation efficiency. Our method reduces GPU memory usage by up to 78.4%,\nand significantly expedites video processing, achieving 5.5x faster training\nand 12.5x faster decoding compared to the state-of-the-art NeRV methods.\n","authors":["Inseo Lee","Youngyoon Choi","Joonseok Lee"],"pdf_url":"https://arxiv.org/pdf/2503.04333v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.04325v1","updated":"2025-03-06T11:18:22Z","published":"2025-03-06T11:18:22Z","title":"GBT-SAM: A Parameter-Efficient Depth-Aware Model for Generalizable Brain\n  tumour Segmentation on mp-MRI","summary":"  Gliomas are brain tumours that stand out for their highly lethal and\naggressive nature, which demands a precise approach in their diagnosis. Medical\nimage segmentation plays a crucial role in the evaluation and follow-up of\nthese tumours, allowing specialists to analyse their morphology. However,\nexisting methods for automatic glioma segmentation often lack generalization\ncapability across other brain tumour domains, require extensive computational\nresources, or fail to fully utilize the multi-parametric MRI (mp-MRI) data used\nto delineate them. In this work, we introduce GBT-SAM, a novel Generalizable\nBrain Tumour (GBT) framework that extends the Segment Anything Model (SAM) to\nbrain tumour segmentation tasks. Our method employs a two-step training\nprotocol: first, fine-tuning the patch embedding layer to process the entire\nmp-MRI modalities, and second, incorporating parameter-efficient LoRA blocks\nand a Depth-Condition block into the Vision Transformer (ViT) to capture\ninter-slice correlations. GBT-SAM achieves state-of-the-art performance on the\nAdult Glioma dataset (Dice Score of $93.54$) while demonstrating robust\ngeneralization across Meningioma, Pediatric Glioma, and Sub-Saharan Glioma\ndatasets. Furthermore, GBT-SAM uses less than 6.5M trainable parameters, thus\noffering an efficient solution for brain tumour segmentation. \\\\ Our code and\nmodels are available at https://github.com/vpulab/med-sam-brain .\n","authors":["Cecilia Diana-Albelda","Roberto Alcover-Couso","lvaro Garca-Martn","Jesus Bescos","Marcos Escudero-Violo"],"pdf_url":"https://arxiv.org/pdf/2503.04325v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2501.17634v2","updated":"2025-03-06T11:17:31Z","published":"2025-01-29T13:11:21Z","title":"Federated Learning With Individualized Privacy Through Client Sampling","summary":"  With growing concerns about user data collection, individualized privacy has\nemerged as a promising solution to balance protection and utility by accounting\nfor diverse user privacy preferences. Instead of enforcing a uniform level of\nanonymization for all users, this approach allows individuals to choose privacy\nsettings that align with their comfort levels. Building on this idea, we\npropose an adapted method for enabling Individualized Differential Privacy\n(IDP) in Federated Learning (FL) by handling clients according to their\npersonal privacy preferences. By extending the SAMPLE algorithm from\ncentralized settings to FL, we calculate client-specific sampling rates based\non their heterogeneous privacy budgets and integrate them into a modified\nIDP-FedAvg algorithm. We test this method under realistic privacy distributions\nand multiple datasets. The experimental results demonstrate that our approach\nachieves clear improvements over uniform DP baselines, reducing the trade-off\nbetween privacy and utility. Compared to the alternative SCALE method in\nrelated work, which assigns differing noise scales to clients, our method\nperforms notably better. However, challenges remain for complex tasks with\nnon-i.i.d. data, primarily stemming from the constraints of the decentralized\nsetting.\n","authors":["Lucas Lange","Ole Borchardt","Erhard Rahm"],"pdf_url":"https://arxiv.org/pdf/2501.17634v2.pdf","comment":"Accepted at 10th International Conference on Machine Learning\n  Technologies (ICMLT 2025)"},{"id":"http://arxiv.org/abs/2503.04322v1","updated":"2025-03-06T11:14:59Z","published":"2025-03-06T11:14:59Z","title":"A Modular Pipeline for 3D Object Tracking Using RGB Cameras","summary":"  Object tracking is a key challenge of computer vision with various\napplications that all require different architectures. Most tracking systems\nhave limitations such as constraining all movement to a 2D plane and they often\ntrack only one object. In this paper, we present a new modular pipeline that\ncalculates 3D trajectories of multiple objects. It is adaptable to various\nsettings where multiple time-synced and stationary cameras record moving\nobjects, using off the shelf webcams. Our pipeline was tested on the Table\nSetting Dataset, where participants are recorded with various sensors as they\nset a table with tableware objects. We need to track these manipulated objects,\nusing 6 rgb webcams. Challenges include: Detecting small objects in 9.874.699\ncamera frames, determining camera poses, discriminating between nearby and\noverlapping objects, temporary occlusions, and finally calculating a 3D\ntrajectory using the right subset of an average of 11.12.456 pixel coordinates\nper 3-minute trial. We implement a robust pipeline that results in accurate\ntrajectories with covariance of x,y,z-position as a confidence metric. It deals\ndynamically with appearing and disappearing objects, instantiating new Extended\nKalman Filters. It scales to hundreds of table-setting trials with very little\nhuman annotation input, even with the camera poses of each trial unknown. The\ncode is available at https://github.com/LarsBredereke/object_tracking\n","authors":["Lars Bredereke","Yale Hartmann","Tanja Schultz"],"pdf_url":"https://arxiv.org/pdf/2503.04322v1.pdf","comment":"9 pages, 11 figures, original paper not to be published anywhere else"},{"id":"http://arxiv.org/abs/2501.16981v3","updated":"2025-03-06T11:08:38Z","published":"2025-01-28T14:28:55Z","title":"Modulating CNN Features with Pre-Trained ViT Representations for\n  Open-Vocabulary Object Detection","summary":"  Owing to large-scale image-text contrastive training, pre-trained vision\nlanguage model (VLM) like CLIP shows superior open-vocabulary recognition\nability. Most existing open-vocabulary object detectors attempt to utilize the\npre-trained VLMs to attain generalized representation. F-ViT uses the\npre-trained visual encoder as the backbone network and freezes it during\ntraining. However, its frozen backbone doesn't benefit from the labeled data to\nstrengthen the representation for detection. Therefore, we propose a novel\ntwo-branch backbone network, named as \\textbf{V}iT-Feature-\\textbf{M}odulated\nMulti-Scale \\textbf{C}onvolutional Network (VMCNet), which consists of a\ntrainable convolutional branch, a frozen pre-trained ViT branch and a VMC\nmodule. The trainable CNN branch could be optimized with labeled data while the\nfrozen pre-trained ViT branch could keep the representation ability derived\nfrom large-scale pre-training. Then, the proposed VMC module could modulate the\nmulti-scale CNN features with the representations from ViT branch. With this\nproposed mixed structure, the detector is more likely to discover objects of\nnovel categories. Evaluated on two popular benchmarks, our method boosts the\ndetection performance on novel category and outperforms state-of-the-art\nmethods. On OV-COCO, the proposed method achieves 44.3\nAP$_{50}^{\\mathrm{novel}}$ with ViT-B/16 and 48.5 AP$_{50}^{\\mathrm{novel}}$\nwith ViT-L/14. On OV-LVIS, VMCNet with ViT-B/16 and ViT-L/14 reaches 27.8 and\n38.4 mAP$_{r}$.\n","authors":["Xiangyu Gao","Yu Dai","Benliu Qiu","Lanxiao Wang","Heqian Qiu","Hongliang Li"],"pdf_url":"https://arxiv.org/pdf/2501.16981v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2402.01879v3","updated":"2025-03-06T11:05:33Z","published":"2024-02-02T20:08:11Z","title":"$$-zero: Gradient-based Optimization of $\\ell_0$-norm Adversarial\n  Examples","summary":"  Evaluating the adversarial robustness of deep networks to gradient-based\nattacks is challenging. While most attacks consider $\\ell_2$- and\n$\\ell_\\infty$-norm constraints to craft input perturbations, only a few\ninvestigate sparse $\\ell_1$- and $\\ell_0$-norm attacks. In particular,\n$\\ell_0$-norm attacks remain the least studied due to the inherent complexity\nof optimizing over a non-convex and non-differentiable constraint. However,\nevaluating adversarial robustness under these attacks could reveal weaknesses\notherwise left untested with more conventional $\\ell_2$- and $\\ell_\\infty$-norm\nattacks. In this work, we propose a novel $\\ell_0$-norm attack, called\n$\\sigma$-zero, which leverages a differentiable approximation of the $\\ell_0$\nnorm to facilitate gradient-based optimization, and an adaptive projection\noperator to dynamically adjust the trade-off between loss minimization and\nperturbation sparsity. Extensive evaluations using MNIST, CIFAR10, and ImageNet\ndatasets, involving robust and non-robust models, show that\n$\\sigma$\\texttt{-zero} finds minimum $\\ell_0$-norm adversarial examples without\nrequiring any time-consuming hyperparameter tuning, and that it outperforms all\ncompeting sparse attacks in terms of success rate, perturbation size, and\nefficiency.\n","authors":["Antonio Emanuele Cin","Francesco Villani","Maura Pintor","Lea Schnherr","Battista Biggio","Marcello Pelillo"],"pdf_url":"https://arxiv.org/pdf/2402.01879v3.pdf","comment":"Paper accepted at International Conference on Learning\n  Representations (ICLR 2025). Code available at\n  https://github.com/sigma0-advx/sigma-zero"},{"id":"http://arxiv.org/abs/2412.00156v3","updated":"2025-03-06T11:05:32Z","published":"2024-11-29T08:10:49Z","title":"VISION-XL: High Definition Video Inverse Problem Solver using Latent\n  Image Diffusion Models","summary":"  In this paper, we propose a novel framework for solving high-definition video\ninverse problems using latent image diffusion models. Building on recent\nadvancements in spatio-temporal optimization for video inverse problems using\nimage diffusion models, our approach leverages latent-space diffusion models to\nachieve enhanced video quality and resolution. To address the high\ncomputational demands of processing high-resolution frames, we introduce a\npseudo-batch consistent sampling strategy, allowing efficient operation on a\nsingle GPU. Additionally, to improve temporal consistency, we present\npseudo-batch inversion, an initialization technique that incorporates\ninformative latents from the measurement. By integrating with SDXL, our\nframework achieves state-of-the-art video reconstruction across a wide range of\nspatio-temporal inverse problems, including complex combinations of frame\naveraging and various spatial degradations, such as deblurring,\nsuper-resolution, and inpainting. Unlike previous methods, our approach\nsupports multiple aspect ratios (landscape, vertical, and square) and delivers\nHD-resolution reconstructions (exceeding 1280x720) in under 6 seconds per frame\non a single NVIDIA 4090 GPU.\n","authors":["Taesung Kwon","Jong Chul Ye"],"pdf_url":"https://arxiv.org/pdf/2412.00156v3.pdf","comment":"Project page: https://vision-xl.github.io/"},{"id":"http://arxiv.org/abs/2501.10814v2","updated":"2025-03-06T11:05:23Z","published":"2025-01-18T16:23:09Z","title":"No More Sliding Window: Efficient 3D Medical Image Segmentation with\n  Differentiable Top-k Patch Sampling","summary":"  3D models surpass 2D models in CT/MRI segmentation by effectively capturing\ninter-slice relationships. However, the added depth dimension substantially\nincreases memory consumption. While patch-based training alleviates memory\nconstraints, it significantly slows down the inference speed due to the sliding\nwindow (SW) approach. We propose No-More-Sliding-Window (NMSW), a novel\nend-to-end trainable framework that enhances the efficiency of generic 3D\nsegmentation backbone during an inference step by eliminating the need for SW.\nNMSW employs a differentiable Top-k module to selectively sample only the most\nrelevant patches, thereby minimizing redundant computations. When patch-level\npredictions are insufficient, the framework intelligently leverages coarse\nglobal predictions to refine results. Evaluated across 3 tasks using 3\nsegmentation backbones, NMSW achieves competitive accuracy compared to SW\ninference while significantly reducing computational complexity by 91% (88.0 to\n8.00 TMACs). Moreover, it delivers a 9.1x faster inference on the H100 GPU\n(99.0 to 8.3 sec) and a 11.1x faster inference on the Xeon Gold CPU (2110 to\n189 sec). NMSW is model-agnostic, further boosting efficiency when integrated\nwith any existing efficient segmentation backbones.\n","authors":["Young Seok Jeon","Hongfei Yang","Huazhu Fu","Mengling Feng"],"pdf_url":"https://arxiv.org/pdf/2501.10814v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.04314v1","updated":"2025-03-06T10:58:26Z","published":"2025-03-06T10:58:26Z","title":"S2Gaussian: Sparse-View Super-Resolution 3D Gaussian Splatting","summary":"  In this paper, we aim ambitiously for a realistic yet challenging problem,\nnamely, how to reconstruct high-quality 3D scenes from sparse low-resolution\nviews that simultaneously suffer from deficient perspectives and clarity.\nWhereas existing methods only deal with either sparse views or low-resolution\nobservations, they fail to handle such hybrid and complicated scenarios. To\nthis end, we propose a novel Sparse-view Super-resolution 3D Gaussian Splatting\nframework, dubbed S2Gaussian, that can reconstruct structure-accurate and\ndetail-faithful 3D scenes with only sparse and low-resolution views. The\nS2Gaussian operates in a two-stage fashion. In the first stage, we initially\noptimize a low-resolution Gaussian representation with depth regularization and\ndensify it to initialize the high-resolution Gaussians through a tailored\nGaussian Shuffle Split operation. In the second stage, we refine the\nhigh-resolution Gaussians with the super-resolved images generated from both\noriginal sparse views and pseudo-views rendered by the low-resolution\nGaussians. In which a customized blur-free inconsistency modeling scheme and a\n3D robust optimization strategy are elaborately designed to mitigate multi-view\ninconsistency and eliminate erroneous updates caused by imperfect supervision.\nExtensive experiments demonstrate superior results and in particular\nestablishing new state-of-the-art performances with more consistent geometry\nand finer details.\n","authors":["Yecong Wan","Mingwen Shao","Yuanshuo Cheng","Wangmeng Zuo"],"pdf_url":"https://arxiv.org/pdf/2503.04314v1.pdf","comment":"CVPR 2025"},{"id":"http://arxiv.org/abs/2503.04308v1","updated":"2025-03-06T10:51:04Z","published":"2025-03-06T10:51:04Z","title":"Shaken, Not Stirred: A Novel Dataset for Visual Understanding of Glasses\n  in Human-Robot Bartending Tasks","summary":"  Datasets for object detection often do not account for enough variety of\nglasses, due to their transparent and reflective properties. Specifically,\nopen-vocabulary object detectors, widely used in embodied robotic agents, fail\nto distinguish subclasses of glasses. This scientific gap poses an issue to\nrobotic applications that suffer from accumulating errors between detection,\nplanning, and action execution. The paper introduces a novel method for the\nacquisition of real-world data from RGB-D sensors that minimizes human effort.\nWe propose an auto-labeling pipeline that generates labels for all the acquired\nframes based on the depth measurements. We provide a novel real-world glass\nobject dataset that was collected on the Neuro-Inspired COLlaborator (NICOL), a\nhumanoid robot platform. The data set consists of 7850 images recorded from\nfive different cameras. We show that our trained baseline model outperforms\nstate-of-the-art open-vocabulary approaches. In addition, we deploy our\nbaseline model in an embodied agent approach to the NICOL platform, on which it\nachieves a success rate of 81% in a human-robot bartending scenario.\n","authors":["Luk Gajdoech","Hassan Ali","Jan-Gerrit Habekost","Martin Madaras","Matthias Kerzel","Stefan Wermter"],"pdf_url":"https://arxiv.org/pdf/2503.04308v1.pdf","comment":"Submitted to IEEE/RSJ International Conference on Intelligent Robots\n  and Systems (IROS) 2025"},{"id":"http://arxiv.org/abs/2412.01615v3","updated":"2025-03-06T10:49:58Z","published":"2024-12-02T15:38:44Z","title":"OmniGuard: Hybrid Manipulation Localization via Augmented Versatile Deep\n  Image Watermarking","summary":"  With the rapid growth of generative AI and its widespread application in\nimage editing, new risks have emerged regarding the authenticity and integrity\nof digital content. Existing versatile watermarking approaches suffer from\ntrade-offs between tamper localization precision and visual quality.\nConstrained by the limited flexibility of previous framework, their localized\nwatermark must remain fixed across all images. Under AIGC-editing, their\ncopyright extraction accuracy is also unsatisfactory. To address these\nchallenges, we propose OmniGuard, a novel augmented versatile watermarking\napproach that integrates proactive embedding with passive, blind extraction for\nrobust copyright protection and tamper localization. OmniGuard employs a hybrid\nforensic framework that enables flexible localization watermark selection and\nintroduces a degradation-aware tamper extraction network for precise\nlocalization under challenging conditions. Additionally, a lightweight\nAIGC-editing simulation layer is designed to enhance robustness across global\nand local editing. Extensive experiments show that OmniGuard achieves superior\nfidelity, robustness, and flexibility. Compared to the recent state-of-the-art\napproach EditGuard, our method outperforms it by 4.25dB in PSNR of the\ncontainer image, 20.7% in F1-Score under noisy conditions, and 14.8% in average\nbit accuracy.\n","authors":["Xuanyu Zhang","Zecheng Tang","Zhipei Xu","Runyi Li","Youmin Xu","Bin Chen","Feng Gao","Jian Zhang"],"pdf_url":"https://arxiv.org/pdf/2412.01615v3.pdf","comment":"Accepted by CVPR 2025"},{"id":"http://arxiv.org/abs/2503.03370v2","updated":"2025-03-06T10:41:28Z","published":"2025-03-05T10:46:03Z","title":"MIAdapt: Source-free Few-shot Domain Adaptive Object Detection for\n  Microscopic Images","summary":"  Existing generic unsupervised domain adaptation approaches require access to\nboth a large labeled source dataset and a sufficient unlabeled target dataset\nduring adaptation. However, collecting a large dataset, even if unlabeled, is a\nchallenging and expensive endeavor, especially in medical imaging. In addition,\nconstraints such as privacy issues can result in cases where source data is\nunavailable. Taking in consideration these challenges, we propose MIAdapt, an\nadaptive approach for Microscopic Imagery Adaptation as a solution for\nSource-free Few-shot Domain Adaptive Object detection (SF-FSDA). We also define\ntwo competitive baselines (1) Faster-FreeShot and (2) MT-FreeShot. Extensive\nexperiments on the challenging M5-Malaria and Raabin-WBC datasets validate the\neffectiveness of MIAdapt. Without using any image from the source domain\nMIAdapt surpasses state-of-the-art source-free UDA (SF-UDA) methods by +21.3%\nmAP and few-shot domain adaptation (FSDA) approaches by +4.7% mAP on\nRaabin-WBC. Our code and models will be publicly available.\n","authors":["Nimra Dilawar","Sara Nadeem","Javed Iqbal","Waqas Sultani","Mohsen Ali"],"pdf_url":"https://arxiv.org/pdf/2503.03370v2.pdf","comment":"6 pages, 5 figures"},{"id":"http://arxiv.org/abs/2312.03286v2","updated":"2025-03-06T10:12:31Z","published":"2023-12-06T04:32:38Z","title":"Indirect Gradient Matching for Adversarial Robust Distillation","summary":"  Adversarial training significantly improves adversarial robustness, but\nsuperior performance is primarily attained with large models. This substantial\nperformance gap for smaller models has spurred active research into adversarial\ndistillation (AD) to mitigate the difference. Existing AD methods leverage the\nteacher's logits as a guide. In contrast to these approaches, we aim to\ntransfer another piece of knowledge from the teacher, the input gradient. In\nthis paper, we propose a distillation module termed Indirect Gradient\nDistillation Module (IGDM) that indirectly matches the student's input gradient\nwith that of the teacher. Experimental results show that IGDM seamlessly\nintegrates with existing AD methods, significantly enhancing their performance.\nParticularly, utilizing IGDM on the CIFAR-100 dataset improves the AutoAttack\naccuracy from 28.06% to 30.32% with the ResNet-18 architecture and from 26.18%\nto 29.32% with the MobileNetV2 architecture when integrated into the SOTA\nmethod without additional data augmentation.\n","authors":["Hongsin Lee","Seungju Cho","Changick Kim"],"pdf_url":"https://arxiv.org/pdf/2312.03286v2.pdf","comment":"ICLR 2025"},{"id":"http://arxiv.org/abs/2503.04268v1","updated":"2025-03-06T09:57:26Z","published":"2025-03-06T09:57:26Z","title":"ControlFill: Spatially Adjustable Image Inpainting from Prompt Learning","summary":"  In this report, I present an inpainting framework named \\textit{ControlFill},\nwhich involves training two distinct prompts: one for generating plausible\nobjects within a designated mask (\\textit{creation}) and another for filling\nthe region by extending the background (\\textit{removal}). During the inference\nstage, these learned embeddings guide a diffusion network that operates without\nrequiring heavy text encoders. By adjusting the relative significance of the\ntwo prompts and employing classifier-free guidance, users can control the\nintensity of removal or creation. Furthermore, I introduce a method to\nspatially vary the intensity of guidance by assigning different scales to\nindividual pixels.\n","authors":["Boseong Jeon"],"pdf_url":"https://arxiv.org/pdf/2503.04268v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2501.18672v4","updated":"2025-03-06T09:55:41Z","published":"2025-01-30T18:51:54Z","title":"Drag Your Gaussian: Effective Drag-Based Editing with Score Distillation\n  for 3D Gaussian Splatting","summary":"  Recent advancements in 3D scene editing have been propelled by the rapid\ndevelopment of generative models. Existing methods typically utilize generative\nmodels to perform text-guided editing on 3D representations, such as 3D\nGaussian Splatting (3DGS). However, these methods are often limited to texture\nmodifications and fail when addressing geometric changes, such as editing a\ncharacter's head to turn around. Moreover, such methods lack accurate control\nover the spatial position of editing results, as language struggles to\nprecisely describe the extent of edits. To overcome these limitations, we\nintroduce DYG, an effective 3D drag-based editing method for 3D Gaussian\nSplatting. It enables users to conveniently specify the desired editing region\nand the desired dragging direction through the input of 3D masks and pairs of\ncontrol points, thereby enabling precise control over the extent of editing.\nDYG integrates the strengths of the implicit triplane representation to\nestablish the geometric scaffold of the editing results, effectively overcoming\nsuboptimal editing outcomes caused by the sparsity of 3DGS in the desired\nediting regions. Additionally, we incorporate a drag-based Latent Diffusion\nModel into our method through the proposed Drag-SDS loss function, enabling\nflexible, multi-view consistent, and fine-grained editing. Extensive\nexperiments demonstrate that DYG conducts effective drag-based editing guided\nby control point prompts, surpassing other baselines in terms of editing effect\nand quality, both qualitatively and quantitatively. Visit our project page at\nhttps://quyans.github.io/Drag-Your-Gaussian.\n","authors":["Yansong Qu","Dian Chen","Xinyang Li","Xiaofan Li","Shengchuan Zhang","Liujuan Cao","Rongrong Ji"],"pdf_url":"https://arxiv.org/pdf/2501.18672v4.pdf","comment":"Visit our project page at https://quyans.github.io/Drag-Your-Gaussian"},{"id":"http://arxiv.org/abs/2405.14736v2","updated":"2025-03-06T09:52:43Z","published":"2024-05-23T16:02:30Z","title":"GIFT: Unlocking Full Potential of Labels in Distilled Dataset at\n  Near-zero Cost","summary":"  Recent advancements in dataset distillation have demonstrated the significant\nbenefits of employing soft labels generated by pre-trained teacher models. In\nthis paper, we introduce a novel perspective by emphasizing the full\nutilization of labels. We first conduct a comprehensive comparison of various\nloss functions for soft label utilization in dataset distillation, revealing\nthat the model trained on the synthetic dataset exhibits high sensitivity to\nthe choice of loss function for soft label utilization. This finding highlights\nthe necessity of a universal loss function for training models on synthetic\ndatasets. Building on these insights, we introduce an extremely simple yet\nsurprisingly effective plug-and-play approach, GIFT, which encompasses soft\nlabel refinement and a cosine similarity-based loss function to efficiently\nleverage full label information. Extensive experiments indicate that GIFT\nconsistently enhances state-of-the-art dataset distillation methods across\nvarious dataset scales, without incurring additional computational costs.\nImportantly, GIFT significantly enhances cross-optimizer generalization, an\narea previously overlooked. For instance, on ImageNet-1K with IPC = 10, GIFT\nenhances the state-of-the-art method RDED by 30.8% in cross-optimizer\ngeneralization. Our code is available at https://github.com/LINs-lab/GIFT.\n","authors":["Xinyi Shang","Peng Sun","Tao Lin"],"pdf_url":"https://arxiv.org/pdf/2405.14736v2.pdf","comment":"https://github.com/LINs-lab/GIFT"},{"id":"http://arxiv.org/abs/2503.04258v1","updated":"2025-03-06T09:39:36Z","published":"2025-03-06T09:39:36Z","title":"TAIL: Text-Audio Incremental Learning","summary":"  Many studies combine text and audio to capture multi-modal information but\nthey overlook the model's generalization ability on new datasets. Introducing\nnew datasets may affect the feature space of the original dataset, leading to\ncatastrophic forgetting. Meanwhile, large model parameters can significantly\nimpact training performance. To address these limitations, we introduce a novel\ntask called Text-Audio Incremental Learning (TAIL) task for text-audio\nretrieval, and propose a new method, PTAT, Prompt Tuning for Audio-Text\nincremental learning. This method utilizes prompt tuning to optimize the model\nparameters while incorporating an audio-text similarity and feature\ndistillation module to effectively mitigate catastrophic forgetting. We\nbenchmark our method and previous incremental learning methods on AudioCaps,\nClotho, BBC Sound Effects and Audioset datasets, and our method outperforms\nprevious methods significantly, particularly demonstrating stronger resistance\nto forgetting on older datasets. Compared to the full-parameters Finetune\n(Sequential) method, our model only requires 2.42\\% of its parameters,\nachieving 4.46\\% higher performance.\n","authors":["Yingfei Sun","Xu Gu","Wei Ji","Hanbin Zhao","Hao Fei","Yifang Yin","Roger Zimmermann"],"pdf_url":"https://arxiv.org/pdf/2503.04258v1.pdf","comment":"4 figures, 5 tables"},{"id":"http://arxiv.org/abs/2503.04257v1","updated":"2025-03-06T09:39:09Z","published":"2025-03-06T09:39:09Z","title":"How to Move Your Dragon: Text-to-Motion Synthesis for Large-Vocabulary\n  Objects","summary":"  Motion synthesis for diverse object categories holds great potential for 3D\ncontent creation but remains underexplored due to two key challenges: (1) the\nlack of comprehensive motion datasets that include a wide range of high-quality\nmotions and annotations, and (2) the absence of methods capable of handling\nheterogeneous skeletal templates from diverse objects. To address these\nchallenges, we contribute the following: First, we augment the Truebones Zoo\ndataset, a high-quality animal motion dataset covering over 70 species, by\nannotating it with detailed text descriptions, making it suitable for\ntext-based motion synthesis. Second, we introduce rig augmentation techniques\nthat generate diverse motion data while preserving consistent dynamics,\nenabling models to adapt to various skeletal configurations. Finally, we\nredesign existing motion diffusion models to dynamically adapt to arbitrary\nskeletal templates, enabling motion synthesis for a diverse range of objects\nwith varying structures. Experiments show that our method learns to generate\nhigh-fidelity motions from textual descriptions for diverse and even unseen\nobjects, setting a strong foundation for motion synthesis across diverse object\ncategories and skeletal templates. Qualitative results are available on this\nlink: t2m4lvo.github.io\n","authors":["Wonkwang Lee","Jongwon Jeong","Taehong Moon","Hyeon-Jong Kim","Jaehyeon Kim","Gunhee Kim","Byeong-Uk Lee"],"pdf_url":"https://arxiv.org/pdf/2503.04257v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.04250v1","updated":"2025-03-06T09:33:46Z","published":"2025-03-06T09:33:46Z","title":"An Egocentric Vision-Language Model based Portable Real-time Smart\n  Assistant","summary":"  We present Vinci, a vision-language system designed to provide real-time,\ncomprehensive AI assistance on portable devices. At its core, Vinci leverages\nEgoVideo-VL, a novel model that integrates an egocentric vision foundation\nmodel with a large language model (LLM), enabling advanced functionalities such\nas scene understanding, temporal grounding, video summarization, and future\nplanning. To enhance its utility, Vinci incorporates a memory module for\nprocessing long video streams in real time while retaining contextual history,\na generation module for producing visual action demonstrations, and a retrieval\nmodule that bridges egocentric and third-person perspectives to provide\nrelevant how-to videos for skill acquisition. Unlike existing systems that\noften depend on specialized hardware, Vinci is hardware-agnostic, supporting\ndeployment across a wide range of devices, including smartphones and wearable\ncameras. In our experiments, we first demonstrate the superior performance of\nEgoVideo-VL on multiple public benchmarks, showcasing its vision-language\nreasoning and contextual understanding capabilities. We then conduct a series\nof user studies to evaluate the real-world effectiveness of Vinci, highlighting\nits adaptability and usability in diverse scenarios. We hope Vinci can\nestablish a new framework for portable, real-time egocentric AI systems,\nempowering users with contextual and actionable insights. Including the\nfrontend, backend, and models, all codes of Vinci are available at\nhttps://github.com/OpenGVLab/vinci.\n","authors":["Yifei Huang","Jilan Xu","Baoqi Pei","Yuping He","Guo Chen","Mingfang Zhang","Lijin Yang","Zheng Nie","Jinyao Liu","Guoshun Fan","Dechen Lin","Fang Fang","Kunpeng Li","Chang Yuan","Xinyuan Chen","Yaohui Wang","Yali Wang","Yu Qiao","Limin Wang"],"pdf_url":"https://arxiv.org/pdf/2503.04250v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2412.07481v5","updated":"2025-03-06T09:26:33Z","published":"2024-12-10T13:03:42Z","title":"Manta: Enhancing Mamba for Few-Shot Action Recognition of Long\n  Sub-Sequence","summary":"  In few-shot action recognition (FSAR), long sub-sequences of video naturally\nexpress entire actions more effectively. However, the high computational\ncomplexity of mainstream Transformer-based methods limits their application.\nRecent Mamba demonstrates efficiency in modeling long sequences, but directly\napplying Mamba to FSAR overlooks the importance of local feature modeling and\nalignment. Moreover, long sub-sequences within the same class accumulate\nintra-class variance, which adversely impacts FSAR performance. To solve these\nchallenges, we propose a Matryoshka MAmba and CoNtrasTive LeArning framework\n(Manta). Firstly, the Matryoshka Mamba introduces multiple Inner Modules to\nenhance local feature representation, rather than directly modeling global\nfeatures. An Outer Module captures dependencies of timeline between these local\nfeatures for implicit temporal alignment. Secondly, a hybrid contrastive\nlearning paradigm, combining both supervised and unsupervised methods, is\ndesigned to mitigate the negative effects of intra-class variance accumulation.\nThe Matryoshka Mamba and the hybrid contrastive learning paradigm operate in\ntwo parallel branches within Manta, enhancing Mamba for FSAR of long\nsub-sequence. Manta achieves new state-of-the-art performance on prominent\nbenchmarks, including SSv2, Kinetics, UCF101, and HMDB51. Extensive empirical\nstudies prove that Manta significantly improves FSAR of long sub-sequence from\nmultiple perspectives.\n","authors":["Wenbo Huang","Jinghui Zhang","Guang Li","Lei Zhang","Shuoyuan Wang","Fang Dong","Jiahui Jin","Takahiro Ogawa","Miki Haseyama"],"pdf_url":"https://arxiv.org/pdf/2412.07481v5.pdf","comment":"Accepted by AAAI 2025"},{"id":"http://arxiv.org/abs/2408.09110v3","updated":"2025-03-06T09:26:00Z","published":"2024-08-17T06:24:43Z","title":"Locate Anything on Earth: Advancing Open-Vocabulary Object Detection for\n  Remote Sensing Community","summary":"  Object detection, particularly open-vocabulary object detection, plays a\ncrucial role in Earth sciences, such as environmental monitoring, natural\ndisaster assessment, and land-use planning. However, existing open-vocabulary\ndetectors, primarily trained on natural-world images, struggle to generalize to\nremote sensing images due to a significant data domain gap. Thus, this paper\naims to advance the development of open-vocabulary object detection in remote\nsensing community. To achieve this, we first reformulate the task as Locate\nAnything on Earth (LAE) with the goal of detecting any novel concepts on Earth.\nWe then developed the LAE-Label Engine which collects, auto-annotates, and\nunifies up to 10 remote sensing datasets creating the LAE-1M - the first\nlarge-scale remote sensing object detection dataset with broad category\ncoverage. Using the LAE-1M, we further propose and train the novel LAE-DINO\nModel, the first open-vocabulary foundation object detector for the LAE task,\nfeaturing Dynamic Vocabulary Construction (DVC) and Visual-Guided Text Prompt\nLearning (VisGT) modules. DVC dynamically constructs vocabulary for each\ntraining batch, while VisGT maps visual features to semantic space, enhancing\ntext features. We comprehensively conduct experiments on established remote\nsensing benchmark DIOR, DOTAv2.0, as well as our newly introduced 80-class\nLAE-80C benchmark. Results demonstrate the advantages of the LAE-1M dataset and\nthe effectiveness of the LAE-DINO method.\n","authors":["Jiancheng Pan","Yanxing Liu","Yuqian Fu","Muyuan Ma","Jiahao Li","Danda Pani Paudel","Luc Van Gool","Xiaomeng Huang"],"pdf_url":"https://arxiv.org/pdf/2408.09110v3.pdf","comment":"15 pages, 11 figures"},{"id":"http://arxiv.org/abs/2503.00168v2","updated":"2025-03-06T09:23:35Z","published":"2025-02-28T20:30:56Z","title":"SSL4EO-S12 v1.1: A Multimodal, Multiseasonal Dataset for Pretraining,\n  Updated","summary":"  This technical report presents SSL4EO-S12 v1.1, a multimodal, multitemporal\nEarth Observation dataset designed for pretraining large-scale foundation\nmodels. Building on the success of SSL4EO-S12 v1.0, the new version addresses\nthe previous challenges of data misalignment and a limited data structure for\nlow-barrier, analysis-ready EO processing. SSL4EO-S12 v1.1 covers the world's\n10,000 largest cities and its surroundings within a 50 km radius across four\nseasons, resulting in a diverse collection of nearly one million patches.\nSSL4EO-S12 v1.1 packages the data in Zarr file format for cloud-efficient\nloading and representation of meta-information such as including cloud masks\nand geolocation. Released under the CC-BY-4.0 license, SSL4EO-S12 v1.1\nfacilitates open research and provides a robust foundation for future\nadvancements in self-supervised learning and geospatial analysis. The dataset\nis available online through https://datapub.fz-juelich.de/ssl4eo-s12, and we\nprovided additional resources at https://github.com/DLR-MF-DAS/SSL4EO-S12-v1.1.\n","authors":["Benedikt Blumenstiel","Nassim Ait Ali Braham","Conrad M Albrecht","Stefano Maurogiovanni","Paolo Fraccaro"],"pdf_url":"https://arxiv.org/pdf/2503.00168v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.04235v1","updated":"2025-03-06T09:15:13Z","published":"2025-03-06T09:15:13Z","title":"Geometry-Constrained Monocular Scale Estimation Using Semantic\n  Segmentation for Dynamic Scenes","summary":"  Monocular visual localization plays a pivotal role in advanced driver\nassistance systems and autonomous driving by estimating a vehicle's ego-motion\nfrom a single pinhole camera. Nevertheless, conventional monocular visual\nodometry encoun-ters challenges in scale estimation due to the absence of depth\ninformation during projection. Previous methodologies, whether rooted in\nphysical constraints or deep learning paradigms, con-tend with issues related\nto computational complexity and the management of dynamic objects. This study\nextends our prior research, presenting innovative strategies for ego-motion\nestima-tion and the selection of ground points. Striving for a nuanced\nequilibrium between computational efficiency and precision, we propose a hybrid\nmethod that leverages the SegNeXt model for real-time applications,\nencompassing both ego-motion estimation and ground point selection. Our\nmethodology incorporates dy-namic object masks to eliminate unstable features\nand employs ground plane masks for meticulous triangulation. Furthermore, we\nexploit Geometry-constraint to delineate road regions for scale recovery. The\nintegration of this approach with the mo-nocular version of ORB-SLAM3\nculminates in the accurate esti-mation of a road model, a pivotal component in\nour scale recov-ery process. Rigorous experiments, conducted on the KITTI\nda-taset, systematically compare our method with existing monocu-lar visual\nodometry algorithms and contemporary scale recovery methodologies. The results\nundeniably confirm the superior ef-fectiveness of our approach, surpassing\nstate-of-the-art visual odometry algorithms. Our source code is available at\nhttps://git hub.com/bFr0zNq/MVOSegScale.\n","authors":["Hui Zhang","Zhiyang Wu","Qianqian Shangguan","Kang An"],"pdf_url":"https://arxiv.org/pdf/2503.04235v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.07076v2","updated":"2025-03-06T09:13:28Z","published":"2024-11-11T15:51:48Z","title":"StoryTeller: Improving Long Video Description through Global\n  Audio-Visual Character Identification","summary":"  Existing large vision-language models (LVLMs) are largely limited to\nprocessing short, seconds-long videos and struggle with generating coherent\ndescriptions for extended video spanning minutes or more. Long video\ndescription introduces new challenges, such as consistent character\nidentification and plot-level descriptions incorporating both visual and audio\ninformation. To address these, we figure out audio-visual character\nidentification, matching character names to each dialogue, as a key factor. We\npropose StoryTeller, a system for generating dense descriptions of long videos,\nincorporating both low-level visual concepts and high-level plot information.\nStoryTeller uses a multimodal large language model that integrates visual,\naudio, and text modalities to perform audio-visual character identification on\nminute-long video clips. The results are then fed into a LVLM to enhance\nconsistency of video description. We validate our approach on movie description\ntasks and introduce MovieStory101, a dataset with dense descriptions for\nthree-minute movie clips. To evaluate long video descriptions, we create\nStoryQA, a large set of multiple-choice questions for MovieStory101 test set.\nWe assess descriptions by inputting them into GPT-4 to answer these questions,\nusing accuracy as an automatic evaluation metric. Experiments show that\nStoryTeller outperforms all open and closed-source baselines on StoryQA,\nachieving 9.5% higher accuracy than the strongest baseline, Gemini-1.5-pro, and\ndemonstrating a +15.56% advantage in human side-by-side evaluations.\nAdditionally, incorporating audio-visual character identification from\nStoryTeller improves the performance of all video description models, with\nGemini-1.5-pro and GPT-4o showing relative improvement of 5.5% and 13.0%,\nrespectively, in accuracy on StoryQA.\n","authors":["Yichen He","Yuan Lin","Jianchao Wu","Hanchong Zhang","Yuchen Zhang","Ruicheng Le"],"pdf_url":"https://arxiv.org/pdf/2411.07076v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.09263v3","updated":"2025-03-06T09:10:07Z","published":"2024-11-14T08:02:14Z","title":"Rethinking Weight-Averaged Model-merging","summary":"  Model-merging has emerged as a powerful approach in deep learning, capable of\nenhancing model performance without any training. However, the underlying\nmechanisms that explain its effectiveness remain largely unexplored. In this\npaper, we investigate this technique from three novel perspectives to\nempirically provide deeper insights into why and how weight-averaged\nmodel-merging works: (1) we examine the intrinsic patterns captured by the\nlearning of the model weights, through the visualizations of their patterns on\nseveral datasets, showing that these weights often encode structured and\ninterpretable patterns and that is the essential why model-merging can work;\n(2) we mathematically and empirically investigate model ensemble merging\nstrategies based on averaging on weights versus averaging on features,\nproviding detailed analyses across diverse architectures and datasets; and (3)\nwe explore the impact on model-merging prediction stability in terms of\nchanging the parameter magnitude, revealing insights into the way of weight\naveraging works as regularization by showing the robustness across different\nparameter scales. Our findings shed light on the \"black box\" of weight-averaged\nmodel-merging, offering valuable insights and practical recommendations that\nadvance the model-merging process. The code is available at\nhttps://github.com/billhhh/Rethink-Merge.\n","authors":["Hu Wang","Congbo Ma","Ibrahim Almakky","Ian Reid","Gustavo Carneiro","Mohammad Yaqub"],"pdf_url":"https://arxiv.org/pdf/2411.09263v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.04229v1","updated":"2025-03-06T09:09:18Z","published":"2025-03-06T09:09:18Z","title":"Synthetic Data is an Elegant GIFT for Continual Vision-Language Models","summary":"  Pre-trained Vision-Language Models (VLMs) require Continual Learning (CL) to\nefficiently update their knowledge and adapt to various downstream tasks\nwithout retraining from scratch. However, for VLMs, in addition to the loss of\nknowledge previously learned from downstream tasks, pre-training knowledge is\nalso corrupted during continual fine-tuning. This issue is exacerbated by the\nunavailability of original pre-training data, leaving VLM's generalization\nability degrading. In this paper, we propose GIFT, a novel continual\nfine-tuning approach that utilizes synthetic data to overcome catastrophic\nforgetting in VLMs. Taking advantage of recent advances in text-to-image\nsynthesis, we employ a pre-trained diffusion model to recreate both\npre-training and learned downstream task data. In this way, the VLM can revisit\nprevious knowledge through distillation on matching diffusion-generated images\nand corresponding text prompts. Leveraging the broad distribution and high\nalignment between synthetic image-text pairs in VLM's feature space, we propose\na contrastive distillation loss along with an image-text alignment constraint.\nTo further combat in-distribution overfitting and enhance distillation\nperformance with limited amount of generated data, we incorporate adaptive\nweight consolidation, utilizing Fisher information from these synthetic\nimage-text pairs and achieving a better stability-plasticity balance. Extensive\nexperiments demonstrate that our method consistently outperforms previous\nstate-of-the-art approaches across various settings.\n","authors":["Bin Wu","Wuxuan Shi","Jinqiao Wang","Mang Ye"],"pdf_url":"https://arxiv.org/pdf/2503.04229v1.pdf","comment":"This work is accepted by CVPR 2025. Modifications may be performed"},{"id":"http://arxiv.org/abs/2503.04223v1","updated":"2025-03-06T09:06:06Z","published":"2025-03-06T09:06:06Z","title":"Spiking Meets Attention: Efficient Remote Sensing Image Super-Resolution\n  with Attention Spiking Neural Networks","summary":"  Spiking neural networks (SNNs) are emerging as a promising alternative to\ntraditional artificial neural networks (ANNs), offering biological plausibility\nand energy efficiency. Despite these merits, SNNs are frequently hampered by\nlimited capacity and insufficient representation power, yet remain\nunderexplored in remote sensing super-resolution (SR) tasks. In this paper, we\nfirst observe that spiking signals exhibit drastic intensity variations across\ndiverse textures, highlighting an active learning state of the neurons. This\nobservation motivates us to apply SNNs for efficient SR of RSIs. Inspired by\nthe success of attention mechanisms in representing salient information, we\ndevise the spiking attention block (SAB), a concise yet effective component\nthat optimizes membrane potentials through inferred attention weights, which,\nin turn, regulates spiking activity for superior feature representation. Our\nkey contributions include: 1) we bridge the independent modulation between\ntemporal and channel dimensions, facilitating joint feature correlation\nlearning, and 2) we access the global self-similar patterns in large-scale\nremote sensing imagery to infer spatial attention weights, incorporating\neffective priors for realistic and faithful reconstruction. Building upon SAB,\nwe proposed SpikeSR, which achieves state-of-the-art performance across various\nremote sensing benchmarks such as AID, DOTA, and DIOR, while maintaining high\ncomputational efficiency. The code of SpikeSR will be available upon paper\nacceptance.\n","authors":["Yi Xiao","Qiangqiang Yuan","Kui Jiang","Qiang Zhang","Tingting Zheng","Chia-Wen Lin","Liangpei Zhang"],"pdf_url":"https://arxiv.org/pdf/2503.04223v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.04215v1","updated":"2025-03-06T08:52:29Z","published":"2025-03-06T08:52:29Z","title":"Energy-Guided Optimization for Personalized Image Editing with\n  Pretrained Text-to-Image Diffusion Models","summary":"  The rapid advancement of pretrained text-driven diffusion models has\nsignificantly enriched applications in image generation and editing. However,\nas the demand for personalized content editing increases, new challenges emerge\nespecially when dealing with arbitrary objects and complex scenes. Existing\nmethods usually mistakes mask as the object shape prior, which struggle to\nachieve a seamless integration result. The mostly used inversion noise\ninitialization also hinders the identity consistency towards the target object.\nTo address these challenges, we propose a novel training-free framework that\nformulates personalized content editing as the optimization of edited images in\nthe latent space, using diffusion models as the energy function guidance\nconditioned by reference text-image pairs. A coarse-to-fine strategy is\nproposed that employs text energy guidance at the early stage to achieve a\nnatural transition toward the target class and uses point-to-point\nfeature-level image energy guidance to perform fine-grained appearance\nalignment with the target object. Additionally, we introduce the latent space\ncontent composition to enhance overall identity consistency with the target.\nExtensive experiments demonstrate that our method excels in object replacement\neven with a large domain gap, highlighting its potential for high-quality,\npersonalized image editing.\n","authors":["Rui Jiang","Xinghe Fu","Guangcong Zheng","Teng Li","Taiping Yao","Xi Li"],"pdf_url":"https://arxiv.org/pdf/2503.04215v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2405.07155v3","updated":"2025-03-06T08:51:28Z","published":"2024-05-12T04:18:10Z","title":"Meta-Learned Modality-Weighted Knowledge Distillation for Robust\n  Multi-Modal Learning with Missing Data","summary":"  In multi-modal learning, some modalities are more influential than others,\nand their absence can have a significant impact on classification/segmentation\naccuracy. Addressing this challenge, we propose a novel approach called\nMeta-learned Modality-weighted Knowledge Distillation (MetaKD), which enables\nmulti-modal models to maintain high accuracy even when key modalities are\nmissing. MetaKD adaptively estimates the importance weight of each modality\nthrough a meta-learning process. These learned importance weights guide a\npairwise modality-weighted knowledge distillation process, allowing\nhigh-importance modalities to transfer knowledge to lower-importance ones,\nresulting in robust performance despite missing inputs. Unlike previous methods\nin the field, which are often task-specific and require significant\nmodifications, our approach is designed to work in multiple tasks (e.g.,\nsegmentation and classification) with minimal adaptation. Experimental results\non five prevalent datasets, including three Brain Tumor Segmentation datasets\n(BraTS2018, BraTS2019 and BraTS2020), the Alzheimer's Disease Neuroimaging\nInitiative (ADNI) classification dataset and the Audiovision-MNIST\nclassification dataset, demonstrate the proposed model is able to outperform\nthe compared models by a large margin. The code is available at\nhttps://github.com/billhhh/MetaKD.\n","authors":["Hu Wang","Salma Hassan","Yuyuan Liu","Congbo Ma","Yuanhong Chen","Yutong Xie","Mostafa Salem","Yu Tian","Jodie Avery","Louise Hull","Ian Reid","Mohammad Yaqub","Gustavo Carneiro"],"pdf_url":"https://arxiv.org/pdf/2405.07155v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.04207v1","updated":"2025-03-06T08:31:40Z","published":"2025-03-06T08:31:40Z","title":"Bridging the Vision-Brain Gap with an Uncertainty-Aware Blur Prior","summary":"  Can our brain signals faithfully reflect the original visual stimuli, even\nincluding high-frequency details? Although human perceptual and cognitive\ncapacities enable us to process and remember visual information, these\nabilities are constrained by several factors, such as limited attentional\nresources and the finite capacity of visual memory. When visual stimuli are\nprocessed by human visual system into brain signals, some information is\ninevitably lost, leading to a discrepancy known as the \\textbf{System GAP}.\nAdditionally, perceptual and cognitive dynamics, along with technical noise in\nsignal acquisition, degrade the fidelity of brain signals relative to the\nvisual stimuli, known as the \\textbf{Random GAP}. When encoded brain\nrepresentations are directly aligned with the corresponding pretrained image\nfeatures, the System GAP and Random GAP between paired data challenge the\nmodel, requiring it to bridge these gaps. However, in the context of limited\npaired data, these gaps are difficult for the model to learn, leading to\noverfitting and poor generalization to new data. To address these GAPs, we\npropose a simple yet effective approach called the \\textbf{Uncertainty-aware\nBlur Prior (UBP)}. It estimates the uncertainty within the paired data,\nreflecting the mismatch between brain signals and visual stimuli. Based on this\nuncertainty, UBP dynamically blurs the high-frequency details of the original\nimages, reducing the impact of the mismatch and improving alignment. Our method\nachieves a top-1 accuracy of \\textbf{50.9\\%} and a top-5 accuracy of\n\\textbf{79.7\\%} on the zero-shot brain-to-image retrieval task, surpassing\nprevious state-of-the-art methods by margins of \\textbf{13.7\\%} and\n\\textbf{9.8\\%}, respectively. Code is available at\n\\href{https://github.com/HaitaoWuTJU/Uncertainty-aware-Blur-Prior}{GitHub}.\n","authors":["Haitao Wu","Qing Li","Changqing Zhang","Zhen He","Xiaomin Ying"],"pdf_url":"https://arxiv.org/pdf/2503.04207v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.04205v1","updated":"2025-03-06T08:30:33Z","published":"2025-03-06T08:30:33Z","title":"Learning 3D Medical Image Models From Brain Functional Connectivity\n  Network Supervision For Mental Disorder Diagnosis","summary":"  In MRI-based mental disorder diagnosis, most previous studies focus on\nfunctional connectivity network (FCN) derived from functional MRI (fMRI).\nHowever, the small size of annotated fMRI datasets restricts its wide\napplication. Meanwhile, structural MRIs (sMRIs), such as 3D T1-weighted (T1w)\nMRI, which are commonly used and readily accessible in clinical settings, are\noften overlooked. To integrate the complementary information from both function\nand structure for improved diagnostic accuracy, we propose CINP (Contrastive\nImage-Network Pre-training), a framework that employs contrastive learning\nbetween sMRI and FCN. During pre-training, we incorporate masked image modeling\nand network-image matching to enhance visual representation learning and\nmodality alignment. Since the CINP facilitates knowledge transfer from FCN to\nsMRI, we introduce network prompting. It utilizes only sMRI from suspected\npatients and a small amount of FCNs from different patient classes for\ndiagnosing mental disorders, which is practical in real-world clinical\nscenario. The competitive performance on three mental disorder diagnosis tasks\ndemonstrate the effectiveness of the CINP in integrating multimodal MRI\ninformation, as well as the potential of incorporating sMRI into clinical\ndiagnosis using network prompting.\n","authors":["Xingcan Hu","Wei Wang","Li Xiao"],"pdf_url":"https://arxiv.org/pdf/2503.04205v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.04204v1","updated":"2025-03-06T08:30:18Z","published":"2025-03-06T08:30:18Z","title":"FUSE: First-Order and Second-Order Unified SynthEsis in Stochastic\n  Optimization","summary":"  Stochastic optimization methods have actively been playing a critical role in\nmodern machine learning algorithms to deliver decent performance. While\nnumerous works have proposed and developed diverse approaches, first-order and\nsecond-order methods are in entirely different situations. The former is\nsignificantly pivotal and dominating in emerging deep learning but only leads\nconvergence to a stationary point. However, second-order methods are less\npopular due to their computational intensity in large-dimensional problems.\nThis paper presents a novel method that leverages both the first-order and\nsecond-order methods in a unified algorithmic framework, termed FUSE, from\nwhich a practical version (PV) is derived accordingly. FUSE-PV stands as a\nsimple yet efficient optimization method involving a switch-over between first\nand second orders. Additionally, we develop different criteria that determine\nwhen to switch. FUSE-PV has provably shown a smaller computational complexity\nthan SGD and Adam. To validate our proposed scheme, we present an ablation\nstudy on several simple test functions and show a comparison with baselines for\nbenchmark datasets.\n","authors":["Zhanhong Jiang","Md Zahid Hasan","Aditya Balu","Joshua R. Waite","Genyi Huang","Soumik Sarkar"],"pdf_url":"https://arxiv.org/pdf/2503.04204v1.pdf","comment":"6 pages, 7 figures"},{"id":"http://arxiv.org/abs/2411.13056v2","updated":"2025-03-06T08:28:09Z","published":"2024-11-20T06:08:21Z","title":"Efficient Masked AutoEncoder for Video Object Counting and A Large-Scale\n  Benchmark","summary":"  The dynamic imbalance of the fore-background is a major challenge in video\nobject counting, which is usually caused by the sparsity of target objects.\nThis remains understudied in existing works and often leads to severe\nunder-/over-prediction errors. To tackle this issue in video object counting,\nwe propose a density-embedded Efficient Masked Autoencoder Counting (E-MAC)\nframework in this paper. To empower the model's representation ability on\ndensity regression, we develop a new $\\mathtt{D}$ensity-$\\mathtt{E}$mbedded\n$\\mathtt{M}$asked m$\\mathtt{O}$deling ($\\mathtt{DEMO}$) method, which first\ntakes the density map as an auxiliary modality to perform multimodal\nself-representation learning for image and density map. Although\n$\\mathtt{DEMO}$ contributes to effective cross-modal regression guidance, it\nalso brings in redundant background information, making it difficult to focus\non the foreground regions. To handle this dilemma, we propose an efficient\nspatial adaptive masking derived from density maps to boost efficiency.\nMeanwhile, we employ an optical flow-based temporal collaborative fusion\nstrategy to effectively capture the dynamic variations across frames, aligning\nfeatures to derive multi-frame density residuals. The counting accuracy of the\ncurrent frame is boosted by harnessing the information from adjacent frames. In\naddition, considering that most existing datasets are limited to human-centric\nscenarios, we first propose a large video bird counting dataset, DroneBird, in\nnatural scenarios for migratory bird protection. Extensive experiments on three\ncrowd datasets and our \\textit{DroneBird} validate our superiority against the\ncounterparts. The code and dataset are available.\n","authors":["Bing Cao","Quanhao Lu","Jiekang Feng","Qilong Wang","Qinghua Hu","Pengfei Zhu"],"pdf_url":"https://arxiv.org/pdf/2411.13056v2.pdf","comment":"ICLR25"},{"id":"http://arxiv.org/abs/2503.04199v1","updated":"2025-03-06T08:27:51Z","published":"2025-03-06T08:27:51Z","title":"MASTER: Multimodal Segmentation with Text Prompts","summary":"  RGB-Thermal fusion is a potential solution for various weather and light\nconditions in challenging scenarios. However, plenty of studies focus on\ndesigning complex modules to fuse different modalities. With the widespread\napplication of large language models (LLMs), valuable information can be more\neffectively extracted from natural language. Therefore, we aim to leverage the\nadvantages of large language models to design a structurally simple and highly\nadaptable multimodal fusion model architecture. We proposed MultimodAl\nSegmentation with TExt PRompts (MASTER) architecture, which integrates LLM into\nthe fusion of RGB-Thermal multimodal data and allows complex query text to\nparticipate in the fusion process. Our model utilizes a dual-path structure to\nextract information from different modalities of images. Additionally, we\nemploy LLM as the core module for multimodal fusion, enabling the model to\ngenerate learnable codebook tokens from RGB, thermal images, and textual\ninformation. A lightweight image decoder is used to obtain semantic\nsegmentation results. The proposed MASTER performs exceptionally well in\nbenchmark tests across various automated driving scenarios, yielding promising\nresults.\n","authors":["Fuyang Liu","Shun Lu","Jilin Mei","Yu Hu"],"pdf_url":"https://arxiv.org/pdf/2503.04199v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.04191v1","updated":"2025-03-06T08:06:03Z","published":"2025-03-06T08:06:03Z","title":"Conformal forecasting for surgical instrument trajectory","summary":"  Forecasting surgical instrument trajectories and predicting the next surgical\naction recently started to attract attention from the research community. Both\nthese tasks are crucial for automation and assistance in endoscopy surgery.\nGiven the safety-critical nature of these tasks, reliable uncertainty\nquantification is essential. Conformal prediction is a fast-growing and widely\nrecognized framework for uncertainty estimation in machine learning and\ncomputer vision, offering distribution-free, theoretically valid prediction\nintervals. In this work, we explore the application of standard conformal\nprediction and conformalized quantile regression to estimate uncertainty in\nforecasting surgical instrument motion, i.e., predicting direction and\nmagnitude of surgical instruments' future motion. We analyze and compare their\ncoverage and interval sizes, assessing the impact of multiple hypothesis\ntesting and correction methods. Additionally, we show how these techniques can\nbe employed to produce useful uncertainty heatmaps. To the best of our\nknowledge, this is the first study applying conformal prediction to surgical\nguidance, marking an initial step toward constructing principled prediction\nintervals with formal coverage guarantees in this domain.\n","authors":["Sara Sangalli","Gary Sarwin","Ertunc Erdil","Carlo Serra","Ender Konukoglu"],"pdf_url":"https://arxiv.org/pdf/2503.04191v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.04171v1","updated":"2025-03-06T07:36:45Z","published":"2025-03-06T07:36:45Z","title":"DuCos: Duality Constrained Depth Super-Resolution via Foundation Model","summary":"  We introduce DuCos, a novel depth super-resolution framework grounded in\nLagrangian duality theory, offering a flexible integration of multiple\nconstraints and reconstruction objectives to enhance accuracy and robustness.\nOur DuCos is the first to significantly improve generalization across diverse\nscenarios with foundation models as prompts. The prompt design consists of two\nkey components: Correlative Fusion (CF) and Gradient Regulation (GR). CF\nfacilitates precise geometric alignment and effective fusion between prompt and\ndepth features, while GR refines depth predictions by enforcing consistency\nwith sharp-edged depth maps derived from foundation models. Crucially, these\nprompts are seamlessly embedded into the Lagrangian constraint term, forming a\nsynergistic and principled framework. Extensive experiments demonstrate that\nDuCos outperforms existing state-of-the-art methods, achieving superior\naccuracy, robustness, and generalization. The source codes and pre-trained\nmodels will be publicly available.\n","authors":["Zhiqiang Yan","Zhengxue Wang","Haoye Dong","Jun Li","Jian Yang","Gim Hee Lee"],"pdf_url":"https://arxiv.org/pdf/2503.04171v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.04167v1","updated":"2025-03-06T07:29:33Z","published":"2025-03-06T07:29:33Z","title":"The Role of Visual Modality in Multimodal Mathematical Reasoning:\n  Challenges and Insights","summary":"  Recent research has increasingly focused on multimodal mathematical\nreasoning, particularly emphasizing the creation of relevant datasets and\nbenchmarks. Despite this, the role of visual information in reasoning has been\nunderexplored. Our findings show that existing multimodal mathematical models\nminimally leverage visual information, and model performance remains largely\nunaffected by changes to or removal of images in the dataset. We attribute this\nto the dominance of textual information and answer options that inadvertently\nguide the model to correct answers. To improve evaluation methods, we introduce\nthe HC-M3D dataset, specifically designed to require image reliance for\nproblem-solving and to challenge models with similar, yet distinct, images that\nchange the correct answer. In testing leading models, their failure to detect\nthese subtle visual differences suggests limitations in current visual\nperception capabilities. Additionally, we observe that the common approach of\nimproving general VQA capabilities by combining various types of image encoders\ndoes not contribute to math reasoning performance. This finding also presents a\nchallenge to enhancing visual reliance during math reasoning. Our benchmark and\ncode would be available at\n\\href{https://github.com/Yufang-Liu/visual_modality_role}{https://github.com/Yufang-Liu/visual\\_modality\\_role}.\n","authors":["Yufang Liu","Yao Du","Tao Ji","Jianing Wang","Yang Liu","Yuanbin Wu","Aimin Zhou","Mengdi Zhang","Xunliang Cai"],"pdf_url":"https://arxiv.org/pdf/2503.04167v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.11505v4","updated":"2025-03-06T07:26:35Z","published":"2024-11-18T12:05:27Z","title":"LaVin-DiT: Large Vision Diffusion Transformer","summary":"  This paper presents the Large Vision Diffusion Transformer (LaVin-DiT), a\nscalable and unified foundation model designed to tackle over 20 computer\nvision tasks in a generative framework. Unlike existing large vision models\ndirectly adapted from natural language processing architectures, which rely on\nless efficient autoregressive techniques and disrupt spatial relationships\nessential for vision data, LaVin-DiT introduces key innovations to optimize\ngenerative performance for vision tasks. First, to address the high\ndimensionality of visual data, we incorporate a spatial-temporal variational\nautoencoder that encodes data into a continuous latent space. Second, for\ngenerative modeling, we develop a joint diffusion transformer that\nprogressively produces vision outputs. Third, for unified multi-task training,\nin-context learning is implemented. Input-target pairs serve as task context,\nwhich guides the diffusion transformer to align outputs with specific tasks\nwithin the latent space. During inference, a task-specific context set and test\ndata as queries allow LaVin-DiT to generalize across tasks without fine-tuning.\nTrained on extensive vision datasets, the model is scaled from 0.1B to 3.4B\nparameters, demonstrating substantial scalability and state-of-the-art\nperformance across diverse vision tasks. This work introduces a novel pathway\nfor large vision foundation models, underscoring the promising potential of\ndiffusion transformers. The code and models are available.\n","authors":["Zhaoqing Wang","Xiaobo Xia","Runnan Chen","Dongdong Yu","Changhu Wang","Mingming Gong","Tongliang Liu"],"pdf_url":"https://arxiv.org/pdf/2411.11505v4.pdf","comment":"37 pages, 30 figures, 4 tables. Accepted by CVPR 2025"},{"id":"http://arxiv.org/abs/2503.04165v1","updated":"2025-03-06T07:25:43Z","published":"2025-03-06T07:25:43Z","title":"WeakSupCon: Weakly Supervised Contrastive Learning for Encoder\n  Pre-training","summary":"  Weakly supervised multiple instance learning (MIL) is a challenging task\ngiven that only bag-level labels are provided, while each bag typically\ncontains multiple instances. This topic has been extensively studied in\nhistopathological image analysis, where labels are usually available only at\nthe whole slide image (WSI) level, while each whole slide image can be divided\ninto thousands of small image patches for training. The dominant MIL approaches\ntake fixed patch features as inputs to address computational constraints and\nensure model stability. These features are commonly generated by encoders\npre-trained on ImageNet, foundation encoders pre-trained on large datasets, or\nthrough self-supervised learning on local datasets. While the self-supervised\nencoder pre-training on the same dataset as downstream MIL tasks helps mitigate\ndomain shift and generate better features, the bag-level labels are not\nutilized during the process, and the features of patches from different\ncategories may cluster together, reducing classification performance on MIL\ntasks. Recently, pre-training with supervised contrastive learning (SupCon) has\ndemonstrated superior performance compared to self-supervised contrastive\nlearning and even end-to-end training on traditional image classification\ntasks. In this paper, we propose a novel encoder pre-training method for\ndownstream MIL tasks called Weakly Supervised Contrastive Learning (WeakSupCon)\nthat utilizes bag-level labels. In our method, we employ multi-task learning\nand define distinct contrastive learning losses for samples with different bag\nlabels. Our experiments demonstrate that the features generated using\nWeakSupCon significantly enhance MIL classification performance compared to\nself-supervised approaches across three datasets.\n","authors":["Bodong Zhang","Hamid Manoochehri","Beatrice S. Knudsen","Tolga Tasdizen"],"pdf_url":"https://arxiv.org/pdf/2503.04165v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.01234v2","updated":"2025-03-06T07:11:32Z","published":"2025-03-03T06:57:54Z","title":"Self-Adaptive Gamma Context-Aware SSM-based Model for Metal Defect\n  Detection","summary":"  Metal defect detection is critical in industrial quality assurance, yet\nexisting methods struggle with grayscale variations and complex defect states,\nlimiting its robustness. To address these challenges, this paper proposes a\nSelf-Adaptive Gamma Context-Aware SSM-based model(GCM-DET). This advanced\ndetection framework integrating a Dynamic Gamma Correction (GC) module to\nenhance grayscale representation and optimize feature extraction for precise\ndefect reconstruction. A State-Space Search Management (SSM) architecture\ncaptures robust multi-scale features, effectively handling defects of varying\nshapes and scales. Focal Loss is employed to mitigate class imbalance and\nrefine detection accuracy. Additionally, the CD5-DET dataset is introduced,\nspecifically designed for port container maintenance, featuring significant\ngrayscale variations and intricate defect patterns. Experimental results\ndemonstrate that the proposed model achieves substantial improvements, with\nmAP@0.5 gains of 27.6\\%, 6.6\\%, and 2.6\\% on the CD5-DET, NEU-DET, and GC10-DET\ndatasets.\n","authors":["Sijin Sun","Ming Deng","Xingrui Yu","Xinyu Xi","Liangbin Zhao"],"pdf_url":"https://arxiv.org/pdf/2503.01234v2.pdf","comment":"19 pages, 9 figures, under review"},{"id":"http://arxiv.org/abs/2410.14595v2","updated":"2025-03-06T07:06:50Z","published":"2024-10-18T16:48:31Z","title":"DRACO-DehazeNet: An Efficient Image Dehazing Network Combining Detail\n  Recovery and a Novel Contrastive Learning Paradigm","summary":"  Image dehazing is crucial for clarifying images obscured by haze or fog, but\ncurrent learning-based approaches is dependent on large volumes of training\ndata and hence consumed significant computational power. Additionally, their\nperformance is often inadequate under non-uniform or heavy haze. To address\nthese challenges, we developed the Detail Recovery And Contrastive DehazeNet,\nwhich facilitates efficient and effective dehazing via a dense dilated inverted\nresidual block and an attention-based detail recovery network that tailors\nenhancements to specific dehazed scene contexts. A major innovation is its\nability to train effectively with limited data, achieved through a novel\nquadruplet loss-based contrastive dehazing paradigm. This approach distinctly\nseparates hazy and clear image features while also distinguish lower-quality\nand higher-quality dehazed images obtained from each sub-modules of our\nnetwork, thereby refining the dehazing process to a larger extent. Extensive\ntests on a variety of benchmarked haze datasets demonstrated the superiority of\nour approach. The code repository for this work is available at\nhttps://github.com/GreedYLearner1146/DRACO-DehazeNet.\n","authors":["Gao Yu Lee","Tanmoy Dam","Md Meftahul Ferdaus","Daniel Puiu Poenar","Vu Duong"],"pdf_url":"https://arxiv.org/pdf/2410.14595v2.pdf","comment":"Once the paper is accepted and published, the copyright will be\n  transferred to the corresponding journal"},{"id":"http://arxiv.org/abs/2503.04154v1","updated":"2025-03-06T07:02:13Z","published":"2025-03-06T07:02:13Z","title":"CA-W3D: Leveraging Context-Aware Knowledge for Weakly Supervised\n  Monocular 3D Detection","summary":"  Weakly supervised monocular 3D detection, while less annotation-intensive,\noften struggles to capture the global context required for reliable 3D\nreasoning. Conventional label-efficient methods focus on object-centric\nfeatures, neglecting contextual semantic relationships that are critical in\ncomplex scenes. In this work, we propose a Context-Aware Weak Supervision for\nMonocular 3D object detection, namely CA-W3D, to address this limitation in a\ntwo-stage training paradigm. Specifically, we first introduce a pre-training\nstage employing Region-wise Object Contrastive Matching (ROCM), which aligns\nregional object embeddings derived from a trainable monocular 3D encoder and a\nfrozen open-vocabulary 2D visual grounding model. This alignment encourages the\nmonocular encoder to discriminate scene-specific attributes and acquire richer\ncontextual knowledge. In the second stage, we incorporate a pseudo-label\ntraining process with a Dual-to-One Distillation (D2OD) mechanism, which\neffectively transfers contextual priors into the monocular encoder while\npreserving spatial fidelity and maintaining computational efficiency during\ninference. Extensive experiments conducted on the public KITTI benchmark\ndemonstrate the effectiveness of our approach, surpassing the SoTA method over\nall metrics, highlighting the importance of contextual-aware knowledge in\nweakly-supervised monocular 3D detection.\n","authors":["Chupeng Liu","Runkai Zhao","Weidong Cai"],"pdf_url":"https://arxiv.org/pdf/2503.04154v1.pdf","comment":"The paper includes 8 pages, 6 figures and 4 tables"},{"id":"http://arxiv.org/abs/2503.04151v1","updated":"2025-03-06T07:01:08Z","published":"2025-03-06T07:01:08Z","title":"Robust Multi-View Learning via Representation Fusion of Sample-Level\n  Attention and Alignment of Simulated Perturbation","summary":"  Recently, multi-view learning (MVL) has garnered significant attention due to\nits ability to fuse discriminative information from multiple views. However,\nreal-world multi-view datasets are often heterogeneous and imperfect, which\nusually makes MVL methods designed for specific combinations of views lack\napplication potential and limits their effectiveness. To address this issue, we\npropose a novel robust MVL method (namely RML) with simultaneous representation\nfusion and alignment. Specifically, we introduce a simple yet effective\nmulti-view transformer fusion network where we transform heterogeneous\nmulti-view data into homogeneous word embeddings, and then integrate multiple\nviews by the sample-level attention mechanism to obtain a fused representation.\nFurthermore, we propose a simulated perturbation based multi-view contrastive\nlearning framework that dynamically generates the noise and unusable\nperturbations for simulating imperfect data conditions. The simulated noisy and\nunusable data obtain two distinct fused representations, and we utilize\ncontrastive learning to align them for learning discriminative and robust\nrepresentations. Our RML is self-supervised and can also be applied for\ndownstream tasks as a regularization. In experiments, we employ it in\nunsupervised multi-view clustering, noise-label classification, and as a\nplug-and-play module for cross-modal hashing retrieval. Extensive comparison\nexperiments and ablation studies validate the effectiveness of RML.\n","authors":["Jie Xu","Na Zhao","Gang Niu","Masashi Sugiyama","Xiaofeng Zhu"],"pdf_url":"https://arxiv.org/pdf/2503.04151v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2307.04014v3","updated":"2025-03-06T06:55:15Z","published":"2023-07-08T16:46:16Z","title":"Novel Pipeline for Diagnosing Acute Lymphoblastic Leukemia Sensitive to\n  Related Biomarkers","summary":"  Acute Lymphoblastic Leukemia (ALL) is one of the most common types of\nchildhood blood cancer. The quick start of the treatment process is critical to\nsaving the patient's life, and for this reason, early diagnosis of this disease\nis essential. Examining the blood smear images of these patients is one of the\nmethods used by expert doctors to diagnose this disease. Deep learning-based\nmethods have numerous applications in medical fields, as they have\nsignificantly advanced in recent years. ALL diagnosis is not an exception in\nthis field, and several machine learning-based methods for this problem have\nbeen proposed. In previous methods, high diagnostic accuracy was reported, but\nour work showed that this alone is not sufficient, as it can lead to models\ntaking shortcuts and not making meaningful decisions. This issue arises due to\nthe small size of medical training datasets. To address this, we constrained\nour model to follow a pipeline inspired by experts' work. We also demonstrated\nthat, since a judgement based on only one image is insufficient, redefining the\nproblem as a multiple-instance learning problem is necessary for achieving a\npractical result. Our model is the first to provide a solution to this problem\nin a multiple-instance learning setup. We introduced a novel pipeline for\ndiagnosing ALL that approximates the process used by hematologists, is\nsensitive to disease biomarkers, and achieves an accuracy of 96.15%, an\nF1-score of 94.24%, a sensitivity of 97.56%, and a specificity of 90.91% on ALL\nIDB 1. Our method was further evaluated on an out-of-distribution dataset,\nwhich posed a challenging test and had acceptable performance. Notably, our\nmodel was trained on a relatively small dataset, highlighting the potential for\nour approach to be applied to other medical datasets with limited data\navailability.\n","authors":["Amirhossein Askari Farsangi","Ali Sharifi-Zarchi","Mohammad Hossein Rohban"],"pdf_url":"https://arxiv.org/pdf/2307.04014v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.04144v1","updated":"2025-03-06T06:41:38Z","published":"2025-03-06T06:41:38Z","title":"DM-Adapter: Domain-Aware Mixture-of-Adapters for Text-Based Person\n  Retrieval","summary":"  Text-based person retrieval (TPR) has gained significant attention as a\nfine-grained and challenging task that closely aligns with practical\napplications. Tailoring CLIP to person domain is now a emerging research topic\ndue to the abundant knowledge of vision-language pretraining, but challenges\nstill remain during fine-tuning: (i) Previous full-model fine-tuning in TPR is\ncomputationally expensive and prone to overfitting.(ii) Existing\nparameter-efficient transfer learning (PETL) for TPR lacks of fine-grained\nfeature extraction. To address these issues, we propose Domain-Aware\nMixture-of-Adapters (DM-Adapter), which unifies Mixture-of-Experts (MOE) and\nPETL to enhance fine-grained feature representations while maintaining\nefficiency. Specifically, Sparse Mixture-of-Adapters is designed in parallel to\nMLP layers in both vision and language branches, where different experts\nspecialize in distinct aspects of person knowledge to handle features more\nfinely. To promote the router to exploit domain information effectively and\nalleviate the routing imbalance, Domain-Aware Router is then developed by\nbuilding a novel gating function and injecting learnable domain-aware prompts.\nExtensive experiments show that our DM-Adapter achieves state-of-the-art\nperformance, outperforming previous methods by a significant margin.\n","authors":["Yating Liu","Zimo Liu","Xiangyuan Lan","Wenming Yang","Yaowei Li","Qingmin Liao"],"pdf_url":"https://arxiv.org/pdf/2503.04144v1.pdf","comment":"9 pages, 5 figures, accepted by AAAI 2025"},{"id":"http://arxiv.org/abs/2503.04139v1","updated":"2025-03-06T06:35:19Z","published":"2025-03-06T06:35:19Z","title":"Robust Computer-Vision based Construction Site Detection for\n  Assistive-Technology Applications","summary":"  Navigating urban environments poses significant challenges for people with\ndisabilities, particularly those with blindness and low vision. Environments\nwith dynamic and unpredictable elements like construction sites are especially\nchallenging. Construction sites introduce hazards like uneven surfaces,\nobstructive barriers, hazardous materials, and excessive noise, and they can\nalter routing, complicating safe mobility. Existing assistive technologies are\nlimited, as navigation apps do not account for construction sites during trip\nplanning, and detection tools that attempt hazard recognition struggle to\naddress the extreme variability of construction paraphernalia. This study\nintroduces a novel computer vision-based system that integrates open-vocabulary\nobject detection, a YOLO-based scaffolding-pole detection model, and an optical\ncharacter recognition (OCR) module to comprehensively identify and interpret\nconstruction site elements for assistive navigation. In static testing across\nseven construction sites, the system achieved an overall accuracy of 88.56\\%,\nreliably detecting objects from 2m to 10m within a 0$^\\circ$ -- 75$^\\circ$\nangular offset. At closer distances (2--4m), the detection rate was 100\\% at\nall tested angles. At\n","authors":["Junchi Feng","Giles Hamilton-Fletcher","Nikhil Ballem","Michael Batavia","Yifei Wang","Jiuling Zhong","Maurizio Porfiri","John-Ross Rizzo"],"pdf_url":"https://arxiv.org/pdf/2503.04139v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.04134v1","updated":"2025-03-06T06:26:57Z","published":"2025-03-06T06:26:57Z","title":"Real-time Spatial-temporal Traversability Assessment via Feature-based\n  Sparse Gaussian Process","summary":"  Terrain analysis is critical for the practical application of ground mobile\nrobots in real-world tasks, especially in outdoor unstructured environments. In\nthis paper, we propose a novel spatial-temporal traversability assessment\nmethod, which aims to enable autonomous robots to effectively navigate through\ncomplex terrains. Our approach utilizes sparse Gaussian processes (SGP) to\nextract geometric features (curvature, gradient, elevation, etc.) directly from\npoint cloud scans. These features are then used to construct a high-resolution\nlocal traversability map. Then, we design a spatial-temporal Bayesian Gaussian\nkernel (BGK) inference method to dynamically evaluate traversability scores,\nintegrating historical and real-time data while considering factors such as\nslope, flatness, gradient, and uncertainty metrics. GPU acceleration is applied\nin the feature extraction step, and the system achieves real-time performance.\nExtensive simulation experiments across diverse terrain scenarios demonstrate\nthat our method outperforms SOTA approaches in both accuracy and computational\nefficiency. Additionally, we develop an autonomous navigation framework\nintegrated with the traversability map and validate it with a differential\ndriven vehicle in complex outdoor environments. Our code will be open-source\nfor further research and development by the community,\nhttps://github.com/ZJU-FAST-Lab/FSGP_BGK.\n","authors":["Senming Tan","Zhenyu Hou","Zhihao Zhang","Long Xu","Mengke Zhang","Zhaoqi He","Chao Xu","Fei Gao","Yanjun Cao"],"pdf_url":"https://arxiv.org/pdf/2503.04134v1.pdf","comment":"8 pages, 10 figures"},{"id":"http://arxiv.org/abs/2503.04131v1","updated":"2025-03-06T06:24:51Z","published":"2025-03-06T06:24:51Z","title":"Q-PART: Quasi-Periodic Adaptive Regression with Test-time Training for\n  Pediatric Left Ventricular Ejection Fraction Regression","summary":"  In this work, we address the challenge of adaptive pediatric Left Ventricular\nEjection Fraction (LVEF) assessment. While Test-time Training (TTT) approaches\nshow promise for this task, they suffer from two significant limitations.\nExisting TTT works are primarily designed for classification tasks rather than\ncontinuous value regression, and they lack mechanisms to handle the\nquasi-periodic nature of cardiac signals. To tackle these issues, we propose a\nnovel \\textbf{Q}uasi-\\textbf{P}eriodic \\textbf{A}daptive \\textbf{R}egression\nwith \\textbf{T}est-time Training (Q-PART) framework. In the training stage, the\nproposed Quasi-Period Network decomposes the echocardiogram into periodic and\naperiodic components within latent space by combining parameterized helix\ntrajectories with Neural Controlled Differential Equations. During inference,\nour framework further employs a variance minimization strategy across image\naugmentations that simulate common quality issues in echocardiogram\nacquisition, along with differential adaptation rates for periodic and\naperiodic components. Theoretical analysis is provided to demonstrate that our\nvariance minimization objective effectively bounds the regression error under\nmild conditions. Furthermore, extensive experiments across three pediatric age\ngroups demonstrate that Q-PART not only significantly outperforms existing\napproaches in pediatric LVEF prediction, but also exhibits strong clinical\nscreening capability with high mAUROC scores (up to 0.9747) and maintains\ngender-fair performance across all metrics, validating its robustness and\npractical utility in pediatric echocardiography analysis.\n","authors":["Jie Liu","Tiexin Qin","Hui Liu","Yilei Shi","Lichao Mou","Xiao Xiang Zhu","Shiqi Wang","Haoliang Li"],"pdf_url":"https://arxiv.org/pdf/2503.04131v1.pdf","comment":"Accepted to CVPR 2025"},{"id":"http://arxiv.org/abs/2503.04130v1","updated":"2025-03-06T06:17:38Z","published":"2025-03-06T06:17:38Z","title":"Token-Efficient Long Video Understanding for Multimodal LLMs","summary":"  Recent advances in video-based multimodal large language models (Video-LLMs)\nhave significantly improved video understanding by processing videos as\nsequences of image frames. However, many existing methods treat frames\nindependently in the vision backbone, lacking explicit temporal modeling, which\nlimits their ability to capture dynamic patterns and efficiently handle long\nvideos. To address these limitations, we introduce STORM\n(\\textbf{S}patiotemporal \\textbf{TO}ken \\textbf{R}eduction for\n\\textbf{M}ultimodal LLMs), a novel architecture incorporating a dedicated\ntemporal encoder between the image encoder and the LLM. Our temporal encoder\nleverages the Mamba State Space Model to integrate temporal information into\nimage tokens, generating enriched representations that preserve inter-frame\ndynamics across the entire video sequence. This enriched encoding not only\nenhances video reasoning capabilities but also enables effective token\nreduction strategies, including test-time sampling and training-based temporal\nand spatial pooling, substantially reducing computational demands on the LLM\nwithout sacrificing key temporal information. By integrating these techniques,\nour approach simultaneously reduces training and inference latency while\nimproving performance, enabling efficient and robust video understanding over\nextended temporal contexts. Extensive evaluations show that STORM achieves\nstate-of-the-art results across various long video understanding benchmarks\n(more than 5\\% improvement on MLVU and LongVideoBench) while reducing the\ncomputation costs by up to $8\\times$ and the decoding latency by\n2.4-2.9$\\times$ for the fixed numbers of input frames. Project page is\navailable at https://research.nvidia.com/labs/lpr/storm\n","authors":["Jindong Jiang","Xiuyu Li","Zhijian Liu","Muyang Li","Guo Chen","Zhiqi Li","De-An Huang","Guilin Liu","Zhiding Yu","Kurt Keutzer","Sungjin Ahn","Jan Kautz","Hongxu Yin","Yao Lu","Song Han","Wonmin Byeon"],"pdf_url":"https://arxiv.org/pdf/2503.04130v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.04127v1","updated":"2025-03-06T06:13:27Z","published":"2025-03-06T06:13:27Z","title":"Diff-Reg v2: Diffusion-Based Matching Matrix Estimation for Image\n  Matching and 3D Registration","summary":"  Establishing reliable correspondences is crucial for all registration tasks,\nincluding 2D image registration, 3D point cloud registration, and 2D-3D\nimage-to-point cloud registration. However, these tasks are often complicated\nby challenges such as scale inconsistencies, symmetry, and large deformations,\nwhich can lead to ambiguous matches. Previous feature-based and\ncorrespondence-based methods typically rely on geometric or semantic features\nto generate or polish initial potential correspondences. Some methods typically\nleverage specific geometric priors, such as topological preservation, to devise\ndiverse and innovative strategies tailored to a given enhancement goal, which\ncannot be exhaustively enumerated. Additionally, many previous approaches rely\non a single-step prediction head, which can struggle with local minima in\ncomplex matching scenarios. To address these challenges, we introduce an\ninnovative paradigm that leverages a diffusion model in matrix space for robust\nmatching matrix estimation. Our model treats correspondence estimation as a\ndenoising diffusion process in the matching matrix space, gradually refining\nthe intermediate matching matrix to the optimal one. Specifically, we apply the\ndiffusion model in the doubly stochastic matrix space for 3D-3D and 2D-3D\nregistration tasks. In the 2D image registration task, we deploy the diffusion\nmodel in a matrix subspace where dual-softmax projection regularization is\napplied. For all three registration tasks, we provide adaptive matching matrix\nembedding implementations tailored to the specific characteristics of each task\nwhile maintaining a consistent \"match-to-warp\" encoding pattern. Furthermore,\nwe adopt a lightweight design for the denoising module. In inference, once\npoints or image features are extracted and fixed, this module performs\nmulti-step denoising predictions through reverse sampling.\n","authors":["Qianliang Wu","Haobo Jiang","Yaqing Ding","Lei Luo","Jin Xie","Jian Yang"],"pdf_url":"https://arxiv.org/pdf/2503.04127v1.pdf","comment":"arXiv admin note: text overlap with arXiv:2403.19919"},{"id":"http://arxiv.org/abs/2503.04126v1","updated":"2025-03-06T06:10:21Z","published":"2025-03-06T06:10:21Z","title":"DVM-SLAM: Decentralized Visual Monocular Simultaneous Localization and\n  Mapping for Multi-Agent Systems","summary":"  Cooperative Simultaneous Localization and Mapping (C-SLAM) enables multiple\nagents to work together in mapping unknown environments while simultaneously\nestimating their own positions. This approach enhances robustness, scalability,\nand accuracy by sharing information between agents, reducing drift, and\nenabling collective exploration of larger areas. In this paper, we present\nDecentralized Visual Monocular SLAM (DVM-SLAM), the first open-source\ndecentralized monocular C-SLAM system. By only utilizing low-cost and\nlight-weight monocular vision sensors, our system is well suited for small\nrobots and micro aerial vehicles (MAVs). DVM-SLAM's real-world applicability is\nvalidated on physical robots with a custom collision avoidance framework,\nshowcasing its potential in real-time multi-agent autonomous navigation\nscenarios. We also demonstrate comparable accuracy to state-of-the-art\ncentralized monocular C-SLAM systems. We open-source our code and provide\nsupplementary material online.\n","authors":["Joshua Bird","Jan Blumenkamp","Amanda Prorok"],"pdf_url":"https://arxiv.org/pdf/2503.04126v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.04123v1","updated":"2025-03-06T06:00:55Z","published":"2025-03-06T06:00:55Z","title":"GAGrasp: Geometric Algebra Diffusion for Dexterous Grasping","summary":"  We propose GAGrasp, a novel framework for dexterous grasp generation that\nleverages geometric algebra representations to enforce equivariance to SE(3)\ntransformations. By encoding the SE(3) symmetry constraint directly into the\narchitecture, our method improves data and parameter efficiency while enabling\nrobust grasp generation across diverse object poses. Additionally, we\nincorporate a differentiable physics-informed refinement layer, which ensures\nthat generated grasps are physically plausible and stable. Extensive\nexperiments demonstrate the model's superior performance in generalization,\nstability, and adaptability compared to existing methods. Additional details at\nhttps://gagrasp.github.io/\n","authors":["Tao Zhong","Christine Allen-Blanchette"],"pdf_url":"https://arxiv.org/pdf/2503.04123v1.pdf","comment":"Accepted at ICRA 2025"},{"id":"http://arxiv.org/abs/2503.00675v2","updated":"2025-03-06T05:59:08Z","published":"2025-03-02T00:40:50Z","title":"Dur360BEV: A Real-world 360-degree Single Camera Dataset and Benchmark\n  for Bird-Eye View Mapping in Autonomous Driving","summary":"  We present Dur360BEV, a novel spherical camera autonomous driving dataset\nequipped with a high-resolution 128-channel 3D LiDAR and a RTK-refined GNSS/INS\nsystem, along with a benchmark architecture designed to generate Bird-Eye-View\n(BEV) maps using only a single spherical camera. This dataset and benchmark\naddress the challenges of BEV generation in autonomous driving, particularly by\nreducing hardware complexity through the use of a single 360-degree camera\ninstead of multiple perspective cameras. Within our benchmark architecture, we\npropose a novel spherical-image-to-BEV module that leverages spherical imagery\nand a refined sampling strategy to project features from 2D to 3D. Our approach\nalso includes an innovative application of focal loss, specifically adapted to\naddress the extreme class imbalance often encountered in BEV segmentation\ntasks, that demonstrates improved segmentation performance on the Dur360BEV\ndataset. The results show that our benchmark not only simplifies the sensor\nsetup but also achieves competitive performance.\n","authors":["Wenke E","Chao Yuan","Li Li","Yixin Sun","Yona Falinie A. Gaus","Amir Atapour-Abarghouei","Toby P. Breckon"],"pdf_url":"https://arxiv.org/pdf/2503.00675v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.04121v1","updated":"2025-03-06T05:58:41Z","published":"2025-03-06T05:58:41Z","title":"Simple Self Organizing Map with Visual Transformer","summary":"  Vision Transformers (ViTs) have demonstrated exceptional performance in\nvarious vision tasks. However, they tend to underperform on smaller datasets\ndue to their inherent lack of inductive biases. Current approaches address this\nlimitation implicitly-often by pairing ViTs with pretext tasks or by distilling\nknowledge from convolutional neural networks (CNNs) to strengthen the prior. In\ncontrast, Self-Organizing Maps (SOMs), a widely adopted self-supervised\nframework, are inherently structured to preserve topology and spatial\norganization, making them a promising candidate to directly address the\nlimitations of ViTs in limited or small training datasets. Despite this\npotential, equipping SOMs with modern deep learning architectures remains\nlargely unexplored. In this study, we conduct a novel exploration on how Vision\nTransformers (ViTs) and Self-Organizing Maps (SOMs) can empower each other,\naiming to bridge this critical research gap. Our findings demonstrate that\nthese architectures can synergistically enhance each other, leading to\nsignificantly improved performance in both unsupervised and supervised tasks.\nCode will be publicly available.\n","authors":["Alan Luo","Kaiwen Yuan"],"pdf_url":"https://arxiv.org/pdf/2503.04121v1.pdf","comment":"5 pages, 4 figures. Submitted to IEEE. All experiments and code work\n  were performed by the first author, with the second author serving in a\n  PI/mentor role, guiding the progression of the work"},{"id":"http://arxiv.org/abs/2503.04119v1","updated":"2025-03-06T05:56:25Z","published":"2025-03-06T05:56:25Z","title":"SCSA: A Plug-and-Play Semantic Continuous-Sparse Attention for Arbitrary\n  Semantic Style Transfer","summary":"  Attention-based arbitrary style transfer methods, including CNN-based,\nTransformer-based, and Diffusion-based, have flourished and produced\nhigh-quality stylized images. However, they perform poorly on the content and\nstyle images with the same semantics, i.e., the style of the corresponding\nsemantic region of the generated stylized image is inconsistent with that of\nthe style image. We argue that the root cause lies in their failure to consider\nthe relationship between local regions and semantic regions. To address this\nissue, we propose a plug-and-play semantic continuous-sparse attention, dubbed\nSCSA, for arbitrary semantic style transfer -- each query point considers\ncertain key points in the corresponding semantic region. Specifically, semantic\ncontinuous attention ensures each query point fully attends to all the\ncontinuous key points in the same semantic region that reflect the overall\nstyle characteristics of that region; Semantic sparse attention allows each\nquery point to focus on the most similar sparse key point in the same semantic\nregion that exhibits the specific stylistic texture of that region. By\ncombining the two modules, the resulting SCSA aligns the overall style of the\ncorresponding semantic regions while transferring the vivid textures of these\nregions. Qualitative and quantitative results prove that SCSA enables\nattention-based arbitrary style transfer methods to produce high-quality\nsemantic stylized images.\n","authors":["Chunnan Shang","Zhizhong Wang","Hongwei Wang","Xiangming Meng"],"pdf_url":"https://arxiv.org/pdf/2503.04119v1.pdf","comment":"Accepted by CVPR 2025"},{"id":"http://arxiv.org/abs/2410.24185v2","updated":"2025-03-06T05:34:17Z","published":"2024-10-31T17:48:45Z","title":"DexMimicGen: Automated Data Generation for Bimanual Dexterous\n  Manipulation via Imitation Learning","summary":"  Imitation learning from human demonstrations is an effective means to teach\nrobots manipulation skills. But data acquisition is a major bottleneck in\napplying this paradigm more broadly, due to the amount of cost and human effort\ninvolved. There has been significant interest in imitation learning for\nbimanual dexterous robots, like humanoids. Unfortunately, data collection is\neven more challenging here due to the challenges of simultaneously controlling\nmultiple arms and multi-fingered hands. Automated data generation in simulation\nis a compelling, scalable alternative to fuel this need for data. To this end,\nwe introduce DexMimicGen, a large-scale automated data generation system that\nsynthesizes trajectories from a handful of human demonstrations for humanoid\nrobots with dexterous hands. We present a collection of simulation environments\nin the setting of bimanual dexterous manipulation, spanning a range of\nmanipulation behaviors and different requirements for coordination among the\ntwo arms. We generate 21K demos across these tasks from just 60 source human\ndemos and study the effect of several data generation and policy learning\ndecisions on agent performance. Finally, we present a real-to-sim-to-real\npipeline and deploy it on a real-world humanoid can sorting task. Generated\ndatasets, simulation environments and additional results are at\nhttps://dexmimicgen.github.io/\n","authors":["Zhenyu Jiang","Yuqi Xie","Kevin Lin","Zhenjia Xu","Weikang Wan","Ajay Mandlekar","Linxi Fan","Yuke Zhu"],"pdf_url":"https://arxiv.org/pdf/2410.24185v2.pdf","comment":"ICRA 2025. Project website: https://dexmimicgen.github.io/"},{"id":"http://arxiv.org/abs/2503.04107v1","updated":"2025-03-06T05:29:20Z","published":"2025-03-06T05:29:20Z","title":"Fractional Correspondence Framework in Detection Transformer","summary":"  The Detection Transformer (DETR), by incorporating the Hungarian algorithm,\nhas significantly simplified the matching process in object detection tasks.\nThis algorithm facilitates optimal one-to-one matching of predicted bounding\nboxes to ground-truth annotations during training. While effective, this strict\nmatching process does not inherently account for the varying densities and\ndistributions of objects, leading to suboptimal correspondences such as failing\nto handle multiple detections of the same object or missing small objects. To\naddress this, we propose the Regularized Transport Plan (RTP). RTP introduces a\nflexible matching strategy that captures the cost of aligning predictions with\nground truths to find the most accurate correspondences between these sets. By\nutilizing the differentiable Sinkhorn algorithm, RTP allows for soft,\nfractional matching rather than strict one-to-one assignments. This approach\nenhances the model's capability to manage varying object densities and\ndistributions effectively. Our extensive evaluations on the MS-COCO and VOC\nbenchmarks demonstrate the effectiveness of our approach. RTP-DETR, surpassing\nthe performance of the Deform-DETR and the recently introduced DINO-DETR,\nachieving absolute gains in mAP of +3.8% and +1.7%, respectively.\n","authors":["Masoumeh Zareapoor","Pourya Shamsolmoali","Huiyu Zhou","Yue Lu","Salvador Garca"],"pdf_url":"https://arxiv.org/pdf/2503.04107v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.04106v1","updated":"2025-03-06T05:28:44Z","published":"2025-03-06T05:28:44Z","title":"WeakMedSAM: Weakly-Supervised Medical Image Segmentation via SAM with\n  Sub-Class Exploration and Prompt Affinity Mining","summary":"  We have witnessed remarkable progress in foundation models in vision tasks.\nCurrently, several recent works have utilized the segmenting anything model\n(SAM) to boost the segmentation performance in medical images, where most of\nthem focus on training an adaptor for fine-tuning a large amount of pixel-wise\nannotated medical images following a fully supervised manner. In this paper, to\nreduce the labeling cost, we investigate a novel weakly-supervised SAM-based\nsegmentation model, namely WeakMedSAM. Specifically, our proposed WeakMedSAM\ncontains two modules: 1) to mitigate severe co-occurrence in medical images, a\nsub-class exploration module is introduced to learn accurate feature\nrepresentations. 2) to improve the quality of the class activation maps, our\nprompt affinity mining module utilizes the prompt capability of SAM to obtain\nan affinity map for random-walk refinement. Our method can be applied to any\nSAM-like backbone, and we conduct experiments with SAMUS and EfficientSAM. The\nexperimental results on three popularly-used benchmark datasets, i.e., BraTS\n2019, AbdomenCT-1K, and MSD Cardiac dataset, show the promising results of our\nproposed WeakMedSAM. Our code is available at\nhttps://github.com/wanghr64/WeakMedSAM.\n","authors":["Haoran Wang","Lian Huai","Wenbin Li","Lei Qi","Xingqun Jiang","Yinghuan Shi"],"pdf_url":"https://arxiv.org/pdf/2503.04106v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.02910v2","updated":"2025-03-06T05:19:44Z","published":"2025-03-04T06:17:17Z","title":"LangGas: Introducing Language in Selective Zero-Shot Background\n  Subtraction for Semi-Transparent Gas Leak Detection with a New Dataset","summary":"  Gas leakage poses a significant hazard that requires prevention.\nTraditionally, human inspection has been used for detection, a slow and\nlabour-intensive process. Recent research has applied machine learning\ntechniques to this problem, yet there remains a shortage of high-quality,\npublicly available datasets. This paper introduces a synthetic dataset\nfeaturing diverse backgrounds, interfering foreground objects, diverse leak\nlocations, and precise segmentation ground truth. We propose a zero-shot method\nthat combines background subtraction, zero-shot object detection, filtering,\nand segmentation to leverage this dataset. Experimental results indicate that\nour approach significantly outperforms baseline methods based solely on\nbackground subtraction and zero-shot object detection with segmentation,\nreaching an IoU of 69\\% overall. We also present an analysis of various prompt\nconfigurations and threshold settings to provide deeper insights into the\nperformance of our method. The code and dataset will be released after\npublication.\n","authors":["Wenqi Guo","Yiyang Du","Shan Du"],"pdf_url":"https://arxiv.org/pdf/2503.02910v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2502.14909v2","updated":"2025-03-06T05:18:12Z","published":"2025-02-19T02:56:27Z","title":"Comparing Deep Neural Network for Multi-Label ECG Diagnosis From Scanned\n  ECG","summary":"  Automated ECG diagnosis has seen significant advancements with deep learning\ntechniques, but real-world applications still face challenges when dealing with\nscanned paper ECGs. In this study, we explore multi-label classification of\nECGs extracted from scanned images, moving beyond traditional binary\nclassification (normal/abnormal). We evaluate the performance of multiple deep\nneural network architectures, including AlexNet, VGG, ResNet, and Vision\nTransformer, on scanned ECG datasets. Our comparative analysis examines model\naccuracy, robustness to image artifacts, and generalizability across different\nECG conditions. Additionally, we investigate whether ECG signals extracted from\nscanned images retain sufficient diagnostic information for reliable automated\nclassification. The findings highlight the strengths and limitations of each\narchitecture, providing insights into the feasibility of image-based ECG\ndiagnosis and its potential integration into clinical workflows.\n","authors":["Cuong V. Nguyen","Hieu X. Nguyen","Dung D. Pham Minh","Cuong D. Do"],"pdf_url":"https://arxiv.org/pdf/2502.14909v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.04096v1","updated":"2025-03-06T05:13:19Z","published":"2025-03-06T05:13:19Z","title":"Image-Based Relocalization and Alignment for Long-Term Monitoring of\n  Dynamic Underwater Environments","summary":"  Effective monitoring of underwater ecosystems is crucial for tracking\nenvironmental changes, guiding conservation efforts, and ensuring long-term\necosystem health. However, automating underwater ecosystem management with\nrobotic platforms remains challenging due to the complexities of underwater\nimagery, which pose significant difficulties for traditional visual\nlocalization methods. We propose an integrated pipeline that combines Visual\nPlace Recognition (VPR), feature matching, and image segmentation on\nvideo-derived images. This method enables robust identification of revisited\nareas, estimation of rigid transformations, and downstream analysis of\necosystem changes. Furthermore, we introduce the SQUIDLE+ VPR Benchmark-the\nfirst large-scale underwater VPR benchmark designed to leverage an extensive\ncollection of unstructured data from multiple robotic platforms, spanning time\nintervals from days to years. The dataset encompasses diverse trajectories,\narbitrary overlap and diverse seafloor types captured under varying\nenvironmental conditions, including differences in depth, lighting, and\nturbidity. Our code is available at: https://github.com/bev-gorry/underloc\n","authors":["Beverley Gorry","Tobias Fischer","Michael Milford","Alejandro Fontan"],"pdf_url":"https://arxiv.org/pdf/2503.04096v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.16805v3","updated":"2025-03-06T05:06:49Z","published":"2024-11-25T14:38:43Z","title":"Human Motion Instruction Tuning","summary":"  This paper presents LLaMo (Large Language and Human Motion Assistant), a\nmultimodal framework for human motion instruction tuning. In contrast to\nconventional instruction-tuning approaches that convert non-linguistic inputs,\nsuch as video or motion sequences, into language tokens, LLaMo retains motion\nin its native form for instruction tuning. This method preserves\nmotion-specific details that are often diminished in tokenization, thereby\nimproving the model's ability to interpret complex human behaviors. By\nprocessing both video and motion data alongside textual inputs, LLaMo enables a\nflexible, human-centric analysis. Experimental evaluations across\nhigh-complexity domains, including human behaviors and professional activities,\nindicate that LLaMo effectively captures domain-specific knowledge, enhancing\ncomprehension and prediction in motion-intensive scenarios. We hope LLaMo\noffers a foundation for future multimodal AI systems with broad applications,\nfrom sports analytics to behavioral prediction. Our code and models are\navailable on the project website: https://github.com/ILGLJ/LLaMo.\n","authors":["Lei Li","Sen Jia","Wang Jianhao","Zhongyu Jiang","Feng Zhou","Ju Dai","Tianfang Zhang","Wu Zongkai","Jenq-Neng Hwang"],"pdf_url":"https://arxiv.org/pdf/2411.16805v3.pdf","comment":"Accepted by CVPR 2025"},{"id":"http://arxiv.org/abs/2503.04087v1","updated":"2025-03-06T04:50:07Z","published":"2025-03-06T04:50:07Z","title":"Brain Tumor Detection in MRI Based on Federated Learning with YOLOv11","summary":"  One of the primary challenges in medical diagnostics is the accurate and\nefficient use of magnetic resonance imaging (MRI) for the detection of brain\ntumors. But the current machine learning (ML) approaches have two major\nlimitations, data privacy and high latency. To solve the problem, in this work\nwe propose a federated learning architecture for a better accurate brain tumor\ndetection incorporating the YOLOv11 algorithm. In contrast to earlier methods\nof centralized learning, our federated learning approach protects the\nunderlying medical data while supporting cooperative deep learning model\ntraining across multiple institutions. To allow the YOLOv11 model to locate and\nidentify tumor areas, we adjust it to handle MRI data. To ensure robustness and\ngeneralizability, the model is trained and tested on a wide range of MRI data\ncollected from several anonymous medical facilities. The results indicate that\nour method significantly maintains higher accuracy than conventional\napproaches.\n","authors":["Sheikh Moonwara Anjum Monisha","Ratun Rahman"],"pdf_url":"https://arxiv.org/pdf/2503.04087v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2405.14701v4","updated":"2025-03-06T04:38:23Z","published":"2024-05-23T15:35:48Z","title":"DreamText: High Fidelity Scene Text Synthesis","summary":"  Scene text synthesis involves rendering specified texts onto arbitrary\nimages. Current methods typically formulate this task in an end-to-end manner\nbut lack effective character-level guidance during training. Besides, their\ntext encoders, pre-trained on a single font type, struggle to adapt to the\ndiverse font styles encountered in practical applications. Consequently, these\nmethods suffer from character distortion, repetition, and absence, particularly\nin polystylistic scenarios. To this end, this paper proposes DreamText for\nhigh-fidelity scene text synthesis. Our key idea is to reconstruct the\ndiffusion training process, introducing more refined guidance tailored to this\ntask, to expose and rectify the model's attention at the character level and\nstrengthen its learning of text regions. This transformation poses a hybrid\noptimization challenge, involving both discrete and continuous variables. To\neffectively tackle this challenge, we employ a heuristic alternate optimization\nstrategy. Meanwhile, we jointly train the text encoder and generator to\ncomprehensively learn and utilize the diverse font present in the training\ndataset. This joint training is seamlessly integrated into the alternate\noptimization process, fostering a synergistic relationship between learning\ncharacter embedding and re-estimating character attention. Specifically, in\neach step, we first encode potential character-generated position information\nfrom cross-attention maps into latent character masks. These masks are then\nutilized to update the representation of specific characters in the current\nstep, which, in turn, enables the generator to correct the character's\nattention in the subsequent steps. Both qualitative and quantitative results\ndemonstrate the superiority of our method to the state of the art.\n","authors":["Yibin Wang","Weizhong Zhang","Honghui Xu","Cheng Jin"],"pdf_url":"https://arxiv.org/pdf/2405.14701v4.pdf","comment":"Code: https://github.com/CodeGoat24/DreamText, Project page:\n  https://codegoat24.github.io/DreamText/"},{"id":"http://arxiv.org/abs/2503.04082v1","updated":"2025-03-06T04:37:09Z","published":"2025-03-06T04:37:09Z","title":"Instrument-Splatting: Controllable Photorealistic Reconstruction of\n  Surgical Instruments Using Gaussian Splatting","summary":"  Real2Sim is becoming increasingly important with the rapid development of\nsurgical artificial intelligence (AI) and autonomy. In this work, we propose a\nnovel Real2Sim methodology, \\textit{Instrument-Splatting}, that leverages 3D\nGaussian Splatting to provide fully controllable 3D reconstruction of surgical\ninstruments from monocular surgical videos. To maintain both high visual\nfidelity and manipulability, we introduce a geometry pre-training to bind\nGaussian point clouds on part mesh with accurate geometric priors and define a\nforward kinematics to control the Gaussians as flexible as real instruments.\nAfterward, to handle unposed videos, we design a novel instrument pose tracking\nmethod leveraging semantics-embedded Gaussians to robustly refine per-frame\ninstrument poses and joint states in a render-and-compare manner, which allows\nour instrument Gaussian to accurately learn textures and reach photorealistic\nrendering. We validated our method on 2 publicly released surgical videos and 4\nvideos collected on ex vivo tissues and green screens. Quantitative and\nqualitative evaluations demonstrate the effectiveness and superiority of the\nproposed method.\n","authors":["Shuojue Yang","Zijian Wu","Mingxuan Hong","Qian Li","Daiyun Shen","Septimiu E. Salcudean","Yueming Jin"],"pdf_url":"https://arxiv.org/pdf/2503.04082v1.pdf","comment":"11 pages, 5 figures"},{"id":"http://arxiv.org/abs/2503.04079v1","updated":"2025-03-06T04:33:19Z","published":"2025-03-06T04:33:19Z","title":"Surgical Gaussian Surfels: Highly Accurate Real-time Surgical Scene\n  Rendering","summary":"  Accurate geometric reconstruction of deformable tissues in monocular\nendoscopic video remains a fundamental challenge in robot-assisted minimally\ninvasive surgery. Although recent volumetric and point primitive methods based\non neural radiance fields (NeRF) and 3D Gaussian primitives have efficiently\nrendered surgical scenes, they still struggle with handling artifact-free tool\nocclusions and preserving fine anatomical details. These limitations stem from\nunrestricted Gaussian scaling and insufficient surface alignment constraints\nduring reconstruction. To address these issues, we introduce Surgical Gaussian\nSurfels (SGS), which transforms anisotropic point primitives into\nsurface-aligned elliptical splats by constraining the scale component of the\nGaussian covariance matrix along the view-aligned axis. We predict accurate\nsurfel motion fields using a lightweight Multi-Layer Perceptron (MLP) coupled\nwith locality constraints to handle complex tissue deformations. We use\nhomodirectional view-space positional gradients to capture fine image details\nby splitting Gaussian Surfels in over-reconstructed regions. In addition, we\ndefine surface normals as the direction of the steepest density change within\neach Gaussian surfel primitive, enabling accurate normal estimation without\nrequiring monocular normal priors. We evaluate our method on two in-vivo\nsurgical datasets, where it outperforms current state-of-the-art methods in\nsurface geometry, normal map quality, and rendering efficiency, while remaining\ncompetitive in real-time rendering performance. We make our code available at\nhttps://github.com/aloma85/SurgicalGaussianSurfels\n","authors":["Idris O. Sunmola","Zhenjun Zhao","Samuel Schmidgall","Yumeng Wang","Paul Maria Scheikl","Axel Krieger"],"pdf_url":"https://arxiv.org/pdf/2503.04079v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2502.20637v2","updated":"2025-03-06T04:31:21Z","published":"2025-02-28T01:36:38Z","title":"TractCloud-FOV: Deep Learning-based Robust Tractography Parcellation in\n  Diffusion MRI with Incomplete Field of View","summary":"  Tractography parcellation classifies streamlines reconstructed from diffusion\nMRI into anatomically defined fiber tracts for clinical and research\napplications. However, clinical scans often have incomplete fields of view\n(FOV) where brain regions are partially imaged, leading to partial or truncated\nfiber tracts. To address this challenge, we introduce TractCloud-FOV, a deep\nlearning framework that robustly parcellates tractography under conditions of\nincomplete FOV. We propose a novel training strategy, FOV-Cut Augmentation\n(FOV-CA), in which we synthetically cut tractograms to simulate a spectrum of\nreal-world inferior FOV cutoff scenarios. This data augmentation approach\nenriches the training set with realistic truncated streamlines, enabling the\nmodel to achieve superior generalization. We evaluate the proposed\nTractCloud-FOV on both synthetically cut tractography and two real-life\ndatasets with incomplete FOV. TractCloud-FOV significantly outperforms several\nstate-of-the-art methods on all testing datasets in terms of streamline\nclassification accuracy, generalization ability, tract anatomical depiction,\nand computational efficiency. Overall, TractCloud-FOV achieves efficient and\nconsistent tractography parcellation in diffusion MRI with incomplete FOV.\n","authors":["Yuqian Chen","Leo Zekelman","Yui Lo","Suheyla Cetin-Karayumak","Tengfei Xue","Yogesh Rathi","Nikos Makris","Fan Zhang","Weidong Cai","Lauren J. O'Donnell"],"pdf_url":"https://arxiv.org/pdf/2502.20637v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.04078v1","updated":"2025-03-06T04:28:11Z","published":"2025-03-06T04:28:11Z","title":"Spatial-Temporal Perception with Causal Inference for Naturalistic\n  Driving Action Recognition","summary":"  Naturalistic driving action recognition is essential for vehicle cabin\nmonitoring systems. However, the complexity of real-world backgrounds presents\nsignificant challenges for this task, and previous approaches have struggled\nwith practical implementation due to their limited ability to observe subtle\nbehavioral differences and effectively learn inter-frame features from video.\nIn this paper, we propose a novel Spatial-Temporal Perception (STP)\narchitecture that emphasizes both temporal information and spatial\nrelationships between key objects, incorporating a causal decoder to perform\nbehavior recognition and temporal action localization. Without requiring\nmultimodal input, STP directly extracts temporal and spatial distance features\nfrom RGB video clips. Subsequently, these dual features are jointly encoded by\nmaximizing the expected likelihood across all possible permutations of the\nfactorization order. By integrating temporal and spatial features at different\nscales, STP can perceive subtle behavioral changes in challenging scenarios.\nAdditionally, we introduce a causal-aware module to explore relationships\nbetween video frame features, significantly enhancing detection efficiency and\nperformance. We validate the effectiveness of our approach using two publicly\navailable driver distraction detection benchmarks. The results demonstrate that\nour framework achieves state-of-the-art performance.\n","authors":["Qing Chang","Wei Dai","Zhihao Shuai","Limin Yu","Yutao Yue"],"pdf_url":"https://arxiv.org/pdf/2503.04078v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2405.15683v3","updated":"2025-03-06T03:59:59Z","published":"2024-05-24T16:21:59Z","title":"Visual Description Grounding Reduces Hallucinations and Boosts Reasoning\n  in LVLMs","summary":"  Large Vision-Language Models (LVLMs) often produce responses that misalign\nwith factual information, a phenomenon known as hallucinations. While\nhallucinations are well-studied, the exact causes behind them remain\nunderexplored. In this paper, we first investigate the root causes of\nhallucinations in LVLMs. Our findings reveal that existing mitigation\ntechniques primarily reduce hallucinations for visual recognition prompts-those\nthat require simple descriptions of visual elements-but fail for cognitive\nprompts that demand deliberate reasoning. We identify the core issue as a lack\nof true visual perception in LVLMs: although they can accurately recognize\nvisual elements, they struggle to fully interpret these elements in the context\nof the input prompt and effectively link this recognition to their internal\nknowledge, which is critical for reasoning. To address this gap, we introduce\nVisual Description Grounded Decoding (VDGD), a simple, robust, and\ntraining-free method designed to enhance visual perception and improve\nreasoning capabilities in LVLMs. VDGD works by first generating a detailed\ndescription of the image and appending it as a prefix to the instruction.\nDuring response generation, tokens are sampled based on their KL divergence to\nthe description, favoring candidates with lower divergence. Experimental\nresults on multiple visual reasoning benchmarks and LVLMs demonstrate that VDGD\nconsistently outperforms existing baselines 2% - 33%. Finally, we introduce\nVaLLu, a benchmark designed for comprehensive evaluation of the cognitive\ncapabilities of LVLMs.\n","authors":["Sreyan Ghosh","Chandra Kiran Reddy Evuru","Sonal Kumar","Utkarsh Tyagi","Oriol Nieto","Zeyu Jin","Dinesh Manocha"],"pdf_url":"https://arxiv.org/pdf/2405.15683v3.pdf","comment":"Accepted to ICLR 2025. Project: https://sreyan88.github.io/VDGD/"},{"id":"http://arxiv.org/abs/2502.16445v3","updated":"2025-03-06T03:55:58Z","published":"2025-02-23T05:08:06Z","title":"Iterative Flow Matching -- Path Correction and Gradual Refinement for\n  Enhanced Generative Modeling","summary":"  Generative models for image generation are now commonly used for a wide\nvariety of applications, ranging from guided image generation for entertainment\nto solving inverse problems. Nonetheless, training a generator is a non-trivial\nfeat that requires fine-tuning and can lead to so-called hallucinations, that\nis, the generation of images that are unrealistic. In this work, we explore\nimage generation using flow matching. We explain and demonstrate why flow\nmatching can generate hallucinations, and propose an iterative process to\nimprove the generation process. Our iterative process can be integrated into\nvirtually $\\textit{any}$ generative modeling technique, thereby enhancing the\nperformance and robustness of image synthesis systems.\n","authors":["Eldad Haber","Shadab Ahamed","Md. Shahriar Rahim Siddiqui","Niloufar Zakariaei","Moshe Eliasof"],"pdf_url":"https://arxiv.org/pdf/2502.16445v3.pdf","comment":"17 pages, 8 figures"},{"id":"http://arxiv.org/abs/2503.04067v1","updated":"2025-03-06T03:52:46Z","published":"2025-03-06T03:52:46Z","title":"FREAK: Frequency-modulated High-fidelity and Real-time Audio-driven\n  Talking Portrait Synthesis","summary":"  Achieving high-fidelity lip-speech synchronization in audio-driven talking\nportrait synthesis remains challenging. While multi-stage pipelines or\ndiffusion models yield high-quality results, they suffer from high\ncomputational costs. Some approaches perform well on specific individuals with\nlow resources, yet still exhibit mismatched lip movements. The aforementioned\nmethods are modeled in the pixel domain. We observed that there are noticeable\ndiscrepancies in the frequency domain between the synthesized talking videos\nand natural videos. Currently, no research on talking portrait synthesis has\nconsidered this aspect. To address this, we propose a FREquency-modulated,\nhigh-fidelity, and real-time Audio-driven talKing portrait synthesis framework,\nnamed FREAK, which models talking portraits from the frequency domain\nperspective, enhancing the fidelity and naturalness of the synthesized\nportraits. FREAK introduces two novel frequency-based modules: 1) the Visual\nEncoding Frequency Modulator (VEFM) to couple multi-scale visual features in\nthe frequency domain, better preserving visual frequency information and\nreducing the gap in the frequency spectrum between synthesized and natural\nframes. and 2) the Audio Visual Frequency Modulator (AVFM) to help the model\nlearn the talking pattern in the frequency domain and improve audio-visual\nsynchronization. Additionally, we optimize the model in both pixel domain and\nfrequency domain jointly. Furthermore, FREAK supports seamless switching\nbetween one-shot and video dubbing settings, offering enhanced flexibility. Due\nto its superior performance, it can simultaneously support high-resolution\nvideo results and real-time inference. Extensive experiments demonstrate that\nour method synthesizes high-fidelity talking portraits with detailed facial\ntextures and precise lip synchronization in real-time, outperforming\nstate-of-the-art methods.\n","authors":["Ziqi Ni","Ao Fu","Yi Zhou"],"pdf_url":"https://arxiv.org/pdf/2503.04067v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.00741v2","updated":"2025-03-06T03:44:10Z","published":"2025-03-02T05:36:04Z","title":"LesionDiffusion: Towards Text-controlled General Lesion Synthesis","summary":"  Fully-supervised lesion recognition methods in medical imaging face\nchallenges due to the reliance on large annotated datasets, which are expensive\nand difficult to collect. To address this, synthetic lesion generation has\nbecome a promising approach. However, existing models struggle with\nscalability, fine-grained control over lesion attributes, and the generation of\ncomplex structures. We propose LesionDiffusion, a text-controllable lesion\nsynthesis framework for 3D CT imaging that generates both lesions and\ncorresponding masks. By utilizing a structured lesion report template, our\nmodel provides greater control over lesion attributes and supports a wider\nvariety of lesion types. We introduce a dataset of 1,505 annotated CT scans\nwith paired lesion masks and structured reports, covering 14 lesion types\nacross 8 organs. LesionDiffusion consists of two components: a lesion mask\nsynthesis network (LMNet) and a lesion inpainting network (LINet), both guided\nby lesion attributes and image features. Extensive experiments demonstrate that\nLesionDiffusion significantly improves segmentation performance, with strong\ngeneralization to unseen lesion types and organs, outperforming current\nstate-of-the-art models. Code will be available at\nhttps://github.com/HengruiTianSJTU/LesionDiffusion.\n","authors":["Henrui Tian","Wenhui Lei","Linrui Dai","Hanyu Chen","Xiaofan Zhang"],"pdf_url":"https://arxiv.org/pdf/2503.00741v2.pdf","comment":"10 pages, 4 figures"},{"id":"http://arxiv.org/abs/2503.04065v1","updated":"2025-03-06T03:43:21Z","published":"2025-03-06T03:43:21Z","title":"PP-DocBee: Improving Multimodal Document Understanding Through a Bag of\n  Tricks","summary":"  With the rapid advancement of digitalization, various document images are\nbeing applied more extensively in production and daily life, and there is an\nincreasingly urgent need for fast and accurate parsing of the content in\ndocument images. Therefore, this report presents PP-DocBee, a novel multimodal\nlarge language model designed for end-to-end document image understanding.\nFirst, we develop a data synthesis strategy tailored to document scenarios in\nwhich we build a diverse dataset to improve the model generalization. Then, we\napply a few training techniques, including dynamic proportional sampling, data\npreprocessing, and OCR postprocessing strategies. Extensive evaluations\ndemonstrate the superior performance of PP-DocBee, achieving state-of-the-art\nresults on English document understanding benchmarks and even outperforming\nexisting open source and commercial models in Chinese document understanding.\nThe source code and pre-trained models are publicly available at\n\\href{https://github.com/PaddlePaddle/PaddleMIX}{https://github.com/PaddlePaddle/PaddleMIX}.\n","authors":["Feng Ni","Kui Huang","Yao Lu","Wenyu Lv","Guanzhong Wang","Zeyu Chen","Yi Liu"],"pdf_url":"https://arxiv.org/pdf/2503.04065v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.00736v2","updated":"2025-03-06T03:35:09Z","published":"2025-03-02T05:20:41Z","title":"Shazam: Unifying Multiple Foundation Models for Advanced Computational\n  Pathology","summary":"  Foundation Models (FMs) in computational pathology (CPath) have significantly\nadvanced the extraction of meaningful features from histopathology image\ndatasets, achieving strong performance across various clinical tasks. Despite\ntheir impressive performance, these models often exhibit variability when\napplied to different tasks, prompting the need for a unified framework capable\nof consistently excelling across various applications. In this work, we propose\nShazam, a novel framework designed to efficiently combine multiple CPath\nmodels. Unlike previous approaches that train a fixed-parameter FM, Shazam\ndynamically extracts and refines information from diverse FMs for each specific\ntask. To ensure that each FM contributes effectively without dominance, a novel\ndistillation strategy is applied, guiding the student model with features from\nall teacher models, which enhances its generalization ability. Experimental\nresults on two pathology patch classification datasets demonstrate that Shazam\noutperforms existing CPath models and other fusion methods. Its lightweight,\nflexible design makes it a promising solution for improving CPath analysis in\nreal-world settings. Code will be available at\nhttps://github.com/Tuner12/Shazam.\n","authors":["Wenhui Lei","Anqi Li","Yusheng Tan","Hanyu Chen","Xiaofan Zhang"],"pdf_url":"https://arxiv.org/pdf/2503.00736v2.pdf","comment":"9 pages, 2 figures"},{"id":"http://arxiv.org/abs/2410.21259v4","updated":"2025-03-06T03:31:32Z","published":"2024-10-28T17:55:08Z","title":"AutoBench-V: Can Large Vision-Language Models Benchmark Themselves?","summary":"  Large Vision-Language Models (LVLMs) have become essential for advancing the\nintegration of visual and linguistic information. However, the evaluation of\nLVLMs presents significant challenges as the evaluation benchmark always\ndemands lots of human cost for its construction, and remains static, lacking\nflexibility once constructed. Even though automatic evaluation has been\nexplored in textual modality, the visual modality remains under-explored. As a\nresult, in this work, we address a question: \"Can LVLMs themselves be used to\nbenchmark each other in the visual automatically domain?\". We introduce\nAutoBench-V, an automated framework for serving evaluation on demand, i.e.,\nbenchmarking LVLMs based on specific aspects of model capability. AutoBench-V\nleverages text-to-image models to generate relevant image samples and then\nutilizes LVLMs to orchestrate visual question-answering (VQA) tasks, completing\nthe evaluation process efficiently and flexibly. Through an extensive\nevaluation of nine popular LVLMs across five demanded user inputs (i.e.,\nevaluation capabilities), the framework shows effectiveness and reliability.\n","authors":["Han Bao","Yue Huang","Yanbo Wang","Jiayi Ye","Xiangqi Wang","Xiuying Chen","Yue Zhao","Tianyi Zhou","Mohamed Elhoseiny","Xiangliang Zhang"],"pdf_url":"https://arxiv.org/pdf/2410.21259v4.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.04059v1","updated":"2025-03-06T03:27:14Z","published":"2025-03-06T03:27:14Z","title":"H3O: Hyper-Efficient 3D Occupancy Prediction with Heterogeneous\n  Supervision","summary":"  3D occupancy prediction has recently emerged as a new paradigm for holistic\n3D scene understanding and provides valuable information for downstream\nplanning in autonomous driving. Most existing methods, however, are\ncomputationally expensive, requiring costly attention-based 2D-3D\ntransformation and 3D feature processing. In this paper, we present a novel 3D\noccupancy prediction approach, H3O, which features highly efficient\narchitecture designs that incur a significantly lower computational cost as\ncompared to the current state-of-the-art methods. In addition, to compensate\nfor the ambiguity in ground-truth 3D occupancy labels, we advocate leveraging\nauxiliary tasks to complement the direct 3D supervision. In particular, we\nintegrate multi-camera depth estimation, semantic segmentation, and surface\nnormal estimation via differentiable volume rendering, supervised by\ncorresponding 2D labels that introduces rich and heterogeneous supervision\nsignals. We conduct extensive experiments on the Occ3D-nuScenes and\nSemanticKITTI benchmarks that demonstrate the superiority of our proposed H3O.\n","authors":["Yunxiao Shi","Hong Cai","Amin Ansari","Fatih Porikli"],"pdf_url":"https://arxiv.org/pdf/2503.04059v1.pdf","comment":"ICRA 2025"},{"id":"http://arxiv.org/abs/2501.06259v3","updated":"2025-03-06T23:10:14Z","published":"2025-01-09T11:08:55Z","title":"Quantum Down Sampling Filter for Variational Auto-encoder","summary":"  Variational autoencoders (VAEs) are fundamental for generative modeling and\nimage reconstruction, yet their performance often struggles to maintain high\nfidelity in reconstructions. This study introduces a hybrid model, quantum\nvariational autoencoder (Q-VAE), which integrates quantum encoding within the\nencoder while utilizing fully connected layers to extract meaningful\nrepresentations. The decoder uses transposed convolution layers for\nup-sampling. The Q-VAE is evaluated against the classical VAE and the classical\ndirect-passing VAE, which utilizes windowed pooling filters. Results on the\nMNIST and USPS datasets demonstrate that Q-VAE consistently outperforms\nclassical approaches, achieving lower Fr\\'echet inception distance scores,\nthereby indicating superior image fidelity and enhanced reconstruction quality.\nThese findings highlight the potential of Q-VAE for high-quality synthetic data\ngeneration and improved image reconstruction in generative models.\n","authors":["Farina Riaz","Fakhar Zaman","Hajime Suzuki","Sharif Abuadbba","David Nguyen"],"pdf_url":"https://arxiv.org/pdf/2501.06259v3.pdf","comment":"18 pages, 13 figures"},{"id":"http://arxiv.org/abs/2503.05031v1","updated":"2025-03-06T23:02:18Z","published":"2025-03-06T23:02:18Z","title":"Enhancing Alzheimer's Diagnosis: Leveraging Anatomical Landmarks in\n  Graph Convolutional Neural Networks on Tetrahedral Meshes","summary":"  Alzheimer's disease (AD) is a major neurodegenerative condition that affects\nmillions around the world. As one of the main biomarkers in the AD diagnosis\nprocedure, brain amyloid positivity is typically identified by positron\nemission tomography (PET), which is costly and invasive. Brain structural\nmagnetic resonance imaging (sMRI) may provide a safer and more convenient\nsolution for the AD diagnosis. Recent advances in geometric deep learning have\nfacilitated sMRI analysis and early diagnosis of AD. However, determining AD\npathology, such as brain amyloid deposition, in preclinical stage remains\nchallenging, as less significant morphological changes can be observed. As a\nresult, few AD classification models are generalizable to the brain amyloid\npositivity classification task. Blood-based biomarkers (BBBMs), on the other\nhand, have recently achieved remarkable success in predicting brain amyloid\npositivity and identifying individuals with high risk of being brain amyloid\npositive. However, individuals in medium risk group still require gold standard\ntests such as Amyloid PET for further evaluation. Inspired by the recent\nsuccess of transformer architectures, we propose a geometric deep learning\nmodel based on transformer that is both scalable and robust to variations in\ninput volumetric mesh size. Our work introduced a novel tokenization scheme for\ntetrahedral meshes, incorporating anatomical landmarks generated by a\npre-trained Gaussian process model. Our model achieved superior classification\nperformance in AD classification task. In addition, we showed that the model\nwas also generalizable to the brain amyloid positivity prediction with\nindividuals in the medium risk class, where BM alone cannot achieve a clear\nclassification. Our work may enrich geometric deep learning research and\nimprove AD diagnosis accuracy without using expensive and invasive PET scans.\n","authors":["Yanxi Chen","Mohammad Farazi","Zhangsihao Yang","Yonghui Fan","Nicholas Ashton","Eric M Reiman","Yi Su","Yalin Wang"],"pdf_url":"https://arxiv.org/pdf/2503.05031v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.04997v1","updated":"2025-03-06T21:56:31Z","published":"2025-03-06T21:56:31Z","title":"ISP-AD: A Large-Scale Real-World Dataset for Advancing Industrial\n  Anomaly Detection with Synthetic and Real Defects","summary":"  Automatic visual inspection using machine learning-based methods plays a key\nrole in achieving zero-defect policies in industry. Research on anomaly\ndetection approaches is constrained by the availability of datasets that\nrepresent complex defect appearances and imperfect imaging conditions, which\nare typical to industrial processes. Recent benchmarks indicate that most\npublicly available datasets are biased towards optimal imaging conditions,\nleading to an overestimation of the methods' applicability to real-world\nindustrial scenarios. To address this gap, we introduce the Industrial Screen\nPrinting Anomaly Detection dataset (ISP-AD). It presents challenging small and\nweakly contrasted surface defects embedded within structured patterns\nexhibiting high permitted design variability. To the best of our knowledge, it\nis the largest publicly available industrial dataset to date, including both\nsynthetic and real defects collected directly from the factory floor. In\naddition to the evaluation of defect detection performance of recent\nunsupervised anomaly detection methods, experiments on a mixed supervised\ntraining approach, incorporating both synthesized and real defects, were\nconducted. Even small amounts of injected real defects prove beneficial for\nmodel generalization. Furthermore, starting from training on purely synthetic\ndefects, emerging real defective samples can be efficiently integrated into\nsubsequent scalable training. Research findings indicate that supervision by\nmeans of both synthetic and accumulated real defects can complement each other,\nmeeting demanded industrial inspection requirements such as low false positive\nrates and high recall. The presented unsupervised and supervised dataset splits\nare designed to emphasize research on unsupervised, self-supervised, and\nsupervised approaches, enhancing their applicability to industrial settings.\n","authors":["Paul J. Krassnig","Dieter P. Gruber"],"pdf_url":"https://arxiv.org/pdf/2503.04997v1.pdf","comment":"26 pages, 6 figures, this preprint has been submitted to the Journal\n  of Intelligent Manufacturing"},{"id":"http://arxiv.org/abs/2503.01906v2","updated":"2025-03-06T21:37:23Z","published":"2025-02-28T15:30:55Z","title":"Learning to Chain Operations by Routing Information Through a Global\n  Workspace","summary":"  We present a model inspired by the Global Workspace Theory that integrates\nspecialized modules to perform a sequential reasoning task. A controller\nselectively routes information between modules through the workspace using a\ngating mechanism. This approach allows the model to chain operations by\niteratively broadcasting information between specialized domains, mimicking\nSystem-2 reasoning. We evaluate the model's performance on a simple addition\ntask, where two addends must be summed. The task can be solved by routing\ninformation sequentially through an Input module, an Increment module (multiple\ntimes), and finally an Output module. We consider two implementations of this\nsystem with increasing complexity. First, using hand-designed modules operating\non one-hot digit representations, the controller (a LSTM recurrent network)\nlearns to select the appropriate modules (input, increment, output) in the\nappropriate sequence. Second, we replace the hand-designed modules with learned\nrepresentation modules for MNIST images and an increment module trained on the\ntask objectives; here again, the controller learns the appropriate sequential\nmodule selection to solve the task. Finally, we show that the Global Workspace\nmodel, while having fewer parameters, outperforms LSTMs and Transformers when\ntested on unseen addition operations (both interpolations and extrapolations of\naddition operations seen during training). Our results highlight the potential\nof architectures inspired by the Global Workspace Theory to enhance deep\nlearning's reasoning capabilities.\n","authors":["Hugo Chateau-Laurent","Rufin VanRullen"],"pdf_url":"https://arxiv.org/pdf/2503.01906v2.pdf","comment":"12 pages, 14 figures, submitted to a conference"},{"id":"http://arxiv.org/abs/2503.04983v1","updated":"2025-03-06T21:23:17Z","published":"2025-03-06T21:23:17Z","title":"Leveraging Large Language Models For Scalable Vector Graphics\n  Processing: A Review","summary":"  In recent years, rapid advances in computer vision have significantly\nimproved the processing and generation of raster images. However, vector\ngraphics, which is essential in digital design, due to its scalability and ease\nof editing, have been relatively understudied. Traditional vectorization\ntechniques, which are often used in vector generation, suffer from long\nprocessing times and excessive output complexity, limiting their usability in\npractical applications. The advent of large language models (LLMs) has opened\nnew possibilities for the generation, editing, and analysis of vector graphics,\nparticularly in the SVG format, which is inherently text-based and well-suited\nfor integration with LLMs.\n  This paper provides a systematic review of existing LLM-based approaches for\nSVG processing, categorizing them into three main tasks: generation, editing,\nand understanding. We observe notable models such as IconShop, StrokeNUWA, and\nStarVector, highlighting their strengths and limitations. Furthermore, we\nanalyze benchmark datasets designed for assessing SVG-related tasks, including\nSVGEditBench, VGBench, and SGP-Bench, and conduct a series of experiments to\nevaluate various LLMs in these domains. Our results demonstrate that for vector\ngraphics reasoning-enhanced models outperform standard LLMs, particularly in\ngeneration and understanding tasks. Furthermore, our findings underscore the\nneed to develop more diverse and richly annotated datasets to further improve\nLLM capabilities in vector graphics tasks.\n","authors":["Boris Malashenko","Ivan Jarsky","Valeria Efimova"],"pdf_url":"https://arxiv.org/pdf/2503.04983v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.04982v1","updated":"2025-03-06T21:21:18Z","published":"2025-03-06T21:21:18Z","title":"LVLM-Compress-Bench: Benchmarking the Broader Impact of Large\n  Vision-Language Model Compression","summary":"  Despite recent efforts in understanding the compression impact on large\nlanguage models (LLMs) in terms of their downstream task performance and\ntrustworthiness on relatively simpler uni-modal benchmarks (for example,\nquestion answering, common sense reasoning), their detailed study on\nmulti-modal Large Vision-Language Models (LVLMs) is yet to be unveiled. Towards\nmitigating this gap, we present LVLM-Compress-Bench, a framework to first\nthoroughly study the broad impact of compression on the generative performance\nof LVLMs with multi-modal input driven tasks. In specific, we consider two\nmajor classes of compression for autoregressive models, namely KV cache and\nweight compression, for the dynamically growing intermediate cache and static\nweights, respectively.\n  We use four LVLM variants of the popular LLaVA framework to present our\nanalysis via integrating various state-of-the-art KV and weight compression\nmethods including uniform, outlier-reduced, and group quantization for the KV\ncache and weights. With this framework we demonstrate on ten different\nmulti-modal datasets with different capabilities including recognition,\nknowledge, language generation, spatial awareness, visual reasoning,\nhallucination and visual illusion identification, toxicity, stereotypes and\nbias. In specific, our framework demonstrates the compression impact on both\ngeneral and ethically critical metrics leveraging a combination of real world\nand synthetic datasets to encompass diverse societal intersectional attributes.\nExtensive experimental evaluations yield diverse and intriguing observations on\nthe behavior of LVLMs at different quantization budget of KV and weights, in\nboth maintaining and losing performance as compared to the baseline model with\nFP16 data format.\n  Code will be open-sourced at\nhttps://github.com/opengear-project/LVLM-compress-bench.\n","authors":["Souvik Kundu","Anahita Bhiwandiwalla","Sungduk Yu","Phillip Howard","Tiep Le","Sharath Nittur Sridhar","David Cobbley","Hao Kang","Vasudev Lal"],"pdf_url":"https://arxiv.org/pdf/2503.04982v1.pdf","comment":"This work has been accepted to NAACL 2025"},{"id":"http://arxiv.org/abs/2503.04979v1","updated":"2025-03-06T21:17:40Z","published":"2025-03-06T21:17:40Z","title":"HyDA: Hypernetworks for Test Time Domain Adaptation in Medical Imaging\n  Analysis","summary":"  Medical imaging datasets often vary due to differences in acquisition\nprotocols, patient demographics, and imaging devices. These variations in data\ndistribution, known as domain shift, present a significant challenge in\nadapting imaging analysis models for practical healthcare applications.\n  Most current domain adaptation (DA) approaches aim either to align the\ndistributions between the source and target domains or to learn an invariant\nfeature space that generalizes well across all domains. However, both\nstrategies require access to a sufficient number of examples, though not\nnecessarily annotated, from the test domain during training. This limitation\nhinders the widespread deployment of models in clinical settings, where target\ndomain data may only be accessible in real time.\n  In this work, we introduce HyDA, a novel hypernetwork framework that\nleverages domain characteristics rather than suppressing them, enabling dynamic\nadaptation at inference time. Specifically, HyDA learns implicit domain\nrepresentations and uses them to adjust model parameters on-the-fly,\neffectively interpolating to unseen domains. We validate HyDA on two clinically\nrelevant applications - MRI brain age prediction and chest X-ray pathology\nclassification - demonstrating its ability to generalize across tasks and\nmodalities. Our code is available at TBD.\n","authors":["Doron Serebro","Tammy Riklin-Raviv"],"pdf_url":"https://arxiv.org/pdf/2503.04979v1.pdf","comment":"submitted to MICCAI 2025"},{"id":"http://arxiv.org/abs/2408.11992v3","updated":"2025-03-06T20:55:40Z","published":"2024-08-21T21:03:36Z","title":"MBSS-T1: Model-Based Subject-Specific Self-Supervised Motion Correction\n  for Robust Cardiac T1 Mapping","summary":"  Cardiac T1 mapping is a valuable quantitative MRI technique for diagnosing\ndiffuse myocardial diseases. Traditional methods, relying on breath-hold\nsequences and cardiac triggering based on an ECG signal, face challenges with\npatient compliance, limiting their effectiveness. Image registration can enable\nmotion-robust cardiac T1 mapping, but inherent intensity differences between\ntime points pose a challenge. We present MBSS-T1, a subject-specific\nself-supervised model for motion correction in cardiac T1 mapping. Physical\nconstraints, implemented through a loss function comparing synthesized and\nmotion-corrected images, enforce signal decay behavior, while anatomical\nconstraints, applied via a Dice loss, ensure realistic deformations. The unique\ncombination of these constraints results in motion-robust cardiac T1 mapping\nalong the longitudinal relaxation axis. In a 5-fold experiment on a public\ndataset of 210 patients (STONE sequence) and an internal dataset of 19 patients\n(MOLLI sequence), MBSS-T1 outperformed baseline deep-learning registration\nmethods. It achieved superior model fitting quality ($R^2$: 0.975 vs. 0.941,\n0.946 for STONE; 0.987 vs. 0.982, 0.965 for MOLLI free-breathing; 0.994 vs.\n0.993, 0.991 for MOLLI breath-hold), anatomical alignment (Dice: 0.89 vs. 0.84,\n0.88 for STONE; 0.963 vs. 0.919, 0.851 for MOLLI free-breathing; 0.954 vs.\n0.924, 0.871 for MOLLI breath-hold), and visual quality (4.33 vs. 3.38, 3.66\nfor STONE; 4.1 vs. 3.5, 3.28 for MOLLI free-breathing; 3.79 vs. 3.15, 2.84 for\nMOLLI breath-hold). MBSS-T1 enables motion-robust T1 mapping for broader\npatient populations, overcoming challenges such as suboptimal compliance, and\nfacilitates free-breathing cardiac T1 mapping without requiring large annotated\ndatasets. Our code is available at\nhttps://github.com/TechnionComputationalMRILab/MBSS-T1.\n","authors":["Eyal Hanania","Adi Zehavi-Lenz","Ilya Volovik","Daphna Link-Sourani","Israel Cohen","Moti Freiman"],"pdf_url":"https://arxiv.org/pdf/2408.11992v3.pdf","comment":"Accepted and published in Medical Image Analysis"},{"id":"http://arxiv.org/abs/2503.04966v1","updated":"2025-03-06T20:52:58Z","published":"2025-03-06T20:52:58Z","title":"Prediction of Frozen Region Growth in Kidney Cryoablation Intervention\n  Using a 3D Flow-Matching Model","summary":"  This study presents a 3D flow-matching model designed to predict the\nprogression of the frozen region (iceball) during kidney cryoablation. Precise\nintraoperative guidance is critical in cryoablation to ensure complete tumor\neradication while preserving adjacent healthy tissue. However, conventional\nmethods, typically based on physics driven or diffusion based simulations, are\ncomputationally demanding and often struggle to represent complex anatomical\nstructures accurately. To address these limitations, our approach leverages\nintraoperative CT imaging to inform the model. The proposed 3D flow matching\nmodel is trained to learn a continuous deformation field that maps early-stage\nCT scans to future predictions. This transformation not only estimates the\nvolumetric expansion of the iceball but also generates corresponding\nsegmentation masks, effectively capturing spatial and morphological changes\nover time. Quantitative analysis highlights the model robustness, demonstrating\nstrong agreement between predictions and ground-truth segmentations. The model\nachieves an Intersection over Union (IoU) score of 0.61 and a Dice coefficient\nof 0.75. By integrating real time CT imaging with advanced deep learning\ntechniques, this approach has the potential to enhance intraoperative guidance\nin kidney cryoablation, improving procedural outcomes and advancing the field\nof minimally invasive surgery.\n","authors":["Siyeop Yoon","Yujin Oh","Matthew Tivnan","Sifan Song","Pengfei Jin","Sekeun KimHyun Jin Cho","Dufan Wu","Raul Uppot","Quanzheng Li"],"pdf_url":"https://arxiv.org/pdf/2503.04966v1.pdf","comment":"MICCAI 2025 submitted version"},{"id":"http://arxiv.org/abs/2503.04953v1","updated":"2025-03-06T20:32:59Z","published":"2025-03-06T20:32:59Z","title":"Spectral Informed Mamba for Robust Point Cloud Processing","summary":"  State space models have shown significant promise in Natural Language\nProcessing (NLP) and, more recently, computer vision. This paper introduces a\nnew methodology leveraging Mamba and Masked Autoencoder networks for point\ncloud data in both supervised and self-supervised learning. We propose three\nkey contributions to enhance Mamba's capability in processing complex point\ncloud structures. First, we exploit the spectrum of a graph Laplacian to\ncapture patch connectivity, defining an isometry-invariant traversal order that\nis robust to viewpoints and better captures shape manifolds than traditional 3D\ngrid-based traversals. Second, we adapt segmentation via a recursive patch\npartitioning strategy informed by Laplacian spectral components, allowing finer\nintegration and segment analysis. Third, we address token placement in Masked\nAutoencoder for Mamba by restoring tokens to their original positions, which\npreserves essential order and improves learning. Extensive experiments\ndemonstrate the improvements of our approach in classification, segmentation,\nand few-shot tasks over state-of-the-art baselines.\n","authors":["Ali Bahri","Moslem Yazdanpanah","Mehrdad Noori","Sahar Dastani","Milad Cheraghalikhani","David Osowiechi","Gustavo Adolfo Vargas Hakim","Farzad Beizaee","Ismail Ben Ayed","Christian Desrosiers"],"pdf_url":"https://arxiv.org/pdf/2503.04953v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.04927v1","updated":"2025-03-06T19:57:45Z","published":"2025-03-06T19:57:45Z","title":"Metadata-free Georegistration of Ground and Airborne Imagery","summary":"  Heterogeneous collections of ground and airborne imagery can readily be used\nto create high-quality 3D models and novel viewpoint renderings of the observed\nscene. Standard photogrammetry pipelines generate models in arbitrary\ncoordinate systems, which is problematic for applications that require\ngeoregistered models. Even for applications that do not require georegistered\nmodels, georegistration is useful as a mechanism for aligning multiple\ndisconnected models generated from non-overlapping data. The proposed method\nleverages satellite imagery, an associated digital surface model (DSM), and the\nnovel view generation capabilities of modern 3D modeling techniques (e.g.\nneural radiance fields) to provide a robust method for georegistering airborne\nimagery, and a related technique for registering ground-based imagery to models\ncreated from airborne imagery. Experiments demonstrate successful\ngeoregistration of airborne and ground-based photogrammetric models across a\nvariety of distinct sites. The proposed method does not require use of any\nmetadata other than a satellite-based reference product and therefore has\ngeneral applicability.\n","authors":["Adam Bredvik","Scott Richardson","Daniel Crispell"],"pdf_url":"https://arxiv.org/pdf/2503.04927v1.pdf","comment":"WACV 2025 ULTRRA Workshop"}],"Machine Learning":[{"id":"http://arxiv.org/abs/2412.06464v3","updated":"2025-03-06T06:57:34Z","published":"2024-12-09T13:09:04Z","title":"Gated Delta Networks: Improving Mamba2 with Delta Rule","summary":"  Linear Transformers have gained attention as efficient alternatives to\nstandard Transformers, but their performance in retrieval and long-context\ntasks has been limited. To address these limitations, recent work has explored\ntwo distinct mechanisms: gating for adaptive memory control and the delta\nupdate rule for precise memory modifications. We observe that these mechanisms\nare complementary: gating enables rapid memory erasure while the delta rule\nfacilitates targeted updates. Building on this insight, we introduce the gated\ndelta rule and develop a parallel training algorithm optimized for modern\nhardware. Our proposed architecture, Gated DeltaNet, consistently surpasses\nexisting models like Mamba2 and DeltaNet across multiple benchmarks, including\nlanguage modeling, common-sense reasoning, in-context retrieval, length\nextrapolation, and long-context understanding. We further enhance performance\nby developing hybrid architectures that combine Gated DeltaNet layers with\nsliding window attention or Mamba2 layers, achieving both improved training\nefficiency and superior task performance.\n","authors":["Songlin Yang","Jan Kautz","Ali Hatamizadeh"],"pdf_url":"https://arxiv.org/pdf/2412.06464v3.pdf","comment":"ICLR 2025 camera ready"},{"id":"http://arxiv.org/abs/2503.04725v1","updated":"2025-03-06T18:59:48Z","published":"2025-03-06T18:59:48Z","title":"L$^2$M: Mutual Information Scaling Law for Long-Context Language\n  Modeling","summary":"  We rigorously establish a bipartite mutual information scaling law in natural\nlanguage that governs long-range dependencies. This scaling law, which we show\nis distinct from and scales independently of the conventional two-point mutual\ninformation, is the key to understanding long-context language modeling. Using\nthis scaling law, we formulate the Long-context Language Modeling (L$^2$M)\ncondition, which relates a model's capacity for effective long context length\nmodeling to the scaling of its latent state size for storing past information.\nOur results are validated through experiments on both transformers and state\nspace models. This work establishes a theoretical foundation that guides the\ndevelopment of large language models toward longer context lengths.\n","authors":["Zhuo Chen","Oriol Mayn i Comas","Zhuotao Jin","Di Luo","Marin Soljai"],"pdf_url":"https://arxiv.org/pdf/2503.04725v1.pdf","comment":"29 pages, 12 figures, 1 table"},{"id":"http://arxiv.org/abs/2503.04722v1","updated":"2025-03-06T18:59:23Z","published":"2025-03-06T18:59:23Z","title":"Enough Coin Flips Can Make LLMs Act Bayesian","summary":"  Large language models (LLMs) exhibit the ability to generalize given few-shot\nexamples in their input prompt, an emergent capability known as in-context\nlearning (ICL). We investigate whether LLMs utilize ICL to perform structured\nreasoning in ways that are consistent with a Bayesian framework or rely on\npattern matching. Using a controlled setting of biased coin flips, we find\nthat: (1) LLMs often possess biased priors, causing initial divergence in\nzero-shot settings, (2) in-context evidence outweighs explicit bias\ninstructions, (3) LLMs broadly follow Bayesian posterior updates, with\ndeviations primarily due to miscalibrated priors rather than flawed updates,\nand (4) attention magnitude has negligible effect on Bayesian inference. With\nsufficient demonstrations of biased coin flips via ICL, LLMs update their\npriors in a Bayesian manner.\n","authors":["Ritwik Gupta","Rodolfo Corona","Jiaxin Ge","Eric Wang","Dan Klein","Trevor Darrell","David M. Chan"],"pdf_url":"https://arxiv.org/pdf/2503.04722v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.04718v1","updated":"2025-03-06T18:58:45Z","published":"2025-03-06T18:58:45Z","title":"Floxels: Fast Unsupervised Voxel Based Scene Flow Estimation","summary":"  Scene flow estimation is a foundational task for many robotic applications,\nincluding robust dynamic object detection, automatic labeling, and sensor\nsynchronization. Two types of approaches to the problem have evolved: 1)\nSupervised and 2) optimization-based methods. Supervised methods are fast\nduring inference and achieve high-quality results, however, they are limited by\nthe need for large amounts of labeled training data and are susceptible to\ndomain gaps. In contrast, unsupervised test-time optimization methods do not\nface the problem of domain gaps but usually suffer from substantial runtime,\nexhibit artifacts, or fail to converge to the right solution. In this work, we\nmitigate several limitations of existing optimization-based methods. To this\nend, we 1) introduce a simple voxel grid-based model that improves over the\nstandard MLP-based formulation in multiple dimensions and 2) introduce a new\nmultiframe loss formulation. 3) We combine both contributions in our new\nmethod, termed Floxels. On the Argoverse 2 benchmark, Floxels is surpassed only\nby EulerFlow among unsupervised methods while achieving comparable performance\nat a fraction of the computational cost. Floxels achieves a massive speedup of\nmore than ~60 - 140x over EulerFlow, reducing the runtime from a day to 10\nminutes per sequence. Over the faster but low-quality baseline, NSFP, Floxels\nachieves a speedup of ~14x.\n","authors":["David T. Hoffmann","Syed Haseeb Raza","Hanqiu Jiang","Denis Tananaev","Steffen Klingenhoefer","Martin Meinke"],"pdf_url":"https://arxiv.org/pdf/2503.04718v1.pdf","comment":"Accepted at CVPR 2025"},{"id":"http://arxiv.org/abs/2503.04715v1","updated":"2025-03-06T18:58:29Z","published":"2025-03-06T18:58:29Z","title":"Predictable Scale: Part I -- Optimal Hyperparameter Scaling Law in Large\n  Language Model Pretraining","summary":"  The impressive capabilities of Large Language Models (LLMs) across diverse\ntasks are now well-established, yet their effective deployment necessitates\ncareful hyperparameter optimization. Through extensive empirical studies\ninvolving grid searches across diverse configurations, we discover universal\nscaling laws governing these hyperparameters: optimal learning rate follows a\npower-law relationship with both model parameters and data sizes, while optimal\nbatch size scales primarily with data sizes. Our analysis reveals a convex\noptimization landscape for hyperparameters under fixed models and data size\nconditions. This convexity implies an optimal hyperparameter plateau. We\ncontribute a universal, plug-and-play optimal hyperparameter tool for the\ncommunity. Its estimated values on the test set are merely 0.07\\% away from the\nglobally optimal LLM performance found via an exhaustive search. These laws\ndemonstrate remarkable robustness across variations in model sparsity, training\ndata distribution, and model shape. To our best known, this is the first work\nthat unifies different model shapes and structures, such as Mixture-of-Experts\nmodels and dense transformers, as well as establishes optimal hyperparameter\nscaling laws across diverse data distributions. This exhaustive optimization\nprocess demands substantial computational resources, utilizing nearly one\nmillion NVIDIA H800 GPU hours to train 3,700 LLMs of varying sizes and\nhyperparameters from scratch and consuming approximately 100 trillion tokens in\ntotal. To facilitate reproducibility and further research, we will\nprogressively release all loss measurements and model checkpoints through our\ndesignated repository https://step-law.github.io/\n","authors":["Houyi Li","Wenzheng Zheng","Jingcheng Hu","Qiufeng Wang","Hanshan Zhang","Zili Wang","Yangshijie Xu","Shuigeng Zhou","Xiangyu Zhang","Daxin Jiang"],"pdf_url":"https://arxiv.org/pdf/2503.04715v1.pdf","comment":"19 pages"},{"id":"http://arxiv.org/abs/2503.04713v1","updated":"2025-03-06T18:57:40Z","published":"2025-03-06T18:57:40Z","title":"Scaling Rich Style-Prompted Text-to-Speech Datasets","summary":"  We introduce Paralinguistic Speech Captions (ParaSpeechCaps), a large-scale\ndataset that annotates speech utterances with rich style captions. While rich\nabstract tags (e.g. guttural, nasal, pained) have been explored in small-scale\nhuman-annotated datasets, existing large-scale datasets only cover basic tags\n(e.g. low-pitched, slow, loud). We combine off-the-shelf text and speech\nembedders, classifiers and an audio language model to automatically scale rich\ntag annotations for the first time. ParaSpeechCaps covers a total of 59 style\ntags, including both speaker-level intrinsic tags and utterance-level\nsituational tags. It consists of 342 hours of human-labelled data (PSC-Base)\nand 2427 hours of automatically annotated data (PSC-Scaled). We finetune\nParler-TTS, an open-source style-prompted TTS model, on ParaSpeechCaps, and\nachieve improved style consistency (+7.9% Consistency MOS) and speech quality\n(+15.5% Naturalness MOS) over the best performing baseline that combines\nexisting rich style tag datasets. We ablate several of our dataset design\nchoices to lay the foundation for future work in this space. Our dataset,\nmodels and code are released at https://github.com/ajd12342/paraspeechcaps .\n","authors":["Anuj Diwan","Zhisheng Zheng","David Harwath","Eunsol Choi"],"pdf_url":"https://arxiv.org/pdf/2503.04713v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.04712v1","updated":"2025-03-06T18:57:34Z","published":"2025-03-06T18:57:34Z","title":"Efficiently Escaping Saddle Points under Generalized Smoothness via\n  Self-Bounding Regularity","summary":"  In this paper, we study the problem of non-convex optimization on functions\nthat are not necessarily smooth using first order methods. Smoothness\n(functions whose gradient and/or Hessian are Lipschitz) is not satisfied by\nmany machine learning problems in both theory and practice, motivating a recent\nline of work studying the convergence of first order methods to first order\nstationary points under appropriate generalizations of smoothness.\n  We develop a novel framework to study convergence of first order methods to\nfirst and \\textit{second} order stationary points under generalized smoothness,\nunder more general smoothness assumptions than the literature. Using our\nframework, we show appropriate variants of GD and SGD (e.g. with appropriate\nperturbations) can converge not just to first order but also \\textit{second\norder stationary points} in runtime polylogarithmic in the dimension. To our\nknowledge, our work contains the first such result, as well as the first\n'non-textbook' rate for non-convex optimization under generalized smoothness.\nWe demonstrate that several canonical non-convex optimization problems fall\nunder our setting and framework.\n","authors":["Daniel Yiming Cao","August Y. Chen","Karthik Sridharan","Benjamin Tang"],"pdf_url":"https://arxiv.org/pdf/2503.04712v1.pdf","comment":"79 pages"},{"id":"http://arxiv.org/abs/2503.04706v1","updated":"2025-03-06T18:54:42Z","published":"2025-03-06T18:54:42Z","title":"Sample-Optimal Agnostic Boosting with Unlabeled Data","summary":"  Boosting provides a practical and provably effective framework for\nconstructing accurate learning algorithms from inaccurate rules of thumb. It\nextends the promise of sample-efficient learning to settings where direct\nEmpirical Risk Minimization (ERM) may not be implementable efficiently. In the\nrealizable setting, boosting is known to offer this computational reprieve\nwithout compromising on sample efficiency. However, in the agnostic case,\nexisting boosting algorithms fall short of achieving the optimal sample\ncomplexity.\n  This paper highlights an unexpected and previously unexplored avenue of\nimprovement: unlabeled samples. We design a computationally efficient agnostic\nboosting algorithm that matches the sample complexity of ERM, given\npolynomially many additional unlabeled samples. In fact, we show that the total\nnumber of samples needed, unlabeled and labeled inclusive, is never more than\nthat for the best known agnostic boosting algorithm -- so this result is never\nworse -- while only a vanishing fraction of these need to be labeled for the\nalgorithm to succeed. This is particularly fortuitous for learning-theoretic\napplications of agnostic boosting, which often take place in the\ndistribution-specific setting, where unlabeled samples can be availed for free.\nWe detail other applications of this result in reinforcement learning.\n","authors":["Udaya Ghai","Karan Singh"],"pdf_url":"https://arxiv.org/pdf/2503.04706v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.04704v1","updated":"2025-03-06T18:54:32Z","published":"2025-03-06T18:54:32Z","title":"Universality of Layer-Level Entropy-Weighted Quantization Beyond Model\n  Architecture and Size","summary":"  We present a novel approach to selective model quantization that transcends\nthe limitations of architecture-specific and size-dependent compression methods\nfor Large Language Models (LLMs) using Entropy-Weighted Quantization (EWQ). By\nanalyzing the entropy distribution across transformer blocks, EWQ determines\nwhich blocks can be safely quantized without causing significant performance\ndegradation, independent of model architecture or size. Our method outperforms\nuniform quantization approaches, maintaining Massive Multitask Language\nUnderstanding (MMLU) accuracy scores within 0.5% of unquantized models while\nreducing memory usage by up to 18%. We demonstrate the effectiveness of EWQ\nacross multiple architectures-from 1.6B to 70B parameters-showcasing consistent\nimprovements in the quality-compression trade-off regardless of model scale or\narchitectural design. A surprising finding of EWQ is its ability to reduce\nperplexity compared to unquantized models, suggesting the presence of\nbeneficial regularization through selective precision reduction. This\nimprovement holds across different model families, indicating a fundamental\nrelationship between layer-level entropy and optimal precision requirements.\nAdditionally, we introduce FastEWQ, a rapid method for entropy distribution\nanalysis that eliminates the need for loading model weights. This technique\nleverages universal characteristics of entropy distribution that persist across\nvarious architectures and scales, enabling near-instantaneous quantization\ndecisions while maintaining 80% classification accuracy with full entropy\nanalysis. Our results demonstrate that effective quantization strategies can be\ndeveloped independently of specific architectural choices or model sizes,\nopening new possibilities for efficient LLM deployment.\n","authors":["Alireza Behtash","Marijan Fofonjka","Ethan Baird","Tyler Mauer","Hossein Moghimifam","David Stout","Joel Dennison"],"pdf_url":"https://arxiv.org/pdf/2503.04704v1.pdf","comment":"29 pages, 7 figures, 14 tables; Comments are welcome"},{"id":"http://arxiv.org/abs/2503.04697v1","updated":"2025-03-06T18:43:29Z","published":"2025-03-06T18:43:29Z","title":"L1: Controlling How Long A Reasoning Model Thinks With Reinforcement\n  Learning","summary":"  Reasoning language models have shown an uncanny ability to improve\nperformance at test-time by ``thinking longer''-that is, by generating longer\nchain-of-thought sequences and hence using more compute. However, the length of\ntheir chain-of-thought reasoning is not controllable, making it impossible to\nallocate test-time compute to achieve a desired level of performance. We\nintroduce Length Controlled Policy Optimization (LCPO), a simple reinforcement\nlearning method that optimizes for accuracy and adherence to user-specified\nlength constraints. We use LCPO to train L1, a reasoning language model that\nproduces outputs satisfying a length constraint given in its prompt. L1's\nlength control allows for smoothly trading off computational cost and accuracy\non a wide range of tasks, and outperforms the state-of-the-art S1 method for\nlength control. Furthermore, we uncover an unexpected short chain-of-thought\ncapability in models trained with LCPO. For instance, our 1.5B L1 model\nsurpasses GPT-4o at equal reasoning lengths. Overall, LCPO enables precise\ncontrol over reasoning length, allowing for fine-grained allocation of\ntest-time compute and accuracy. We release code and models at\nhttps://www.cmu-l3.github.io/l1\n","authors":["Pranjal Aggarwal","Sean Welleck"],"pdf_url":"https://arxiv.org/pdf/2503.04697v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.01843v2","updated":"2025-03-06T18:38:33Z","published":"2025-03-03T18:59:40Z","title":"When Can You Get Away with Low Memory Adam?","summary":"  Adam is the go-to optimizer for training modern machine learning models, but\nit requires additional memory to maintain the moving averages of the gradients\nand their squares. While various low-memory optimizers have been proposed that\nsometimes match the performance of Adam, their lack of reliability has left\nAdam as the default choice. In this work, we apply a simple layer-wise\nSignal-to-Noise Ratio (SNR) analysis to quantify when second-moment tensors can\nbe effectively replaced by their means across different dimensions. Our SNR\nanalysis reveals how architecture, training hyperparameters, and dataset\nproperties impact compressibility along Adam's trajectory, naturally leading to\n$\\textit{SlimAdam}$, a memory-efficient Adam variant. $\\textit{SlimAdam}$\ncompresses the second moments along dimensions with high SNR when feasible, and\nleaves when compression would be detrimental. Through experiments across a\ndiverse set of architectures and training scenarios, we show that\n$\\textit{SlimAdam}$ matches Adam's performance and stability while saving up to\n$98\\%$ of total second moments. Code for $\\textit{SlimAdam}$ is available at\nhttps://github.com/dayal-kalra/low-memory-adam.\n","authors":["Dayal Singh Kalra","John Kirchenbauer","Maissam Barkeshli","Tom Goldstein"],"pdf_url":"https://arxiv.org/pdf/2503.01843v2.pdf","comment":"Acknowledgement updates and minor writing edits"},{"id":"http://arxiv.org/abs/2503.04690v1","updated":"2025-03-06T18:32:35Z","published":"2025-03-06T18:32:35Z","title":"Coarse graining and reduced order models for plume ejection dynamics","summary":"  Monitoring the atmospheric dispersion of pollutants is increasingly critical\nfor environmental impact assessments. High-fidelity computational models are\noften employed to simulate plume dynamics, guiding decision-making and\nprioritizing resource deployment. However, such models can be prohibitively\nexpensive to simulate, as they require resolving turbulent flows at fine\nspatial and temporal resolutions. Moreover, there are at least two distinct\ndynamical regimes of interest in the plume: (i) the initial ejection of the\nplume where turbulent mixing is generated by the shear-driven Kelvin-Helmholtz\ninstability, and (ii) the ensuing turbulent diffusion and advection which is\noften modeled by the Gaussian plume model. We address the challenge of modeling\nthe initial plume generation. Specifically, we propose a data-driven framework\nthat identifies a reduced-order analytical model for plume dynamics -- directly\nfrom video data. We extract a time series of plume center and edge points from\nvideo snapshots and evaluate different regressions based to their extrapolation\nperformance to generate a time series of coefficients that characterize the\nplume's overall direction and spread. We regress to a sinusoidal model inspired\nby the Kelvin-Helmholtz instability for the edge points in order to identify\nthe plume's dispersion and vorticity. Overall, this reduced-order modeling\nframework provides a data-driven and lightweight approach to capture the\ndominant features of the initial nonlinear point-source plume dynamics,\nagnostic to plume type and starting only from video. The resulting model is a\npre-cursor to standard models such as the Gaussian plume model and has the\npotential to enable rapid assessment and evaluation of critical environmental\nhazards, such as methane leaks, chemical spills, and pollutant dispersal from\nsmokestacks.\n","authors":["Ike Griss Salas","Megan R. Ebers","Jake Stevens-Haas","J. Nathan Kutz"],"pdf_url":"https://arxiv.org/pdf/2503.04690v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.02800v2","updated":"2025-03-06T18:30:45Z","published":"2025-03-04T17:20:43Z","title":"RAAD-LLM: Adaptive Anomaly Detection Using LLMs and RAG Integration","summary":"  Anomaly detection in complex industrial environments poses unique challenges,\nparticularly in contexts characterized by data sparsity and evolving\noperational conditions. Predictive maintenance (PdM) in such settings demands\nmethodologies that are adaptive, transferable, and capable of integrating\ndomain-specific knowledge. In this paper, we present RAAD-LLM, a novel\nframework for adaptive anomaly detection, leveraging large language models\n(LLMs) integrated with Retrieval-Augmented Generation (RAG). This approach\naddresses the aforementioned PdM challenges. By effectively utilizing\ndomain-specific knowledge, RAAD-LLM enhances the detection of anomalies in time\nseries data without requiring fine-tuning on specific datasets. The framework's\nadaptability mechanism enables it to adjust its understanding of normal\noperating conditions dynamically, thus increasing detection accuracy. We\nvalidate this methodology through a real-world application for a plastics\nmanufacturing plant and the Skoltech Anomaly Benchmark (SKAB). Results show\nsignificant improvements over our previous model with an accuracy increase from\n70.7% to 89.1% on the real-world dataset. By allowing for the enriching of\ninput series data with semantics, RAAD-LLM incorporates multimodal capabilities\nthat facilitate more collaborative decision-making between the model and plant\noperators. Overall, our findings support RAAD-LLM's ability to revolutionize\nanomaly detection methodologies in PdM, potentially leading to a paradigm shift\nin how anomaly detection is implemented across various industries.\n","authors":["Alicia Russell-Gilbert","Sudip Mittal","Shahram Rahimi","Maria Seale","Joseph Jabour","Thomas Arnold","Joshua Church"],"pdf_url":"https://arxiv.org/pdf/2503.02800v2.pdf","comment":"arXiv admin note: substantial text overlap with arXiv:2411.00914"},{"id":"http://arxiv.org/abs/2503.04687v1","updated":"2025-03-06T18:29:45Z","published":"2025-03-06T18:29:45Z","title":"Compositional World Knowledge leads to High Utility Synthetic data","summary":"  Machine learning systems struggle with robustness, under subpopulation\nshifts. This problem becomes especially pronounced in scenarios where only a\nsubset of attribute combinations is observed during training -a severe form of\nsubpopulation shift, referred as compositional shift. To address this problem,\nwe ask the following question: Can we improve the robustness by training on\nsynthetic data, spanning all possible attribute combinations? We first show\nthat training of conditional diffusion models on limited data lead to incorrect\nunderlying distribution. Therefore, synthetic data sampled from such models\nwill result in unfaithful samples and does not lead to improve performance of\ndownstream machine learning systems. To address this problem, we propose CoInD\nto reflect the compositional nature of the world by enforcing conditional\nindependence through minimizing Fisher's divergence between joint and marginal\ndistributions. We demonstrate that synthetic data generated by CoInD is\nfaithful and this translates to state-of-the-art worst-group accuracy on\ncompositional shift tasks on CelebA.\n","authors":["Sachit Gaudi","Gautam Sreekumar","Vishnu Boddeti"],"pdf_url":"https://arxiv.org/pdf/2503.04687v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.04684v1","updated":"2025-03-06T18:26:42Z","published":"2025-03-06T18:26:42Z","title":"Propagating Model Uncertainty through Filtering-based Probabilistic\n  Numerical ODE Solvers","summary":"  Filtering-based probabilistic numerical solvers for ordinary differential\nequations (ODEs), also known as ODE filters, have been established as efficient\nmethods for quantifying numerical uncertainty in the solution of ODEs. In\npractical applications, however, the underlying dynamical system often contains\nuncertain parameters, requiring the propagation of this model uncertainty to\nthe ODE solution. In this paper, we demonstrate that ODE filters, despite their\nprobabilistic nature, do not automatically solve this uncertainty propagation\nproblem. To address this limitation, we present a novel approach that combines\nODE filters with numerical quadrature to properly marginalize over uncertain\nparameters, while accounting for both parameter uncertainty and numerical\nsolver uncertainty. Experiments across multiple dynamical systems demonstrate\nthat the resulting uncertainty estimates closely match reference solutions.\nNotably, we show how the numerical uncertainty from the ODE solver can help\nprevent overconfidence in the propagated uncertainty estimates, especially when\nusing larger step sizes. Our results illustrate that probabilistic numerical\nmethods can effectively quantify both numerical and parametric uncertainty in\ndynamical systems.\n","authors":["Dingling Yao","Filip Tronarp","Nathanael Bosch"],"pdf_url":"https://arxiv.org/pdf/2503.04684v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.04680v1","updated":"2025-03-06T18:22:46Z","published":"2025-03-06T18:22:46Z","title":"Matrix Factorization for Inferring Associations and Missing Links","summary":"  Missing link prediction is a method for network analysis, with applications\nin recommender systems, biology, social sciences, cybersecurity, information\nretrieval, and Artificial Intelligence (AI) reasoning in Knowledge Graphs.\nMissing link prediction identifies unseen but potentially existing connections\nin a network by analyzing the observed patterns and relationships. In\nproliferation detection, this supports efforts to identify and characterize\nattempts by state and non-state actors to acquire nuclear weapons or associated\ntechnology - a notoriously challenging but vital mission for global security.\nDimensionality reduction techniques like Non-Negative Matrix Factorization\n(NMF) and Logistic Matrix Factorization (LMF) are effective but require\nselection of the matrix rank parameter, that is, of the number of hidden\nfeatures, k, to avoid over/under-fitting. We introduce novel Weighted (WNMFk),\nBoolean (BNMFk), and Recommender (RNMFk) matrix factorization methods, along\nwith ensemble variants incorporating logistic factorization, for link\nprediction. Our methods integrate automatic model determination for rank\nestimation by evaluating stability and accuracy using a modified bootstrap\nmethodology and uncertainty quantification (UQ), assessing prediction\nreliability under random perturbations. We incorporate Otsu threshold selection\nand k-means clustering for Boolean matrix factorization, comparing them to\ncoordinate descent-based Boolean thresholding. Our experiments highlight the\nimpact of rank k selection, evaluate model performance under varying test-set\nsizes, and demonstrate the benefits of UQ for reliable predictions using\nabstention. We validate our methods on three synthetic datasets (Boolean and\nuniformly distributed) and benchmark them against LMF and symmetric LMF\n(symLMF) on five real-world protein-protein interaction networks, showcasing an\nimproved prediction performance.\n","authors":["Ryan Barron","Maksim E. Eren","Duc P. Truong","Cynthia Matuszek","James Wendelberger","Mary F. Dorn","Boian Alexandrov"],"pdf_url":"https://arxiv.org/pdf/2503.04680v1.pdf","comment":"35 pages, 14 figures, 3 tables, 1 algorithm"},{"id":"http://arxiv.org/abs/2503.04679v1","updated":"2025-03-06T18:22:29Z","published":"2025-03-06T18:22:29Z","title":"Multi-Agent Inverse Q-Learning from Demonstrations","summary":"  When reward functions are hand-designed, deep reinforcement learning\nalgorithms often suffer from reward misspecification, causing them to learn\nsuboptimal policies in terms of the intended task objectives. In the\nsingle-agent case, inverse reinforcement learning (IRL) techniques attempt to\naddress this issue by inferring the reward function from expert demonstrations.\nHowever, in multi-agent problems, misalignment between the learned and true\nobjectives is exacerbated due to increased environment non-stationarity and\nvariance that scales with multiple agents. As such, in multi-agent general-sum\ngames, multi-agent IRL algorithms have difficulty balancing cooperative and\ncompetitive objectives. To address these issues, we propose Multi-Agent\nMarginal Q-Learning from Demonstrations (MAMQL), a novel sample-efficient\nframework for multi-agent IRL. For each agent, MAMQL learns a critic\nmarginalized over the other agents' policies, allowing for a well-motivated use\nof Boltzmann policies in the multi-agent context. We identify a connection\nbetween optimal marginalized critics and single-agent soft-Q IRL, allowing us\nto apply a direct, simple optimization criterion from the single-agent domain.\nAcross our experiments on three different simulated domains, MAMQL\nsignificantly outperforms previous multi-agent methods in average reward,\nsample efficiency, and reward recovery by often more than 2-5x. We make our\ncode available at https://sites.google.com/view/mamql .\n","authors":["Nathaniel Haynam","Adam Khoja","Dhruv Kumar","Vivek Myers","Erdem Byk"],"pdf_url":"https://arxiv.org/pdf/2503.04679v1.pdf","comment":"8 pages, 4 figures, 2 tables. Published at the International\n  Conference on Robotics and Automation (ICRA) 2025"},{"id":"http://arxiv.org/abs/2410.06186v4","updated":"2025-03-06T18:20:00Z","published":"2024-10-08T16:51:10Z","title":"The Last Iterate Advantage: Empirical Auditing and Principled Heuristic\n  Analysis of Differentially Private SGD","summary":"  We propose a simple heuristic privacy analysis of noisy clipped stochastic\ngradient descent (DP-SGD) in the setting where only the last iterate is\nreleased and the intermediate iterates remain hidden. Namely, our heuristic\nassumes a linear structure for the model.\n  We show experimentally that our heuristic is predictive of the outcome of\nprivacy auditing applied to various training procedures. Thus it can be used\nprior to training as a rough estimate of the final privacy leakage. We also\nprobe the limitations of our heuristic by providing some artificial\ncounterexamples where it underestimates the privacy leakage.\n  The standard composition-based privacy analysis of DP-SGD effectively assumes\nthat the adversary has access to all intermediate iterates, which is often\nunrealistic. However, this analysis remains the state of the art in practice.\nWhile our heuristic does not replace a rigorous privacy analysis, it\nillustrates the large gap between the best theoretical upper bounds and the\nprivacy auditing lower bounds and sets a target for further work to improve the\ntheoretical privacy analyses. We also empirically support our heuristic and\nshow existing privacy auditing attacks are bounded by our heuristic analysis in\nboth vision and language tasks.\n","authors":["Thomas Steinke","Milad Nasr","Arun Ganesh","Borja Balle","Christopher A. Choquette-Choo","Matthew Jagielski","Jamie Hayes","Abhradeep Guha Thakurta","Adam Smith","Andreas Terzis"],"pdf_url":"https://arxiv.org/pdf/2410.06186v4.pdf","comment":"ICLR 2025 camera-ready version"},{"id":"http://arxiv.org/abs/2402.10065v2","updated":"2025-03-06T18:17:02Z","published":"2024-02-15T16:30:55Z","title":"Some Targets Are Harder to Identify than Others: Quantifying the\n  Target-dependent Membership Leakage","summary":"  In a Membership Inference (MI) game, an attacker tries to infer whether a\ntarget point was included or not in the input of an algorithm. Existing works\nshow that some target points are easier to identify, while others are harder.\nThis paper explains the target-dependent hardness of membership attacks by\nstudying the powers of the optimal attacks in a fixed-target MI game. We\ncharacterise the optimal advantage and trade-off functions of attacks against\nthe empirical mean in terms of the Mahalanobis distance between the target\npoint and the data-generating distribution. We further derive the impacts of\ntwo privacy defences, i.e. adding Gaussian noise and sub-sampling, and that of\ntarget misspecification on optimal attacks. As by-products of our novel\nanalysis of the Likelihood Ratio (LR) test, we provide a new covariance attack\nwhich generalises and improves the scalar product attack. Also, we propose a\nnew optimal canary-choosing strategy for auditing privacy in the white-box\nfederated learning setting. Our experiments validate that the Mahalanobis score\nexplains the hardness of fixed-target MI games.\n","authors":["Achraf Azize","Debabrota Basu"],"pdf_url":"https://arxiv.org/pdf/2402.10065v2.pdf","comment":"Appears in AISTATS 2025 (Oral)"},{"id":"http://arxiv.org/abs/2502.02067v2","updated":"2025-03-06T18:09:38Z","published":"2025-02-04T07:32:39Z","title":"AdaptBot: Combining LLM with Knowledge Graphs and Human Input for\n  Generic-to-Specific Task Decomposition and Knowledge Refinement","summary":"  An embodied agent assisting humans is often asked to complete new tasks, and\nthere may not be sufficient time or labeled examples to train the agent to\nperform these new tasks. Large Language Models (LLMs) trained on considerable\nknowledge across many domains can be used to predict a sequence of abstract\nactions for completing such tasks, although the agent may not be able to\nexecute this sequence due to task-, agent-, or domain-specific constraints. Our\nframework addresses these challenges by leveraging the generic predictions\nprovided by LLM and the prior domain knowledge encoded in a Knowledge Graph\n(KG), enabling an agent to quickly adapt to new tasks. The robot also solicits\nand uses human input as needed to refine its existing knowledge. Based on\nexperimental evaluation in the context of cooking and cleaning tasks in\nsimulation domains, we demonstrate that the interplay between LLM, KG, and\nhuman input leads to substantial performance gains compared with just using the\nLLM. Project website{\\S}: https://sssshivvvv.github.io/adaptbot/\n","authors":["Shivam Singh","Karthik Swaminathan","Nabanita Dash","Ramandeep Singh","Snehasis Banerjee","Mohan Sridharan","Madhava Krishna"],"pdf_url":"https://arxiv.org/pdf/2502.02067v2.pdf","comment":"Accepted to IEEE International Conference on Robotics and Automation\n  (ICRA) 2025"},{"id":"http://arxiv.org/abs/2502.12360v2","updated":"2025-03-06T18:07:00Z","published":"2025-02-17T22:50:45Z","title":"Detecting Systematic Weaknesses in Vision Models along Predefined\n  Human-Understandable Dimensions","summary":"  Slice discovery methods (SDMs) are prominent algorithms for finding\nsystematic weaknesses in DNNs. They identify top-k semantically coherent\nslices/subsets of data where a DNN-under-test has low performance. For being\ndirectly useful, slices should be aligned with human-understandable and\nrelevant dimensions, which, for example, are defined by safety and domain\nexperts as part of the operational design domain (ODD). While SDMs can be\napplied effectively on structured data, their application on image data is\ncomplicated by the lack of semantic metadata. To address these issues, we\npresent an algorithm that combines foundation models for zero-shot image\nclassification to generate semantic metadata with methods for combinatorial\nsearch to find systematic weaknesses in images. In contrast to existing\napproaches, ours identifies weak slices that are in line with pre-defined\nhuman-understandable dimensions. As the algorithm includes foundation models,\nits intermediate and final results may not always be exact. Therefore, we\ninclude an approach to address the impact of noisy metadata. We validate our\nalgorithm on both synthetic and real-world datasets, demonstrating its ability\nto recover human-understandable systematic weaknesses. Furthermore, using our\napproach, we identify systematic weaknesses of multiple pre-trained and\npublicly available state-of-the-art computer vision DNNs.\n","authors":["Sujan Sai Gannamaneni","Rohil Prakash Rao","Michael Mock","Maram Akila","Stefan Wrobel"],"pdf_url":"https://arxiv.org/pdf/2502.12360v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.04667v1","updated":"2025-03-06T17:59:51Z","published":"2025-03-06T17:59:51Z","title":"An Information-theoretic Multi-task Representation Learning Framework\n  for Natural Language Understanding","summary":"  This paper proposes a new principled multi-task representation learning\nframework (InfoMTL) to extract noise-invariant sufficient representations for\nall tasks. It ensures sufficiency of shared representations for all tasks and\nmitigates the negative effect of redundant features, which can enhance language\nunderstanding of pre-trained language models (PLMs) under the multi-task\nparadigm. Firstly, a shared information maximization principle is proposed to\nlearn more sufficient shared representations for all target tasks. It can avoid\nthe insufficiency issue arising from representation compression in the\nmulti-task paradigm. Secondly, a task-specific information minimization\nprinciple is designed to mitigate the negative effect of potential redundant\nfeatures in the input for each task. It can compress task-irrelevant redundant\ninformation and preserve necessary information relevant to the target for\nmulti-task prediction. Experiments on six classification benchmarks show that\nour method outperforms 12 comparative multi-task methods under the same\nmulti-task settings, especially in data-constrained and noisy scenarios.\nExtensive experiments demonstrate that the learned representations are more\nsufficient, data-efficient, and robust.\n","authors":["Dou Hu","Lingwei Wei","Wei Zhou","Songlin Hu"],"pdf_url":"https://arxiv.org/pdf/2503.04667v1.pdf","comment":"11 pages, accepted to AAAI 2025 (main conference), the code is\n  available at https://github.com/zerohd4869/InfoMTL"},{"id":"http://arxiv.org/abs/2503.04655v1","updated":"2025-03-06T17:49:13Z","published":"2025-03-06T17:49:13Z","title":"CLDyB: Towards Dynamic Benchmarking for Continual Learning with\n  Pre-trained Models","summary":"  The advent of the foundation model era has sparked significant research\ninterest in leveraging pre-trained representations for continual learning (CL),\nyielding a series of top-performing CL methods on standard evaluation\nbenchmarks. Nonetheless, there are growing concerns regarding potential data\ncontamination during the pre-training stage. Furthermore, standard evaluation\nbenchmarks, which are typically static, fail to capture the complexities of\nreal-world CL scenarios, resulting in saturated performance. To address these\nissues, we describe CL on dynamic benchmarks (CLDyB), a general computational\nframework based on Markov decision processes for evaluating CL methods\nreliably. CLDyB dynamically identifies inherently difficult and\nalgorithm-dependent tasks for the given CL methods, and determines challenging\ntask orders using Monte Carlo tree search. Leveraging CLDyB, we first conduct a\njoint evaluation of multiple state-of-the-art CL methods, leading to a set of\ncommonly challenging and generalizable task sequences where existing CL methods\ntend to perform poorly. We then conduct separate evaluations of individual CL\nmethods using CLDyB, discovering their respective strengths and weaknesses. The\nsource code and generated task sequences are publicly accessible at\nhttps://github.com/szc12153/CLDyB.\n","authors":["Shengzhuang Chen","Yikai Liao","Xiaoxiao Sun","Kede Ma","Ying Wei"],"pdf_url":"https://arxiv.org/pdf/2503.04655v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.04650v1","updated":"2025-03-06T17:39:12Z","published":"2025-03-06T17:39:12Z","title":"Joint Masked Reconstruction and Contrastive Learning for Mining\n  Interactions Between Proteins","summary":"  Protein-protein interaction (PPI) prediction is an instrumental means in\nelucidating the mechanisms underlying cellular operations, holding significant\npractical implications for the realms of pharmaceutical development and\nclinical treatment. Presently, the majority of research methods primarily\nconcentrate on the analysis of amino acid sequences, while investigations\npredicated on protein structures remain in the nascent stages of exploration.\nDespite the emergence of several structure-based algorithms in recent years,\nthese are still confronted with inherent challenges: (1) the extraction of\nintrinsic structural information of proteins typically necessitates the\nexpenditure of substantial computational resources; (2) these models are overly\nreliant on seen protein data, struggling to effectively unearth interaction\ncues between unknown proteins. To further propel advancements in this domain,\nthis paper introduces a novel PPI prediction method jointing masked\nreconstruction and contrastive learning, termed JmcPPI. This methodology\ndissects the PPI prediction task into two distinct phases: during the residue\nstructure encoding phase, JmcPPI devises two feature reconstruction tasks and\nemploys graph attention mechanism to capture structural information between\nresidues; during the protein interaction inference phase, JmcPPI perturbs the\noriginal PPI graph and employs a multi-graph contrastive learning strategy to\nthoroughly mine extrinsic interaction information of novel proteins. Extensive\nexperiments conducted on three widely utilized PPI datasets demonstrate that\nJmcPPI surpasses existing optimal baseline models across various data partition\nschemes. The associated code can be accessed via\nhttps://github.com/lijfrank-open/JmcPPI.\n","authors":["Jiang Li","Xiaoping Wang"],"pdf_url":"https://arxiv.org/pdf/2503.04650v1.pdf","comment":"Submitted"},{"id":"http://arxiv.org/abs/2503.04649v1","updated":"2025-03-06T17:35:37Z","published":"2025-03-06T17:35:37Z","title":"Transferable Foundation Models for Geometric Tasks on Point Cloud\n  Representations: Geometric Neural Operators","summary":"  We introduce methods for obtaining pretrained Geometric Neural Operators\n(GNPs) that can serve as basal foundation models for use in obtaining geometric\nfeatures. These can be used within data processing pipelines for machine\nlearning tasks and numerical methods. We show how our GNPs can be trained to\nlearn robust latent representations for the differential geometry of\npoint-clouds to provide estimates of metric, curvature, and other shape-related\nfeatures. We demonstrate how our pre-trained GNPs can be used (i) to estimate\nthe geometric properties of surfaces of arbitrary shape and topologies with\nrobustness in the presence of noise, (ii) to approximate solutions of geometric\npartial differential equations (PDEs) on manifolds, and (iii) to solve\nequations for shape deformations such as curvature driven flows. We also\nrelease a package of the codes and weights for using our pre-trained GNPs for\nprocessing point cloud representations. This allows for incorporating our\npre-trained GNPs as components for reuse within existing and new data\nprocessing pipelines. The GNPs also can be used as part of numerical solvers\ninvolving geometry or as part of methods for performing inference and other\ngeometric tasks.\n","authors":["Blaine Quackenbush","Paul J. Atzberger"],"pdf_url":"https://arxiv.org/pdf/2503.04649v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2501.04873v2","updated":"2025-03-06T17:35:19Z","published":"2025-01-08T23:07:10Z","title":"Back Home: A Machine Learning Approach to Seashell Classification and\n  Ecosystem Restoration","summary":"  In Costa Rica, an average of 5 tons of seashells are extracted from\necosystems annually. Confiscated seashells, cannot be returned to their\necosystems due to the lack of origin recognition. To address this issue, we\ndeveloped a convolutional neural network (CNN) specifically for seashell\nidentification. We built a dataset from scratch, consisting of approximately\n19000 images from the Pacific and Caribbean coasts. Using this dataset, the\nmodel achieved a classification accuracy exceeding 85%. The model has been\nintegrated into a user-friendly application, which has classified over 36,000\nseashells to date, delivering real-time results within 3 seconds per image. To\nfurther enhance the system's accuracy, an anomaly detection mechanism was\nincorporated to filter out irrelevant or anomalous inputs, ensuring only valid\nseashell images are processed.\n","authors":["Alexander Valverde","Luis Solano"],"pdf_url":"https://arxiv.org/pdf/2501.04873v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.04641v1","updated":"2025-03-06T17:31:43Z","published":"2025-03-06T17:31:43Z","title":"Simulating the Real World: A Unified Survey of Multimodal Generative\n  Models","summary":"  Understanding and replicating the real world is a critical challenge in\nArtificial General Intelligence (AGI) research. To achieve this, many existing\napproaches, such as world models, aim to capture the fundamental principles\ngoverning the physical world, enabling more accurate simulations and meaningful\ninteractions. However, current methods often treat different modalities,\nincluding 2D (images), videos, 3D, and 4D representations, as independent\ndomains, overlooking their interdependencies. Additionally, these methods\ntypically focus on isolated dimensions of reality without systematically\nintegrating their connections. In this survey, we present a unified survey for\nmultimodal generative models that investigate the progression of data\ndimensionality in real-world simulation. Specifically, this survey starts from\n2D generation (appearance), then moves to video (appearance+dynamics) and 3D\ngeneration (appearance+geometry), and finally culminates in 4D generation that\nintegrate all dimensions. To the best of our knowledge, this is the first\nattempt to systematically unify the study of 2D, video, 3D and 4D generation\nwithin a single framework. To guide future research, we provide a comprehensive\nreview of datasets, evaluation metrics and future directions, and fostering\ninsights for newcomers. This survey serves as a bridge to advance the study of\nmultimodal generative models and real-world simulation within a unified\nframework.\n","authors":["Yuqi Hu","Longguang Wang","Xian Liu","Ling-Hao Chen","Yuwei Guo","Yukai Shi","Ce Liu","Anyi Rao","Zeyu Wang","Hui Xiong"],"pdf_url":"https://arxiv.org/pdf/2503.04641v1.pdf","comment":"Repository for the related papers at\n  https://github.com/ALEEEHU/World-Simulator"},{"id":"http://arxiv.org/abs/2503.04639v1","updated":"2025-03-06T17:28:48Z","published":"2025-03-06T17:28:48Z","title":"Enhancing SAM with Efficient Prompting and Preference Optimization for\n  Semi-supervised Medical Image Segmentation","summary":"  Foundational models such as the Segment Anything Model (SAM) are gaining\ntraction in medical imaging segmentation, supporting multiple downstream tasks.\nHowever, such models are supervised in nature, still relying on large annotated\ndatasets or prompts supplied by experts. Conventional techniques such as active\nlearning to alleviate such limitations are limited in scope and still\nnecessitate continuous human involvement and complex domain knowledge for label\nrefinement or establishing reward ground truth. To address these challenges, we\npropose an enhanced Segment Anything Model (SAM) framework that utilizes\nannotation-efficient prompts generated in a fully unsupervised fashion, while\nstill capturing essential semantic, location, and shape information through\ncontrastive language-image pretraining and visual question answering. We adopt\nthe direct preference optimization technique to design an optimal policy that\nenables the model to generate high-fidelity segmentations with simple ratings\nor rankings provided by a virtual annotator simulating the human annotation\nprocess. State-of-the-art performance of our framework in tasks such as lung\nsegmentation, breast tumor segmentation, and organ segmentation across various\nmodalities, including X-ray, ultrasound, and abdominal CT, justifies its\neffectiveness in low-annotation data scenarios.\n","authors":["Aishik Konwer","Zhijian Yang","Erhan Bas","Cao Xiao","Prateek Prasanna","Parminder Bhatia","Taha Kass-Hout"],"pdf_url":"https://arxiv.org/pdf/2503.04639v1.pdf","comment":"Accepted to CVPR 2025"},{"id":"http://arxiv.org/abs/2503.04638v1","updated":"2025-03-06T17:25:46Z","published":"2025-03-06T17:25:46Z","title":"No Forgetting Learning: Memory-free Continual Learning","summary":"  Continual Learning (CL) remains a central challenge in deep learning, where\nmodels must sequentially acquire new knowledge while mitigating Catastrophic\nForgetting (CF) of prior tasks. Existing approaches often struggle with\nefficiency and scalability, requiring extensive memory or model buffers. This\nwork introduces ``No Forgetting Learning\" (NFL), a memory-free CL framework\nthat leverages knowledge distillation to maintain stability while preserving\nplasticity. Memory-free means the NFL does not rely on any memory buffer.\nThrough extensive evaluations of three benchmark datasets, we demonstrate that\nNFL achieves competitive performance while utilizing approximately 14.75 times\nless memory than state-of-the-art methods. Furthermore, we introduce a new\nmetric to better assess CL's plasticity-stability trade-off.\n","authors":["Mohammad Ali Vahedifar","Qi Zhang"],"pdf_url":"https://arxiv.org/pdf/2503.04638v1.pdf","comment":"This paper is submitted to ICCV 2025"},{"id":"http://arxiv.org/abs/2202.00665v4","updated":"2025-03-06T17:24:46Z","published":"2022-02-01T18:58:33Z","title":"Tutorial on amortized optimization","summary":"  Optimization is a ubiquitous modeling tool and is often deployed in settings\nwhich repeatedly solve similar instances of the same problem. Amortized\noptimization methods use learning to predict the solutions to problems in these\nsettings, exploiting the shared structure between similar problem instances.\nThese methods have been crucial in variational inference and reinforcement\nlearning and are capable of solving optimization problems many orders of\nmagnitudes times faster than traditional optimization methods that do not use\namortization. This tutorial presents an introduction to the amortized\noptimization foundations behind these advancements and overviews their\napplications in variational inference, sparse coding, gradient-based\nmeta-learning, control, reinforcement learning, convex optimization, optimal\ntransport, and deep equilibrium networks. The source code for this tutorial is\navailable at\nhttps://github.com/facebookresearch/amortized-optimization-tutorial.\n","authors":["Brandon Amos"],"pdf_url":"https://arxiv.org/pdf/2202.00665v4.pdf","comment":"Foundations and Trends in Machine Learning"},{"id":"http://arxiv.org/abs/2503.04636v1","updated":"2025-03-06T17:24:06Z","published":"2025-03-06T17:24:06Z","title":"Mark Your LLM: Detecting the Misuse of Open-Source Large Language Models\n  via Watermarking","summary":"  As open-source large language models (LLMs) like Llama3 become more capable,\nit is crucial to develop watermarking techniques to detect their potential\nmisuse. Existing watermarking methods either add watermarks during LLM\ninference, which is unsuitable for open-source LLMs, or primarily target\nclassification LLMs rather than recent generative LLMs. Adapting these\nwatermarks to open-source LLMs for misuse detection remains an open challenge.\nThis work defines two misuse scenarios for open-source LLMs: intellectual\nproperty (IP) violation and LLM Usage Violation. Then, we explore the\napplication of inference-time watermark distillation and backdoor watermarking\nin these contexts. We propose comprehensive evaluation methods to assess the\nimpact of various real-world further fine-tuning scenarios on watermarks and\nthe effect of these watermarks on LLM performance. Our experiments reveal that\nbackdoor watermarking could effectively detect IP Violation, while\ninference-time watermark distillation is applicable in both scenarios but less\nrobust to further fine-tuning and has a more significant impact on LLM\nperformance compared to backdoor watermarking. Exploring more advanced\nwatermarking methods for open-source LLMs to detect their misuse should be an\nimportant future direction.\n","authors":["Yijie Xu","Aiwei Liu","Xuming Hu","Lijie Wen","Hui Xiong"],"pdf_url":"https://arxiv.org/pdf/2503.04636v1.pdf","comment":"Accepted by the 1st Workshop on GenAI Watermarking, collocated with\n  ICLR 2025"},{"id":"http://arxiv.org/abs/2503.00897v3","updated":"2025-03-06T17:19:22Z","published":"2025-03-02T13:43:53Z","title":"A Simple and Effective Reinforcement Learning Method for Text-to-Image\n  Diffusion Fine-tuning","summary":"  Reinforcement learning (RL)-based fine-tuning has emerged as a powerful\napproach for aligning diffusion models with black-box objectives. Proximal\npolicy optimization (PPO) is the most popular choice of method for policy\noptimization. While effective in terms of performance, PPO is highly sensitive\nto hyper-parameters and involves substantial computational overhead. REINFORCE,\non the other hand, mitigates some computational complexities such as high\nmemory overhead and sensitive hyper-parameter tuning, but has suboptimal\nperformance due to high-variance and sample inefficiency. While the variance of\nthe REINFORCE can be reduced by sampling multiple actions per input prompt and\nusing a baseline correction term, it still suffers from sample inefficiency. To\naddress these challenges, we systematically analyze the\nefficiency-effectiveness trade-off between REINFORCE and PPO, and propose\nleave-one-out PPO (LOOP), a novel RL for diffusion fine-tuning method. LOOP\ncombines variance reduction techniques from REINFORCE, such as sampling\nmultiple actions per input prompt and a baseline correction term, with the\nrobustness and sample efficiency of PPO via clipping and importance sampling.\nOur results demonstrate that LOOP effectively improves diffusion models on\nvarious black-box objectives, and achieves a better balance between\ncomputational efficiency and performance.\n","authors":["Shashank Gupta","Chaitanya Ahuja","Tsung-Yu Lin","Sreya Dutta Roy","Harrie Oosterhuis","Maarten de Rijke","Satya Narayan Shukla"],"pdf_url":"https://arxiv.org/pdf/2503.00897v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.04626v1","updated":"2025-03-06T17:12:46Z","published":"2025-03-06T17:12:46Z","title":"IDInit: A Universal and Stable Initialization Method for Neural Network\n  Training","summary":"  Deep neural networks have achieved remarkable accomplishments in practice.\nThe success of these networks hinges on effective initialization methods, which\nare vital for ensuring stable and rapid convergence during training. Recently,\ninitialization methods that maintain identity transition within layers have\nshown good efficiency in network training. These techniques (e.g., Fixup) set\nspecific weights to zero to achieve identity control. However, settings of\nremaining weight (e.g., Fixup uses random values to initialize non-zero\nweights) will affect the inductive bias that is achieved only by a zero weight,\nwhich may be harmful to training. Addressing this concern, we introduce fully\nidentical initialization (IDInit), a novel method that preserves identity in\nboth the main and sub-stem layers of residual networks. IDInit employs a padded\nidentity-like matrix to overcome rank constraints in non-square weight\nmatrices. Furthermore, we show the convergence problem of an identity matrix\ncan be solved by stochastic gradient descent. Additionally, we enhance the\nuniversality of IDInit by processing higher-order weights and addressing dead\nneuron problems. IDInit is a straightforward yet effective initialization\nmethod, with improved convergence, stability, and performance across various\nsettings, including large-scale datasets and deep models.\n","authors":["Yu Pan","Chaozheng Wang","Zekai Wu","Qifan Wang","Min Zhang","Zenglin Xu"],"pdf_url":"https://arxiv.org/pdf/2503.04626v1.pdf","comment":"Accepted in ICLR 2025"},{"id":"http://arxiv.org/abs/2410.05116v2","updated":"2025-03-06T17:11:55Z","published":"2024-10-07T15:12:01Z","title":"Human-Feedback Efficient Reinforcement Learning for Online Diffusion\n  Model Finetuning","summary":"  Controllable generation through Stable Diffusion (SD) fine-tuning aims to\nimprove fidelity, safety, and alignment with human guidance. Existing\nreinforcement learning from human feedback methods usually rely on predefined\nheuristic reward functions or pretrained reward models built on large-scale\ndatasets, limiting their applicability to scenarios where collecting such data\nis costly or difficult. To effectively and efficiently utilize human feedback,\nwe develop a framework, HERO, which leverages online human feedback collected\non the fly during model learning. Specifically, HERO features two key\nmechanisms: (1) Feedback-Aligned Representation Learning, an online training\nmethod that captures human feedback and provides informative learning signals\nfor fine-tuning, and (2) Feedback-Guided Image Generation, which involves\ngenerating images from SD's refined initialization samples, enabling faster\nconvergence towards the evaluator's intent. We demonstrate that HERO is 4x more\nefficient in online feedback for body part anomaly correction compared to the\nbest existing method. Additionally, experiments show that HERO can effectively\nhandle tasks like reasoning, counting, personalization, and reducing NSFW\ncontent with only 0.5K online feedback.\n","authors":["Ayano Hiranaka","Shang-Fu Chen","Chieh-Hsin Lai","Dongjun Kim","Naoki Murata","Takashi Shibuya","Wei-Hsiang Liao","Shao-Hua Sun","Yuki Mitsufuji"],"pdf_url":"https://arxiv.org/pdf/2410.05116v2.pdf","comment":"Published in International Conference on Learning Representations\n  (ICLR) 2025"},{"id":"http://arxiv.org/abs/2412.16561v2","updated":"2025-03-06T17:04:11Z","published":"2024-12-21T10:07:40Z","title":"A learning-based approach to stochastic optimal control under\n  reach-avoid constraint","summary":"  We develop a model-free approach to optimally control stochastic, Markovian\nsystems subject to a reach-avoid constraint. Specifically, the state trajectory\nmust remain within a safe set while reaching a target set within a finite time\nhorizon. Due to the time-dependent nature of these constraints, we show that,\nin general, the optimal policy for this constrained stochastic control problem\nis non-Markovian, which increases the computational complexity. To address this\nchallenge, we apply the state-augmentation technique from arXiv:2402.19360,\nreformulating the problem as a constrained Markov decision process (CMDP) on an\nextended state space. This transformation allows us to search for a Markovian\npolicy, avoiding the complexity of non-Markovian policies. To learn the optimal\npolicy without a system model, and using only trajectory data, we develop a\nlog-barrier policy gradient approach. We prove that under suitable assumptions,\nthe policy parameters converge to the optimal parameters, while ensuring that\nthe system trajectories satisfy the stochastic reach-avoid constraint with high\nprobability.\n","authors":["Tingting Ni","Maryam Kamgarpour"],"pdf_url":"https://arxiv.org/pdf/2412.16561v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.04606v1","updated":"2025-03-06T16:53:14Z","published":"2025-03-06T16:53:14Z","title":"The Best of Both Worlds: Integrating Language Models and Diffusion\n  Models for Video Generation","summary":"  Recent advancements in text-to-video (T2V) generation have been driven by two\ncompeting paradigms: autoregressive language models and diffusion models.\nHowever, each paradigm has intrinsic limitations: language models struggle with\nvisual quality and error accumulation, while diffusion models lack semantic\nunderstanding and causal modeling. In this work, we propose LanDiff, a hybrid\nframework that synergizes the strengths of both paradigms through\ncoarse-to-fine generation. Our architecture introduces three key innovations:\n(1) a semantic tokenizer that compresses 3D visual features into compact 1D\ndiscrete representations through efficient semantic compression, achieving a\n$\\sim$14,000$\\times$ compression ratio; (2) a language model that generates\nsemantic tokens with high-level semantic relationships; (3) a streaming\ndiffusion model that refines coarse semantics into high-fidelity videos.\nExperiments show that LanDiff, a 5B model, achieves a score of 85.43 on the\nVBench T2V benchmark, surpassing the state-of-the-art open-source models\nHunyuan Video (13B) and other commercial models such as Sora, Keling, and\nHailuo. Furthermore, our model also achieves state-of-the-art performance in\nlong video generation, surpassing other open-source models in this field. Our\ndemo can be viewed at https://landiff.github.io/.\n","authors":["Aoxiong Yin","Kai Shen","Yichong Leng","Xu Tan","Xinyu Zhou","Juncheng Li","Siliang Tang"],"pdf_url":"https://arxiv.org/pdf/2503.04606v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.03770v1","updated":"2025-03-06T16:42:53Z","published":"2025-03-06T16:42:53Z","title":"Fusion of Various Optimization Based Feature Smoothing Methods for\n  Wearable and Non-invasive Blood Glucose Estimation","summary":"  Recently, the wearable and non-invasive blood glucose estimation approach has\nbeen proposed. However, due to the unreliability of the acquisition device, the\npresence of the noise and the variations of the acquisition environments, the\nobtained features and the reference blood glucose values are highly unreliable.\nTo address this issue, this paper proposes a polynomial fitting approach to\nsmooth the obtained features or the reference blood glucose values. First, the\nblood glucose values are estimated based on the individual optimization\napproaches. Second, the absolute difference values between the estimated blood\nglucose values and the actual blood glucose values based on each optimization\napproach are computed. Third, these absolute difference values for each\noptimization approach are sorted in the ascending order. Fourth, for each\nsorted blood glucose value, the optimization method corresponding to the\nminimum absolute difference value is selected. Fifth, the accumulate\nprobability of each selected optimization method is computed. If the accumulate\nprobability of any selected optimization method at a point is greater than a\nthreshold value, then the accumulate probabilities of these three selected\noptimization methods at that point are reset to zero. A range of the sorted\nblood glucose values are defined as that with the corresponding boundaries\npoints being the previous reset point and this reset point. Hence, after\nperforming the above procedures for all the sorted reference blood glucose\nvalues in the validation set, the regions of the sorted reference blood glucose\nvalues and the corresponding optimization methods in these regions are\ndetermined. The computer numerical simulation results show that our proposed\nmethod yields the mean absolute relative deviation (MARD) at 0.0930 and the\npercentage of the test data falling in the zone A of the Clarke error grid at\n94.1176%.\n","authors":["Yiting Wei","Bingo Wing-Kuen Ling","Danni Chen","Yuheng Dai","Qing Liu"],"pdf_url":"https://arxiv.org/pdf/2503.03770v1.pdf","comment":"This version corrects several typos"},{"id":"http://arxiv.org/abs/2503.04598v1","updated":"2025-03-06T16:40:48Z","published":"2025-03-06T16:40:48Z","title":"HybridNorm: Towards Stable and Efficient Transformer Training via Hybrid\n  Normalization","summary":"  Transformers have become the de facto architecture for a wide range of\nmachine learning tasks, particularly in large language models (LLMs). Despite\ntheir remarkable performance, challenges remain in training deep transformer\nnetworks, especially regarding the location of layer normalization. While\nPre-Norm structures facilitate easier training due to their more prominent\nidentity path, they often yield suboptimal performance compared to Post-Norm.\nIn this paper, we propose $\\textbf{HybridNorm}$, a straightforward yet\neffective hybrid normalization strategy that integrates the advantages of both\nPre-Norm and Post-Norm approaches. Specifically, HybridNorm employs QKV\nnormalization within the attention mechanism and Post-Norm in the feed-forward\nnetwork (FFN) of each transformer block. This design not only stabilizes\ntraining but also enhances performance, particularly in the context of LLMs.\nComprehensive experiments in both dense and sparse architectures show that\nHybridNorm consistently outperforms both Pre-Norm and Post-Norm approaches,\nachieving state-of-the-art results across various benchmarks. These findings\nhighlight the potential of HybridNorm as a more stable and effective technique\nfor improving the training and performance of deep transformer models. %Code\nwill be made publicly available. Code is available at\nhttps://github.com/BryceZhuo/HybridNorm.\n","authors":["Zhijian Zhuo","Yutao Zeng","Ya Wang","Sijun Zhang","Jian Yang","Xiaoqing Li","Xun Zhou","Jinwen Ma"],"pdf_url":"https://arxiv.org/pdf/2503.04598v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2405.17412v3","updated":"2025-03-06T16:22:22Z","published":"2024-05-27T17:57:12Z","title":"Towards One Model for Classical Dimensionality Reduction: A\n  Probabilistic Perspective on UMAP and t-SNE","summary":"  This paper shows that dimensionality reduction methods such as UMAP and\nt-SNE, can be approximately recast as MAP inference methods corresponding to a\nmodel introduced in ProbDR, that describes the graph Laplacian (an estimate of\nthe data precision matrix) using a Wishart distribution, with a mean given by a\nnon-linear covariance function evaluated on the latents. This interpretation\noffers deeper theoretical and semantic insights into such algorithms, by\nshowing that variances corresponding to these covariances are low (potentially\nmisspecified), and forging a connection to Gaussian process latent variable\nmodels by showing that well-known kernels can be used to describe covariances\nimplied by graph Laplacians. We also introduce tools with which similar\ndimensionality reduction methods can be studied.\n","authors":["Aditya Ravuri","Neil D. Lawrence"],"pdf_url":"https://arxiv.org/pdf/2405.17412v3.pdf","comment":"Updated preprint"},{"id":"http://arxiv.org/abs/2503.04585v1","updated":"2025-03-06T16:22:19Z","published":"2025-03-06T16:22:19Z","title":"Advancing Solutions for the Three-Body Problem Through Physics-Informed\n  Neural Networks","summary":"  First formulated by Sir Isaac Newton in his work \"Philosophiae Naturalis\nPrincipia Mathematica\", the concept of the Three-Body Problem was put forth as\na study of the motion of the three celestial bodies within the Earth-Sun-Moon\nsystem. In a generalized definition, it seeks to predict the motion for an\nisolated system composed of three point masses freely interacting under\nNewton's law of universal attraction. This proves to be analogous to a\nmultitude of interactions between celestial bodies, and thus, the problem finds\napplicability within the studies of celestial mechanics. Despite numerous\nattempts by renowned physicists to solve it throughout the last three\ncenturies, no general closed-form solutions have been reached due to its\ninherently chaotic nature for most initial conditions. Current state-of-the-art\nsolutions are based on two approaches, either numerical high-precision\nintegration or machine learning-based. Notwithstanding the breakthroughs of\nneural networks, these present a significant limitation, which is their\nignorance of any prior knowledge of the chaotic systems presented. Thus, in\nthis work, we propose a novel method that utilizes Physics-Informed Neural\nNetworks (PINNs). These deep neural networks are able to incorporate any prior\nsystem knowledge expressible as an Ordinary Differential Equation (ODE) into\ntheir learning processes as a regularizing agent. Our findings showcase that\nPINNs surpass current state-of-the-art machine learning methods with comparable\nprediction quality. Despite a better prediction quality, the usability of\nnumerical integrators suffers due to their prohibitively high computational\ncost. These findings confirm that PINNs are both effective and time-efficient\nopen-form solvers of the Three-Body Problem that capitalize on the extensive\nknowledge we hold of classical mechanics.\n","authors":["Manuel Santos Pereira","Lus Tripa","Nlson Lima","Francisco Caldas","Cludia Soares"],"pdf_url":"https://arxiv.org/pdf/2503.04585v1.pdf","comment":"14 pages, 25 figures, 3 tables. 75th International Astronautical\n  Congress (IAC), Milan, Italy, 14-18 October"},{"id":"http://arxiv.org/abs/2503.04582v1","updated":"2025-03-06T16:20:25Z","published":"2025-03-06T16:20:25Z","title":"PSDNorm: Test-Time Temporal Normalization for Deep Learning on EEG\n  Signals","summary":"  Distribution shift poses a significant challenge in machine learning,\nparticularly in biomedical applications such as EEG signals collected across\ndifferent subjects, institutions, and recording devices. While existing\nnormalization layers, Batch-Norm, LayerNorm and InstanceNorm, help address\ndistribution shifts, they fail to capture the temporal dependencies inherent in\ntemporal signals. In this paper, we propose PSDNorm, a layer that leverages\nMonge mapping and temporal context to normalize feature maps in deep learning\nmodels. Notably, the proposed method operates as a test-time domain adaptation\ntechnique, addressing distribution shifts without additional training.\nEvaluations on 10 sleep staging datasets using the U-Time model demonstrate\nthat PSDNorm achieves state-of-the-art performance at test time on datasets not\nseen during training while being 4x more data-efficient than the best baseline.\nAdditionally, PSDNorm provides a significant improvement in robustness,\nachieving markedly higher F1 scores for the 20% hardest subjects.\n","authors":["Tho Gnassounou","Antoine Collas","Rmi Flamary","Alexandre Gramfort"],"pdf_url":"https://arxiv.org/pdf/2503.04582v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2502.17504v2","updated":"2025-03-06T16:14:45Z","published":"2025-02-21T19:22:10Z","title":"Protein Large Language Models: A Comprehensive Survey","summary":"  Protein-specific large language models (Protein LLMs) are revolutionizing\nprotein science by enabling more efficient protein structure prediction,\nfunction annotation, and design. While existing surveys focus on specific\naspects or applications, this work provides the first comprehensive overview of\nProtein LLMs, covering their architectures, training datasets, evaluation\nmetrics, and diverse applications. Through a systematic analysis of over 100\narticles, we propose a structured taxonomy of state-of-the-art Protein LLMs,\nanalyze how they leverage large-scale protein sequence data for improved\naccuracy, and explore their potential in advancing protein engineering and\nbiomedical research. Additionally, we discuss key challenges and future\ndirections, positioning Protein LLMs as essential tools for scientific\ndiscovery in protein science. Resources are maintained at\nhttps://github.com/Yijia-Xiao/Protein-LLM-Survey.\n","authors":["Yijia Xiao","Wanjia Zhao","Junkai Zhang","Yiqiao Jin","Han Zhang","Zhicheng Ren","Renliang Sun","Haixin Wang","Guancheng Wan","Pan Lu","Xiao Luo","Yu Zhang","James Zou","Yizhou Sun","Wei Wang"],"pdf_url":"https://arxiv.org/pdf/2502.17504v2.pdf","comment":"24 pages, 4 figures, 5 tables"},{"id":"http://arxiv.org/abs/2412.07093v2","updated":"2025-03-06T16:14:01Z","published":"2024-12-10T01:21:56Z","title":"Streaming Private Continual Counting via Binning","summary":"  In differential privacy, $\\textit{continual observation}$ refers to problems\nin which we wish to continuously release a function of a dataset that is\nrevealed one element at a time. The challenge is to maintain a good\napproximation while keeping the combined output over all time steps\ndifferentially private. In the special case of $\\textit{continual counting}$ we\nseek to approximate a sum of binary input elements. This problem has received\nconsiderable attention lately, in part due to its relevance in implementations\nof differentially private stochastic gradient descent. $\\textit{Factorization\nmechanisms}$ are the leading approach to continual counting, but the best such\nmechanisms do not work well in $\\textit{streaming}$ settings since they require\nspace proportional to the size of the input. In this paper, we present a simple\napproach to approximating factorization mechanisms in low space via\n$\\textit{binning}$, where adjacent matrix entries with similar values are\nchanged to be identical in such a way that a matrix-vector product can be\nmaintained in sublinear space. Our approach has provable sublinear space\nguarantees for a class of lower triangular matrices whose entries are\nmonotonically decreasing away from the diagonal. We show empirically that even\nwith very low space usage we are able to closely match, and sometimes surpass,\nthe performance of asymptotically optimal factorization mechanisms. Recently,\nand independently of our work, Dvijotham et al. have also suggested an approach\nto implementing factorization mechanisms in a streaming setting. Their work\ndiffers from ours in several respects: It only addresses factorization into\n$\\textit{Toeplitz}$ matrices, only considers $\\textit{maximum}$ error, and uses\na different technique based on rational function approximation that seems less\nversatile than our binning approach.\n","authors":["Joel Daniel Andersson","Rasmus Pagh"],"pdf_url":"https://arxiv.org/pdf/2412.07093v2.pdf","comment":"Accepted to SaTML 2025. Final version to appear on IEEE eXplore"},{"id":"http://arxiv.org/abs/2503.04579v1","updated":"2025-03-06T16:13:32Z","published":"2025-03-06T16:13:32Z","title":"Data-augmented Learning of Geodesic Distances in Irregular Domains\n  through Soner Boundary Conditions","summary":"  Geodesic distances play a fundamental role in robotics, as they efficiently\nencode global geometric information of the domain. Recent methods use neural\nnetworks to approximate geodesic distances by solving the Eikonal equation\nthrough physics-informed approaches. While effective, these approaches often\nsuffer from unstable convergence during training in complex environments. We\npropose a framework to learn geodesic distances in irregular domains by using\nthe Soner boundary condition, and systematically evaluate the impact of data\nlosses on training stability and solution accuracy. Our experiments demonstrate\nthat incorporating data losses significantly improves convergence robustness,\nreducing training instabilities and sensitivity to initialization. These\nfindings suggest that hybrid data-physics approaches can effectively enhance\nthe reliability of learning-based geodesic distance solvers with sparse data.\n","authors":["Rafael I. Cabral Muchacho","Florian T. Pokorny"],"pdf_url":"https://arxiv.org/pdf/2503.04579v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.01804v2","updated":"2025-03-06T16:07:43Z","published":"2025-03-03T18:33:46Z","title":"$\\texttt{SEM-CTRL}$: Semantically Controlled Decoding","summary":"  Ensuring both syntactic and semantic correctness in Large Language Model\n(LLM) outputs remains a significant challenge, despite being critical for\nreal-world deployment. In this paper, we introduce $\\texttt{SEM-CTRL}$, a\nunified approach that enforces rich context-sensitive constraints and task- and\ninstance-specific semantics directly on an LLM decoder. Our approach integrates\ntoken-level MCTS, which is guided by specific syntactic and semantic\nconstraints. The constraints over the desired outputs are expressed using\nAnswer Set Grammars -- a logic-based formalism that generalizes\ncontext-sensitive grammars while incorporating background knowledge to\nrepresent task-specific semantics. We show that our approach guarantees correct\ncompletions for any off-the-shelf LLM without the need for fine-tuning. We\nevaluate $\\texttt{SEM-CTRL}$ on a range of tasks, including synthetic grammar\nsynthesis, combinatorial reasoning, and planning. Our results demonstrate that\n$\\texttt{SEM-CTRL}$ allows small pre-trained LLMs to efficiently outperform\nlarger variants and state-of-the-art reasoning models (e.g., o1-preview) while\nsimultaneously guaranteeing solution correctness.\n","authors":["Mohammad Albinhassan","Pranava Madhyastha","Alessandra Russo"],"pdf_url":"https://arxiv.org/pdf/2503.01804v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.04570v1","updated":"2025-03-06T16:05:29Z","published":"2025-03-06T16:05:29Z","title":"Meta Learning not to Learn: Robustly Informing Meta-Learning under\n  Nuisance-Varying Families","summary":"  In settings where both spurious and causal predictors are available, standard\nneural networks trained under the objective of empirical risk minimization\n(ERM) with no additional inductive biases tend to have a dependence on a\nspurious feature. As a result, it is necessary to integrate additional\ninductive biases in order to guide the network toward generalizable hypotheses.\nOften these spurious features are shared across related tasks, such as\nestimating disease prognoses from image scans coming from different hospitals,\nmaking the challenge of generalization more difficult. In these settings, it is\nimportant that methods are able to integrate the proper inductive biases to\ngeneralize across both nuisance-varying families as well as task families.\nMotivated by this setting, we present RIME (Robustly Informed Meta lEarning), a\nnew method for meta learning under the presence of both positive and negative\ninductive biases (what to learn and what not to learn). We first develop a\ntheoretical causal framework showing why existing approaches at knowledge\nintegration can lead to worse performance on distributionally robust\nobjectives. We then show that RIME is able to simultaneously integrate both\nbiases, reaching state of the art performance under distributionally robust\nobjectives in informed meta-learning settings under nuisance-varying families.\n","authors":["Louis McConnell"],"pdf_url":"https://arxiv.org/pdf/2503.04570v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2502.18049v2","updated":"2025-03-06T16:03:59Z","published":"2025-02-25T10:15:16Z","title":"Golden Ratio Weighting Prevents Model Collapse","summary":"  Recent studies identified an intriguing phenomenon in recursive generative\nmodel training known as model collapse, where models trained on data generated\nby previous models exhibit severe performance degradation. Addressing this\nissue and developing more effective training strategies have become central\nchallenges in generative model research. In this paper, we investigate this\nphenomenon theoretically within a novel framework, where generative models are\niteratively trained on a combination of newly collected real data and synthetic\ndata from the previous training step. To develop an optimal training strategy\nfor integrating real and synthetic data, we evaluate the performance of a\nweighted training scheme in various scenarios, including Gaussian distribution\nestimation and linear regression. We theoretically characterize the impact of\nthe mixing proportion and weighting scheme of synthetic data on the final\nmodel's performance. Our key finding is that, across different settings, the\noptimal weighting scheme under different proportions of synthetic data\nasymptotically follows a unified expression, revealing a fundamental trade-off\nbetween leveraging synthetic data and generative model performance. Notably, in\nsome cases, the optimal weight assigned to real data corresponds to the\nreciprocal of the golden ratio. Finally, we validate our theoretical results on\nextensive simulated datasets and a real tabular dataset.\n","authors":["Hengzhi He","Shirong Xu","Guang Cheng"],"pdf_url":"https://arxiv.org/pdf/2502.18049v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.00153v2","updated":"2025-03-06T15:50:28Z","published":"2024-09-30T18:52:53Z","title":"Beyond Single Concept Vector: Modeling Concept Subspace in LLMs with\n  Gaussian Distribution","summary":"  Probing learned concepts in large language models (LLMs) is crucial for\nunderstanding how semantic knowledge is encoded internally. Training linear\nclassifiers on probing tasks is a principle approach to denote the vector of a\ncertain concept in the representation space. However, the single vector\nidentified for a concept varies with both data and training, making it less\nrobust and weakening its effectiveness in real-world applications. To address\nthis challenge, we propose an approach to approximate the subspace representing\na specific concept. Built on linear probing classifiers, we extend the concept\nvectors into Gaussian Concept Subspace (GCS). We demonstrate GCS's\neffectiveness through measuring its faithfulness and plausibility across\nmultiple LLMs with different sizes and architectures. Additionally, we use\nrepresentation intervention tasks to showcase its efficacy in real-world\napplications such as emotion steering. Experimental results indicate that GCS\nconcept vectors have the potential to balance steering performance and\nmaintaining the fluency in natural language generation tasks.\n","authors":["Haiyan Zhao","Heng Zhao","Bo Shen","Ali Payani","Fan Yang","Mengnan Du"],"pdf_url":"https://arxiv.org/pdf/2410.00153v2.pdf","comment":"Accepted by ICLR 2025"},{"id":"http://arxiv.org/abs/2501.02436v2","updated":"2025-03-06T15:49:50Z","published":"2025-01-05T04:23:21Z","title":"An Analysis Framework for Understanding Deep Neural Networks Based on\n  Network Dynamics","summary":"  Advancing artificial intelligence demands a deeper understanding of the\nmechanisms underlying deep learning. Here, we propose a straightforward\nanalysis framework based on the dynamics of learning models. Neurons are\ncategorized into two modes based on whether their transformation functions\npreserve order. This categorization reveals how deep neural networks (DNNs)\nmaximize information extraction by rationally allocating the proportion of\nneurons in different modes across deep layers. We further introduce the\nattraction basins of the training samples in both the sample vector space and\nthe weight vector space to characterize the generalization ability of DNNs.\nThis framework allows us to identify optimal depth and width configurations,\nproviding a unified explanation for fundamental DNN behaviors such as the \"flat\nminima effect,\" \"grokking,\" and double descent phenomena. Our analysis extends\nto networks with depths up to 100 layers.\n","authors":["Yuchen Lin","Yong Zhang","Sihan Feng","Hong Zhao"],"pdf_url":"https://arxiv.org/pdf/2501.02436v2.pdf","comment":"12 pages, 10 figures"},{"id":"http://arxiv.org/abs/2503.04556v1","updated":"2025-03-06T15:47:19Z","published":"2025-03-06T15:47:19Z","title":"Compositional Causal Reasoning Evaluation in Language Models","summary":"  Causal reasoning and compositional reasoning are two core aspirations in\ngenerative AI. Measuring the extent of these behaviors requires principled\nevaluation methods. We explore a unified perspective that considers both\nbehaviors simultaneously, termed compositional causal reasoning (CCR): the\nability to infer how causal measures compose and, equivalently, how causal\nquantities propagate through graphs. We instantiate a framework for the\nsystematic evaluation of CCR for the average treatment effect and the\nprobability of necessity and sufficiency. As proof of concept, we demonstrate\nthe design of CCR tasks for language models in the LLama, Phi, and GPT\nfamilies. On a math word problem, our framework revealed a range of\ntaxonomically distinct error patterns. Additionally, CCR errors increased with\nthe complexity of causal paths for all models except o1.\n","authors":["Jacqueline R. M. A. Maasch","Alihan Hyk","Xinnuo Xu","Aditya V. Nori","Javier Gonzalez"],"pdf_url":"https://arxiv.org/pdf/2503.04556v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2407.18691v2","updated":"2025-03-06T15:47:01Z","published":"2024-07-26T12:16:53Z","title":"Graph Neural Networks for Virtual Sensing in Complex Systems: Addressing\n  Heterogeneous Temporal Dynamics","summary":"  Real-time condition monitoring is crucial for the reliable and efficient\noperation of complex systems. However, relying solely on physical sensors can\nbe limited due to their cost, placement constraints, or inability to directly\nmeasure certain critical parameters. Virtual sensing addresses these\nlimitations by leveraging readily available sensor data and system knowledge to\nestimate inaccessible parameters or infer system states. The increasing\ncomplexity of industrial systems necessitates deployments of sensors with\ndiverse modalities to provide a comprehensive understanding of system states.\nThese sensors capture data at varying frequencies to monitor both rapid and\nslowly varying system dynamics, as well as local and global state evolutions of\nthe systems. This leads to heterogeneous temporal dynamics, which, particularly\nunder varying operational end environmental conditions, pose a significant\nchallenge for accurate virtual sensing. To address this, we propose a\nHeterogeneous Temporal Graph Neural Network (HTGNN) framework. HTGNN explicitly\nmodels signals from diverse sensors and integrates operating conditions into\nthe model architecture. We evaluate HTGNN using two newly released datasets: a\nbearing dataset with diverse load conditions for bearing load prediction and a\nyear-long simulated dataset for predicting bridge live loads. Our results\ndemonstrate that HTGNN significantly outperforms established baseline methods\nin both tasks, particularly under highly varying operating conditions. These\nresults highlight HTGNN's potential as a robust and accurate virtual sensing\napproach for complex systems, paving the way for improved monitoring,\npredictive maintenance, and enhanced system performance. Our code and data are\navailable under https://github.com/EPFL-IMOS/htgnn.\n","authors":["Mengjie Zhao","Cees Taal","Stephan Baggerohr","Olga Fink"],"pdf_url":"https://arxiv.org/pdf/2407.18691v2.pdf","comment":"This paper extends our previous conference paper (Best Paper at\n  European Conference of the PHM Society 2024,\n  https://doi.org/10.36001/phme.2024.v8i1.3998). Accepted by Mechanical Systems\n  and Signal Processing (MSSP)"},{"id":"http://arxiv.org/abs/2502.18394v4","updated":"2025-03-06T15:39:55Z","published":"2025-02-25T17:43:43Z","title":"The FFT Strikes Back: An Efficient Alternative to Self-Attention","summary":"  Conventional self-attention mechanisms incur quadratic complexity, limiting\ntheir scalability on long sequences. We introduce \\textbf{FFTNet}, an adaptive\nspectral filtering framework that leverages the Fast Fourier Transform (FFT) to\nachieve global token mixing in $\\mathcal{O}(n\\log n)$ time. By transforming\ninputs into the frequency domain, FFTNet exploits the orthogonality and energy\npreservation guaranteed by Parseval's theorem to capture long-range\ndependencies efficiently. Our main theoretical contributions are 1) an adaptive\nspectral filter, 2) combining local windowing with a global FFT branch, and 3)\nrich nonlinearity introduction in both the frequency and token domains.\nExperiments on the Long Range Arena and ImageNet benchmarks validate our\ntheoretical insights and demonstrate superior performance over fixed Fourier\nand standard attention models.\n","authors":["Jacob Fein-Ashley"],"pdf_url":"https://arxiv.org/pdf/2502.18394v4.pdf","comment":null},{"id":"http://arxiv.org/abs/2502.09990v2","updated":"2025-03-06T15:38:31Z","published":"2025-02-14T08:22:51Z","title":"X-Boundary: Establishing Exact Safety Boundary to Shield LLMs from\n  Multi-Turn Jailbreaks without Compromising Usability","summary":"  Despite the rapid development of safety alignment techniques for LLMs,\ndefending against multi-turn jailbreaks is still a challenging task. In this\npaper, we conduct a comprehensive comparison, revealing that some existing\ndefense methods can improve the robustness of LLMs against multi-turn\njailbreaks but compromise usability, i.e., reducing general capabilities or\ncausing the over-refusal problem. From the perspective of mechanism\ninterpretability of LLMs, we discover that these methods fail to establish a\nboundary that exactly distinguishes safe and harmful feature representations.\nTherefore, boundary-safe representations close to harmful representations are\ninevitably disrupted, leading to a decline in usability. To address this issue,\nwe propose X-Boundary to push harmful representations away from boundary-safe\nrepresentations and obtain an exact distinction boundary. In this way, harmful\nrepresentations can be precisely erased without disrupting safe ones.\nExperimental results show that X-Boundary achieves state-of-the-art defense\nperformance against multi-turn jailbreaks, while reducing the over-refusal rate\nby about 20% and maintaining nearly complete general capability. Furthermore,\nwe theoretically prove and empirically verify that X-Boundary can accelerate\nthe convergence process during training. Please see our code at:\nhttps://github.com/AI45Lab/X-Boundary.\n","authors":["Xiaoya Lu","Dongrui Liu","Yi Yu","Luxin Xu","Jing Shao"],"pdf_url":"https://arxiv.org/pdf/2502.09990v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.03660v2","updated":"2025-03-06T15:32:00Z","published":"2025-03-05T16:47:36Z","title":"Chunking the Critic: A Transformer-based Soft Actor-Critic with N-Step\n  Returns","summary":"  Soft Actor-Critic (SAC) critically depends on its critic network, which\ntypically evaluates a single state-action pair to guide policy updates. Using\nN-step returns is a common practice to reduce the bias in the target values of\nthe critic. However, using N-step returns can again introduce high variance and\nnecessitates importance sampling, often destabilizing training. Recent\nalgorithms have also explored action chunking-such as direct action repetition\nand movement primitives-to enhance exploration. In this paper, we propose a\nTransformer-based Critic Network for SAC that integrates the N-returns\nframework in a stable and efficient manner. Unlike approaches that perform\nchunking in the actor network, we feed chunked actions into the critic network\nto explore potential performance gains. Our architecture leverages the\nTransformer's ability to process sequential information, facilitating more\nrobust value estimation. Empirical results show that this method not only\nachieves efficient, stable training but also excels in sparse\nreward/multi-phase environments-traditionally a challenge for step-based\nmethods. These findings underscore the promise of combining Transformer-based\ncritics with N-returns to advance reinforcement learning performance\n","authors":["Dong Tian","Ge Li","Hongyi Zhou","Onur Celik","Gerhard Neumann"],"pdf_url":"https://arxiv.org/pdf/2503.03660v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2312.07516v3","updated":"2025-03-06T15:30:10Z","published":"2023-12-12T18:47:12Z","title":"Learning finitely correlated states: stability of the spectral\n  reconstruction","summary":"  Matrix product operators allow efficient descriptions (or realizations) of\nstates on a 1D lattice. We consider the task of learning a realization of\nminimal dimension from copies of an unknown state, such that the resulting\noperator is close to the density matrix in trace norm. For finitely correlated\ntranslation-invariant states on an infinite chain, a realization of minimal\ndimension can be exactly reconstructed via linear algebra operations from the\nmarginals of a size depending on the representation dimension. We establish a\nbound on the trace norm error for an algorithm that estimates a candidate\nrealization from estimates of these marginals and outputs a matrix product\noperator, estimating the state of a chain of arbitrary length $t$. This bound\nallows us to establish an $O(t^2)$ upper bound on the sample complexity of the\nlearning task, with an explicit dependence on the site dimension, realization\ndimension and spectral properties of a certain map constructed from the state.\nA refined error bound can be proven for $C^*$-finitely correlated states, which\nhave an operational interpretation in terms of sequential quantum channels\napplied to the memory system. We can also obtain an analogous error bound for a\nclass of matrix product density operators on a finite chain reconstructible by\nlocal marginals. In this case, a linear number of marginals must be estimated,\nobtaining a sample complexity of $\\tilde{O}(t^3)$. The learning algorithm also\nworks for states that are sufficiently close to a finitely correlated state,\nwith the potential of providing competitive algorithms for other interesting\nfamilies of states.\n","authors":["Marco Fanizza","Niklas Galke","Josep Lumbreras","Cambyse Rouz","Andreas Winter"],"pdf_url":"https://arxiv.org/pdf/2312.07516v3.pdf","comment":"42 pages, 7 figures. Manuscript restructured, with minor corrections\n  and clarifications"},{"id":"http://arxiv.org/abs/2403.00025v2","updated":"2025-03-06T15:29:41Z","published":"2024-02-28T15:19:33Z","title":"On the Challenges and Opportunities in Generative AI","summary":"  The field of deep generative modeling has grown rapidly in the last few\nyears. With the availability of massive amounts of training data coupled with\nadvances in scalable unsupervised learning paradigms, recent large-scale\ngenerative models show tremendous promise in synthesizing high-resolution\nimages and text, as well as structured data such as videos and molecules.\nHowever, we argue that current large-scale generative AI models exhibit several\nfundamental shortcomings that hinder their widespread adoption across domains.\nIn this work, our objective is to identify these issues and highlight key\nunresolved challenges in modern generative AI paradigms that should be\naddressed to further enhance their capabilities, versatility, and reliability.\nBy identifying these challenges, we aim to provide researchers with insights\nfor exploring fruitful research directions, thus fostering the development of\nmore robust and accessible generative AI solutions.\n","authors":["Laura Manduchi","Kushagra Pandey","Clara Meister","Robert Bamler","Ryan Cotterell","Sina Dubener","Sophie Fellenz","Asja Fischer","Thomas Grtner","Matthias Kirchler","Marius Kloft","Yingzhen Li","Christoph Lippert","Gerard de Melo","Eric Nalisnick","Bjrn Ommer","Rajesh Ranganath","Maja Rudolph","Karen Ullrich","Guy Van den Broeck","Julia E Vogt","Yixin Wang","Florian Wenzel","Frank Wood","Stephan Mandt","Vincent Fortuin"],"pdf_url":"https://arxiv.org/pdf/2403.00025v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.07180v5","updated":"2025-03-06T15:26:56Z","published":"2024-11-11T17:57:30Z","title":"Gumbel Counterfactual Generation From Language Models","summary":"  Understanding and manipulating the causal generation mechanisms in language\nmodels is essential for controlling their behavior. Previous work has primarily\nrelied on techniques such as representation surgery -- e.g., model ablations or\nmanipulation of linear subspaces tied to specific concepts -- to\n\\emph{intervene} on these models. To understand the impact of interventions\nprecisely, it is useful to examine \\emph{counterfactuals} -- e.g., how a given\nsentence would have appeared had it been generated by the model following a\nspecific intervention. We highlight that counterfactual reasoning is\nconceptually distinct from interventions, as articulated in Pearl's causal\nhierarchy. Based on this observation, we propose a framework for generating\ntrue string counterfactuals by reformulating language models as a structural\nequation model using the Gumbel-max trick, which we called Gumbel\ncounterfactual generation. This reformulation allows us to model the joint\ndistribution over original strings and their counterfactuals resulting from the\nsame instantiation of the sampling noise. We develop an algorithm based on\nhindsight Gumbel sampling that allows us to infer the latent noise variables\nand generate counterfactuals of observed strings. Our experiments demonstrate\nthat the approach produces meaningful counterfactuals while at the same time\nshowing that commonly used intervention techniques have considerable undesired\nside effects.\n","authors":["Shauli Ravfogel","Anej Svete","Vsteinn Snbjarnarson","Ryan Cotterell"],"pdf_url":"https://arxiv.org/pdf/2411.07180v5.pdf","comment":"Accepted in ICLR 2025"},{"id":"http://arxiv.org/abs/2503.04528v1","updated":"2025-03-06T15:16:57Z","published":"2025-03-06T15:16:57Z","title":"Federated Dynamic Modeling and Learning for Spatiotemporal Data\n  Forecasting","summary":"  This paper presents an advanced Federated Learning (FL) framework for\nforecasting complex spatiotemporal data, improving upon recent state-of-the-art\nmodels. In the proposed approach, the original Gated Recurrent Unit (GRU)\nmodule within previous Dynamic Spatial--Temporal Graph Convolutional Recurrent\nNetwork (DSTGCRN) modeling is first replaced with a Long Short-Term Memory\n(LSTM) network, enabling the resulting model to more effectively capture\nlong-term dependencies inherent to time series data. The resulting architecture\nsignificantly improves the model's capacity to handle complex temporal patterns\nin diverse forecasting applications. Furthermore, the proposed FL framework\nintegrates a novel Client-Side Validation (CSV) mechanism, introducing a\ncritical validation step at the client level before incorporating aggregated\nparameters from the central server into local models. This ensures that only\nthe most effective updates are adopted, improving both the robustness and\naccuracy of the forecasting model across clients. The efficiency of our\napproach is demonstrated through extensive experiments on real-world\napplications, including public datasets for multimodal transport demand\nforecasting and private datasets for Origin-Destination (OD) matrix forecasting\nin urban areas. The results demonstrate substantial improvements over\nconventional methods, highlighting the framework's ability to capture complex\nspatiotemporal dependencies while preserving data privacy. This work not only\nprovides a scalable and privacy-preserving solution for real-time,\nregion-specific forecasting and management but also underscores the potential\nof leveraging distributed data sources in a FL context. We provide our\nalgorithms as open-source on GitHub.\n","authors":["Thien Pham","Angelo Furno","Facel Chamroukhi","Latifa Oukhellou"],"pdf_url":"https://arxiv.org/pdf/2503.04528v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2412.07775v2","updated":"2025-03-06T15:15:58Z","published":"2024-12-10T18:59:58Z","title":"Efficient Diversity-Preserving Diffusion Alignment via Gradient-Informed\n  GFlowNets","summary":"  While one commonly trains large diffusion models by collecting datasets on\ntarget downstream tasks, it is often desired to align and finetune pretrained\ndiffusion models with some reward functions that are either designed by experts\nor learned from small-scale datasets. Existing post-training methods for reward\nfinetuning of diffusion models typically suffer from lack of diversity in\ngenerated samples, lack of prior preservation, and/or slow convergence in\nfinetuning. Inspired by recent successes in generative flow networks\n(GFlowNets), a class of probabilistic models that sample with the unnormalized\ndensity of a reward function, we propose a novel GFlowNet method dubbed\nNabla-GFlowNet (abbreviated as \\methodname), the first GFlowNet method that\nleverages the rich signal in reward gradients, together with an objective\ncalled \\graddb plus its variant \\resgraddb designed for prior-preserving\ndiffusion finetuning. We show that our proposed method achieves fast yet\ndiversity- and prior-preserving finetuning of Stable Diffusion, a large-scale\ntext-conditioned image diffusion model, on different realistic reward\nfunctions.\n","authors":["Zhen Liu","Tim Z. Xiao","Weiyang Liu","Yoshua Bengio","Dinghuai Zhang"],"pdf_url":"https://arxiv.org/pdf/2412.07775v2.pdf","comment":"Technical Report (35 pages, 31 figures), Accepted at ICLR 2025"},{"id":"http://arxiv.org/abs/2411.12580v2","updated":"2025-03-06T15:14:17Z","published":"2024-11-19T15:47:12Z","title":"Procedural Knowledge in Pretraining Drives Reasoning in Large Language\n  Models","summary":"  The capabilities and limitations of Large Language Models have been sketched\nout in great detail in recent years, providing an intriguing yet conflicting\npicture. On the one hand, LLMs demonstrate a general ability to solve problems.\nOn the other hand, they show surprising reasoning gaps when compared to humans,\ncasting doubt on the robustness of their generalisation strategies. The sheer\nvolume of data used in the design of LLMs has precluded us from applying the\nmethod traditionally used to measure generalisation: train-test set separation.\nTo overcome this, we study what kind of generalisation strategies LLMs employ\nwhen performing reasoning tasks by investigating the pretraining data they rely\non. For two models of different sizes (7B and 35B) and 2.5B of their\npretraining tokens, we identify what documents influence the model outputs for\nthree simple mathematical reasoning tasks and contrast this to the data that\nare influential for answering factual questions. We find that, while the models\nrely on mostly distinct sets of data for each factual question, a document\noften has a similar influence across different reasoning questions within the\nsame task, indicating the presence of procedural knowledge. We further find\nthat the answers to factual questions often show up in the most influential\ndata. However, for reasoning questions the answers usually do not show up as\nhighly influential, nor do the answers to the intermediate reasoning steps.\nWhen we characterise the top ranked documents for the reasoning questions\nqualitatively, we confirm that the influential documents often contain\nprocedural knowledge, like demonstrating how to obtain a solution using\nformulae or code. Our findings indicate that the approach to reasoning the\nmodels use is unlike retrieval, and more like a generalisable strategy that\nsynthesises procedural knowledge from documents doing a similar form of\nreasoning.\n","authors":["Laura Ruis","Maximilian Mozes","Juhan Bae","Siddhartha Rao Kamalakara","Dwarak Talupuru","Acyr Locatelli","Robert Kirk","Tim Rocktschel","Edward Grefenstette","Max Bartolo"],"pdf_url":"https://arxiv.org/pdf/2411.12580v2.pdf","comment":"Published at ICLR 2025"},{"id":"http://arxiv.org/abs/2410.04166v2","updated":"2025-03-06T15:11:57Z","published":"2024-10-05T14:04:03Z","title":"Learning from negative feedback, or positive feedback or both","summary":"  Existing preference optimization methods often assume scenarios where paired\npreference feedback (preferred/positive vs. dis-preferred/negative examples) is\navailable. This requirement limits their applicability in scenarios where only\nunpaired feedback--for example, either positive or negative--is available. To\naddress this, we introduce a novel approach that decouples learning from\npositive and negative feedback. This decoupling enables control over the\ninfluence of each feedback type and, importantly, allows learning even when\nonly one feedback type is present. A key contribution is demonstrating stable\nlearning from negative feedback alone, a capability not well-addressed by\ncurrent methods. Our approach builds upon the probabilistic framework\nintroduced in (Dayan and Hinton, 1997), which uses expectation-maximization\n(EM) to directly optimize the probability of positive outcomes (as opposed to\nclassic expected reward maximization). We address a key limitation in current\nEM-based methods: they solely maximize the likelihood of positive examples,\nwhile neglecting negative ones. We show how to extend EM algorithms to\nexplicitly incorporate negative examples, leading to a theoretically grounded\nalgorithm that offers an intuitive and versatile way to learn from both\npositive and negative feedback. We evaluate our approach for training language\nmodels based on human feedback as well as training policies for sequential\ndecision-making problems, where learned value functions are available.\n","authors":["Abbas Abdolmaleki","Bilal Piot","Bobak Shahriari","Jost Tobias Springenberg","Tim Hertweck","Rishabh Joshi","Junhyuk Oh","Michael Bloesch","Thomas Lampe","Nicolas Heess","Jonas Buchli","Martin Riedmiller"],"pdf_url":"https://arxiv.org/pdf/2410.04166v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.04518v1","updated":"2025-03-06T15:06:01Z","published":"2025-03-06T15:06:01Z","title":"Leveraging priors on distribution functions for multi-arm bandits","summary":"  We introduce Dirichlet Process Posterior Sampling (DPPS), a Bayesian\nnon-parametric algorithm for multi-arm bandits based on Dirichlet Process (DP)\npriors. Like Thompson-sampling, DPPS is a probability-matching algorithm, i.e.,\nit plays an arm based on its posterior-probability of being optimal. Instead of\nassuming a parametric class for the reward generating distribution of each arm,\nand then putting a prior on the parameters, in DPPS the reward generating\ndistribution is directly modeled using DP priors. DPPS provides a principled\napproach to incorporate prior belief about the bandit environment, and in the\nnoninformative limit of the DP posteriors (i.e. Bayesian Bootstrap), we recover\nNon Parametric Thompson Sampling (NPTS), a popular non-parametric bandit\nalgorithm, as a special case of DPPS. We employ stick-breaking representation\nof the DP priors, and show excellent empirical performance of DPPS in\nchallenging synthetic and real world bandit environments. Finally, using an\ninformation-theoretic analysis, we show non-asymptotic optimality of DPPS in\nthe Bayesian regret setup.\n","authors":["Sumit Vashishtha","Odalric-Ambrym Maillard"],"pdf_url":"https://arxiv.org/pdf/2503.04518v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2502.05874v2","updated":"2025-03-06T15:02:33Z","published":"2025-02-09T12:23:40Z","title":"MMGDreamer: Mixed-Modality Graph for Geometry-Controllable 3D Indoor\n  Scene Generation","summary":"  Controllable 3D scene generation has extensive applications in virtual\nreality and interior design, where the generated scenes should exhibit high\nlevels of realism and controllability in terms of geometry. Scene graphs\nprovide a suitable data representation that facilitates these applications.\nHowever, current graph-based methods for scene generation are constrained to\ntext-based inputs and exhibit insufficient adaptability to flexible user\ninputs, hindering the ability to precisely control object geometry. To address\nthis issue, we propose MMGDreamer, a dual-branch diffusion model for scene\ngeneration that incorporates a novel Mixed-Modality Graph, visual enhancement\nmodule, and relation predictor. The mixed-modality graph allows object nodes to\nintegrate textual and visual modalities, with optional relationships between\nnodes. It enhances adaptability to flexible user inputs and enables meticulous\ncontrol over the geometry of objects in the generated scenes. The visual\nenhancement module enriches the visual fidelity of text-only nodes by\nconstructing visual representations using text embeddings. Furthermore, our\nrelation predictor leverages node representations to infer absent relationships\nbetween nodes, resulting in more coherent scene layouts. Extensive experimental\nresults demonstrate that MMGDreamer exhibits superior control of object\ngeometry, achieving state-of-the-art scene generation performance. Project\npage: https://yangzhifeio.github.io/project/MMGDreamer.\n","authors":["Zhifei Yang","Keyang Lu","Chao Zhang","Jiaxing Qi","Hanqi Jiang","Ruifei Ma","Shenglin Yin","Yifan Xu","Mingzhe Xing","Zhen Xiao","Jieyi Long","Xiangde Liu","Guangyao Zhai"],"pdf_url":"https://arxiv.org/pdf/2502.05874v2.pdf","comment":"Accepted by AAAI 2025 Main Track"},{"id":"http://arxiv.org/abs/2503.04509v1","updated":"2025-03-06T14:55:25Z","published":"2025-03-06T14:55:25Z","title":"STX-Search: Explanation Search for Continuous Dynamic Spatio-Temporal\n  Models","summary":"  Recent improvements in the expressive power of spatio-temporal models have\nled to performance gains in many real-world applications, such as traffic\nforecasting and social network modelling. However, understanding the\npredictions from a model is crucial to ensure reliability and trustworthiness,\nparticularly for high-risk applications, such as healthcare and transport. Few\nexisting methods are able to generate explanations for models trained on\ncontinuous-time dynamic graph data and, of these, the computational complexity\nand lack of suitable explanation objectives pose challenges. In this paper, we\npropose $\\textbf{S}$patio-$\\textbf{T}$emporal E$\\textbf{X}$planation\n$\\textbf{Search}$ (STX-Search), a novel method for generating instance-level\nexplanations that is applicable to static and dynamic temporal graph\nstructures. We introduce a novel search strategy and objective function, to\nfind explanations that are highly faithful and interpretable. When compared\nwith existing methods, STX-Search produces explanations of higher fidelity\nwhilst optimising explanation size to maintain interpretability.\n","authors":["Saif Anwar","Nathan Griffiths","Thomas Popham","Abhir Bhalerao"],"pdf_url":"https://arxiv.org/pdf/2503.04509v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.04507v1","updated":"2025-03-06T14:54:28Z","published":"2025-03-06T14:54:28Z","title":"A Morse Transform for Drug Discovery","summary":"  We introduce a new ligand-based virtual screening (LBVS) framework that uses\npiecewise linear (PL) Morse theory to predict ligand binding potential. We\nmodel ligands as simplicial complexes via a pruned Delaunay triangulation, and\ncatalogue the critical points across multiple directional height functions.\nThis produces a rich feature vector, consisting of crucial topological features\n-- peaks, troughs, and saddles -- that characterise ligand surfaces relevant to\nbinding interactions. Unlike contemporary LBVS methods that rely on\ncomputationally-intensive deep neural networks, we require only a lightweight\nclassifier. The Morse theoretic approach achieves state-of-the-art performance\non standard datasets while offering an interpretable feature vector and\nscalable method for ligand prioritization in early-stage drug discovery.\n","authors":["Alexander M. Tanaka","Aras T. Asaad","Richard Cooper","Vidit Nanda"],"pdf_url":"https://arxiv.org/pdf/2503.04507v1.pdf","comment":"25 pages, 5 main figures, 2 main tables, 6 supplementary figures and\n  4 supplementary tables"},{"id":"http://arxiv.org/abs/2501.00020v2","updated":"2025-03-06T14:52:11Z","published":"2024-12-16T11:35:40Z","title":"Magnetic Field Data Calibration with Transformer Model Using Physical\n  Constraints: A Scalable Method for Satellite Missions, Illustrated by\n  Tianwen-1","summary":"  This study introduces a novel approach that integrates the magnetic field\ndata correction from the Tianwen-1 Mars mission with a neural network\narchitecture constrained by physical principles derived from Maxwell's equation\nequations. By employing a Transformer based model capable of efficiently\nhandling sequential data, the method corrects measurement anomalies caused by\nsatellite dynamics, instrument interference, and environmental noise. As a\nresult, it significantly improves both the accuracy and the physical\nconsistency of the calibrated data. Compared to traditional methods that\nrequire long data segments and manual intervention often taking weeks or even\nmonths to complete this new approach can finish calibration in just minutes to\nhours, and predictions are made within seconds. This innovation not only\naccelerates the process of space weather modeling and planetary magnetospheric\nstudies but also provides a robust framework for future planetary exploration\nand solar wind interaction research.\n","authors":["Beibei Li","Yutian Chi","Yuming Wang"],"pdf_url":"https://arxiv.org/pdf/2501.00020v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.04496v1","updated":"2025-03-06T14:44:25Z","published":"2025-03-06T14:44:25Z","title":"Learning Object Placement Programs for Indoor Scene Synthesis with\n  Iterative Self Training","summary":"  Data driven and autoregressive indoor scene synthesis systems generate indoor\nscenes automatically by suggesting and then placing objects one at a time.\nEmpirical observations show that current systems tend to produce incomplete\nnext object location distributions. We introduce a system which addresses this\nproblem. We design a Domain Specific Language (DSL) that specifies functional\nconstraints. Programs from our language take as input a partial scene and\nobject to place. Upon execution they predict possible object placements. We\ndesign a generative model which writes these programs automatically. Available\n3D scene datasets do not contain programs to train on, so we build upon\nprevious work in unsupervised program induction to introduce a new program\nbootstrapping algorithm. In order to quantify our empirical observations we\nintroduce a new evaluation procedure which captures how well a system models\nper-object location distributions. We ask human annotators to label all the\npossible places an object can go in a scene and show that our system produces\nper-object location distributions more consistent with human annotators. Our\nsystem also generates indoor scenes of comparable quality to previous systems\nand while previous systems degrade in performance when training data is sparse,\nour system does not degrade to the same degree.\n","authors":["Adrian Chang","Kai Wang","Yuanbo Li","Manolis Savva","Angel X. Chang","Daniel Ritchie"],"pdf_url":"https://arxiv.org/pdf/2503.04496v1.pdf","comment":"21 pages, 20 figures Subjects: Graphics (cs.GR), Computer Vision and\n  Pattern Recognition (cs.CV), Machine Learning (cs.LG)"},{"id":"http://arxiv.org/abs/2503.04492v1","updated":"2025-03-06T14:40:21Z","published":"2025-03-06T14:40:21Z","title":"Accurate predictive model of band gap with selected important features\n  based on explainable machine learning","summary":"  In the rapidly advancing field of materials informatics, nonlinear machine\nlearning models have demonstrated exceptional predictive capabilities for\nmaterial properties. However, their black-box nature limits interpretability,\nand they may incorporate features that do not contribute to, or even\ndeteriorate, model performance. This study employs explainable ML (XML)\ntechniques, including permutation feature importance and the SHapley Additive\nexPlanation, applied to a pristine support vector regression model designed to\npredict band gaps at the GW level using 18 input features. Guided by\nXML-derived individual feature importance, a simple framework is proposed to\nconstruct reduced-feature predictive models. Model evaluations indicate that an\nXML-guided compact model, consisting of the top five features, achieves\ncomparable accuracy to the pristine model on in-domain datasets while\ndemonstrating superior generalization with lower prediction errors on\nout-of-domain data. Additionally, the study underscores the necessity for\neliminating strongly correlated features to prevent misinterpretation and\noverestimation of feature importance before applying XML. This study highlights\nXML's effectiveness in developing simplified yet highly accurate machine\nlearning models by clarifying feature roles.\n","authors":["Joohwi Lee","Kaito Miyamoto"],"pdf_url":"https://arxiv.org/pdf/2503.04492v1.pdf","comment":"9 pages, 4 figures, SI is included"},{"id":"http://arxiv.org/abs/2503.04483v1","updated":"2025-03-06T14:32:00Z","published":"2025-03-06T14:32:00Z","title":"InfoSEM: A Deep Generative Model with Informative Priors for Gene\n  Regulatory Network Inference","summary":"  Inferring Gene Regulatory Networks (GRNs) from gene expression data is\ncrucial for understanding biological processes. While supervised models are\nreported to achieve high performance for this task, they rely on costly ground\ntruth (GT) labels and risk learning gene-specific biases, such as class\nimbalances of GT interactions, rather than true regulatory mechanisms. To\naddress these issues, we introduce InfoSEM, an unsupervised generative model\nthat leverages textual gene embeddings as informative priors, improving GRN\ninference without GT labels. InfoSEM can also integrate GT labels as an\nadditional prior when available, avoiding biases and further enhancing\nperformance. Additionally, we propose a biologically motivated benchmarking\nframework that better reflects real-world applications such as biomarker\ndiscovery and reveals learned biases of existing supervised methods. InfoSEM\noutperforms existing models by 38.5% across four datasets using textual\nembeddings prior and further boosts performance by 11.1% when integrating\nlabeled data as priors.\n","authors":["Tianyu Cui","Song-Jun Xu","Artem Moskalev","Shuwei Li","Tommaso Mansi","Mangal Prakash","Rui Liao"],"pdf_url":"https://arxiv.org/pdf/2503.04483v1.pdf","comment":"ICLR 2025 AI4NA Oral, ICLR 2025 MLGenX Spotlight, ICLR 2025 LMRL"},{"id":"http://arxiv.org/abs/2503.04482v1","updated":"2025-03-06T14:30:55Z","published":"2025-03-06T14:30:55Z","title":"Generalized Interpolating Discrete Diffusion","summary":"  While state-of-the-art language models achieve impressive results through\nnext-token prediction, they have inherent limitations such as the inability to\nrevise already generated tokens. This has prompted exploration of alternative\napproaches such as discrete diffusion. However, masked diffusion, which has\nemerged as a popular choice due to its simplicity and effectiveness,\nreintroduces this inability to revise words. To overcome this, we generalize\nmasked diffusion and derive the theoretical backbone of a family of general\ninterpolating discrete diffusion (GIDD) processes offering greater flexibility\nin the design of the noising processes. Leveraging a novel diffusion ELBO, we\nachieve compute-matched state-of-the-art performance in diffusion language\nmodeling. Exploiting GIDD's flexibility, we explore a hybrid approach combining\nmasking and uniform noise, leading to improved sample quality and unlocking the\nability for the model to correct its own mistakes, an area where autoregressive\nmodels notoriously have struggled. Our code and models are open-source:\nhttps://github.com/dvruette/gidd/\n","authors":["Dimitri von Rtte","Janis Fluri","Yuhui Ding","Antonio Orvieto","Bernhard Schlkopf","Thomas Hofmann"],"pdf_url":"https://arxiv.org/pdf/2503.04482v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.04480v1","updated":"2025-03-06T14:30:15Z","published":"2025-03-06T14:30:15Z","title":"Poisoning Bayesian Inference via Data Deletion and Replication","summary":"  Research in adversarial machine learning (AML) has shown that statistical\nmodels are vulnerable to maliciously altered data. However, despite advances in\nBayesian machine learning models, most AML research remains concentrated on\nclassical techniques. Therefore, we focus on extending the white-box model\npoisoning paradigm to attack generic Bayesian inference, highlighting its\nvulnerability in adversarial contexts. A suite of attacks are developed that\nallow an attacker to steer the Bayesian posterior toward a target distribution\nthrough the strategic deletion and replication of true observations, even when\nonly sampling access to the posterior is available. Analytic properties of\nthese algorithms are proven and their performance is empirically examined in\nboth synthetic and real-world scenarios. With relatively little effort, the\nattacker is able to substantively alter the Bayesian's beliefs and, by\naccepting more risk, they can mold these beliefs to their will. By carefully\nconstructing the adversarial posterior, surgical poisoning is achieved such\nthat only targeted inferences are corrupted and others are minimally disturbed.\n","authors":["Matthieu Carreau","Roi Naveiro","William N. Caballero"],"pdf_url":"https://arxiv.org/pdf/2503.04480v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2502.13524v4","updated":"2025-03-06T14:27:12Z","published":"2025-02-19T08:21:59Z","title":"MobileViM: A Light-weight and Dimension-independent Vision Mamba for 3D\n  Medical Image Analysis","summary":"  Efficient evaluation of three-dimensional (3D) medical images is crucial for\ndiagnostic and therapeutic practices in healthcare. Recent years have seen a\nsubstantial uptake in applying deep learning and computer vision to analyse and\ninterpret medical images. Traditional approaches, such as convolutional neural\nnetworks (CNNs) and vision transformers (ViTs), face significant computational\nchallenges, prompting the need for architectural advancements. Recent efforts\nhave led to the introduction of novel architectures like the ``Mamba'' model as\nalternative solutions to traditional CNNs or ViTs. The Mamba model excels in\nthe linear processing of one-dimensional data with low computational demands.\nHowever, Mamba's potential for 3D medical image analysis remains underexplored\nand could face significant computational challenges as the dimension increases.\nThis manuscript presents MobileViM, a streamlined architecture for efficient\nsegmentation of 3D medical images. In the MobileViM network, we invent a new\ndimension-independent mechanism and a dual-direction traversing approach to\nincorporate with a vision-Mamba-based framework. MobileViM also features a\ncross-scale bridging technique to improve efficiency and accuracy across\nvarious medical imaging modalities. With these enhancements, MobileViM achieves\nsegmentation speeds exceeding 90 frames per second (FPS) on a single graphics\nprocessing unit (i.e., NVIDIA RTX 4090). This performance is over 24 FPS faster\nthan the state-of-the-art deep learning models for processing 3D images with\nthe same computational resources. In addition, experimental evaluations\ndemonstrate that MobileViM delivers superior performance, with Dice similarity\nscores reaching 92.72%, 86.69%, 80.46%, and 77.43% for PENGWIN, BraTS2024,\nATLAS, and Toothfairy2 datasets, respectively, which significantly surpasses\nexisting models.\n","authors":["Wei Dai","Jun Liu"],"pdf_url":"https://arxiv.org/pdf/2502.13524v4.pdf","comment":"The corresponding author disagrees with the manuscript submitted to\n  arXiv"},{"id":"http://arxiv.org/abs/2503.03454v2","updated":"2025-03-06T14:25:03Z","published":"2025-03-05T12:40:34Z","title":"Data Poisoning Attacks to Locally Differentially Private Range Query\n  Protocols","summary":"  Local Differential Privacy (LDP) has been widely adopted to protect user\nprivacy in decentralized data collection. However, recent studies have revealed\nthat LDP protocols are vulnerable to data poisoning attacks, where malicious\nusers manipulate their reported data to distort aggregated results. In this\nwork, we present the first study on data poisoning attacks targeting LDP range\nquery protocols, focusing on both tree-based and grid-based approaches. We\nidentify three key challenges in executing such attacks, including crafting\nconsistent and effective fake data, maintaining data consistency across levels\nor grids, and preventing server detection. To address the first two challenges,\nwe propose novel attack methods that are provably optimal, including a\ntree-based attack and a grid-based attack, designed to manipulate range query\nresults with high effectiveness. \\textbf{Our key finding is that the common\npost-processing procedure, Norm-Sub, in LDP range query protocols can help the\nattacker massively amplify their attack effectiveness.} In addition, we study a\npotential countermeasure, but also propose an adaptive attack capable of\nevading this defense to address the third challenge. We evaluate our methods\nthrough theoretical analysis and extensive experiments on synthetic and\nreal-world datasets. Our results show that the proposed attacks can\nsignificantly amplify estimations for arbitrary range queries by manipulating a\nsmall fraction of users, providing 5-10x more influence than a normal user to\nthe estimation.\n","authors":["Ting-Wei Liao","Chih-Hsun Lin","Yu-Lin Tsai","Takao Murakami","Chia-Mu Yu","Jun Sakuma","Chun-Ying Huang","Hiroaki Kikuchi"],"pdf_url":"https://arxiv.org/pdf/2503.03454v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.04474v1","updated":"2025-03-06T14:24:12Z","published":"2025-03-06T14:24:12Z","title":"Know Thy Judge: On the Robustness Meta-Evaluation of LLM Safety Judges","summary":"  Large Language Model (LLM) based judges form the underpinnings of key safety\nevaluation processes such as offline benchmarking, automated red-teaming, and\nonline guardrailing. This widespread requirement raises the crucial question:\ncan we trust the evaluations of these evaluators? In this paper, we highlight\ntwo critical challenges that are typically overlooked: (i) evaluations in the\nwild where factors like prompt sensitivity and distribution shifts can affect\nperformance and (ii) adversarial attacks that target the judge. We highlight\nthe importance of these through a study of commonly used safety judges, showing\nthat small changes such as the style of the model output can lead to jumps of\nup to 0.24 in the false negative rate on the same dataset, whereas adversarial\nattacks on the model generation can fool some judges into misclassifying 100%\nof harmful generations as safe ones. These findings reveal gaps in commonly\nused meta-evaluation benchmarks and weaknesses in the robustness of current LLM\njudges, indicating that low attack success under certain judges could create a\nfalse sense of security.\n","authors":["Francisco Eiras","Eliott Zemour","Eric Lin","Vaikkunth Mugunthan"],"pdf_url":"https://arxiv.org/pdf/2503.04474v1.pdf","comment":"Accepted to the ICBINB Workshop at ICLR'25"},{"id":"http://arxiv.org/abs/2503.04472v1","updated":"2025-03-06T14:23:06Z","published":"2025-03-06T14:23:06Z","title":"DAST: Difficulty-Adaptive Slow-Thinking for Large Reasoning Models","summary":"  Recent advancements in slow-thinking reasoning models have shown exceptional\nperformance in complex reasoning tasks. However, these models often exhibit\noverthinking-generating redundant reasoning steps for simple problems, leading\nto excessive computational resource usage. While current mitigation strategies\nuniformly reduce reasoning tokens, they risk degrading performance on\nchallenging tasks that require extended reasoning. This paper introduces\nDifficulty-Adaptive Slow-Thinking (DAST), a novel framework that enables models\nto autonomously adjust the length of Chain-of-Thought(CoT) based on problem\ndifficulty. We first propose a Token Length Budget (TLB) metric to quantify\ndifficulty, then leveraging length-aware reward shaping and length preference\noptimization to implement DAST. DAST penalizes overlong responses for simple\ntasks while incentivizing sufficient reasoning for complex problems.\nExperiments on diverse datasets and model scales demonstrate that DAST\neffectively mitigates overthinking (reducing token usage by over 30\\% on\naverage) while preserving reasoning accuracy on complex problems.\n","authors":["Yi Shen","Jian Zhang","Jieyun Huang","Shuming Shi","Wenjing Zhang","Jiangze Yan","Ning Wang","Kai Wang","Shiguo Lian"],"pdf_url":"https://arxiv.org/pdf/2503.04472v1.pdf","comment":"working in progress"},{"id":"http://arxiv.org/abs/2503.04469v1","updated":"2025-03-06T14:19:55Z","published":"2025-03-06T14:19:55Z","title":"An artificially intelligent magnetic resonance spectroscopy\n  quantification method: Comparison between QNet and LCModel on the cloud\n  computing platform CloudBrain-MRS","summary":"  Objctives: This work aimed to statistically compare the metabolite\nquantification of human brain magnetic resonance spectroscopy (MRS) between the\ndeep learning method QNet and the classical method LCModel through an\neasy-to-use intelligent cloud computing platform CloudBrain-MRS. Materials and\nMethods: In this retrospective study, two 3 T MRI scanners Philips Ingenia and\nAchieva collected 61 and 46 in vivo 1H magnetic resonance (MR) spectra of\nhealthy participants, respectively, from the brain region of pregenual anterior\ncingulate cortex from September to October 2021. The analyses of Bland-Altman,\nPearson correlation and reasonability were performed to assess the degree of\nagreement, linear correlation and reasonability between the two quantification\nmethods. Results: Fifteen healthy volunteers (12 females and 3 males, age\nrange: 21-35 years, mean age/standard deviation = 27.4/3.9 years) were\nrecruited. The analyses of Bland-Altman, Pearson correlation and reasonability\nshowed high to good consistency and very strong to moderate correlation between\nthe two methods for quantification of total N-acetylaspartate (tNAA), total\ncholine (tCho), and inositol (Ins) (relative half interval of limits of\nagreement = 3.04%, 9.3%, and 18.5%, respectively; Pearson correlation\ncoefficient r = 0.775, 0.927, and 0.469, respectively). In addition,\nquantification results of QNet are more likely to be closer to the previous\nreported average values than those of LCModel. Conclusion: There were high or\ngood degrees of consistency between the quantification results of QNet and\nLCModel for tNAA, tCho, and Ins, and QNet generally has more reasonable\nquantification than LCModel.\n","authors":["Meijin Lin","Lin Guo","Dicheng Chen","Jianshu Chen","Zhangren Tu","Xu Huang","Jianhua Wang","Ji Qi","Yuan Long","Zhiguo Huang","Di Guo","Xiaobo Qu","Haiwei Han"],"pdf_url":"https://arxiv.org/pdf/2503.04469v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.04462v1","updated":"2025-03-06T14:13:59Z","published":"2025-03-06T14:13:59Z","title":"PALo: Learning Posture-Aware Locomotion for Quadruped Robots","summary":"  With the rapid development of embodied intelligence, locomotion control of\nquadruped robots on complex terrains has become a research hotspot. Unlike\ntraditional locomotion control approaches focusing solely on velocity tracking,\nwe pursue to balance the agility and robustness of quadruped robots on diverse\nand complex terrains. To this end, we propose an end-to-end deep reinforcement\nlearning framework for posture-aware locomotion named PALo, which manages to\nhandle simultaneous linear and angular velocity tracking and real-time\nadjustments of body height, pitch, and roll angles. In PALo, the locomotion\ncontrol problem is formulated as a partially observable Markov decision\nprocess, and an asymmetric actor-critic architecture is adopted to overcome the\nsim-to-real challenge. Further, by incorporating customized training curricula,\nPALo achieves agile posture-aware locomotion control in simulated environments\nand successfully transfers to real-world settings without fine-tuning, allowing\nreal-time control of the quadruped robot's locomotion and body posture across\nchallenging terrains. Through in-depth experimental analysis, we identify the\nkey components of PALo that contribute to its performance, further validating\nthe effectiveness of the proposed method. The results of this study provide new\npossibilities for the low-level locomotion control of quadruped robots in\nhigher dimensional command spaces and lay the foundation for future research on\nupper-level modules for embodied intelligence.\n","authors":["Xiangyu Miao","Jun Sun","Hang Lai","Xinpeng Di","Jiahang Cao","Yong Yu","Weinan Zhang"],"pdf_url":"https://arxiv.org/pdf/2503.04462v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.01684v2","updated":"2025-03-06T14:07:34Z","published":"2025-03-03T15:58:15Z","title":"An Efficient Learning Method to Connect Observables","summary":"  Constructing fast and accurate surrogate models is a key ingredient for\nmaking robust predictions in many topics. We introduce a new model, the\nMultiparameter Eigenvalue Problem (MEP) emulator. The new method connects\nemulators and can make predictions directly from observables to observables. We\npresent that the MEP emulator can be trained with data from Eigenvector\nContinuation (EC) and Parametric Matrix Model (PMM) emulators. A simple\nsimulation on a one-dimensional lattice confirms the performance of the MEP\nemulator. Using $^{28}$O as an example, we also demonstrate that the predictive\nprobability distribution of the target observables can be easily obtained\nthrough the new emulator.\n","authors":["Hang Yu","Takayuki Miyagi"],"pdf_url":"https://arxiv.org/pdf/2503.01684v2.pdf","comment":"5+2 pages, 4 figures, updated acknowledgment"},{"id":"http://arxiv.org/abs/2503.04453v1","updated":"2025-03-06T14:06:50Z","published":"2025-03-06T14:06:50Z","title":"Reproducibility Assessment of Magnetic Resonance Spectroscopy of\n  Pregenual Anterior Cingulate Cortex across Sessions and Vendors via the Cloud\n  Computing Platform CloudBrain-MRS","summary":"  Given the need to elucidate the mechanisms underlying illnesses and their\ntreatment, as well as the lack of harmonization of acquisition and\npost-processing protocols among different magnetic resonance system vendors,\nthis work is to determine if metabolite concentrations obtained from different\nsessions, machine models and even different vendors of 3 T scanners can be\nhighly reproducible and be pooled for diagnostic analysis, which is very\nvaluable for the research of rare diseases. Participants underwent magnetic\nresonance imaging (MRI) scanning once on two separate days within one week (one\nsession per day, each session including two proton magnetic resonance\nspectroscopy (1H-MRS) scans with no more than a 5-minute interval between scans\n(no off-bed activity)) on each machine. were analyzed for reliability of\nwithin- and between- sessions using the coefficient of variation (CV) and\nintraclass correlation coefficient (ICC), and for reproducibility of across the\nmachines using correlation coefficient. As for within- and between- session,\nall CV values for a group of all the first or second scans of a session, or for\na session were almost below 20%, and most of the ICCs for metabolites range\nfrom moderate (0.4-0.59) to excellent (0.75-1), indicating high data\nreliability. When it comes to the reproducibility across the three scanners,\nall Pearson correlation coefficients across the three machines approached 1\nwith most around 0.9, and majority demonstrated statistical significance\n(P<0.01). Additionally, the intra-vendor reproducibility was greater than the\ninter-vendor ones.\n","authors":["Runhan Chen","Meijin Lin","Jianshu Chen","Liangjie Lin","Jiazheng Wang","Xiaoqing Li","Jianhua Wang","Xu Huang","Ling Qian","Shaoxing Liu","Yuan Long","Di Guo","Xiaobo Qu","Haiwei Han"],"pdf_url":"https://arxiv.org/pdf/2503.04453v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.04451v1","updated":"2025-03-06T14:06:20Z","published":"2025-03-06T14:06:20Z","title":"Privacy Preserving and Robust Aggregation for Cross-Silo Federated\n  Learning in Non-IID Settings","summary":"  Federated Averaging remains the most widely used aggregation strategy in\nfederated learning due to its simplicity and scalability. However, its\nperformance degrades significantly in non-IID data settings, where client\ndistributions are highly imbalanced or skewed. Additionally, it relies on\nclients transmitting metadata, specifically the number of training samples,\nwhich introduces privacy risks and may conflict with regulatory frameworks like\nthe European GDPR. In this paper, we propose a novel aggregation strategy that\naddresses these challenges by introducing class-aware gradient masking. Unlike\ntraditional approaches, our method relies solely on gradient updates,\neliminating the need for any additional client metadata, thereby enhancing\nprivacy protection. Furthermore, our approach validates and dynamically weights\nclient contributions based on class-specific importance, ensuring robustness\nagainst non-IID distributions, convergence prevention, and backdoor attacks.\nExtensive experiments on benchmark datasets demonstrate that our method not\nonly outperforms FedAvg and other widely accepted aggregation strategies in\nnon-IID settings but also preserves model integrity in adversarial scenarios.\nOur results establish the effectiveness of gradient masking as a practical and\nsecure solution for federated learning.\n","authors":["Marco Arazzi","Mert Cihangiroglu","Antonino Nocera"],"pdf_url":"https://arxiv.org/pdf/2503.04451v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.04447v1","updated":"2025-03-06T14:02:28Z","published":"2025-03-06T14:02:28Z","title":"A Graph-Partitioning Based Continuous Optimization Approach to\n  Semi-supervised Clustering Problems","summary":"  Semi-supervised clustering is a basic problem in various applications. Most\nexisting methods require knowledge of the ideal cluster number, which is often\ndifficult to obtain in practice. Besides, satisfying the must-link constraints\nis another major challenge for these methods. In this work, we view the\nsemi-supervised clustering task as a partitioning problem on a graph associated\nwith the given dataset, where the similarity matrix includes a scaling\nparameter to reflect the must-link constraints. Utilizing a relaxation\ntechnique, we formulate the graph partitioning problem into a continuous\noptimization model that does not require the exact cluster number, but only an\noverestimate of it. We then propose a block coordinate descent algorithm to\nefficiently solve this model, and establish its convergence result. Based on\nthe obtained solution, we can construct the clusters that theoretically meet\nthe must-link constraints under mild assumptions. Furthermore, we verify the\neffectiveness and efficiency of our proposed method through comprehensive\nnumerical experiments.\n","authors":["Wei Liu","Xin Liu","Michael K. Ng","Zaikun Zhang"],"pdf_url":"https://arxiv.org/pdf/2503.04447v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2402.08010v2","updated":"2025-03-06T14:01:48Z","published":"2024-02-12T19:18:50Z","title":"Which Frequencies do CNNs Need? Emergent Bottleneck Structure in Feature\n  Learning","summary":"  We describe the emergence of a Convolution Bottleneck (CBN) structure in\nCNNs, where the network uses its first few layers to transform the input\nrepresentation into a representation that is supported only along a few\nfrequencies and channels, before using the last few layers to map back to the\noutputs. We define the CBN rank, which describes the number and type of\nfrequencies that are kept inside the bottleneck, and partially prove that the\nparameter norm required to represent a function $f$ scales as depth times the\nCBN rank $f$. We also show that the parameter norm depends at next order on the\nregularity of $f$. We show that any network with almost optimal parameter norm\nwill exhibit a CBN structure in both the weights and - under the assumption\nthat the network is stable under large learning rate - the activations, which\nmotivates the common practice of down-sampling; and we verify that the CBN\nresults still hold with down-sampling. Finally we use the CBN structure to\ninterpret the functions learned by CNNs on a number of tasks.\n","authors":["Yuxiao Wen","Arthur Jacot"],"pdf_url":"https://arxiv.org/pdf/2402.08010v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2405.17573v2","updated":"2025-03-06T13:47:53Z","published":"2024-05-27T18:15:05Z","title":"Hamiltonian Mechanics of Feature Learning: Bottleneck Structure in Leaky\n  ResNets","summary":"  We study Leaky ResNets, which interpolate between ResNets and Fully-Connected\nnets depending on an 'effective depth' hyper-parameter $\\tilde{L}$. In the\ninfinite depth limit, we study 'representation geodesics' $A_{p}$: continuous\npaths in representation space (similar to NeuralODEs) from input $p=0$ to\noutput $p=1$ that minimize the parameter norm of the network. We give a\nLagrangian and Hamiltonian reformulation, which highlight the importance of two\nterms: a kinetic energy which favors small layer derivatives\n$\\partial_{p}A_{p}$ and a potential energy that favors low-dimensional\nrepresentations, as measured by the 'Cost of Identity'. The balance between\nthese two forces offers an intuitive understanding of feature learning in\nResNets. We leverage this intuition to explain the emergence of a bottleneck\nstructure, as observed in previous work: for large $\\tilde{L}$ the potential\nenergy dominates and leads to a separation of timescales, where the\nrepresentation jumps rapidly from the high dimensional inputs to a\nlow-dimensional representation, move slowly inside the space of low-dimensional\nrepresentations, before jumping back to the potentially high-dimensional\noutputs. Inspired by this phenomenon, we train with an adaptive layer step-size\nto adapt to the separation of timescales.\n","authors":["Arthur Jacot","Alexandre Kaiser"],"pdf_url":"https://arxiv.org/pdf/2405.17573v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2407.05664v2","updated":"2025-03-06T13:40:09Z","published":"2024-07-08T06:59:29Z","title":"How DNNs break the Curse of Dimensionality: Compositionality and\n  Symmetry Learning","summary":"  We show that deep neural networks (DNNs) can efficiently learn any\ncomposition of functions with bounded $F_{1}$-norm, which allows DNNs to break\nthe curse of dimensionality in ways that shallow networks cannot. More\nspecifically, we derive a generalization bound that combines a covering number\nargument for compositionality, and the $F_{1}$-norm (or the related Barron\nnorm) for large width adaptivity. We show that the global minimizer of the\nregularized loss of DNNs can fit for example the composition of two functions\n$f^{*}=h\\circ g$ from a small number of observations, assuming $g$ is\nsmooth/regular and reduces the dimensionality (e.g. $g$ could be the quotient\nmap of the symmetries of $f^{*}$), so that $h$ can be learned in spite of its\nlow regularity. The measures of regularity we consider is the Sobolev norm with\ndifferent levels of differentiability, which is well adapted to the $F_{1}$\nnorm. We compute scaling laws empirically and observe phase transitions\ndepending on whether $g$ or $h$ is harder to learn, as predicted by our theory.\n","authors":["Arthur Jacot","Seok Hoan Choi","Yuxiao Wen"],"pdf_url":"https://arxiv.org/pdf/2407.05664v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.12261v3","updated":"2025-03-06T13:39:32Z","published":"2024-10-16T05:58:55Z","title":"CATCH: Channel-Aware multivariate Time Series Anomaly Detection via\n  Frequency Patching","summary":"  Anomaly detection in multivariate time series is challenging as heterogeneous\nsubsequence anomalies may occur. Reconstruction-based methods, which focus on\nlearning normal patterns in the frequency domain to detect diverse abnormal\nsubsequences, achieve promising results, while still falling short on capturing\nfine-grained frequency characteristics and channel correlations. To contend\nwith the limitations, we introduce CATCH, a framework based on frequency\npatching. We propose to patchify the frequency domain into frequency bands,\nwhich enhances its ability to capture fine-grained frequency characteristics.\nTo perceive appropriate channel correlations, we propose a Channel Fusion\nModule (CFM), which features a patch-wise mask generator and a masked-attention\nmechanism. Driven by a bi-level multi-objective optimization algorithm, the CFM\nis encouraged to iteratively discover appropriate patch-wise channel\ncorrelations, and to cluster relevant channels while isolating adverse effects\nfrom irrelevant channels. Extensive experiments on 10 real-world datasets and\n12 synthetic datasets demonstrate that CATCH achieves state-of-the-art\nperformance. We make our code and datasets available at\nhttps://github.com/decisionintelligence/CATCH.\n","authors":["Xingjian Wu","Xiangfei Qiu","Zhengyu Li","Yihang Wang","Jilin Hu","Chenjuan Guo","Hui Xiong","Bin Yang"],"pdf_url":"https://arxiv.org/pdf/2410.12261v3.pdf","comment":"Accepted by ICLR 2025"},{"id":"http://arxiv.org/abs/2503.04426v1","updated":"2025-03-06T13:35:59Z","published":"2025-03-06T13:35:59Z","title":"FORTALESA: Fault-Tolerant Reconfigurable Systolic Array for DNN\n  Inference","summary":"  The emergence of Deep Neural Networks (DNNs) in mission- and safety-critical\napplications brings their reliability to the front. High performance demands of\nDNNs require the use of specialized hardware accelerators. Systolic array\narchitecture is widely used in DNN accelerators due to its parallelism and\nregular structure. This work presents a run-time reconfigurable systolic array\narchitecture with three execution modes and four implementation options. All\nfour implementations are evaluated in terms of resource utilization,\nthroughput, and fault tolerance improvement. The proposed architecture is used\nfor reliability enhancement of DNN inference on systolic array through\nheterogeneous mapping of different network layers to different execution modes.\nThe approach is supported by a novel reliability assessment method based on\nfault propagation analysis. It is used for the exploration of the appropriate\nexecution mode-layer mapping for DNN inference. The proposed architecture\nefficiently protects registers and MAC units of systolic array PEs from\ntransient and permanent faults. The reconfigurability feature enables a speedup\nof up to $3\\times$, depending on layer vulnerability. Furthermore, it requires\n$6\\times$ less resources compared to static redundancy and $2.5\\times$ less\nresources compared to the previously proposed solution for transient faults.\n","authors":["Natalia Cherezova","Artur Jutman","Maksim Jenihhin"],"pdf_url":"https://arxiv.org/pdf/2503.04426v1.pdf","comment":"11 pages, 15 figures"},{"id":"http://arxiv.org/abs/2503.04424v1","updated":"2025-03-06T13:32:13Z","published":"2025-03-06T13:32:13Z","title":"Determinant Estimation under Memory Constraints and Neural Scaling Laws","summary":"  Calculating or accurately estimating log-determinants of large positive\nsemi-definite matrices is of fundamental importance in many machine learning\ntasks. While its cubic computational complexity can already be prohibitive, in\nmodern applications, even storing the matrices themselves can pose a memory\nbottleneck. To address this, we derive a novel hierarchical algorithm based on\nblock-wise computation of the LDL decomposition for large-scale log-determinant\ncalculation in memory-constrained settings. In extreme cases where matrices are\nhighly ill-conditioned, accurately computing the full matrix itself may be\ninfeasible. This is particularly relevant when considering kernel matrices at\nscale, including the empirical Neural Tangent Kernel (NTK) of neural networks\ntrained on large datasets. Under the assumption of neural scaling laws in the\ntest error, we show that the ratio of pseudo-determinants satisfies a power-law\nrelationship, allowing us to derive corresponding scaling laws. This enables\naccurate estimation of NTK log-determinants from a tiny fraction of the full\ndataset; in our experiments, this results in a $\\sim$100,000$\\times$ speedup\nwith improved accuracy over competing approximations. Using these techniques,\nwe successfully estimate log-determinants for dense matrices of extreme sizes,\nwhich were previously deemed intractable and inaccessible due to their enormous\nscale and computational demands.\n","authors":["Siavash Ameli","Chris van der Heide","Liam Hodgkinson","Fred Roosta","Michael W. Mahoney"],"pdf_url":"https://arxiv.org/pdf/2503.04424v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.07978v4","updated":"2025-03-06T13:29:24Z","published":"2023-11-14T08:10:14Z","title":"AfroBench: How Good are Large Language Models on African Languages?","summary":"  Large-scale multilingual evaluations, such as MEGA, often include only a\nhandful of African languages due to the scarcity of high-quality evaluation\ndata and the limited discoverability of existing African datasets. This lack of\nrepresentation hinders comprehensive LLM evaluation across a diverse range of\nlanguages and tasks. To address these challenges, we introduce AfroBench -- a\nmulti-task benchmark for evaluating the performance of LLMs across 64 African\nlanguages, 15 tasks and 22 datasets. AfroBench consists of nine natural\nlanguage understanding datasets, six text generation datasets, six knowledge\nand question answering tasks, and one mathematical reasoning task. We present\nresults comparing the performance of prompting LLMs to fine-tuned baselines\nbased on BERT and T5-style models. Our results suggest large gaps in\nperformance between high-resource languages, such as English, and African\nlanguages across most tasks; but performance also varies based on the\navailability of monolingual data resources. Our findings confirm that\nperformance on African languages continues to remain a hurdle for current LLMs,\nunderscoring the need for additional efforts to close this gap.\n  https://mcgill-nlp.github.io/AfroBench/\n","authors":["Jessica Ojo","Odunayo Ogundepo","Akintunde Oladipo","Kelechi Ogueji","Jimmy Lin","Pontus Stenetorp","David Ifeoluwa Adelani"],"pdf_url":"https://arxiv.org/pdf/2311.07978v4.pdf","comment":"Under review"},{"id":"http://arxiv.org/abs/2503.04418v1","updated":"2025-03-06T13:21:38Z","published":"2025-03-06T13:21:38Z","title":"AOLO: Analysis and Optimization For Low-Carbon Oriented Wireless Large\n  Language Model Services","summary":"  Recent advancements in large language models (LLMs) have led to their\nwidespread adoption and large-scale deployment across various domains. However,\ntheir environmental impact, particularly during inference, has become a growing\nconcern due to their substantial energy consumption and carbon footprint.\nExisting research has focused on inference computation alone, overlooking the\nanalysis and optimization of carbon footprint in network-aided LLM service\nsystems. To address this gap, we propose AOLO, a framework for analysis and\noptimization for low-carbon oriented wireless LLM services. AOLO introduces a\ncomprehensive carbon footprint model that quantifies greenhouse gas emissions\nacross the entire LLM service chain, including computational inference and\nwireless communication. Furthermore, we formulate an optimization problem aimed\nat minimizing the overall carbon footprint, which is solved through joint\noptimization of inference outputs and transmit power under\nquality-of-experience and system performance constraints. To achieve this joint\noptimization, we leverage the energy efficiency of spiking neural networks\n(SNNs) by adopting SNN as the actor network and propose a low-carbon-oriented\noptimization algorithm, i.e., SNN-based deep reinforcement learning (SDRL).\nComprehensive simulations demonstrate that SDRL algorithm significantly reduces\noverall carbon footprint, achieving an 18.77% reduction compared to the\nbenchmark soft actor-critic, highlighting its potential for enabling more\nsustainable LLM inference services.\n","authors":["Xiaoqi Wang","Hongyang Du","Yuehong Gao","Dong In Kim"],"pdf_url":"https://arxiv.org/pdf/2503.04418v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.04416v1","updated":"2025-03-06T13:18:37Z","published":"2025-03-06T13:18:37Z","title":"Learning Transformer-based World Models with Contrastive Predictive\n  Coding","summary":"  The DreamerV3 algorithm recently obtained remarkable performance across\ndiverse environment domains by learning an accurate world model based on\nRecurrent Neural Networks (RNNs). Following the success of model-based\nreinforcement learning algorithms and the rapid adoption of the Transformer\narchitecture for its superior training efficiency and favorable scaling\nproperties, recent works such as STORM have proposed replacing RNN-based world\nmodels with Transformer-based world models using masked self-attention.\nHowever, despite the improved training efficiency of these methods, their\nimpact on performance remains limited compared to the Dreamer algorithm,\nstruggling to learn competitive Transformer-based world models. In this work,\nwe show that the next state prediction objective adopted in previous approaches\nis insufficient to fully exploit the representation capabilities of\nTransformers. We propose to extend world model predictions to longer time\nhorizons by introducing TWISTER (Transformer-based World model wIth contraSTivE\nRepresentations), a world model using action-conditioned Contrastive Predictive\nCoding to learn high-level temporal feature representations and improve the\nagent performance. TWISTER achieves a human-normalized mean score of 162% on\nthe Atari 100k benchmark, setting a new record among state-of-the-art methods\nthat do not employ look-ahead search.\n","authors":["Maxime Burchi","Radu Timofte"],"pdf_url":"https://arxiv.org/pdf/2503.04416v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.04406v1","updated":"2025-03-06T13:00:53Z","published":"2025-03-06T13:00:53Z","title":"Training-Free Graph Filtering via Multimodal Feature Refinement for\n  Extremely Fast Multimodal Recommendation","summary":"  Multimodal recommender systems improve the performance of canonical\nrecommender systems with no item features by utilizing diverse content types\nsuch as text, images, and videos, while alleviating inherent sparsity of\nuser-item interactions and accelerating user engagement. However, current\nneural network-based models often incur significant computational overhead due\nto the complex training process required to learn and integrate information\nfrom multiple modalities. To overcome this limitation, we propose\nMultiModal-Graph Filtering (MM-GF), a training-free method based on the notion\nof graph filtering (GF) for efficient and accurate multimodal recommendations.\nSpecifically, MM-GF first constructs multiple similarity graphs through\nnontrivial multimodal feature refinement such as robust scaling and vector\nshifting by addressing the heterogeneous characteristics across modalities.\nThen, MM-GF optimally fuses multimodal information using linear low-pass\nfilters across different modalities. Extensive experiments on real-world\nbenchmark datasets demonstrate that MM-GF not only improves recommendation\naccuracy by up to 13.35% compared to the best competitor but also dramatically\nreduces computational costs by achieving the runtime of less than 10 seconds.\n","authors":["Yu-Seung Roh","Joo-Young Kim","Jin-Duk Park","Won-Yong Shin"],"pdf_url":"https://arxiv.org/pdf/2503.04406v1.pdf","comment":"10 pages, 6 figures, 6 tables"},{"id":"http://arxiv.org/abs/2503.04404v1","updated":"2025-03-06T12:58:09Z","published":"2025-03-06T12:58:09Z","title":"Temporal Analysis of NetFlow Datasets for Network Intrusion Detection\n  Systems","summary":"  This paper investigates the temporal analysis of NetFlow datasets for machine\nlearning (ML)-based network intrusion detection systems (NIDS). Although many\nprevious studies have highlighted the critical role of temporal features, such\nas inter-packet arrival time and flow length/duration, in NIDS, the currently\navailable NetFlow datasets for NIDS lack these temporal features. This study\naddresses this gap by creating and making publicly available a set of NetFlow\ndatasets that incorporate these temporal features [1]. With these temporal\nfeatures, we provide a comprehensive temporal analysis of NetFlow datasets by\nexamining the distribution of various features over time and presenting\ntime-series representations of NetFlow features. This temporal analysis has not\nbeen previously provided in the existing literature. We also borrowed an idea\nfrom signal processing, time frequency analysis, and tested it to see how\ndifferent the time frequency signal presentations (TFSPs) are for various\nattacks. The results indicate that many attacks have unique patterns, which\ncould help ML models to identify them more easily.\n","authors":["Majed Luay","Siamak Layeghy","Seyedehfaezeh Hosseininoorbin","Mohanad Sarhan","Nour Moustafa","Marius Portmann"],"pdf_url":"https://arxiv.org/pdf/2503.04404v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.04398v1","updated":"2025-03-06T12:52:22Z","published":"2025-03-06T12:52:22Z","title":"Speculative MoE: Communication Efficient Parallel MoE Inference with\n  Speculative Token and Expert Pre-scheduling","summary":"  MoE (Mixture of Experts) prevails as a neural architecture that can scale\nmodern transformer-based LLMs (Large Language Models) to unprecedented scales.\nNevertheless, large MoEs' great demands of computing power, memory capacity and\nmemory bandwidth make scalable serving a fundamental challenge and efficient\nparallel inference has become a requisite to attain adequate throughput under\nlatency constraints. DeepSpeed-MoE, one state-of-the-art MoE inference\nframework, adopts a 3D-parallel paradigm including EP (Expert Parallelism), TP\n(Tensor Parallel) and DP (Data Parallelism). However, our analysis shows\nDeepSpeed-MoE's inference efficiency is largely bottlenecked by EP, which is\nimplemented with costly all-to-all collectives to route token activation. Our\nwork aims to boost DeepSpeed-MoE by strategically reducing EP's communication\noverhead with a technique named Speculative MoE. Speculative MoE has two\nspeculative parallelization schemes, speculative token shuffling and\nspeculative expert grouping, which predict outstanding tokens' expert routing\npaths and pre-schedule tokens and experts across devices to losslessly trim\nEP's communication volume. Besides DeepSpeed-MoE, we also build Speculative MoE\ninto a prevailing MoE inference engine SGLang. Experiments show Speculative MoE\ncan significantly boost state-of-the-art MoE inference frameworks on fast\nhomogeneous and slow heterogeneous interconnects.\n","authors":["Yan Li","Pengfei Zheng","Shuang Chen","Zewei Xu","Yunfei Du","Zhengang Wang"],"pdf_url":"https://arxiv.org/pdf/2503.04398v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2501.13483v3","updated":"2025-03-06T12:51:49Z","published":"2025-01-23T08:57:02Z","title":"Robust Amortized Bayesian Inference with Self-Consistency Losses on\n  Unlabeled Data","summary":"  Neural amortized Bayesian inference (ABI) can solve probabilistic inverse\nproblems orders of magnitude faster than classical methods. However, neural ABI\nis not yet sufficiently robust for widespread and safe applicability. In\nparticular, when performing inference on observations outside of the scope of\nthe simulated data seen during training, for example, because of model\nmisspecification, the posterior approximations are likely to become highly\nbiased. Due to the bad pre-asymptotic behavior of current neural posterior\nestimators in the out-of-simulation regime, the resulting estimation biases\ncannot be fixed in acceptable time by just simulating more training data. In\nthis proof-of-concept paper, we propose a semi-supervised approach that enables\ntraining not only on (labeled) simulated data generated from the model, but\nalso on unlabeled data originating from any source, including real-world data.\nTo achieve the latter, we exploit Bayesian self-consistency properties that can\nbe transformed into strictly proper losses without requiring knowledge of true\nparameter values, that is, without requiring data labels. The results of our\ninitial experiments show remarkable improvements in the robustness of ABI on\nout-of-simulation data. Even if the observed data is far away from both labeled\nand unlabeled training data, inference remains highly accurate. If our findings\nalso generalize to other scenarios and model classes, we believe that our new\nmethod represents a major breakthrough in neural ABI.\n","authors":["Aayush Mishra","Daniel Habermann","Marvin Schmitt","Stefan T. Radev","Paul-Christian Brkner"],"pdf_url":"https://arxiv.org/pdf/2501.13483v3.pdf","comment":"added acknowledgements"},{"id":"http://arxiv.org/abs/2503.03285v2","updated":"2025-03-06T12:42:37Z","published":"2025-03-05T09:12:16Z","title":"Enhancing Vietnamese VQA through Curriculum Learning on Raw and\n  Augmented Text Representations","summary":"  Visual Question Answering (VQA) is a multimodal task requiring reasoning\nacross textual and visual inputs, which becomes particularly challenging in\nlow-resource languages like Vietnamese due to linguistic variability and the\nlack of high-quality datasets. Traditional methods often rely heavily on\nextensive annotated datasets, computationally expensive pipelines, and large\npre-trained models, specifically in the domain of Vietnamese VQA, limiting\ntheir applicability in such scenarios. To address these limitations, we propose\na training framework that combines a paraphrase-based feature augmentation\nmodule with a dynamic curriculum learning strategy. Explicitly, augmented\nsamples are considered \"easy\" while raw samples are regarded as \"hard\". The\nframework then utilizes a mechanism that dynamically adjusts the ratio of easy\nto hard samples during training, progressively modifying the same dataset to\nincrease its difficulty level. By enabling gradual adaptation to task\ncomplexity, this approach helps the Vietnamese VQA model generalize well, thus\nimproving overall performance. Experimental results show consistent\nimprovements on the OpenViVQA dataset and mixed outcomes on the ViVQA dataset,\nhighlighting both the potential and challenges of our approach in advancing VQA\nfor Vietnamese language.\n","authors":["Khoi Anh Nguyen","Linh Yen Vu","Thang Dinh Duong","Thuan Nguyen Duong","Huy Thanh Nguyen","Vinh Quang Dinh"],"pdf_url":"https://arxiv.org/pdf/2503.03285v2.pdf","comment":"10 pages, 3 figures, AAAI-25 Workshop on Document Understanding and\n  Intelligence"},{"id":"http://arxiv.org/abs/2407.07918v2","updated":"2025-03-06T12:41:21Z","published":"2024-07-07T12:41:40Z","title":"Detecting new obfuscated malware variants: A lightweight and\n  interpretable machine learning approach","summary":"  Machine learning has been successfully applied in developing malware\ndetection systems, with a primary focus on accuracy, and increasing attention\nto reducing computational overhead and improving model interpretability.\nHowever, an important question remains underexplored: How well can machine\nlearning-based models detect entirely new forms of malware not present in the\ntraining data? In this study, we present a machine learning-based system for\ndetecting obfuscated malware that is not only highly accurate, lightweight and\ninterpretable, but also capable of successfully adapting to new types of\nmalware attacks. Our system is capable of detecting 15 malware subtypes despite\nbeing exclusively trained on one malware subtype, namely the Transponder from\nthe Spyware family. This system was built after training 15 distinct random\nforest-based models, each on a different malware subtype from the\nCIC-MalMem-2022 dataset. These models were evaluated against the entire range\nof malware subtypes, including all unseen malware subtypes. To maintain the\nsystem's streamlined nature, training was confined to the top five most\nimportant features, which also enhanced interpretability. The\nTransponder-focused model exhibited high accuracy, exceeding 99.8%, with an\naverage processing speed of 5.7 microseconds per file. We also illustrate how\nthe Shapley additive explanations technique can facilitate the interpretation\nof the model predictions. Our research contributes to advancing malware\ndetection methodologies, pioneering the feasibility of detecting obfuscated\nmalware by exclusively training a model on a single or a few carefully selected\nmalware subtypes and applying it to detect unseen subtypes.\n","authors":["Oladipo A. Madamidola","Felix Ngobigha","Adnane Ez-zizi"],"pdf_url":"https://arxiv.org/pdf/2407.07918v2.pdf","comment":"30 pages (excluding Appendix), 5 figures and 5 tables. Now published\n  in Intelligent Systems with Applications\n  (https://doi.org/10.1016/j.iswa.2024.200472)"},{"id":"http://arxiv.org/abs/2503.04386v1","updated":"2025-03-06T12:37:55Z","published":"2025-03-06T12:37:55Z","title":"Time-varying Factor Augmented Vector Autoregression with Grouped Sparse\n  Autoencoder","summary":"  Recent economic events, including the global financial crisis and COVID-19\npandemic, have exposed limitations in linear Factor Augmented Vector\nAutoregressive (FAVAR) models for forecasting and structural analysis.\nNonlinear dimension techniques, particularly autoencoders, have emerged as\npromising alternatives in a FAVAR framework, but challenges remain in\nidentifiability, interpretability, and integration with traditional nonlinear\ntime series methods. We address these challenges through two contributions.\nFirst, we introduce a Grouped Sparse autoencoder that employs the\nSpike-and-Slab Lasso prior, with parameters under this prior being shared\nacross variables of the same economic category, thereby achieving\nsemi-identifiability and enhancing model interpretability. Second, we\nincorporate time-varying parameters into the VAR component to better capture\nevolving economic dynamics. Our empirical application to the US economy\ndemonstrates that the Grouped Sparse autoencoder produces more interpretable\nfactors through its parsimonious structure; and its combination with\ntime-varying parameter VAR shows superior performance in both point and density\nforecasting. Impulse response analysis reveals that monetary policy shocks\nduring recessions generate more moderate responses with higher uncertainty\ncompared to expansionary periods.\n","authors":["Yiyong Luo","Brooks Paige","Jim Griffin"],"pdf_url":"https://arxiv.org/pdf/2503.04386v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2502.07527v2","updated":"2025-03-06T12:34:23Z","published":"2025-02-11T13:08:03Z","title":"Nature Language Model: Deciphering the Language of Nature for Scientific\n  Discovery","summary":"  Foundation models have revolutionized natural language processing and\nartificial intelligence, significantly enhancing how machines comprehend and\ngenerate human languages. Inspired by the success of these foundation models,\nresearchers have developed foundation models for individual scientific domains,\nincluding small molecules, materials, proteins, DNA, RNA and even cells.\nHowever, these models are typically trained in isolation, lacking the ability\nto integrate across different scientific domains. Recognizing that entities\nwithin these domains can all be represented as sequences, which together form\nthe \"language of nature\", we introduce Nature Language Model (NatureLM), a\nsequence-based science foundation model designed for scientific discovery.\nPre-trained with data from multiple scientific domains, NatureLM offers a\nunified, versatile model that enables various applications including: (i)\ngenerating and optimizing small molecules, proteins, RNA, and materials using\ntext instructions; (ii) cross-domain generation/design, such as\nprotein-to-molecule and protein-to-RNA generation; and (iii) top performance\nacross different domains, matching or surpassing state-of-the-art specialist\nmodels. NatureLM offers a promising generalist approach for various scientific\ntasks, including drug discovery (hit generation/optimization, ADMET\noptimization, synthesis), novel material design, and the development of\ntherapeutic proteins or nucleotides. We have developed NatureLM models in\ndifferent sizes (1 billion, 8 billion, and 46.7 billion parameters) and\nobserved a clear improvement in performance as the model size increases.\n","authors":["Yingce Xia","Peiran Jin","Shufang Xie","Liang He","Chuan Cao","Renqian Luo","Guoqing Liu","Yue Wang","Zequn Liu","Yuan-Jyue Chen","Zekun Guo","Yeqi Bai","Pan Deng","Yaosen Min","Ziheng Lu","Hongxia Hao","Han Yang","Jielan Li","Chang Liu","Jia Zhang","Jianwei Zhu","Ran Bi","Kehan Wu","Wei Zhang","Kaiyuan Gao","Qizhi Pei","Qian Wang","Xixian Liu","Yanting Li","Houtian Zhu","Yeqing Lu","Mingqian Ma","Zun Wang","Tian Xie","Krzysztof Maziarz","Marwin Segler","Zhao Yang","Zilong Chen","Yu Shi","Shuxin Zheng","Lijun Wu","Chen Hu","Peggy Dai","Tie-Yan Liu","Haiguang Liu","Tao Qin"],"pdf_url":"https://arxiv.org/pdf/2502.07527v2.pdf","comment":"93 pages"},{"id":"http://arxiv.org/abs/2503.04378v1","updated":"2025-03-06T12:30:24Z","published":"2025-03-06T12:30:24Z","title":"Dedicated Feedback and Edit Models Empower Inference-Time Scaling for\n  Open-Ended General-Domain Tasks","summary":"  Inference-Time Scaling has been critical to the success of recent models such\nas OpenAI o1 and DeepSeek R1. However, many techniques used to train models for\ninference-time scaling require tasks to have answers that can be verified,\nlimiting their application to domains such as math, coding and logical\nreasoning. We take inspiration from how humans make first attempts, ask for\ndetailed feedback from others and make improvements based on such feedback\nacross a wide spectrum of open-ended endeavors. To this end, we collect data\nfor and train dedicated Feedback and Edit Models that are capable of performing\ninference-time scaling for open-ended general-domain tasks. In our setup, one\nmodel generates an initial response, which are given feedback by a second\nmodel, that are then used by a third model to edit the response. We show that\nperformance on Arena Hard, a benchmark strongly predictive of Chatbot Arena Elo\ncan be boosted by scaling the number of initial response drafts, effective\nfeedback and edited responses. When scaled optimally, our setup based on 70B\nmodels from the Llama 3 family can reach SoTA performance on Arena Hard at 92.7\nas of 5 Mar 2025, surpassing OpenAI o1-preview-2024-09-12 with 90.4 and\nDeepSeek R1 with 92.3.\n","authors":["Zhilin Wang","Jiaqi Zeng","Olivier Delalleau","Daniel Egert","Ellie Evans","Hoo-Chang Shin","Felipe Soares","Yi Dong","Oleksii Kuchaiev"],"pdf_url":"https://arxiv.org/pdf/2503.04378v1.pdf","comment":"22 pages, 2 figures"},{"id":"http://arxiv.org/abs/2503.04377v1","updated":"2025-03-06T12:28:59Z","published":"2025-03-06T12:28:59Z","title":"How can representation dimension dominate structurally pruned LLMs?","summary":"  Pruning assumes a subnetwork exists in the original deep neural network,\nwhich can achieve comparative model performance with less computation than the\noriginal. However, it is unclear how the model performance varies with the\ndifferent subnetwork extractions. In this paper, we choose the representation\ndimension (or embedding dimension, model dimension, the dimension of the\nresidual stream in the relevant literature) as the entry point to this issue.\nWe investigate the linear transformations in the LLM transformer blocks and\nconsider a specific structured pruning approach, SliceGPT, to extract the\nsubnetworks of different representation dimensions. We mechanistically analyse\nthe activation flow during the model forward passes, and find the\nrepresentation dimension dominates the linear transformations, model\npredictions, and, finally, the model performance. Explicit analytical relations\nare given to calculate the pruned model performance (perplexity and accuracy)\nwithout actual evaluation, and are empirically validated with\nLlama-3-8B-Instruct and Phi-3-mini-4k-Instruct.\n","authors":["Mingxue Xu","Lisa Alazraki","Danilo P. Mandic"],"pdf_url":"https://arxiv.org/pdf/2503.04377v1.pdf","comment":"ICLR 2025 Workshop on Sparsity in LLMs (SLLM)"},{"id":"http://arxiv.org/abs/2502.16532v2","updated":"2025-03-06T12:19:59Z","published":"2025-02-23T10:48:11Z","title":"Deep unrolling for learning optimal spatially varying regularisation\n  parameters for Total Generalised Variation","summary":"  We extend a recently introduced deep unrolling framework for learning\nspatially varying regularisation parameters in inverse imaging problems to the\ncase of Total Generalised Variation (TGV). The framework combines a deep\nconvolutional neural network (CNN) inferring the two spatially varying TGV\nparameters with an unrolled algorithmic scheme that solves the corresponding\nvariational problem. The two subnetworks are jointly trained end-to-end in a\nsupervised fashion and as such the CNN learns to compute those parameters that\ndrive the reconstructed images as close to the ground truth as possible.\nNumerical results in image denoising and MRI reconstruction show a significant\nqualitative and quantitative improvement compared to the best TGV scalar\nparameter case as well as to other approaches employing spatially varying\nparameters computed by unsupervised methods. We also observe that the inferred\nspatially varying parameter maps have a consistent structure near the image\nedges, asking for further theoretical investigations. In particular, the\nparameter that weighs the first-order TGV term has a triple-edge structure with\nalternating high-low-high values whereas the one that weighs the second-order\nterm attains small values in a large neighbourhood around the edges.\n","authors":["Thanh Trung Vu","Andreas Kofler","Kostas Papafitsoros"],"pdf_url":"https://arxiv.org/pdf/2502.16532v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.04370v1","updated":"2025-03-06T12:15:56Z","published":"2025-03-06T12:15:56Z","title":"FILM: Framework for Imbalanced Learning Machines based on a new unbiased\n  performance measure and a new ensemble-based technique","summary":"  This research addresses the challenges of handling unbalanced datasets for\nbinary classification tasks. In such scenarios, standard evaluation metrics are\noften biased by the disproportionate representation of the minority class.\nConducting experiments across seven datasets, we uncovered inconsistencies in\nevaluation metrics when determining the model that outperforms others for each\nbinary classification problem. This justifies the need for a metric that\nprovides a more consistent and unbiased evaluation across unbalanced datasets,\nthereby supporting robust model selection. To mitigate this problem, we propose\na novel metric, the Unbiased Integration Coefficients (UIC), which exhibits\nsignificantly reduced bias ($p < 10^{-4}$) towards the minority class compared\nto conventional metrics. The UIC is constructed by aggregating existing metrics\nwhile penalising those more prone to imbalance. In addition, we introduce the\nIdentical Partitions for Imbalance Problems (IPIP) algorithm for imbalanced ML\nproblems, an ensemble-based approach. Our experimental results show that IPIP\noutperforms other baseline imbalance-aware approaches using Random Forest and\nLogistic Regression models in three out of seven datasets as assessed by the\nUIC metric, demonstrating its effectiveness in addressing imbalanced data\nchallenges in binary classification tasks. This new framework for dealing with\nimbalanced datasets is materialized in the FILM (Framework for Imbalanced\nLearning Machines) R Package, accessible at https://github.com/antoniogt/FILM.\n","authors":["Antonio Guilln-Teruel","Marcos Caracena","Jose A. Pardo","Fernando de-la-Gndara","Jos Palma","Juan A. Bota"],"pdf_url":"https://arxiv.org/pdf/2503.04370v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.01257v2","updated":"2025-03-06T12:13:14Z","published":"2024-10-02T06:05:52Z","title":"HelpSteer2-Preference: Complementing Ratings with Preferences","summary":"  Reward models are critical for aligning models to follow instructions, and\nare typically trained following one of two popular paradigms: Bradley-Terry\nstyle or Regression style. However, there is a lack of evidence that either\napproach is better than the other, when adequately matched for data. This is\nprimarily because these approaches require data collected in different (but\nincompatible) formats, meaning that adequately matched data is not available in\nexisting public datasets. To tackle this problem, we release preference\nannotations (designed for Bradley-Terry training) to complement existing\nratings (designed for Regression style training) in the HelpSteer2 dataset. To\nimprove data interpretability, preference annotations are accompanied with\nhuman-written justifications. Using this data, we conduct the first\nhead-to-head comparison of Bradley-Terry and Regression models when adequately\nmatched for data. Based on insights derived from such a comparison, we propose\na novel approach to combine Bradley-Terry and Regression reward modeling. A\nLlama-3.1-70B-Instruct model tuned with this approach scores 94.1 on\nRewardBench, emerging top of more than 140 reward models as of 1 Oct 2024. This\nreward model can then be used with REINFORCE algorithm (RLHF) to align an\nInstruct model to reach 85.0 on Arena Hard, which is No. 1 as of 1 Oct 2024. We\nopen-source this dataset (CC-BY-4.0 license) at\nhttps://huggingface.co/datasets/nvidia/HelpSteer2#preferences-new -- 1-oct-2024\nand openly release the trained Reward and Instruct models at\nhttps://huggingface.co/nvidia/Llama-3.1-Nemotron-70B-Reward and\nhttps://huggingface.co/nvidia/Llama-3.1-Nemotron-70B-Instruct\n","authors":["Zhilin Wang","Alexander Bukharin","Olivier Delalleau","Daniel Egert","Gerald Shen","Jiaqi Zeng","Oleksii Kuchaiev","Yi Dong"],"pdf_url":"https://arxiv.org/pdf/2410.01257v2.pdf","comment":"Accepted to ICLR 2025; 28 pages, 3 figures"},{"id":"http://arxiv.org/abs/2503.04363v1","updated":"2025-03-06T12:06:54Z","published":"2025-03-06T12:06:54Z","title":"Causally Reliable Concept Bottleneck Models","summary":"  Concept-based models are an emerging paradigm in deep learning that\nconstrains the inference process to operate through human-interpretable\nconcepts, facilitating explainability and human interaction. However, these\narchitectures, on par with popular opaque neural models, fail to account for\nthe true causal mechanisms underlying the target phenomena represented in the\ndata. This hampers their ability to support causal reasoning tasks, limits\nout-of-distribution generalization, and hinders the implementation of fairness\nconstraints. To overcome these issues, we propose \\emph{Causally reliable\nConcept Bottleneck Models} (C$^2$BMs), a class of concept-based architectures\nthat enforce reasoning through a bottleneck of concepts structured according to\na model of the real-world causal mechanisms. We also introduce a pipeline to\nautomatically learn this structure from observational data and\n\\emph{unstructured} background knowledge (e.g., scientific literature).\nExperimental evidence suggest that C$^2$BM are more interpretable, causally\nreliable, and improve responsiveness to interventions w.r.t. standard opaque\nand concept-based models, while maintaining their accuracy.\n","authors":["Giovanni De Felice","Arianna Casanova Flores","Francesco De Santis","Silvia Santini","Johannes Schneider","Pietro Barbiero","Alberto Termine"],"pdf_url":"https://arxiv.org/pdf/2503.04363v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.04362v1","updated":"2025-03-06T12:04:56Z","published":"2025-03-06T12:04:56Z","title":"A Generalist Cross-Domain Molecular Learning Framework for\n  Structure-Based Drug Discovery","summary":"  Structure-based drug discovery (SBDD) is a systematic scientific process that\ndevelops new drugs by leveraging the detailed physical structure of the target\nprotein. Recent advancements in pre-trained models for biomolecules have\ndemonstrated remarkable success across various biochemical applications,\nincluding drug discovery and protein engineering. However, in most approaches,\nthe pre-trained models primarily focus on the characteristics of either small\nmolecules or proteins, without delving into their binding interactions which\nare essential cross-domain relationships pivotal to SBDD. To fill this gap, we\npropose a general-purpose foundation model named BIT (an abbreviation for\nBiomolecular Interaction Transformer), which is capable of encoding a range of\nbiochemical entities, including small molecules, proteins, and protein-ligand\ncomplexes, as well as various data formats, encompassing both 2D and 3D\nstructures. Specifically, we introduce Mixture-of-Domain-Experts (MoDE) to\nhandle the biomolecules from diverse biochemical domains and\nMixture-of-Structure-Experts (MoSE) to capture positional dependencies in the\nmolecular structures. The proposed mixture-of-experts approach enables BIT to\nachieve both deep fusion and domain-specific encoding, effectively capturing\nfine-grained molecular interactions within protein-ligand complexes. Then, we\nperform cross-domain pre-training on the shared Transformer backbone via\nseveral unified self-supervised denoising tasks. Experimental results on\nvarious benchmarks demonstrate that BIT achieves exceptional performance in\ndownstream tasks, including binding affinity prediction, structure-based\nvirtual screening, and molecular property prediction.\n","authors":["Yiheng Zhu","Mingyang Li","Junlong Liu","Kun Fu","Jiansheng Wu","Qiuyi Li","Mingze Yin","Jieping Ye","Jian Wu","Zheng Wang"],"pdf_url":"https://arxiv.org/pdf/2503.04362v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.04358v1","updated":"2025-03-06T12:01:41Z","published":"2025-03-06T12:01:41Z","title":"Learning Causal Response Representations through Direct Effect Analysis","summary":"  We propose a novel approach for learning causal response representations. Our\nmethod aims to extract directions in which a multidimensional outcome is most\ndirectly caused by a treatment variable. By bridging conditional independence\ntesting with causal representation learning, we formulate an optimisation\nproblem that maximises the evidence against conditional independence between\nthe treatment and outcome, given a conditioning set. This formulation employs\nflexible regression models tailored to specific applications, creating a\nversatile framework. The problem is addressed through a generalised eigenvalue\ndecomposition. We show that, under mild assumptions, the distribution of the\nlargest eigenvalue can be bounded by a known $F$-distribution, enabling\ntestable conditional independence. We also provide theoretical guarantees for\nthe optimality of the learned representation in terms of signal-to-noise ratio\nand Fisher information maximisation. Finally, we demonstrate the empirical\neffectiveness of our approach in simulation and real-world experiments. Our\nresults underscore the utility of this framework in uncovering direct causal\neffects within complex, multivariate settings.\n","authors":["Homer Durand","Gherardo Varando","Gustau Camps-Valls"],"pdf_url":"https://arxiv.org/pdf/2503.04358v1.pdf","comment":"32 pages, 15 figures, stat.ML"},{"id":"http://arxiv.org/abs/2503.04357v1","updated":"2025-03-06T12:01:20Z","published":"2025-03-06T12:01:20Z","title":"scDD: Latent Codes Based scRNA-seq Dataset Distillation with Foundation\n  Model Knowledge","summary":"  Single-cell RNA sequencing (scRNA-seq) technology has profiled hundreds of\nmillions of human cells across organs, diseases, development and perturbations\nto date. However, the high-dimensional sparsity, batch effect noise, category\nimbalance, and ever-increasing data scale of the original sequencing data pose\nsignificant challenges for multi-center knowledge transfer, data fusion, and\ncross-validation between scRNA-seq datasets. To address these barriers, (1) we\nfirst propose a latent codes-based scRNA-seq dataset distillation framework\nnamed scDD, which transfers and distills foundation model knowledge and\noriginal dataset information into a compact latent space and generates\nsynthetic scRNA-seq dataset by a generator to replace the original dataset.\nThen, (2) we propose a single-step conditional diffusion generator named SCDG,\nwhich perform single-step gradient back-propagation to help scDD optimize\ndistillation quality and avoid gradient decay caused by multi-step\nback-propagation. Meanwhile, SCDG ensures the scRNA-seq data characteristics\nand inter-class discriminability of the synthetic dataset through flexible\nconditional control and generation quality assurance. Finally, we propose a\ncomprehensive benchmark to evaluate the performance of scRNA-seq dataset\ndistillation in different data analysis tasks. It is validated that our\nproposed method can achieve 7.61% absolute and 15.70% relative improvement over\nprevious state-of-the-art methods on average task.\n","authors":["Zhen Yu","Jianan Han","Yang Liu","Qingchao Chen"],"pdf_url":"https://arxiv.org/pdf/2503.04357v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.04350v1","updated":"2025-03-06T11:46:07Z","published":"2025-03-06T11:46:07Z","title":"EDCA -- An Evolutionary Data-Centric AutoML Framework for Efficient\n  Pipelines","summary":"  Automated Machine Learning (AutoML) gained popularity due to the increased\ndemand for Machine Learning (ML) specialists, allowing them to apply ML\ntechniques effortlessly and quickly. AutoML implementations use optimisation\nmethods to identify the most effective ML solution for a given dataset, aiming\nto improve one or more predefined metrics. However, most implementations focus\non model selection and hyperparameter tuning. Despite being an important factor\nin obtaining high-performance ML systems, data quality is usually an overlooked\npart of AutoML and continues to be a manual and time-consuming task. This work\npresents EDCA, an Evolutionary Data Centric AutoML framework. In addition to\nthe traditional tasks such as selecting the best models and hyperparameters,\nEDCA enhances the given data by optimising data processing tasks such as data\nreduction and cleaning according to the problems' needs. All these steps create\nan ML pipeline that is optimised by an evolutionary algorithm. To assess its\neffectiveness, EDCA was compared to FLAML and TPOT, two frameworks at the top\nof the AutoML benchmarks. The frameworks were evaluated in the same conditions\nusing datasets from AMLB classification benchmarks. EDCA achieved statistically\nsimilar results in performance to FLAML and TPOT but used significantly less\ndata to train the final solutions. Moreover, EDCA experimental results reveal\nthat a good performance can be achieved using less data and efficient ML\nalgorithm aspects that align with Green AutoML guidelines\n","authors":["Joana Simes","Joo Correia"],"pdf_url":"https://arxiv.org/pdf/2503.04350v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.04347v1","updated":"2025-03-06T11:43:30Z","published":"2025-03-06T11:43:30Z","title":"Large Language Models for Zero-shot Inference of Causal Structures in\n  Biology","summary":"  Genes, proteins and other biological entities influence one another via\ncausal molecular networks. Causal relationships in such networks are mediated\nby complex and diverse mechanisms, through latent variables, and are often\nspecific to cellular context. It remains challenging to characterise such\nnetworks in practice. Here, we present a novel framework to evaluate large\nlanguage models (LLMs) for zero-shot inference of causal relationships in\nbiology. In particular, we systematically evaluate causal claims obtained from\nan LLM using real-world interventional data. This is done over one hundred\nvariables and thousands of causal hypotheses. Furthermore, we consider several\nprompting and retrieval-augmentation strategies, including large, and\npotentially conflicting, collections of scientific articles. Our results show\nthat with tailored augmentation and prompting, even relatively small LLMs can\ncapture meaningful aspects of causal structure in biological systems. This\nsupports the notion that LLMs could act as orchestration tools in biological\ndiscovery, by helping to distil current knowledge in ways amenable to\ndownstream analysis. Our approach to assessing LLMs with respect to\nexperimental data is relevant for a broad range of problems at the intersection\nof causal learning, LLMs and scientific discovery.\n","authors":["Izzy Newsham","Luka Kovaevi","Richard Moulange","Nan Rosemary Ke","Sach Mukherjee"],"pdf_url":"https://arxiv.org/pdf/2503.04347v1.pdf","comment":"ICLR 2025 Workshop on Machine Learning for Genomics Explorations"},{"id":"http://arxiv.org/abs/2503.04342v1","updated":"2025-03-06T11:39:07Z","published":"2025-03-06T11:39:07Z","title":"TRANSIT your events into a new mass: Fast background interpolation for\n  weakly-supervised anomaly searches","summary":"  We introduce a new model for conditional and continuous data morphing called\nTRansport Adversarial Network for Smooth InTerpolation (TRANSIT). We apply it\nto create a background data template for weakly-supervised searches at the LHC.\nThe method smoothly transforms sideband events to match signal region mass\ndistributions. We demonstrate the performance of TRANSIT using the LHC Olympics\nR\\&D dataset. The model captures non-linear mass correlations of features and\nproduces a template that offers a competitive anomaly sensitivity compared to\nstate-of-the-art transport-based template generators. Moreover, the\ncomputational training time required for TRANSIT is an order of magnitude lower\nthan that of competing deep learning methods. This makes it ideal for analyses\nthat iterate over many signal regions and signal models. Unlike generative\nmodels, which must learn a full probability density distribution, i.e., the\ncorrelations between all the variables, the proposed transport model only has\nto learn a smooth conditional shift of the distribution. This allows for a\nsimpler, more efficient residual architecture, enabling mass uncorrelated\nfeatures to pass the network unchanged while the mass correlated features are\nadjusted accordingly. Furthermore, we show that the latent space of the model\nprovides a set of mass decorrelated features useful for anomaly detection\nwithout background sculpting.\n","authors":["Ivan Oleksiyuk","Svyatoslav Voloshynovskiy","Tobias Golling"],"pdf_url":"https://arxiv.org/pdf/2503.04342v1.pdf","comment":"34 pages, 14 figures"},{"id":"http://arxiv.org/abs/2401.13898v2","updated":"2025-03-06T11:38:00Z","published":"2024-01-25T02:25:23Z","title":"Cross-Modal Prototype based Multimodal Federated Learning under Severely\n  Missing Modality","summary":"  Multimodal federated learning (MFL) has emerged as a decentralized machine\nlearning paradigm, allowing multiple clients with different modalities to\ncollaborate on training a global model across diverse data sources without\nsharing their private data. However, challenges, such as data heterogeneity and\nseverely missing modalities, pose crucial hindrances to the robustness of MFL,\nsignificantly impacting the performance of global model. The occurrence of\nmissing modalities in real-world applications, such as autonomous driving,\noften arises from factors like sensor failures, leading knowledge gaps during\nthe training process. Specifically, the absence of a modality introduces\nmisalignment during the local training phase, stemming from zero-filling in the\ncase of clients with missing modalities. Consequently, achieving robust\ngeneralization in global model becomes imperative, especially when dealing with\nclients that have incomplete data. In this paper, we propose\n$\\textbf{Multimodal Federated Cross Prototype Learning (MFCPL)}$, a novel\napproach for MFL under severely missing modalities. Our MFCPL leverages the\ncomplete prototypes to provide diverse modality knowledge in modality-shared\nlevel with the cross-modal regularization and modality-specific level with\ncross-modal contrastive mechanism. Additionally, our approach introduces the\ncross-modal alignment to provide regularization for modality-specific features,\nthereby enhancing the overall performance, particularly in scenarios involving\nseverely missing modalities. Through extensive experiments on three multimodal\ndatasets, we demonstrate the effectiveness of MFCPL in mitigating the\nchallenges of data heterogeneity and severely missing modalities while\nimproving the overall performance and robustness of MFL.\n","authors":["Huy Q. Le","Chu Myaet Thwal","Yu Qiao","Ye Lin Tun","Minh N. H. Nguyen","Eui-Nam Huh","Choong Seon Hong"],"pdf_url":"https://arxiv.org/pdf/2401.13898v2.pdf","comment":"14 pages, 8 figures, 11 tables"},{"id":"http://arxiv.org/abs/2401.12113v2","updated":"2025-03-06T11:33:28Z","published":"2024-01-22T16:51:01Z","title":"Extracting Formulae in Many-Valued Logic from Deep Neural Networks","summary":"  We propose a new perspective on deep ReLU networks, namely as circuit\ncounterparts of Lukasiewicz infinite-valued logic -- a many-valued (MV)\ngeneralization of Boolean logic. An algorithm for extracting formulae in MV\nlogic from deep ReLU networks is presented. As the algorithm applies to\nnetworks with general, in particular also real-valued, weights, it can be used\nto extract logical formulae from deep ReLU networks trained on data.\n","authors":["Yani Zhang","Helmut Blcskei"],"pdf_url":"https://arxiv.org/pdf/2401.12113v2.pdf","comment":"Signicant extension of the previous version"},{"id":"http://arxiv.org/abs/2503.04332v1","updated":"2025-03-06T11:30:32Z","published":"2025-03-06T11:30:32Z","title":"The Challenge of Identifying the Origin of Black-Box Large Language\n  Models","summary":"  The tremendous commercial potential of large language models (LLMs) has\nheightened concerns about their unauthorized use. Third parties can customize\nLLMs through fine-tuning and offer only black-box API access, effectively\nconcealing unauthorized usage and complicating external auditing processes.\nThis practice not only exacerbates unfair competition, but also violates\nlicensing agreements. In response, identifying the origin of black-box LLMs is\nan intrinsic solution to this issue. In this paper, we first reveal the\nlimitations of state-of-the-art passive and proactive identification methods\nwith experiments on 30 LLMs and two real-world black-box APIs. Then, we propose\nthe proactive technique, PlugAE, which optimizes adversarial token embeddings\nin a continuous space and proactively plugs them into the LLM for tracing and\nidentification. The experiments show that PlugAE can achieve substantial\nimprovement in identifying fine-tuned derivatives. We further advocate for\nlegal frameworks and regulations to better address the challenges posed by the\nunauthorized use of LLMs.\n","authors":["Ziqing Yang","Yixin Wu","Yun Shen","Wei Dai","Michael Backes","Yang Zhang"],"pdf_url":"https://arxiv.org/pdf/2503.04332v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2404.00390v2","updated":"2025-03-06T11:21:39Z","published":"2024-03-30T15:03:52Z","title":"Learning truly monotone operators with applications to nonlinear inverse\n  problems","summary":"  This article introduces a novel approach to learning monotone neural networks\nthrough a newly defined penalization loss. The proposed method is particularly\neffective in solving classes of variational problems, specifically monotone\ninclusion problems, commonly encountered in image processing tasks. The\nForward-Backward-Forward (FBF) algorithm is employed to address these problems,\noffering a solution even when the Lipschitz constant of the neural network is\nunknown. Notably, the FBF algorithm provides convergence guarantees under the\ncondition that the learned operator is monotone. Building on plug-and-play\nmethodologies, our objective is to apply these newly learned operators to\nsolving non-linear inverse problems. To achieve this, we initially formulate\nthe problem as a variational inclusion problem. Subsequently, we train a\nmonotone neural network to approximate an operator that may not inherently be\nmonotone. Leveraging the FBF algorithm, we then show simulation examples where\nthe non-linear inverse problem is successfully solved.\n","authors":["Younes Belkouchi","Jean-Christophe Pesquet","Audrey Repetti","Hugues Talbot"],"pdf_url":"https://arxiv.org/pdf/2404.00390v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2406.05714v4","updated":"2025-03-06T11:20:32Z","published":"2024-06-09T10:12:08Z","title":"A conversion theorem and minimax optimality for continuum contextual\n  bandits","summary":"  We study the contextual continuum bandits problem, where the learner\nsequentially receives a side information vector and has to choose an action in\na convex set, minimizing a function associated with the context. The goal is to\nminimize all the underlying functions for the received contexts, leading to the\ncontextual notion of regret, which is stronger than the standard static regret.\nAssuming that the objective functions are $\\gamma$-H\\\"older with respect to the\ncontexts, $0<\\gamma\\le 1,$ we demonstrate that any algorithm achieving a\nsub-linear static regret can be extended to achieve a sub-linear contextual\nregret. We prove a static-to-contextual regret conversion theorem that provides\nan upper bound for the contextual regret of the output algorithm as a function\nof the static regret of the input algorithm. We further study the implications\nof this general result for three fundamental cases of dependency of the\nobjective function on the action variable: (a) Lipschitz bandits, (b) convex\nbandits, (c) strongly convex and smooth bandits. For Lipschitz bandits and\n$\\gamma=1,$ combining our results with the lower bound of Slivkins (2014), we\nprove that the minimax optimal contextual regret for the noise-free adversarial\nsetting is achieved. Then, we prove that in the presence of noise, the\ncontextual regret rate as a function of the number of queries is the same for\nconvex bandits as it is for strongly convex and smooth bandits. Lastly, we\npresent a minimax lower bound, implying two key facts. First, obtaining a\nsub-linear contextual regret may be impossible over functions that are not\ncontinuous with respect to the context. Second, for convex bandits and strongly\nconvex and smooth bandits, the algorithms that we propose achieve, up to a\nlogarithmic factor, the minimax optimal rate of contextual regret as a function\nof the number of queries.\n","authors":["Arya Akhavan","Karim Lounici","Massimiliano Pontil","Alexandre B. Tsybakov"],"pdf_url":"https://arxiv.org/pdf/2406.05714v4.pdf","comment":null},{"id":"http://arxiv.org/abs/2501.17634v2","updated":"2025-03-06T11:17:31Z","published":"2025-01-29T13:11:21Z","title":"Federated Learning With Individualized Privacy Through Client Sampling","summary":"  With growing concerns about user data collection, individualized privacy has\nemerged as a promising solution to balance protection and utility by accounting\nfor diverse user privacy preferences. Instead of enforcing a uniform level of\nanonymization for all users, this approach allows individuals to choose privacy\nsettings that align with their comfort levels. Building on this idea, we\npropose an adapted method for enabling Individualized Differential Privacy\n(IDP) in Federated Learning (FL) by handling clients according to their\npersonal privacy preferences. By extending the SAMPLE algorithm from\ncentralized settings to FL, we calculate client-specific sampling rates based\non their heterogeneous privacy budgets and integrate them into a modified\nIDP-FedAvg algorithm. We test this method under realistic privacy distributions\nand multiple datasets. The experimental results demonstrate that our approach\nachieves clear improvements over uniform DP baselines, reducing the trade-off\nbetween privacy and utility. Compared to the alternative SCALE method in\nrelated work, which assigns differing noise scales to clients, our method\nperforms notably better. However, challenges remain for complex tasks with\nnon-i.i.d. data, primarily stemming from the constraints of the decentralized\nsetting.\n","authors":["Lucas Lange","Ole Borchardt","Erhard Rahm"],"pdf_url":"https://arxiv.org/pdf/2501.17634v2.pdf","comment":"Accepted at 10th International Conference on Machine Learning\n  Technologies (ICMLT 2025)"},{"id":"http://arxiv.org/abs/2402.03448v4","updated":"2025-03-06T11:07:54Z","published":"2024-02-05T19:02:19Z","title":"Decentralized Sporadic Federated Learning: A Unified Algorithmic\n  Framework with Convergence Guarantees","summary":"  Decentralized federated learning (DFL) captures FL settings where both (i)\nmodel updates and (ii) model aggregations are exclusively carried out by the\nclients without a central server. Existing DFL works have mostly focused on\nsettings where clients conduct a fixed number of local updates between local\nmodel exchanges, overlooking heterogeneity and dynamics in communication and\ncomputation capabilities. In this work, we propose Decentralized Sporadic\nFederated Learning ($\\texttt{DSpodFL}$), a DFL methodology built on a\ngeneralized notion of $\\textit{sporadicity}$ in both local gradient and\naggregation processes. $\\texttt{DSpodFL}$ subsumes many existing decentralized\noptimization methods under a unified algorithmic framework by modeling the\nper-iteration (i) occurrence of gradient descent at each client and (ii)\nexchange of models between client pairs as arbitrary indicator random\nvariables, thus capturing $\\textit{heterogeneous and time-varying}$\ncomputation/communication scenarios. We analytically characterize the\nconvergence behavior of $\\texttt{DSpodFL}$ for both convex and non-convex\nmodels and for both constant and diminishing learning rates, under mild\nassumptions on the communication graph connectivity, data heterogeneity across\nclients, and gradient noises. We show how our bounds recover existing results\nfrom decentralized gradient descent as special cases. Experiments demonstrate\nthat $\\texttt{DSpodFL}$ consistently achieves improved training speeds compared\nwith baselines under various system settings.\n","authors":["Shahryar Zehtabi","Dong-Jun Han","Rohit Parasnis","Seyyedali Hosseinalipour","Christopher G. Brinton"],"pdf_url":"https://arxiv.org/pdf/2402.03448v4.pdf","comment":null},{"id":"http://arxiv.org/abs/2502.15109v2","updated":"2025-03-06T11:07:48Z","published":"2025-02-21T00:05:40Z","title":"Social Genome: Grounded Social Reasoning Abilities of Multimodal Models","summary":"  Social reasoning abilities are crucial for AI systems to effectively\ninterpret and respond to multimodal human communication and interaction within\nsocial contexts. We introduce Social Genome, the first benchmark for\nfine-grained, grounded social reasoning abilities of multimodal models. Social\nGenome contains 272 videos of interactions and 1,486 human-annotated reasoning\ntraces related to inferences about these interactions. These traces contain\n5,777 reasoning steps that reference evidence from visual cues, verbal cues,\nvocal cues, and external knowledge (contextual knowledge external to videos).\nSocial Genome is also the first modeling challenge to study external knowledge\nin social reasoning. Social Genome computes metrics to holistically evaluate\nsemantic and structural qualities of model-generated social reasoning traces.\nWe demonstrate the utility of Social Genome through experiments with\nstate-of-the-art models, identifying performance gaps and opportunities for\nfuture research to improve the grounded social reasoning abilities of\nmultimodal models.\n","authors":["Leena Mathur","Marian Qian","Paul Pu Liang","Louis-Philippe Morency"],"pdf_url":"https://arxiv.org/pdf/2502.15109v2.pdf","comment":"Under Review, 22 pages"},{"id":"http://arxiv.org/abs/2402.01879v3","updated":"2025-03-06T11:05:33Z","published":"2024-02-02T20:08:11Z","title":"$$-zero: Gradient-based Optimization of $\\ell_0$-norm Adversarial\n  Examples","summary":"  Evaluating the adversarial robustness of deep networks to gradient-based\nattacks is challenging. While most attacks consider $\\ell_2$- and\n$\\ell_\\infty$-norm constraints to craft input perturbations, only a few\ninvestigate sparse $\\ell_1$- and $\\ell_0$-norm attacks. In particular,\n$\\ell_0$-norm attacks remain the least studied due to the inherent complexity\nof optimizing over a non-convex and non-differentiable constraint. However,\nevaluating adversarial robustness under these attacks could reveal weaknesses\notherwise left untested with more conventional $\\ell_2$- and $\\ell_\\infty$-norm\nattacks. In this work, we propose a novel $\\ell_0$-norm attack, called\n$\\sigma$-zero, which leverages a differentiable approximation of the $\\ell_0$\nnorm to facilitate gradient-based optimization, and an adaptive projection\noperator to dynamically adjust the trade-off between loss minimization and\nperturbation sparsity. Extensive evaluations using MNIST, CIFAR10, and ImageNet\ndatasets, involving robust and non-robust models, show that\n$\\sigma$\\texttt{-zero} finds minimum $\\ell_0$-norm adversarial examples without\nrequiring any time-consuming hyperparameter tuning, and that it outperforms all\ncompeting sparse attacks in terms of success rate, perturbation size, and\nefficiency.\n","authors":["Antonio Emanuele Cin","Francesco Villani","Maura Pintor","Lea Schnherr","Battista Biggio","Marcello Pelillo"],"pdf_url":"https://arxiv.org/pdf/2402.01879v3.pdf","comment":"Paper accepted at International Conference on Learning\n  Representations (ICLR 2025). Code available at\n  https://github.com/sigma0-advx/sigma-zero"},{"id":"http://arxiv.org/abs/2412.00156v3","updated":"2025-03-06T11:05:32Z","published":"2024-11-29T08:10:49Z","title":"VISION-XL: High Definition Video Inverse Problem Solver using Latent\n  Image Diffusion Models","summary":"  In this paper, we propose a novel framework for solving high-definition video\ninverse problems using latent image diffusion models. Building on recent\nadvancements in spatio-temporal optimization for video inverse problems using\nimage diffusion models, our approach leverages latent-space diffusion models to\nachieve enhanced video quality and resolution. To address the high\ncomputational demands of processing high-resolution frames, we introduce a\npseudo-batch consistent sampling strategy, allowing efficient operation on a\nsingle GPU. Additionally, to improve temporal consistency, we present\npseudo-batch inversion, an initialization technique that incorporates\ninformative latents from the measurement. By integrating with SDXL, our\nframework achieves state-of-the-art video reconstruction across a wide range of\nspatio-temporal inverse problems, including complex combinations of frame\naveraging and various spatial degradations, such as deblurring,\nsuper-resolution, and inpainting. Unlike previous methods, our approach\nsupports multiple aspect ratios (landscape, vertical, and square) and delivers\nHD-resolution reconstructions (exceeding 1280x720) in under 6 seconds per frame\non a single NVIDIA 4090 GPU.\n","authors":["Taesung Kwon","Jong Chul Ye"],"pdf_url":"https://arxiv.org/pdf/2412.00156v3.pdf","comment":"Project page: https://vision-xl.github.io/"},{"id":"http://arxiv.org/abs/2501.10814v2","updated":"2025-03-06T11:05:23Z","published":"2025-01-18T16:23:09Z","title":"No More Sliding Window: Efficient 3D Medical Image Segmentation with\n  Differentiable Top-k Patch Sampling","summary":"  3D models surpass 2D models in CT/MRI segmentation by effectively capturing\ninter-slice relationships. However, the added depth dimension substantially\nincreases memory consumption. While patch-based training alleviates memory\nconstraints, it significantly slows down the inference speed due to the sliding\nwindow (SW) approach. We propose No-More-Sliding-Window (NMSW), a novel\nend-to-end trainable framework that enhances the efficiency of generic 3D\nsegmentation backbone during an inference step by eliminating the need for SW.\nNMSW employs a differentiable Top-k module to selectively sample only the most\nrelevant patches, thereby minimizing redundant computations. When patch-level\npredictions are insufficient, the framework intelligently leverages coarse\nglobal predictions to refine results. Evaluated across 3 tasks using 3\nsegmentation backbones, NMSW achieves competitive accuracy compared to SW\ninference while significantly reducing computational complexity by 91% (88.0 to\n8.00 TMACs). Moreover, it delivers a 9.1x faster inference on the H100 GPU\n(99.0 to 8.3 sec) and a 11.1x faster inference on the Xeon Gold CPU (2110 to\n189 sec). NMSW is model-agnostic, further boosting efficiency when integrated\nwith any existing efficient segmentation backbones.\n","authors":["Young Seok Jeon","Hongfei Yang","Huazhu Fu","Mengling Feng"],"pdf_url":"https://arxiv.org/pdf/2501.10814v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.04318v1","updated":"2025-03-06T11:00:18Z","published":"2025-03-06T11:00:18Z","title":"InFL-UX: A Toolkit for Web-Based Interactive Federated Learning","summary":"  This paper presents InFL-UX, an interactive, proof-of-concept browser-based\nFederated Learning (FL) toolkit designed to integrate user contributions\nseamlessly into the machine learning (ML) workflow. InFL-UX enables users\nacross multiple devices to upload datasets, define classes, and collaboratively\ntrain classification models directly in the browser using modern web\ntechnologies. Unlike traditional FL toolkits, which often focus on backend\nsimulations, InFL-UX provides a simple user interface for researchers to\nexplore how users interact with and contribute to FL systems in real-world,\ninteractive settings. By prioritising usability and decentralised model\ntraining, InFL-UX bridges the gap between FL and Interactive Machine Learning\n(IML), empowering non-technical users to actively participate in ML\nclassification tasks.\n","authors":["Tim Maurer","Abdulrahman Mohamed Selim","Hasan Md Tusfiqur Alam","Matthias Eiletz","Michael Barz","Daniel Sonntag"],"pdf_url":"https://arxiv.org/pdf/2503.04318v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.04315v1","updated":"2025-03-06T10:58:35Z","published":"2025-03-06T10:58:35Z","title":"Provable Robust Overfitting Mitigation in Wasserstein Distributionally\n  Robust Optimization","summary":"  Wasserstein distributionally robust optimization (WDRO) optimizes against\nworst-case distributional shifts within a specified uncertainty set, leading to\nenhanced generalization on unseen adversarial examples, compared to standard\nadversarial training which focuses on pointwise adversarial perturbations.\nHowever, WDRO still suffers fundamentally from the robust overfitting problem,\nas it does not consider statistical error. We address this gap by proposing a\nnovel robust optimization framework under a new uncertainty set for adversarial\nnoise via Wasserstein distance and statistical error via Kullback-Leibler\ndivergence, called the Statistically Robust WDRO. We establish a robust\ngeneralization bound for the new optimization framework, implying that\nout-of-distribution adversarial performance is at least as good as the\nstatistically robust training loss with high probability. Furthermore, we\nderive conditions under which Stackelberg and Nash equilibria exist between the\nlearner and the adversary, giving an optimal robust model in certain sense.\nFinally, through extensive experiments, we demonstrate that our method\nsignificantly mitigates robust overfitting and enhances robustness within the\nframework of WDRO.\n","authors":["Shuang Liu","Yihan Wang","Yifan Zhu","Yibo Miao","Xiao-Shan Gao"],"pdf_url":"https://arxiv.org/pdf/2503.04315v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2501.13794v2","updated":"2025-03-06T10:49:24Z","published":"2025-01-23T16:13:08Z","title":"Unveiling the Power of Noise Priors: Enhancing Diffusion Models for\n  Mobile Traffic Prediction","summary":"  Accurate prediction of mobile traffic, \\textit{i.e.,} network traffic from\ncellular base stations, is crucial for optimizing network performance and\nsupporting urban development. However, the non-stationary nature of mobile\ntraffic, driven by human activity and environmental changes, leads to both\nregular patterns and abrupt variations. Diffusion models excel in capturing\nsuch complex temporal dynamics due to their ability to capture the inherent\nuncertainties. Most existing approaches prioritize designing novel denoising\nnetworks but often neglect the critical role of noise itself, potentially\nleading to sub-optimal performance. In this paper, we introduce a novel\nperspective by emphasizing the role of noise in the denoising process. Our\nanalysis reveals that noise fundamentally shapes mobile traffic predictions,\nexhibiting distinct and consistent patterns. We propose NPDiff, a framework\nthat decomposes noise into \\textit{prior} and \\textit{residual} components,\nwith the \\textit{prior} derived from data dynamics, enhancing the model's\nability to capture both regular and abrupt variations. NPDiff can seamlessly\nintegrate with various diffusion-based prediction models, delivering\npredictions that are effective, efficient, and robust. Extensive experiments\ndemonstrate that it achieves superior performance with an improvement over\n30\\%, offering a new perspective on leveraging diffusion models in this domain.\n","authors":["Zhi Sheng","Yuan Yuan","Jingtao Ding","Yong Li"],"pdf_url":"https://arxiv.org/pdf/2501.13794v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2406.18380v4","updated":"2025-03-06T10:25:17Z","published":"2024-06-26T14:21:21Z","title":"KAGNNs: Kolmogorov-Arnold Networks meet Graph Learning","summary":"  In recent years, Graph Neural Networks (GNNs) have become the de facto tool\nfor learning node and graph representations. Most GNNs typically consist of a\nsequence of neighborhood aggregation (a.k.a., message-passing) layers, within\nwhich the representation of each node is updated based on those of its\nneighbors. The most expressive message-passing GNNs can be obtained through the\nuse of the sum aggregator and of MLPs for feature transformation, thanks to\ntheir universal approximation capabilities. However, the limitations of MLPs\nrecently motivated the introduction of another family of universal\napproximators, called Kolmogorov-Arnold Networks (KANs) which rely on a\ndifferent representation theorem. In this work, we compare the performance of\nKANs against that of MLPs on graph learning tasks. We implement three new\nKAN-based GNN layers, inspired respectively by the GCN, GAT and GIN layers. We\nevaluate two different implementations of KANs using two distinct base families\nof functions, namely B-splines and radial basis functions. We perform extensive\nexperiments on node classification, link prediction, graph classification and\ngraph regression datasets. Our results indicate that KANs are on-par with or\nbetter than MLPs on all tasks studied in this paper. We also show that the size\nand training speed of RBF-based KANs is only marginally higher than for MLPs,\nmaking them viable alternatives. Code available at\nhttps://github.com/RomanBresson/KAGNN.\n","authors":["Roman Bresson","Giannis Nikolentzos","George Panagopoulos","Michail Chatzianastasis","Jun Pang","Michalis Vazirgiannis"],"pdf_url":"https://arxiv.org/pdf/2406.18380v4.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.16935v2","updated":"2025-03-06T10:10:06Z","published":"2024-10-22T12:12:43Z","title":"Graph Neural Networks for Edge Signals: Orientation Equivariance and\n  Invariance","summary":"  Many applications in traffic, civil engineering, or electrical engineering\nrevolve around edge-level signals. Such signals can be categorized as\ninherently directed, for example, the water flow in a pipe network, and\nundirected, like the diameter of a pipe. Topological methods model edge signals\nwith inherent direction by representing them relative to a so-called\norientation assigned to each edge. These approaches can neither model\nundirected edge signals nor distinguish if an edge itself is directed or\nundirected. We address these shortcomings by (i) revising the notion of\norientation equivariance to enable edge direction-aware topological models,\n(ii) proposing orientation invariance as an additional requirement to describe\nsignals without inherent direction, and (iii) developing EIGN, an architecture\ncomposed of novel direction-aware edge-level graph shift operators, that\nprovably fulfills the aforementioned desiderata. It is the first\ngeneral-purpose topological GNN for edge-level signals that can model directed\nand undirected signals while distinguishing between directed and undirected\nedges. A comprehensive evaluation shows that EIGN outperforms prior work in\nedge-level tasks, for example, improving in RMSE on flow simulation tasks by up\nto 23.5%.\n","authors":["Dominik Fuchsgruber","Tim Potuvan","Stephan Gnnemann","Simon Geisler"],"pdf_url":"https://arxiv.org/pdf/2410.16935v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.04283v1","updated":"2025-03-06T10:09:20Z","published":"2025-03-06T10:09:20Z","title":"Explainable AI in Time-Sensitive Scenarios: Prefetched Offline\n  Explanation Model","summary":"  As predictive machine learning models become increasingly adopted and\nadvanced, their role has evolved from merely predicting outcomes to actively\nshaping them. This evolution has underscored the importance of Trustworthy AI,\nhighlighting the necessity to extend our focus beyond mere accuracy and toward\na comprehensive understanding of these models' behaviors within the specific\ncontexts of their applications. To further progress in explainability, we\nintroduce Poem, Prefetched Offline Explanation Model, a model-agnostic, local\nexplainability algorithm for image data. The algorithm generates exemplars,\ncounterexemplars and saliency maps to provide quick and effective explanations\nsuitable for time-sensitive scenarios. Leveraging an existing local algorithm,\n\\poem{} infers factual and counterfactual rules from data to create\nillustrative examples and opposite scenarios with an enhanced stability by\ndesign. A novel mechanism then matches incoming test points with an explanation\nbase and produces diverse exemplars, informative saliency maps and believable\ncounterexemplars. Experimental results indicate that Poem outperforms its\npredecessor Abele in speed and ability to generate more nuanced and varied\nexemplars alongside more insightful saliency maps and valuable\ncounterexemplars.\n","authors":["Fabio Michele Russo","Carlo Metta","Anna Monreale","Salvatore Rinzivillo","Fabio Pinelli"],"pdf_url":"https://arxiv.org/pdf/2503.04283v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.04280v1","updated":"2025-03-06T10:08:44Z","published":"2025-03-06T10:08:44Z","title":"Towards Autonomous Reinforcement Learning for Real-World Robotic\n  Manipulation with Large Language Models","summary":"  Recent advancements in Large Language Models (LLMs) and Visual Language\nModels (VLMs) have significantly impacted robotics, enabling high-level\nsemantic motion planning applications. Reinforcement Learning (RL), a\ncomplementary paradigm, enables agents to autonomously optimize complex\nbehaviors through interaction and reward signals. However, designing effective\nreward functions for RL remains challenging, especially in real-world tasks\nwhere sparse rewards are insufficient and dense rewards require elaborate\ndesign. In this work, we propose Autonomous Reinforcement learning for Complex\nHumanInformed Environments (ARCHIE), an unsupervised pipeline leveraging GPT-4,\na pre-trained LLM, to generate reward functions directly from natural language\ntask descriptions. The rewards are used to train RL agents in simulated\nenvironments, where we formalize the reward generation process to enhance\nfeasibility. Additionally, GPT-4 automates the coding of task success criteria,\ncreating a fully automated, one-shot procedure for translating human-readable\ntext into deployable robot skills. Our approach is validated through extensive\nsimulated experiments on single-arm and bi-manual manipulation tasks using an\nABB YuMi collaborative robot, highlighting its practicality and effectiveness.\nTasks are demonstrated on the real robot setup.\n","authors":["Niccol Turcato","Matteo Iovino","Aris Synodinos","Alberto Dalla Libera","Ruggero Carli","Pietro Falco"],"pdf_url":"https://arxiv.org/pdf/2503.04280v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.04278v1","updated":"2025-03-06T10:07:17Z","published":"2025-03-06T10:07:17Z","title":"A General Framework for Scalable UE-AP Association in User-Centric\n  Cell-Free Massive MIMO based on Recurrent Neural Networks","summary":"  This study addresses the challenge of access point (AP) and user equipment\n(UE) association in cell-free massive MIMO networks. It introduces a deep\nlearning algorithm leveraging Bidirectional Long Short-Term Memory cells and a\nhybrid probabilistic methodology for weight updating. This approach enhances\nscalability by adapting to variations in the number of UEs without requiring\nretraining. Additionally, the study presents a training methodology that\nimproves scalability not only with respect to the number of UEs but also to the\nnumber of APs. Furthermore, a variant of the proposed AP-UE algorithm ensures\nrobustness against pilot contamination effects, a critical issue arising from\npilot reuse in channel estimation. Extensive numerical results validate the\neffectiveness and adaptability of the proposed methods, demonstrating their\nsuperiority over widely used heuristic alternatives.\n","authors":["Giovanni Di Gennaro","Amedeo Buonanno","Gianmarco Romano","Stefano Buzzi","Francesco A. N. Palmieri"],"pdf_url":"https://arxiv.org/pdf/2503.04278v1.pdf","comment":"submitted to IEEE journal"},{"id":"http://arxiv.org/abs/2405.14736v2","updated":"2025-03-06T09:52:43Z","published":"2024-05-23T16:02:30Z","title":"GIFT: Unlocking Full Potential of Labels in Distilled Dataset at\n  Near-zero Cost","summary":"  Recent advancements in dataset distillation have demonstrated the significant\nbenefits of employing soft labels generated by pre-trained teacher models. In\nthis paper, we introduce a novel perspective by emphasizing the full\nutilization of labels. We first conduct a comprehensive comparison of various\nloss functions for soft label utilization in dataset distillation, revealing\nthat the model trained on the synthetic dataset exhibits high sensitivity to\nthe choice of loss function for soft label utilization. This finding highlights\nthe necessity of a universal loss function for training models on synthetic\ndatasets. Building on these insights, we introduce an extremely simple yet\nsurprisingly effective plug-and-play approach, GIFT, which encompasses soft\nlabel refinement and a cosine similarity-based loss function to efficiently\nleverage full label information. Extensive experiments indicate that GIFT\nconsistently enhances state-of-the-art dataset distillation methods across\nvarious dataset scales, without incurring additional computational costs.\nImportantly, GIFT significantly enhances cross-optimizer generalization, an\narea previously overlooked. For instance, on ImageNet-1K with IPC = 10, GIFT\nenhances the state-of-the-art method RDED by 30.8% in cross-optimizer\ngeneralization. Our code is available at https://github.com/LINs-lab/GIFT.\n","authors":["Xinyi Shang","Peng Sun","Tao Lin"],"pdf_url":"https://arxiv.org/pdf/2405.14736v2.pdf","comment":"https://github.com/LINs-lab/GIFT"},{"id":"http://arxiv.org/abs/2503.04266v1","updated":"2025-03-06T09:50:43Z","published":"2025-03-06T09:50:43Z","title":"Frequency Hopping Synchronization by Reinforcement Learning for\n  Satellite Communication System","summary":"  Satellite communication systems (SCSs) used for tactical purposes require\nrobust security and anti-jamming capabilities, making frequency hopping (FH) a\npowerful option. However, the current FH systems face challenges due to\nsignificant interference from other devices and the considerable path loss\ninherent in satellite communication. This misalignment leads to inefficient\nsynchronization, crucial for maintaining reliable communication. Traditional\nmethods, such as those employing long short-term memory (LSTM) networks, have\nmade improvements, but they still struggle in dynamic conditions of satellite\nenvironments. This paper presents a novel method for synchronizing FH signals\nin tactical SCSs by combining serial search and reinforcement learning to\nachieve coarse and fine acquisition, respectively. The mathematical analysis\nand simulation results demonstrate that the proposed method reduces the average\nnumber of hops required for synchronization by 58.17% and mean squared error\n(MSE) of the uplink hop timing estimation by 76.95%, as compared to the\nconventional serial search method. Comparing with the early late gate\nsynchronization method based on serial search and use of LSTM network, the\naverage number of hops for synchronization is reduced by 12.24% and the MSE by\n18.5%.\n","authors":["Inkyu Kim","Sangkeum Lee","Haechan Jeong","Sarvar Hussain Nengroo","Dongsoo Har"],"pdf_url":"https://arxiv.org/pdf/2503.04266v1.pdf","comment":"18pages, 5figures"},{"id":"http://arxiv.org/abs/2503.04263v1","updated":"2025-03-06T09:47:41Z","published":"2025-03-06T09:47:41Z","title":"Bi-Lipschitz Ansatz for Anti-Symmetric Functions","summary":"  Motivated by applications for simulating quantum many body functions, we\npropose a new universal ansatz for approximating anti-symmetric functions. The\nmain advantage of this ansatz over previous alternatives is that it is\nbi-Lipschitz with respect to a naturally defined metric. As a result, we are\nable to obtain quantitative approximation results for approximation of\nLipschitz continuous antisymmetric functions. Moreover, we provide preliminary\nexperimental evidence to the improved performance of this ansatz for learning\nantisymmetric functions.\n","authors":["Nadav Dym","Jianfeng Lu","Matan Mizrachi"],"pdf_url":"https://arxiv.org/pdf/2503.04263v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.04256v1","updated":"2025-03-06T09:38:14Z","published":"2025-03-06T09:38:14Z","title":"Knowledge Retention for Continual Model-Based Reinforcement Learning","summary":"  We propose DRAGO, a novel approach for continual model-based reinforcement\nlearning aimed at improving the incremental development of world models across\na sequence of tasks that differ in their reward functions but not the state\nspace or dynamics. DRAGO comprises two key components: Synthetic Experience\nRehearsal, which leverages generative models to create synthetic experiences\nfrom past tasks, allowing the agent to reinforce previously learned dynamics\nwithout storing data, and Regaining Memories Through Exploration, which\nintroduces an intrinsic reward mechanism to guide the agent toward revisiting\nrelevant states from prior tasks. Together, these components enable the agent\nto maintain a comprehensive and continually developing world model,\nfacilitating more effective learning and adaptation across diverse\nenvironments. Empirical evaluations demonstrate that DRAGO is able to preserve\nknowledge across tasks, achieving superior performance in various continual\nlearning scenarios.\n","authors":["Yixiang Sun","Haotian Fu","Michael Littman","George Konidaris"],"pdf_url":"https://arxiv.org/pdf/2503.04256v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.04252v1","updated":"2025-03-06T09:35:20Z","published":"2025-03-06T09:35:20Z","title":"RCRank: Multimodal Ranking of Root Causes of Slow Queries in Cloud\n  Database Systems","summary":"  With the continued migration of storage to cloud database systems,the impact\nof slow queries in such systems on services and user experience is increasing.\nRoot-cause diagnosis plays an indispensable role in facilitating slow-query\ndetection and revision. This paper proposes a method capable of both\nidentifying possible root cause types for slow queries and ranking these\naccording to their potential for accelerating slow queries. This enables\nprioritizing root causes with the highest impact, in turn improving slow-query\nrevision effectiveness. To enable more accurate and detailed diagnoses, we\npropose the multimodal Ranking for the Root Causes of slow queries (RCRank)\nframework, which formulates root cause analysis as a multimodal machine\nlearning problem and leverages multimodal information from query statements,\nexecution plans, execution logs, and key performance indicators. To obtain\nexpressive embeddings from its heterogeneous multimodal input, RCRank\nintegrates self-supervised pre-training that enhances cross-modal alignment and\ntask relevance. Next, the framework integrates root-cause-adaptive cross\nTransformers that enable adaptive fusion of multimodal features with varying\ncharacteristics. Finally, the framework offers a unified model that features an\nimpact-aware training objective for identifying and ranking root causes. We\nreport on experiments on real and synthetic datasets, finding that RCRank is\ncapable of consistently outperforming the state-of-the-art methods at root\ncause identification and ranking according to a range of metrics.\n","authors":["Biao Ouyang","Yingying Zhang","Hanyin Cheng","Yang Shu","Chenjuan Guo","Bin Yang","Qingsong Wen","Lunting Fan","Christian S. Jensen"],"pdf_url":"https://arxiv.org/pdf/2503.04252v1.pdf","comment":"Accepted by VLDB 2025"},{"id":"http://arxiv.org/abs/2403.15038v2","updated":"2025-03-06T09:32:52Z","published":"2024-03-22T08:42:41Z","title":"Estimation of multiple mean vectors in high dimension","summary":"  We endeavour to estimate numerous multi-dimensional means of various\nprobability distributions on a common space based on independent samples. Our\napproach involves forming estimators through convex combinations of empirical\nmeans derived from these samples. We introduce two strategies to find\nappropriate data-dependent convex combination weights: a first one employing a\ntesting procedure to identify neighbouring means with low variance, which\nresults in a closed-form plug-in formula for the weights, and a second one\ndetermining weights via minimization of an upper confidence bound on the\nquadratic risk.Through theoretical analysis, we evaluate the improvement in\nquadratic risk offered by our methods compared to the empirical means. Our\nanalysis focuses on a dimensional asymptotics perspective, showing that our\nmethods asymptotically approach an oracle (minimax) improvement as the\neffective dimension of the data increases.We demonstrate the efficacy of our\nmethods in estimating multiple kernel mean embeddings through experiments on\nboth simulated and real-world datasets.\n","authors":["Gilles Blanchard","Jean-Baptiste Fermanian","Hannah Marienwald"],"pdf_url":"https://arxiv.org/pdf/2403.15038v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.04249v1","updated":"2025-03-06T09:32:39Z","published":"2025-03-06T09:32:39Z","title":"How to Mitigate Overfitting in Weak-to-strong Generalization?","summary":"  Aligning powerful AI models on tasks that surpass human evaluation\ncapabilities is the central problem of \\textbf{superalignment}. To address this\nproblem, weak-to-strong generalization aims to elicit the capabilities of\nstrong models through weak supervisors and ensure that the behavior of strong\nmodels aligns with the intentions of weak supervisors without unsafe behaviors\nsuch as deception. Although weak-to-strong generalization exhibiting certain\ngeneralization capabilities, strong models exhibit significant overfitting in\nweak-to-strong generalization: Due to the strong fit ability of strong models,\nerroneous labels from weak supervisors may lead to overfitting in strong\nmodels. In addition, simply filtering out incorrect labels may lead to a\ndegeneration in question quality, resulting in a weak generalization ability of\nstrong models on hard questions. To mitigate overfitting in weak-to-strong\ngeneralization, we propose a two-stage framework that simultaneously improves\nthe quality of supervision signals and the quality of input questions.\nExperimental results in three series of large language models and two\nmathematical benchmarks demonstrate that our framework significantly improves\nPGR compared to naive weak-to-strong generalization, even achieving up to 100\\%\nPGR on some models.\n","authors":["Junhao Shi","Qinyuan Cheng","Zhaoye Fei","Yining Zheng","Qipeng Guo","Xipeng Qiu"],"pdf_url":"https://arxiv.org/pdf/2503.04249v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2412.19085v2","updated":"2025-03-06T09:32:37Z","published":"2024-12-26T06:54:22Z","title":"Assessing Pre-Trained Models for Transfer Learning Through Distribution\n  of Spectral Components","summary":"  Pre-trained model assessment for transfer learning aims to identify the\noptimal candidate for the downstream tasks from a model hub, without the need\nof time-consuming fine-tuning. Existing advanced works mainly focus on\nanalyzing the intrinsic characteristics of the entire features extracted by\neach pre-trained model or how well such features fit the target labels. This\npaper proposes a novel perspective for pre-trained model assessment through the\nDistribution of Spectral Components (DISCO). Through singular value\ndecomposition of features extracted from pre-trained models, we investigate\ndifferent spectral components and observe that they possess distinct\ntransferability, contributing diversely to the fine-tuning performance.\nInspired by this, we propose an assessment method based on the distribution of\nspectral components which measures the proportions of their corresponding\nsingular values. Pre-trained models with features concentrating on more\ntransferable components are regarded as better choices for transfer learning.\nWe further leverage the labels of downstream data to better estimate the\ntransferability of each spectral component and derive the final assessment\ncriterion. Our proposed method is flexible and can be applied to both\nclassification and regression tasks. We conducted comprehensive experiments\nacross three benchmarks and two tasks including image classification and object\ndetection, demonstrating that our method achieves state-of-the-art performance\nin choosing proper pre-trained models from the model hub for transfer learning.\n","authors":["Tengxue Zhang","Yang Shu","Xinyang Chen","Yifei Long","Chenjuan Guo","Bin Yang"],"pdf_url":"https://arxiv.org/pdf/2412.19085v2.pdf","comment":"Accepted by AAAI 2025"},{"id":"http://arxiv.org/abs/2503.04242v1","updated":"2025-03-06T09:24:23Z","published":"2025-03-06T09:24:23Z","title":"Incorporating Surrogate Gradient Norm to Improve Offline Optimization\n  Techniques","summary":"  Offline optimization has recently emerged as an increasingly popular approach\nto mitigate the prohibitively expensive cost of online experimentation. The key\nidea is to learn a surrogate of the black-box function that underlines the\ntarget experiment using a static (offline) dataset of its previous input-output\nqueries. Such an approach is, however, fraught with an out-of-distribution\nissue where the learned surrogate becomes inaccurate outside the offline data\nregimes. To mitigate this, existing offline optimizers have proposed numerous\nconditioning techniques to prevent the learned surrogate from being too\nerratic. Nonetheless, such conditioning strategies are often specific to\nparticular surrogate or search models, which might not generalize to a\ndifferent model choice. This motivates us to develop a model-agnostic approach\ninstead, which incorporates a notion of model sharpness into the training loss\nof the surrogate as a regularizer. Our approach is supported by a new\ntheoretical analysis demonstrating that reducing surrogate sharpness on the\noffline dataset provably reduces its generalized sharpness on unseen data. Our\nanalysis extends existing theories from bounding generalized prediction loss\n(on unseen data) with loss sharpness to bounding the worst-case generalized\nsurrogate sharpness with its empirical estimate on training data, providing a\nnew perspective on sharpness regularization. Our extensive experimentation on a\ndiverse range of optimization tasks also shows that reducing surrogate\nsharpness often leads to significant improvement, marking (up to) a noticeable\n9.6% performance boost. Our code is publicly available at\nhttps://github.com/cuong-dm/IGNITE\n","authors":["Manh Cuong Dao","Phi Le Nguyen","Thao Nguyen Truong","Trong Nghia Hoang"],"pdf_url":"https://arxiv.org/pdf/2503.04242v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2501.19102v2","updated":"2025-03-06T09:23:22Z","published":"2025-01-31T12:51:55Z","title":"Reinforcement Learning on Reconfigurable Hardware: Overcoming Material\n  Variability in Laser Material Processing","summary":"  Ensuring consistent processing quality is challenging in laser processes due\nto varying material properties and surface conditions. Although some approaches\nhave shown promise in solving this problem via automation, they often rely on\npredetermined targets or are limited to simulated environments. To address\nthese shortcomings, we propose a novel real-time reinforcement learning\napproach for laser process control, implemented on a Field Programmable Gate\nArray to achieve real-time execution. Our experimental results from laser\nwelding tests on stainless steel samples with a range of surface roughnesses\nvalidated the method's ability to adapt autonomously, without relying on reward\nengineering or prior setup information. Specifically, the algorithm learned the\ncorrect power profile for each unique surface characteristic, demonstrating\nsignificant improvements over hand-engineered optimal constant power strategies\n-- up to 23% better performance on rougher surfaces and 7% on mixed surfaces.\nThis approach represents a significant advancement in automating and optimizing\nlaser processes, with potential applications across multiple industries.\n","authors":["Giulio Masinelli","Chang Rajani","Patrik Hoffmann","Kilian Wasmer","David Atienza"],"pdf_url":"https://arxiv.org/pdf/2501.19102v2.pdf","comment":"Accepted for the 2025 IEEE International Conference on Robotics and\n  Automation (ICRA), May 19-23, 2025, Atlanta, USA; Camera ready version --\n  addressed reviewer comments in text, improved plot clarity"},{"id":"http://arxiv.org/abs/2501.13430v2","updated":"2025-03-06T09:22:38Z","published":"2025-01-23T07:29:44Z","title":"Wasserstein-regularized Conformal Prediction under General Distribution\n  Shift","summary":"  Conformal prediction yields a prediction set with guaranteed $1-\\alpha$\ncoverage of the true target under the i.i.d. assumption, which may not hold and\nlead to a gap between $1-\\alpha$ and the actual coverage. Prior studies bound\nthe gap using total variation distance, which cannot identify the gap changes\nunder distribution shift at a given $\\alpha$. Besides, existing methods are\nmostly limited to covariate shift,while general joint distribution shifts are\nmore common in practice but less researched.In response, we first propose a\nWasserstein distance-based upper bound of the coverage gap and analyze the\nbound using probability measure pushforwards between the shifted joint data and\nconformal score distributions, enabling a separation of the effect of covariate\nand concept shifts over the coverage gap. We exploit the separation to design\nan algorithm based on importance weighting and regularized representation\nlearning (WR-CP) to reduce the Wasserstein bound with a finite-sample error\nbound.WR-CP achieves a controllable balance between conformal prediction\naccuracy and efficiency. Experiments on six datasets prove that WR-CP can\nreduce coverage gaps to $3.2\\%$ across different confidence levels and outputs\nprediction sets 37$\\%$ smaller than the worst-case approach on average.\n","authors":["Rui Xu","Chao Chen","Yue Sun","Parvathinathan Venkitasubramaniam","Sihong Xie"],"pdf_url":"https://arxiv.org/pdf/2501.13430v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.04241v1","updated":"2025-03-06T09:22:23Z","published":"2025-03-06T09:22:23Z","title":"ThrowBench: Benchmarking LLMs by Predicting Runtime Exceptions","summary":"  Modern Large Language Models (LLMs) have shown astounding capabilities of\ncode understanding and synthesis. In order to assess such capabilities, several\nbenchmarks have been devised (e.g., HumanEval). However, most benchmarks focus\non code synthesis from natural language instructions. Hence, such benchmarks do\nnot test for other forms of code understanding. Moreover, there have been\nconcerns about contamination and leakage. That is, benchmark problems (or\nclosely related problems) may appear in training set, strongly biasing\nbenchmark results. In this work we investigate whether large language models\ncan correctly predict runtime program behavior. To this end, we introduce\nThrowBench, a benchmark consisting of over 2,400 short user-written programs\nwritten in four different programming languages. The majority of these programs\nthrow an exception during runtime (due to a bug). LLMs are asked to predict\nwhether a presented program throws an exception and, if so, which one.\nEvaluating our benchmark on six state-of-the-art code LLMs we see modest\nperformance ranging from 19 to 38% (F1 score). Benchmarking a wider set of code\ncapabilities could improve the assessment of code LLMs and help identify weak\npoints in current models. Moreover, as ground-truth answers have been\ndetermined through program execution, leakage is not a concern. We release\nThrowBench as well as all of our results together with this work.\n","authors":["Julian Aron Prenner","Romain Robbes"],"pdf_url":"https://arxiv.org/pdf/2503.04241v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.04231v1","updated":"2025-03-06T09:12:43Z","published":"2025-03-06T09:12:43Z","title":"One-Shot Clustering for Federated Learning","summary":"  Federated Learning (FL) is a widespread and well adopted paradigm of\ndecentralized learning that allows training one model from multiple sources\nwithout the need to directly transfer data between participating clients. Since\nits inception in 2015, it has been divided into numerous sub-fields that deal\nwith application-specific issues, be it data heterogeneity or resource\nallocation. One such sub-field, Clustered Federated Learning (CFL), is dealing\nwith the problem of clustering the population of clients into separate cohorts\nto deliver personalized models. Although few remarkable works have been\npublished in this domain, the problem is still largely unexplored, as its basic\nassumption and settings are slightly different from standard FL. In this work,\nwe present One-Shot Clustered Federated Learning (OCFL), a clustering-agnostic\nalgorithm that can automatically detect the earliest suitable moment for\nclustering. Our algorithm is based on the computation of cosine similarity\nbetween gradients of the clients and a temperature measure that detects when\nthe federated model starts to converge. We empirically evaluate our methodology\nby testing various one-shot clustering algorithms for over thirty different\ntasks on three benchmark datasets. Our experiments showcase the good\nperformance of our approach when used to perform CFL in an automated manner\nwithout the need to adjust hyperparameters.\n","authors":["Maciej Krzysztof Zuziak","Roberto Pellungrini","Salvatore Rinzivillo"],"pdf_url":"https://arxiv.org/pdf/2503.04231v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2206.02796v3","updated":"2025-03-06T09:10:18Z","published":"2022-06-06T14:26:34Z","title":"Mixed Graph Contrastive Network for Semi-Supervised Node Classification","summary":"  Graph Neural Networks (GNNs) have achieved promising performance in\nsemi-supervised node classification in recent years. However, the problem of\ninsufficient supervision, together with representation collapse, largely limits\nthe performance of the GNNs in this field. To alleviate the collapse of node\nrepresentations in semi-supervised scenario, we propose a novel graph\ncontrastive learning method, termed Mixed Graph Contrastive Network (MGCN). In\nour method, we improve the discriminative capability of the latent embeddings\nby an interpolation-based augmentation strategy and a correlation reduction\nmechanism. Specifically, we first conduct the interpolation-based augmentation\nin the latent space and then force the prediction model to change linearly\nbetween samples. Second, we enable the learned network to tell apart samples\nacross two interpolation-perturbed views through forcing the correlation matrix\nacross views to approximate an identity matrix. By combining the two settings,\nwe extract rich supervision information from both the abundant unlabeled nodes\nand the rare yet valuable labeled nodes for discriminative representation\nlearning. Extensive experimental results on six datasets demonstrate the\neffectiveness and the generality of MGCN compared to the existing\nstate-of-the-art methods. The code of MGCN is available at\nhttps://github.com/xihongyang1999/MGCN on Github.\n","authors":["Xihong Yang","Yiqi Wang","Yue Liu","Yi Wen","Lingyuan Meng","Sihang Zhou","Xinwang Liu","En Zhu"],"pdf_url":"https://arxiv.org/pdf/2206.02796v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.09263v3","updated":"2025-03-06T09:10:07Z","published":"2024-11-14T08:02:14Z","title":"Rethinking Weight-Averaged Model-merging","summary":"  Model-merging has emerged as a powerful approach in deep learning, capable of\nenhancing model performance without any training. However, the underlying\nmechanisms that explain its effectiveness remain largely unexplored. In this\npaper, we investigate this technique from three novel perspectives to\nempirically provide deeper insights into why and how weight-averaged\nmodel-merging works: (1) we examine the intrinsic patterns captured by the\nlearning of the model weights, through the visualizations of their patterns on\nseveral datasets, showing that these weights often encode structured and\ninterpretable patterns and that is the essential why model-merging can work;\n(2) we mathematically and empirically investigate model ensemble merging\nstrategies based on averaging on weights versus averaging on features,\nproviding detailed analyses across diverse architectures and datasets; and (3)\nwe explore the impact on model-merging prediction stability in terms of\nchanging the parameter magnitude, revealing insights into the way of weight\naveraging works as regularization by showing the robustness across different\nparameter scales. Our findings shed light on the \"black box\" of weight-averaged\nmodel-merging, offering valuable insights and practical recommendations that\nadvance the model-merging process. The code is available at\nhttps://github.com/billhhh/Rethink-Merge.\n","authors":["Hu Wang","Congbo Ma","Ibrahim Almakky","Ian Reid","Gustavo Carneiro","Mohammad Yaqub"],"pdf_url":"https://arxiv.org/pdf/2411.09263v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.04229v1","updated":"2025-03-06T09:09:18Z","published":"2025-03-06T09:09:18Z","title":"Synthetic Data is an Elegant GIFT for Continual Vision-Language Models","summary":"  Pre-trained Vision-Language Models (VLMs) require Continual Learning (CL) to\nefficiently update their knowledge and adapt to various downstream tasks\nwithout retraining from scratch. However, for VLMs, in addition to the loss of\nknowledge previously learned from downstream tasks, pre-training knowledge is\nalso corrupted during continual fine-tuning. This issue is exacerbated by the\nunavailability of original pre-training data, leaving VLM's generalization\nability degrading. In this paper, we propose GIFT, a novel continual\nfine-tuning approach that utilizes synthetic data to overcome catastrophic\nforgetting in VLMs. Taking advantage of recent advances in text-to-image\nsynthesis, we employ a pre-trained diffusion model to recreate both\npre-training and learned downstream task data. In this way, the VLM can revisit\nprevious knowledge through distillation on matching diffusion-generated images\nand corresponding text prompts. Leveraging the broad distribution and high\nalignment between synthetic image-text pairs in VLM's feature space, we propose\na contrastive distillation loss along with an image-text alignment constraint.\nTo further combat in-distribution overfitting and enhance distillation\nperformance with limited amount of generated data, we incorporate adaptive\nweight consolidation, utilizing Fisher information from these synthetic\nimage-text pairs and achieving a better stability-plasticity balance. Extensive\nexperiments demonstrate that our method consistently outperforms previous\nstate-of-the-art approaches across various settings.\n","authors":["Bin Wu","Wuxuan Shi","Jinqiao Wang","Mang Ye"],"pdf_url":"https://arxiv.org/pdf/2503.04229v1.pdf","comment":"This work is accepted by CVPR 2025. Modifications may be performed"},{"id":"http://arxiv.org/abs/2402.02998v2","updated":"2025-03-06T08:57:29Z","published":"2024-02-05T13:37:00Z","title":"Careful with that Scalpel: Improving Gradient Surgery with an EMA","summary":"  Beyond minimizing a single training loss, many deep learning estimation\npipelines rely on an auxiliary objective to quantify and encourage desirable\nproperties of the model (e.g. performance on another dataset, robustness,\nagreement with a prior). Although the simplest approach to incorporating an\nauxiliary loss is to sum it with the training loss as a regularizer, recent\nworks have shown that one can improve performance by blending the gradients\nbeyond a simple sum; this is known as gradient surgery. We cast the problem as\na constrained minimization problem where the auxiliary objective is minimized\namong the set of minimizers of the training loss. To solve this bilevel\nproblem, we follow a parameter update direction that combines the training loss\ngradient and the orthogonal projection of the auxiliary gradient to the\ntraining gradient. In a setting where gradients come from mini-batches, we\nexplain how, using a moving average of the training loss gradients, we can\ncarefully maintain this critical orthogonality property. We demonstrate that\nour method, Bloop, can lead to much better performances on NLP and vision\nexperiments than other gradient surgery methods without EMA.\n","authors":["Yu-Guan Hsieh","James Thornton","Eugene Ndiaye","Michal Klein","Marco Cuturi","Pierre Ablin"],"pdf_url":"https://arxiv.org/pdf/2402.02998v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.04219v1","updated":"2025-03-06T08:54:31Z","published":"2025-03-06T08:54:31Z","title":"Quantum-Inspired Reinforcement Learning in the Presence of Epistemic\n  Ambivalence","summary":"  The complexity of online decision-making under uncertainty stems from the\nrequirement of finding a balance between exploiting known strategies and\nexploring new possibilities. Naturally, the uncertainty type plays a crucial\nrole in developing decision-making strategies that manage complexity\neffectively. In this paper, we focus on a specific form of uncertainty known as\nepistemic ambivalence (EA), which emerges from conflicting pieces of evidence\nor contradictory experiences. It creates a delicate interplay between\nuncertainty and confidence, distinguishing it from epistemic uncertainty that\ntypically diminishes with new information. Indeed, ambivalence can persist even\nafter additional knowledge is acquired. To address this phenomenon, we propose\na novel framework, called the epistemically ambivalent Markov decision process\n(EA-MDP), aiming to understand and control EA in decision-making processes.\nThis framework incorporates the concept of a quantum state from the quantum\nmechanics formalism, and its core is to assess the probability and reward of\nevery possible outcome. We calculate the reward function using quantum\nmeasurement techniques and prove the existence of an optimal policy and an\noptimal value function in the EA-MDP framework. We also propose the\nEA-epsilon-greedy Q-learning algorithm. To evaluate the impact of EA on\ndecision-making and the expedience of our framework, we study two distinct\nexperimental setups, namely the two-state problem and the lattice problem. Our\nresults show that using our methods, the agent converges to the optimal policy\nin the presence of EA.\n","authors":["Alireza Habibi","Saeed Ghoorchian","Setareh Maghsudi"],"pdf_url":"https://arxiv.org/pdf/2503.04219v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.02495v2","updated":"2025-03-06T08:51:47Z","published":"2025-03-04T11:01:25Z","title":"Union of Experts: Adapting Hierarchical Routing to Equivalently\n  Decomposed Transformer","summary":"  We propose Union-of-Experts (UoE), which decomposes transformer into an\nequitant group of experts, and then implement selective routing on input data\nand experts. Our approach advances MoE design with four key innovations: (1) We\nconducted equitant expert decomposition on both MLP blocks and attention blocks\nbased on matrix partition in tensor parallelism. (2) We developed two routing\nparadigms: patch-wise data selection and expert selection, to apply routing\nacross different levels. (3) We design the architecture of UoE model, including\nSelective Multi-Head Attention (SMHA) and Union-of-MLP-Experts (UoME). (4) We\ndevelop parallel implementation of UoE's routing and computation operation, and\noptimize efficiency based on the hardware processing analysis. The experiments\ndemonstrate that the UoE model surpass Full Attention, state-of-art MoEs and\nefficient transformers (including the model architecture of recently proposed\nDeepSeek-V3) in several tasks across image and natural language domains. In\nlanguage modeling tasks, we achieve an average reduction of 2.38 in perplexity\ncompared to the best-performed MoE method with an average of 76% FLOPs. In Long\nRange Arena benchmark, we recorded an average score that is at least 0.68%\nhigher than all comparison models including Full Attention, MoEs, and\ntransformer variants, with only 50% FLOPs of the best MoE method. In image\nclassification, our model yielded an average accuracy improvement of 1.75% than\nthe best model while maintaining comparable FLOPs. The source codes are\navailable at https://github.com/YujiaoYang-work/UoE.\n","authors":["Yujiao Yang","Jing Lian","Linhui Li"],"pdf_url":"https://arxiv.org/pdf/2503.02495v2.pdf","comment":"17 pages"},{"id":"http://arxiv.org/abs/2503.01224v2","updated":"2025-03-06T08:51:38Z","published":"2025-03-03T06:43:45Z","title":"CE-U: Cross Entropy Unlearning","summary":"  Large language models (LLMs) inadvertently memorize sensitive data from their\nmassive pretraining corpora \\cite{jang2022knowledge}. In this work, we propose\nCE-U (Cross Entropy Unlearning), a novel loss function designed specifically\nfor unlearning tasks. CE-U addresses fundamental limitations of gradient ascent\napproaches which suffer from instability due to vanishing gradients when model\nconfidence is high and gradient exploding when confidence is low. We also unify\nstandard cross entropy supervision and cross entropy unlearning into a single\nframework. Notably, on the TOFU benchmark for unlearning \\cite{maini2024tofu},\nCE-U achieves state-of-the-art results on LLaMA2-7B with 1\\% and 5\\%\nforgetting, even without the use of any extra reference model or additional\npositive samples. Our theoretical analysis further reveals that the gradient\ninstability issues also exist in popular reinforcement learning algorithms like\nDPO \\cite{rafailov2023direct} and GRPO\\cite{Shao2024DeepSeekMath}, as they\ninclude a gradient ascent component. This suggests that applying CE-U\nprinciples to reinforcement learning could be a promising direction for\nimproving stability and convergence.\n","authors":["Bo Yang"],"pdf_url":"https://arxiv.org/pdf/2503.01224v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.04204v1","updated":"2025-03-06T08:30:18Z","published":"2025-03-06T08:30:18Z","title":"FUSE: First-Order and Second-Order Unified SynthEsis in Stochastic\n  Optimization","summary":"  Stochastic optimization methods have actively been playing a critical role in\nmodern machine learning algorithms to deliver decent performance. While\nnumerous works have proposed and developed diverse approaches, first-order and\nsecond-order methods are in entirely different situations. The former is\nsignificantly pivotal and dominating in emerging deep learning but only leads\nconvergence to a stationary point. However, second-order methods are less\npopular due to their computational intensity in large-dimensional problems.\nThis paper presents a novel method that leverages both the first-order and\nsecond-order methods in a unified algorithmic framework, termed FUSE, from\nwhich a practical version (PV) is derived accordingly. FUSE-PV stands as a\nsimple yet efficient optimization method involving a switch-over between first\nand second orders. Additionally, we develop different criteria that determine\nwhen to switch. FUSE-PV has provably shown a smaller computational complexity\nthan SGD and Adam. To validate our proposed scheme, we present an ablation\nstudy on several simple test functions and show a comparison with baselines for\nbenchmark datasets.\n","authors":["Zhanhong Jiang","Md Zahid Hasan","Aditya Balu","Joshua R. Waite","Genyi Huang","Soumik Sarkar"],"pdf_url":"https://arxiv.org/pdf/2503.04204v1.pdf","comment":"6 pages, 7 figures"},{"id":"http://arxiv.org/abs/2503.04203v1","updated":"2025-03-06T08:29:36Z","published":"2025-03-06T08:29:36Z","title":"Geometric Re-Analysis of Classical MDP Solving Algorithms","summary":"  We build on a recently introduced geometric interpretation of Markov Decision\nProcesses (MDPs) to analyze classical MDP-solving algorithms: Value Iteration\n(VI) and Policy Iteration (PI). First, we develop a geometry-based analytical\napparatus, including a transformation that modifies the discount factor\n$\\gamma$, to improve convergence guarantees for these algorithms in several\nsettings. In particular, one of our results identifies a rotation component in\nthe VI method, and as a consequence shows that when a Markov Reward Process\n(MRP) induced by the optimal policy is irreducible and aperiodic, the\nasymptotic convergence rate of value iteration is strictly smaller than\n$\\gamma$.\n","authors":["Arsenii Mustafin","Aleksei Pakharev","Alex Olshevsky","Ioannis Ch. Paschalidis"],"pdf_url":"https://arxiv.org/pdf/2503.04203v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2102.01130v3","updated":"2025-03-06T14:21:55Z","published":"2021-02-01T19:45:47Z","title":"Comparing hundreds of machine learning classifiers and discrete choice\n  models in predicting travel behavior: an empirical benchmark","summary":"  Numerous studies have compared machine learning (ML) and discrete choice\nmodels (DCMs) in predicting travel demand. However, these studies often lack\ngeneralizability as they compare models deterministically without considering\ncontextual variations. To address this limitation, our study develops an\nempirical benchmark by designing a tournament model, thus efficiently\nsummarizing a large number of experiments, quantifying the randomness in model\ncomparisons, and using formal statistical tests to differentiate between the\nmodel and contextual effects. This benchmark study compares two large-scale\ndata sources: a database compiled from literature review summarizing 136\nexperiments from 35 studies, and our own experiment data, encompassing a total\nof 6,970 experiments from 105 models and 12 model families. This benchmark\nstudy yields two key findings. Firstly, many ML models, particularly the\nensemble methods and deep learning, statistically outperform the DCM family\n(i.e., multinomial, nested, and mixed logit models). However, this study also\nhighlights the crucial role of the contextual factors (i.e., data sources,\ninputs and choice categories), which can explain models' predictive performance\nmore effectively than the differences in model types alone. Model performance\nvaries significantly with data sources, improving with larger sample sizes and\nlower dimensional alternative sets. After controlling all the model and\ncontextual factors, significant randomness still remains, implying inherent\nuncertainty in such model comparisons. Overall, we suggest that future\nresearchers shift more focus from context-specific model comparisons towards\nexamining model transferability across contexts and characterizing the inherent\nuncertainty in ML, thus creating more robust and generalizable next-generation\ntravel demand models.\n","authors":["Shenhao Wang","Baichuan Mo","Yunhan Zheng","Stephane Hess","Jinhua Zhao"],"pdf_url":"https://arxiv.org/pdf/2102.01130v3.pdf","comment":null}],"Information Retrieval":[{"id":"http://arxiv.org/abs/2503.04653v1","updated":"2025-03-06T17:43:03Z","published":"2025-03-06T17:43:03Z","title":"RadIR: A Scalable Framework for Multi-Grained Medical Image Retrieval\n  via Radiology Report Mining","summary":"  Developing advanced medical imaging retrieval systems is challenging due to\nthe varying definitions of `similar images' across different medical contexts.\nThis challenge is compounded by the lack of large-scale, high-quality medical\nimaging retrieval datasets and benchmarks. In this paper, we propose a novel\nmethodology that leverages dense radiology reports to define image-wise\nsimilarity ordering at multiple granularities in a scalable and fully automatic\nmanner. Using this approach, we construct two comprehensive medical imaging\nretrieval datasets: MIMIC-IR for Chest X-rays and CTRATE-IR for CT scans,\nproviding detailed image-image ranking annotations conditioned on diverse\nanatomical structures. Furthermore, we develop two retrieval systems, RadIR-CXR\nand model-ChestCT, which demonstrate superior performance in traditional\nimage-image and image-report retrieval tasks. These systems also enable\nflexible, effective image retrieval conditioned on specific anatomical\nstructures described in text, achieving state-of-the-art results on 77 out of\n78 metrics.\n","authors":["Tengfei Zhang","Ziheng Zhao","Chaoyi Wu","Xiao Zhou","Ya Zhang","Yangfeng Wang","Weidi Xie"],"pdf_url":"https://arxiv.org/pdf/2503.04653v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.04644v1","updated":"2025-03-06T17:32:22Z","published":"2025-03-06T17:32:22Z","title":"IFIR: A Comprehensive Benchmark for Evaluating Instruction-Following in\n  Expert-Domain Information Retrieval","summary":"  We introduce IFIR, the first comprehensive benchmark designed to evaluate\ninstruction-following information retrieval (IR) in expert domains. IFIR\nincludes 2,426 high-quality examples and covers eight subsets across four\nspecialized domains: finance, law, healthcare, and science literature. Each\nsubset addresses one or more domain-specific retrieval tasks, replicating\nreal-world scenarios where customized instructions are critical. IFIR enables a\ndetailed analysis of instruction-following retrieval capabilities by\nincorporating instructions at different levels of complexity. We also propose a\nnovel LLM-based evaluation method to provide a more precise and reliable\nassessment of model performance in following instructions. Through extensive\nexperiments on 15 frontier retrieval models, including those based on LLMs, our\nresults reveal that current models face significant challenges in effectively\nfollowing complex, domain-specific instructions. We further provide in-depth\nanalyses to highlight these limitations, offering valuable insights to guide\nfuture advancements in retriever development.\n","authors":["Tingyu Song","Guo Gan","Mingsheng Shang","Yilun Zhao"],"pdf_url":"https://arxiv.org/pdf/2503.04644v1.pdf","comment":"NAACL 2025 Main"},{"id":"http://arxiv.org/abs/2503.03606v2","updated":"2025-03-06T14:28:36Z","published":"2025-03-05T15:42:37Z","title":"Decoupled Recommender Systems: Exploring Alternative Recommender\n  Ecosystem Designs","summary":"  Recommender ecosystems are an emerging subject of research. Such research\nexamines how the characteristics of algorithms, recommendation consumers, and\nitem providers influence system dynamics and long-term outcomes. One\narchitectural possibility that has not yet been widely explored in this line of\nresearch is the consequences of a configuration in which recommendation\nalgorithms are decoupled from the platforms they serve. This is sometimes\ncalled \"the friendly neighborhood algorithm store\" or \"middleware\" model. We\nare particularly interested in how such architectures might offer a range of\ndifferent distributions of utility across consumers, providers, and\nrecommendation platforms. In this paper, we create a model of a recommendation\necosystem that incorporates algorithm choice and examine the outcomes of such a\ndesign.\n","authors":["Anas Buhayh","Elizabeth McKinnie","Robin Burke"],"pdf_url":"https://arxiv.org/pdf/2503.03606v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2501.13959v2","updated":"2025-03-06T13:51:24Z","published":"2025-01-21T06:32:25Z","title":"Assisting Mathematical Formalization with A Learning-based Premise\n  Retriever","summary":"  Premise selection is a crucial yet challenging step in mathematical\nformalization, especially for users with limited experience. Due to the lack of\navailable formalization projects, existing approaches that leverage language\nmodels often suffer from data scarcity. In this work, we introduce an\ninnovative method for training a premise retriever to support the formalization\nof mathematics. Our approach employs a BERT model to embed proof states and\npremises into a shared latent space. The retrieval model is trained within a\ncontrastive learning framework and incorporates a domain-specific tokenizer\nalong with a fine-grained similarity computation method. Experimental results\nshow that our model is highly competitive compared to existing baselines,\nachieving strong performance while requiring fewer computational resources.\nPerformance is further enhanced through the integration of a re-ranking module.\nTo streamline the formalization process, we will release a search engine that\nenables users to query Mathlib theorems directly using proof states,\nsignificantly improving accessibility and efficiency. Codes are available at\nhttps://github.com/ruc-ai4math/Premise-Retrieval.\n","authors":["Yicheng Tao","Haotian Liu","Shanwen Wang","Hongteng Xu"],"pdf_url":"https://arxiv.org/pdf/2501.13959v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.04406v1","updated":"2025-03-06T13:00:53Z","published":"2025-03-06T13:00:53Z","title":"Training-Free Graph Filtering via Multimodal Feature Refinement for\n  Extremely Fast Multimodal Recommendation","summary":"  Multimodal recommender systems improve the performance of canonical\nrecommender systems with no item features by utilizing diverse content types\nsuch as text, images, and videos, while alleviating inherent sparsity of\nuser-item interactions and accelerating user engagement. However, current\nneural network-based models often incur significant computational overhead due\nto the complex training process required to learn and integrate information\nfrom multiple modalities. To overcome this limitation, we propose\nMultiModal-Graph Filtering (MM-GF), a training-free method based on the notion\nof graph filtering (GF) for efficient and accurate multimodal recommendations.\nSpecifically, MM-GF first constructs multiple similarity graphs through\nnontrivial multimodal feature refinement such as robust scaling and vector\nshifting by addressing the heterogeneous characteristics across modalities.\nThen, MM-GF optimally fuses multimodal information using linear low-pass\nfilters across different modalities. Extensive experiments on real-world\nbenchmark datasets demonstrate that MM-GF not only improves recommendation\naccuracy by up to 13.35% compared to the best competitor but also dramatically\nreduces computational costs by achieving the runtime of less than 10 seconds.\n","authors":["Yu-Seung Roh","Joo-Young Kim","Jin-Duk Park","Won-Yong Shin"],"pdf_url":"https://arxiv.org/pdf/2503.04406v1.pdf","comment":"10 pages, 6 figures, 6 tables"},{"id":"http://arxiv.org/abs/2503.01346v2","updated":"2025-03-06T12:27:24Z","published":"2025-03-03T09:37:33Z","title":"SRAG: Structured Retrieval-Augmented Generation for Multi-Entity\n  Question Answering over Wikipedia Graph","summary":"  Multi-entity question answering (MEQA) poses significant challenges for large\nlanguage models (LLMs), which often struggle to consolidate scattered\ninformation across multiple documents. An example question might be \"What is\nthe distribution of IEEE Fellows among various fields of study?\", which\nrequires retrieving information from diverse sources e.g., Wikipedia pages. The\neffectiveness of current retrieval-augmented generation (RAG) methods is\nlimited by the LLMs' capacity to aggregate insights from numerous pages. To\naddress this gap, this paper introduces a structured RAG (SRAG) framework that\nsystematically organizes extracted entities into relational tables (e.g.,\ntabulating entities with schema columns like \"name\" and \"field of study\") and\nthen apply table-based reasoning techniques. Our approach decouples retrieval\nand reasoning, enabling LLMs to focus on structured data analysis rather than\nraw text aggregation. Extensive experiments on Wikipedia-based multi-entity QA\ntasks demonstrate that SRAG significantly outperforms state-of-the-art\nlong-context LLMs and RAG solutions, achieving a 29.6% improvement in accuracy.\nThe results underscore the efficacy of structuring unstructured data to enhance\nLLMs' reasoning capabilities.\n","authors":["Teng Lin","Yizhang Zhu","Yuyu Luo","Nan Tang"],"pdf_url":"https://arxiv.org/pdf/2503.01346v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2407.12468v3","updated":"2025-03-06T11:53:49Z","published":"2024-07-17T10:40:39Z","title":"Evaluating Search Engines and Large Language Models for Answering Health\n  Questions","summary":"  Search engines (SEs) have traditionally been primary tools for information\nseeking, but the new Large Language Models (LLMs) are emerging as powerful\nalternatives, particularly for question-answering tasks. This study compares\nthe performance of four popular SEs, seven LLMs, and retrieval-augmented (RAG)\nvariants in answering 150 health-related questions from the TREC Health\nMisinformation (HM) Track. Results reveal SEs correctly answer between 50 and\n70% of questions, often hindered by many retrieval results not responding to\nthe health question. LLMs deliver higher accuracy, correctly answering about\n80% of questions, though their performance is sensitive to input prompts. RAG\nmethods significantly enhance smaller LLMs' effectiveness, improving accuracy\nby up to 30% by integrating retrieval evidence.\n","authors":["Marcos Fernndez-Pichel","Juan C. Pichel","David E. Losada"],"pdf_url":"https://arxiv.org/pdf/2407.12468v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.04338v1","updated":"2025-03-06T11:34:49Z","published":"2025-03-06T11:34:49Z","title":"In-depth Analysis of Graph-based RAG in a Unified Framework","summary":"  Graph-based Retrieval-Augmented Generation (RAG) has proven effective in\nintegrating external knowledge into large language models (LLMs), improving\ntheir factual accuracy, adaptability, interpretability, and trustworthiness. A\nnumber of graph-based RAG methods have been proposed in the literature.\nHowever, these methods have not been systematically and comprehensively\ncompared under the same experimental settings. In this paper, we first\nsummarize a unified framework to incorporate all graph-based RAG methods from a\nhigh-level perspective. We then extensively compare representative graph-based\nRAG methods over a range of questing-answering (QA) datasets -- from specific\nquestions to abstract questions -- and examine the effectiveness of all\nmethods, providing a thorough analysis of graph-based RAG approaches. As a\nbyproduct of our experimental analysis, we are also able to identify new\nvariants of the graph-based RAG methods over specific QA and abstract QA tasks\nrespectively, by combining existing techniques, which outperform the\nstate-of-the-art methods. Finally, based on these findings, we offer promising\nresearch opportunities. We believe that a deeper understanding of the behavior\nof existing methods can provide new valuable insights for future research.\n","authors":["Yingli Zhou","Yaodong Su","Youran Sun","Shu Wang","Taotao Wang","Runyuan He","Yongwei Zhang","Sicong Liang","Xilin Liu","Yuchi Ma","Yixiang Fang"],"pdf_url":"https://arxiv.org/pdf/2503.04338v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2405.01924v2","updated":"2025-03-06T10:39:48Z","published":"2024-05-03T08:34:13Z","title":"Semi-Parametric Retrieval via Binary Bag-of-Tokens Index","summary":"  Information retrieval has transitioned from standalone systems into essential\ncomponents across broader applications, with indexing efficiency,\ncost-effectiveness, and freshness becoming increasingly critical yet often\noverlooked. In this paper, we introduce SemI-parametric Disentangled Retrieval\n(SiDR), a bi-encoder retrieval framework that decouples retrieval index from\nneural parameters to enable efficient, low-cost, and parameter-agnostic\nindexing for emerging use cases. Specifically, in addition to using embeddings\nas indexes like existing neural retrieval methods, SiDR supports a\nnon-parametric tokenization index for search, achieving BM25-like indexing\ncomplexity with significantly better effectiveness. Our comprehensive\nevaluation across 16 retrieval benchmarks demonstrates that SiDR outperforms\nboth neural and term-based retrieval baselines under the same indexing\nworkload: (i) When using an embedding-based index, SiDR exceeds the performance\nof conventional neural retrievers while maintaining similar training\ncomplexity; (ii) When using a tokenization-based index, SiDR drastically\nreduces indexing cost and time, matching the complexity of traditional\nterm-based retrieval, while consistently outperforming BM25 on all in-domain\ndatasets; (iii) Additionally, we introduce a late parametric mechanism that\nmatches BM25 index preparation time while outperforming other neural retrieval\nbaselines in effectiveness.\n","authors":["Jiawei Zhou","Li Dong","Furu Wei","Lei Chen"],"pdf_url":"https://arxiv.org/pdf/2405.01924v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.04188v1","updated":"2025-03-06T08:03:51Z","published":"2025-03-06T08:03:51Z","title":"Measuring temporal effects of agent knowledge by date-controlled tool\n  use","summary":"  Temporal progression is an integral part of knowledge accumulation and\nupdate. Web search is frequently adopted as grounding for agent knowledge, yet\nits inappropriate configuration affects the quality of agent responses. Here,\nwe construct a tool-based out-of-sample testing framework to measure the\nknowledge variability of large language model (LLM) agents from distinct\ndate-controlled tools (DCTs). We demonstrate the temporal effects of an LLM\nagent as a writing assistant, which can use web search to help complete\nscientific publication abstracts. We show that temporal effects of the search\nengine translates into tool-dependent agent performance but can be alleviated\nwith base model choice and explicit reasoning instructions such as\nchain-of-thought prompting. Our results indicate that agent evaluation should\ntake a dynamical view and account for the temporal influence of tools and the\nupdates of external resources.\n","authors":["R. Patrick Xian","Qiming Cui","Stefan Bauer","Reza Abbasi-Asl"],"pdf_url":"https://arxiv.org/pdf/2503.04188v1.pdf","comment":"comments welcome"},{"id":"http://arxiv.org/abs/2503.04162v1","updated":"2025-03-06T07:25:19Z","published":"2025-03-06T07:25:19Z","title":"Semantic Retrieval Augmented Contrastive Learning for Sequential\n  Recommendation","summary":"  Sequential recommendation aims to model user preferences based on historical\nbehavior sequences, which is crucial for various online platforms. Data\nsparsity remains a significant challenge in this area as most users have\nlimited interactions and many items receive little attention. To mitigate this\nissue, contrastive learning has been widely adopted. By constructing positive\nsample pairs from the data itself and maximizing their agreement in the\nembedding space,it can leverage available data more effectively. Constructing\nreasonable positive sample pairs is crucial for the success of contrastive\nlearning. However, current approaches struggle to generate reliable positive\npairs as they either rely on representations learned from inherently sparse\ncollaborative signals or use random perturbations which introduce significant\nuncertainty. To address these limitations, we propose a novel approach named\nSemantic Retrieval Augmented Contrastive Learning (SRA-CL), which leverages\nsemantic information to improve the reliability of contrastive samples. SRA-CL\ncomprises two main components: (1) Cross-Sequence Contrastive Learning via User\nSemantic Retrieval, which utilizes large language models (LLMs) to understand\ndiverse user preferences and retrieve semantically similar users to form\nreliable positive samples through a learnable sample synthesis method; and (2)\nIntra-Sequence Contrastive Learning via Item Semantic Retrieval, which employs\nLLMs to comprehend items and retrieve similar items to perform semantic-based\nitem substitution, thereby creating semantically consistent augmented views for\ncontrastive learning. SRA-CL is plug-and-play and can be integrated into\nstandard sequential recommendation models. Extensive experiments on four public\ndatasets demonstrate the effectiveness and generalizability of the proposed\napproach.\n","authors":["Ziqiang Cui","Yunpeng Weng","Xing Tang","Xiaokun Zhang","Dugang Liu","Shiwei Li","Peiyang Liu","Bowei He","Weihong Luo","Xiuqiang He","Chen Ma"],"pdf_url":"https://arxiv.org/pdf/2503.04162v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.04141v1","updated":"2025-03-06T06:39:25Z","published":"2025-03-06T06:39:25Z","title":"HEISIR: Hierarchical Expansion of Inverted Semantic Indexing for\n  Training-free Retrieval of Conversational Data using LLMs","summary":"  The growth of conversational AI services has increased demand for effective\ninformation retrieval from dialogue data. However, existing methods often face\nchallenges in capturing semantic intent or require extensive labeling and\nfine-tuning. This paper introduces HEISIR (Hierarchical Expansion of Inverted\nSemantic Indexing for Retrieval), a novel framework that enhances semantic\nunderstanding in conversational data retrieval through optimized data\ningestion, eliminating the need for resource-intensive labeling or model\nadaptation. HEISIR implements a two-step process: (1) Hierarchical Triplets\nFormulation and (2) Adjunct Augmentation, creating semantic indices consisting\nof Subject-Verb-Object-Adjunct (SVOA) quadruplets. This structured\nrepresentation effectively captures the underlying semantic information from\ndialogue content. HEISIR achieves high retrieval performance while maintaining\nlow latency during the actual retrieval process. Our experimental results\ndemonstrate that HEISIR outperforms fine-tuned models across various embedding\ntypes and language models. Beyond improving retrieval capabilities, HEISIR also\noffers opportunities for intent and topic analysis in conversational data,\nproviding a versatile solution for dialogue systems.\n","authors":["Sangyeop Kim","Hangyeul Lee","Yohan Lee"],"pdf_url":"https://arxiv.org/pdf/2503.04141v1.pdf","comment":"Accepted by NAACL 2025 (Findings)"},{"id":"http://arxiv.org/abs/2503.05049v1","updated":"2025-03-06T23:58:01Z","published":"2025-03-06T23:58:01Z","title":"Dynamic-KGQA: A Scalable Framework for Generating Adaptive Question\n  Answering Datasets","summary":"  As question answering (QA) systems advance alongside the rapid evolution of\nfoundation models, the need for robust, adaptable, and large-scale evaluation\nbenchmarks becomes increasingly critical. Traditional QA benchmarks are often\nstatic and publicly available, making them susceptible to data contamination\nand memorization by large language models (LLMs). Consequently, static\nbenchmarks may overestimate model generalization and hinder a reliable\nassessment of real-world performance. In this work, we introduce Dynamic-KGQA,\na scalable framework for generating adaptive QA datasets from knowledge graphs\n(KGs), designed to mitigate memorization risks while maintaining statistical\nconsistency across iterations. Unlike fixed benchmarks, Dynamic-KGQA generates\na new dataset variant on every run while preserving the underlying\ndistribution, enabling fair and reproducible evaluations. Furthermore, our\nframework provides fine-grained control over dataset characteristics,\nsupporting domain-specific and topic-focused QA dataset generation.\nAdditionally, Dynamic-KGQA produces compact, semantically coherent subgraphs\nthat facilitate both training and evaluation of KGQA models, enhancing their\nability to leverage structured knowledge effectively. To align with existing\nevaluation protocols, we also provide static large-scale train/test/validation\nsplits, ensuring comparability with prior methods. By introducing a dynamic,\ncustomizable benchmarking paradigm, Dynamic-KGQA enables a more rigorous and\nadaptable evaluation of QA systems.\n","authors":["Preetam Prabhu Srikar Dammu","Himanshu Naidu","Chirag Shah"],"pdf_url":"https://arxiv.org/pdf/2503.05049v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.05037v1","updated":"2025-03-06T23:23:13Z","published":"2025-03-06T23:23:13Z","title":"Collapse of Dense Retrievers: Short, Early, and Literal Biases\n  Outranking Factual Evidence","summary":"  Dense retrieval models are commonly used in Information Retrieval (IR)\napplications, such as Retrieval-Augmented Generation (RAG). Since they often\nserve as the first step in these systems, their robustness is critical to avoid\nfailures. In this work, by repurposing a relation extraction dataset (e.g.\nRe-DocRED), we design controlled experiments to quantify the impact of\nheuristic biases, such as favoring shorter documents, in retrievers like\nDragon+ and Contriever. Our findings reveal significant vulnerabilities:\nretrievers often rely on superficial patterns like over-prioritizing document\nbeginnings, shorter documents, repeated entities, and literal matches.\nAdditionally, they tend to overlook whether the document contains the query's\nanswer, lacking deep semantic understanding. Notably, when multiple biases\ncombine, models exhibit catastrophic performance degradation, selecting the\nanswer-containing document in less than 3% of cases over a biased document\nwithout the answer. Furthermore, we show that these biases have direct\nconsequences for downstream applications like RAG, where retrieval-preferred\ndocuments can mislead LLMs, resulting in a 34% performance drop than not\nproviding any documents at all.\n","authors":["Mohsen Fayyaz","Ali Modarressi","Hinrich Schuetze","Nanyun Peng"],"pdf_url":"https://arxiv.org/pdf/2503.05037v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.04973v1","updated":"2025-03-06T21:07:41Z","published":"2025-03-06T21:07:41Z","title":"Beyond RAG: Task-Aware KV Cache Compression for Comprehensive Knowledge\n  Reasoning","summary":"  Incorporating external knowledge in large language models (LLMs) enhances\ntheir utility across diverse applications, but existing methods have\ntrade-offs. Retrieval-Augmented Generation (RAG) fetches evidence via\nsimilarity search, but key information may fall outside top ranked results.\nLong-context models can process multiple documents but are computationally\nexpensive and limited by context window size. Inspired by students condensing\nstudy material for open-book exams, we propose task-aware key-value (KV) cache\ncompression, which compresses external knowledge in a zero- or few-shot setup.\nThis enables LLMs to reason efficiently over a compacted representation of all\nrelevant information. Experiments show our approach outperforms both RAG and\ntask-agnostic compression methods. On LongBench v2, it improves accuracy by up\nto 7 absolute points over RAG with a 30x compression rate, while reducing\ninference latency from 0.43s to 0.16s. A synthetic dataset highlights that RAG\nperforms well when sparse evidence suffices, whereas task-aware compression is\nsuperior for broad knowledge tasks.\n","authors":["Giulio Corallo","Orion Weller","Fabio Petroni","Paolo Papotti"],"pdf_url":"https://arxiv.org/pdf/2503.04973v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.04972v1","updated":"2025-03-06T21:06:35Z","published":"2025-03-06T21:06:35Z","title":"Evaluating Answer Reranking Strategies in Time-sensitive Question\n  Answering","summary":"  Despite advancements in state-of-the-art models and information retrieval\ntechniques, current systems still struggle to handle temporal information and\nto correctly answer detailed questions about past events. In this paper, we\ninvestigate the impact of temporal characteristics of answers in Question\nAnswering (QA) by exploring several simple answer selection techniques. Our\nfindings emphasize the role of temporal features in selecting the most relevant\nanswers from diachronic document collections and highlight differences between\nexplicit and implicit temporal questions.\n","authors":["Mehmet Kardan","Bhawna Piryani","Adam Jatowt"],"pdf_url":"https://arxiv.org/pdf/2503.04972v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.07022v2","updated":"2025-03-06T19:31:31Z","published":"2024-10-09T16:05:16Z","title":"Exploiting Distribution Constraints for Scalable and Efficient Image\n  Retrieval","summary":"  Image retrieval is crucial in robotics and computer vision, with downstream\napplications in robot place recognition and vision-based product\nrecommendations. Modern retrieval systems face two key challenges: scalability\nand efficiency. State-of-the-art image retrieval systems train specific neural\nnetworks for each dataset, an approach that lacks scalability. Furthermore,\nsince retrieval speed is directly proportional to embedding size, existing\nsystems that use large embeddings lack efficiency. To tackle scalability,\nrecent works propose using off-the-shelf foundation models. However, these\nmodels, though applicable across datasets, fall short in achieving performance\ncomparable to that of dataset-specific models. Our key observation is that,\nwhile foundation models capture necessary subtleties for effective retrieval,\nthe underlying distribution of their embedding space can negatively impact\ncosine similarity searches. We introduce Autoencoders with Strong Variance\nConstraints (AE-SVC), which, when used for projection, significantly improves\nthe performance of foundation models. We provide an in-depth theoretical\nanalysis of AE-SVC. Addressing efficiency, we introduce Single-shot Similarity\nSpace Distillation ((SS)$_2$D), a novel approach to learn embeddings with\nadaptive sizes that offers a better trade-off between size and performance. We\nconducted extensive experiments on four retrieval datasets, including Stanford\nOnline Products (SoP) and Pittsburgh30k, using four different off-the-shelf\nfoundation models, including DinoV2 and CLIP. AE-SVC demonstrates up to a\n$16\\%$ improvement in retrieval performance, while (SS)$_2$D shows a further\n$10\\%$ improvement for smaller embedding sizes.\n","authors":["Mohammad Omama","Po-han Li","Sandeep P. Chinchali"],"pdf_url":"https://arxiv.org/pdf/2410.07022v2.pdf","comment":null}]},"2025-03-07T00:00:00Z":{"Computation and Language":[{"id":"http://arxiv.org/abs/2503.04723v2","updated":"2025-03-07T03:14:02Z","published":"2025-03-06T18:59:37Z","title":"Shifting Long-Context LLMs Research from Input to Output","summary":"  Recent advancements in long-context Large Language Models (LLMs) have\nprimarily concentrated on processing extended input contexts, resulting in\nsignificant strides in long-context comprehension. However, the equally\ncritical aspect of generating long-form outputs has received comparatively less\nattention. This paper advocates for a paradigm shift in NLP research toward\naddressing the challenges of long-output generation. Tasks such as novel\nwriting, long-term planning, and complex reasoning require models to understand\nextensive contexts and produce coherent, contextually rich, and logically\nconsistent extended text. These demands highlight a critical gap in current LLM\ncapabilities. We underscore the importance of this under-explored domain and\ncall for focused efforts to develop foundational LLMs tailored for generating\nhigh-quality, long-form outputs, which hold immense potential for real-world\napplications.\n","authors":["Yuhao Wu","Yushi Bai","Zhiqing Hu","Shangqing Tu","Ming Shan Hee","Juanzi Li","Roy Ka-Wei Lee"],"pdf_url":"https://arxiv.org/pdf/2503.04723v2.pdf","comment":"Preprint"},{"id":"http://arxiv.org/abs/2503.04685v2","updated":"2025-03-07T08:19:07Z","published":"2025-03-06T18:27:41Z","title":"DIMSUM: Discourse in Mathematical Reasoning as a Supervision Module","summary":"  We look at reasoning on GSM8k, a dataset of short texts presenting primary\nschool, math problems. We find, with Mirzadeh et al. (2024), that current LLM\nprogress on the data set may not be explained by better reasoning but by\nexposure to a broader pretraining data distribution. We then introduce a novel\ninformation source for helping models with less data or inferior training\nreason better: discourse structure. We show that discourse structure improves\nperformance for models like Llama2 13b by up to 160%. Even for models that have\nmost likely memorized the data set, adding discourse structural information to\nthe model still improves predictions and dramatically improves large model\nperformance on out of distribution examples.\n","authors":["Krish Sharma","Niyar R Barman","Akshay Chaturvedi","Nicholas Asher"],"pdf_url":"https://arxiv.org/pdf/2503.04685v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.04625v2","updated":"2025-03-07T18:13:22Z","published":"2025-03-06T17:11:51Z","title":"START: Self-taught Reasoner with Tools","summary":"  Large reasoning models (LRMs) like OpenAI-o1 and DeepSeek-R1 have\ndemonstrated remarkable capabilities in complex reasoning tasks through the\nutilization of long Chain-of-thought (CoT). However, these models often suffer\nfrom hallucinations and inefficiencies due to their reliance solely on internal\nreasoning processes. In this paper, we introduce START (Self-Taught Reasoner\nwith Tools), a novel tool-integrated long CoT reasoning LLM that significantly\nenhances reasoning capabilities by leveraging external tools. Through code\nexecution, START is capable of performing complex computations, self-checking,\nexploring diverse methods, and self-debugging, thereby addressing the\nlimitations of LRMs. The core innovation of START lies in its self-learning\nframework, which comprises two key techniques: 1) Hint-infer: We demonstrate\nthat inserting artificially designed hints (e.g., ``Wait, maybe using Python\nhere is a good idea.'') during the inference process of a LRM effectively\nstimulates its ability to utilize external tools without the need for any\ndemonstration data. Hint-infer can also serve as a simple and effective\nsequential test-time scaling method; 2) Hint Rejection Sampling Fine-Tuning\n(Hint-RFT): Hint-RFT combines Hint-infer and RFT by scoring, filtering, and\nmodifying the reasoning trajectories with tool invocation generated by a LRM\nvia Hint-infer, followed by fine-tuning the LRM. Through this framework, we\nhave fine-tuned the QwQ-32B model to achieve START. On PhD-level science QA\n(GPQA), competition-level math benchmarks (AMC23, AIME24, AIME25), and the\ncompetition-level code benchmark (LiveCodeBench), START achieves accuracy rates\nof 63.6%, 95.0%, 66.7%, 47.1%, and 47.3%, respectively. It significantly\noutperforms the base QwQ-32B and achieves performance comparable to the\nstate-of-the-art open-weight model R1-Distill-Qwen-32B and the proprietary\nmodel o1-Preview.\n","authors":["Chengpeng Li","Mingfeng Xue","Zhenru Zhang","Jiaxi Yang","Beichen Zhang","Xiang Wang","Bowen Yu","Binyuan Hui","Junyang Lin","Dayiheng Liu"],"pdf_url":"https://arxiv.org/pdf/2503.04625v2.pdf","comment":"38 pages, 5 figures and 6 tables"},{"id":"http://arxiv.org/abs/2503.02972v3","updated":"2025-03-07T09:31:42Z","published":"2025-03-04T19:57:47Z","title":"LINGOLY-TOO: Disentangling Memorisation from Reasoning with Linguistic\n  Templatisation and Orthographic Obfuscation","summary":"  Assessing the reasoning capabilities of large language models (LLMs) is\nsusceptible to overestimation due to data exposure of evaluation benchmarks. We\nintroduce a framework for producing linguistic reasoning problems that reduces\nthe effect of memorisation in model performance estimates and apply this\nframework to develop LINGOLY-TOO, a challenging benchmark for linguistic\nreasoning. By developing orthographic templates, we dynamically obfuscate the\nwriting systems of real languages to generate numerousquestion variations.\nThese variations preserve the reasoning steps required for each solution while\nreducing the likelihood of specific problem instances appearing in model\ntraining data. Our experiments demonstrate that frontier models, including\nClaud 3.7 Sonnet, o1-preview and DeepSeek R1, struggle with advanced reasoning.\nOur analysis also shows that LLMs exhibit noticeable variance in accuracy\nacross permutations of the same problem, and on average perform better on\nquestions appearing in their original orthography. Our findings highlight the\nopaque nature of response generation in LLMs and provide evidence that prior\ndata exposure contributes to over estimating the reasoning capabilities of\nfrontier models.\n","authors":["Jude Khouja","Karolina Korgul","Simi Hellsten","Lingyi Yang","Vlad Neacsu","Harry Mayne","Ryan Kearns","Andrew Bean","Adam Mahdi"],"pdf_url":"https://arxiv.org/pdf/2503.02972v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.04346v2","updated":"2025-03-07T15:13:32Z","published":"2025-03-06T11:42:03Z","title":"Adding Alignment Control to Language Models","summary":"  Post-training alignment has increasingly become a crucial factor in enhancing\nthe usability of language models (LMs). However, the strength of alignment\nvaries depending on individual preferences. This paper proposes a method to\nincorporate alignment control into a single model, referred to as CLM. This\napproach adds one identity layer preceding the initial layers and performs\npreference learning only on this layer to map unaligned input token embeddings\ninto the aligned space. Experimental results demonstrate that this efficient\nfine-tuning method performs comparable to full fine-tuning. During inference,\nthe input embeddings are processed through the aligned and unaligned layers,\nwhich are then merged through the interpolation coefficient. By controlling\nthis parameter, the alignment exhibits a clear interpolation and extrapolation\nphenomenon.\n","authors":["Wenhong Zhu","Weinan Zhang","Rui Wang"],"pdf_url":"https://arxiv.org/pdf/2503.04346v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.04150v2","updated":"2025-03-07T09:37:53Z","published":"2025-03-06T06:59:09Z","title":"Ticktack : Long Span Temporal Alignment of Large Language Models\n  Leveraging Sexagenary Cycle Time Expression","summary":"  Large language models (LLMs) suffer from temporal misalignment issues\nespecially across long span of time. The issue arises from knowing that LLMs\nare trained on large amounts of data where temporal information is rather\nsparse over long times, such as thousands of years, resulting in insufficient\nlearning or catastrophic forgetting by the LLMs. This paper proposes a\nmethodology named \"Ticktack\" for addressing the LLM's long-time span\nmisalignment in a yearly setting. Specifically, we first propose to utilize the\nsexagenary year expression instead of the Gregorian year expression employed by\nLLMs, achieving a more uniform distribution in yearly granularity. Then, we\nemploy polar coordinates to model the sexagenary cycle of 60 terms and the year\norder within each term, with additional temporal encoding to ensure LLMs\nunderstand them. Finally, we present a temporal representational alignment\napproach for post-training LLMs that effectively distinguishes time points with\nrelevant knowledge, hence improving performance on time-related tasks,\nparticularly over a long period. We also create a long time span benchmark for\nevaluation. Experimental results prove the effectiveness of our proposal.\n","authors":["Xue Han","Qian Hu","Yitong Wang","Wenchun Gao","Lianlian Zhang","Qing Wang","Lijun Mei","Chao Deng","Junlan Feng"],"pdf_url":"https://arxiv.org/pdf/2503.04150v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.04095v2","updated":"2025-03-07T05:18:44Z","published":"2025-03-06T05:08:40Z","title":"Chart-HQA: A Benchmark for Hypothetical Question Answering in Charts","summary":"  Multimodal Large Language Models (MLLMs) have garnered significant attention\nfor their strong visual-semantic understanding. Most existing chart benchmarks\nevaluate MLLMs' ability to parse information from charts to answer questions.\nHowever, they overlook the inherent output biases of MLLMs, where models rely\non their parametric memory to answer questions rather than genuinely\nunderstanding the chart content. To address this limitation, we introduce a\nnovel Chart Hypothetical Question Answering (HQA) task, which imposes\nassumptions on the same question to compel models to engage in counterfactual\nreasoning based on the chart content. Furthermore, we introduce HAI, a human-AI\ninteractive data synthesis approach that leverages the efficient text-editing\ncapabilities of LLMs alongside human expert knowledge to generate diverse and\nhigh-quality HQA data at a low cost. Using HAI, we construct Chart-HQA, a\nchallenging benchmark synthesized from publicly available data sources.\nEvaluation results on 18 MLLMs of varying model sizes reveal that current\nmodels face significant generalization challenges and exhibit imbalanced\nreasoning performance on the HQA task.\n","authors":["Xiangnan Chen","Yuancheng Fang","Qian Xiao","Juncheng Li","Jun Lin","Siliang Tang","Yi Yang","Yueting Zhuang"],"pdf_url":"https://arxiv.org/pdf/2503.04095v2.pdf","comment":"Under review"},{"id":"http://arxiv.org/abs/2402.18668v2","updated":"2025-03-07T18:57:52Z","published":"2024-02-28T19:28:27Z","title":"Simple linear attention language models balance the recall-throughput\n  tradeoff","summary":"  Recent work has shown that attention-based language models excel at recall,\nthe ability to ground generations in tokens previously seen in context.\nHowever, the efficiency of attention-based models is bottle-necked during\ninference by the KV-cache's aggressive memory consumption. In this work, we\nexplore whether we can improve language model efficiency (e.g. by reducing\nmemory consumption) without compromising on recall. By applying experiments and\ntheory to a broad set of architectures, we identify a key tradeoff between a\nmodel's state size and recall ability. We show that efficient alternatives to\nattention (e.g. H3, Mamba, RWKV) maintain a fixed-size recurrent state, but\nstruggle at recall. We propose BASED a simple architecture combining linear and\nsliding window attention. By varying BASED window size and linear attention\nfeature dimension, we can dial the state size and traverse the pareto frontier\nof the recall-memory tradeoff curve, recovering the full quality of attention\non one end and the small state size of attention-alternatives on the other. We\ntrain language models up to 1.3b parameters and show that BASED matches the\nstrongest sub-quadratic models (e.g. Mamba) in perplexity and outperforms them\non real-world recall-intensive tasks by 6.22 accuracy points. Implementations\nof linear attention are often less efficient than optimized standard attention\nimplementations. To make BASED competitive, we develop IO-aware algorithms that\nenable 24x higher throughput on language generation than FlashAttention-2, when\ngenerating 1024 tokens using 1.3b parameter models. Code for this work is\nprovided at: https://github.com/HazyResearch/based.\n","authors":["Simran Arora","Sabri Eyuboglu","Michael Zhang","Aman Timalsina","Silas Alberti","Dylan Zinsley","James Zou","Atri Rudra","Christopher R"],"pdf_url":"https://arxiv.org/pdf/2402.18668v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2406.00226v2","updated":"2025-03-07T18:48:54Z","published":"2024-05-31T23:05:04Z","title":"Entangled Relations: Leveraging NLI and Meta-analysis to Enhance\n  Biomedical Relation Extraction","summary":"  Recent research efforts have explored the potential of leveraging natural\nlanguage inference (NLI) techniques to enhance relation extraction (RE). In\nthis vein, we introduce MetaEntailRE, a novel adaptation method that harnesses\nNLI principles to enhance RE performance. Our approach follows past works by\nverbalizing relation classes into class-indicative hypotheses, aligning a\ntraditionally multi-class classification task to one of textual entailment. We\nintroduce three key enhancements: (1) Meta-class analysis which, instead of\nlabeling non-entailed premise-hypothesis pairs with the less informative\n\"neutral\" entailment label, provides additional context by analyzing\noverarching meta-relationships between classes; (2) Feasible hypothesis\nfiltering, which removes unlikely hypotheses from consideration based on domain\nknowledge derived from data; and (3) Group-based prediction selection, which\nfurther improves performance by selecting highly confident predictions.\nMetaEntailRE is conceptually simple and empirically powerful, yielding\nsignificant improvements over conventional relation extraction techniques and\nother NLI formulations. We observe surprisingly large F1 gains of 17.6 points\non BioRED and 13.4 points on ReTACRED compared to conventional methods,\nunderscoring the versatility of MetaEntailRE across both biomedical and general\ndomains.\n","authors":["William Hogan","Jingbo Shang"],"pdf_url":"https://arxiv.org/pdf/2406.00226v2.pdf","comment":"17 pages, 1 figure"},{"id":"http://arxiv.org/abs/2503.05683v1","updated":"2025-03-07T18:45:42Z","published":"2025-03-07T18:45:42Z","title":"Understanding the Limits of Lifelong Knowledge Editing in LLMs","summary":"  Keeping large language models factually up-to-date is crucial for deployment,\nyet costly retraining remains a challenge. Knowledge editing offers a promising\nalternative, but methods are only tested on small-scale or synthetic edit\nbenchmarks. In this work, we aim to bridge research into lifelong knowledge\nediting to real-world edits at practically relevant scale. We first introduce\nWikiBigEdit; a large-scale benchmark of real-world Wikidata edits, built to\nautomatically extend lifelong for future-proof benchmarking. In its first\ninstance, it includes over 500K question-answer pairs for knowledge editing\nalongside a comprehensive evaluation pipeline. Finally, we use WikiBigEdit to\nstudy existing knowledge editing techniques' ability to incorporate large\nvolumes of real-world facts and contrast their capabilities to generic\nmodification techniques such as retrieval augmentation and continual finetuning\nto acquire a complete picture of the practical extent of current lifelong\nknowledge editing.\n","authors":["Lukas Thede","Karsten Roth","Matthias Bethge","Zeynep Akata","Tom Hartvigsen"],"pdf_url":"https://arxiv.org/pdf/2503.05683v1.pdf","comment":"Preprint"},{"id":"http://arxiv.org/abs/2502.10297v2","updated":"2025-03-07T18:31:55Z","published":"2025-02-14T16:59:05Z","title":"DeltaProduct: Increasing the Expressivity of DeltaNet Through Products\n  of Householders","summary":"  Linear Recurrent Neural Networks (linear RNNs) have emerged as competitive\nalternatives to Transformers for sequence modeling, offering efficient training\nand linear-time inference. However, existing architectures face a fundamental\ntrade-off between expressivity and efficiency, dictated by the structure of\ntheir state-transition matrices. While diagonal matrices used in architectures\nlike Mamba, GLA, or mLSTM yield fast runtime, they suffer from severely limited\nexpressivity. To address this, recent architectures such as (Gated) DeltaNet\nand RWKVv7 adopted a diagonal plus rank-1 structure, allowing simultaneous\ntoken-channel mixing, which overcomes some expressivity limitations with only a\nslight decrease in training efficiency. Building on the interpretation of\nDeltaNet's recurrence as performing one step of online gradient descent per\ntoken on an associative recall loss, we introduce DeltaProduct, which instead\ntakes multiple ($n_h$) steps per token. This naturally leads to diagonal plus\nrank-$n_h$ state-transition matrices, formed as products of $n_h$ generalized\nHouseholder transformations, providing a tunable mechanism to balance\nexpressivity and efficiency and a stable recurrence. Through extensive\nexperiments, we demonstrate that DeltaProduct achieves superior state-tracking\nand language modeling capabilities while exhibiting significantly improved\nlength extrapolation compared to DeltaNet. Additionally, we also strengthen the\ntheoretical foundation of DeltaNet's expressivity by proving that it can solve\ndihedral group word problems in just two layers.\n","authors":["Julien Siems","Timur Carstensen","Arber Zela","Frank Hutter","Massimiliano Pontil","Riccardo Grazzi"],"pdf_url":"https://arxiv.org/pdf/2502.10297v2.pdf","comment":"Accepted at ICLR 2025 Workshop on Foundation Models in the Wild"},{"id":"http://arxiv.org/abs/2503.05641v1","updated":"2025-03-07T18:03:13Z","published":"2025-03-07T18:03:13Z","title":"Symbolic Mixture-of-Experts: Adaptive Skill-based Routing for\n  Heterogeneous Reasoning","summary":"  Combining existing pre-trained expert LLMs is a promising avenue for scalably\ntackling large-scale and diverse tasks. However, selecting experts at the task\nlevel is often too coarse-grained, as heterogeneous tasks may require different\nexpertise for each instance. To enable adaptive instance-level mixing of\npre-trained LLM experts, we propose Symbolic-MoE, a symbolic, text-based, and\ngradient-free Mixture-of-Experts framework. Symbolic-MoE takes a fine-grained\napproach to selection by emphasizing skills, e.g., algebra in math or molecular\nbiology in biomedical reasoning. We propose a skill-based recruiting strategy\nthat dynamically selects the most relevant set of expert LLMs for diverse\nreasoning tasks based on their strengths. Each selected expert then generates\nits own reasoning, resulting in k outputs from k experts, which are then\nsynthesized into a final high-quality response by an aggregator chosen based on\nits ability to integrate diverse reasoning outputs. We show that Symbolic-MoE's\ninstance-level expert selection improves performance by a large margin but --\nwhen implemented naively -- can introduce a high computational overhead due to\nthe need for constant model loading and offloading. To address this, we\nimplement a batch inference strategy that groups instances based on their\nassigned experts, loading each model only once. This allows us to integrate 16\nexpert models on 1 GPU with a time cost comparable to or better than prior\nmulti-agent baselines using 4 GPUs. Through extensive evaluations on diverse\nbenchmarks (MMLU-Pro, GPQA, AIME, and MedMCQA), we demonstrate that\nSymbolic-MoE outperforms strong LLMs like GPT4o-mini, as well as multi-agent\napproaches, with an absolute average improvement of 8.15% over the best\nmulti-agent baseline. Moreover, Symbolic-MoE removes the need for expensive\nmulti-round discussions, outperforming discussion baselines with less\ncomputation.\n","authors":["Justin Chih-Yao Chen","Sukwon Yun","Elias Stengel-Eskin","Tianlong Chen","Mohit Bansal"],"pdf_url":"https://arxiv.org/pdf/2503.05641v1.pdf","comment":"The first three authors contributed equally. Project Page:\n  https://symbolic_moe.github.io/"},{"id":"http://arxiv.org/abs/2404.00242v4","updated":"2025-03-07T17:47:42Z","published":"2024-03-30T04:34:54Z","title":"DeFT: Decoding with Flash Tree-attention for Efficient Tree-structured\n  LLM Inference","summary":"  Large language models (LLMs) are increasingly employed for complex tasks that\nprocess multiple generation calls in a tree structure with shared prefixes of\ntokens, including few-shot prompting, multi-step reasoning, speculative\ndecoding, etc. However, existing inference systems for tree-based applications\nare inefficient due to improper partitioning of queries and KV cache during\nattention calculation. This leads to two main issues: (1) a lack of memory\naccess (IO) reuse for KV cache of shared prefixes, and (2) poor load\nbalancing.As a result, there is redundant KV cache IO between GPU global memory\nand shared memory, along with low GPU utilization. To address these challenges,\nwe propose DeFT(Decoding with Flash Tree-Attention), a hardware-efficient\nattention algorithm with prefix-aware and load-balanced KV cache partitions.\nDeFT reduces the number of read/write operations of KV cache during attention\ncalculation through KV-Guided Grouping, a method that avoids repeatedly loading\nKV cache of shared prefixes in attention computation. Additionally, we propose\nFlattened Tree KV Splitting, a mechanism that ensures even distribution of the\nKV cache across partitions with little computation redundancy, enhancing GPU\nutilization during attention computations. By reducing 73-99% KV cache IO and\nnearly 100% IO for partial results during attention calculation, DeFT achieves\nup to 2.23/3.59x speedup in the end-to-end/attention latency across three\npractical tree-based workloads compared to state-of-the-art attention\nalgorithms. Our code is available at https://github.com/LINs-lab/DeFT.\n","authors":["Jinwei Yao","Kaiqi Chen","Kexun Zhang","Jiaxuan You","Binhang Yuan","Zeke Wang","Tao Lin"],"pdf_url":"https://arxiv.org/pdf/2404.00242v4.pdf","comment":"Update DeFT-v4, accepted by ICLR'25\n  (https://openreview.net/forum?id=2c7pfOqu9k). Our code is available at\n  https://github.com/LINs-lab/DeFT"},{"id":"http://arxiv.org/abs/2503.05620v1","updated":"2025-03-07T17:46:13Z","published":"2025-03-07T17:46:13Z","title":"Learning LLM Preference over Intra-Dialogue Pairs: A Framework for\n  Utterance-level Understandings","summary":"  Large language models (LLMs) have demonstrated remarkable capabilities in\nhandling complex dialogue tasks without requiring use case-specific\nfine-tuning. However, analyzing live dialogues in real-time necessitates\nlow-latency processing systems, making it impractical to deploy models with\nbillions of parameters due to latency constraints. As a result, practitioners\noften prefer smaller models with millions of parameters, trained on\nhigh-quality, human-annotated datasets. Yet, curating such datasets is both\ntime-consuming and costly. Consequently, there is a growing need to combine the\nscalability of LLM-generated labels with the precision of human annotations,\nenabling fine-tuned smaller models to achieve both higher speed and accuracy\ncomparable to larger models. In this paper, we introduce a simple yet effective\nframework to address this challenge. Our approach is specifically designed for\nper-utterance classification problems, which encompass tasks such as intent\ndetection, dialogue state tracking, and more. To mitigate the impact of\nlabeling errors from LLMs -- the primary source of inaccuracies in student\nmodels -- we propose a noise-reduced preference learning loss. Experimental\nresults demonstrate that our method significantly improves accuracy across\nutterance-level dialogue tasks, including sentiment detection (over $2\\%$),\ndialogue act classification (over $1.5\\%$), etc.\n","authors":["Xuanqing Liu","Luyang Kong","Wei Niu","Afshin Khashei","Belinda Zeng","Steve Johnson","Jon Jay","Davor Golac","Matt Pope"],"pdf_url":"https://arxiv.org/pdf/2503.05620v1.pdf","comment":"7 pages, 4 figures"},{"id":"http://arxiv.org/abs/2503.05613v1","updated":"2025-03-07T17:38:00Z","published":"2025-03-07T17:38:00Z","title":"A Survey on Sparse Autoencoders: Interpreting the Internal Mechanisms of\n  Large Language Models","summary":"  Large Language Models (LLMs) have revolutionized natural language processing,\nyet their internal mechanisms remain largely opaque. Recently, mechanistic\ninterpretability has attracted significant attention from the research\ncommunity as a means to understand the inner workings of LLMs. Among various\nmechanistic interpretability approaches, Sparse Autoencoders (SAEs) have\nemerged as a particularly promising method due to their ability to disentangle\nthe complex, superimposed features within LLMs into more interpretable\ncomponents. This paper presents a comprehensive examination of SAEs as a\npromising approach to interpreting and understanding LLMs. We provide a\nsystematic overview of SAE principles, architectures, and applications\nspecifically tailored for LLM analysis, covering theoretical foundations,\nimplementation strategies, and recent developments in sparsity mechanisms. We\nalso explore how SAEs can be leveraged to explain the internal workings of\nLLMs, steer model behaviors in desired directions, and develop more transparent\ntraining methodologies for future models. Despite the challenges that remain\naround SAE implementation and scaling, they continue to provide valuable tools\nfor understanding the internal mechanisms of large language models.\n","authors":["Dong Shu","Xuansheng Wu","Haiyan Zhao","Daking Rai","Ziyu Yao","Ninghao Liu","Mengnan Du"],"pdf_url":"https://arxiv.org/pdf/2503.05613v1.pdf","comment":"20 pages, 3 figures"},{"id":"http://arxiv.org/abs/2304.09433v3","updated":"2025-03-07T17:33:50Z","published":"2023-04-19T06:00:26Z","title":"Language Models Enable Simple Systems for Generating Structured Views of\n  Heterogeneous Data Lakes","summary":"  A long standing goal of the data management community is to develop general,\nautomated systems that ingest semi-structured documents and output queryable\ntables without human effort or domain specific customization. Given the sheer\nvariety of potential documents, state-of-the art systems make simplifying\nassumptions and use domain specific training. In this work, we ask whether we\ncan maintain generality by using large language models (LLMs). LLMs, which are\npretrained on broad data, can perform diverse downstream tasks simply\nconditioned on natural language task descriptions.\n  We propose and evaluate EVAPORATE, a simple, prototype system powered by\nLLMs. We identify two fundamentally different strategies for implementing this\nsystem: prompt the LLM to directly extract values from documents or prompt the\nLLM to synthesize code that performs the extraction. Our evaluations show a\ncost-quality tradeoff between these two approaches. Code synthesis is cheap,\nbut far less accurate than directly processing each document with the LLM. To\nimprove quality while maintaining low cost, we propose an extended code\nsynthesis implementation, EVAPORATE-CODE+, which achieves better quality than\ndirect extraction. Our key insight is to generate many candidate functions and\nensemble their extractions using weak supervision. EVAPORATE-CODE+ not only\noutperforms the state-of-the art systems, but does so using a sublinear pass\nover the documents with the LLM. This equates to a 110x reduction in the number\nof tokens the LLM needs to process, averaged across 16 real-world evaluation\nsettings of 10k documents each.\n","authors":["Simran Arora","Brandon Yang","Sabri Eyuboglu","Avanika Narayan","Andrew Hojel","Immanuel Trummer","Christopher R"],"pdf_url":"https://arxiv.org/pdf/2304.09433v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2501.06826v2","updated":"2025-03-07T17:32:57Z","published":"2025-01-12T14:39:26Z","title":"Correcting Annotator Bias in Training Data: Population-Aligned Instance\n  Replication (PAIR)","summary":"  Models trained on crowdsourced labels may not reflect broader population\nviews, because those who work as annotators do not represent the population. We\npropose Population-Aligned Instance Replication (PAIR), a method to address\nbias caused by non-representative annotator pools. Using a simulation study of\noffensive language and hate speech, we create two types of annotators with\ndifferent labeling tendencies and generate datasets with varying proportions of\nthe types. We observe that models trained on unbalanced annotator pools show\npoor calibration compared to those trained on representative data. By\nduplicating labels from underrepresented annotator groups to match population\nproportions, PAIR reduces bias without collecting additional annotations. These\nresults suggest that statistical techniques from survey research can improve\nmodel performance. We conclude with practical recommendations for improving the\nrepresentativity of training data and model performance.\n","authors":["Stephanie Eckman","Bolei Ma","Christoph Kern","Rob Chew","Barbara Plank","Frauke Kreuter"],"pdf_url":"https://arxiv.org/pdf/2501.06826v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.05592v1","updated":"2025-03-07T17:14:44Z","published":"2025-03-07T17:14:44Z","title":"R1-Searcher: Incentivizing the Search Capability in LLMs via\n  Reinforcement Learning","summary":"  Existing Large Reasoning Models (LRMs) have shown the potential of\nreinforcement learning (RL) to enhance the complex reasoning capabilities of\nLarge Language Models~(LLMs). While they achieve remarkable performance on\nchallenging tasks such as mathematics and coding, they often rely on their\ninternal knowledge to solve problems, which can be inadequate for\ntime-sensitive or knowledge-intensive questions, leading to inaccuracies and\nhallucinations. To address this, we propose \\textbf{R1-Searcher}, a novel\ntwo-stage outcome-based RL approach designed to enhance the search capabilities\nof LLMs. This method allows LLMs to autonomously invoke external search systems\nto access additional knowledge during the reasoning process. Our framework\nrelies exclusively on RL, without requiring process rewards or distillation for\na cold start. % effectively generalizing to out-of-domain datasets and\nsupporting both Base and Instruct models. Our experiments demonstrate that our\nmethod significantly outperforms previous strong RAG methods, even when\ncompared to the closed-source GPT-4o-mini.\n","authors":["Huatong Song","Jinhao Jiang","Yingqian Min","Jie Chen","Zhipeng Chen","Wayne Xin Zhao","Lei Fang","Ji-Rong Wen"],"pdf_url":"https://arxiv.org/pdf/2503.05592v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.05587v1","updated":"2025-03-07T17:11:34Z","published":"2025-03-07T17:11:34Z","title":"Quantifying the Robustness of Retrieval-Augmented Language Models\n  Against Spurious Features in Grounding Data","summary":"  Robustness has become a critical attribute for the deployment of RAG systems\nin real-world applications. Existing research focuses on robustness to explicit\nnoise (e.g., document semantics) but overlooks spurious features (a.k.a.\nimplicit noise). While previous works have explored spurious features in LLMs,\nthey are limited to specific features (e.g., formats) and narrow scenarios\n(e.g., ICL). In this work, we statistically confirm the presence of spurious\nfeatures in the RAG paradigm, a robustness problem caused by the sensitivity of\nLLMs to semantic-agnostic features. Moreover, we provide a comprehensive\ntaxonomy of spurious features and empirically quantify their impact through\ncontrolled experiments. Further analysis reveals that not all spurious features\nare harmful and they can even be beneficial sometimes. Extensive evaluation\nresults across multiple LLMs suggest that spurious features are a widespread\nand challenging problem in the field of RAG. The code and dataset will be\nreleased to facilitate future research. We release all codes and data at:\n$\\\\\\href{https://github.com/maybenotime/RAG-SpuriousFeatures}{https://github.com/maybenotime/RAG-SpuriousFeatures}$.\n","authors":["Shiping Yang","Jie Wu","Wenbiao Ding","Ning Wu","Shining Liang","Ming Gong","Hengyuan Zhang","Dongmei Zhang"],"pdf_url":"https://arxiv.org/pdf/2503.05587v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2409.08936v2","updated":"2025-03-07T17:09:02Z","published":"2024-09-13T15:55:15Z","title":"SynSUM -- Synthetic Benchmark with Structured and Unstructured Medical\n  Records","summary":"  We present the SynSUM benchmark, a synthetic dataset linking unstructured\nclinical notes to structured background variables. The dataset consists of\n10,000 artificial patient records containing tabular variables (like symptoms,\ndiagnoses and underlying conditions) and related notes describing the fictional\npatient encounter in the domain of respiratory diseases. The tabular portion of\nthe data is generated through a Bayesian network, where both the causal\nstructure between the variables and the conditional probabilities are proposed\nby an expert based on domain knowledge. We then prompt a large language model\n(GPT-4o) to generate a clinical note related to this patient encounter,\ndescribing the patient symptoms and additional context. We conduct both an\nexpert evaluation study to assess the quality of the generated notes, as well\nas running some simple predictor models on both the tabular and text portions\nof the dataset, forming a baseline for further research. The SynSUM dataset is\nprimarily designed to facilitate research on clinical information extraction in\nthe presence of tabular background variables, which can be linked through\ndomain knowledge to concepts of interest to be extracted from the text - the\nsymptoms, in the case of SynSUM. Secondary uses include research on the\nautomation of clinical reasoning over both tabular data and text, causal effect\nestimation in the presence of tabular and/or textual confounders, and\nmulti-modal synthetic data generation.\n","authors":["Paloma Rabaey","Henri Arno","Stefan Heytens","Thomas Demeester"],"pdf_url":"https://arxiv.org/pdf/2409.08936v2.pdf","comment":"The dataset can be downloaded from https://github.com/prabaey/synsum.\n  Presented at the GenAI4Health workshop at AAAI 2025"},{"id":"http://arxiv.org/abs/2410.02355v3","updated":"2025-03-07T17:06:04Z","published":"2024-10-03T10:06:27Z","title":"AlphaEdit: Null-Space Constrained Knowledge Editing for Language Models","summary":"  Large language models (LLMs) often exhibit hallucinations due to incorrect or\noutdated knowledge. Hence, model editing methods have emerged to enable\ntargeted knowledge updates. To achieve this, a prevailing paradigm is the\nlocating-then-editing approach, which first locates influential parameters and\nthen edits them by introducing a perturbation. While effective, current studies\nhave demonstrated that this perturbation inevitably disrupt the originally\npreserved knowledge within LLMs, especially in sequential editing scenarios. To\naddress this, we introduce AlphaEdit, a novel solution that projects\nperturbation onto the null space of the preserved knowledge before applying it\nto the parameters. We theoretically prove that this projection ensures the\noutput of post-edited LLMs remains unchanged when queried about the preserved\nknowledge, thereby mitigating the issue of disruption. Extensive experiments on\nvarious LLMs, including LLaMA3, GPT2-XL, and GPT-J, show that AlphaEdit boosts\nthe performance of most locating-then-editing methods by an average of 36.4%\nwith a single line of additional code for projection solely. Our code is\navailable at: https://github.com/jianghoucheng/AlphaEdit.\n","authors":["Junfeng Fang","Houcheng Jiang","Kun Wang","Yunshan Ma","Shi Jie","Xiang Wang","Xiangnan He","Tat-seng Chua"],"pdf_url":"https://arxiv.org/pdf/2410.02355v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2501.02068v2","updated":"2025-03-07T16:48:14Z","published":"2025-01-03T19:28:53Z","title":"The interplay between domain specialization and model size","summary":"  Scaling laws for language models have often focused on finding the optimal\nmodel size and token count for training from scratch. However, achieving this\noptimal balance requires significant compute resources due to the extensive\ndata demands when training models from randomly-initialized weights. Continued\npretraining offers a cost-effective alternative, leveraging the compute\ninvestment from pretrained models to incorporate new knowledge without\nrequiring extensive new data. Recent findings suggest that data quality\ninfluences constants in scaling laws, thereby altering the optimal\nparameter-token allocation ratio. Building on this insight, we investigate the\ninterplay between domain specialization and model size during continued\npretraining under compute-constrained scenarios. Our goal is to identify an\noptimal training regime for this scenario and detect patterns in this interplay\nthat can be generalized across different model sizes and domains. To compare\ngeneral and specialized training, we filtered a web-based dataset to extract\ndata from three domains: legal, medical, and accounting. We pretrained models\nwith 1.5B, 3B, 7B, and 14B parameters on both the unfiltered and filtered\ndatasets, then evaluated their performance on domain-specific exams. Results\nshow that as model size increases, specialized models outperform general models\nwhile requiring less training compute. Additionally, their growing compute\nefficiency leads to reduced forgetting of previously learned knowledge.\n","authors":["Roseval Malaquias Junior","Ramon Pires","Thales Sales Almeida","Kenzo Sakiyama","Roseli A. F. Romero","Rodrigo Nogueira"],"pdf_url":"https://arxiv.org/pdf/2501.02068v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.05565v1","updated":"2025-03-07T16:45:33Z","published":"2025-03-07T16:45:33Z","title":"Evaluating open-source Large Language Models for automated fact-checking","summary":"  The increasing prevalence of online misinformation has heightened the demand\nfor automated fact-checking solutions. Large Language Models (LLMs) have\nemerged as potential tools for assisting in this task, but their effectiveness\nremains uncertain. This study evaluates the fact-checking capabilities of\nvarious open-source LLMs, focusing on their ability to assess claims with\ndifferent levels of contextual information. We conduct three key experiments:\n(1) evaluating whether LLMs can identify the semantic relationship between a\nclaim and a fact-checking article, (2) assessing models' accuracy in verifying\nclaims when given a related fact-checking article, and (3) testing LLMs'\nfact-checking abilities when leveraging data from external knowledge sources\nsuch as Google and Wikipedia. Our results indicate that LLMs perform well in\nidentifying claim-article connections and verifying fact-checked stories but\nstruggle with confirming factual news, where they are outperformed by\ntraditional fine-tuned models such as RoBERTa. Additionally, the introduction\nof external knowledge does not significantly enhance LLMs' performance, calling\nfor more tailored approaches. Our findings highlight both the potential and\nlimitations of LLMs in automated fact-checking, emphasizing the need for\nfurther refinements before they can reliably replace human fact-checkers.\n","authors":["Nicolo' Fontana","Francesco Corso","Enrico Zuccolotto","Francesco Pierri"],"pdf_url":"https://arxiv.org/pdf/2503.05565v1.pdf","comment":"Main: 10 pages, 13 figures. Supplementary Materials: 7 pages, 29\n  figures, 1 table ### This work has been submitted to the IEEE for possible\n  publication. ###"},{"id":"http://arxiv.org/abs/2406.17975v3","updated":"2025-03-07T16:30:07Z","published":"2024-06-25T23:12:07Z","title":"SoK: Membership Inference Attacks on LLMs are Rushing Nowhere (and How\n  to Fix It)","summary":"  Whether LLMs memorize their training data and what this means, from measuring\nprivacy leakage to detecting copyright violations, has become a rapidly growing\narea of research. In the last few months, more than 10 new methods have been\nproposed to perform Membership Inference Attacks (MIAs) against LLMs. Contrary\nto traditional MIAs which rely on fixed-but randomized-records or models, these\nmethods are mostly trained and tested on datasets collected post-hoc. Sets of\nmembers and non-members, used to evaluate the MIA, are constructed using\ninformed guesses after the release of a model. This lack of randomization\nraises concerns of a distribution shift between members and non-members. In\nthis work, we first extensively review the literature on MIAs against LLMs and\nshow that, while most work focuses on sequence-level MIAs evaluated in post-hoc\nsetups, a range of target models, motivations and units of interest are\nconsidered. We then quantify distribution shifts present in 6 datasets used in\nthe literature using a model-less bag of word classifier and show that all\ndatasets constructed post-hoc suffer from strong distribution shifts. These\nshifts invalidate the claims of LLMs memorizing strongly in real-world\nscenarios and, potentially, also the methodological contributions of the recent\npapers based on these datasets. Yet, all hope might not be lost. We introduce\nimportant considerations to properly evaluate MIAs against LLMs and discuss, in\nturn, potential ways forwards: randomized test splits, injections of randomized\n(unique) sequences, randomized fine-tuning, and several post-hoc control\nmethods. While each option comes with its advantages and limitations, we\nbelieve they collectively provide solid grounds to guide MIA development and\nstudy LLM memorization. We conclude with an overview of recommended approaches\nto benchmark sequence-level and document-level MIAs against LLMs.\n","authors":["Matthieu Meeus","Igor Shilov","Shubham Jain","Manuel Faysse","Marek Rei","Yves-Alexandre de Montjoye"],"pdf_url":"https://arxiv.org/pdf/2406.17975v3.pdf","comment":"IEEE Conference on Secure and Trustworthy Machine Learning (SaTML\n  2025)"},{"id":"http://arxiv.org/abs/2503.05543v1","updated":"2025-03-07T16:15:00Z","published":"2025-03-07T16:15:00Z","title":"Pi-GPS: Enhancing Geometry Problem Solving by Unleashing the Power of\n  Diagrammatic Information","summary":"  Geometry problem solving has garnered increasing attention due to its\npotential applications in intelligent education field. Inspired by the\nobservation that text often introduces ambiguities that diagrams can clarify,\nthis paper presents Pi-GPS, a novel framework that unleashes the power of\ndiagrammatic information to resolve textual ambiguities, an aspect largely\noverlooked in prior research. Specifically, we design a micro module comprising\na rectifier and verifier: the rectifier employs MLLMs to disambiguate text\nbased on the diagrammatic context, while the verifier ensures the rectified\noutput adherence to geometric rules, mitigating model hallucinations.\nAdditionally, we explore the impact of LLMs in theorem predictor based on the\ndisambiguated formal language. Empirical results demonstrate that Pi-GPS\nsurpasses state-of-the-art models, achieving a nearly 10\\% improvement on\nGeometry3K over prior neural-symbolic approaches. We hope this work highlights\nthe significance of resolving textual ambiguity in multimodal mathematical\nreasoning, a crucial factor limiting performance.\n","authors":["Junbo Zhao","Ting Zhang","Jiayu Sun","Mi Tian","Hua Huang"],"pdf_url":"https://arxiv.org/pdf/2503.05543v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2502.19202v2","updated":"2025-03-07T16:11:10Z","published":"2025-02-26T15:09:28Z","title":"LiGT: Layout-infused Generative Transformer for Visual Question\n  Answering on Vietnamese Receipts","summary":"  Document Visual Question Answering (Document VQA) challenges multimodal\nsystems to holistically handle textual, layout, and visual modalities to\nprovide appropriate answers. Document VQA has gained popularity in recent years\ndue to the increasing amount of documents and the high demand for digitization.\nNonetheless, most of document VQA datasets are developed in high-resource\nlanguages such as English. In this paper, we present ReceiptVQA\n(\\textbf{Receipt} \\textbf{V}isual \\textbf{Q}uestion \\textbf{A}nswering), the\ninitial large-scale document VQA dataset in Vietnamese dedicated to receipts, a\ndocument kind with high commercial potentials. The dataset encompasses\n\\textbf{9,000+} receipt images and \\textbf{60,000+} manually annotated\nquestion-answer pairs. In addition to our study, we introduce LiGT\n(\\textbf{L}ayout-\\textbf{i}nfused \\textbf{G}enerative \\textbf{T}ransformer), a\nlayout-aware encoder-decoder architecture designed to leverage embedding layers\nof language models to operate layout embeddings, minimizing the use of\nadditional neural modules. Experiments on ReceiptVQA show that our architecture\nyielded promising performance, achieving competitive results compared with\noutstanding baselines. Furthermore, throughout analyzing experimental results,\nwe found evident patterns that employing encoder-only model architectures has\nconsiderable disadvantages in comparison to architectures that can generate\nanswers. We also observed that it is necessary to combine multiple modalities\nto tackle our dataset, despite the critical role of semantic understanding from\nlanguage models. We hope that our work will encourage and facilitate future\ndevelopment in Vietnamese document VQA, contributing to a diverse multimodal\nresearch community in the Vietnamese language.\n","authors":["Thanh-Phong Le","Trung Le Chi Phan","Nghia Hieu Nguyen","Kiet Van Nguyen"],"pdf_url":"https://arxiv.org/pdf/2502.19202v2.pdf","comment":"Accepted at IJDAR"},{"id":"http://arxiv.org/abs/2503.05516v1","updated":"2025-03-07T15:35:37Z","published":"2025-03-07T15:35:37Z","title":"Cognitive Bias Detection Using Advanced Prompt Engineering","summary":"  Cognitive biases, systematic deviations from rationality in judgment, pose\nsignificant challenges in generating objective content. This paper introduces a\nnovel approach for real-time cognitive bias detection in user-generated text\nusing large language models (LLMs) and advanced prompt engineering techniques.\nThe proposed system analyzes textual data to identify common cognitive biases\nsuch as confirmation bias, circular reasoning, and hidden assumption. By\ndesigning tailored prompts, the system effectively leverages LLMs' capabilities\nto both recognize and mitigate these biases, improving the quality of\nhuman-generated content (e.g., news, media, reports). Experimental results\ndemonstrate the high accuracy of our approach in identifying cognitive biases,\noffering a valuable tool for enhancing content objectivity and reducing the\nrisks of biased decision-making.\n","authors":["Frederic Lemieux","Aisha Behr","Clara Kellermann-Bryant","Zaki Mohammed"],"pdf_url":"https://arxiv.org/pdf/2503.05516v1.pdf","comment":"17 pages. 6 Figures, 2 Tables"},{"id":"http://arxiv.org/abs/2406.09760v2","updated":"2025-03-07T15:26:03Z","published":"2024-06-14T06:57:18Z","title":"Bootstrapping Language Models with DPO Implicit Rewards","summary":"  Human alignment in large language models (LLMs) is an active area of\nresearch. A recent groundbreaking work, direct preference optimization (DPO),\nhas greatly simplified the process from past work in reinforcement learning\nfrom human feedback (RLHF) by bypassing the reward learning stage in RLHF. DPO,\nafter training, provides an implicit reward model. In this work, we make a\nnovel observation that this implicit reward model can by itself be used in a\nbootstrapping fashion to further align the LLM. Our approach is to use the\nrewards from a current LLM to construct a preference dataset, which is then\nused in subsequent DPO rounds. We incorporate two refinements to further\nimprove our approach: 1) length-regularized reward shaping to make the\npreference dataset length-unbiased; 2) experience replay to enhance the quality\nof the preference dataset. Our approach, named self-alignment with DPO ImpliCit\nrEwards (DICE), shows great improvements in alignment. It achieves an increase\nof more than 8$\\\\%$ in lengthcontrolled win rate on AlpacaEval 2 for all the\ndifferent base models that we tried, without relying on external feedback. Our\ncode is available at https://github.com/sail-sg/dice.\n","authors":["Changyu Chen","Zichen Liu","Chao Du","Tianyu Pang","Qian Liu","Arunesh Sinha","Pradeep Varakantham","Min Lin"],"pdf_url":"https://arxiv.org/pdf/2406.09760v2.pdf","comment":"Accepted in ICLR 2025"},{"id":"http://arxiv.org/abs/2503.05505v1","updated":"2025-03-07T15:22:10Z","published":"2025-03-07T15:22:10Z","title":"Statistical Guarantees of Correctness Coverage for Medical\n  Multiple-Choice Question Answering","summary":"  Large language models (LLMs) are increasingly deployed in real-world\nquestion-answering (QA) applications. However, LLMs have been proven to\ngenerate hallucinations and nonfactual information, undermining their\ntrustworthiness in high-stakes medical tasks. Conformal prediction (CP) is\nwell-known to be model-agnostic and distribution-free, which creates\nstatistically rigorous prediction sets in classification tasks. In this work,\nwe for the first time adapt the CP framework to medical multiple-choice\nquestion-answering (MCQA) tasks, by correlating the nonconformity score with\nthe frequency score of correct options grounded in self-consistency theory,\nassuming no access to internal model information. Considering that the adapted\nCP framework can only control the (mis)coverage rate, we employ a risk control\nframework, which can manage task-specific metrics by devising a monotonically\ndecreasing loss function. We evaluate our framework on 3 popular medical MCQA\ndatasets utilizing 4 ``off-the-shelf'' LLMs. Empirical results demonstrate that\nwe achieve user-specified average (or marginal) error rates on the test set.\nFurthermore, we observe that the average prediction set size (APSS) on the test\nset decreases as the risk level increases, which concludes a promising\nevaluation metric for the uncertainty of LLMs.\n","authors":["Yusong Ke"],"pdf_url":"https://arxiv.org/pdf/2503.05505v1.pdf","comment":"Under Review"},{"id":"http://arxiv.org/abs/2502.08080v2","updated":"2025-03-07T15:17:43Z","published":"2025-02-12T02:54:12Z","title":"NLI under the Microscope: What Atomic Hypothesis Decomposition Reveals","summary":"  Decomposition of text into atomic propositions is a flexible framework\nallowing for the closer inspection of input and output text. We use atomic\ndecomposition of hypotheses in two natural language reasoning tasks,\ntraditional NLI and defeasible NLI, to form atomic sub-problems, or granular\ninferences that models must weigh when solving the overall problem. These\natomic sub-problems serve as a tool to further understand the structure of both\nNLI and defeasible reasoning, probe a model's consistency and understanding of\ndifferent inferences, and measure the diversity of examples in benchmark\ndatasets. Our results indicate that LLMs still struggle with logical\nconsistency on atomic NLI and defeasible NLI sub-problems. Lastly, we identify\ncritical atomic sub-problems of defeasible NLI examples, or those that most\ncontribute to the overall label, and propose a method to measure the\ninferential consistency of a model, a metric designed to capture the degree to\nwhich a model makes consistently correct or incorrect predictions about the\nsame fact under different contexts.\n","authors":["Neha Srikanth","Rachel Rudinger"],"pdf_url":"https://arxiv.org/pdf/2502.08080v2.pdf","comment":"Accepted to NAACL 2025"},{"id":"http://arxiv.org/abs/2503.05500v1","updated":"2025-03-07T15:13:58Z","published":"2025-03-07T15:13:58Z","title":"EuroBERT: Scaling Multilingual Encoders for European Languages","summary":"  General-purpose multilingual vector representations, used in retrieval,\nregression and classification, are traditionally obtained from bidirectional\nencoder models. Despite their wide applicability, encoders have been recently\novershadowed by advances in generative decoder-only models. However, many\ninnovations driving this progress are not inherently tied to decoders. In this\npaper, we revisit the development of multilingual encoders through the lens of\nthese advances, and introduce EuroBERT, a family of multilingual encoders\ncovering European and widely spoken global languages. Our models outperform\nexisting alternatives across a diverse range of tasks, spanning multilingual\ncapabilities, mathematics, and coding, and natively supporting sequences of up\nto 8,192 tokens. We also examine the design decisions behind EuroBERT, offering\ninsights into our dataset composition and training pipeline. We publicly\nrelease the EuroBERT models, including intermediate training checkpoints,\ntogether with our training framework.\n","authors":["Nicolas Boizard","Hippolyte Gisserot-Boukhlef","Duarte M. Alves","Andr Martins","Ayoub Hammal","Caio Corro","Cline Hudelot","Emmanuel Malherbe","Etienne Malaboeuf","Fanny Jourdan","Gabriel Hautreux","Joo Alves","Kevin El-Haddad","Manuel Faysse","Maxime Peyrard","Nuno M. Guerreiro","Patrick Fernandes","Ricardo Rei","Pierre Colombo"],"pdf_url":"https://arxiv.org/pdf/2503.05500v1.pdf","comment":"26 pages, 6 figures, 11 tables"},{"id":"http://arxiv.org/abs/2503.05493v1","updated":"2025-03-07T15:05:23Z","published":"2025-03-07T15:05:23Z","title":"Benchmarking LLMs in Recommendation Tasks: A Comparative Evaluation with\n  Conventional Recommenders","summary":"  In recent years, integrating large language models (LLMs) into recommender\nsystems has created new opportunities for improving recommendation quality.\nHowever, a comprehensive benchmark is needed to thoroughly evaluate and compare\nthe recommendation capabilities of LLMs with traditional recommender systems.\nIn this paper, we introduce RecBench, which systematically investigates various\nitem representation forms (including unique identifier, text, semantic\nembedding, and semantic identifier) and evaluates two primary recommendation\ntasks, i.e., click-through rate prediction (CTR) and sequential recommendation\n(SeqRec). Our extensive experiments cover up to 17 large models and are\nconducted across five diverse datasets from fashion, news, video, books, and\nmusic domains. Our findings indicate that LLM-based recommenders outperform\nconventional recommenders, achieving up to a 5% AUC improvement in the CTR\nscenario and up to a 170% NDCG@10 improvement in the SeqRec scenario. However,\nthese substantial performance gains come at the expense of significantly\nreduced inference efficiency, rendering the LLM-as-RS paradigm impractical for\nreal-time recommendation environments. We aim for our findings to inspire\nfuture research, including recommendation-specific model acceleration methods.\nWe will release our code, data, configurations, and platform to enable other\nresearchers to reproduce and build upon our experimental results.\n","authors":["Qijiong Liu","Jieming Zhu","Lu Fan","Kun Wang","Hengchang Hu","Wei Guo","Yong Liu","Xiao-Ming Wu"],"pdf_url":"https://arxiv.org/pdf/2503.05493v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.05488v1","updated":"2025-03-07T14:58:14Z","published":"2025-03-07T14:58:14Z","title":"KIEval: Evaluation Metric for Document Key Information Extraction","summary":"  Document Key Information Extraction (KIE) is a technology that transforms\nvaluable information in document images into structured data, and it has become\nan essential function in industrial settings. However, current evaluation\nmetrics of this technology do not accurately reflect the critical attributes of\nits industrial applications. In this paper, we present KIEval, a novel\napplication-centric evaluation metric for Document KIE models. Unlike prior\nmetrics, KIEval assesses Document KIE models not just on the extraction of\nindividual information (entity) but also of the structured information\n(grouping). Evaluation of structured information provides assessment of\nDocument KIE models that are more reflective of extracting grouped information\nfrom documents in industrial settings. Designed with industrial application in\nmind, we believe that KIEval can become a standard evaluation metric for\ndeveloping or applying Document KIE models in practice. The code will be\npublicly available.\n","authors":["Minsoo Khang","Sang Chul Jung","Sungrae Park","Teakgyu Hong"],"pdf_url":"https://arxiv.org/pdf/2503.05488v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2502.19723v3","updated":"2025-03-07T14:56:45Z","published":"2025-02-27T03:25:34Z","title":"CNsum:Automatic Summarization for Chinese News Text","summary":"  Obtaining valuable information from massive data efficiently has become our\nresearch goal in the era of Big Data. Text summarization technology has been\ncontinuously developed to meet this demand. Recent work has also shown that\ntransformer-based pre-trained language models have achieved great success on\nvarious tasks in Natural Language Processing (NLP). Aiming at the problem of\nChinese news text summary generation and the application of Transformer\nstructure on Chinese, this paper proposes a Chinese news text summarization\nmodel (CNsum) based on Transformer structure, and tests it on Chinese datasets\nsuch as THUCNews. The results of the conducted experiments show that CNsum\nachieves better ROUGE score than the baseline models, which verifies the\noutperformance of the model.\n","authors":["Yu Zhao","Songping Huang","Dongsheng Zhou","Zhaoyun Ding","Fei Wang","Aixin Nian"],"pdf_url":"https://arxiv.org/pdf/2502.19723v3.pdf","comment":"This withdrawal is due to the lack of authorization from all\n  co-authors for the publication of this version"},{"id":"http://arxiv.org/abs/2403.02694v4","updated":"2025-03-07T14:49:07Z","published":"2024-03-05T06:23:50Z","title":"MeanCache: User-Centric Semantic Caching for LLM Web Services","summary":"  Large Language Models (LLMs) like ChatGPT and Llama have revolutionized\nnatural language processing and search engine dynamics. However, these models\nincur exceptionally high computational costs. For instance, GPT-3 consists of\n175 billion parameters, where inference demands billions of floating-point\noperations. Caching is a natural solution to reduce LLM inference costs on\nrepeated queries, which constitute about 31% of the total queries. However,\nexisting caching methods are incapable of finding semantic similarities among\nLLM queries nor do they operate on contextual queries, leading to unacceptable\nfalse hit-and-miss rates. This paper introduces MeanCache, a user-centric\nsemantic cache for LLM-based services that identifies semantically similar\nqueries to determine cache hit or miss. Using MeanCache, the response to a\nuser's semantically similar query can be retrieved from a local cache rather\nthan re-querying the LLM, thus reducing costs, service provider load, and\nenvironmental impact. MeanCache leverages Federated Learning (FL) to\ncollaboratively train a query similarity model without violating user privacy.\nBy placing a local cache in each user's device and using FL, MeanCache reduces\nthe latency and costs and enhances model performance, resulting in lower false\nhit rates. MeanCache also encodes context chains for every cached query,\noffering a simple yet highly effective mechanism to discern contextual query\nresponses from standalone. Our experiments benchmarked against the\nstate-of-the-art caching method, reveal that MeanCache attains an approximately\n17% higher F-score and a 20% increase in precision during semantic cache\nhit-and-miss decisions while performing even better on contextual queries. It\nalso reduces the storage requirement by 83% and accelerates semantic cache\nhit-and-miss decisions by 11%.\n","authors":["Waris Gill","Mohamed Elidrisi","Pallavi Kalapatapu","Ammar Ahmed","Ali Anwar","Muhammad Ali Gulzar"],"pdf_url":"https://arxiv.org/pdf/2403.02694v4.pdf","comment":"Accepted at 2025 IEEE 39th International Parallel and Distributed\n  Processing Symposium (IPDPS)"},{"id":"http://arxiv.org/abs/2503.00435v2","updated":"2025-03-07T14:33:10Z","published":"2025-03-01T10:24:42Z","title":"AILS-NTUA at SemEval-2025 Task 8: Language-to-Code prompting and Error\n  Fixing for Tabular Question Answering","summary":"  In this paper, we present our submission to SemEval-2025 Task 8: Question\nAnswering over Tabular Data. This task, evaluated on the DataBench dataset,\nassesses Large Language Models' (LLMs) ability to answer natural language\nquestions over structured data while addressing topic diversity and table size\nlimitations in previous benchmarks. We propose a system that employs effective\nLLM prompting to translate natural language queries into executable code,\nenabling accurate responses, error correction, and interpretability. Our\napproach ranks first in both subtasks of the competition in the proprietary\nmodel category, significantly outperforming the organizer's baseline.\n","authors":["Andreas Evangelatos","Giorgos Filandrianos","Maria Lymperaiou","Athanasios Voulodimos","Giorgos Stamou"],"pdf_url":"https://arxiv.org/pdf/2503.00435v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2502.14644v2","updated":"2025-03-07T14:18:56Z","published":"2025-02-20T15:32:24Z","title":"LIFT: Improving Long Context Understanding of Large Language Models\n  through Long Input Fine-Tuning","summary":"  Long context understanding remains challenging for large language models due\nto their limited context windows. This paper presents Long Input Fine-Tuning\n(LIFT), a novel framework for long-context modeling that can improve the\nlong-context performance of arbitrary (short-context) LLMs by dynamically\nadapting model parameters based on the long input. Importantly, LIFT, rather\nthan endlessly extending the context window size to accommodate increasingly\nlonger inputs in context, chooses to store and absorb the long input in\nparameter. By fine-tuning the long input into model parameters, LIFT allows\nshort-context LLMs to answer questions even when the required information is\nnot provided in the context during inference. Furthermore, to enhance LIFT\nperformance while maintaining the original in-context learning (ICL)\ncapabilities, we introduce Gated Memory, a specialized attention adapter that\nautomatically balances long input memorization and ICL. We provide a\ncomprehensive analysis of the strengths and limitations of LIFT on long context\nunderstanding, offering valuable directions for future research.\n","authors":["Yansheng Mao","Yufei Xu","Jiaqi Li","Fanxu Meng","Haotong Yang","Zilong Zheng","Xiyuan Wang","Muhan Zhang"],"pdf_url":"https://arxiv.org/pdf/2502.14644v2.pdf","comment":"arXiv admin note: text overlap with arXiv:2412.13626"},{"id":"http://arxiv.org/abs/2503.05447v1","updated":"2025-03-07T14:17:45Z","published":"2025-03-07T14:17:45Z","title":"Linear-MoE: Linear Sequence Modeling Meets Mixture-of-Experts","summary":"  Linear Sequence Modeling (LSM) like linear attention, state space models and\nlinear RNNs, and Mixture-of-Experts (MoE) have recently emerged as significant\narchitectural improvements. In this paper, we introduce Linear-MoE, a\nproduction-level system for modeling and training large-scale models that\nintegrate LSM with MoE. Linear-MoE leverages the advantages of both LSM modules\nfor linear-complexity sequence modeling and MoE layers for sparsely activation,\naiming to offer high performance with efficient training. The Linear-MoE system\ncomprises: 1) Modeling subsystem, which provides a unified framework supporting\nall instances of LSM. and 2) Training subsystem, which facilitates efficient\ntraining by incorporating various advanced parallelism technologies,\nparticularly Sequence Parallelism designed for Linear-MoE models. Additionally,\nwe explore hybrid models that combine Linear-MoE layers with standard\nTransformer-MoE layers with its Sequence Parallelism to further enhance model\nflexibility and performance. Evaluations on two model series, A0.3B-2B and\nA1B-7B, demonstrate Linear-MoE achieves efficiency gains while maintaining\ncompetitive performance on various benchmarks, showcasing its potential as a\nnext-generation foundational model architecture. Code:\nhttps://github.com/OpenSparseLLMs/Linear-MoE.\n","authors":["Weigao Sun","Disen Lan","Tong Zhu","Xiaoye Qu","Yu Cheng"],"pdf_url":"https://arxiv.org/pdf/2503.05447v1.pdf","comment":"Technical report, 17 pages"},{"id":"http://arxiv.org/abs/2503.05439v1","updated":"2025-03-07T14:10:10Z","published":"2025-03-07T14:10:10Z","title":"An Empirical Study of Conformal Prediction in LLM with ASP Scaffolds for\n  Robust Reasoning","summary":"  In this paper, we examine the use of Conformal Language Modelling (CLM)\nalongside Answer Set Programming (ASP) to enhance the performance of standard\nopen-weight LLMs on complex multi-step reasoning tasks. Using the StepGame\ndataset, which requires spatial reasoning, we apply CLM to generate sets of ASP\nprograms from an LLM, providing statistical guarantees on the correctness of\nthe outputs. Experimental results show that CLM significantly outperforms\nbaseline models that use standard sampling methods, achieving substantial\naccuracy improvements across different levels of reasoning complexity.\nAdditionally, the LLM-as-Judge metric enhances CLM's performance, especially in\nassessing structurally and logically correct ASP outputs. However, calibrating\nCLM with diverse calibration sets did not improve generalizability for tasks\nrequiring much longer reasoning steps, indicating limitations in handling more\ncomplex tasks.\n","authors":["Navdeep Kaur","Lachlan McPheat","Alessandra Russo","Anthony G Cohn","Pranava Madhyastha"],"pdf_url":"https://arxiv.org/pdf/2503.05439v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2502.20576v2","updated":"2025-03-07T13:35:33Z","published":"2025-02-27T22:35:31Z","title":"ECCOS: Efficient Capability and Cost Coordinated Scheduling for\n  Multi-LLM Serving","summary":"  As large language models (LLMs) are increasingly deployed as service\nendpoints in systems, the surge in query volume creates significant scheduling\nchallenges. Existing scheduling frameworks mainly target at latency\noptimization while neglecting the capability of LLMs to serve different level\nof queries, which could lead to computational resource waste. This paper\naddresses this challenge by proposing a capability-cost coordinated scheduling\nframework, ECCOS, for multi-LLM serving, which explicitly constrains response\nquality and workload to optimize LLM inference cost. Specifically, it\nintroduces the two-stage scheduling by designing a multi-objective predictor\nand a constrained optimizer. The predictor estimates both model capabilities\nand computational costs through training-based and retrieval-based approaches,\nwhile the optimizer determines cost-optimal assignments under quality and\nworkload constraints. It also introduces QAServe, a dataset collected for\nsample-wise response quality and costs by zero-shot prompting different LLMs on\nknowledge QA and mathematical reasoning. Extensive experiments demonstrate that\nECCOS improves success rates by 6.30% while reducing costs by 10.15% compared\nto existing methods, consuming less than 0.5% of LLM response time. The code is\navailable at: https://github.com/agiresearch/ECCOS.\n","authors":["Kai Mei","Wujiang Xu","Shuhang Lin","Yongfeng Zhang"],"pdf_url":"https://arxiv.org/pdf/2502.20576v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.05397v1","updated":"2025-03-07T13:20:12Z","published":"2025-03-07T13:20:12Z","title":"Multi Agent based Medical Assistant for Edge Devices","summary":"  Large Action Models (LAMs) have revolutionized intelligent automation, but\ntheir application in healthcare faces challenges due to privacy concerns,\nlatency, and dependency on internet access. This report introduces an ondevice,\nmulti-agent healthcare assistant that overcomes these limitations. The system\nutilizes smaller, task-specific agents to optimize resources, ensure\nscalability and high performance. Our proposed system acts as a one-stop\nsolution for health care needs with features like appointment booking, health\nmonitoring, medication reminders, and daily health reporting. Powered by the\nQwen Code Instruct 2.5 7B model, the Planner and Caller Agents achieve an\naverage RougeL score of 85.5 for planning and 96.5 for calling for our tasks\nwhile being lightweight for on-device deployment. This innovative approach\ncombines the benefits of ondevice systems with multi-agent architectures,\npaving the way for user-centric healthcare solutions.\n","authors":["Sakharam Gawade","Shivam Akhouri","Chinmay Kulkarni","Jagdish Samant","Pragya Sahu"," Aastik","Jai Pahal","Saswat Meher"],"pdf_url":"https://arxiv.org/pdf/2503.05397v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2409.02645v2","updated":"2025-03-07T12:39:10Z","published":"2024-09-04T12:22:05Z","title":"Emergent Language: A Survey and Taxonomy","summary":"  The field of emergent language represents a novel area of research within the\ndomain of artificial intelligence, particularly within the context of\nmulti-agent reinforcement learning. Although the concept of studying language\nemergence is not new, early approaches were primarily concerned with explaining\nhuman language formation, with little consideration given to its potential\nutility for artificial agents. In contrast, studies based on reinforcement\nlearning aim to develop communicative capabilities in agents that are\ncomparable to or even superior to human language. Thus, they extend beyond the\nlearned statistical representations that are common in natural language\nprocessing research. This gives rise to a number of fundamental questions, from\nthe prerequisites for language emergence to the criteria for measuring its\nsuccess. This paper addresses these questions by providing a comprehensive\nreview of 181 scientific publications on emergent language in artificial\nintelligence. Its objective is to serve as a reference for researchers\ninterested in or proficient in the field. Consequently, the main contributions\nare the definition and overview of the prevailing terminology, the analysis of\nexisting evaluation methods and metrics, and the description of the identified\nresearch gaps.\n","authors":["Jannik Peters","Constantin Waubert de Puiseau","Hasan Tercan","Arya Gopikrishnan","Gustavo Adolpho Lucas De Carvalho","Christian Bitter","Tobias Meisen"],"pdf_url":"https://arxiv.org/pdf/2409.02645v2.pdf","comment":"published in Journal of Autonomous Agents and Multi-Agent Systems"},{"id":"http://arxiv.org/abs/2503.05373v1","updated":"2025-03-07T12:29:21Z","published":"2025-03-07T12:29:21Z","title":"Leveraging Semantic Type Dependencies for Clinical Named Entity\n  Recognition","summary":"  Previous work on clinical relation extraction from free-text sentences\nleveraged information about semantic types from clinical knowledge bases as a\npart of entity representations. In this paper, we exploit additional evidence\nby also making use of domain-specific semantic type dependencies. We encode the\nrelation between a span of tokens matching a Unified Medical Language System\n(UMLS) concept and other tokens in the sentence. We implement our method and\ncompare against different named entity recognition (NER) architectures (i.e.,\nBiLSTM-CRF and BiLSTM-GCN-CRF) using different pre-trained clinical embeddings\n(i.e., BERT, BioBERT, UMLSBert). Our experimental results on clinical datasets\nshow that in some cases NER effectiveness can be significantly improved by\nmaking use of domain-specific semantic type dependencies. Our work is also the\nfirst study generating a matrix encoding to make use of more than three\ndependencies in one pass for the NER task.\n","authors":["Linh Le","Guido Zuccon","Gianluca Demartini","Genghong Zhao","Xia Zhang"],"pdf_url":"https://arxiv.org/pdf/2503.05373v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.05371v1","updated":"2025-03-07T12:25:29Z","published":"2025-03-07T12:25:29Z","title":"Shifting Perspectives: Steering Vector Ensembles for Robust Bias\n  Mitigation in LLMs","summary":"  We present a novel approach to bias mitigation in large language models\n(LLMs) by applying steering vectors to modify model activations in forward\npasses. We employ Bayesian optimization to systematically identify effective\ncontrastive pair datasets across nine bias axes. When optimized on the BBQ\ndataset, our individually tuned steering vectors achieve average improvements\nof 12.2%, 4.7%, and 3.2% over the baseline for Mistral, Llama, and Qwen,\nrespectively. Building on these promising results, we introduce Steering Vector\nEnsembles (SVE), a method that averages multiple individually optimized\nsteering vectors, each targeting a specific bias axis such as age, race, or\ngender. By leveraging their collective strength, SVE outperforms individual\nsteering vectors in both bias reduction and maintaining model performance. The\nwork presents the first systematic investigation of steering vectors for bias\nmitigation, and we demonstrate that SVE is a powerful and computationally\nefficient strategy for reducing bias in LLMs, with broader implications for\nenhancing AI safety.\n","authors":["Zara Siddique","Irtaza Khalid","Liam D. Turner","Luis Espinosa-Anke"],"pdf_url":"https://arxiv.org/pdf/2503.05371v1.pdf","comment":"Submitted to ACL 2025"},{"id":"http://arxiv.org/abs/2503.05362v1","updated":"2025-03-07T12:07:59Z","published":"2025-03-07T12:07:59Z","title":"Chain of Strategy Optimization Makes Large Language Models Better\n  Emotional Supporter","summary":"  The growing emotional stress in modern society has increased the demand for\nEmotional Support Conversations (ESC). While Large Language Models (LLMs) show\npromise for ESC, they face two key challenges: (1) low strategy selection\naccuracy, and (2) preference bias, limiting their adaptability to emotional\nneeds of users. Existing supervised fine-tuning (SFT) struggles to address\nthese issues, as it rigidly trains models on single gold-standard responses\nwithout modeling nuanced strategy trade-offs. To overcome these limitations, we\npropose Chain-of-Strategy Optimization (CSO), a novel approach that optimizes\nstrategy selection preferences at each dialogue turn. We first leverage Monte\nCarlo Tree Search to construct ESC-Pro, a high-quality preference dataset with\nturn-level strategy-response pairs. Training on ESC-Pro with CSO improves both\nstrategy accuracy and bias mitigation, enabling LLMs to generate more\nempathetic and contextually appropriate responses. Experiments on LLaMA-3.1-8B,\nGemma-2-9B, and Qwen2.5-7B demonstrate that CSO outperforms standard SFT,\nhighlighting the efficacy of fine-grained, turn-level preference modeling in\nESC.\n","authors":["Weixiang Zhao","Xingyu Sui","Xinyang Han","Yang Deng","Yulin Hu","Jiahe Guo","Libo Qin","Qianyun Du","Shijin Wang","Yanyan Zhao","Bing Qin","Ting Liu"],"pdf_url":"https://arxiv.org/pdf/2503.05362v1.pdf","comment":"19 pages, 9 figures, 15 tables"},{"id":"http://arxiv.org/abs/2503.05357v1","updated":"2025-03-07T12:01:02Z","published":"2025-03-07T12:01:02Z","title":"Improving Hate Speech Classification with Cross-Taxonomy Dataset\n  Integration","summary":"  Algorithmic hate speech detection faces significant challenges due to the\ndiverse definitions and datasets used in research and practice. Social media\nplatforms, legal frameworks, and institutions each apply distinct yet\noverlapping definitions, complicating classification efforts. This study\naddresses these challenges by demonstrating that existing datasets and\ntaxonomies can be integrated into a unified model, enhancing prediction\nperformance and reducing reliance on multiple specialized classifiers. The work\nintroduces a universal taxonomy and a hate speech classifier capable of\ndetecting a wide range of definitions within a single framework. Our approach\nis validated by combining two widely used but differently annotated datasets,\nshowing improved classification performance on an independent test set. This\nwork highlights the potential of dataset and taxonomy integration in advancing\nhate speech detection, increasing efficiency, and ensuring broader\napplicability across contexts.\n","authors":["Jan Fillies","Adrian Paschke"],"pdf_url":"https://arxiv.org/pdf/2503.05357v1.pdf","comment":"Accepted for publication at LaTeCH-CLfL 2025. The 9th Joint ACL\n  Special Interest Group on Language Technologies for the Socio-Economic\n  Sciences and Humanities (SIGHUM) Workshop on Computational Linguistics for\n  Cultural Heritage, Social Sciences, Humanities and Literature"},{"id":"http://arxiv.org/abs/2412.10121v2","updated":"2025-03-07T11:54:22Z","published":"2024-12-13T13:06:58Z","title":"Familiarity: Better Evaluation of Zero-Shot Named Entity Recognition by\n  Quantifying Label Shifts in Synthetic Training Data","summary":"  Zero-shot named entity recognition (NER) is the task of detecting named\nentities of specific types (such as 'Person' or 'Medicine') without any\ntraining examples. Current research increasingly relies on large synthetic\ndatasets, automatically generated to cover tens of thousands of distinct entity\ntypes, to train zero-shot NER models. However, in this paper, we find that\nthese synthetic datasets often contain entity types that are semantically\nhighly similar to (or even the same as) those in standard evaluation\nbenchmarks. Because of this overlap, we argue that reported F1 scores for\nzero-shot NER overestimate the true capabilities of these approaches. Further,\nwe argue that current evaluation setups provide an incomplete picture of\nzero-shot abilities since they do not quantify the label shift (i.e., the\nsimilarity of labels) between training and evaluation datasets. To address\nthese issues, we propose Familiarity, a novel metric that captures both the\nsemantic similarity between entity types in training and evaluation, as well as\ntheir frequency in the training data, to provide an estimate of label shift. It\nallows researchers to contextualize reported zero-shot NER scores when using\ncustom synthetic training datasets. Further, it enables researchers to generate\nevaluation setups of various transfer difficulties for fine-grained analysis of\nzero-shot NER.\n","authors":["Jonas Golde","Patrick Haller","Max Ploner","Fabio Barth","Nicolaas Jedema","Alan Akbik"],"pdf_url":"https://arxiv.org/pdf/2412.10121v2.pdf","comment":"9 pages, 4 figures, 5 tables"},{"id":"http://arxiv.org/abs/2503.05347v1","updated":"2025-03-07T11:42:22Z","published":"2025-03-07T11:42:22Z","title":"GEMA-Score: Granular Explainable Multi-Agent Score for Radiology Report\n  Evaluation","summary":"  Automatic medical report generation supports clinical diagnosis, reduces the\nworkload of radiologists, and holds the promise of improving diagnosis\nconsistency. However, existing evaluation metrics primarily assess the accuracy\nof key medical information coverage in generated reports compared to\nhuman-written reports, while overlooking crucial details such as the location\nand certainty of reported abnormalities. These limitations hinder the\ncomprehensive assessment of the reliability of generated reports and pose risks\nin their selection for clinical use. Therefore, we propose a Granular\nExplainable Multi-Agent Score (GEMA-Score) in this paper, which conducts both\nobjective quantification and subjective evaluation through a large language\nmodel-based multi-agent workflow. Our GEMA-Score parses structured reports and\nemploys NER-F1 calculations through interactive exchanges of information among\nagents to assess disease diagnosis, location, severity, and uncertainty.\nAdditionally, an LLM-based scoring agent evaluates completeness, readability,\nand clinical terminology while providing explanatory feedback. Extensive\nexperiments validate that GEMA-Score achieves the highest correlation with\nhuman expert evaluations on a public dataset, demonstrating its effectiveness\nin clinical scoring (Kendall coefficient = 0.70 for Rexval dataset and Kendall\ncoefficient = 0.54 for RadEvalX dataset). The anonymous project demo is\navailable at: https://github.com/Zhenxuan-Zhang/GEMA_score.\n","authors":["Zhenxuan Zhang","Kinhei Lee","Weihang Deng","Huichi Zhou","Zihao Jin","Jiahao Huang","Zhifan Gao","Dominic C Marshall","Yingying Fang","Guang Yang"],"pdf_url":"https://arxiv.org/pdf/2503.05347v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.05346v1","updated":"2025-03-07T11:40:52Z","published":"2025-03-07T11:40:52Z","title":"AutoIOT: LLM-Driven Automated Natural Language Programming for AIoT\n  Applications","summary":"  The advent of Large Language Models (LLMs) has profoundly transformed our\nlives, revolutionizing interactions with AI and lowering the barrier to AI\nusage. While LLMs are primarily designed for natural language interaction, the\nextensive embedded knowledge empowers them to comprehend digital sensor data.\nThis capability enables LLMs to engage with the physical world through IoT\nsensors and actuators, performing a myriad of AIoT tasks. Consequently, this\nevolution triggers a paradigm shift in conventional AIoT application\ndevelopment, democratizing its accessibility to all by facilitating the design\nand development of AIoT applications via natural language. However, some\nlimitations need to be addressed to unlock the full potential of LLMs in AIoT\napplication development. First, existing solutions often require transferring\nraw sensor data to LLM servers, which raises privacy concerns, incurs high\nquery fees, and is limited by token size. Moreover, the reasoning processes of\nLLMs are opaque to users, making it difficult to verify the robustness and\ncorrectness of inference results. This paper introduces AutoIOT, an LLM-based\nautomated program generator for AIoT applications. AutoIOT enables users to\nspecify their requirements using natural language (input) and automatically\nsynthesizes interpretable programs with documentation (output). AutoIOT\nautomates the iterative optimization to enhance the quality of generated code\nwith minimum user involvement. AutoIOT not only makes the execution of AIoT\ntasks more explainable but also mitigates privacy concerns and reduces token\ncosts with local execution of synthesized programs. Extensive experiments and\nuser studies demonstrate AutoIOT's remarkable capability in program synthesis\nfor various AIoT tasks. The synthesized programs can match and even outperform\nsome representative baselines.\n","authors":["Leming Shen","Qiang Yang","Yuanqing Zheng","Mo Li"],"pdf_url":"https://arxiv.org/pdf/2503.05346v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2310.08944v3","updated":"2025-03-07T11:23:19Z","published":"2023-10-13T08:19:31Z","title":"A Confidence-based Acquisition Model for Self-supervised Active Learning\n  and Label Correction","summary":"  Supervised neural approaches are hindered by their dependence on large,\nmeticulously annotated datasets, a requirement that is particularly cumbersome\nfor sequential tasks. The quality of annotations tends to deteriorate with the\ntransition from expert-based to crowd-sourced labelling. To address these\nchallenges, we present CAMEL (Confidence-based Acquisition Model for Efficient\nself-supervised active Learning), a pool-based active learning framework\ntailored to sequential multi-output problems. CAMEL possesses two core\nfeatures: (1) it requires expert annotators to label only a fraction of a\nchosen sequence, and (2) it facilitates self-supervision for the remainder of\nthe sequence. By deploying a label correction mechanism, CAMEL can also be\nutilised for data cleaning. We evaluate CAMEL on two sequential tasks, with a\nspecial emphasis on dialogue belief tracking, a task plagued by the constraints\nof limited and noisy datasets. Our experiments demonstrate that CAMEL\nsignificantly outperforms the baselines in terms of efficiency. Furthermore,\nthe data corrections suggested by our method contribute to an overall\nimprovement in the quality of the resulting datasets.\n","authors":["Carel van Niekerk","Christian Geishauser","Michael Heck","Shutong Feng","Hsien-chin Lin","Nurul Lubis","Benjamin Ruppik","Renato Vukovic","Milica Gai"],"pdf_url":"https://arxiv.org/pdf/2310.08944v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2308.14352v2","updated":"2025-03-07T11:16:40Z","published":"2023-08-28T06:56:08Z","title":"EdgeMoE: Empowering Sparse Large Language Models on Mobile Devices","summary":"  Large language models (LLMs) such as GPTs and Mixtral-8x7B have\nrevolutionized machine intelligence due to their exceptional abilities in\ngeneric ML tasks. Transiting LLMs from datacenters to edge devices brings\nbenefits like better privacy and availability, but is challenged by their\nmassive parameter size and thus unbearable runtime costs. To this end, we\npresent EdgeMoE, an on-device inference engine for mixture-of-expert (MoE) LLMs\n-- a popular form of sparse LLM that scales its parameter size with almost\nconstant computing complexity. EdgeMoE achieves both memory- and\ncompute-efficiency by partitioning the model into the storage hierarchy:\nnon-expert weights are held in device memory; while expert weights are held on\nexternal storage and fetched to memory only when activated. This design is\nmotivated by a key observation that expert weights are bulky but infrequently\nused due to sparse activation. To further reduce the expert I/O swapping\noverhead, EdgeMoE incorporates two novel techniques: (1) expert-wise bitwidth\nadaptation that reduces the expert sizes with tolerable accuracy loss; (2)\nexpert preloading that predicts the activated experts ahead of time and\npreloads it with the compute-I/O pipeline. On popular MoE LLMs and edge\ndevices, EdgeMoE showcase significant memory savings and speedup over\ncompetitive baselines. The code is available at\nhttps://github.com/UbiquitousLearning/mllm.\n","authors":["Rongjie Yi","Liwei Guo","Shiyun Wei","Ao Zhou","Shangguang Wang","Mengwei Xu"],"pdf_url":"https://arxiv.org/pdf/2308.14352v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.05330v1","updated":"2025-03-07T11:15:36Z","published":"2025-03-07T11:15:36Z","title":"Speculative Decoding for Multi-Sample Inference","summary":"  We propose a novel speculative decoding method tailored for multi-sample\nreasoning scenarios, such as self-consistency and Best-of-N sampling. Our\nmethod exploits the intrinsic consensus of parallel generation paths to\nsynthesize high-quality draft tokens without requiring auxiliary models or\nexternal databases. By dynamically analyzing structural patterns across\nparallel reasoning paths through a probabilistic aggregation mechanism, it\nidentifies consensus token sequences that align with the decoding distribution.\nEvaluations on mathematical reasoning benchmarks demonstrate a substantial\nimprovement in draft acceptance rates over baselines, while reducing the\nlatency in draft token construction. This work establishes a paradigm shift for\nefficient multi-sample inference, enabling seamless integration of speculative\ndecoding with sampling-based reasoning techniques.\n","authors":["Yiwei Li","Jiayi Shi","Shaoxiong Feng","Peiwen Yuan","Xinglin Wang","Yueqi Zhang","Ji Zhang","Chuyi Tan","Boyuan Pan","Yao Hu","Kan Li"],"pdf_url":"https://arxiv.org/pdf/2503.05330v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.05328v1","updated":"2025-03-07T11:13:33Z","published":"2025-03-07T11:13:33Z","title":"Dynamic Knowledge Integration for Evidence-Driven Counter-Argument\n  Generation with Large Language Models","summary":"  This paper investigates the role of dynamic external knowledge integration in\nimproving counter-argument generation using Large Language Models (LLMs). While\nLLMs have shown promise in argumentative tasks, their tendency to generate\nlengthy, potentially unfactual responses highlights the need for more\ncontrolled and evidence-based approaches. We introduce a new manually curated\ndataset of argument and counter-argument pairs specifically designed to balance\nargumentative complexity with evaluative feasibility. We also propose a new\nLLM-as-a-Judge evaluation methodology that shows a stronger correlation with\nhuman judgments compared to traditional reference-based metrics. Our\nexperimental results demonstrate that integrating dynamic external knowledge\nfrom the web significantly improves the quality of generated counter-arguments,\nparticularly in terms of relatedness, persuasiveness, and factuality. The\nfindings suggest that combining LLMs with real-time external knowledge\nretrieval offers a promising direction for developing more effective and\nreliable counter-argumentation systems.\n","authors":["Anar Yeginbergen","Maite Oronoz","Rodrigo Agerri"],"pdf_url":"https://arxiv.org/pdf/2503.05328v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2408.02361v2","updated":"2025-03-07T11:12:17Z","published":"2024-08-05T10:10:01Z","title":"Dialogue Ontology Relation Extraction via Constrained Chain-of-Thought\n  Decoding","summary":"  State-of-the-art task-oriented dialogue systems typically rely on\ntask-specific ontologies for fulfilling user queries. The majority of\ntask-oriented dialogue data, such as customer service recordings, comes without\nontology and annotation. Such ontologies are normally built manually, limiting\nthe application of specialised systems. Dialogue ontology construction is an\napproach for automating that process and typically consists of two steps: term\nextraction and relation extraction. In this work, we focus on relation\nextraction in a transfer learning set-up. To improve the generalisation, we\npropose an extension to the decoding mechanism of large language models. We\nadapt Chain-of-Thought (CoT) decoding, recently developed for reasoning\nproblems, to generative relation extraction. Here, we generate multiple\nbranches in the decoding space and select the relations based on a confidence\nthreshold. By constraining the decoding to ontology terms and relations, we aim\nto decrease the risk of hallucination. We conduct extensive experimentation on\ntwo widely used datasets and find improvements in performance on target\nontology for source fine-tuned and one-shot prompted large language models.\n","authors":["Renato Vukovic","David Arps","Carel van Niekerk","Benjamin Matthias Ruppik","Hsien-Chin Lin","Michael Heck","Milica Gai"],"pdf_url":"https://arxiv.org/pdf/2408.02361v2.pdf","comment":"Accepted to appear at SIGDIAL 2024. 9 pages, 4 figures"},{"id":"http://arxiv.org/abs/2503.05326v1","updated":"2025-03-07T11:10:33Z","published":"2025-03-07T11:10:33Z","title":"Fine-Grained Evaluation for Implicit Discourse Relation Recognition","summary":"  Implicit discourse relation recognition is a challenging task in discourse\nanalysis due to the absence of explicit discourse connectives between spans of\ntext. Recent pre-trained language models have achieved great success on this\ntask. However, there is no fine-grained analysis of the performance of these\npre-trained language models for this task. Therefore, the difficulty and\npossible directions of this task is unclear. In this paper, we deeply analyze\nthe model prediction, attempting to find out the difficulty for the pre-trained\nlanguage models and the possible directions of this task. In addition to having\nan in-depth analysis for this task by using pre-trained language models, we\nsemi-manually annotate data to add relatively high-quality data for the\nrelations with few annotated examples in PDTB 3.0. The annotated data\nsignificantly help improve implicit discourse relation recognition for level-2\nsenses.\n","authors":["Xinyi Cai"],"pdf_url":"https://arxiv.org/pdf/2503.05326v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2502.19103v2","updated":"2025-03-07T11:05:01Z","published":"2025-02-26T12:46:36Z","title":"LongEval: A Comprehensive Analysis of Long-Text Generation Through a\n  Plan-based Paradigm","summary":"  Large Language Models (LLMs) have achieved remarkable success in various\nnatural language processing tasks, yet their ability to generate long-form\ncontent remains poorly understood and evaluated. Our analysis reveals that\ncurrent LLMs struggle with length requirements and information density in\nlong-text generation, with performance deteriorating as text length increases.\nTo quantitively locate such a performance degradation and provide further\ninsights on model development, we present LongEval, a benchmark that evaluates\nlong-text generation through both direct and plan-based generation paradigms,\ninspired by cognitive and linguistic writing models. The comprehensive\nexperiments in this work reveal interesting findings such as that while model\nsize correlates with generation ability, the small-scale model (e.g.,\nLongWriter), well-trained on long texts, has comparable performance. All code\nand datasets are released in https://github.com/Wusiwei0410/LongEval.\n","authors":["Siwei Wu","Yizhi Li","Xingwei Qu","Rishi Ravikumar","Yucheng Li","Tyler Loakman","Shanghaoran Quan","Xiaoyong Wei","Riza Batista-Navarro","Chenghua Lin"],"pdf_url":"https://arxiv.org/pdf/2502.19103v2.pdf","comment":"Under review"},{"id":"http://arxiv.org/abs/2503.05318v1","updated":"2025-03-07T10:55:12Z","published":"2025-03-07T10:55:12Z","title":"Uncertainty-Aware Decoding with Minimum Bayes Risk","summary":"  Despite their outstanding performance in the majority of scenarios,\ncontemporary language models still occasionally generate undesirable outputs,\nfor example, hallucinated text. While such behaviors have previously been\nlinked to uncertainty, there is a notable lack of methods that actively\nconsider uncertainty during text generation. In this work, we show how Minimum\nBayes Risk (MBR) decoding, which selects model generations according to an\nexpected risk, can be generalized into a principled uncertainty-aware decoding\nmethod. In short, we account for model uncertainty during decoding by\nincorporating a posterior over model parameters into MBR's computation of\nexpected risk. We show that this modified expected risk is useful for both\nchoosing outputs and deciding when to abstain from generation and can provide\nimprovements without incurring overhead. We benchmark different methods for\nlearning posteriors and show that performance improves with prediction\ndiversity. We release our code publicly.\n","authors":["Nico Daheim","Clara Meister","Thomas Mllenhoff","Iryna Gurevych"],"pdf_url":"https://arxiv.org/pdf/2503.05318v1.pdf","comment":"ICLR 2025 (Poster)"},{"id":"http://arxiv.org/abs/2503.05298v1","updated":"2025-03-07T10:23:22Z","published":"2025-03-07T10:23:22Z","title":"Coreference as an indicator of context scope in multimodal narrative","summary":"  We demonstrate that large multimodal language models differ substantially\nfrom humans in the distribution of coreferential expressions in a visual\nstorytelling task. We introduce a number of metrics to quantify the\ncharacteristics of coreferential patterns in both human- and machine-written\ntexts. Humans distribute coreferential expressions in a way that maintains\nconsistency across texts and images, interleaving references to different\nentities in a highly varied way. Machines are less able to track mixed\nreferences, despite achieving perceived improvements in generation quality.\n","authors":["Nikolai Ilinykh","Shalom Lappin","Asad Sayeed","Sharid Loiciga"],"pdf_url":"https://arxiv.org/pdf/2503.05298v1.pdf","comment":"20 pages, 4 tables"},{"id":"http://arxiv.org/abs/2410.14677v3","updated":"2025-03-07T10:17:34Z","published":"2024-10-18T17:59:57Z","title":"Are AI Detectors Good Enough? A Survey on Quality of Datasets With\n  Machine-Generated Texts","summary":"  The rapid development of autoregressive Large Language Models (LLMs) has\nsignificantly improved the quality of generated texts, necessitating reliable\nmachine-generated text detectors. A huge number of detectors and collections\nwith AI fragments have emerged, and several detection methods even showed\nrecognition quality up to 99.9% according to the target metrics in such\ncollections. However, the quality of such detectors tends to drop dramatically\nin the wild, posing a question: Are detectors actually highly trustworthy or do\ntheir high benchmark scores come from the poor quality of evaluation datasets?\nIn this paper, we emphasise the need for robust and qualitative methods for\nevaluating generated data to be secure against bias and low generalising\nability of future model. We present a systematic review of datasets from\ncompetitions dedicated to AI-generated content detection and propose methods\nfor evaluating the quality of datasets containing AI-generated fragments. In\naddition, we discuss the possibility of using high-quality generated data to\nachieve two goals: improving the training of detection models and improving the\ntraining datasets themselves. Our contribution aims to facilitate a better\nunderstanding of the dynamics between human and machine text, which will\nultimately support the integrity of information in an increasingly automated\nworld. The code is available at\nhttps://github.com/Advacheck-OU/ai-dataset-analysing.\n","authors":["German Gritsai","Anastasia Voznyuk","Andrey Grabovoy","Yury Chekhovich"],"pdf_url":"https://arxiv.org/pdf/2410.14677v3.pdf","comment":"Presented at Preventing and Detecting LLM Misinformation (PDLM) at\n  AAAI 2025"},{"id":"http://arxiv.org/abs/2502.08662v2","updated":"2025-03-07T09:55:19Z","published":"2025-02-10T09:34:15Z","title":"RoToR: Towards More Reliable Responses for Order-Invariant Inputs","summary":"  Mitigating positional bias of language models (LMs) for listwise inputs is a\nwell-known and important problem (e.g., lost-in-the-middle). While zero-shot\norder-invariant LMs have been proposed to solve this issue, their success on\npractical listwise problems has been limited. In this work, as a first\ncontribution, we identify and overcome two limitations to make zero-shot\ninvariant LMs more practical: (1) training and inference distribution mismatch\narising from modifying positional ID assignments to enforce invariance, and (2)\nfailure to adapt to a mixture of order-invariant and sensitive inputs in\npractical listwise problems. Then, to overcome these issues we propose (1)\nRoToR, a zero-shot invariant LM for genuinely order-invariant inputs with\nminimal modifications of positional IDs, and (2) Selective Routing, an adaptive\nframework that handles both order-invariant and order-sensitive inputs in\nlistwise tasks. On the Lost in the middle (LitM), Knowledge Graph QA (KGQA),\nand MMLU benchmarks, we show that RoToR with Selective Routing can effectively\nhandle practical listwise input tasks in a zero-shot manner.\n","authors":["Soyoung Yoon","Dongha Ahn","Youngwon Lee","Minkyu Jung","HyungJoo Jang","Seung-won Hwang"],"pdf_url":"https://arxiv.org/pdf/2502.08662v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.05281v1","updated":"2025-03-07T09:51:07Z","published":"2025-03-07T09:51:07Z","title":"Similarity-Based Domain Adaptation with LLMs","summary":"  Unsupervised domain adaptation leverages abundant labeled data from various\nsource domains to generalize onto unlabeled target data. Prior research has\nprimarily focused on learning domain-invariant features across the source and\ntarget domains. However, these methods often require training a model using\nsource domain data, which is time-consuming and can limit model usage for\napplications with different source data. This paper introduces a simple\nframework that utilizes the impressive generalization capabilities of Large\nLanguage Models (LLMs) for target data annotation without the need of source\nmodel training, followed by a novel similarity-based knowledge distillation\nloss. Our extensive experiments on cross-domain text classification reveal that\nour framework achieves impressive performance, specifically, 2.44\\% accuracy\nimprovement when compared to the SOTA method.\n","authors":["Jie He","Wendi Zhou","Xiang Lorraine Li","Jeff Z. Pan"],"pdf_url":"https://arxiv.org/pdf/2503.05281v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.05280v1","updated":"2025-03-07T09:49:31Z","published":"2025-03-07T09:49:31Z","title":"Revealing Hidden Mechanisms of Cross-Country Content Moderation with\n  Natural Language Processing","summary":"  The ability of Natural Language Processing (NLP) methods to categorize text\ninto multiple classes has motivated their use in online content moderation\ntasks, such as hate speech and fake news detection. However, there is limited\nunderstanding of how or why these methods make such decisions, or why certain\ncontent is moderated in the first place. To investigate the hidden mechanisms\nbehind content moderation, we explore multiple directions: 1) training\nclassifiers to reverse-engineer content moderation decisions across countries;\n2) explaining content moderation decisions by analyzing Shapley values and\nLLM-guided explanations. Our primary focus is on content moderation decisions\nmade across countries, using pre-existing corpora sampled from the Twitter\nStream Grab. Our experiments reveal interesting patterns in censored posts,\nboth across countries and over time. Through human evaluations of LLM-generated\nexplanations across three LLMs, we assess the effectiveness of using LLMs in\ncontent moderation. Finally, we discuss potential future directions, as well as\nthe limitations and ethical considerations of this work. Our code and data are\navailable at https://github.com/causalNLP/censorship\n","authors":["Neemesh Yadav","Jiarui Liu","Francesco Ortu","Roya Ensafi","Zhijing Jin","Rada Mihalcea"],"pdf_url":"https://arxiv.org/pdf/2503.05280v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.05268v1","updated":"2025-03-07T09:33:30Z","published":"2025-03-07T09:33:30Z","title":"ZOGRASCOPE: A New Benchmark for Property Graphs","summary":"  Natural language interfaces to knowledge graphs have become increasingly\nimportant in recent years, enabling easy and efficient access to structured\ndata. In particular property graphs have seen growing adoption. However, these\nkind of graphs remain relatively underrepresented in research, which has\nfocused in large part on RDF-style graphs. As a matter of fact there is a lack\nof resources for evaluating systems on property graphs, with many existing\ndatasets featuring relatively simple queries. To address this gap, we introduce\nZOGRASCOPE, a benchmark designed specifically for the cypher query language.\nThe benchmark includes a diverse set of manually annotated queries of varying\ncomplexity. We complement this paper with a set of experiments that test the\nperformance of out-of-the-box LLMs of different sizes. Our experiments show\nthat semantic parsing over graphs is still a challenging open problem that can\nnot be solved by prompting LLMs alone.\n","authors":["Francesco Cazzaro","Justin Kleindienst","Sofia Marquez","Ariadna Quattoni"],"pdf_url":"https://arxiv.org/pdf/2503.05268v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.05265v1","updated":"2025-03-07T09:30:16Z","published":"2025-03-07T09:30:16Z","title":"PhiloBERTA: A Transformer-Based Cross-Lingual Analysis of Greek and\n  Latin Lexicons","summary":"  We present PhiloBERTA, a cross-lingual transformer model that measures\nsemantic relationships between ancient Greek and Latin lexicons. Through\nanalysis of selected term pairs from classical texts, we use contextual\nembeddings and angular similarity metrics to identify precise semantic\nalignments. Our results show that etymologically related pairs demonstrate\nsignificantly higher similarity scores, particularly for abstract philosophical\nconcepts such as epist\\=em\\=e (scientia) and dikaiosyn\\=e (iustitia).\nStatistical analysis reveals consistent patterns in these relationships (p =\n0.012), with etymologically related pairs showing remarkably stable semantic\npreservation compared to control pairs. These findings establish a quantitative\nframework for examining how philosophical concepts moved between Greek and\nLatin traditions, offering new methods for classical philological research.\n","authors":["Rumi A. Allbert","Makai L. Allbert"],"pdf_url":"https://arxiv.org/pdf/2503.05265v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.23746v2","updated":"2025-03-07T09:06:03Z","published":"2024-10-31T09:01:25Z","title":"DetectRL: Benchmarking LLM-Generated Text Detection in Real-World\n  Scenarios","summary":"  Detecting text generated by large language models (LLMs) is of great recent\ninterest. With zero-shot methods like DetectGPT, detection capabilities have\nreached impressive levels. However, the reliability of existing detectors in\nreal-world applications remains underexplored. In this study, we present a new\nbenchmark, DetectRL, highlighting that even state-of-the-art (SOTA) detection\ntechniques still underperformed in this task. We collected human-written\ndatasets from domains where LLMs are particularly prone to misuse. Using\npopular LLMs, we generated data that better aligns with real-world\napplications. Unlike previous studies, we employed heuristic rules to create\nadversarial LLM-generated text, simulating various prompts usages, human\nrevisions like word substitutions, and writing noises like spelling mistakes.\nOur development of DetectRL reveals the strengths and limitations of current\nSOTA detectors. More importantly, we analyzed the potential impact of writing\nstyles, model types, attack methods, the text lengths, and real-world human\nwriting factors on different types of detectors. We believe DetectRL could\nserve as an effective benchmark for assessing detectors in real-world\nscenarios, evolving with advanced attack methods, thus providing more stressful\nevaluation to drive the development of more efficient detectors. Data and code\nare publicly available at: https://github.com/NLP2CT/DetectRL.\n","authors":["Junchao Wu","Runzhe Zhan","Derek F. Wong","Shu Yang","Xinyi Yang","Yulin Yuan","Lidia S. Chao"],"pdf_url":"https://arxiv.org/pdf/2410.23746v2.pdf","comment":"Accepted to NeurIPS 2024 Datasets and Benchmarks Track (Camera-Ready)"},{"id":"http://arxiv.org/abs/2503.01743v2","updated":"2025-03-07T09:05:58Z","published":"2025-03-03T17:05:52Z","title":"Phi-4-Mini Technical Report: Compact yet Powerful Multimodal Language\n  Models via Mixture-of-LoRAs","summary":"  We introduce Phi-4-Mini and Phi-4-Multimodal, compact yet highly capable\nlanguage and multimodal models. Phi-4-Mini is a 3.8-billion-parameter language\nmodel trained on high-quality web and synthetic data, significantly\noutperforming recent open-source models of similar size and matching the\nperformance of models twice its size on math and coding tasks requiring complex\nreasoning. This achievement is driven by a carefully curated synthetic data\nrecipe emphasizing high-quality math and coding datasets. Compared to its\npredecessor, Phi-3.5-Mini, Phi-4-Mini features an expanded vocabulary size of\n200K tokens to better support multilingual applications, as well as group query\nattention for more efficient long-sequence generation. Phi-4-Multimodal is a\nmultimodal model that integrates text, vision, and speech/audio input\nmodalities into a single model. Its novel modality extension approach leverages\nLoRA adapters and modality-specific routers to allow multiple inference modes\ncombining various modalities without interference. For example, it now ranks\nfirst in the OpenASR leaderboard to date, although the LoRA component of the\nspeech/audio modality has just 460 million parameters. Phi-4-Multimodal\nsupports scenarios involving (vision + language), (vision + speech), and\n(speech/audio) inputs, outperforming larger vision-language and speech-language\nmodels on a wide range of tasks. Additionally, we experiment to further train\nPhi-4-Mini to enhance its reasoning capabilities. Despite its compact\n3.8-billion-parameter size, this experimental version achieves reasoning\nperformance on par with or surpassing significantly larger models, including\nDeepSeek-R1-Distill-Qwen-7B and DeepSeek-R1-Distill-Llama-8B.\n","authors":[" Microsoft"," :","Abdelrahman Abouelenin","Atabak Ashfaq","Adam Atkinson","Hany Awadalla","Nguyen Bach","Jianmin Bao","Alon Benhaim","Martin Cai","Vishrav Chaudhary","Congcong Chen","Dong Chen","Dongdong Chen","Junkun Chen","Weizhu Chen","Yen-Chun Chen","Yi-ling Chen","Qi Dai","Xiyang Dai","Ruchao Fan","Mei Gao","Min Gao","Amit Garg","Abhishek Goswami","Junheng Hao","Amr Hendy","Yuxuan Hu","Xin Jin","Mahmoud Khademi","Dongwoo Kim","Young Jin Kim","Gina Lee","Jinyu Li","Yunsheng Li","Chen Liang","Xihui Lin","Zeqi Lin","Mengchen Liu","Yang Liu","Gilsinia Lopez","Chong Luo","Piyush Madan","Vadim Mazalov","Arindam Mitra","Ali Mousavi","Anh Nguyen","Jing Pan","Daniel Perez-Becker","Jacob Platin","Thomas Portet","Kai Qiu","Bo Ren","Liliang Ren","Sambuddha Roy","Ning Shang","Yelong Shen","Saksham Singhal","Subhojit Som","Xia Song","Tetyana Sych","Praneetha Vaddamanu","Shuohang Wang","Yiming Wang","Zhenghao Wang","Haibin Wu","Haoran Xu","Weijian Xu","Yifan Yang","Ziyi Yang","Donghan Yu","Ishmam Zabir","Jianwen Zhang","Li Lyna Zhang","Yunan Zhang","Xiren Zhou"],"pdf_url":"https://arxiv.org/pdf/2503.01743v2.pdf","comment":"39 pages"},{"id":"http://arxiv.org/abs/2501.13983v4","updated":"2025-03-07T09:02:42Z","published":"2025-01-23T06:57:24Z","title":"AdEval: Alignment-based Dynamic Evaluation to Mitigate Data\n  Contamination in Large Language Models","summary":"  As Large Language Models (LLMs) are pretrained on massive-scale corpora, the\nissue of data contamination has become increasingly severe, leading to\npotential overestimation of model performance during evaluation. To address\nthis, we propose AdEval (Alignment-based Dynamic Evaluation), a dynamic data\nevaluation method aimed at mitigating the impact of data contamination on\nevaluation reliability. Experimental results on multiple datasets demonstrate\nthat AdEval effectively reduces the impact of data contamination on evaluation\noutcomes, enhancing both the fairness and reliability of the evaluation\nprocess.\n","authors":["Yang Fan"],"pdf_url":"https://arxiv.org/pdf/2501.13983v4.pdf","comment":"There are serious academic problems in this paper, such as data\n  falsification and plagiarism in the method of the paper"},{"id":"http://arxiv.org/abs/2503.05244v1","updated":"2025-03-07T08:56:20Z","published":"2025-03-07T08:56:20Z","title":"WritingBench: A Comprehensive Benchmark for Generative Writing","summary":"  Recent advancements in large language models (LLMs) have significantly\nenhanced text generation capabilities, yet evaluating their performance in\ngenerative writing remains a challenge. Existing benchmarks primarily focus on\ngeneric text generation or limited in writing tasks, failing to capture the\ndiverse requirements of high-quality written contents across various domains.\nTo bridge this gap, we present WritingBench, a comprehensive benchmark designed\nto evaluate LLMs across 6 core writing domains and 100 subdomains, encompassing\ncreative, persuasive, informative, and technical writing. We further propose a\nquery-dependent evaluation framework that empowers LLMs to dynamically generate\ninstance-specific assessment criteria. This framework is complemented by a\nfine-tuned critic model for criteria-aware scoring, enabling evaluations in\nstyle, format and length. The framework's validity is further demonstrated by\nits data curation capability, which enables 7B-parameter models to approach\nstate-of-the-art (SOTA) performance. We open-source the benchmark, along with\nevaluation tools and modular framework components, to advance the development\nof LLMs in writing.\n","authors":["Yuning Wu","Jiahao Mei","Ming Yan","Chenliang Li","SHaopeng Lai","Yuran Ren","Zijia Wang","Ji Zhang","Mengyue Wu","Qin Jin","Fei Huang"],"pdf_url":"https://arxiv.org/pdf/2503.05244v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.03360v2","updated":"2025-03-07T08:55:13Z","published":"2025-03-05T10:40:09Z","title":"Transformers for molecular property prediction: Domain adaptation\n  efficiently improves performance","summary":"  Most of the current transformer-based chemical language models are\npre-trained on millions to billions of molecules. However, the improvement from\nsuch scaling in dataset size is not confidently linked to improved molecular\nproperty prediction. The aim of this study is to investigate and overcome some\nof the limitations of transformer models in predicting molecular properties.\nSpecifically, we examine the impact of pre-training dataset size and diversity\non the performance of transformer models and investigate the use of domain\nadaptation as a technique for improving model performance. First, our findings\nindicate that increasing pretraining dataset size beyond 400K molecules from\nthe GuacaMol dataset does not result in a significant improvement on four ADME\nendpoints, namely, solubility, permeability, microsomal stability, and plasma\nprotein binding. Second, our results demonstrate that using domain adaptation\nby further training the transformer model on a small set of domain-relevant\nmolecules, i.e., a few hundred to a few thousand, using multi-task regression\nof physicochemical properties was sufficient to significantly improve\nperformance for three out of the four investigated ADME endpoints (P-value <\n0.001). Finally, we observe that a model pre-trained on 400K molecules and\ndomain adopted on a few hundred/thousand molecules performs similarly (P-value\n> 0.05) to more complicated transformer models like MolBERT(pre-trained on 1.3M\nmolecules) and MolFormer (pre-trained on 100M molecules). A comparison to a\nrandom forest model trained on basic physicochemical properties showed similar\nperformance to the examined transformer models. We believe that current\ntransformer models can be improved through further systematic analysis of\npre-training and downstream data, pre-training objectives, and scaling laws,\nultimately leading to better and more helpful models.\n","authors":["Afnan Sultan","Max Rausch-Dupont","Shahrukh Khan","Olga Kalinina","Andrea Volkamer","Dietrich Klakow"],"pdf_url":"https://arxiv.org/pdf/2503.03360v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.05242v1","updated":"2025-03-07T08:53:10Z","published":"2025-03-07T08:53:10Z","title":"MM-StoryAgent: Immersive Narrated Storybook Video Generation with a\n  Multi-Agent Paradigm across Text, Image and Audio","summary":"  The rapid advancement of large language models (LLMs) and artificial\nintelligence-generated content (AIGC) has accelerated AI-native applications,\nsuch as AI-based storybooks that automate engaging story production for\nchildren. However, challenges remain in improving story attractiveness,\nenriching storytelling expressiveness, and developing open-source evaluation\nbenchmarks and frameworks. Therefore, we propose and opensource MM-StoryAgent,\nwhich creates immersive narrated video storybooks with refined plots,\nrole-consistent images, and multi-channel audio. MM-StoryAgent designs a\nmulti-agent framework that employs LLMs and diverse expert tools (generative\nmodels and APIs) across several modalities to produce expressive storytelling\nvideos. The framework enhances story attractiveness through a multi-stage\nwriting pipeline. In addition, it improves the immersive storytelling\nexperience by integrating sound effects with visual, music and narrative\nassets. MM-StoryAgent offers a flexible, open-source platform for further\ndevelopment, where generative modules can be substituted. Both objective and\nsubjective evaluation regarding textual story quality and alignment between\nmodalities validate the effectiveness of our proposed MM-StoryAgent system. The\ndemo and source code are available.\n","authors":["Xuenan Xu","Jiahao Mei","Chenliang Li","Yuning Wu","Ming Yan","Shaopeng Lai","Ji Zhang","Mengyue Wu"],"pdf_url":"https://arxiv.org/pdf/2503.05242v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2502.05605v2","updated":"2025-03-07T08:35:00Z","published":"2025-02-08T15:21:55Z","title":"ARIES: Stimulating Self-Refinement of Large Language Models by Iterative\n  Preference Optimization","summary":"  A truly intelligent Large Language Model (LLM) should be capable of\ncorrecting errors in its responses through external interactions. However, even\nthe most advanced models often face challenges in improving their outputs. In\nthis paper, we explore how to cultivate LLMs with the self-refinement\ncapability through iterative preference training, and how this ability can be\nleveraged to improve model performance during inference. To this end, we\nintroduce a novel post-training and inference framework, called ARIES: Adaptive\nRefinement and Iterative Enhancement Structure. This method iteratively\nperforms preference training and self-refinement-based data collection. During\ntraining, ARIES strengthen the model's direct question-answering capability\nwhile simultaneously unlocking its self-refinement potential. During inference,\nARIES harnesses this self-refinement capability to generate a series of\nprogressively refined responses, which are then filtered using either the\nReward Model Scoring or a simple yet effective Rule-Based Selection mechanism,\nspecifically tailored to our approach, to construct a dataset for the next\nround of preference training. Experimental results demonstrate the remarkable\nperformance of ARIES. When applied to the Llama-3.1-8B model and under the\nself-refinement setting, ARIES surpasses powerful models such as GPT-4o,\nachieving 62.3% length-controlled (LC) and a 63.3% raw win rates on AlpacaEval\n2, outperforming Iterative DPO by 27.8% and 35.5% respectively, as well as a\n50.3% win rate on Arena-Hard, surpassing Iterative DPO by 26.6%. Furthermore,\nARIES consistently enhances performance on mathematical reasoning tasks like\nGSM8K and MATH.\n","authors":["Yongcheng Zeng","Xinyu Cui","Xuanfa Jin","Guoqing Liu","Zexu Sun","Quan He","Dong Li","Ning Yang","Jianye Hao","Haifeng Zhang","Jun Wang"],"pdf_url":"https://arxiv.org/pdf/2502.05605v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.19346v2","updated":"2025-03-07T08:08:18Z","published":"2024-11-28T19:48:54Z","title":"CLIP meets DINO for Tuning Zero-Shot Classifier using Unlabeled Image\n  Collections","summary":"  In the era of foundation models, CLIP has emerged as a powerful tool for\naligning text & visual modalities into a common embedding space. However, the\nalignment objective used to train CLIP often results in subpar visual features\nfor fine-grained tasks. In contrast, SSL-pretrained models like DINO excel at\nextracting rich visual features due to their specialized training paradigm.\nYet, these SSL models require an additional supervised linear probing step,\nwhich relies on fully labeled data which is often expensive and difficult to\nobtain at scale. In this paper, we propose a label-free prompt-tuning method\nthat leverages the rich visual features of self-supervised learning models\n(DINO) and the broad textual knowledge of large language models (LLMs) to\nlargely enhance CLIP-based image classification performance using unlabeled\nimages. Our approach unfolds in three key steps: (1) We generate robust textual\nfeature embeddings that more accurately represent object classes by leveraging\nclass-specific descriptions from LLMs, enabling more effective zero-shot\nclassification compared to CLIP's default name-specific prompts. (2) These\ntextual embeddings are then used to produce pseudo-labels to train an alignment\nmodule that integrates the complementary strengths of LLM description-based\ntextual embeddings & DINO's visual features. (3) Finally, we prompt-tune CLIP's\nvision encoder through DINO-assisted supervision using the trained alignment\nmodule. This three-step process allows us to harness the best of visual &\ntextual foundation models, resulting in a powerful and efficient approach that\nsurpasses state-of-the-art label-free classification methods. Notably, our\nframework, NoLA (No Labels Attached), achieves an average absolute gain of 3.6%\nover the state-of-the-art LaFTer across 11 diverse image classification\ndatasets. Our code & models can be found at https://github.com/fazliimam/NoLA.\n","authors":["Mohamed Fazli Imam","Rufael Fedaku Marew","Jameel Hassan","Mustansar Fiaz","Alham Fikri Aji","Hisham Cholakkal"],"pdf_url":"https://arxiv.org/pdf/2411.19346v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.05213v1","updated":"2025-03-07T08:07:15Z","published":"2025-03-07T08:07:15Z","title":"Personalized Text Generation with Contrastive Activation Steering","summary":"  Personalized text generation aims to infer users' writing style preferences\nfrom their historical texts and generate outputs that faithfully reflect these\nstylistic characteristics. Existing solutions primarily adopt two paradigms:\nretrieval-augmented generation (RAG) and parameter-efficient fine-tuning\n(PEFT). While these approaches have advanced the field, they suffer from two\ncritical limitations: (1) the entanglement of content semantics and stylistic\npatterns in historical texts impedes accurate modeling of user-specific writing\npreferences; and (2) scalability challenges arising from both RAG's inference\nlatency by retrieval operations and PEFT's parameter storage requirements for\nper user model. To overcome these limitations, we propose StyleVector, a\ntraining-free framework that disentangles and represents personalized writing\nstyle as a vector in LLM's activation space, enabling style-steered generation\nduring inference without requiring costly retrieval or parameter storage.\nComprehensive experiments demonstrate that our framework achieves a significant\n8% relative improvement in personalized generation while reducing storage\nrequirements by 1700 times over PEFT method.\n","authors":["Jinghao Zhang","Yuting Liu","Wenjie Wang","Qiang Liu","Shu Wu","Liang Wang","Tat-Seng Chua"],"pdf_url":"https://arxiv.org/pdf/2503.05213v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.05212v1","updated":"2025-03-07T08:04:25Z","published":"2025-03-07T08:04:25Z","title":"Knowledge Updating? No More Model Editing! Just Selective Contextual\n  Reasoning","summary":"  As real-world knowledge evolves, the information embedded within large\nlanguage models (LLMs) can become outdated, inadequate, or erroneous. Model\nediting has emerged as a prominent approach for updating LLMs' knowledge with\nminimal computational costs and parameter changes. This approach typically\nidentifies and adjusts specific model parameters associated with newly acquired\nknowledge. However, existing methods often underestimate the adverse effects\nthat parameter modifications can have on broadly distributed knowledge. More\ncritically, post-edit LLMs frequently struggle with multi-hop reasoning and\ncontinuous knowledge updates. Although various studies have discussed these\nshortcomings, there is a lack of comprehensive evaluation. In this paper, we\nprovide an evaluation of ten model editing methods along four dimensions:\nreliability, generalization, locality, and portability. Results confirm that\nall ten popular model editing methods show significant shortcomings across\nmultiple dimensions, suggesting model editing is less promising. We then\npropose a straightforward method called Selective Contextual Reasoning (SCR),\nfor knowledge updating. SCR does not modify model parameters but harnesses\nLLM's inherent contextual reasoning capabilities utilizing the updated\nknowledge pieces. Under SCR, an LLM first assesses whether an incoming query\nfalls within the scope of an external knowledge base. If it does, the relevant\nexternal knowledge texts are contextualized to enhance reasoning; otherwise,\nthe query is answered directly. We evaluate SCR against the ten model editing\nmethods on two counterfactual datasets with three backbone LLMs. Empirical\nresults confirm the effectiveness and efficiency of contextual reasoning for\nknowledge updating.\n","authors":["Guoxiu He","Xin Song","Aixin Sun"],"pdf_url":"https://arxiv.org/pdf/2503.05212v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.05203v1","updated":"2025-03-07T07:48:30Z","published":"2025-03-07T07:48:30Z","title":"Path Pooling: Train-Free Structure Enhancement for Efficient Knowledge\n  Graph Retrieval-Augmented Generation","summary":"  Although Large Language Models achieve strong success in many tasks, they\nstill suffer from hallucinations and knowledge deficiencies in real-world\napplications. Many knowledge graph-based retrieval-augmented generation\n(KG-RAG) methods enhance the quality and credibility of LLMs by leveraging\nstructure and semantic information in KGs as external knowledge bases. However,\nthese methods struggle to effectively incorporate structure information, either\nincurring high computational costs or underutilizing available knowledge.\nInspired by smoothing operations in graph representation learning, we propose\npath pooling, a simple, train-free strategy that introduces structure\ninformation through a novel path-centric pooling operation. It seamlessly\nintegrates into existing KG-RAG methods in a plug-and-play manner, enabling\nricher structure information utilization. Extensive experiments demonstrate\nthat incorporating the path pooling into the state-of-the-art KG-RAG method\nconsistently improves performance across various settings while introducing\nnegligible additional cost. Code is coming soon at\nhttps://github.com/hrwang00/path-pooling.\n","authors":["Hairu Wang","Yuan Feng","Xike Xie","S Kevin Zhou"],"pdf_url":"https://arxiv.org/pdf/2503.05203v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.05200v1","updated":"2025-03-07T07:44:31Z","published":"2025-03-07T07:44:31Z","title":"ORANSight-2.0: Foundational LLMs for O-RAN","summary":"  Despite the transformative impact of Large Language Models (LLMs) across\ncritical domains such as healthcare, customer service, and business marketing,\ntheir integration into Open Radio Access Networks (O-RAN) remains limited. This\ngap is primarily due to the absence of domain-specific foundational models,\nwith existing solutions often relying on general-purpose LLMs that fail to\naddress the unique challenges and technical intricacies of O-RAN. To bridge\nthis gap, we introduce ORANSight-2.0 (O-RAN Insights), a pioneering initiative\naimed at developing specialized foundational LLMs tailored for O-RAN. Built on\n18 LLMs spanning five open-source LLM frameworks, ORANSight-2.0 fine-tunes\nmodels ranging from 1 to 70B parameters, significantly reducing reliance on\nproprietary, closed-source models while enhancing performance for O-RAN. At the\ncore of ORANSight-2.0 is RANSTRUCT, a novel Retrieval-Augmented Generation\n(RAG) based instruction-tuning framework that employs two LLM agents to create\nhigh-quality instruction-tuning datasets. The generated dataset is then used to\nfine-tune the 18 pre-trained open-source LLMs via QLoRA. To evaluate\nORANSight-2.0, we introduce srsRANBench, a novel benchmark designed for code\ngeneration and codebase understanding in the context of srsRAN, a widely used\n5G O-RAN stack. We also leverage ORANBench13K, an existing benchmark for\nassessing O-RAN-specific knowledge. Our comprehensive evaluations demonstrate\nthat ORANSight-2.0 models outperform general-purpose and closed-source models,\nsuch as ChatGPT-4o and Gemini, by 5.421% on ORANBench and 18.465% on\nsrsRANBench, achieving superior performance while maintaining lower\ncomputational and energy costs. We also experiment with RAG-augmented variants\nof ORANSight-2.0 LLMs and thoroughly evaluate their energy characteristics,\ndemonstrating costs for training, standard inference, and RAG-augmented\ninference.\n","authors":["Pranshav Gajjar","Vijay K. Shah"],"pdf_url":"https://arxiv.org/pdf/2503.05200v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.05193v1","updated":"2025-03-07T07:28:32Z","published":"2025-03-07T07:28:32Z","title":"Memory-augmented Query Reconstruction for LLM-based Knowledge Graph\n  Reasoning","summary":"  Large language models (LLMs) have achieved remarkable performance on\nknowledge graph question answering (KGQA) tasks by planning and interacting\nwith knowledge graphs. However, existing methods often confuse tool utilization\nwith knowledge reasoning, harming readability of model outputs and giving rise\nto hallucinatory tool invocations, which hinder the advancement of KGQA. To\naddress this issue, we propose Memory-augmented Query Reconstruction for\nLLM-based Knowledge Graph Reasoning (MemQ) to decouple LLM from tool invocation\ntasks using LLM-built query memory. By establishing a memory module with\nexplicit descriptions of query statements, the proposed MemQ facilitates the\nKGQA process with natural language reasoning and memory-augmented query\nreconstruction. Meanwhile, we design an effective and readable reasoning to\nenhance the LLM's reasoning capability in KGQA. Experimental results that MemQ\nachieves state-of-the-art performance on widely used benchmarks WebQSP and CWQ.\n","authors":["Mufan Xu","Gewen Liang","Kehai Chen","Wei Wang","Xun Zhou","Muyun Yang","Tiejun Zhao","Min Zhang"],"pdf_url":"https://arxiv.org/pdf/2503.05193v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.05188v1","updated":"2025-03-07T07:20:24Z","published":"2025-03-07T07:20:24Z","title":"Rewarding Curse: Analyze and Mitigate Reward Modeling Issues for LLM\n  Reasoning","summary":"  Chain-of-thought (CoT) prompting demonstrates varying performance under\ndifferent reasoning tasks. Previous work attempts to evaluate it but falls\nshort in providing an in-depth analysis of patterns that influence the CoT. In\nthis paper, we study the CoT performance from the perspective of effectiveness\nand faithfulness. For the former, we identify key factors that influence CoT\neffectiveness on performance improvement, including problem difficulty,\ninformation gain, and information flow. For the latter, we interpret the\nunfaithful CoT issue by conducting a joint analysis of the information\ninteraction among the question, CoT, and answer. The result demonstrates that,\nwhen the LLM predicts answers, it can recall correct information missing in the\nCoT from the question, leading to the problem. Finally, we propose a novel\nalgorithm to mitigate this issue, in which we recall extra information from the\nquestion to enhance the CoT generation and evaluate CoTs based on their\ninformation gain. Extensive experiments demonstrate that our approach enhances\nboth the faithfulness and effectiveness of CoT.\n","authors":["Jiachun Li","Pengfei Cao","Yubo Chen","Jiexin Xu","Huaijun Li","Xiaojian Jiang","Kang Liu","Jun Zhao"],"pdf_url":"https://arxiv.org/pdf/2503.05188v1.pdf","comment":"18 pages, 21 figures"},{"id":"http://arxiv.org/abs/2412.12643v2","updated":"2025-03-07T07:14:33Z","published":"2024-12-17T08:07:16Z","title":"LLM-based Discriminative Reasoning for Knowledge Graph Question\n  Answering","summary":"  Large language models (LLMs) based on generative pre-trained Transformer have\nachieved remarkable performance on knowledge graph question-answering (KGQA)\ntasks. However, LLMs often produce ungrounded subgraph planning or reasoning\nresults in KGQA due to the hallucinatory behavior brought by the generative\nparadigm. To tackle this issue, we propose READS to reformulate the KGQA\nprocess into discriminative subtasks, which simplifies the search space for\neach subtasks. Based on the subtasks, we design a new corresponding\ndiscriminative inference strategy to conduct the reasoning for KGQA, thereby\nalleviating hallucination and ungrounded reasoning issues in LLMs. Experimental\nresults show that the proposed approach outperforms multiple strong comparison\nmethods, along with achieving state-of-the-art performance on widely used\nbenchmarks WebQSP and CWQ.\n","authors":["Mufan Xu","Kehai Chen","Xuefeng Bai","Muyun Yang","Tiejun Zhao","Min Zhang"],"pdf_url":"https://arxiv.org/pdf/2412.12643v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.05179v1","updated":"2025-03-07T06:57:17Z","published":"2025-03-07T06:57:17Z","title":"Sketch-of-Thought: Efficient LLM Reasoning with Adaptive\n  Cognitive-Inspired Sketching","summary":"  Recent advances in large language models have demonstrated remarkable\nreasoning capabilities through Chain of Thought (CoT) prompting, but often at\nthe cost of excessive verbosity in their intermediate outputs, which increases\ncomputational overhead. We introduce Sketch-of-Thought (SoT), a novel prompting\nframework that combines cognitive-inspired reasoning paradigms with linguistic\nconstraints to minimize token usage while preserving reasoning accuracy. SoT is\ndesigned as a flexible framework that can incorporate any custom reasoning\nparadigms based on cognitive science, and we instantiate it with three such\nparadigms - Conceptual Chaining, Chunked Symbolism, and Expert Lexicons - each\ntailored to different reasoning tasks and selected dynamically via a\nlightweight routing model. Through comprehensive evaluation across 15 reasoning\ndatasets with multiple languages and multimodal scenarios, we demonstrate that\nSoT achieves token reductions of 76% with negligible accuracy impact. In\ncertain domains like mathematical and multi-hop reasoning, it even improves\naccuracy while using significantly fewer tokens. Our code is publicly\navailable: https://www.github.com/SimonAytes/SoT.\n","authors":["Simon A. Aytes","Jinheon Baek","Sung Ju Hwang"],"pdf_url":"https://arxiv.org/pdf/2503.05179v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2501.02295v2","updated":"2025-03-07T06:16:34Z","published":"2025-01-04T14:08:52Z","title":"Explicit vs. Implicit: Investigating Social Bias in Large Language\n  Models through Self-Reflection","summary":"  Large Language Models (LLMs) have been shown to exhibit various biases and\nstereotypes in their generated content. While extensive research has\ninvestigated bias in LLMs, prior work has predominantly focused on explicit\nbias, leaving the more nuanced implicit biases largely unexplored. This paper\npresents a systematic framework grounded in social psychology theories to\ninvestigate and compare explicit and implicit biases in LLMs. We propose a\nnovel \"self-reflection\" based evaluation framework that operates in two phases:\nfirst measuring implicit bias through simulated psychological assessment\nmethods, then evaluating explicit bias by prompting LLMs to analyze their own\ngenerated content. Through extensive experiments on state-of-the-art LLMs\nacross multiple social dimensions, we demonstrate that LLMs exhibit a\nsubstantial inconsistency between explicit and implicit biases, where explicit\nbiases manifest as mild stereotypes while implicit biases show strong\nstereotypes. Furthermore, we investigate the underlying factors contributing to\nthis explicit-implicit bias inconsistency. Our experiments examine the effects\nof training data scale, model parameters, and alignment techniques. Results\nindicate that while explicit bias diminishes with increased training data and\nmodel size, implicit bias exhibits a contrasting upward trend. Notably,\ncontemporary alignment methods (e.g., RLHF, DPO) effectively suppress explicit\nbias but show limited efficacy in mitigating implicit bias. These findings\nsuggest that while scaling up models and alignment training can address\nexplicit bias, the challenge of implicit bias requires novel approaches beyond\ncurrent methodologies.\n","authors":["Yachao Zhao","Bo Wang","Yan Wang"],"pdf_url":"https://arxiv.org/pdf/2501.02295v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2502.11142v3","updated":"2025-03-07T06:06:29Z","published":"2025-02-16T14:17:36Z","title":"NavRAG: Generating User Demand Instructions for Embodied Navigation\n  through Retrieval-Augmented LLM","summary":"  Vision-and-Language Navigation (VLN) is an essential skill for embodied\nagents, allowing them to navigate in 3D environments following natural language\ninstructions. High-performance navigation models require a large amount of\ntraining data, the high cost of manually annotating data has seriously hindered\nthis field. Therefore, some previous methods translate trajectory videos into\nstep-by-step instructions for expanding data, but such instructions do not\nmatch well with users' communication styles that briefly describe destinations\nor state specific needs. Moreover, local navigation trajectories overlook\nglobal context and high-level task planning. To address these issues, we\npropose NavRAG, a retrieval-augmented generation (RAG) framework that generates\nuser demand instructions for VLN. NavRAG leverages LLM to build a hierarchical\nscene description tree for 3D scene understanding from global layout to local\ndetails, then simulates various user roles with specific demands to retrieve\nfrom the scene tree, generating diverse instructions with LLM. We annotate over\n2 million navigation instructions across 861 scenes and evaluate the data\nquality and navigation performance of trained models.\n","authors":["Zihan Wang","Yaohui Zhu","Gim Hee Lee","Yachun Fan"],"pdf_url":"https://arxiv.org/pdf/2502.11142v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.00691v2","updated":"2025-03-07T05:38:47Z","published":"2025-03-02T02:04:58Z","title":"How Diversely Can Language Models Solve Problems? Exploring the\n  Algorithmic Diversity of Model-Generated Code","summary":"  Language models (LMs) have exhibited impressive abilities in generating code\nfrom natural language requirements. In this work, we highlight the diversity of\ncode generated by LMs as a critical criterion for evaluating their code\ngeneration capabilities. There is a lack of studies focused on assessing the\ndiversity of generated code, which overlooks its importance in code LMs.\nTherefore, we propose a systematic approach to evaluate code diversity,\nintroducing various metrics with inter-code similarity. Specifically, we\nintroduce code clustering methods that leverages LMs' capabilities in code\nunderstanding and reasoning, resulting in a set of metrics that represent the\nnumber of algorithms in model-generated solutions. We extensively investigate\nthe property of model-generated solutions by contrasting them with\nhuman-written ones and quantifying the impact of various factors on code\ndiversity: model size, temperature, instruction tuning, and problem complexity.\nOur analysis demonstrates that model-generated solutions exhibit low\nalgorithmic diversity, which was neglected by the research community. Moreover,\nwe explore methods to increase code diversity by combining solutions from\ndifferent models and increasing sampling temperatures. Our findings highlight\nthat code diversity can be enhanced with the help of heterogeneous models and\nsetting temperature beyond 1.0 that has not been fully explored due to the\nfunctional correctness degradation. To facilitate our research direction, we\npublicly share our code and datasets through open-source repositories.\n","authors":["Seonghyeon Lee","Heejae Chon","Joonwon Jang","Dongha Lee","Hwanjo Yu"],"pdf_url":"https://arxiv.org/pdf/2503.00691v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.05157v1","updated":"2025-03-07T05:34:31Z","published":"2025-03-07T05:34:31Z","title":"Ensemble Debiasing Across Class and Sample Levels for Fairer Prompting\n  Accuracy","summary":"  Language models are strong few-shot learners and achieve good overall\naccuracy in text classification tasks, masking the fact that their results\nsuffer from great class accuracy imbalance. We believe that the pursuit of\noverall accuracy should not come from enriching the strong classes, but from\nraising up the weak ones. To address the imbalance, we propose a post-hoc\nnonlinear integer programming based debiasing method that ensembles weight\ncorrection and membership correction to enable flexible rectifications of class\nprobabilities at both class and sample levels, enhancing the performance of\nLLMs directly from their outputs. Evaluations with Llama-2-13B on seven text\nclassification benchmarks show that our approach achieves state-of-the-art\noverall accuracy gains with balanced class accuracies. The resulted probability\ncorrection scheme demonstrates that sample-level corrections are necessary to\nelevate weak classes. In addition, due to effectively correcting weak classes,\nour method also brings significant performance gains to Llama-2-70B, especially\non a biomedical domain task, demonstrating its effectiveness across both small\nand large model variants.\n","authors":["Ruixi Lin","Ziqiao Wang","Yang You"],"pdf_url":"https://arxiv.org/pdf/2503.05157v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2401.10510v3","updated":"2025-03-07T05:29:18Z","published":"2024-01-19T05:58:30Z","title":"When Large Language Models Meet Evolutionary Algorithms: Potential\n  Enhancements and Challenges","summary":"  Pre-trained large language models (LLMs) exhibit powerful capabilities for\ngenerating natural text. Evolutionary algorithms (EAs) can discover diverse\nsolutions to complex real-world problems. Motivated by the common collective\nand directionality of text generation and evolution, this paper first\nillustrates the conceptual parallels between LLMs and EAs at a micro level,\nwhich includes multiple one-to-one key characteristics: token representation\nand individual representation, position encoding and fitness shaping, position\nembedding and selection, Transformers block and reproduction, and model\ntraining and parameter adaptation. These parallels highlight potential\nopportunities for technical advancements in both LLMs and EAs. Subsequently, we\nanalyze existing interdisciplinary research from a macro perspective to uncover\ncritical challenges, with a particular focus on evolutionary fine-tuning and\nLLM-enhanced EAs. These analyses not only provide insights into the\nevolutionary mechanisms behind LLMs but also offer potential directions for\nenhancing the capabilities of artificial agents.\n","authors":["Chao Wang","Jiaxuan Zhao","Licheng Jiao","Lingling Li","Fang Liu","Shuyuan Yang"],"pdf_url":"https://arxiv.org/pdf/2401.10510v3.pdf","comment":"The article has been accepted for publication in Research"},{"id":"http://arxiv.org/abs/2503.05150v1","updated":"2025-03-07T05:19:17Z","published":"2025-03-07T05:19:17Z","title":"Interpersonal Memory Matters: A New Task for Proactive Dialogue\n  Utilizing Conversational History","summary":"  Proactive dialogue systems aim to empower chatbots with the capability of\nleading conversations towards specific targets, thereby enhancing user\nengagement and service autonomy. Existing systems typically target pre-defined\nkeywords or entities, neglecting user attributes and preferences implicit in\ndialogue history, hindering the development of long-term user intimacy. To\naddress these challenges, we take a radical step towards building a more\nhuman-like conversational agent by integrating proactive dialogue systems with\nlong-term memory into a unified framework. Specifically, we define a novel task\nnamed Memory-aware Proactive Dialogue (MapDia). By decomposing the task, we\nthen propose an automatic data construction method and create the first Chinese\nMemory-aware Proactive Dataset (ChMapData). Furthermore, we introduce a joint\nframework based on Retrieval Augmented Generation (RAG), featuring three\nmodules: Topic Summarization, Topic Retrieval, and Proactive Topic-shifting\nDetection and Generation, designed to steer dialogues towards relevant\nhistorical topics at the right time. The effectiveness of our dataset and\nmodels is validated through both automatic and human evaluations. We release\nthe open-source framework and dataset at\nhttps://github.com/FrontierLabs/MapDia.\n","authors":["Bowen Wu","Wenqing Wang","Haoran Li","Ying Li","Jingsong Yu","Baoxun Wang"],"pdf_url":"https://arxiv.org/pdf/2503.05150v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.05142v1","updated":"2025-03-07T04:51:30Z","published":"2025-03-07T04:51:30Z","title":"RocketEval: Efficient Automated LLM Evaluation via Grading Checklist","summary":"  Evaluating large language models (LLMs) in diverse and challenging scenarios\nis essential to align them with human preferences. To mitigate the prohibitive\ncosts associated with human evaluations, utilizing a powerful LLM as a judge\nhas emerged as a favored approach. Nevertheless, this methodology encounters\nseveral challenges, including substantial expenses, concerns regarding privacy\nand security, and reproducibility. In this paper, we propose a straightforward,\nreplicable, and accurate automated evaluation method by leveraging a\nlightweight LLM as the judge, named RocketEval. Initially, we identify that the\nperformance disparity between lightweight and powerful LLMs in evaluation tasks\nprimarily stems from their ability to conduct comprehensive analyses, which is\nnot easily enhanced through techniques such as chain-of-thought reasoning. By\nreframing the evaluation task as a multi-faceted Q&A using an instance-specific\nchecklist, we demonstrate that the limited judgment accuracy of lightweight\nLLMs is largely attributes to high uncertainty and positional bias. To address\nthese challenges, we introduce an automated evaluation process grounded in\nchecklist grading, which is designed to accommodate a variety of scenarios and\nquestions. This process encompasses the creation of checklists, the grading of\nthese checklists by lightweight LLMs, and the reweighting of checklist items to\nalign with the supervised annotations. Our experiments carried out on the\nautomated evaluation benchmarks, MT-Bench and WildBench datasets, reveal that\nRocketEval, when using Gemma-2-2B as the judge, achieves a high correlation\n(0.965) with human preferences, which is comparable to GPT-4o. Moreover,\nRocketEval provides a cost reduction exceeding 50-fold for large-scale\nevaluation and comparison scenarios. Our code is available at\nhttps://github.com/Joinn99/RocketEval-ICLR .\n","authors":["Tianjun Wei","Wei Wen","Ruizhi Qiao","Xing Sun","Jianghong Ma"],"pdf_url":"https://arxiv.org/pdf/2503.05142v1.pdf","comment":"Accepted by ICLR 2025: https://openreview.net/forum?id=zJjzNj6QUe"},{"id":"http://arxiv.org/abs/2503.05139v1","updated":"2025-03-07T04:43:39Z","published":"2025-03-07T04:43:39Z","title":"Every FLOP Counts: Scaling a 300B Mixture-of-Experts LING LLM without\n  Premium GPUs","summary":"  In this technical report, we tackle the challenges of training large-scale\nMixture of Experts (MoE) models, focusing on overcoming cost inefficiency and\nresource limitations prevalent in such systems. To address these issues, we\npresent two differently sized MoE large language models (LLMs), namely\nLing-Lite and Ling-Plus (referred to as \"Bailing\" in Chinese, spelled\nB\\v{a}il\\'ing in Pinyin). Ling-Lite contains 16.8 billion parameters with 2.75\nbillion activated parameters, while Ling-Plus boasts 290 billion parameters\nwith 28.8 billion activated parameters. Both models exhibit comparable\nperformance to leading industry benchmarks. This report offers actionable\ninsights to improve the efficiency and accessibility of AI development in\nresource-constrained settings, promoting more scalable and sustainable\ntechnologies. Specifically, to reduce training costs for large-scale MoE\nmodels, we propose innovative methods for (1) optimization of model\narchitecture and training processes, (2) refinement of training anomaly\nhandling, and (3) enhancement of model evaluation efficiency. Additionally,\nleveraging high-quality data generated from knowledge graphs, our models\ndemonstrate superior capabilities in tool use compared to other models.\nUltimately, our experimental findings demonstrate that a 300B MoE LLM can be\neffectively trained on lower-performance devices while achieving comparable\nperformance to models of a similar scale, including dense and MoE models.\nCompared to high-performance devices, utilizing a lower-specification hardware\nsystem during the pre-training phase demonstrates significant cost savings,\nreducing computing costs by approximately 20%. The models can be accessed at\nhttps://huggingface.co/inclusionAI.\n","authors":[" Ling Team","Binwei Zeng","Chao Huang","Chao Zhang","Changxin Tian","Cong Chen","Dingnan Jin","Feng Yu","Feng Zhu","Feng Yuan","Fakang Wang","Gangshan Wang","Guangyao Zhai","Haitao Zhang","Huizhong Li","Jun Zhou","Jia Liu","Junpeng Fang","Junjie Ou","Jun Hu","Ji Luo","Ji Zhang","Jian Liu","Jian Sha","Jianxue Qian","Jiewei Wu","Junping Zhao","Jianguo Li","Jubao Feng","Jingchao Di","Junming Xu","Jinghua Yao","Kuan Xu","Kewei Du","Longfei Li","Lei Liang","Lu Yu","Li Tang","Lin Ju","Peng Xu","Qing Cui","Song Liu","Shicheng Li","Shun Song","Song Yan","Tengwei Cai","Tianyi Chen","Ting Guo","Ting Huang","Tao Feng","Tao Wu","Wei Wu","Xiaolu Zhang","Xueming Yang","Xin Zhao","Xiaobo Hu","Xin Lin","Yao Zhao","Yilong Wang","Yongzhen Guo","Yuanyuan Wang","Yue Yang","Yang Cao","Yuhao Fu","Yi Xiong","Yanzhe Li","Zhe Li","Zhiqiang Zhang","Ziqi Liu","Zhaoxin Huan","Zujie Wen","Zhenhang Sun","Zhuoxuan Du","Zhengyu He"],"pdf_url":"https://arxiv.org/pdf/2503.05139v1.pdf","comment":"34 pages"},{"id":"http://arxiv.org/abs/2409.11283v4","updated":"2025-03-07T04:29:19Z","published":"2024-09-17T15:38:36Z","title":"Zero-resource Hallucination Detection for Text Generation via\n  Graph-based Contextual Knowledge Triples Modeling","summary":"  LLMs obtain remarkable performance but suffer from hallucinations. Most\nresearch on detecting hallucination focuses on the questions with short and\nconcrete correct answers that are easy to check the faithfulness. Hallucination\ndetections for text generation with open-ended answers are more challenging.\nSome researchers use external knowledge to detect hallucinations in generated\ntexts, but external resources for specific scenarios are hard to access. Recent\nstudies on detecting hallucinations in long text without external resources\nconduct consistency comparison among multiple sampled outputs. To handle long\ntexts, researchers split long texts into multiple facts and individually\ncompare the consistency of each pairs of facts. However, these methods (1)\nhardly achieve alignment among multiple facts; (2) overlook dependencies\nbetween multiple contextual facts. In this paper, we propose a graph-based\ncontext-aware (GCA) hallucination detection for text generations, which aligns\nknowledge facts and considers the dependencies between contextual knowledge\ntriples in consistency comparison. Particularly, to align multiple facts, we\nconduct a triple-oriented response segmentation to extract multiple knowledge\ntriples. To model dependencies among contextual knowledge triple (facts), we\nconstruct contextual triple into a graph and enhance triples' interactions via\nmessage passing and aggregating via RGCN. To avoid the omission of knowledge\ntriples in long text, we conduct a LLM-based reverse verification via\nreconstructing the knowledge triples. Experiments show that our model enhances\nhallucination detection and excels all baselines.\n","authors":["Xinyue Fang","Zhen Huang","Zhiliang Tian","Minghui Fang","Ziyi Pan","Quntian Fang","Zhihua Wen","Hengyue Pan","Dongsheng Li"],"pdf_url":"https://arxiv.org/pdf/2409.11283v4.pdf","comment":"Accepted by AAAI25"},{"id":"http://arxiv.org/abs/2410.21357v4","updated":"2025-03-07T04:28:45Z","published":"2024-10-28T17:25:56Z","title":"Energy-Based Diffusion Language Models for Text Generation","summary":"  Despite remarkable progress in autoregressive language models, alternative\ngenerative paradigms beyond left-to-right generation are still being actively\nexplored. Discrete diffusion models, with the capacity for parallel generation,\nhave recently emerged as a promising alternative. Unfortunately, these models\nstill underperform the autoregressive counterparts, with the performance gap\nincreasing when reducing the number of sampling steps. Our analysis reveals\nthat this degradation is a consequence of an imperfect approximation used by\ndiffusion models. In this work, we propose Energy-based Diffusion Language\nModel (EDLM), an energy-based model operating at the full sequence level for\neach diffusion step, introduced to improve the underlying approximation used by\ndiffusion models. More specifically, we introduce an EBM in a residual form,\nand show that its parameters can be obtained by leveraging a pretrained\nautoregressive model or by finetuning a bidirectional transformer via noise\ncontrastive estimation. We also propose an efficient generation algorithm via\nparallel important sampling. Comprehensive experiments on language modeling\nbenchmarks show that our model can consistently outperform state-of-the-art\ndiffusion models by a significant margin, and approaches autoregressive models'\nperplexity. We further show that, without any generation performance drop, our\nframework offers a 1.3$\\times$ sampling speedup over existing diffusion models.\nReproduced code is available at\nhttps://github.com/MinkaiXu/Energy-Diffusion-LLM.\n","authors":["Minkai Xu","Tomas Geffner","Karsten Kreis","Weili Nie","Yilun Xu","Jure Leskovec","Stefano Ermon","Arash Vahdat"],"pdf_url":"https://arxiv.org/pdf/2410.21357v4.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.05102v1","updated":"2025-03-07T02:44:17Z","published":"2025-03-07T02:44:17Z","title":"AutoTestForge: A Multidimensional Automated Testing Framework for\n  Natural Language Processing Models","summary":"  In recent years, the application of behavioral testing in Natural Language\nProcessing (NLP) model evaluation has experienced a remarkable and substantial\ngrowth. However, the existing methods continue to be restricted by the\nrequirements for manual labor and the limited scope of capability assessment.\nTo address these limitations, we introduce AutoTestForge, an automated and\nmultidimensional testing framework for NLP models in this paper. Within\nAutoTestForge, through the utilization of Large Language Models (LLMs) to\nautomatically generate test templates and instantiate them, manual involvement\nis significantly reduced. Additionally, a mechanism for the validation of test\ncase labels based on differential testing is implemented which makes use of a\nmulti-model voting system to guarantee the quality of test cases. The framework\nalso extends the test suite across three dimensions, taxonomy, fairness, and\nrobustness, offering a comprehensive evaluation of the capabilities of NLP\nmodels. This expansion enables a more in-depth and thorough assessment of the\nmodels, providing valuable insights into their strengths and weaknesses. A\ncomprehensive evaluation across sentiment analysis (SA) and semantic textual\nsimilarity (STS) tasks demonstrates that AutoTestForge consistently outperforms\nexisting datasets and testing tools, achieving higher error detection rates (an\naverage of $30.89\\%$ for SA and $34.58\\%$ for STS). Moreover, different\ngeneration strategies exhibit stable effectiveness, with error detection rates\nranging from $29.03\\% - 36.82\\%$.\n","authors":["Hengrui Xing","Cong Tian","Liang Zhao","Zhi Ma","WenSheng Wang","Nan Zhang","Chao Huang","Zhenhua Duan"],"pdf_url":"https://arxiv.org/pdf/2503.05102v1.pdf","comment":"15 pages, 4 figures, Under review"},{"id":"http://arxiv.org/abs/2503.05096v1","updated":"2025-03-07T02:27:51Z","published":"2025-03-07T02:27:51Z","title":"SpecServe: Efficient and SLO-Aware Large Language Model Serving with\n  Adaptive Speculative Decoding","summary":"  Large Language Model (LLM) services often face challenges in achieving low\ninference latency and meeting Service Level Objectives (SLOs) under dynamic\nrequest patterns. Speculative decoding, which exploits lightweight models for\ndrafting and LLMs for verification, has emerged as a compelling technique to\naccelerate LLM inference. However, existing speculative decoding solutions\noften fail to adapt to varying workloads and system environments, resulting in\nperformance variability and SLO violations. In this paper, we introduce\nSpecServe, an efficient LLM inference system that dynamically adjusts\nspeculative strategies according to real-time request loads and system\nconfigurations. SpecServe proposes a theoretical model to understand and\npredict the efficiency of speculative decoding across diverse scenarios.\nAdditionally, it implements intelligent drafting and verification algorithms to\nguarantee optimal performance while achieving high SLO attainment. Experimental\nresults on real-world LLM traces demonstrate that SpecServe consistently meets\nSLOs and achieves substantial performance improvements, yielding\n1.14$\\times$-14.3$\\times$ speedups over state-of-the-art speculative inference\nsystems.\n","authors":["Kaiyu Huang","Hao Wu","Zhubo Shi","Han Zou","Minchen Yu","Qingjiang Shi"],"pdf_url":"https://arxiv.org/pdf/2503.05096v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.05085v1","updated":"2025-03-07T02:07:00Z","published":"2025-03-07T02:07:00Z","title":"S2S-Arena, Evaluating Speech2Speech Protocols on Instruction Following\n  with Paralinguistic Information","summary":"  The rapid development of large language models (LLMs) has brought significant\nattention to speech models, particularly recent progress in speech2speech\nprotocols supporting speech input and output. However, the existing benchmarks\nadopt automatic text-based evaluators for evaluating the instruction following\nability of these models lack consideration for paralinguistic information in\nboth speech understanding and generation. To address these issues, we introduce\nS2S-Arena, a novel arena-style S2S benchmark that evaluates\ninstruction-following capabilities with paralinguistic information in both\nspeech-in and speech-out across real-world tasks. We design 154 samples that\nfused TTS and live recordings in four domains with 21 tasks and manually\nevaluate existing popular speech models in an arena-style manner. The\nexperimental results show that: (1) in addition to the superior performance of\nGPT-4o, the speech model of cascaded ASR, LLM, and TTS outperforms the jointly\ntrained model after text-speech alignment in speech2speech protocols; (2)\nconsidering paralinguistic information, the knowledgeability of the speech\nmodel mainly depends on the LLM backbone, and the multilingual support of that\nis limited by the speech module; (3) excellent speech models can already\nunderstand the paralinguistic information in speech input, but generating\nappropriate audio with paralinguistic information is still a challenge.\n","authors":["Feng Jiang","Zhiyu Lin","Fan Bu","Yuhao Du","Benyou Wang","Haizhou Li"],"pdf_url":"https://arxiv.org/pdf/2503.05085v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.10541v2","updated":"2025-03-07T01:18:37Z","published":"2023-11-17T14:08:44Z","title":"Detection and Analysis of Offensive Online Content in Hausa Language","summary":"  Hausa, a major Chadic language spoken by over 100 million people mostly in\nWest Africa is considered a low-resource language from a computational\nlinguistic perspective. This classification indicates a scarcity of linguistic\nresources and tools necessary for handling various natural language processing\n(NLP) tasks, including the detection of offensive content. To address this gap,\nwe conducted two set of studies (1) a user study (n=101) to explore\ncyberbullying in Hausa and (2) an empirical study that led to the creation of\nthe first dataset of offensive terms in the Hausa language. We developed\ndetection systems trained on this dataset and compared their performance\nagainst relevant multilingual models, including Google Translate. Our detection\nsystem successfully identified over 70% of offensive, whereas baseline models\nfrequently mistranslated such terms. We attribute this discrepancy to the\nnuanced nature of the Hausa language and the reliance of baseline models on\ndirect or literal translation due to limited data to build purposive detection\nsystems. These findings highlight the importance of incorporating cultural\ncontext and linguistic nuances when developing NLP models for low-resource\nlanguages such as Hausa. A post hoc analysis further revealed that offensive\nlanguage is particularly prevalent in discussions related to religion and\npolitics. To foster a safer online environment, we recommend involving diverse\nstakeholders with expertise in local contexts and demographics. Their insights\nwill be crucial in developing more accurate detection systems and targeted\nmoderation strategies that align with cultural sensitivities.\n","authors":["Fatima Muhammad Adam","Abubakar Yakubu Zandam","Isa Inuwa-Dutse"],"pdf_url":"https://arxiv.org/pdf/2311.10541v2.pdf","comment":"21 pages, 4 figures, 7 tables"},{"id":"http://arxiv.org/abs/2503.05066v1","updated":"2025-03-07T01:11:39Z","published":"2025-03-07T01:11:39Z","title":"Capacity-Aware Inference: Mitigating the Straggler Effect in Mixture of\n  Experts","summary":"  The Mixture of Experts (MoE) is an effective architecture for scaling large\nlanguage models by leveraging sparse expert activation, optimizing the\ntrade-off between performance and efficiency. However, under expert\nparallelism, MoE suffers from inference inefficiencies due to imbalanced\ntoken-to-expert assignment, where some experts are overloaded while others\nremain underutilized. This imbalance leads to poor resource utilization and\nincreased latency, as the most burdened expert dictates the overall delay, a\nphenomenon we define as the \\textbf{\\textit{Straggler Effect}}. To mitigate\nthis, we propose Capacity-Aware Inference, including two key techniques: (1)\n\\textbf{\\textit{Capacity-Aware Token Drop}}, which discards overloaded tokens\nto regulate the maximum latency of MoE, and (2) \\textbf{\\textit{Capacity-Aware\nToken Reroute}}, which reallocates overflowed tokens to underutilized experts,\nbalancing the token distribution. These techniques collectively optimize both\nhigh-load and low-load expert utilization, leading to a more efficient MoE\ninference pipeline. Extensive experiments demonstrate the effectiveness of our\nmethods, showing significant improvements in inference efficiency, e.g., 0.2\\%\naverage performance increase and a 1.94$\\times$ inference speedup on\nMixtral-8$\\times$7B-Instruct.\n","authors":["Shwai He","Weilin Cai","Jiayi Huang","Ang Li"],"pdf_url":"https://arxiv.org/pdf/2503.05066v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.05065v1","updated":"2025-03-07T01:05:46Z","published":"2025-03-07T01:05:46Z","title":"The study of short texts in digital politics: Document aggregation for\n  topic modeling","summary":"  Statistical topic modeling is widely used in political science to study text.\nResearchers examine documents of varying lengths, from tweets to speeches.\nThere is ongoing debate on how document length affects the interpretability of\ntopic models. We investigate the effects of aggregating short documents into\nlarger ones based on natural units that partition the corpus. In our study, we\nanalyze one million tweets by U.S. state legislators from April 2016 to\nSeptember 2020. We find that for documents aggregated at the account level,\ntopics are more associated with individual states than when using individual\ntweets. This finding is replicated with Wikipedia pages aggregated by birth\ncities, showing how document definitions can impact topic modeling results.\n","authors":["Nitheesha Nakka","Omer F. Yalcin","Bruce A. Desmarais","Sarah Rajtmajer","Burt Monroe"],"pdf_url":"https://arxiv.org/pdf/2503.05065v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.05061v1","updated":"2025-03-07T00:42:08Z","published":"2025-03-07T00:42:08Z","title":"No Free Labels: Limitations of LLM-as-a-Judge Without Human Grounding","summary":"  LLM-as-a-Judge is a framework that uses an LLM (large language model) to\nevaluate the quality of natural language text - typically text that is also\ngenerated by an LLM. This framework holds great promise due to its relative\nlow-cost, ease of use, and strong correlations with human stylistic\npreferences. However, LLM Judges have been shown to exhibit biases that can\ndistort their judgments. We evaluate how well LLM Judges can grade whether a\ngiven response to a conversational question is correct, an ability crucial to\nsoundly estimating the overall response quality. To do so, we create and\npublicly release a human-annotated dataset with labels of correctness for 1,200\nLLM responses. We source questions from a combination of existing datasets and\na novel, challenging benchmark (BFF-Bench) created for this analysis. We\ndemonstrate a strong connection between an LLM's ability to correctly answer a\nquestion and grade responses to that question. Although aggregate level\nstatistics might imply a judge has high agreement with human annotators, it\nwill struggle on the subset of questions it could not answer. To address this\nissue, we recommend a simple solution: provide the judge with a correct,\nhuman-written reference answer. We perform an in-depth analysis on how\nreference quality can affect the performance of an LLM Judge. We show that\nproviding a weaker judge (e.g. Qwen 2.5 7B) with higher quality references\nreaches better agreement with human annotators than a stronger judge (e.g.\nGPT-4o) with synthetic references.\n","authors":["Michael Krumdick","Charles Lovering","Varshini Reddy","Seth Ebner","Chris Tanner"],"pdf_url":"https://arxiv.org/pdf/2503.05061v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.05060v1","updated":"2025-03-07T00:28:08Z","published":"2025-03-07T00:28:08Z","title":"ModernBERT is More Efficient than Conventional BERT for Chest CT\n  Findings Classification in Japanese Radiology Reports","summary":"  Objective: This study aims to evaluate and compare the performance of two\nJapanese language models-conventional Bidirectional Encoder Representations\nfrom Transformers (BERT) and the newer ModernBERT-in classifying findings from\nchest CT reports, with a focus on tokenization efficiency, processing time, and\nclassification performance. Methods: We conducted a retrospective study using\nthe CT-RATE-JPN dataset containing 22,778 training reports and 150 test\nreports. Both models were fine-tuned for multi-label classification of 18\ncommon chest CT conditions. The training data was split in 18,222:4,556 for\ntraining and validation. Performance was evaluated using F1 scores for each\ncondition and exact match accuracy across all 18 labels. Results: ModernBERT\ndemonstrated superior tokenization efficiency, requiring 24.0% fewer tokens per\ndocument (258.1 vs. 339.6) compared to BERT Base. This translated to\nsignificant performance improvements, with ModernBERT completing training in\n1877.67 seconds versus BERT's 3090.54 seconds (39% reduction). ModernBERT\nprocessed 38.82 samples per second during training (1.65x faster) and 139.90\nsamples per second during inference (1.66x faster). Despite these efficiency\ngains, classification performance remained comparable, with ModernBERT\nachieving superior F1 scores in 8 conditions, while BERT performed better in 4\nconditions. Overall exact match accuracy was slightly higher for ModernBERT\n(74.67% vs. 72.67%), though this difference was not statistically significant\n(p=0.6291). Conclusion: ModernBERT offers substantial improvements in\ntokenization efficiency and training speed without sacrificing classification\nperformance. These results suggest that ModernBERT is a promising candidate for\nclinical applications in Japanese radiology reports analysis.\n","authors":["Yosuke Yamagishi","Tomohiro Kikuchi","Shouhei Hanaoka","Takeharu Yoshikawa","Osamu Abe"],"pdf_url":"https://arxiv.org/pdf/2503.05060v1.pdf","comment":"23 pages, 8 figures"}],"Computer Vision and Pattern Recognition":[{"id":"http://arxiv.org/abs/2503.04499v2","updated":"2025-03-07T15:51:19Z","published":"2025-03-06T14:48:25Z","title":"Spatial regularisation for improved accuracy and interpretability in\n  keypoint-based registration","summary":"  Unsupervised registration strategies bypass requirements in ground truth\ntransforms or segmentations by optimising similarity metrics between fixed and\nmoved volumes. Among these methods, a recent subclass of approaches based on\nunsupervised keypoint detection stand out as very promising for\ninterpretability. Specifically, these methods train a network to predict\nfeature maps for fixed and moving images, from which explainable centres of\nmass are computed to obtain point clouds, that are then aligned in closed-form.\nHowever, the features returned by the network often yield spatially diffuse\npatterns that are hard to interpret, thus undermining the purpose of\nkeypoint-based registration. Here, we propose a three-fold loss to regularise\nthe spatial distribution of the features. First, we use the KL divergence to\nmodel features as point spread functions that we interpret as probabilistic\nkeypoints. Then, we sharpen the spatial distributions of these features to\nincrease the precision of the detected landmarks. Finally, we introduce a new\nrepulsive loss across keypoints to encourage spatial diversity. Overall, our\nloss considerably improves the interpretability of the features, which now\ncorrespond to precise and anatomically meaningful landmarks. We demonstrate our\nthree-fold loss in foetal rigid motion tracking and brain MRI affine\nregistration tasks, where it not only outperforms state-of-the-art unsupervised\nstrategies, but also bridges the gap with state-of-the-art supervised methods.\nOur code is available at https://github.com/BenBillot/spatial_regularisation.\n","authors":["Benjamin Billot","Ramya Muthukrishnan","Esra Abaci-Turk","P. Ellen Grant","Nicholas Ayache","Herv Delingette","Polina Golland"],"pdf_url":"https://arxiv.org/pdf/2503.04499v2.pdf","comment":"under review"},{"id":"http://arxiv.org/abs/2503.04459v2","updated":"2025-03-07T09:27:33Z","published":"2025-03-06T14:11:46Z","title":"Question-Aware Gaussian Experts for Audio-Visual Question Answering","summary":"  Audio-Visual Question Answering (AVQA) requires not only question-based\nmultimodal reasoning but also precise temporal grounding to capture subtle\ndynamics for accurate prediction. However, existing methods mainly use question\ninformation implicitly, limiting focus on question-specific details.\nFurthermore, most studies rely on uniform frame sampling, which can miss key\nquestion-relevant frames. Although recent Top-K frame selection methods aim to\naddress this, their discrete nature still overlooks fine-grained temporal\ndetails. This paper proposes QA-TIGER, a novel framework that explicitly\nincorporates question information and models continuous temporal dynamics. Our\nkey idea is to use Gaussian-based modeling to adaptively focus on both\nconsecutive and non-consecutive frames based on the question, while explicitly\ninjecting question information and applying progressive refinement. We leverage\na Mixture of Experts (MoE) to flexibly implement multiple Gaussian models,\nactivating temporal experts specifically tailored to the question. Extensive\nexperiments on multiple AVQA benchmarks show that QA-TIGER consistently\nachieves state-of-the-art performance. Code is available at\nhttps://aim-skku.github.io/QA-TIGER/\n","authors":["Hongyeob Kim","Inyoung Jung","Dayoon Suh","Youjia Zhang","Sangmin Lee","Sungeun Hong"],"pdf_url":"https://arxiv.org/pdf/2503.04459v2.pdf","comment":"CVPR 2025. Code is available at https://github.com/AIM-SKKU/QA-TIGER"},{"id":"http://arxiv.org/abs/2503.04344v2","updated":"2025-03-07T06:49:29Z","published":"2025-03-06T11:41:36Z","title":"LEDiT: Your Length-Extrapolatable Diffusion Transformer without\n  Positional Encoding","summary":"  Diffusion transformers(DiTs) struggle to generate images at resolutions\nhigher than their training resolutions. The primary obstacle is that the\nexplicit positional encodings(PE), such as RoPE, need extrapolation which\ndegrades performance when the inference resolution differs from training. In\nthis paper, we propose a Length-Extrapolatable Diffusion Transformer(LEDiT), a\nsimple yet powerful architecture to overcome this limitation. LEDiT needs no\nexplicit PEs, thereby avoiding extrapolation. The key innovations of LEDiT are\nintroducing causal attention to implicitly impart global positional information\nto tokens, while enhancing locality to precisely distinguish adjacent tokens.\nExperiments on 256x256 and 512x512 ImageNet show that LEDiT can scale the\ninference resolution to 512x512 and 1024x1024, respectively, while achieving\nbetter image quality compared to current state-of-the-art length extrapolation\nmethods(NTK-aware, YaRN). Moreover, LEDiT achieves strong extrapolation\nperformance with just 100K steps of fine-tuning on a pretrained DiT,\ndemonstrating its potential for integration into existing text-to-image DiTs.\nProject page: https://shenzhang2145.github.io/ledit/\n","authors":["Shen Zhang","Yaning Tan","Siyuan Liang","Zhaowei Chen","Linze Li","Ge Wu","Yuhao Chen","Shuheng Li","Zhenyu Zhao","Caihua Chen","Jiajun Liang","Yao Tang"],"pdf_url":"https://arxiv.org/pdf/2503.04344v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.04325v2","updated":"2025-03-07T10:22:10Z","published":"2025-03-06T11:18:22Z","title":"GBT-SAM: A Parameter-Efficient Depth-Aware Model for Generalizable Brain\n  tumour Segmentation on mp-MRI","summary":"  Gliomas are brain tumours that stand out for their highly lethal and\naggressive nature, which demands a precise approach in their diagnosis. Medical\nimage segmentation plays a crucial role in the evaluation and follow-up of\nthese tumours, allowing specialists to analyse their morphology. However,\nexisting methods for automatic glioma segmentation often lack generalization\ncapability across other brain tumour domains, require extensive computational\nresources, or fail to fully utilize the multi-parametric MRI (mp-MRI) data used\nto delineate them. In this work, we introduce GBT-SAM, a novel Generalizable\nBrain Tumour (GBT) framework that extends the Segment Anything Model (SAM) to\nbrain tumour segmentation tasks. Our method employs a two-step training\nprotocol: first, fine-tuning the patch embedding layer to process the entire\nmp-MRI modalities, and second, incorporating parameter-efficient LoRA blocks\nand a Depth-Condition block into the Vision Transformer (ViT) to capture\ninter-slice correlations. GBT-SAM achieves state-of-the-art performance on the\nAdult Glioma dataset (Dice Score of $93.54$) while demonstrating robust\ngeneralization across Meningioma, Pediatric Glioma, and Sub-Saharan Glioma\ndatasets. Furthermore, GBT-SAM uses less than 6.5M trainable parameters, thus\noffering an efficient solution for brain tumour segmentation. \\\\ Our code and\nmodels are available at https://github.com/vpulab/med-sam-brain .\n","authors":["Cecilia Diana-Albelda","Roberto Alcover-Couso","lvaro Garca-Martn","Jesus Bescos","Marcos Escudero-Violo"],"pdf_url":"https://arxiv.org/pdf/2503.04325v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2412.00156v4","updated":"2025-03-07T02:43:19Z","published":"2024-11-29T08:10:49Z","title":"VISION-XL: High Definition Video Inverse Problem Solver using Latent\n  Image Diffusion Models","summary":"  In this paper, we propose a novel framework for solving high-definition video\ninverse problems using latent image diffusion models. Building on recent\nadvancements in spatio-temporal optimization for video inverse problems using\nimage diffusion models, our approach leverages latent-space diffusion models to\nachieve enhanced video quality and resolution. To address the high\ncomputational demands of processing high-resolution frames, we introduce a\npseudo-batch consistent sampling strategy, allowing efficient operation on a\nsingle GPU. Additionally, to improve temporal consistency, we present\npseudo-batch inversion, an initialization technique that incorporates\ninformative latents from the measurement. By integrating with SDXL, our\nframework achieves state-of-the-art video reconstruction across a wide range of\nspatio-temporal inverse problems, including complex combinations of frame\naveraging and various spatial degradations, such as deblurring,\nsuper-resolution, and inpainting. Unlike previous methods, our approach\nsupports multiple aspect ratios (landscape, vertical, and square) and delivers\nHD-resolution reconstructions (exceeding 1280x720) in under 6 seconds per frame\non a single NVIDIA 4090 GPU.\n","authors":["Taesung Kwon","Jong Chul Ye"],"pdf_url":"https://arxiv.org/pdf/2412.00156v4.pdf","comment":"Project page: https://vision-xl.github.io/"},{"id":"http://arxiv.org/abs/2503.04127v2","updated":"2025-03-07T02:39:57Z","published":"2025-03-06T06:13:27Z","title":"Diff-Reg v2: Diffusion-Based Matching Matrix Estimation for Image\n  Matching and 3D Registration","summary":"  Establishing reliable correspondences is crucial for all registration tasks,\nincluding 2D image registration, 3D point cloud registration, and 2D-3D\nimage-to-point cloud registration. However, these tasks are often complicated\nby challenges such as scale inconsistencies, symmetry, and large deformations,\nwhich can lead to ambiguous matches. Previous feature-based and\ncorrespondence-based methods typically rely on geometric or semantic features\nto generate or polish initial potential correspondences. Some methods typically\nleverage specific geometric priors, such as topological preservation, to devise\ndiverse and innovative strategies tailored to a given enhancement goal, which\ncannot be exhaustively enumerated. Additionally, many previous approaches rely\non a single-step prediction head, which can struggle with local minima in\ncomplex matching scenarios. To address these challenges, we introduce an\ninnovative paradigm that leverages a diffusion model in matrix space for robust\nmatching matrix estimation. Our model treats correspondence estimation as a\ndenoising diffusion process in the matching matrix space, gradually refining\nthe intermediate matching matrix to the optimal one. Specifically, we apply the\ndiffusion model in the doubly stochastic matrix space for 3D-3D and 2D-3D\nregistration tasks. In the 2D image registration task, we deploy the diffusion\nmodel in a matrix subspace where dual-softmax projection regularization is\napplied. For all three registration tasks, we provide adaptive matching matrix\nembedding implementations tailored to the specific characteristics of each task\nwhile maintaining a consistent \"match-to-warp\" encoding pattern. Furthermore,\nwe adopt a lightweight design for the denoising module. In inference, once\npoints or image features are extracted and fixed, this module performs\nmulti-step denoising predictions through reverse sampling.\n","authors":["Qianliang Wu","Haobo Jiang","Yaqing Ding","Lei Luo","Jin Xie","Jian Yang"],"pdf_url":"https://arxiv.org/pdf/2503.04127v2.pdf","comment":"arXiv admin note: text overlap with arXiv:2403.19919"},{"id":"http://arxiv.org/abs/2503.05689v1","updated":"2025-03-07T18:52:08Z","published":"2025-03-07T18:52:08Z","title":"GoalFlow: Goal-Driven Flow Matching for Multimodal Trajectories\n  Generation in End-to-End Autonomous Driving","summary":"  We propose GoalFlow, an end-to-end autonomous driving method for generating\nhigh-quality multimodal trajectories. In autonomous driving scenarios, there is\nrarely a single suitable trajectory. Recent methods have increasingly focused\non modeling multimodal trajectory distributions. However, they suffer from\ntrajectory selection complexity and reduced trajectory quality due to high\ntrajectory divergence and inconsistencies between guidance and scene\ninformation. To address these issues, we introduce GoalFlow, a novel method\nthat effectively constrains the generative process to produce high-quality,\nmultimodal trajectories. To resolve the trajectory divergence problem inherent\nin diffusion-based methods, GoalFlow constrains the generated trajectories by\nintroducing a goal point. GoalFlow establishes a novel scoring mechanism that\nselects the most appropriate goal point from the candidate points based on\nscene information. Furthermore, GoalFlow employs an efficient generative\nmethod, Flow Matching, to generate multimodal trajectories, and incorporates a\nrefined scoring mechanism to select the optimal trajectory from the candidates.\nOur experimental results, validated on the Navsim\\cite{Dauner2024_navsim},\ndemonstrate that GoalFlow achieves state-of-the-art performance, delivering\nrobust multimodal trajectories for autonomous driving. GoalFlow achieved PDMS\nof 90.3, significantly surpassing other methods. Compared with other\ndiffusion-policy-based methods, our approach requires only a single denoising\nstep to obtain excellent performance. The code is available at\nhttps://github.com/YvanYin/GoalFlow.\n","authors":["Zebin Xing","Xingyu Zhang","Yang Hu","Bo Jiang","Tong He","Qian Zhang","Xiaoxiao Long","Wei Yin"],"pdf_url":"https://arxiv.org/pdf/2503.05689v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2412.12561v2","updated":"2025-03-07T18:51:48Z","published":"2024-12-17T05:43:35Z","title":"Tell Me What to Track: Infusing Robust Language Guidance for Enhanced\n  Referring Multi-Object Tracking","summary":"  Referring multi-object tracking (RMOT) is an emerging cross-modal task that\naims to localize an arbitrary number of targets based on a language expression\nand continuously track them in a video. This intricate task involves reasoning\non multi-modal data and precise target localization with temporal association.\nHowever, prior studies overlook the imbalanced data distribution between\nnewborn targets and existing targets due to the nature of the task. In\naddition, they only indirectly fuse multi-modal features, struggling to deliver\nclear guidance on newborn target detection. To solve the above issues, we\nconduct a collaborative matching strategy to alleviate the impact of the\nimbalance, boosting the ability to detect newborn targets while maintaining\ntracking performance. In the encoder, we integrate and enhance the cross-modal\nand multi-scale fusion, overcoming the bottlenecks in previous work, where\nlimited multi-modal information is shared and interacted between feature maps.\nIn the decoder, we also develop a referring-infused adaptation that provides\nexplicit referring guidance through the query tokens. The experiments showcase\nthe superior performance of our model (+3.42%) compared to prior works,\ndemonstrating the effectiveness of our designs.\n","authors":["Wenjun Huang","Yang Ni","Hanning Chen","Yirui He","Ian Bryant","Yezi Liu","Mohsen Imani"],"pdf_url":"https://arxiv.org/pdf/2412.12561v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.05684v1","updated":"2025-03-07T18:49:57Z","published":"2025-03-07T18:49:57Z","title":"Fairness-Aware Low-Rank Adaptation Under Demographic Privacy Constraints","summary":"  Pre-trained foundation models can be adapted for specific tasks using\nLow-Rank Adaptation (LoRA). However, the fairness properties of these adapted\nclassifiers remain underexplored. Existing fairness-aware fine-tuning methods\nrely on direct access to sensitive attributes or their predictors, but in\npractice, these sensitive attributes are often held under strict consumer\nprivacy controls, and neither the attributes nor their predictors are available\nto model developers, hampering the development of fair models. To address this\nissue, we introduce a set of LoRA-based fine-tuning methods that can be trained\nin a distributed fashion, where model developers and fairness auditors\ncollaborate without sharing sensitive attributes or predictors. In this paper,\nwe evaluate three such methods - sensitive unlearning, adversarial training,\nand orthogonality loss - against a fairness-unaware baseline, using experiments\non the CelebA and UTK-Face datasets with an ImageNet pre-trained ViT-Base\nmodel. We find that orthogonality loss consistently reduces bias while\nmaintaining or improving utility, whereas adversarial training improves False\nPositive Rate Parity and Demographic Parity in some cases, and sensitive\nunlearning provides no clear benefit. In tasks where significant biases are\npresent, distributed fairness-aware fine-tuning methods can effectively\neliminate bias without compromising consumer privacy and, in most cases,\nimprove model utility.\n","authors":["Parameswaran Kamalaruban","Mark Anderson","Stuart Burrell","Maeve Madigan","Piotr Skalski","David Sutton"],"pdf_url":"https://arxiv.org/pdf/2503.05684v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2412.07750v2","updated":"2025-03-07T18:46:34Z","published":"2024-12-10T18:49:39Z","title":"Motion by Queries: Identity-Motion Trade-offs in Text-to-Video\n  Generation","summary":"  Text-to-video diffusion models have shown remarkable progress in generating\ncoherent video clips from textual descriptions. However, the interplay between\nmotion, structure, and identity representations in these models remains\nunder-explored. Here, we investigate how self-attention query features (a.k.a.\nQ features) simultaneously govern motion, structure, and identity and examine\nthe challenges arising when these representations interact. Our analysis\nreveals that Q affects not only layout, but that during denoising Q also has a\nstrong effect on subject identity, making it hard to transfer motion without\nthe side-effect of transferring identity. Understanding this dual role enabled\nus to control query feature injection (Q injection) and demonstrate two\napplications: (1) a zero-shot motion transfer method that is 20 times more\nefficient than existing approaches, and (2) a training-free technique for\nconsistent multi-shot video generation, where characters maintain identity\nacross multiple video shots while Q injection enhances motion fidelity.\n","authors":["Yuval Atzmon","Rinon Gal","Yoad Tewel","Yoni Kasten","Gal Chechik"],"pdf_url":"https://arxiv.org/pdf/2412.07750v2.pdf","comment":"(1) Project page:\n  https://research.nvidia.com/labs/par/MotionByQueries/ (2) The methods and\n  results in section 5, \"Consistent multi-shot video generation\", are based on\n  the arXiv version 1 (v1) of this work. Here, in version 2 (v2), we extend and\n  further analyze those findings to efficient motion transfer"},{"id":"http://arxiv.org/abs/2503.05682v1","updated":"2025-03-07T18:44:53Z","published":"2025-03-07T18:44:53Z","title":"Task-oriented Uncertainty Collaborative Learning for Label-Efficient\n  Brain Tumor Segmentation","summary":"  Multi-contrast magnetic resonance imaging (MRI) plays a vital role in brain\ntumor segmentation and diagnosis by leveraging complementary information from\ndifferent contrasts. Each contrast highlights specific tumor characteristics,\nenabling a comprehensive understanding of tumor morphology, edema, and\npathological heterogeneity. However, existing methods still face the challenges\nof multi-level specificity perception across different contrasts, especially\nwith limited annotations. These challenges include data heterogeneity,\ngranularity differences, and interference from redundant information. To\naddress these limitations, we propose a Task-oriented Uncertainty Collaborative\nLearning (TUCL) framework for multi-contrast MRI segmentation. TUCL introduces\na task-oriented prompt attention (TPA) module with intra-prompt and\ncross-prompt attention mechanisms to dynamically model feature interactions\nacross contrasts and tasks. Additionally, a cyclic process is designed to map\nthe predictions back to the prompt to ensure that the prompts are effectively\nutilized. In the decoding stage, the TUCL framework proposes a dual-path\nuncertainty refinement (DUR) strategy which ensures robust segmentation by\nrefining predictions iteratively. Extensive experimental results on limited\nlabeled data demonstrate that TUCL significantly improves segmentation accuracy\n(88.2\\% in Dice and 10.853 mm in HD95). It shows that TUCL has the potential to\nextract multi-contrast information and reduce the reliance on extensive\nannotations. The code is available at:\nhttps://github.com/Zhenxuan-Zhang/TUCL_BrainSeg.\n","authors":["Zhenxuan Zhang","Hongjie Wu","Jiahao Huang","Baihong Xie","Zhifan Gao","Junxian Du","Pete Lally","Guang Yang"],"pdf_url":"https://arxiv.org/pdf/2503.05682v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.05665v1","updated":"2025-03-07T18:26:48Z","published":"2025-03-07T18:26:48Z","title":"AIM-Fair: Advancing Algorithmic Fairness via Selectively Fine-Tuning\n  Biased Models with Contextual Synthetic Data","summary":"  Recent advances in generative models have sparked research on improving model\nfairness with AI-generated data. However, existing methods often face\nlimitations in the diversity and quality of synthetic data, leading to\ncompromised fairness and overall model accuracy. Moreover, many approaches rely\non the availability of demographic group labels, which are often costly to\nannotate. This paper proposes AIM-Fair, aiming to overcome these limitations\nand harness the potential of cutting-edge generative models in promoting\nalgorithmic fairness. We investigate a fine-tuning paradigm starting from a\nbiased model initially trained on real-world data without demographic\nannotations. This model is then fine-tuned using unbiased synthetic data\ngenerated by a state-of-the-art diffusion model to improve its fairness. Two\nkey challenges are identified in this fine-tuning paradigm, 1) the low quality\nof synthetic data, which can still happen even with advanced generative models,\nand 2) the domain and bias gap between real and synthetic data. To address the\nlimitation of synthetic data quality, we propose Contextual Synthetic Data\nGeneration (CSDG) to generate data using a text-to-image diffusion model (T2I)\nwith prompts generated by a context-aware LLM, ensuring both data diversity and\ncontrol of bias in synthetic data. To resolve domain and bias shifts, we\nintroduce a novel selective fine-tuning scheme in which only model parameters\nmore sensitive to bias and less sensitive to domain shift are updated.\nExperiments on CelebA and UTKFace datasets show that our AIM-Fair improves\nmodel fairness while maintaining utility, outperforming both fully and\npartially fine-tuned approaches to model fairness.\n","authors":["Zengqun Zhao","Ziquan Liu","Yu Cao","Shaogang Gong","Ioannis Patras"],"pdf_url":"https://arxiv.org/pdf/2503.05665v1.pdf","comment":"Accepted at CVPR 2025. Github:\n  https://github.com/zengqunzhao/AIM-Fair. Project page:\n  https://zengqunzhao.github.io/AIMFair"},{"id":"http://arxiv.org/abs/2411.02482v2","updated":"2025-03-07T18:20:38Z","published":"2024-11-04T18:59:36Z","title":"NeRF-Aug: Data Augmentation for Robotics with Neural Radiance Fields","summary":"  Training a policy that can generalize to unknown objects is a long standing\nchallenge within the field of robotics. The performance of a policy often drops\nsignificantly in situations where an object in the scene was not seen during\ntraining. To solve this problem, we present NeRF-Aug, a novel method that is\ncapable of teaching a policy to interact with objects that are not present in\nthe dataset. This approach differs from existing approaches by leveraging the\nspeed, photorealism, and 3D consistency of a neural radiance field for\naugmentation. NeRF-Aug both creates more photorealistic data and runs 63%\nfaster than existing methods. We demonstrate the effectiveness of our method on\n5 tasks with 9 novel objects that are not present in the expert demonstrations.\nWe achieve an average performance boost of 55.6% when comparing our method to\nthe next best method. You can see video results at https://nerf-aug.github.io.\n","authors":["Eric Zhu","Mara Levy","Matthew Gwilliam","Abhinav Shrivastava"],"pdf_url":"https://arxiv.org/pdf/2411.02482v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.05657v1","updated":"2025-03-07T18:19:19Z","published":"2025-03-07T18:19:19Z","title":"NoT: Federated Unlearning via Weight Negation","summary":"  Federated unlearning (FU) aims to remove a participant's data contributions\nfrom a trained federated learning (FL) model, ensuring privacy and regulatory\ncompliance. Traditional FU methods often depend on auxiliary storage on either\nthe client or server side or require direct access to the data targeted for\nremoval-a dependency that may not be feasible if the data is no longer\navailable. To overcome these limitations, we propose NoT, a novel and efficient\nFU algorithm based on weight negation (multiplying by -1), which circumvents\nthe need for additional storage and access to the target data. We argue that\neffective and efficient unlearning can be achieved by perturbing model\nparameters away from the set of optimal parameters, yet being well-positioned\nfor quick re-optimization. This technique, though seemingly contradictory, is\ntheoretically grounded: we prove that the weight negation perturbation\neffectively disrupts inter-layer co-adaptation, inducing unlearning while\npreserving an approximate optimality property, thereby enabling rapid recovery.\nExperimental results across three datasets and three model architectures\ndemonstrate that NoT significantly outperforms existing baselines in unlearning\nefficacy as well as in communication and computational efficiency.\n","authors":["Yasser H. Khalil","Leo Brunswic","Soufiane Lamghari","Xu Li","Mahdi Beitollahi","Xi Chen"],"pdf_url":"https://arxiv.org/pdf/2503.05657v1.pdf","comment":"The 42nd IEEE/CVF Conference on Computer Vision and Pattern\n  Recognition, Nashville TN, US. 2025"},{"id":"http://arxiv.org/abs/2503.05652v1","updated":"2025-03-07T18:15:21Z","published":"2025-03-07T18:15:21Z","title":"BEHAVIOR Robot Suite: Streamlining Real-World Whole-Body Manipulation\n  for Everyday Household Activities","summary":"  Real-world household tasks present significant challenges for mobile\nmanipulation robots. An analysis of existing robotics benchmarks reveals that\nsuccessful task performance hinges on three key whole-body control\ncapabilities: bimanual coordination, stable and precise navigation, and\nextensive end-effector reachability. Achieving these capabilities requires\ncareful hardware design, but the resulting system complexity further\ncomplicates visuomotor policy learning. To address these challenges, we\nintroduce the BEHAVIOR Robot Suite (BRS), a comprehensive framework for\nwhole-body manipulation in diverse household tasks. Built on a bimanual,\nwheeled robot with a 4-DoF torso, BRS integrates a cost-effective whole-body\nteleoperation interface for data collection and a novel algorithm for learning\nwhole-body visuomotor policies. We evaluate BRS on five challenging household\ntasks that not only emphasize the three core capabilities but also introduce\nadditional complexities, such as long-range navigation, interaction with\narticulated and deformable objects, and manipulation in confined spaces. We\nbelieve that BRS's integrated robotic embodiment, data collection interface,\nand learning framework mark a significant step toward enabling real-world\nwhole-body manipulation for everyday household tasks. BRS is open-sourced at\nhttps://behavior-robot-suite.github.io/\n","authors":["Yunfan Jiang","Ruohan Zhang","Josiah Wong","Chen Wang","Yanjie Ze","Hang Yin","Cem Gokmen","Shuran Song","Jiajun Wu","Li Fei-Fei"],"pdf_url":"https://arxiv.org/pdf/2503.05652v1.pdf","comment":"Project website: https://behavior-robot-suite.github.io/"},{"id":"http://arxiv.org/abs/2503.05639v1","updated":"2025-03-07T17:59:46Z","published":"2025-03-07T17:59:46Z","title":"VideoPainter: Any-length Video Inpainting and Editing with Plug-and-Play\n  Context Control","summary":"  Video inpainting, which aims to restore corrupted video content, has\nexperienced substantial progress. Despite these advances, existing methods,\nwhether propagating unmasked region pixels through optical flow and receptive\nfield priors, or extending image-inpainting models temporally, face challenges\nin generating fully masked objects or balancing the competing objectives of\nbackground context preservation and foreground generation in one model,\nrespectively. To address these limitations, we propose a novel dual-stream\nparadigm VideoPainter that incorporates an efficient context encoder\n(comprising only 6% of the backbone parameters) to process masked videos and\ninject backbone-aware background contextual cues to any pre-trained video DiT,\nproducing semantically consistent content in a plug-and-play manner. This\narchitectural separation significantly reduces the model's learning complexity\nwhile enabling nuanced integration of crucial background context. We also\nintroduce a novel target region ID resampling technique that enables any-length\nvideo inpainting, greatly enhancing our practical applicability. Additionally,\nwe establish a scalable dataset pipeline leveraging current vision\nunderstanding models, contributing VPData and VPBench to facilitate\nsegmentation-based inpainting training and assessment, the largest video\ninpainting dataset and benchmark to date with over 390K diverse clips. Using\ninpainting as a pipeline basis, we also explore downstream applications\nincluding video editing and video editing pair data generation, demonstrating\ncompetitive performance and significant practical potential. Extensive\nexperiments demonstrate VideoPainter's superior performance in both any-length\nvideo inpainting and editing, across eight key metrics, including video\nquality, mask region preservation, and textual coherence.\n","authors":["Yuxuan Bian","Zhaoyang Zhang","Xuan Ju","Mingdeng Cao","Liangbin Xie","Ying Shan","Qiang Xu"],"pdf_url":"https://arxiv.org/pdf/2503.05639v1.pdf","comment":"Project page available at\n  https://yxbian23.github.io/project/video-painter"},{"id":"http://arxiv.org/abs/2503.05638v1","updated":"2025-03-07T17:57:53Z","published":"2025-03-07T17:57:53Z","title":"TrajectoryCrafter: Redirecting Camera Trajectory for Monocular Videos\n  via Diffusion Models","summary":"  We present TrajectoryCrafter, a novel approach to redirect camera\ntrajectories for monocular videos. By disentangling deterministic view\ntransformations from stochastic content generation, our method achieves precise\ncontrol over user-specified camera trajectories. We propose a novel dual-stream\nconditional video diffusion model that concurrently integrates point cloud\nrenders and source videos as conditions, ensuring accurate view transformations\nand coherent 4D content generation. Instead of leveraging scarce multi-view\nvideos, we curate a hybrid training dataset combining web-scale monocular\nvideos with static multi-view datasets, by our innovative double-reprojection\nstrategy, significantly fostering robust generalization across diverse scenes.\nExtensive evaluations on multi-view and large-scale monocular videos\ndemonstrate the superior performance of our method.\n","authors":["Mark YU","Wenbo Hu","Jinbo Xing","Ying Shan"],"pdf_url":"https://arxiv.org/pdf/2503.05638v1.pdf","comment":"Project webpage: https://trajectorycrafter.github.io/"},{"id":"http://arxiv.org/abs/2503.05630v1","updated":"2025-03-07T17:54:02Z","published":"2025-03-07T17:54:02Z","title":"Joint 3D Point Cloud Segmentation using Real-Sim Loop: From Panels to\n  Trees and Branches","summary":"  Modern orchards are planted in structured rows with distinct panel divisions\nto improve management. Accurate and efficient joint segmentation of point cloud\nfrom Panel to Tree and Branch (P2TB) is essential for robotic operations.\nHowever, most current segmentation methods focus on single instance\nsegmentation and depend on a sequence of deep networks to perform joint tasks.\nThis strategy hinders the use of hierarchical information embedded in the data,\nleading to both error accumulation and increased costs for annotation and\ncomputation, which limits its scalability for real-world applications. In this\nstudy, we proposed a novel approach that incorporated a Real2Sim L-TreeGen for\ntraining data generation and a joint model (J-P2TB) designed for the P2TB task.\nThe J-P2TB model, trained on the generated simulation dataset, was used for\njoint segmentation of real-world panel point clouds via zero-shot learning.\nCompared to representative methods, our model outperformed them in most\nsegmentation metrics while using 40% fewer learnable parameters. This Sim2Real\nresult highlighted the efficacy of L-TreeGen in model training and the\nperformance of J-P2TB for joint segmentation, demonstrating its strong\naccuracy, efficiency, and generalizability for real-world applications. These\nimprovements would not only greatly benefit the development of robots for\nautomated orchard operations but also advance digital twin technology.\n","authors":["Tian Qiu","Ruiming Du","Nikolai Spine","Lailiang Cheng","Yu Jiang"],"pdf_url":"https://arxiv.org/pdf/2503.05630v1.pdf","comment":"Accepted by ICRA 2025"},{"id":"http://arxiv.org/abs/2503.05626v1","updated":"2025-03-07T17:52:12Z","published":"2025-03-07T17:52:12Z","title":"FMT:A Multimodal Pneumonia Detection Model Based on Stacking MOE\n  Framework","summary":"  Artificial intelligence has shown the potential to improve diagnostic\naccuracy through medical image analysis for pneumonia diagnosis. However,\ntraditional multimodal approaches often fail to address real-world challenges\nsuch as incomplete data and modality loss. In this study, a Flexible Multimodal\nTransformer (FMT) was proposed, which uses ResNet-50 and BERT for joint\nrepresentation learning, followed by a dynamic masked attention strategy that\nsimulates clinical modality loss to improve robustness; finally, a sequential\nmixture of experts (MOE) architecture was used to achieve multi-level decision\nrefinement. After evaluation on a small multimodal pneumonia dataset, FMT\nachieved state-of-the-art performance with 94% accuracy, 95% recall, and 93% F1\nscore, outperforming single-modal baselines (ResNet: 89%; BERT: 79%) and the\nmedical benchmark CheXMed (90%), providing a scalable solution for multimodal\ndiagnosis of pneumonia in resource-constrained medical settings.\n","authors":["Jingyu Xu","Yang Wang"],"pdf_url":"https://arxiv.org/pdf/2503.05626v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.05618v1","updated":"2025-03-07T17:42:30Z","published":"2025-03-07T17:42:30Z","title":"Conformal Prediction for Image Segmentation Using Morphological\n  Prediction Sets","summary":"  Image segmentation is a challenging task influenced by multiple sources of\nuncertainty, such as the data labeling process or the sampling of training\ndata. In this paper we focus on binary segmentation and address these\nchallenges using conformal prediction, a family of model- and data-agnostic\nmethods for uncertainty quantification that provide finite-sample theoretical\nguarantees and applicable to any pretrained predictor. Our approach involves\ncomputing nonconformity scores, a type of prediction residual, on held-out\ncalibration data not used during training. We use dilation, one of the\nfundamental operations in mathematical morphology, to construct a margin added\nto the borders of predicted segmentation masks. At inference, the predicted set\nformed by the mask and its margin contains the ground-truth mask with high\nprobability, at a confidence level specified by the user. The size of the\nmargin serves as an indicator of predictive uncertainty for a given model and\ndataset. We work in a regime of minimal information as we do not require any\nfeedback from the predictor: only the predicted masks are needed for computing\nthe prediction sets. Hence, our method is applicable to any segmentation model,\nincluding those based on deep learning; we evaluate our approach on several\nmedical imaging applications.\n","authors":["Luca Mossina","Corentin Friedrich"],"pdf_url":"https://arxiv.org/pdf/2503.05618v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2408.11963v2","updated":"2025-03-07T17:38:59Z","published":"2024-08-21T19:31:39Z","title":"Real-Time Incremental Explanations for Object Detectors in Autonomous\n  Driving","summary":"  Object detectors are widely used in safety-critical real-time applications\nsuch as autonomous driving. Explainability is especially important for\nsafety-critical applications, and due to the variety of object detectors and\ntheir often proprietary nature, black-box explainability tools are needed.\nHowever, existing black-box explainability tools for AI models rely on multiple\nmodel calls, rendering them impractical for real-time use.\n  In this paper, we introduce IncX, an algorithm and a tool for real-time\nblack-box explainability for object detectors. The algorithm is based on linear\ntransformations of saliency maps, producing sufficient explanations. We\nevaluate our implementation on four widely used video datasets of autonomous\ndriving and demonstrate that IncX's explanations are comparable in quality to\nthe state-of-the-art and are computed two orders of magnitude faster than the\nstate-of-the-art, making them usable in real time.\n","authors":["Santiago Caldern-Pea","Hana Chockler","David A. Kelly"],"pdf_url":"https://arxiv.org/pdf/2408.11963v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.05604v1","updated":"2025-03-07T17:29:04Z","published":"2025-03-07T17:29:04Z","title":"CACTUS: An Open Dataset and Framework for Automated Cardiac Assessment\n  and Classification of Ultrasound Images Using Deep Transfer Learning","summary":"  Cardiac ultrasound (US) scanning is a commonly used techniques in cardiology\nto diagnose the health of the heart and its proper functioning. Therefore, it\nis necessary to consider ways to automate these tasks and assist medical\nprofessionals in classifying and assessing cardiac US images. Machine learning\n(ML) techniques are regarded as a prominent solution due to their success in\nnumerous applications aimed at enhancing the medical field, including\naddressing the shortage of echography technicians. However, the limited\navailability of medical data presents a significant barrier to applying ML in\ncardiology, particularly regarding US images of the heart. This paper addresses\nthis challenge by introducing the first open graded dataset for Cardiac\nAssessment and ClassificaTion of UltraSound (CACTUS), which is available\nonline. This dataset contains images obtained from scanning a CAE Blue Phantom\nand representing various heart views and different quality levels, exceeding\nthe conventional cardiac views typically found in the literature. Additionally,\nthe paper introduces a Deep Learning (DL) framework consisting of two main\ncomponents. The first component classifies cardiac US images based on the heart\nview using a Convolutional Neural Network (CNN). The second component uses\nTransfer Learning (TL) to fine-tune the knowledge from the first component and\ncreate a model for grading and assessing cardiac images. The framework\ndemonstrates high performance in both classification and grading, achieving up\nto 99.43% accuracy and as low as 0.3067 error, respectively. To showcase its\nrobustness, the framework is further fine-tuned using new images representing\nadditional cardiac views and compared to several other state-of-the-art\narchitectures. The framework's outcomes and performance in handling real-time\nscans were also assessed using a questionnaire answered by cardiac experts.\n","authors":["Hanae Elmekki","Ahmed Alagha","Hani Sami","Amanda Spilkin","Antonela Mariel Zanuttini","Ehsan Zakeri","Jamal Bentahar","Lyes Kadem","Wen-Fang Xie","Philippe Pibarot","Rabeb Mizouni","Hadi Otrok","Shakti Singh","Azzam Mourad"],"pdf_url":"https://arxiv.org/pdf/2503.05604v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.05600v1","updated":"2025-03-07T17:26:27Z","published":"2025-03-07T17:26:27Z","title":"D2GV: Deformable 2D Gaussian Splatting for Video Representation in\n  400FPS","summary":"  Implicit Neural Representations (INRs) have emerged as a powerful approach\nfor video representation, offering versatility across tasks such as compression\nand inpainting. However, their implicit formulation limits both\ninterpretability and efficacy, undermining their practicality as a\ncomprehensive solution. We propose a novel video representation based on\ndeformable 2D Gaussian splatting, dubbed D2GV, which aims to achieve three key\nobjectives: 1) improved efficiency while delivering superior quality; 2)\nenhanced scalability and interpretability; and 3) increased friendliness for\ndownstream tasks. Specifically, we initially divide the video sequence into\nfixed-length Groups of Pictures (GoP) to allow parallel training and linear\nscalability with video length. For each GoP, D2GV represents video frames by\napplying differentiable rasterization to 2D Gaussians, which are deformed from\na canonical space into their corresponding timestamps. Notably, leveraging\nefficient CUDA-based rasterization, D2GV converges fast and decodes at speeds\nexceeding 400 FPS, while delivering quality that matches or surpasses\nstate-of-the-art INRs. Moreover, we incorporate a learnable pruning and\nquantization strategy to streamline D2GV into a more compact representation. We\ndemonstrate D2GV's versatility in tasks including video interpolation,\ninpainting and denoising, underscoring its potential as a promising solution\nfor video representation. Code is available at:\n\\href{https://github.com/Evan-sudo/D2GV}{https://github.com/Evan-sudo/D2GV}.\n","authors":["Mufan Liu","Qi Yang","Miaoran Zhao","He Huang","Le Yang","Zhu Li","Yiling Xu"],"pdf_url":"https://arxiv.org/pdf/2503.05600v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.05595v1","updated":"2025-03-07T17:23:52Z","published":"2025-03-07T17:23:52Z","title":"Anti-Diffusion: Preventing Abuse of Modifications of Diffusion-Based\n  Models","summary":"  Although diffusion-based techniques have shown remarkable success in image\ngeneration and editing tasks, their abuse can lead to severe negative social\nimpacts. Recently, some works have been proposed to provide defense against the\nabuse of diffusion-based methods. However, their protection may be limited in\nspecific scenarios by manually defined prompts or the stable diffusion (SD)\nversion. Furthermore, these methods solely focus on tuning methods, overlooking\nediting methods that could also pose a significant threat. In this work, we\npropose Anti-Diffusion, a privacy protection system designed for general\ndiffusion-based methods, applicable to both tuning and editing techniques. To\nmitigate the limitations of manually defined prompts on defense performance, we\nintroduce the prompt tuning (PT) strategy that enables precise expression of\noriginal images. To provide defense against both tuning and editing methods, we\npropose the semantic disturbance loss (SDL) to disrupt the semantic information\nof protected images. Given the limited research on the defense against editing\nmethods, we develop a dataset named Defense-Edit to assess the defense\nperformance of various methods. Experiments demonstrate that our Anti-Diffusion\nachieves superior defense performance across a wide range of diffusion-based\ntechniques in different scenarios.\n","authors":["Zheng Li","Liangbin Xie","Jiantao Zhou","Xintao Wang","Haiwei Wu","Jinyu Tian"],"pdf_url":"https://arxiv.org/pdf/2503.05595v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.17385v2","updated":"2025-03-07T17:21:06Z","published":"2024-11-26T12:44:17Z","title":"DepthCues: Evaluating Monocular Depth Perception in Large Vision Models","summary":"  Large-scale pre-trained vision models are becoming increasingly prevalent,\noffering expressive and generalizable visual representations that benefit\nvarious downstream tasks. Recent studies on the emergent properties of these\nmodels have revealed their high-level geometric understanding, in particular in\nthe context of depth perception. However, it remains unclear how depth\nperception arises in these models without explicit depth supervision provided\nduring pre-training. To investigate this, we examine whether the monocular\ndepth cues, similar to those used by the human visual system, emerge in these\nmodels. We introduce a new benchmark, DepthCues, designed to evaluate depth cue\nunderstanding, and present findings across 20 diverse and representative\npre-trained vision models. Our analysis shows that human-like depth cues emerge\nin more recent larger models. We also explore enhancing depth perception in\nlarge vision models by fine-tuning on DepthCues, and find that even without\ndense depth supervision, this improves depth estimation. To support further\nresearch, our benchmark and evaluation code will be made publicly available for\nstudying depth perception in vision models.\n","authors":["Duolikun Danier","Mehmet Aygn","Changjian Li","Hakan Bilen","Oisin Mac Aodha"],"pdf_url":"https://arxiv.org/pdf/2411.17385v2.pdf","comment":"Accepted to CVPR 2025. Project page:\n  https://danier97.github.io/depthcues/"},{"id":"http://arxiv.org/abs/2503.05584v1","updated":"2025-03-07T17:11:07Z","published":"2025-03-07T17:11:07Z","title":"QArtSR: Quantization via Reverse-Module and Timestep-Retraining in\n  One-Step Diffusion based Image Super-Resolution","summary":"  One-step diffusion-based image super-resolution (OSDSR) models are showing\nincreasingly superior performance nowadays. However, although their denoising\nsteps are reduced to one and they can be quantized to 8-bit to reduce the costs\nfurther, there is still significant potential for OSDSR to quantize to lower\nbits. To explore more possibilities of quantized OSDSR, we propose an efficient\nmethod, Quantization via reverse-module and timestep-retraining for OSDSR,\nnamed QArtSR. Firstly, we investigate the influence of timestep value on the\nperformance of quantized models. Then, we propose Timestep Retraining\nQuantization (TRQ) and Reversed Per-module Quantization (RPQ) strategies to\ncalibrate the quantized model. Meanwhile, we adopt the module and image losses\nto update all quantized modules. We only update the parameters in quantization\nfinetuning components, excluding the original weights. To ensure that all\nmodules are fully finetuned, we add extended end-to-end training after\nper-module stage. Our 4-bit and 2-bit quantization experimental results\nindicate that QArtSR obtains superior effects against the recent leading\ncomparison methods. The performance of 4-bit QArtSR is close to the\nfull-precision one. Our code will be released at\nhttps://github.com/libozhu03/QArtSR.\n","authors":["Libo Zhu","Haotong Qin","Kaicheng Yang","Wenbo Li","Yong Guo","Yulun Zhang","Susanto Rahardja","Xiaokang Yang"],"pdf_url":"https://arxiv.org/pdf/2503.05584v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.05578v1","updated":"2025-03-07T17:00:41Z","published":"2025-03-07T17:00:41Z","title":"Novel Object 6D Pose Estimation with a Single Reference View","summary":"  Existing novel object 6D pose estimation methods typically rely on CAD models\nor dense reference views, which are both difficult to acquire. Using only a\nsingle reference view is more scalable, but challenging due to large pose\ndiscrepancies and limited geometric and spatial information. To address these\nissues, we propose a Single-Reference-based novel object 6D (SinRef-6D) pose\nestimation method. Our key idea is to iteratively establish point-wise\nalignment in the camera coordinate system based on state space models (SSMs).\nSpecifically, iterative camera-space point-wise alignment can effectively\nhandle large pose discrepancies, while our proposed RGB and Points SSMs can\ncapture long-range dependencies and spatial information from a single view,\noffering linear complexity and superior spatial modeling capability. Once\npre-trained on synthetic data, SinRef-6D can estimate the 6D pose of a novel\nobject using only a single reference view, without requiring retraining or a\nCAD model. Extensive experiments on six popular datasets and real-world robotic\nscenes demonstrate that we achieve on-par performance with CAD-based and dense\nreference view-based methods, despite operating in the more challenging single\nreference setting. Code will be released at\nhttps://github.com/CNJianLiu/SinRef-6D.\n","authors":["Jian Liu","Wei Sun","Kai Zeng","Jin Zheng","Hui Yang","Lin Wang","Hossein Rahmani","Ajmal Mian"],"pdf_url":"https://arxiv.org/pdf/2503.05578v1.pdf","comment":"17 pages, 12 figures (including supplementary material)"},{"id":"http://arxiv.org/abs/2503.05568v1","updated":"2025-03-07T16:47:48Z","published":"2025-03-07T16:47:48Z","title":"TomatoScanner: phenotyping tomato fruit based on only RGB image","summary":"  In tomato greenhouse, phenotypic measurement is meaningful for researchers\nand farmers to monitor crop growth, thereby precisely control environmental\nconditions in time, leading to better quality and higher yield. Traditional\nphenotyping mainly relies on manual measurement, which is accurate but\ninefficient, more importantly, endangering the health and safety of people.\nSeveral studies have explored computer vision-based methods to replace manual\nphenotyping. However, the 2D-based need extra calibration, or cause destruction\nto fruit, or can only measure limited and meaningless traits. The 3D-based need\nextra depth camera, which is expensive and unacceptable for most farmers. In\nthis paper, we propose a non-contact tomato fruit phenotyping method, titled\nTomatoScanner, where RGB image is all you need for input. First, pixel feature\nis extracted by instance segmentation of our proposed EdgeYOLO with\npreprocessing of individual separation and pose correction. Second, depth\nfeature is extracted by depth estimation of Depth Pro. Third, pixel and depth\nfeature are fused to output phenotype results in reality. We establish\nself-built Tomato Phenotype Dataset to test TomatoScanner, which achieves\nexcellent phenotyping on width, height, vertical area and volume, with median\nrelative error of 5.63%, 7.03%, -0.64% and 37.06%, respectively. We propose and\nadd three innovative modules - EdgeAttention, EdgeLoss and EdgeBoost - into\nEdgeYOLO, to enhance the segmentation accuracy on edge portion. Precision and\nmean Edge Error greatly improve from 0.943 and 5.641% to 0.986 and 2.963%,\nrespectively. Meanwhile, EdgeYOLO keeps lightweight and efficient, with 48.7 M\nweights size and 76.34 FPS. Codes and datasets:\nhttps://github.com/AlexTraveling/TomatoScanner.\n","authors":["Xiaobei Zhao","Xiangrong Zeng","Yihang Ma","Pengjin Tang","Xiang Li"],"pdf_url":"https://arxiv.org/pdf/2503.05568v1.pdf","comment":"12 pages, 37 figures. Codes and datasets are open-sourced in\n  https://github.com/AlexTraveling/TomatoScanner"},{"id":"http://arxiv.org/abs/2503.05549v1","updated":"2025-03-07T16:20:36Z","published":"2025-03-07T16:20:36Z","title":"Stereo Any Video: Temporally Consistent Stereo Matching","summary":"  This paper introduces Stereo Any Video, a powerful framework for video stereo\nmatching. It can estimate spatially accurate and temporally consistent\ndisparities without relying on auxiliary information such as camera poses or\noptical flow. The strong capability is driven by rich priors from monocular\nvideo depth models, which are integrated with convolutional features to produce\nstable representations. To further enhance performance, key architectural\ninnovations are introduced: all-to-all-pairs correlation, which constructs\nsmooth and robust matching cost volumes, and temporal convex upsampling, which\nimproves temporal coherence. These components collectively ensure robustness,\naccuracy, and temporal consistency, setting a new standard in video stereo\nmatching. Extensive experiments demonstrate that our method achieves\nstate-of-the-art performance across multiple datasets both qualitatively and\nquantitatively in zero-shot settings, as well as strong generalization to\nreal-world indoor and outdoor scenarios.\n","authors":["Junpeng Jing","Weixun Luo","Ye Mao","Krystian Mikolajczyk"],"pdf_url":"https://arxiv.org/pdf/2503.05549v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.05543v1","updated":"2025-03-07T16:15:00Z","published":"2025-03-07T16:15:00Z","title":"Pi-GPS: Enhancing Geometry Problem Solving by Unleashing the Power of\n  Diagrammatic Information","summary":"  Geometry problem solving has garnered increasing attention due to its\npotential applications in intelligent education field. Inspired by the\nobservation that text often introduces ambiguities that diagrams can clarify,\nthis paper presents Pi-GPS, a novel framework that unleashes the power of\ndiagrammatic information to resolve textual ambiguities, an aspect largely\noverlooked in prior research. Specifically, we design a micro module comprising\na rectifier and verifier: the rectifier employs MLLMs to disambiguate text\nbased on the diagrammatic context, while the verifier ensures the rectified\noutput adherence to geometric rules, mitigating model hallucinations.\nAdditionally, we explore the impact of LLMs in theorem predictor based on the\ndisambiguated formal language. Empirical results demonstrate that Pi-GPS\nsurpasses state-of-the-art models, achieving a nearly 10\\% improvement on\nGeometry3K over prior neural-symbolic approaches. We hope this work highlights\nthe significance of resolving textual ambiguity in multimodal mathematical\nreasoning, a crucial factor limiting performance.\n","authors":["Junbo Zhao","Ting Zhang","Jiayu Sun","Mi Tian","Hua Huang"],"pdf_url":"https://arxiv.org/pdf/2503.05543v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.05541v1","updated":"2025-03-07T16:11:55Z","published":"2025-03-07T16:11:55Z","title":"Disconnect to Connect: A Data Augmentation Method for Improving Topology\n  Accuracy in Image Segmentation","summary":"  Accurate segmentation of thin, tubular structures (e.g., blood vessels) is\nchallenging for deep neural networks. These networks classify individual\npixels, and even minor misclassifications can break the thin connections within\nthese structures. Existing methods for improving topology accuracy, such as\ntopology loss functions, rely on very precise, topologically-accurate training\nlabels, which are difficult to obtain. This is because annotating images,\nespecially 3D images, is extremely laborious and time-consuming. Low image\nresolution and contrast further complicates the annotation by causing tubular\nstructures to appear disconnected. We present CoLeTra, a data augmentation\nstrategy that integrates to the models the prior knowledge that structures that\nappear broken are actually connected. This is achieved by creating images with\nthe appearance of disconnected structures while maintaining the original\nlabels. Our extensive experiments, involving different architectures, loss\nfunctions, and datasets, demonstrate that CoLeTra leads to segmentations\ntopologically more accurate while often improving the Dice coefficient and\nHausdorff distance. CoLeTra's hyper-parameters are intuitive to tune, and our\nsensitivity analysis shows that CoLeTra is robust to changes in these\nhyper-parameters. We also release a dataset specifically suited for image\nsegmentation methods with a focus on topology accuracy. CoLetra's code can be\nfound at https://github.com/jmlipman/CoLeTra.\n","authors":["Juan Miguel Valverde","Maja stergaard","Adrian Rodriguez-Palomo","Peter Alling Strange Vibe","Nina Klln Wittig","Henrik Birkedal","Anders Bjorholm Dahl"],"pdf_url":"https://arxiv.org/pdf/2503.05541v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.01565v2","updated":"2025-03-07T16:08:17Z","published":"2025-03-03T14:09:36Z","title":"AutoLUT: LUT-Based Image Super-Resolution with Automatic Sampling and\n  Adaptive Residual Learning","summary":"  In recent years, the increasing popularity of Hi-DPI screens has driven a\nrising demand for high-resolution images. However, the limited computational\npower of edge devices poses a challenge in deploying complex super-resolution\nneural networks, highlighting the need for efficient methods. While prior works\nhave made significant progress, they have not fully exploited pixel-level\ninformation. Moreover, their reliance on fixed sampling patterns limits both\naccuracy and the ability to capture fine details in low-resolution images. To\naddress these challenges, we introduce two plug-and-play modules designed to\ncapture and leverage pixel information effectively in Look-Up Table (LUT) based\nsuper-resolution networks. Our method introduces Automatic Sampling\n(AutoSample), a flexible LUT sampling approach where sampling weights are\nautomatically learned during training to adapt to pixel variations and expand\nthe receptive field without added inference cost. We also incorporate Adaptive\nResidual Learning (AdaRL) to enhance inter-layer connections, enabling detailed\ninformation flow and improving the network's ability to reconstruct fine\ndetails. Our method achieves significant performance improvements on both MuLUT\nand SPF-LUT while maintaining similar storage sizes. Specifically, for MuLUT,\nwe achieve a PSNR improvement of approximately +0.20 dB improvement on average\nacross five datasets. For SPF-LUT, with more than a 50% reduction in storage\nspace and about a 2/3 reduction in inference time, our method still maintains\nperformance comparable to the original. The code is available at\nhttps://github.com/SuperKenVery/AutoLUT.\n","authors":["Yuheng Xu","Shijie Yang","Xin Liu","Jie Liu","Jie Tang","Gangshan Wu"],"pdf_url":"https://arxiv.org/pdf/2503.01565v2.pdf","comment":"Accepted by CVPR2025"},{"id":"http://arxiv.org/abs/2411.03554v3","updated":"2025-03-07T16:05:19Z","published":"2024-11-05T23:26:10Z","title":"Benchmarking Vision Language Model Unlearning via Fictitious Facial\n  Identity Dataset","summary":"  Machine unlearning has emerged as an effective strategy for forgetting\nspecific information in the training data. However, with the increasing\nintegration of visual data, privacy concerns in Vision Language Models (VLMs)\nremain underexplored. To address this, we introduce Facial Identity Unlearning\nBenchmark (FIUBench), a novel VLM unlearning benchmark designed to robustly\nevaluate the effectiveness of unlearning algorithms under the Right to be\nForgotten setting. Specifically, we formulate the VLM unlearning task via\nconstructing the Fictitious Facial Identity VQA dataset and apply a two-stage\nevaluation pipeline that is designed to precisely control the sources of\ninformation and their exposure levels. In terms of evaluation, since VLM\nsupports various forms of ways to ask questions with the same semantic meaning,\nwe also provide robust evaluation metrics including membership inference\nattacks and carefully designed adversarial privacy attacks to evaluate the\nperformance of algorithms. Through the evaluation of four baseline VLM\nunlearning algorithms within FIUBench, we find that all methods remain limited\nin their unlearning performance, with significant trade-offs between model\nutility and forget quality. Furthermore, our findings also highlight the\nimportance of privacy attacks for robust evaluations. We hope FIUBench will\ndrive progress in developing more effective VLM unlearning algorithms.\n","authors":["Yingzi Ma","Jiongxiao Wang","Fei Wang","Siyuan Ma","Jiazhao Li","Jinsheng Pan","Xiujun Li","Furong Huang","Lichao Sun","Bo Li","Yejin Choi","Muhao Chen","Chaowei Xiao"],"pdf_url":"https://arxiv.org/pdf/2411.03554v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.05534v1","updated":"2025-03-07T16:02:11Z","published":"2025-03-07T16:02:11Z","title":"S4M: Segment Anything with 4 Extreme Points","summary":"  The Segment Anything Model (SAM) has revolutionized open-set interactive\nimage segmentation, inspiring numerous adapters for the medical domain.\nHowever, SAM primarily relies on sparse prompts such as point or bounding box,\nwhich may be suboptimal for fine-grained instance segmentation, particularly in\nendoscopic imagery, where precise localization is critical and existing prompts\nstruggle to capture object boundaries effectively. To address this, we\nintroduce S4M (Segment Anything with 4 Extreme Points), which augments SAM by\nleveraging extreme points -- the top-, bottom-, left-, and right-most points of\nan instance -- prompts. These points are intuitive to identify and provide a\nfaster, structured alternative to box prompts. However, a na\\\"ive use of\nextreme points degrades performance, due to SAM's inability to interpret their\nsemantic roles. To resolve this, we introduce dedicated learnable embeddings,\nenabling the model to distinguish extreme points from generic free-form points\nand better reason about their spatial relationships. We further propose an\nauxiliary training task through the Canvas module, which operates solely on\nprompts -- without vision input -- to predict a coarse instance mask. This\nencourages the model to internalize the relationship between extreme points and\nmask distributions, leading to more robust segmentation. S4M outperforms other\nSAM-based approaches on three endoscopic surgical datasets, demonstrating its\neffectiveness in complex scenarios. Finally, we validate our approach through a\nhuman annotation study on surgical endoscopic videos, confirming that extreme\npoints are faster to acquire than bounding boxes.\n","authors":["Adrien Meyer","Lorenzo Arboit","Giuseppe Massimiani","Francesco Brucchi","Luca Emanuele Amodio","Didier Mutter","Nicolas Padoy"],"pdf_url":"https://arxiv.org/pdf/2503.05534v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.05531v1","updated":"2025-03-07T15:58:36Z","published":"2025-03-07T15:58:36Z","title":"State-of-the-Art Stroke Lesion Segmentation at 1/1000th of Parameters","summary":"  Efficient and accurate whole-brain lesion segmentation remains a challenge in\nmedical image analysis. In this work, we revisit MeshNet, a parameter-efficient\nsegmentation model, and introduce a novel multi-scale dilation pattern with an\nencoder-decoder structure. This innovation enables capturing broad contextual\ninformation and fine-grained details without traditional downsampling,\nupsampling, or skip-connections. Unlike previous approaches processing\nsubvolumes or slices, we operate directly on whole-brain $256^3$ MRI volumes.\nEvaluations on the Aphasia Recovery Cohort (ARC) dataset demonstrate that\nMeshNet achieves superior or comparable DICE scores to state-of-the-art\narchitectures such as MedNeXt and U-MAMBA at 1/1000th of parameters. Our\nresults validate MeshNet's strong balance of efficiency and performance, making\nit particularly suitable for resource-limited environments such as web-based\napplications and opening new possibilities for the widespread deployment of\nadvanced medical image analysis tools.\n","authors":["Alex Fedorov","Yutong Bu","Xiao Hu","Chris Rorden","Sergey Plis"],"pdf_url":"https://arxiv.org/pdf/2503.05531v1.pdf","comment":"International Symposium on Biomedical Imaging, April 14-17, 2025"},{"id":"http://arxiv.org/abs/2309.04145v3","updated":"2025-03-07T15:46:46Z","published":"2023-09-08T06:15:27Z","title":"Depth Completion with Multiple Balanced Bases and Confidence for Dense\n  Monocular SLAM","summary":"  Dense SLAM based on monocular cameras does indeed have immense application\nvalue in the field of AR/VR, especially when it is performed on a mobile\ndevice. In this paper, we propose a novel method that integrates a light-weight\ndepth completion network into a sparse SLAM system using a multi-basis depth\nrepresentation, so that dense mapping can be performed online even on a mobile\nphone. Specifically, we present a specifically optimized multi-basis depth\ncompletion network, called BBC-Net, tailored to the characteristics of\ntraditional sparse SLAM systems. BBC-Net can predict multiple balanced bases\nand a confidence map from a monocular image with sparse points generated by\noff-the-shelf keypoint-based SLAM systems. The final depth is a linear\ncombination of predicted depth bases that can be optimized by tuning the\ncorresponding weights. To seamlessly incorporate the weights into traditional\nSLAM optimization and ensure efficiency and robustness, we design a set of\ndepth weight factors, which makes our network a versatile plug-in module,\nfacilitating easy integration into various existing sparse SLAM systems and\nsignificantly enhancing global depth consistency through bundle adjustment. To\nverify the portability of our method, we integrate BBC-Net into two\nrepresentative SLAM systems. The experimental results on various datasets show\nthat the proposed method achieves better performance in monocular dense mapping\nthan the state-of-the-art methods. We provide an online demo running on a\nmobile phone, which verifies the efficiency and mapping quality of the proposed\nmethod in real-world scenarios.\n","authors":["Weijian Xie","Guanyi Chu","Quanhao Qian","Yihao Yu","Hai Li","Danpeng Chen","Shangjin Zhai","Nan Wang","Hujun Bao","Guofeng Zhang"],"pdf_url":"https://arxiv.org/pdf/2309.04145v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.05522v1","updated":"2025-03-07T15:45:43Z","published":"2025-03-07T15:45:43Z","title":"Post-Hoc Concept Disentanglement: From Correlated to Isolated Concept\n  Representations","summary":"  Concept Activation Vectors (CAVs) are widely used to model\nhuman-understandable concepts as directions within the latent space of neural\nnetworks. They are trained by identifying directions from the activations of\nconcept samples to those of non-concept samples. However, this method often\nproduces similar, non-orthogonal directions for correlated concepts, such as\n\"beard\" and \"necktie\" within the CelebA dataset, which frequently co-occur in\nimages of men. This entanglement complicates the interpretation of concepts in\nisolation and can lead to undesired effects in CAV applications, such as\nactivation steering. To address this issue, we introduce a post-hoc concept\ndisentanglement method that employs a non-orthogonality loss, facilitating the\nidentification of orthogonal concept directions while preserving directional\ncorrectness. We evaluate our approach with real-world and controlled correlated\nconcepts in CelebA and a synthetic FunnyBirds dataset with VGG16 and ResNet18\narchitectures. We further demonstrate the superiority of orthogonalized concept\nrepresentations in activation steering tasks, allowing (1) the insertion of\nisolated concepts into input images through generative models and (2) the\nremoval of concepts for effective shortcut suppression with reduced impact on\ncorrelated concepts in comparison to baseline CAVs.\n","authors":["Eren Erogullari","Sebastian Lapuschkin","Wojciech Samek","Frederik Pahde"],"pdf_url":"https://arxiv.org/pdf/2503.05522v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2407.21604v2","updated":"2025-03-07T15:44:36Z","published":"2024-07-31T13:38:47Z","title":"MicroMIL: Graph-based Contextual Multiple Instance Learning for Patient\n  Diagnosis Using Microscopy Images","summary":"  Cancer diagnosis has greatly benefited from the integration of whole-slide\nimages (WSIs) with multiple instance learning (MIL), enabling high-resolution\nanalysis of tissue morphology. Graph-based MIL (GNN-MIL) approaches have\nemerged as powerful solutions for capturing spatial and relational structures\nin WSIs, thereby improving diagnostic accuracy. However, despite their\neffectiveness, WSIs require significant computational and infrastructural\nresources, limiting accessibility in resource-constrained settings. Microscopy\nimaging provides a cost-effective alternative, but applying GNN-MIL to\nmicroscopy imaging is challenging due to the absence of spatial coordinates and\nthe high redundancy in pathologist-acquired images. To address these issues, we\nintroduce MicroMIL, the first weakly-supervised MIL framework specifically\ndesigned for microscopy imaging. MicroMIL leverages a representative image\nextractor (RIE) that employs deep cluster embedding (DCE) and hard\nGumbel-Softmax to dynamically reduce redundancy and select representative\nimages. These selected images serve as graph nodes, with edges determined by\ncosine similarity, eliminating the need for spatial coordinates while\npreserving relational structure. Extensive experiments on a real-world colon\ncancer dataset and the BreakHis dataset demonstrate that MicroMIL achieves\nstate-of-the-art performance, improving both diagnostic accuracy and robustness\nto redundancy. The code is available at\nhttps://anonymous.4open.science/r/MicroMIL-6C7C\n","authors":["JongWoo Kim","Bryan Wong","Huazhu Fu","Willmer Rafell Quiones","MunYong Yi"],"pdf_url":"https://arxiv.org/pdf/2407.21604v2.pdf","comment":"The first two authors contributed equally to this work"},{"id":"http://arxiv.org/abs/2503.05520v1","updated":"2025-03-07T15:42:51Z","published":"2025-03-07T15:42:51Z","title":"Removing Geometric Bias in One-Class Anomaly Detection with Adaptive\n  Feature Perturbation","summary":"  One-class anomaly detection aims to detect objects that do not belong to a\npredefined normal class. In practice training data lack those anomalous\nsamples; hence state-of-the-art methods are trained to discriminate between\nnormal and synthetically-generated pseudo-anomalous data. Most methods use data\naugmentation techniques on normal images to simulate anomalies. However the\nbest-performing ones implicitly leverage a geometric bias present in the\nbenchmarking datasets. This limits their usability in more general conditions.\nOthers are relying on basic noising schemes that may be suboptimal in capturing\nthe underlying structure of normal data. In addition most still favour the\nimage domain to generate pseudo-anomalies training models end-to-end from only\nthe normal class and overlooking richer representations of the information. To\novercome these limitations we consider frozen yet rich feature spaces given by\npretrained models and create pseudo-anomalous features with a novel adaptive\nlinear feature perturbation technique. It adapts the noise distribution to each\nsample applies decaying linear perturbations to feature vectors and further\nguides the classification process using a contrastive learning objective.\nExperimental evaluation conducted on both standard and geometric bias-free\ndatasets demonstrates the superiority of our approach with respect to\ncomparable baselines. The codebase is accessible via our public repository.\n","authors":["Romain Hermary","Vincent Gaudillire","Abd El Rahman Shabayek","Djamila Aouada"],"pdf_url":"https://arxiv.org/pdf/2503.05520v1.pdf","comment":"Published in WACV 2025"},{"id":"http://arxiv.org/abs/2412.19225v2","updated":"2025-03-07T15:33:32Z","published":"2024-12-26T14:05:01Z","title":"Completion as Enhancement: A Degradation-Aware Selective Image Guided\n  Network for Depth Completion","summary":"  In this paper, we introduce the Selective Image Guided Network (SigNet), a\nnovel degradation-aware framework that transforms depth completion into depth\nenhancement for the first time. Moving beyond direct completion using\nconvolutional neural networks (CNNs), SigNet initially densifies sparse depth\ndata through non-CNN densification tools to obtain coarse yet dense depth. This\napproach eliminates the mismatch and ambiguity caused by direct convolution\nover irregularly sampled sparse data. Subsequently, SigNet redefines completion\nas enhancement, establishing a self-supervised degradation bridge between the\ncoarse depth and the targeted dense depth for effective RGB-D fusion. To\nachieve this, SigNet leverages the implicit degradation to adaptively select\nhigh-frequency components (e.g., edges) of RGB data to compensate for the\ncoarse depth. This degradation is further integrated into a multi-modal\nconditional Mamba, dynamically generating the state parameters to enable\nefficient global high-frequency information interaction. We conduct extensive\nexperiments on the NYUv2, DIML, SUN RGBD, and TOFDC datasets, demonstrating the\nstate-of-the-art (SOTA) performance of SigNet.\n","authors":["Zhiqiang Yan","Zhengxue Wang","Kun Wang","Jun Li","Jian Yang"],"pdf_url":"https://arxiv.org/pdf/2412.19225v2.pdf","comment":"CVPR 2025"},{"id":"http://arxiv.org/abs/2503.05492v1","updated":"2025-03-07T15:01:55Z","published":"2025-03-07T15:01:55Z","title":"FastMap: Fast Queries Initialization Based Vectorized HD Map\n  Reconstruction Framework","summary":"  Reconstruction of high-definition maps is a crucial task in perceiving the\nautonomous driving environment, as its accuracy directly impacts the\nreliability of prediction and planning capabilities in downstream modules.\nCurrent vectorized map reconstruction methods based on the DETR framework\nencounter limitations due to the redundancy in the decoder structure,\nnecessitating the stacking of six decoder layers to maintain performance, which\nsignificantly hampers computational efficiency. To tackle this issue, we\nintroduce FastMap, an innovative framework designed to reduce decoder\nredundancy in existing approaches. FastMap optimizes the decoder architecture\nby employing a single-layer, two-stage transformer that achieves multilevel\nrepresentation capabilities. Our framework eliminates the conventional practice\nof randomly initializing queries and instead incorporates a heatmap-guided\nquery generation module during the decoding phase, which effectively maps image\nfeatures into structured query vectors using learnable positional encoding.\nAdditionally, we propose a geometry-constrained point-to-line loss mechanism\nfor FastMap, which adeptly addresses the challenge of distinguishing highly\nhomogeneous features that often arise in traditional point-to-point loss\ncomputations. Extensive experiments demonstrate that FastMap achieves\nstate-of-the-art performance in both nuScenes and Argoverse2 datasets, with its\ndecoder operating 3.2 faster than the baseline. Code and more demos are\navailable at https://github.com/hht1996ok/FastMap.\n","authors":["Haotian Hu","Jingwei Xu","Fanyi Wang","Toyota Li","Yaonong Wang","Laifeng Hu","Zhiwang Zhang"],"pdf_url":"https://arxiv.org/pdf/2503.05492v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.05484v1","updated":"2025-03-07T14:54:54Z","published":"2025-03-07T14:54:54Z","title":"DecoupledGaussian: Object-Scene Decoupling for Physics-Based Interaction","summary":"  We present DecoupledGaussian, a novel system that decouples static objects\nfrom their contacted surfaces captured in-the-wild videos, a key prerequisite\nfor realistic Newtonian-based physical simulations. Unlike prior methods\nfocused on synthetic data or elastic jittering along the contact surface, which\nprevent objects from fully detaching or moving independently, DecoupledGaussian\nallows for significant positional changes without being constrained by the\ninitial contacted surface. Recognizing the limitations of current 2D inpainting\ntools for restoring 3D locations, our approach proposes joint Poisson fields to\nrepair and expand the Gaussians of both objects and contacted scenes after\nseparation. This is complemented by a multi-carve strategy to refine the\nobject's geometry. Our system enables realistic simulations of decoupling\nmotions, collisions, and fractures driven by user-specified impulses,\nsupporting complex interactions within and across multiple scenes. We validate\nDecoupledGaussian through a comprehensive user study and quantitative\nbenchmarks. This system enhances digital interaction with objects and scenes in\nreal-world environments, benefiting industries such as VR, robotics, and\nautonomous driving. Our project page is at:\nhttps://wangmiaowei.github.io/DecoupledGaussian.github.io/.\n","authors":["Miaowei Wang","Yibo Zhang","Rui Ma","Weiwei Xu","Changqing Zou","Daniel Morris"],"pdf_url":"https://arxiv.org/pdf/2503.05484v1.pdf","comment":"CVPR2025 Accepted"},{"id":"http://arxiv.org/abs/2404.07785v2","updated":"2025-03-07T14:51:06Z","published":"2024-04-11T14:28:04Z","title":"PRAM: Place Recognition Anywhere Model for Efficient Visual Localization","summary":"  Visual localization is a key technique to a variety of applications, e.g.,\nautonomous driving, AR/VR, and robotics. For these real applications, both\nefficiency and accuracy are important especially on edge devices with limited\ncomputing resources. However, previous frameworks, e.g., absolute pose\nregression (APR), scene coordinate regression (SCR), and the hierarchical\nmethod (HM), have limited either accuracy or efficiency in both indoor and\noutdoor environments. In this paper, we propose the place recognition anywhere\nmodel (PRAM), a new framework, to perform visual localization efficiently and\naccurately by recognizing 3D landmarks. Specifically, PRAM first generates\nlandmarks directly in 3D space in a self-supervised manner. Without relying on\ncommonly used classic semantic labels, these 3D landmarks can be defined in any\nplace in indoor and outdoor scenes with higher generalization ability.\nRepresenting the map with 3D landmarks, PRAM discards global descriptors,\nrepetitive local descriptors, and redundant 3D points, increasing the memory\nefficiency significantly. Then, sparse keypoints, rather than dense pixels, are\nutilized as the input tokens to a transformer-based recognition module for\nlandmark recognition, which enables PRAM to recognize hundreds of landmarks\nwith high time and memory efficiency. At test time, sparse keypoints and\npredicted landmark labels are utilized for outlier removal and landmark-wise\n2D-3D matching as opposed to exhaustive 2D-2D matching, which further increases\nthe time efficiency. A comprehensive evaluation of APRs, SCRs, HMs, and PRAM on\nboth indoor and outdoor datasets demonstrates that PRAM outperforms ARPs and\nSCRs in large-scale scenes with a large margin and gives competitive accuracy\nto HMs but reduces over 90\\% memory cost and runs 2.4 times faster, leading to\na better balance between efficiency and accuracy.\n","authors":["Fei Xue","Ignas Budvytis","Roberto Cipolla"],"pdf_url":"https://arxiv.org/pdf/2404.07785v2.pdf","comment":"project page: https://feixue94.github.io/pram-project/"},{"id":"http://arxiv.org/abs/2503.05464v1","updated":"2025-03-07T14:33:54Z","published":"2025-03-07T14:33:54Z","title":"Automatic Teaching Platform on Vision Language Retrieval Augmented\n  Generation","summary":"  Automating teaching presents unique challenges, as replicating human\ninteraction and adaptability is complex. Automated systems cannot often provide\nnuanced, real-time feedback that aligns with students' individual learning\npaces or comprehension levels, which can hinder effective support for diverse\nneeds. This is especially challenging in fields where abstract concepts require\nadaptive explanations. In this paper, we propose a vision language retrieval\naugmented generation (named VL-RAG) system that has the potential to bridge\nthis gap by delivering contextually relevant, visually enriched responses that\ncan enhance comprehension. By leveraging a database of tailored answers and\nimages, the VL-RAG system can dynamically retrieve information aligned with\nspecific questions, creating a more interactive and engaging experience that\nfosters deeper understanding and active student participation. It allows\nstudents to explore concepts visually and verbally, promoting deeper\nunderstanding and reducing the need for constant human oversight while\nmaintaining flexibility to expand across different subjects and course\nmaterial.\n","authors":["Ruslan Gokhman","Jialu Li","Youshan Zhang"],"pdf_url":"https://arxiv.org/pdf/2503.05464v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2501.00962v3","updated":"2025-03-07T14:31:49Z","published":"2025-01-01T21:47:52Z","title":"OASIS Uncovers: High-Quality T2I Models, Same Old Stereotypes","summary":"  Images generated by text-to-image (T2I) models often exhibit visual biases\nand stereotypes of concepts such as culture and profession. Existing\nquantitative measures of stereotypes are based on statistical parity that does\nnot align with the sociological definition of stereotypes and, therefore,\nincorrectly categorizes biases as stereotypes. Instead of oversimplifying\nstereotypes as biases, we propose a quantitative measure of stereotypes that\naligns with its sociological definition. We then propose OASIS to measure the\nstereotypes in a generated dataset and understand their origins within the T2I\nmodel. OASIS includes two scores to measure stereotypes from a generated image\ndataset: (M1) Stereotype Score to measure the distributional violation of\nstereotypical attributes, and (M2) WALS to measure spectral variance in the\nimages along a stereotypical attribute. OASIS also includes two methods to\nunderstand the origins of stereotypes in T2I models: (U1) StOP to discover\nattributes that the T2I model internally associates with a given concept, and\n(U2) SPI to quantify the emergence of stereotypical attributes in the latent\nspace of the T2I model during image generation. Despite the considerable\nprogress in image fidelity, using OASIS, we conclude that newer T2I models such\nas FLUX.1 and SDv3 contain strong stereotypical predispositions about concepts\nand still generate images with widespread stereotypical attributes.\nAdditionally, the quantity of stereotypes worsens for nationalities with lower\nInternet footprints.\n","authors":["Sepehr Dehdashtian","Gautam Sreekumar","Vishnu Naresh Boddeti"],"pdf_url":"https://arxiv.org/pdf/2501.00962v3.pdf","comment":"Accepted as a Spotlight paper at ICLR 2025"},{"id":"http://arxiv.org/abs/2501.13354v3","updated":"2025-03-07T14:28:51Z","published":"2025-01-23T03:42:22Z","title":"ATRNet-STAR: A Large Dataset and Benchmark Towards Remote Sensing Object\n  Recognition in the Wild","summary":"  The absence of publicly available, large-scale, high-quality datasets for\nSynthetic Aperture Radar Automatic Target Recognition (SAR ATR) has\nsignificantly hindered the application of rapidly advancing deep learning\ntechniques, which hold huge potential to unlock new capabilities in this field.\nThis is primarily because collecting large volumes of diverse target samples\nfrom SAR images is prohibitively expensive, largely due to privacy concerns,\nthe characteristics of microwave radar imagery perception, and the need for\nspecialized expertise in data annotation. Throughout the history of SAR ATR\nresearch, there have been only a number of small datasets, mainly including\ntargets like ships, airplanes, buildings, etc. There is only one vehicle\ndataset MSTAR collected in the 1990s, which has been a valuable source for SAR\nATR. To fill this gap, this paper introduces a large-scale, new dataset named\nATRNet-STAR with 40 different vehicle categories collected under various\nrealistic imaging conditions and scenes. It marks a substantial advancement in\ndataset scale and diversity, comprising over 190,000 well-annotated samples, 10\ntimes larger than its predecessor, the famous MSTAR. Building such a large\ndataset is a challenging task, and the data collection scheme will be detailed.\nSecondly, we illustrate the value of ATRNet-STAR via extensively evaluating the\nperformance of 15 representative methods with 7 different experimental settings\non challenging classification and detection benchmarks derived from the\ndataset. Finally, based on our extensive experiments, we identify valuable\ninsights for SAR ATR and discuss potential future research directions in this\nfield. We hope that the scale, diversity, and benchmark of ATRNet-STAR can\nsignificantly facilitate the advancement of SAR ATR.\n","authors":["Yongxiang Liu","Weijie Li","Li Liu","Jie Zhou","Bowen Peng","Yafei Song","Xuying Xiong","Wei Yang","Tianpeng Liu","Zhen Liu","Xiang Li"],"pdf_url":"https://arxiv.org/pdf/2501.13354v3.pdf","comment":"17 pages, 14 figures; ATRNet-STAR:\n  https://github.com/waterdisappear/ATRNet-STAR"},{"id":"http://arxiv.org/abs/2407.20836v2","updated":"2025-03-07T14:28:34Z","published":"2024-07-30T14:07:17Z","title":"Vulnerabilities in AI-generated Image Detection: The Challenge of\n  Adversarial Attacks","summary":"  Recent advancements in image synthesis, particularly with the advent of GAN\nand Diffusion models, have amplified public concerns regarding the\ndissemination of disinformation. To address such concerns, numerous\nAI-generated Image (AIGI) Detectors have been proposed and achieved promising\nperformance in identifying fake images. However, there still lacks a systematic\nunderstanding of the adversarial robustness of AIGI detectors. In this paper,\nwe examine the vulnerability of state-of-the-art AIGI detectors against\nadversarial attack under white-box and black-box settings, which has been\nrarely investigated so far. To this end, we propose a new method to attack AIGI\ndetectors. First, inspired by the obvious difference between real images and\nfake images in the frequency domain, we add perturbations under the frequency\ndomain to push the image away from its original frequency distribution. Second,\nwe explore the full posterior distribution of the surrogate model to further\nnarrow this gap between heterogeneous AIGI detectors, e.g. transferring\nadversarial examples across CNNs and ViTs. This is achieved by introducing a\nnovel post-train Bayesian strategy that turns a single surrogate into a\nBayesian one, capable of simulating diverse victim models using one pre-trained\nsurrogate, without the need for re-training. We name our method as\nFrequency-based Post-train Bayesian Attack, or FPBA. Through FPBA, we show that\nadversarial attack is truly a real threat to AIGI detectors, because FPBA can\ndeliver successful black-box attacks across models, generators, defense\nmethods, and even evade cross-generator detection, which is a crucial\nreal-world detection scenario. The code will be shared upon acceptance.\n","authors":["Yunfeng Diao","Naixin Zhai","Changtao Miao","Zitong Yu","Xingxing Wei","Xun Yang","Meng Wang"],"pdf_url":"https://arxiv.org/pdf/2407.20836v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2412.02734v3","updated":"2025-03-07T14:21:17Z","published":"2024-12-03T18:18:33Z","title":"MVCTrack: Boosting 3D Point Cloud Tracking via Multimodal-Guided Virtual\n  Cues","summary":"  3D single object tracking is essential in autonomous driving and robotics.\nExisting methods often struggle with sparse and incomplete point cloud\nscenarios. To address these limitations, we propose a Multimodal-guided Virtual\nCues Projection (MVCP) scheme that generates virtual cues to enrich sparse\npoint clouds. Additionally, we introduce an enhanced tracker MVCTrack based on\nthe generated virtual cues. Specifically, the MVCP scheme seamlessly integrates\nRGB sensors into LiDAR-based systems, leveraging a set of 2D detections to\ncreate dense 3D virtual cues that significantly improve the sparsity of point\nclouds. These virtual cues can naturally integrate with existing LiDAR-based 3D\ntrackers, yielding substantial performance gains. Extensive experiments\ndemonstrate that our method achieves competitive performance on the NuScenes\ndataset.\n","authors":["Zhaofeng Hu","Sifan Zhou","Shibo Zhao","Zhihang Yuan"],"pdf_url":"https://arxiv.org/pdf/2412.02734v3.pdf","comment":"Accepted by ICRA 2025"},{"id":"http://arxiv.org/abs/2503.05424v1","updated":"2025-03-07T13:50:37Z","published":"2025-03-07T13:50:37Z","title":"Towards Locally Explaining Prediction Behavior via Gradual Interventions\n  and Measuring Property Gradients","summary":"  Deep learning models achieve high predictive performance but lack intrinsic\ninterpretability, hindering our understanding of the learned prediction\nbehavior. Existing local explainability methods focus on associations,\nneglecting the causal drivers of model predictions. Other approaches adopt a\ncausal perspective but primarily provide more general global explanations.\nHowever, for specific inputs, it's unclear whether globally identified factors\napply locally. To address this limitation, we introduce a novel framework for\nlocal interventional explanations by leveraging recent advances in\nimage-to-image editing models. Our approach performs gradual interventions on\nsemantic properties to quantify the corresponding impact on a model's\npredictions using a novel score, the expected property gradient magnitude. We\ndemonstrate the effectiveness of our approach through an extensive empirical\nevaluation on a wide range of architectures and tasks. First, we validate it in\na synthetic scenario and demonstrate its ability to locally identify biases.\nAfterward, we apply our approach to analyze network training dynamics,\ninvestigate medical skin lesion classifiers, and study a pre-trained CLIP model\nwith real-life interventional data. Our results highlight the potential of\ninterventional explanations on the property level to reveal new insights into\nthe behavior of deep models.\n","authors":["Niklas Penzel","Joachim Denzler"],"pdf_url":"https://arxiv.org/pdf/2503.05424v1.pdf","comment":"44 pages, 39 figures, 14 tables"},{"id":"http://arxiv.org/abs/2503.05423v1","updated":"2025-03-07T13:50:29Z","published":"2025-03-07T13:50:29Z","title":"Semantic Shift Estimation via Dual-Projection and Classifier\n  Reconstruction for Exemplar-Free Class-Incremental Learning","summary":"  Exemplar-Free Class-Incremental Learning (EFCIL) aims to sequentially learn\nfrom distinct categories without retaining exemplars but easily suffers from\ncatastrophic forgetting of learned knowledge. While existing EFCIL methods\nleverage knowledge distillation to alleviate forgetting, they still face two\ncritical challenges: semantic shift and decision bias. Specifically, the\nembeddings of old tasks shift in the embedding space after learning new tasks,\nand the classifier becomes biased towards new tasks due to training solely with\nnew data, thereby hindering the balance between old and new knowledge. To\naddress these issues, we propose the Dual-Projection Shift Estimation and\nClassifier Reconstruction (DPCR) approach for EFCIL. DPCR effectively estimates\nsemantic shift through a dual-projection, which combines a learnable\ntransformation with a row-space projection to capture both task-wise and\ncategory-wise shifts. Furthermore, to mitigate decision bias, DPCR employs\nridge regression to reformulate classifier training as a reconstruction\nprocess. This reconstruction exploits previous information encoded in\ncovariance and prototype of each class after calibration with estimated shift,\nthereby reducing decision bias. Extensive experiments demonstrate that, across\nvarious datasets, DPCR effectively balances old and new tasks, outperforming\nstate-of-the-art EFCIL methods.\n","authors":["Run He","Di Fang","Yicheng Xu","Yawen Cui","Ming Li","Cen Chen","Ziqian Zeng","Huiping Zhuang"],"pdf_url":"https://arxiv.org/pdf/2503.05423v1.pdf","comment":"14 pages, 7 figures"},{"id":"http://arxiv.org/abs/2502.13593v2","updated":"2025-03-07T13:45:22Z","published":"2025-02-19T10:12:19Z","title":"Toward Robust Non-Transferable Learning: A Survey and Benchmark","summary":"  Over the past decades, researchers have primarily focused on improving the\ngeneralization abilities of models, with limited attention given to regulating\nsuch generalization. However, the ability of models to generalize to unintended\ndata (e.g., harmful or unauthorized data) can be exploited by malicious\nadversaries in unforeseen ways, potentially resulting in violations of model\nethics. Non-transferable learning (NTL), a task aimed at reshaping the\ngeneralization abilities of deep learning models, was proposed to address these\nchallenges. While numerous methods have been proposed in this field, a\ncomprehensive review of existing progress and a thorough analysis of current\nlimitations remain lacking. In this paper, we bridge this gap by presenting the\nfirst comprehensive survey on NTL and introducing NTLBench, the first benchmark\nto evaluate NTL performance and robustness within a unified framework.\nSpecifically, we first introduce the task settings, general framework, and\ncriteria of NTL, followed by a summary of NTL approaches. Furthermore, we\nemphasize the often-overlooked issue of robustness against various attacks that\ncan destroy the non-transferable mechanism established by NTL. Experiments\nconducted via NTLBench verify the limitations of existing NTL methods in\nrobustness. Finally, we discuss the practical applications of NTL, along with\nits future directions and associated challenges.\n","authors":["Ziming Hong","Yongli Xiang","Tongliang Liu"],"pdf_url":"https://arxiv.org/pdf/2502.13593v2.pdf","comment":"Code is available at https://github.com/tmllab/NTLBench"},{"id":"http://arxiv.org/abs/2502.12600v2","updated":"2025-03-07T13:26:55Z","published":"2025-02-18T07:23:22Z","title":"Revisiting the Generalization Problem of Low-level Vision Models Through\n  the Lens of Image Deraining","summary":"  Generalization remains a significant challenge for low-level vision models,\nwhich often struggle with unseen degradations in real-world scenarios despite\ntheir success in controlled benchmarks. In this paper, we revisit the\ngeneralization problem in low-level vision models. Image deraining is selected\nas a case study due to its well-defined and easily decoupled structure,\nallowing for more effective observation and analysis. Through comprehensive\nexperiments, we reveal that the generalization issue is not primarily due to\nlimited network capacity but rather the failure of existing training\nstrategies, which leads networks to overfit specific degradation patterns. Our\nfindings show that guiding networks to focus on learning the underlying image\ncontent, rather than the degradation patterns, is key to improving\ngeneralization. We demonstrate that balancing the complexity of background\nimages and degradations in the training data helps networks better fit the\nimage distribution. Furthermore, incorporating content priors from pre-trained\ngenerative models significantly enhances generalization. Experiments on both\nimage deraining and image denoising validate the proposed strategies. We\nbelieve the insights and solutions will inspire further research and improve\nthe generalization of low-level vision models.\n","authors":["Jinfan Hu","Zhiyuan You","Jinjin Gu","Kaiwen Zhu","Tianfan Xue","Chao Dong"],"pdf_url":"https://arxiv.org/pdf/2502.12600v2.pdf","comment":"arXiv admin note: substantial text overlap with arXiv:2305.15134"},{"id":"http://arxiv.org/abs/2408.16504v2","updated":"2025-03-07T13:26:50Z","published":"2024-08-29T13:02:12Z","title":"A Simple and Generalist Approach for Panoptic Segmentation","summary":"  Panoptic segmentation is an important computer vision task, where the current\nstate-of-the-art solutions require specialized components to perform well. We\npropose a simple generalist framework based on a deep encoder - shallow decoder\narchitecture with per-pixel prediction. Essentially fine-tuning a massively\npretrained image model with minimal additional components. Naively this method\ndoes not yield good results. We show that this is due to imbalance during\ntraining and propose a novel method for reducing it - centroid regression in\nthe space of spectral positional embeddings. Our method achieves panoptic\nquality (PQ) of 55.1 on the challenging MS-COCO dataset, state-of-the-art\nperformance among generalist methods.\n","authors":["Nedyalko Prisadnikov","Wouter Van Gansbeke","Danda Pani Paudel","Luc Van Gool"],"pdf_url":"https://arxiv.org/pdf/2408.16504v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2405.09787v2","updated":"2025-03-07T13:25:18Z","published":"2024-05-16T03:23:57Z","title":"Analysis of the BraTS 2023 Intracranial Meningioma Segmentation\n  Challenge","summary":"  We describe the design and results from the BraTS 2023 Intracranial\nMeningioma Segmentation Challenge. The BraTS Meningioma Challenge differed from\nprior BraTS Glioma challenges in that it focused on meningiomas, which are\ntypically benign extra-axial tumors with diverse radiologic and anatomical\npresentation and a propensity for multiplicity. Nine participating teams each\ndeveloped deep-learning automated segmentation models using image data from the\nlargest multi-institutional systematically expert annotated multilabel\nmulti-sequence meningioma MRI dataset to date, which included 1000 training set\ncases, 141 validation set cases, and 283 hidden test set cases. Each case\nincluded T2, FLAIR, T1, and T1Gd brain MRI sequences with associated tumor\ncompartment labels delineating enhancing tumor, non-enhancing tumor, and\nsurrounding non-enhancing FLAIR hyperintensity. Participant automated\nsegmentation models were evaluated and ranked based on a scoring system\nevaluating lesion-wise metrics including dice similarity coefficient (DSC) and\n95% Hausdorff Distance. The top ranked team had a lesion-wise median dice\nsimilarity coefficient (DSC) of 0.976, 0.976, and 0.964 for enhancing tumor,\ntumor core, and whole tumor, respectively and a corresponding average DSC of\n0.899, 0.904, and 0.871, respectively. These results serve as state-of-the-art\nbenchmarks for future pre-operative meningioma automated segmentation\nalgorithms. Additionally, we found that 1286 of 1424 cases (90.3%) had at least\n1 compartment voxel abutting the edge of the skull-stripped image edge, which\nrequires further investigation into optimal pre-processing face anonymization\nsteps.\n","authors":["Dominic LaBella","Ujjwal Baid","Omaditya Khanna","Shan McBurney-Lin","Ryan McLean","Pierre Nedelec","Arif Rashid","Nourel Hoda Tahon","Talissa Altes","Radhika Bhalerao","Yaseen Dhemesh","Devon Godfrey","Fathi Hilal","Scott Floyd","Anastasia Janas","Anahita Fathi Kazerooni","John Kirkpatrick","Collin Kent","Florian Kofler","Kevin Leu","Nazanin Maleki","Bjoern Menze","Maxence Pajot","Zachary J. Reitman","Jeffrey D. Rudie","Rachit Saluja","Yury Velichko","Chunhao Wang","Pranav Warman","Maruf Adewole","Jake Albrecht","Udunna Anazodo","Syed Muhammad Anwar","Timothy Bergquist","Sully Francis Chen","Verena Chung","Rong Chai","Gian-Marco Conte","Farouk Dako","James Eddy","Ivan Ezhov","Nastaran Khalili","Juan Eugenio Iglesias","Zhifan Jiang","Elaine Johanson","Koen Van Leemput","Hongwei Bran Li","Marius George Linguraru","Xinyang Liu","Aria Mahtabfar","Zeke Meier","Ahmed W. Moawad","John Mongan","Marie Piraud","Russell Takeshi Shinohara","Walter F. Wiggins","Aly H. Abayazeed","Rachel Akinola","Andrs Jakab","Michel Bilello","Maria Correia de Verdier","Priscila Crivellaro","Christos Davatzikos","Keyvan Farahani","John Freymann","Christopher Hess","Raymond Huang","Philipp Lohmann","Mana Moassefi","Matthew W. Pease","Phillipp Vollmuth","Nico Sollmann","David Diffley","Khanak K. Nandolia","Daniel I. Warren","Ali Hussain","Pascal Fehringer","Yulia Bronstein","Lisa Deptula","Evan G. Stein","Mahsa Taherzadeh","Eduardo Portela de Oliveira","Aoife Haughey","Marinos Kontzialis","Luca Saba","Benjamin Turner","Melanie M. T. Breler","Shehbaz Ansari","Athanasios Gkampenis","David Maximilian Weiss","Aya Mansour","Islam H. Shawali","Nikolay Yordanov","Joel M. Stein","Roula Hourani","Mohammed Yahya Moshebah","Ahmed Magdy Abouelatta","Tanvir Rizvi","Klara Willms","Dann C. Martin","Abdullah Okar","Gennaro D'Anna","Ahmed Taha","Yasaman Sharifi","Shahriar Faghani","Dominic Kite","Marco Pinho","Muhammad Ammar Haider","Alejandro Aristizabal","Alexandros Karargyris","Hasan Kassem","Sarthak Pati","Micah Sheller","Michelle Alonso-Basanta","Javier Villanueva-Meyer","Andreas M. Rauschecker","Ayman Nada","Mariam Aboian","Adam E. Flanders","Benedikt Wiestler","Spyridon Bakas","Evan Calabrese"],"pdf_url":"https://arxiv.org/pdf/2405.09787v2.pdf","comment":"Accepted for publication at the Journal of Machine Learning for\n  Biomedical Imaging (MELBA) https://melba-journal.org/2025:003 22 pages, 6\n  tables, 12 figures, MICCAI, MELBA"},{"id":"http://arxiv.org/abs/2411.17984v2","updated":"2025-03-07T13:24:25Z","published":"2024-11-27T01:43:38Z","title":"RS-vHeat: Heat Conduction Guided Efficient Remote Sensing Foundation\n  Model","summary":"  Remote sensing foundation models largely break away from the traditional\nparadigm of designing task-specific models, offering greater scalability across\nmultiple tasks. However, they face challenges such as low computational\nefficiency and limited interpretability, especially when dealing with\nlarge-scale remote sensing images. To overcome these, we draw inspiration from\nheat conduction, a physical process modeling local heat diffusion. Building on\nthis idea, we are the first to explore the potential of using the parallel\ncomputing model of heat conduction to simulate the local region correlations in\nhigh-resolution remote sensing images, and introduce RS-vHeat, an efficient\nmulti-modal remote sensing foundation model. Specifically, RS-vHeat 1) applies\nthe Heat Conduction Operator (HCO) with a complexity of $O(N^{1.5})$ and a\nglobal receptive field, reducing computational overhead while capturing remote\nsensing object structure information to guide heat diffusion; 2) learns the\nfrequency distribution representations of various scenes through a\nself-supervised strategy based on frequency domain hierarchical masking and\nmulti-domain reconstruction; 3) significantly improves efficiency and\nperformance over state-of-the-art techniques across 4 tasks and 10 datasets.\nCompared to attention-based remote sensing foundation models, we reduce memory\nusage by 84\\%, FLOPs by 24\\% and improves throughput by 2.7 times. The code\nwill be made publicly available.\n","authors":["Huiyang Hu","Peijin Wang","Hanbo Bi","Boyuan Tong","Zhaozhi Wang","Wenhui Diao","Hao Chang","Yingchao Feng","Ziqi Zhang","Yaowei Wang","Qixiang Ye","Kun Fu","Xian Sun"],"pdf_url":"https://arxiv.org/pdf/2411.17984v2.pdf","comment":"19 pages, 8 figures and 10 tables"},{"id":"http://arxiv.org/abs/2503.05398v1","updated":"2025-03-07T13:21:18Z","published":"2025-03-07T13:21:18Z","title":"Self-Modeling Robots by Photographing","summary":"  Self-modeling enables robots to build task-agnostic models of their\nmorphology and kinematics based on data that can be automatically collected,\nwith minimal human intervention and prior information, thereby enhancing\nmachine intelligence. Recent research has highlighted the potential of\ndata-driven technology in modeling the morphology and kinematics of robots.\nHowever, existing self-modeling methods suffer from either low modeling quality\nor excessive data acquisition costs. Beyond morphology and kinematics, texture\nis also a crucial component of robots, which is challenging to model and\nremains unexplored. In this work, a high-quality, texture-aware, and link-level\nmethod is proposed for robot self-modeling. We utilize three-dimensional (3D)\nGaussians to represent the static morphology and texture of robots, and cluster\nthe 3D Gaussians to construct neural ellipsoid bones, whose deformations are\ncontrolled by the transformation matrices generated by a kinematic neural\nnetwork. The 3D Gaussians and kinematic neural network are trained using data\npairs composed of joint angles, camera parameters and multi-view images without\ndepth information. By feeding the kinematic neural network with joint angles,\nwe can utilize the well-trained model to describe the corresponding morphology,\nkinematics and texture of robots at the link level, and render robot images\nfrom different perspectives with the aid of 3D Gaussian splatting. Furthermore,\nwe demonstrate that the established model can be exploited to perform\ndownstream tasks such as motion planning and inverse kinematics.\n","authors":["Kejun Hu","Peng Yu","Ning Tan"],"pdf_url":"https://arxiv.org/pdf/2503.05398v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2412.13533v2","updated":"2025-03-07T13:13:02Z","published":"2024-12-18T06:19:03Z","title":"Language-guided Medical Image Segmentation with Target-informed\n  Multi-level Contrastive Alignments","summary":"  Medical image segmentation is crucial in modern medical image analysis, which\ncan aid into diagnosis of various disease conditions. Recently, language-guided\nsegmentation methods have shown promising results in automating image\nsegmentation where text reports are incorporated as guidance. These text\nreports, containing image impressions and insights given by clinicians,\nprovides auxiliary guidance. However, these methods neglect the inherent\npattern gaps between the two distinct modalities, which leads to sub-optimal\nimage-text feature fusion without proper cross-modality feature alignments.\nContrastive alignments are widely used to associate image-text semantics in\nrepresentation learning; however, it has not been exploited to bridge the\npattern gaps in language-guided segmentation that relies on subtle low level\nimage details to represent diseases. Existing contrastive alignment methods\ntypically algin high-level global image semantics without involving low-level,\nlocalized target information, and therefore fails to explore fine-grained text\nguidance for language-guided segmentation. In this study, we propose a\nlanguage-guided segmentation network with Target-informed Multi-level\nContrastive Alignments (TMCA). TMCA enables target-informed cross-modality\nalignments and fine-grained text guidance to bridge the pattern gaps in\nlanguage-guided segmentation. Specifically, we introduce: 1) a target-sensitive\nsemantic distance module that enables granular image-text alignment modelling,\nand 2) a multi-level alignment strategy that directs text guidance on low-level\nimage features. In addition, a language-guided target enhancement module is\nproposed to leverage the aligned text to redirect attention to focus on\ncritical localized image features. Extensive experiments on 4 image-text\ndatasets, involving 3 medical imaging modalities, demonstrated that our TMCA\nachieved superior performances.\n","authors":["Mingjian Li","Mingyuan Meng","Shuchang Ye","Michael Fulham","Lei Bi","Jinman Kim"],"pdf_url":"https://arxiv.org/pdf/2412.13533v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2401.03890v6","updated":"2025-03-07T13:06:56Z","published":"2024-01-08T13:42:59Z","title":"A Survey on 3D Gaussian Splatting","summary":"  3D Gaussian splatting (GS) has emerged as a transformative technique in\nexplicit radiance field and computer graphics. This innovative approach,\ncharacterized by the use of millions of learnable 3D Gaussians, represents a\nsignificant departure from mainstream neural radiance field approaches, which\npredominantly use implicit, coordinate-based models to map spatial coordinates\nto pixel values. 3D GS, with its explicit scene representation and\ndifferentiable rendering algorithm, not only promises real-time rendering\ncapability but also introduces unprecedented levels of editability. This\npositions 3D GS as a potential game-changer for the next generation of 3D\nreconstruction and representation. In the present paper, we provide the first\nsystematic overview of the recent developments and critical contributions in\nthe domain of 3D GS. We begin with a detailed exploration of the underlying\nprinciples and the driving forces behind the emergence of 3D GS, laying the\ngroundwork for understanding its significance. A focal point of our discussion\nis the practical applicability of 3D GS. By enabling unprecedented rendering\nspeed, 3D GS opens up a plethora of applications, ranging from virtual reality\nto interactive media and beyond. This is complemented by a comparative analysis\nof leading 3D GS models, evaluated across various benchmark tasks to highlight\ntheir performance and practical utility. The survey concludes by identifying\ncurrent challenges and suggesting potential avenues for future research.\nThrough this survey, we aim to provide a valuable resource for both newcomers\nand seasoned researchers, fostering further exploration and advancement in\nexplicit radiance field.\n","authors":["Guikun Chen","Wenguan Wang"],"pdf_url":"https://arxiv.org/pdf/2401.03890v6.pdf","comment":"Ongoing project. Paper list:\n  https://github.com/guikunchen/Awesome3DGS ; Benchmark:\n  https://github.com/guikunchen/3DGS-Benchmarks"},{"id":"http://arxiv.org/abs/2503.05379v1","updated":"2025-03-07T12:46:42Z","published":"2025-03-07T12:46:42Z","title":"R1-Omni: Explainable Omni-Multimodal Emotion Recognition with\n  Reinforcing Learning","summary":"  In this work, we present the first application of Reinforcement Learning with\nVerifiable Reward (RLVR) to an Omni-multimodal large language model in the\ncontext of emotion recognition, a task where both visual and audio modalities\nplay crucial roles. We leverage RLVR to optimize the Omni model, significantly\nenhancing its performance in three key aspects: reasoning capability, emotion\nrecognition accuracy, and generalization ability. The introduction of RLVR not\nonly improves the model's overall performance on in-distribution data but also\ndemonstrates superior robustness when evaluated on out-of-distribution\ndatasets. More importantly, the improved reasoning capability enables clear\nanalysis of the contributions of different modalities, particularly visual and\naudio information, in the emotion recognition process. This provides valuable\ninsights into the optimization of multimodal large language models.\n","authors":["Jiaxing Zhao","Xihan Wei","Liefeng Bo"],"pdf_url":"https://arxiv.org/pdf/2503.05379v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.19233v2","updated":"2025-03-07T12:37:47Z","published":"2024-11-28T16:01:58Z","title":"Gaussians-to-Life: Text-Driven Animation of 3D Gaussian Splatting Scenes","summary":"  State-of-the-art novel view synthesis methods achieve impressive results for\nmulti-view captures of static 3D scenes. However, the reconstructed scenes\nstill lack \"liveliness,\" a key component for creating engaging 3D experiences.\nRecently, novel video diffusion models generate realistic videos with complex\nmotion and enable animations of 2D images, however they cannot naively be used\nto animate 3D scenes as they lack multi-view consistency. To breathe life into\nthe static world, we propose Gaussians2Life, a method for animating parts of\nhigh-quality 3D scenes in a Gaussian Splatting representation. Our key idea is\nto leverage powerful video diffusion models as the generative component of our\nmodel and to combine these with a robust technique to lift 2D videos into\nmeaningful 3D motion. We find that, in contrast to prior work, this enables\nrealistic animations of complex, pre-existing 3D scenes and further enables the\nanimation of a large variety of object classes, while related work is mostly\nfocused on prior-based character animation, or single 3D objects. Our model\nenables the creation of consistent, immersive 3D experiences for arbitrary\nscenes.\n","authors":["Thomas Wimmer","Michael Oechsle","Michael Niemeyer","Federico Tombari"],"pdf_url":"https://arxiv.org/pdf/2411.19233v2.pdf","comment":"Project website at https://wimmerth.github.io/gaussians2life.html.\n  Accepted to 3DV 2025"},{"id":"http://arxiv.org/abs/2308.01196v3","updated":"2025-03-07T12:31:27Z","published":"2023-07-27T22:57:55Z","title":"Sustainable transparency in Recommender Systems: Bayesian Ranking of\n  Images for Explainability","summary":"  Recommender Systems have become crucial in the modern world, commonly guiding\nusers towards relevant content or products, and having a large influence over\nthe decisions of users and citizens. However, ensuring transparency and user\ntrust in these systems remains a challenge; personalized explanations have\nemerged as a solution, offering justifications for recommendations. Among the\nexisting approaches for generating personalized explanations, using existing\nvisual content created by users is a promising option to maximize transparency\nand user trust. State-of-the-art models that follow this approach, despite\nleveraging highly optimized architectures, employ surrogate learning tasks that\ndo not efficiently model the objective of ranking images as explanations for a\ngiven recommendation; this leads to a suboptimal training process with high\ncomputational costs that may not be reduced without affecting model\nperformance. This work presents BRIE, a novel model where we leverage Bayesian\nPairwise Ranking to enhance the training process, allowing us to consistently\noutperform state-of-the-art models in six real-world datasets while reducing\nits model size by up to 64 times and its CO2 emissions by up to 75% in training\nand inference.\n","authors":["Jorge Paz-Ruza","Amparo Alonso-Betanzos","Berta Guijarro-Berdias","Brais Cancela","Carlos Eiras-Franco"],"pdf_url":"https://arxiv.org/pdf/2308.01196v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2502.14195v2","updated":"2025-03-07T12:30:18Z","published":"2025-02-20T02:00:02Z","title":"Bridging Text and Vision: A Multi-View Text-Vision Registration Approach\n  for Cross-Modal Place Recognition","summary":"  Mobile robots necessitate advanced natural language understanding\ncapabilities to accurately identify locations and perform tasks such as package\ndelivery. However, traditional visual place recognition (VPR) methods rely\nsolely on single-view visual information and cannot interpret human language\ndescriptions. To overcome this challenge, we bridge text and vision by\nproposing a multiview (360{\\deg} views of the surroundings) text-vision\nregistration approach called Text4VPR for place recognition task, which is the\nfirst method that exclusively utilizes textual descriptions to match a database\nof images. Text4VPR employs the frozen T5 language model to extract global\ntextual embeddings. Additionally, it utilizes the Sinkhorn algorithm with\ntemperature coefficient to assign local tokens to their respective clusters,\nthereby aggregating visual descriptors from images. During the training stage,\nText4VPR emphasizes the alignment between individual text-image pairs for\nprecise textual description. In the inference stage, Text4VPR uses the Cascaded\nCross-Attention Cosine Alignment (CCCA) to address the internal mismatch\nbetween text and image groups. Subsequently, Text4VPR performs precisely place\nmatch based on the descriptions of text-image groups. On Street360Loc, the\nfirst text to image VPR dataset we created, Text4VPR builds a robust baseline,\nachieving a leading top-1 accuracy of 57% and a leading top-10 accuracy of 92%\nwithin a 5-meter radius on the test set, which indicates that localization from\ntextual descriptions to images is not only feasible but also holds significant\npotential for further advancement, as shown in Figure 1.\n","authors":["Tianyi Shang","Zhenyu Li","Pengjie Xu","Jinwei Qiao","Gang Chen","Zihan Ruan","Weijun Hu"],"pdf_url":"https://arxiv.org/pdf/2502.14195v2.pdf","comment":"8 pages, 4 figures, conference"},{"id":"http://arxiv.org/abs/2503.05365v1","updated":"2025-03-07T12:14:51Z","published":"2025-03-07T12:14:51Z","title":"Multi-Grained Feature Pruning for Video-Based Human Pose Estimation","summary":"  Human pose estimation, with its broad applications in action recognition and\nmotion capture, has experienced significant advancements. However, current\nTransformer-based methods for video pose estimation often face challenges in\nmanaging redundant temporal information and achieving fine-grained perception\nbecause they only focus on processing low-resolution features. To address these\nchallenges, we propose a novel multi-scale resolution framework that encodes\nspatio-temporal representations at varying granularities and executes\nfine-grained perception compensation. Furthermore, we employ a density peaks\nclustering method to dynamically identify and prioritize tokens that offer\nimportant semantic information. This strategy effectively prunes redundant\nfeature tokens, especially those arising from multi-frame features, thereby\noptimizing computational efficiency without sacrificing semantic richness.\nEmpirically, it sets new benchmarks for both performance and efficiency on\nthree large-scale datasets. Our method achieves a 93.8% improvement in\ninference speed compared to the baseline, while also enhancing pose estimation\naccuracy, reaching 87.4 mAP on the PoseTrack2017 dataset.\n","authors":["Zhigang Wang","Shaojing Fan","Zhenguang Liu","Zheqi Wu","Sifan Wu","Yingying Jiao"],"pdf_url":"https://arxiv.org/pdf/2503.05365v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.10173v2","updated":"2025-03-07T12:03:09Z","published":"2024-03-15T10:28:31Z","title":"A Hybrid SNN-ANN Network for Event-based Object Detection with Spatial\n  and Temporal AttentionEfficient Event-Based Object Detection: A Hybrid Neural\n  Network with Spatial and Temporal Attention","summary":"  Event cameras offer high temporal resolution and dynamic range with minimal\nmotion blur, making them promising for robust object detection. While Spiking\nNeural Networks (SNNs) on neuromorphic hardware are often considered for energy\nefficient and low latency event-based data processing, they often fall short of\nArtificial Neural Networks (ANNs) in accuracy and flexibility. Here, we\nintroduce Attention-based Hybrid SNN-ANN backbones for event-based object\ndetection to leverage the strengths of both SNN and ANN architectures. A novel\nAttention-based SNN-ANN bridge module captures sparse spatial and temporal\nrelations from the SNN layer and converts them into dense feature maps for the\nANN part of the backbone. Additionally, we present a variant that integrates\nDWConvLSTMs to the ANN blocks to capture slower dynamics. This multi-timescale\nnetwork combines fast SNN processing for short timesteps with long-term dense\nRNN processing, effectively capturing both fast and slow dynamics. Experimental\nresults demonstrate that our proposed method surpasses SNN-based approaches by\nsignificant margins, with results comparable to existing ANN and RNN-based\nmethods. Unlike ANN-only networks, the hybrid setup allows us to implement the\nSNN blocks on digital neuromorphic hardware to investigate the feasibility of\nour approach. Extensive ablation studies and implementation on neuromorphic\nhardware confirm the effectiveness of our proposed modules and architectural\nchoices. Our hybrid SNN-ANN architectures pave the way for ANN-like performance\nat a drastically reduced parameter, latency, and power budget.\n","authors":["Soikat Hasan Ahmed","Jan Finkbeiner","Emre Neftci"],"pdf_url":"https://arxiv.org/pdf/2403.10173v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2409.17095v2","updated":"2025-03-07T11:47:28Z","published":"2024-09-25T17:05:55Z","title":"General Detection-based Text Line Recognition","summary":"  We introduce a general detection-based approach to text line recognition, be\nit printed (OCR) or handwritten (HTR), with Latin, Chinese, or ciphered\ncharacters. Detection-based approaches have until now been largely discarded\nfor HTR because reading characters separately is often challenging, and\ncharacter-level annotation is difficult and expensive. We overcome these\nchallenges thanks to three main insights: (i) synthetic pre-training with\nsufficiently diverse data enables learning reasonable character localization\nfor any script; (ii) modern transformer-based detectors can jointly detect a\nlarge number of instances, and, if trained with an adequate masking strategy,\nleverage consistency between the different detections; (iii) once a pre-trained\ndetection model with approximate character localization is available, it is\npossible to fine-tune it with line-level annotation on real data, even with a\ndifferent alphabet. Our approach, dubbed DTLR, builds on a completely different\nparadigm than state-of-the-art HTR methods, which rely on autoregressive\ndecoding, predicting character values one by one, while we treat a complete\nline in parallel. Remarkably, we demonstrate good performance on a large range\nof scripts, usually tackled with specialized approaches. In particular, we\nimprove state-of-the-art performances for Chinese script recognition on the\nCASIA v2 dataset, and for cipher recognition on the Borg and Copiale datasets.\nOur code and models are available at https://github.com/raphael-baena/DTLR.\n","authors":["Raphael Baena","Syrine Kalleli","Mathieu Aubry"],"pdf_url":"https://arxiv.org/pdf/2409.17095v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2409.12667v2","updated":"2025-03-07T11:31:10Z","published":"2024-09-19T11:27:40Z","title":"METDrive: Multi-modal End-to-end Autonomous Driving with Temporal\n  Guidance","summary":"  Multi-modal end-to-end autonomous driving has shown promising advancements in\nrecent work. By embedding more modalities into end-to-end networks, the\nsystem's understanding of both static and dynamic aspects of the driving\nenvironment is enhanced, thereby improving the safety of autonomous driving. In\nthis paper, we introduce METDrive, an end-to-end system that leverages temporal\nguidance from the embedded time series features of ego states, including\nrotation angles, steering, throttle signals, and waypoint vectors. The\ngeometric features derived from perception sensor data and the time series\nfeatures of ego state data jointly guide the waypoint prediction with the\nproposed temporal guidance loss function. We evaluated METDrive on the CARLA\nleaderboard benchmarks, achieving a driving score of 70%, a route completion\nscore of 94%, and an infraction score of 0.78.\n","authors":["Ziang Guo","Xinhao Lin","Zakhar Yagudin","Artem Lykov","Yong Wang","Yanqiang Li","Dzmitry Tsetserukou"],"pdf_url":"https://arxiv.org/pdf/2409.12667v2.pdf","comment":"Accepted by ICRA"},{"id":"http://arxiv.org/abs/2503.05339v1","updated":"2025-03-07T11:28:55Z","published":"2025-03-07T11:28:55Z","title":"Pretext Task Adversarial Learning for Unpaired Low-field to Ultra\n  High-field MRI Synthesis","summary":"  Given the scarcity and cost of high-field MRI, the synthesis of high-field\nMRI from low-field MRI holds significant potential when there is limited data\nfor training downstream tasks (e.g. segmentation). Low-field MRI often suffers\nfrom a reduced signal-to-noise ratio (SNR) and spatial resolution compared to\nhigh-field MRI. However, synthesizing high-field MRI data presents challenges.\nThese involve aligning image features across domains while preserving\nanatomical accuracy and enhancing fine details. To address these challenges, we\npropose a Pretext Task Adversarial (PTA) learning framework for high-field MRI\nsynthesis from low-field MRI data. The framework comprises three processes: (1)\nThe slice-wise gap perception (SGP) network aligns the slice inconsistencies of\nlow-field and high-field datasets based on contrastive learning. (2) The local\nstructure correction (LSC) network extracts local structures by restoring the\nlocally rotated and masked images. (3) The pretext task-guided adversarial\ntraining process introduces additional supervision and incorporates a\ndiscriminator to improve image realism. Extensive experiments on low-field to\nultra high-field task demonstrate the effectiveness of our method, achieving\nstate-of-the-art performance (16.892 in FID, 1.933 in IS, and 0.324 in\nMS-SSIM). This enables the generation of high-quality high-field-like MRI data\nfrom low-field MRI data to augment training datasets for downstream tasks. The\ncode is available at:\nhttps://github.com/Zhenxuan-Zhang/PTA4Unpaired_HF_MRI_SYN.\n","authors":["Zhenxuan Zhang","Peiyuan Jing","Coraline Beitone","Jiahao Huang","Zhifan Gao","Guang Yang","Pete Lally"],"pdf_url":"https://arxiv.org/pdf/2503.05339v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.05335v1","updated":"2025-03-07T11:22:33Z","published":"2025-03-07T11:22:33Z","title":"New multimodal similarity measure for image registration via modeling\n  local functional dependence with linear combination of learned basis\n  functions","summary":"  The deformable registration of images of different modalities, essential in\nmany medical imaging applications, remains challenging. The main challenge is\ndeveloping a robust measure for image overlap despite the compared images\ncapturing different aspects of the underlying tissue. Here, we explore\nsimilarity metrics based on functional dependence between intensity values of\nregistered images. Although functional dependence is too restrictive on the\nglobal scale, earlier work has shown competitive performance in deformable\nregistration when such measures are applied over small enough contexts. We\nconfirm this finding and further develop the idea by modeling local functional\ndependence via the linear basis function model with the basis functions learned\njointly with the deformation. The measure can be implemented via convolutions,\nmaking it efficient to compute on GPUs. We release the method as an easy-to-use\ntool and show good performance on three datasets compared to well-established\nbaseline and earlier functional dependence-based methods.\n","authors":["Joel Honkamaa","Pekka Marttinen"],"pdf_url":"https://arxiv.org/pdf/2503.05335v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.05333v1","updated":"2025-03-07T11:19:13Z","published":"2025-03-07T11:19:13Z","title":"PhysicsGen: Can Generative Models Learn from Images to Predict Complex\n  Physical Relations?","summary":"  The image-to-image translation abilities of generative learning models have\nrecently made significant progress in the estimation of complex (steered)\nmappings between image distributions. While appearance based tasks like image\nin-painting or style transfer have been studied at length, we propose to\ninvestigate the potential of generative models in the context of physical\nsimulations. Providing a dataset of 300k image-pairs and baseline evaluations\nfor three different physical simulation tasks, we propose a benchmark to\ninvestigate the following research questions: i) are generative models able to\nlearn complex physical relations from input-output image pairs? ii) what\nspeedups can be achieved by replacing differential equation based simulations?\nWhile baseline evaluations of different current models show the potential for\nhigh speedups (ii), these results also show strong limitations toward the\nphysical correctness (i). This underlines the need for new methods to enforce\nphysical correctness. Data, baseline models and evaluation code\nhttp://www.physics-gen.org.\n","authors":["Martin Spitznagel","Jan Vaillant","Janis Keuper"],"pdf_url":"https://arxiv.org/pdf/2503.05333v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.05332v1","updated":"2025-03-07T11:18:43Z","published":"2025-03-07T11:18:43Z","title":"CoMoGaussian: Continuous Motion-Aware Gaussian Splatting from\n  Motion-Blurred Images","summary":"  3D Gaussian Splatting (3DGS) has gained significant attention for their\nhigh-quality novel view rendering, motivating research to address real-world\nchallenges. A critical issue is the camera motion blur caused by movement\nduring exposure, which hinders accurate 3D scene reconstruction. In this study,\nwe propose CoMoGaussian, a Continuous Motion-Aware Gaussian Splatting that\nreconstructs precise 3D scenes from motion-blurred images while maintaining\nreal-time rendering speed. Considering the complex motion patterns inherent in\nreal-world camera movements, we predict continuous camera trajectories using\nneural ordinary differential equations (ODEs). To ensure accurate modeling, we\nemploy rigid body transformations, preserving the shape and size of the object\nbut rely on the discrete integration of sampled frames. To better approximate\nthe continuous nature of motion blur, we introduce a continuous motion\nrefinement (CMR) transformation that refines rigid transformations by\nincorporating additional learnable parameters. By revisiting fundamental camera\ntheory and leveraging advanced neural ODE techniques, we achieve precise\nmodeling of continuous camera trajectories, leading to improved reconstruction\naccuracy. Extensive experiments demonstrate state-of-the-art performance both\nquantitatively and qualitatively on benchmark datasets, which include a wide\nrange of motion blur scenarios, from moderate to extreme blur.\n","authors":["Jungho Lee","Donghyeong Kim","Dogyoon Lee","Suhwan Cho","Minhyeok Lee","Wonjoon Lee","Taeoh Kim","Dongyoon Wee","Sangyoun Lee"],"pdf_url":"https://arxiv.org/pdf/2503.05332v1.pdf","comment":"Revised Version of CRiM-GS, Github:\n  https://github.com/Jho-Yonsei/CoMoGaussian"},{"id":"http://arxiv.org/abs/2412.14103v2","updated":"2025-03-07T11:02:33Z","published":"2024-12-18T17:50:15Z","title":"A Simple yet Effective Test-Time Adaptation for Zero-Shot Monocular\n  Metric Depth Estimation","summary":"  The recent development of foundation models for monocular depth estimation\nsuch as Depth Anything paved the way to zero-shot monocular depth estimation.\nSince it returns an affine-invariant disparity map, the favored technique to\nrecover the metric depth consists in fine-tuning the model. However, this stage\nis not straightforward, it can be costly and time-consuming because of the\ntraining and the creation of the dataset. The latter must contain images\ncaptured by the camera that will be used at test time and the corresponding\nground truth. Moreover, the fine-tuning may also degrade the generalizing\ncapacity of the original model. Instead, we propose in this paper a new method\nto rescale Depth Anything predictions using 3D points provided by sensors or\ntechniques such as low-resolution LiDAR or structure-from-motion with poses\ngiven by an IMU. This approach avoids fine-tuning and preserves the\ngeneralizing power of the original depth estimation model while being robust to\nthe noise of the sparse depth or of the depth model. Our experiments highlight\nenhancements relative to zero-shot monocular metric depth estimation methods,\ncompetitive results compared to fine-tuned approaches and a better robustness\nthan depth completion approaches. Code available at\nhttps://gitlab.ensta.fr/ssh/monocular-depth-rescaling.\n","authors":["Rmi Marsal","Alexandre Chapoutot","Philippe Xu","David Filliat"],"pdf_url":"https://arxiv.org/pdf/2412.14103v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.05322v1","updated":"2025-03-07T11:01:00Z","published":"2025-03-07T11:01:00Z","title":"Attenuation artifact detection and severity classification in\n  intracoronary OCT using mixed image representations","summary":"  In intracoronary optical coherence tomography (OCT), blood residues and gas\nbubbles cause attenuation artifacts that can obscure critical vessel\nstructures. The presence and severity of these artifacts may warrant\nre-acquisition, prolonging procedure time and increasing use of contrast agent.\nAccurate detection of these artifacts can guide targeted re-acquisition,\nreducing the amount of repeated scans needed to achieve diagnostically viable\nimages. However, the highly heterogeneous appearance of these artifacts poses a\nchallenge for the automated detection of the affected image regions. To enable\nautomatic detection of the attenuation artifacts caused by blood residues and\ngas bubbles based on their severity, we propose a convolutional neural network\nthat performs classification of the attenuation lines (A-lines) into three\nclasses: no artifact, mild artifact and severe artifact. Our model extracts and\nmerges features from OCT images in both Cartesian and polar coordinates, where\neach column of the image represents an A-line. Our method detects the presence\nof attenuation artifacts in OCT frames reaching F-scores of 0.77 and 0.94 for\nmild and severe artifacts, respectively. The inference time over a full OCT\nscan is approximately 6 seconds. Our experiments show that analysis of images\nrepresented in both Cartesian and polar coordinate systems outperforms the\nanalysis in polar coordinates only, suggesting that these representations\ncontain complementary features. This work lays the foundation for automated\nartifact assessment and image acquisition guidance in intracoronary OCT\nimaging.\n","authors":["Pierandrea Cancian","Simone Saitta","Xiaojin Gu","Rudolf L. M. van Herten","Thijs J. Luttikholt","Jos Thannhauser","Rick H. J. A. Volleberg","Ruben G. A. van der Waerden","Joske L. van der Zande","Clarisa I. Snchez","Bram van Ginneken","Niels van Royen","Ivana Igum"],"pdf_url":"https://arxiv.org/pdf/2503.05322v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.05319v1","updated":"2025-03-07T10:58:38Z","published":"2025-03-07T10:58:38Z","title":"Robust Multimodal Learning for Ophthalmic Disease Grading via\n  Disentangled Representation","summary":"  This paper discusses how ophthalmologists often rely on multimodal data to\nimprove diagnostic accuracy. However, complete multimodal data is rare in\nreal-world applications due to a lack of medical equipment and concerns about\ndata privacy. Traditional deep learning methods typically address these issues\nby learning representations in latent space. However, the paper highlights two\nkey limitations of these approaches: (i) Task-irrelevant redundant information\n(e.g., numerous slices) in complex modalities leads to significant redundancy\nin latent space representations. (ii) Overlapping multimodal representations\nmake it difficult to extract unique features for each modality. To overcome\nthese challenges, the authors propose the Essence-Point and Disentangle\nRepresentation Learning (EDRL) strategy, which integrates a self-distillation\nmechanism into an end-to-end framework to enhance feature selection and\ndisentanglement for more robust multimodal learning. Specifically, the\nEssence-Point Representation Learning module selects discriminative features\nthat improve disease grading performance. The Disentangled Representation\nLearning module separates multimodal data into modality-common and\nmodality-unique representations, reducing feature entanglement and enhancing\nboth robustness and interpretability in ophthalmic disease diagnosis.\nExperiments on multimodal ophthalmology datasets show that the proposed EDRL\nstrategy significantly outperforms current state-of-the-art methods.\n","authors":["Xinkun Wang","Yifang Wang","Senwei Liang","Feilong Tang","Chengzhi Liu","Ming Hu","Chao Hu","Junjun He","Zongyuan Ge","Imran Razzak"],"pdf_url":"https://arxiv.org/pdf/2503.05319v1.pdf","comment":"10pages"},{"id":"http://arxiv.org/abs/2501.18478v2","updated":"2025-03-07T10:40:43Z","published":"2025-01-30T16:51:40Z","title":"SimpleDepthPose: Fast and Reliable Human Pose Estimation with\n  RGBD-Images","summary":"  In the rapidly advancing domain of computer vision, accurately estimating the\nposes of multiple individuals from various viewpoints remains a significant\nchallenge, especially when reliability is a key requirement. This paper\nintroduces a novel algorithm that excels in multi-view, multi-person pose\nestimation by incorporating depth information. An extensive evaluation\ndemonstrates that the proposed algorithm not only generalizes well to unseen\ndatasets, and shows a fast runtime performance, but also is adaptable to\ndifferent keypoints. To support further research, all of the work is publicly\naccessible.\n","authors":["Daniel Bermuth","Alexander Poeppel","Wolfgang Reif"],"pdf_url":"https://arxiv.org/pdf/2501.18478v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.05305v1","updated":"2025-03-07T10:34:04Z","published":"2025-03-07T10:34:04Z","title":"Frequency Autoregressive Image Generation with Continuous Tokens","summary":"  Autoregressive (AR) models for image generation typically adopt a two-stage\nparadigm of vector quantization and raster-scan ``next-token prediction\",\ninspired by its great success in language modeling. However, due to the huge\nmodality gap, image autoregressive models may require a systematic reevaluation\nfrom two perspectives: tokenizer format and regression direction. In this\npaper, we introduce the frequency progressive autoregressive (\\textbf{FAR})\nparadigm and instantiate FAR with the continuous tokenizer. Specifically, we\nidentify spectral dependency as the desirable regression direction for FAR,\nwherein higher-frequency components build upon the lower one to progressively\nconstruct a complete image. This design seamlessly fits the causality\nrequirement for autoregressive models and preserves the unique spatial locality\nof image data. Besides, we delve into the integration of FAR and the continuous\ntokenizer, introducing a series of techniques to address optimization\nchallenges and improve the efficiency of training and inference processes. We\ndemonstrate the efficacy of FAR through comprehensive experiments on the\nImageNet dataset and verify its potential on text-to-image generation.\n","authors":["Hu Yu","Hao Luo","Hangjie Yuan","Yu Rong","Feng Zhao"],"pdf_url":"https://arxiv.org/pdf/2503.05305v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.05283v1","updated":"2025-03-07T09:51:56Z","published":"2025-03-07T09:51:56Z","title":"Escaping Plato's Cave: Towards the Alignment of 3D and Text Latent\n  Spaces","summary":"  Recent works have shown that, when trained at scale, uni-modal 2D vision and\ntext encoders converge to learned features that share remarkable structural\nproperties, despite arising from different representations. However, the role\nof 3D encoders with respect to other modalities remains unexplored.\nFurthermore, existing 3D foundation models that leverage large datasets are\ntypically trained with explicit alignment objectives with respect to frozen\nencoders from other representations. In this work, we investigate the\npossibility of a posteriori alignment of representations obtained from\nuni-modal 3D encoders compared to text-based feature spaces. We show that naive\npost-training feature alignment of uni-modal text and 3D encoders results in\nlimited performance. We then focus on extracting subspaces of the corresponding\nfeature spaces and discover that by projecting learned representations onto\nwell-chosen lower-dimensional subspaces the quality of alignment becomes\nsignificantly higher, leading to improved accuracy on matching and retrieval\ntasks. Our analysis further sheds light on the nature of these shared\nsubspaces, which roughly separate between semantic and geometric data\nrepresentations. Overall, ours is the first work that helps to establish a\nbaseline for post-training alignment of 3D uni-modal and text feature spaces,\nand helps to highlight both the shared and unique properties of 3D data\ncompared to other representations.\n","authors":["Souhail Hadgi","Luca Moschella","Andrea Santilli","Diego Gomez","Qixing Huang","Emanuele Rodol","Simone Melzi","Maks Ovsjanikov"],"pdf_url":"https://arxiv.org/pdf/2503.05283v1.pdf","comment":"Accepted at CVPR 2025"},{"id":"http://arxiv.org/abs/2406.09367v3","updated":"2025-03-07T09:40:34Z","published":"2024-06-13T17:50:05Z","title":"Needle In A Video Haystack: A Scalable Synthetic Evaluator for Video\n  MLLMs","summary":"  Video understanding is a crucial next step for multimodal large language\nmodels (MLLMs). Various benchmarks are introduced for better evaluating the\nMLLMs. Nevertheless, current video benchmarks are still inefficient for\nevaluating video models during iterative development due to the high cost of\nconstructing datasets and the difficulty in isolating specific skills. In this\npaper, we propose VideoNIAH (Video Needle In A Haystack), a benchmark\nconstruction framework through synthetic video generation. VideoNIAH decouples\nvideo content from their query-responses by inserting unrelated visual\n'needles' into original videos. The framework automates the generation of\nquery-response pairs using predefined rules, minimizing manual labor. The\nqueries focus on specific aspects of video understanding, enabling more\nskill-specific evaluations. The separation between video content and the\nqueries also allow for increased video variety and evaluations across different\nlengths. Utilizing VideoNIAH, we compile a video benchmark VNBench, which\nincludes tasks such as retrieval, ordering, and counting to evaluate three key\naspects of video understanding: temporal perception, chronological ordering,\nand spatio-temporal coherence. We conduct a comprehensive evaluation of both\nproprietary and open-source models, uncovering significant differences in their\nvideo understanding capabilities across various tasks. Additionally, we perform\nan in-depth analysis of the test results and model configurations. Based on\nthese findings, we provide some advice for improving video MLLM training,\noffering valuable insights to guide future research and model development. The\ncode and data are available at https://github.com/joez17/VideoNIAH.\n","authors":["Zijia Zhao","Haoyu Lu","Yuqi Huo","Yifan Du","Tongtian Yue","Longteng Guo","Bingning Wang","Weipeng Chen","Jing Liu"],"pdf_url":"https://arxiv.org/pdf/2406.09367v3.pdf","comment":"ICLR 2025"},{"id":"http://arxiv.org/abs/2409.12319v2","updated":"2025-03-07T09:30:16Z","published":"2024-09-18T21:17:27Z","title":"Large Language Models are Strong Audio-Visual Speech Recognition\n  Learners","summary":"  Multimodal large language models (MLLMs) have recently become a focal point\nof research due to their formidable multimodal understanding capabilities. For\nexample, in the audio and speech domains, an LLM can be equipped with\n(automatic) speech recognition (ASR) abilities by just concatenating the audio\ntokens, computed with an audio encoder, and the text tokens to achieve\nstate-of-the-art results. On the contrary, tasks like visual and audio-visual\nspeech recognition (VSR/AVSR), which also exploit noise-invariant lip movement\ninformation, have received little or no attention. To bridge this gap, we\npropose Llama-AVSR, a new MLLM with strong audio-visual speech recognition\ncapabilities. It leverages pre-trained audio and video encoders to produce\nmodality-specific tokens which, together with the text tokens, are processed by\na pre-trained LLM (e.g., Llama3.1-8B) to yield the resulting response in an\nauto-regressive fashion. Llama-AVSR requires a small number of trainable\nparameters as only modality-specific projectors and LoRA modules are trained\nwhereas the multi-modal encoders and LLM are kept frozen. We evaluate our\nproposed approach on LRS3, the largest public AVSR benchmark, and we achieve\nnew state-of-the-art results for the tasks of ASR and AVSR with a WER of 0.79%\nand 0.77%, respectively. To bolster our results, we investigate the key factors\nthat underpin the effectiveness of Llama-AVSR: the choice of the pre-trained\nencoders and LLM, the efficient integration of LoRA modules, and the optimal\nperformance-efficiency trade-off obtained via modality-aware compression rates.\n","authors":["Umberto Cappellazzo","Minsu Kim","Honglie Chen","Pingchuan Ma","Stavros Petridis","Daniele Falavigna","Alessio Brutti","Maja Pantic"],"pdf_url":"https://arxiv.org/pdf/2409.12319v2.pdf","comment":"Accepted for publication at ICASSP 2025. The code and checkpoints are\n  available here: https://github.com/umbertocappellazzo/Llama-AVSR"},{"id":"http://arxiv.org/abs/2503.01879v2","updated":"2025-03-07T09:21:40Z","published":"2025-02-26T17:26:36Z","title":"Nexus-O: An Omni-Perceptive And -Interactive Model for Language, Audio,\n  And Vision","summary":"  Human beings perceive the real world through a spectrum of sensory\nmodalities, encompassing auditory, visual, and linguistic faculties. The\njourney towards achieving Artificial General Intelligence (AGI) necessitates\nthe development of models that can emulate these multifaceted perceptual\ncapabilities and comprehensively understand these diversified data. To this\nend, we introduce \\textbf{Nexus-O}, an industry-level \\textbf{omni-perceptive\nand -interactive} model capable of efficiently processing Audio, Image, Video,\nand Text data in any combination and output audio/text in an end-to-end way. We\nsystematically investigate Nexus-O by addressing three key research questions:\nFirst, how can models be efficiently designed and trained to achieve tri-modal\nalignment, understanding and reasoning capabilities across multiple modalities?\nSecond, what approaches can be implemented to evaluate tri-modal model\nrobustness, ensuring reliable performance and applicability in real-world\nscenarios? Third, what strategies can be employed to curate and obtain\nhigh-quality, real-life scenario speech datasets? For the first question, we\ndesign and pre-train Nexus-O based on the vision-language model, rather than\nthe language model. By pre-training the model over high-quality synthetic audio\ndata, our model is capable of tri-modal perception and interaction. For the\nsecond question, we introduce a new audio testbed, Nexus-O-audio, comprising\ndiverse Automatic Speech Recognition (ASR) samples, spanning various real-world\nscenarios, such as corporate meetings and live stream. For the third question,\nwe design the speech data synthesis pipeline to obtain high-quality speech\ntraining datasets, covering various real-world scenarios. Comprehensive\nexperimentation and an in-depth analysis of tri-modal alignment over latent\nspace demonstrate the advantages of our model on downstream tasks.\n","authors":["Che Liu","Yingji Zhang","Dong Zhang","Weijie Zhang","Chenggong Gong","Haohan Li","Yu Lu","Shilin Zhou","Yue Lu","Ziliang Gan","Ziao Wang","Junwei Liao","Haipang Wu","Ji Liu","Andr Freitas","Qifan Wang","Zenglin Xu","Rongjuncheng Zhang","Yong Dai"],"pdf_url":"https://arxiv.org/pdf/2503.01879v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.15107v2","updated":"2025-03-07T09:18:19Z","published":"2024-03-22T10:51:31Z","title":"PseudoTouch: Efficiently Imaging the Surface Feel of Objects for Robotic\n  Manipulation","summary":"  Tactile sensing is vital for human dexterous manipulation, however, it has\nnot been widely used in robotics. Compact, low-cost sensing platforms can\nfacilitate a change, but unlike their popular optical counterparts, they are\ndifficult to deploy in high-fidelity tasks due to their low signal\ndimensionality and lack of a simulation model. To overcome these challenges, we\nintroduce PseudoTouch which links high-dimensional structural information to\nlow-dimensional sensor signals. It does so by learning a low-dimensional\nvisual-tactile embedding, wherein we encode a depth patch from which we decode\nthe tactile signal. We collect and train PseudoTouch on a dataset comprising\naligned tactile and visual data pairs obtained through random touching of eight\nbasic geometric shapes. We demonstrate the utility of our trained PseudoTouch\nmodel in two downstream tasks: object recognition and grasp stability\nprediction. In the object recognition task, we evaluate the learned embedding's\nperformance on a set of five basic geometric shapes and five household objects.\nUsing PseudoTouch, we achieve an object recognition accuracy 84% after just ten\ntouches, surpassing a proprioception baseline. For the grasp stability task, we\nuse ACRONYM labels to train and evaluate a grasp success predictor using\nPseudoTouch's predictions derived from virtual depth information. Our approach\nyields a 32% absolute improvement in accuracy compared to the baseline relying\non partial point cloud data. We make the data, code, and trained models\npublicly available at https://pseudotouch.cs.uni-freiburg.de.\n","authors":["Adrian Rfer","Nick Heppert","Abdallah Ayad","Eugenio Chisari","Abhinav Valada"],"pdf_url":"https://arxiv.org/pdf/2403.15107v2.pdf","comment":"7 pages, 5 figures, 2 tables, accepted at ICRA 2025"},{"id":"http://arxiv.org/abs/2503.05255v1","updated":"2025-03-07T09:13:17Z","published":"2025-03-07T09:13:17Z","title":"CMMCoT: Enhancing Complex Multi-Image Comprehension via Multi-Modal\n  Chain-of-Thought and Memory Augmentation","summary":"  While previous multimodal slow-thinking methods have demonstrated remarkable\nsuccess in single-image understanding scenarios, their effectiveness becomes\nfundamentally constrained when extended to more complex multi-image\ncomprehension tasks. This limitation stems from their predominant reliance on\ntext-based intermediate reasoning processes. While for human, when engaging in\nsophisticated multi-image analysis, they typically perform two complementary\ncognitive operations: (1) continuous cross-image visual comparison through\nregion-of-interest matching, and (2) dynamic memorization of critical visual\nconcepts throughout the reasoning chain. Motivated by these observations, we\npropose the Complex Multi-Modal Chain-of-Thought (CMMCoT) framework, a\nmulti-step reasoning framework that mimics human-like \"slow thinking\" for\nmulti-image understanding. Our approach incorporates two key innovations: 1.\nThe construction of interleaved multimodal multi-step reasoning chains, which\nutilize critical visual region tokens, extracted from intermediate reasoning\nsteps, as supervisory signals. This mechanism not only facilitates\ncomprehensive cross-modal understanding but also enhances model\ninterpretability. 2. The introduction of a test-time memory augmentation module\nthat expands the model reasoning capacity during inference while preserving\nparameter efficiency. Furthermore, to facilitate research in this direction, we\nhave curated a novel multi-image slow-thinking dataset. Extensive experiments\ndemonstrate the effectiveness of our model.\n","authors":["Guanghao Zhang","Tao Zhong","Yan Xia","Zhelun Yu","Haoyuan Li","Wanggui He","Fangxun Shu","Mushui Liu","Dong She","Yi Wang","Hao Jiang"],"pdf_url":"https://arxiv.org/pdf/2503.05255v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2409.04003v3","updated":"2025-03-07T09:09:18Z","published":"2024-09-06T03:09:58Z","title":"DreamForge: Motion-Aware Autoregressive Video Generation for Multi-View\n  Driving Scenes","summary":"  Recent advances in diffusion models have improved controllable streetscape\ngeneration and supported downstream perception and planning tasks. However,\nchallenges remain in accurately modeling driving scenes and generating long\nvideos. To alleviate these issues, we propose DreamForge, an advanced\ndiffusion-based autoregressive video generation model tailored for\n3D-controllable long-term generation. To enhance the lane and foreground\ngeneration, we introduce perspective guidance and integrate object-wise\nposition encoding to incorporate local 3D correlation and improve foreground\nobject modeling. We also propose motion-aware temporal attention to capture\nmotion cues and appearance changes in videos. By leveraging motion frames and\nan autoregressive generation paradigm,we can autoregressively generate long\nvideos (over 200 frames) using a model trained in short sequences, achieving\nsuperior quality compared to the baseline in 16-frame video evaluations.\nFinally, we integrate our method with the realistic simulator DriveArena to\nprovide more reliable open-loop and closed-loop evaluations for vision-based\ndriving agents. Project Page:\nhttps://pjlab-adg.github.io/DriveArena/dreamforge.\n","authors":["Jianbiao Mei","Tao Hu","Xuemeng Yang","Licheng Wen","Yu Yang","Tiantian Wei","Yukai Ma","Min Dou","Botian Shi","Yong Liu"],"pdf_url":"https://arxiv.org/pdf/2409.04003v3.pdf","comment":"15 figures, 9 tables"},{"id":"http://arxiv.org/abs/2411.10309v2","updated":"2025-03-07T09:06:51Z","published":"2024-11-15T16:05:01Z","title":"Modification Takes Courage: Seamless Image Stitching via\n  Reference-Driven Inpainting","summary":"  Current image stitching methods often produce noticeable seams in challenging\nscenarios such as uneven hue and large parallax. To tackle this problem, we\npropose the Reference-Driven Inpainting Stitcher (RDIStitcher), which\nreformulates the image fusion and rectangling as a reference-based inpainting\nmodel, incorporating a larger modification fusion area and stronger\nmodification intensity than previous methods. Furthermore, we introduce a\nself-supervised model training method, which enables the implementation of\nRDIStitcher without requiring labeled data by fine-tuning a Text-to-Image (T2I)\ndiffusion model. Recognizing difficulties in assessing the quality of stitched\nimages, we present the Multimodal Large Language Models (MLLMs)-based metrics,\noffering a new perspective on evaluating stitched image quality. Compared to\nthe state-of-the-art (SOTA) method, extensive experiments demonstrate that our\nmethod significantly enhances content coherence and seamless transitions in the\nstitched images. Especially in the zero-shot experiments, our method exhibits\nstrong generalization capabilities. Code:\nhttps://github.com/yayoyo66/RDIStitcher\n","authors":["Ziqi Xie","Xiao Lai","Weidong Zhao","Siqi Jiang","Xianhui Liu","Wenlong Hou"],"pdf_url":"https://arxiv.org/pdf/2411.10309v2.pdf","comment":"18 pages, 10 figures"},{"id":"http://arxiv.org/abs/2411.16771v2","updated":"2025-03-07T09:00:43Z","published":"2024-11-25T06:17:23Z","title":"VidHal: Benchmarking Temporal Hallucinations in Vision LLMs","summary":"  Vision Large Language Models (VLLMs) are widely acknowledged to be prone to\nhallucinations. Existing research addressing this problem has primarily been\nconfined to image inputs, with limited exploration of video-based\nhallucinations. Furthermore, current evaluation methods fail to capture nuanced\nerrors in generated responses, which are often exacerbated by the rich\nspatiotemporal dynamics of videos. To address this, we introduce VidHal, a\nbenchmark specially designed to evaluate video-based hallucinations in VLLMs.\nVidHal is constructed by bootstrapping video instances across a wide range of\ncommon temporal aspects. A defining feature of our benchmark lies in the\ncareful creation of captions which represent varying levels of hallucination\nassociated with each video. To enable fine-grained evaluation, we propose a\nnovel caption ordering task requiring VLLMs to rank captions by hallucinatory\nextent. We conduct extensive experiments on VidHal and comprehensively evaluate\na broad selection of models. Our results uncover significant limitations in\nexisting VLLMs regarding hallucination generation. Through our benchmark, we\naim to inspire further research on 1) holistic understanding of VLLM\ncapabilities, particularly regarding hallucination, and 2) extensive\ndevelopment of advanced VLLMs to alleviate this problem.\n","authors":["Wey Yeh Choong","Yangyang Guo","Mohan Kankanhalli"],"pdf_url":"https://arxiv.org/pdf/2411.16771v2.pdf","comment":"9 pages, 10 figures. Code available at\n  https://github.com/Lookuz/VidHal"},{"id":"http://arxiv.org/abs/2503.05247v1","updated":"2025-03-07T09:00:14Z","published":"2025-03-07T09:00:14Z","title":"ColFigPhotoAttnNet: Reliable Finger Photo Presentation Attack Detection\n  Leveraging Window-Attention on Color Spaces","summary":"  Finger photo Presentation Attack Detection (PAD) can significantly strengthen\nsmartphone device security. However, these algorithms are trained to detect\ncertain types of attacks. Furthermore, they are designed to operate on images\nacquired by specific capture devices, leading to poor generalization and a lack\nof robustness in handling the evolving nature of mobile hardware. The proposed\ninvestigation is the first to systematically analyze the performance\ndegradation of existing deep learning PAD systems, convolutional and\ntransformers, in cross-capture device settings. In this paper, we introduce the\nColFigPhotoAttnNet architecture designed based on window attention on color\nchannels, followed by the nested residual network as the predictor to achieve a\nreliable PAD. Extensive experiments using various capture devices, including\niPhone13 Pro, GooglePixel 3, Nokia C5, and OnePlusOne, were carried out to\nevaluate the performance of proposed and existing methods on three publicly\navailable databases. The findings underscore the effectiveness of our approach.\n","authors":["Anudeep Vurity","Emanuela Marasco","Raghavendra Ramachandra","Jongwoo Park"],"pdf_url":"https://arxiv.org/pdf/2503.05247v1.pdf","comment":"Accepted in Winter Conference on Applications of Computer Vision\n  (WACV) 2025"},{"id":"http://arxiv.org/abs/2503.05245v1","updated":"2025-03-07T08:57:38Z","published":"2025-03-07T08:57:38Z","title":"L-FUSION: Laplacian Fetal Ultrasound Segmentation & Uncertainty\n  Estimation","summary":"  Accurate analysis of prenatal ultrasound (US) is essential for early\ndetection of developmental anomalies. However, operator dependency and\ntechnical limitations (e.g. intrinsic artefacts and effects, setting errors)\ncan complicate image interpretation and the assessment of diagnostic\nuncertainty. We present L-FUSION (Laplacian Fetal US Segmentation with\nIntegrated FoundatiON models), a framework that integrates uncertainty\nquantification through unsupervised, normative learning and large-scale\nfoundation models for robust segmentation of fetal structures in normal and\npathological scans. We propose to utilise the aleatoric logit distributions of\nStochastic Segmentation Networks and Laplace approximations with fast Hessian\nestimations to estimate epistemic uncertainty only from the segmentation head.\nThis enables us to achieve reliable abnormality quantification for instant\ndiagnostic feedback. Combined with an integrated Dropout component, L-FUSION\nenables reliable differentiation of lesions from normal fetal anatomy with\nenhanced uncertainty maps and segmentation counterfactuals in US imaging. It\nimproves epistemic and aleatoric uncertainty interpretation and removes the\nneed for manual disease-labelling. Evaluations across multiple datasets show\nthat L-FUSION achieves superior segmentation accuracy and consistent\nuncertainty quantification, supporting on-site decision-making and offering a\nscalable solution for advancing fetal ultrasound analysis in clinical settings.\n","authors":["Johanna P. Mller","Robert Wright","Thomas G. Day","Lorenzo Venturini","Samuel F. Budd","Hadrien Reynaud","Joseph V. Hajnal","Reza Razavi","Bernhard Kainz"],"pdf_url":"https://arxiv.org/pdf/2503.05245v1.pdf","comment":"Under Review"},{"id":"http://arxiv.org/abs/2502.07351v2","updated":"2025-03-07T08:56:46Z","published":"2025-02-11T08:22:21Z","title":"Multi-Knowledge-oriented Nighttime Haze Imaging Enhancer for\n  Vision-driven Intelligent Systems","summary":"  Salient object detection (SOD) plays a critical role in vision-driven\nmeasurement systems (VMS), facilitating the detection and segmentation of key\nvisual elements in an image. However, adverse imaging conditions such as haze\nduring the day, low light, and haze at night severely degrade image quality,\nand complicating the SOD process. To address these challenges, we propose a\nmulti-task-oriented nighttime haze imaging enhancer (MToIE), which integrates\nthree tasks: daytime dehazing, low-light enhancement, and nighttime dehazing.\nThe MToIE incorporates two key innovative components: First, the network\nemploys a task-oriented node learning mechanism to handle three specific\ndegradation types: day-time haze, low light, and night-time haze conditions,\nwith an embedded self-attention module enhancing its performance in nighttime\nimaging. In addition, multi-receptive field enhancement module that efficiently\nextracts multi-scale features through three parallel depthwise separable\nconvolution branches with different dilation rates, capturing comprehensive\nspatial information with minimal computational overhead. To ensure optimal\nimage reconstruction quality and visual characteristics, we suggest a hybrid\nloss function. Extensive experiments on different types of weather/imaging\nconditions illustrate that MToIE surpasses existing methods, significantly\nenhancing the accuracy and reliability of vision systems across diverse imaging\nscenarios. The code is available at https://github.com/Ai-Chen-Lab/MKoIE.\n","authors":["Ai Chen","Yuxu Lu","Dong Yang","Junlin Zhou","Yan Fu","Duanbing Chen"],"pdf_url":"https://arxiv.org/pdf/2502.07351v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2104.11977v2","updated":"2025-03-07T08:52:46Z","published":"2021-04-24T16:16:30Z","title":"Generalized moduli of continuity under irregular or random deformations\n  via multiscale analysis","summary":"  Motivated by the problem of robustness to deformations of the input for deep\nconvolutional neural networks, we identify signal classes which are inherently\nstable to irregular deformations induced by distortion fields $\\tau\\in\nL^\\infty(\\mathbb{R}^d;\\mathbb{R}^d)$, to be characterized in terms of a\ngeneralized modulus of continuity associated with the deformation operator.\nResorting to ideas of harmonic and multiscale analysis, we prove that for\nsignals in multiresolution approximation spaces $U_s$ at scale $s$, stability\nin $L^2$ holds in the regime $\\|\\tau\\|_{L^\\infty}/s\\ll 1$ - essentially as an\neffect of the uncertainty principle. Instability occurs when\n$\\|\\tau\\|_{L^\\infty}/s\\gg 1$, and we provide a sharp upper bound for the\nasymptotic growth rate. The stability results are then extended to signals in\nthe Besov space $B^{d/2}_{2,1}$ tailored to the given multiresolution\napproximation. We also consider the case of more general time-frequency\ndeformations. Finally, we provide stochastic versions of the aforementioned\nresults, namely we study the issue of stability in mean when $\\tau(x)$ is\nmodeled as a random field (not bounded, in general) with identically\ndistributed variables $|\\tau(x)|$, $x\\in\\mathbb{R}^d$.\n","authors":["Fabio Nicola","S. Ivan Trapasso"],"pdf_url":"https://arxiv.org/pdf/2104.11977v2.pdf","comment":"25 pages"},{"id":"http://arxiv.org/abs/2503.05236v1","updated":"2025-03-07T08:36:05Z","published":"2025-03-07T08:36:05Z","title":"Unified Reward Model for Multimodal Understanding and Generation","summary":"  Recent advances in human preference alignment have significantly enhanced\nmultimodal generation and understanding. A key approach is training reward\nmodels to guide preference optimization. However, existing models are often\ntask-specific, limiting their adaptability across diverse visual applications.\nWe also argue that jointly learning to assess multiple tasks may foster a\nsynergistic effect, where improved image understanding enhances image\ngeneration assessment, and refined image evaluation benefits video assessment\nthrough better frame analysis. To this end, this paper proposes UnifiedReward,\nthe first unified reward model for multimodal understanding and generation\nassessment, enabling both pairwise ranking and pointwise scoring, which can be\nemployed for vision model preference alignment. Specifically, (1) we first\ndevelop UnifiedReward on our constructed large-scale human preference dataset,\nincluding both image and video generation/understanding tasks. (2) Then, it is\nutilized to automatically construct high-quality preference pair data based on\nthe vision models, fine-gradually filtering their outputs through pair ranking\nand point sifting. (3) Finally, these data are used for their preference\nalignment through Direct Preference Optimization (DPO). Experimental results\ndemonstrate that joint learning to assess diverse visual tasks can lead to\nsubstantial mutual benefits and we apply our pipeline to both image and video\nunderstanding/generation tasks, significantly improving the performance in each\ndomain.\n","authors":["Yibin Wang","Yuhang Zang","Hao Li","Cheng Jin","Jiaqi Wang"],"pdf_url":"https://arxiv.org/pdf/2503.05236v1.pdf","comment":"project page: https://codegoat24.github.io/UnifiedReward/"},{"id":"http://arxiv.org/abs/2503.05228v1","updated":"2025-03-07T08:25:28Z","published":"2025-03-07T08:25:28Z","title":"RecipeGen: A Benchmark for Real-World Recipe Image Generation","summary":"  Recipe image generation is an important challenge in food computing, with\napplications from culinary education to interactive recipe platforms. However,\nthere is currently no real-world dataset that comprehensively connects recipe\ngoals, sequential steps, and corresponding images. To address this, we\nintroduce RecipeGen, the first real-world goal-step-image benchmark for recipe\ngeneration, featuring diverse ingredients, varied recipe steps, multiple\ncooking styles, and a broad collection of food categories. Data is in\nhttps://github.com/zhangdaxia22/RecipeGen.\n","authors":["Ruoxuan Zhang","Hongxia Xie","Yi Yao","Jian-Yu Jiang-Lin","Bin Wen","Ling Lo","Hong-Han Shuai","Yung-Hui Li","Wen-Huang Cheng"],"pdf_url":"https://arxiv.org/pdf/2503.05228v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.05223v1","updated":"2025-03-07T08:21:48Z","published":"2025-03-07T08:21:48Z","title":"DiVISe: Direct Visual-Input Speech Synthesis Preserving Speaker\n  Characteristics And Intelligibility","summary":"  Video-to-speech (V2S) synthesis, the task of generating speech directly from\nsilent video input, is inherently more challenging than other speech synthesis\ntasks due to the need to accurately reconstruct both speech content and speaker\ncharacteristics from visual cues alone. Recently, audio-visual pre-training has\neliminated the need for additional acoustic hints in V2S, which previous\nmethods often relied on to ensure training convergence. However, even with\npre-training, existing methods continue to face challenges in achieving a\nbalance between acoustic intelligibility and the preservation of\nspeaker-specific characteristics. We analyzed this limitation and were\nmotivated to introduce DiVISe (Direct Visual-Input Speech Synthesis), an\nend-to-end V2S model that predicts Mel-spectrograms directly from video frames\nalone. Despite not taking any acoustic hints, DiVISe effectively preserves\nspeaker characteristics in the generated audio, and achieves superior\nperformance on both objective and subjective metrics across the LRS2 and LRS3\ndatasets. Our results demonstrate that DiVISe not only outperforms existing V2S\nmodels in acoustic intelligibility but also scales more effectively with\nincreased data and model parameters. Code and weights can be found at\nhttps://github.com/PussyCat0700/DiVISe.\n","authors":["Yifan Liu","Yu Fang","Zhouhan Lin"],"pdf_url":"https://arxiv.org/pdf/2503.05223v1.pdf","comment":"to be published in NAACL 25"},{"id":"http://arxiv.org/abs/2503.01428v2","updated":"2025-03-07T08:21:10Z","published":"2025-03-03T11:29:35Z","title":"DLF: Extreme Image Compression with Dual-generative Latent Fusion","summary":"  Recent studies in extreme image compression have achieved remarkable\nperformance by compressing the tokens from generative tokenizers. However,\nthese methods often prioritize clustering common semantics within the dataset,\nwhile overlooking the diverse details of individual objects. Consequently, this\nresults in suboptimal reconstruction fidelity, especially at low bitrates. To\naddress this issue, we introduce a Dual-generative Latent Fusion (DLF)\nparadigm. DLF decomposes the latent into semantic and detail elements,\ncompressing them through two distinct branches. The semantic branch clusters\nhigh-level information into compact tokens, while the detail branch encodes\nperceptually critical details to enhance the overall fidelity. Additionally, we\npropose a cross-branch interactive design to reduce redundancy between the two\nbranches, thereby minimizing the overall bit cost. Experimental results\ndemonstrate the impressive reconstruction quality of DLF even below 0.01 bits\nper pixel (bpp). On the CLIC2020 test set, our method achieves bitrate savings\nof up to 27.93% on LPIPS and 53.55% on DISTS compared to MS-ILLM. Furthermore,\nDLF surpasses recent diffusion-based codecs in visual fidelity while\nmaintaining a comparable level of generative realism. Code will be available\nlater.\n","authors":["Naifu Xue","Zhaoyang Jia","Jiahao Li","Bin Li","Yuan Zhang","Yan Lu"],"pdf_url":"https://arxiv.org/pdf/2503.01428v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2502.20224v2","updated":"2025-03-07T08:17:31Z","published":"2025-02-27T16:06:57Z","title":"RURANET++: An Unsupervised Learning Method for Diabetic Macular Edema\n  Based on SCSE Attention Mechanisms and Dynamic Multi-Projection Head\n  Clustering","summary":"  Diabetic Macular Edema (DME), a prevalent complication among diabetic\npatients, constitutes a major cause of visual impairment and blindness.\nAlthough deep learning has achieved remarkable progress in medical image\nanalysis, traditional DME diagnosis still relies on extensive annotated data\nand subjective ophthalmologist assessments, limiting practical applications. To\naddress this, we present RURANET++, an unsupervised learning-based automated\nDME diagnostic system. This framework incorporates an optimized U-Net\narchitecture with embedded Spatial and Channel Squeeze & Excitation (SCSE)\nattention mechanisms to enhance lesion feature extraction. During feature\nprocessing, a pre-trained GoogLeNet model extracts deep features from retinal\nimages, followed by PCA-based dimensionality reduction to 50 dimensions for\ncomputational efficiency. Notably, we introduce a novel clustering algorithm\nemploying multi-projection heads to explicitly control cluster diversity while\ndynamically adjusting similarity thresholds, thereby optimizing intra-class\nconsistency and inter-class discrimination. Experimental results demonstrate\nsuperior performance across multiple metrics, achieving maximum accuracy\n(0.8411), precision (0.8593), recall (0.8411), and F1-score (0.8390), with\nexceptional clustering quality. This work provides an efficient unsupervised\nsolution for DME diagnosis with significant clinical implications.\n","authors":["Wei Yang","Yiran Zhu","Jiayu Shen","Yuhan Tang","Chengchang Pan","Hui He","Yan Su","Honggang Qi"],"pdf_url":"https://arxiv.org/pdf/2502.20224v2.pdf","comment":"10 pages, 2 figures, 5 tables, submitted to The 28th International\n  Conference on Medical Image Computing and Computer Assisted Intervention\n  (MICCAI 2025)"},{"id":"http://arxiv.org/abs/2503.05217v1","updated":"2025-03-07T08:15:02Z","published":"2025-03-07T08:15:02Z","title":"Separability Membrane: 3D Active Contour for Point Cloud Surface\n  Reconstruction","summary":"  This paper proposes Separability Membrane, a robust 3D active contour for\nextracting a surface from 3D point cloud object. Our approach defines the\nsurface of a 3D object as the boundary that maximizes the separability of point\nfeatures, such as intensity, color, or local density, between its inner and\nouter regions based on Fisher's ratio. Separability Membrane identifies the\nexact surface of a 3D object by maximizing class separability while controlling\nthe rigidity of the 3D surface model with an adaptive B-spline surface that\nadjusts its properties based on the local and global separability. A key\nadvantage of our method is its ability to accurately reconstruct surface\nboundaries even when they are ambiguous due to noise or outliers, without\nrequiring any training data or conversion to volumetric representation.\nEvaluations on a synthetic 3D point cloud dataset and the 3DNet dataset\ndemonstrate the membrane's effectiveness and robustness under diverse\nconditions.\n","authors":["Gulpi Qorik Oktagalu Pratamasunu","Guoqing Hao","Kazuhiro Fukui"],"pdf_url":"https://arxiv.org/pdf/2503.05217v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.05214v1","updated":"2025-03-07T08:09:59Z","published":"2025-03-07T08:09:59Z","title":"Gaussian Random Fields as an Abstract Representation of Patient Metadata\n  for Multimodal Medical Image Segmentation","summary":"  The growing rate of chronic wound occurrence, especially in patients with\ndiabetes, has become a concerning trend in recent years. Chronic wounds are\ndifficult and costly to treat, and have become a serious burden on health care\nsystems worldwide. Chronic wounds can have devastating consequences for the\npatient, with infection often leading to reduced quality of life and increased\nmortality risk. Innovative deep learning methods for the detection and\nmonitoring of such wounds have the potential to reduce the impact to both\npatient and clinician. We present a novel multimodal segmentation method which\nallows for the introduction of patient metadata into the training workflow\nwhereby the patient data are expressed as Gaussian random fields. Our results\nindicate that the proposed method improved performance when utilising multiple\nmodels, each trained on different metadata categories. Using the Diabetic Foot\nUlcer Challenge 2022 test set, when compared to the baseline results\n(intersection over union = 0.4670, Dice similarity coefficient = 0.5908) we\ndemonstrate improvements of +0.0220 and +0.0229 for intersection over union and\nDice similarity coefficient respectively. This paper presents the first study\nto focus on integrating patient data into a chronic wound segmentation\nworkflow. Our results show significant performance gains when training\nindividual models using specific metadata categories, followed by average\nmerging of prediction masks using distance transforms. All source code for this\nstudy is available at:\nhttps://github.com/mmu-dermatology-research/multimodal-grf\n","authors":["Bill Cassidy","Christian McBride","Connah Kendrick","Neil D. Reeves","Joseph M. Pappachan","Shaghayegh Raad","Moi Hoon Yap"],"pdf_url":"https://arxiv.org/pdf/2503.05214v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.19346v2","updated":"2025-03-07T08:08:18Z","published":"2024-11-28T19:48:54Z","title":"CLIP meets DINO for Tuning Zero-Shot Classifier using Unlabeled Image\n  Collections","summary":"  In the era of foundation models, CLIP has emerged as a powerful tool for\naligning text & visual modalities into a common embedding space. However, the\nalignment objective used to train CLIP often results in subpar visual features\nfor fine-grained tasks. In contrast, SSL-pretrained models like DINO excel at\nextracting rich visual features due to their specialized training paradigm.\nYet, these SSL models require an additional supervised linear probing step,\nwhich relies on fully labeled data which is often expensive and difficult to\nobtain at scale. In this paper, we propose a label-free prompt-tuning method\nthat leverages the rich visual features of self-supervised learning models\n(DINO) and the broad textual knowledge of large language models (LLMs) to\nlargely enhance CLIP-based image classification performance using unlabeled\nimages. Our approach unfolds in three key steps: (1) We generate robust textual\nfeature embeddings that more accurately represent object classes by leveraging\nclass-specific descriptions from LLMs, enabling more effective zero-shot\nclassification compared to CLIP's default name-specific prompts. (2) These\ntextual embeddings are then used to produce pseudo-labels to train an alignment\nmodule that integrates the complementary strengths of LLM description-based\ntextual embeddings & DINO's visual features. (3) Finally, we prompt-tune CLIP's\nvision encoder through DINO-assisted supervision using the trained alignment\nmodule. This three-step process allows us to harness the best of visual &\ntextual foundation models, resulting in a powerful and efficient approach that\nsurpasses state-of-the-art label-free classification methods. Notably, our\nframework, NoLA (No Labels Attached), achieves an average absolute gain of 3.6%\nover the state-of-the-art LaFTer across 11 diverse image classification\ndatasets. Our code & models can be found at https://github.com/fazliimam/NoLA.\n","authors":["Mohamed Fazli Imam","Rufael Fedaku Marew","Jameel Hassan","Mustansar Fiaz","Alham Fikri Aji","Hisham Cholakkal"],"pdf_url":"https://arxiv.org/pdf/2411.19346v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.05204v1","updated":"2025-03-07T07:49:31Z","published":"2025-03-07T07:49:31Z","title":"Data-Efficient Generalization for Zero-shot Composed Image Retrieval","summary":"  Zero-shot Composed Image Retrieval (ZS-CIR) aims to retrieve the target image\nbased on a reference image and a text description without requiring\nin-distribution triplets for training. One prevalent approach follows the\nvision-language pretraining paradigm that employs a mapping network to transfer\nthe image embedding to a pseudo-word token in the text embedding space.\nHowever, this approach tends to impede network generalization due to modality\ndiscrepancy and distribution shift between training and inference. To this end,\nwe propose a Data-efficient Generalization (DeG) framework, including two novel\ndesigns, namely, Textual Supplement (TS) module and Semantic-Set (S-Set). The\nTS module exploits compositional textual semantics during training, enhancing\nthe pseudo-word token with more linguistic semantics and thus mitigating the\nmodality discrepancy effectively. The S-Set exploits the zero-shot capability\nof pretrained Vision-Language Models (VLMs), alleviating the distribution shift\nand mitigating the overfitting issue from the redundancy of the large-scale\nimage-text data. Extensive experiments over four ZS-CIR benchmarks show that\nDeG outperforms the state-of-the-art (SOTA) methods with much less training\ndata, and saves substantial training and inference time for practical usage.\n","authors":["Zining Chen","Zhicheng Zhao","Fei Su","Xiaoqin Zhang","Shijian Lu"],"pdf_url":"https://arxiv.org/pdf/2503.05204v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.05196v1","updated":"2025-03-07T07:37:34Z","published":"2025-03-07T07:37:34Z","title":"STGA: Selective-Training Gaussian Head Avatars","summary":"  We propose selective-training Gaussian head avatars (STGA) to enhance the\ndetails of dynamic head Gaussian. The dynamic head Gaussian model is trained\nbased on the FLAME parameterized model. Each Gaussian splat is embedded within\nthe FLAME mesh to achieve mesh-based animation of the Gaussian model. Before\ntraining, our selection strategy calculates the 3D Gaussian splat to be\noptimized in each frame. The parameters of these 3D Gaussian splats are\noptimized in the training of each frame, while those of the other splats are\nfrozen. This means that the splats participating in the optimization process\ndiffer in each frame, to improve the realism of fine details. Compared with\nnetwork-based methods, our method achieves better results with shorter training\ntime. Compared with mesh-based methods, our method produces more realistic\ndetails within the same training time. Additionally, the ablation experiment\nconfirms that our method effectively enhances the quality of details.\n","authors":["Hanzhi Guo","Yixiao Chen","Dongye Xiaonuo","Zeyu Tian","Dongdong Weng","Le Luo"],"pdf_url":"https://arxiv.org/pdf/2503.05196v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.05190v1","updated":"2025-03-07T07:22:42Z","published":"2025-03-07T07:22:42Z","title":"Partially Supervised Unpaired Multi-Modal Learning for Label-Efficient\n  Medical Image Segmentation","summary":"  Unpaired Multi-Modal Learning (UMML) which leverages unpaired multi-modal\ndata to boost model performance on each individual modality has attracted a lot\nof research interests in medical image analysis. However, existing UMML methods\nrequire multi-modal datasets to be fully labeled, which incurs tremendous\nannotation cost. In this paper, we investigate the use of partially labeled\ndata for label-efficient unpaired multi-modal learning, which can reduce the\nannotation cost by up to one half. We term the new learning paradigm as\nPartially Supervised Unpaired Multi-Modal Learning (PSUMML) and propose a novel\nDecomposed partial class adaptation with snapshot Ensembled Self-Training\n(DEST) framework for it. Specifically, our framework consists of a compact\nsegmentation network with modality specific normalization layers for learning\nwith partially labeled unpaired multi-modal data. The key challenge in PSUMML\nlies in the complex partial class distribution discrepancy due to partial class\nannotation, which hinders effective knowledge transfer across modalities. We\ntheoretically analyze this phenomenon with a decomposition theorem and propose\na decomposed partial class adaptation technique to precisely align the\npartially labeled classes across modalities to reduce the distribution\ndiscrepancy. We further propose a snapshot ensembled self-training technique to\nleverage the valuable snapshot models during training to assign pseudo-labels\nto partially labeled pixels for self-training to boost model performance. We\nperform extensive experiments under different scenarios of PSUMML for two\nmedical image segmentation tasks, namely cardiac substructure segmentation and\nabdominal multi-organ segmentation. Our framework outperforms existing methods\nsignificantly.\n","authors":["Lei Zhu","Yanyu Xu","Huazhu Fu","Xinxing Xu","Rick Siow Mong Goh","Yong Liu"],"pdf_url":"https://arxiv.org/pdf/2503.05190v1.pdf","comment":"Accepted to MLMI 2024"},{"id":"http://arxiv.org/abs/2503.05186v1","updated":"2025-03-07T07:15:06Z","published":"2025-03-07T07:15:06Z","title":"Narrating the Video: Boosting Text-Video Retrieval via Comprehensive\n  Utilization of Frame-Level Captions","summary":"  In recent text-video retrieval, the use of additional captions from\nvision-language models has shown promising effects on the performance. However,\nexisting models using additional captions often have struggled to capture the\nrich semantics, including temporal changes, inherent in the video. In addition,\nincorrect information caused by generative models can lead to inaccurate\nretrieval. To address these issues, we propose a new framework, Narrating the\nVideo (NarVid), which strategically leverages the comprehensive information\navailable from frame-level captions, the narration. The proposed NarVid\nexploits narration in multiple ways: 1) feature enhancement through cross-modal\ninteractions between narration and video, 2) query-aware adaptive filtering to\nsuppress irrelevant or incorrect information, 3) dual-modal matching score by\nadding query-video similarity and query-narration similarity, and 4)\nhard-negative loss to learn discriminative features from multiple perspectives\nusing the two similarities from different views. Experimental results\ndemonstrate that NarVid achieves state-of-the-art performance on various\nbenchmark datasets.\n","authors":["Chan hur","Jeong-hun Hong","Dong-hun Lee","Dabin Kang","Semin Myeong","Sang-hyo Park","Hyeyoung Park"],"pdf_url":"https://arxiv.org/pdf/2503.05186v1.pdf","comment":"Accepted at CVPR 2025"},{"id":"http://arxiv.org/abs/2503.05183v1","updated":"2025-03-07T07:08:14Z","published":"2025-03-07T07:08:14Z","title":"Spectral-Spatial Extraction through Layered Tensor Decomposition for\n  Hyperspectral Anomaly Detection","summary":"  Low rank tensor representation (LRTR) methods are very useful for\nhyperspectral anomaly detection (HAD). To overcome the limitations that they\noften overlook spectral anomaly and rely on large-scale matrix singular value\ndecomposition, we first apply non-negative matrix factorization (NMF) to\nalleviate spectral dimensionality redundancy and extract spectral anomaly and\nthen employ LRTR to extract spatial anomaly while mitigating spatial\nredundancy, yielding a highly efffcient layered tensor decomposition (LTD)\nframework for HAD. An iterative algorithm based on proximal alternating\nminimization is developed to solve the proposed LTD model, with convergence\nguarantees provided. Moreover, we introduce a rank reduction strategy with\nvalidation mechanism that adaptively reduces data size while preventing\nexcessive reduction. Theoretically, we rigorously establish the equivalence\nbetween the tensor tubal rank and tensor group sparsity regularization (TGSR)\nand, under mild conditions, demonstrate that the relaxed formulation of TGSR\nshares the same global minimizers and optimal values as its original\ncounterpart. Experimental results on the Airport-Beach-Urban and MVTec datasets\ndemonstrate that our approach outperforms state-of-the-art methods in the HAD\ntask.\n","authors":["Quan Yu","Yu-Hong Dai","Minru Bai"],"pdf_url":"https://arxiv.org/pdf/2503.05183v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.05182v1","updated":"2025-03-07T07:06:47Z","published":"2025-03-07T07:06:47Z","title":"MGSR: 2D/3D Mutual-boosted Gaussian Splatting for High-fidelity Surface\n  Reconstruction under Various Light Conditions","summary":"  Novel view synthesis (NVS) and surface reconstruction (SR) are essential\ntasks in 3D Gaussian Splatting (3D-GS). Despite recent progress, these tasks\nare often addressed independently, with GS-based rendering methods struggling\nunder diverse light conditions and failing to produce accurate surfaces, while\nGS-based reconstruction methods frequently compromise rendering quality. This\nraises a central question: must rendering and reconstruction always involve a\ntrade-off? To address this, we propose MGSR, a 2D/3D Mutual-boosted Gaussian\nsplatting for Surface Reconstruction that enhances both rendering quality and\n3D reconstruction accuracy. MGSR introduces two branches--one based on 2D-GS\nand the other on 3D-GS. The 2D-GS branch excels in surface reconstruction,\nproviding precise geometry information to the 3D-GS branch. Leveraging this\ngeometry, the 3D-GS branch employs a geometry-guided illumination decomposition\nmodule that captures reflected and transmitted components, enabling realistic\nrendering under varied light conditions. Using the transmitted component as\nsupervision, the 2D-GS branch also achieves high-fidelity surface\nreconstruction. Throughout the optimization process, the 2D-GS and 3D-GS\nbranches undergo alternating optimization, providing mutual supervision. Prior\nto this, each branch completes an independent warm-up phase, with an early\nstopping strategy implemented to reduce computational costs. We evaluate MGSR\non a diverse set of synthetic and real-world datasets, at both object and scene\nlevels, demonstrating strong performance in rendering and surface\nreconstruction.\n","authors":["Qingyuan Zhou","Yuehu Gong","Weidong Yang","Jiaze Li","Yeqi Luo","Baixin Xu","Shuhao Li","Ben Fei","Ying He"],"pdf_url":"https://arxiv.org/pdf/2503.05182v1.pdf","comment":"11 pages, 7 figures"},{"id":"http://arxiv.org/abs/2409.00926v2","updated":"2025-03-07T07:00:24Z","published":"2024-09-02T03:44:24Z","title":"Towards Student Actions in Classroom Scenes: New Dataset and Baseline","summary":"  Analyzing student actions is an important and challenging task in educational\nresearch. Existing efforts have been hampered by the lack of accessible\ndatasets to capture the nuanced action dynamics in classrooms. In this paper,\nwe present a new multi-label Student Action Video (SAV) dataset, specifically\ndesigned for action detection in classroom settings. The SAV dataset consists\nof 4,324 carefully trimmed video clips from 758 different classrooms, annotated\nwith 15 distinct student actions. Compared to existing action detection\ndatasets, the SAV dataset stands out by providing a wide range of real\nclassroom scenarios, high-quality video data, and unique challenges, including\nsubtle movement differences, dense object engagement, significant scale\ndifferences, varied shooting angles, and visual occlusion. These complexities\nintroduce new opportunities and challenges to advance action detection methods.\nTo benchmark this, we propose a novel baseline method based on a visual\ntransformer, designed to enhance attention to key local details within small\nand dense object regions. Our method demonstrates excellent performance with a\nmean Average Precision (mAP) of 67.9% and 27.4% on the SAV and AVA datasets,\nrespectively. This paper not only provides the dataset but also calls for\nfurther research into AI-driven educational tools that may transform teaching\nmethodologies and learning outcomes. The code and dataset are released at\nhttps://github.com/Ritatanz/SAV.\n","authors":["Zhuolin Tan","Chenqiang Gao","Anyong Qin","Ruixin Chen","Tiecheng Song","Feng Yang","Deyu Meng"],"pdf_url":"https://arxiv.org/pdf/2409.00926v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.15808v4","updated":"2025-03-07T06:49:23Z","published":"2024-11-24T12:30:12Z","title":"LRSAA: Large-scale Remote Sensing Image Target Recognition and Automatic\n  Annotation","summary":"  This paper presents a method for object recognition and automatic labeling in\nlarge-area remote sensing images called LRSAA. The method integrates YOLOv11\nand MobileNetV3-SSD object detection algorithms through ensemble learning to\nenhance model performance. Furthermore, it employs Poisson disk sampling\nsegmentation techniques and the EIOU metric to optimize the training and\ninference processes of segmented images, followed by the integration of\nresults. This approach not only reduces the demand for computational resources\nbut also achieves a good balance between accuracy and speed. The source code\nfor this project has been made publicly available on\nhttps://github.com/anaerovane/LRSAA.\n","authors":["Wuzheng Dong","Yujuan Zhu","Sheng Zhang"],"pdf_url":"https://arxiv.org/pdf/2411.15808v4.pdf","comment":"arXiv admin note: text overlap with arXiv:2411.07802"},{"id":"http://arxiv.org/abs/2502.21314v2","updated":"2025-03-07T06:46:50Z","published":"2025-02-28T18:56:35Z","title":"Raccoon: Multi-stage Diffusion Training with Coarse-to-Fine Curating\n  Videos","summary":"  Text-to-video generation has demonstrated promising progress with the advent\nof diffusion models, yet existing approaches are limited by dataset quality and\ncomputational resources. To address these limitations, this paper presents a\ncomprehensive approach that advances both data curation and model design. We\nintroduce CFC-VIDS-1M, a high-quality video dataset constructed through a\nsystematic coarse-to-fine curation pipeline. The pipeline first evaluates video\nquality across multiple dimensions, followed by a fine-grained stage that\nleverages vision-language models to enhance text-video alignment and semantic\nrichness. Building upon the curated dataset's emphasis on visual quality and\ntemporal coherence, we develop RACCOON, a transformer-based architecture with\ndecoupled spatial-temporal attention mechanisms. The model is trained through a\nprogressive four-stage strategy designed to efficiently handle the complexities\nof video generation. Extensive experiments demonstrate that our integrated\napproach of high-quality data curation and efficient training strategy\ngenerates visually appealing and temporally coherent videos while maintaining\ncomputational efficiency. We will release our dataset, code, and models.\n","authors":["Zhiyu Tan","Junyan Wang","Hao Yang","Luozheng Qin","Hesen Chen","Qiang Zhou","Hao Li"],"pdf_url":"https://arxiv.org/pdf/2502.21314v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.05174v1","updated":"2025-03-07T06:40:06Z","published":"2025-03-07T06:40:06Z","title":"SplatPose: Geometry-Aware 6-DoF Pose Estimation from Single RGB Image\n  via 3D Gaussian Splatting","summary":"  6-DoF pose estimation is a fundamental task in computer vision with\nwide-ranging applications in augmented reality and robotics. Existing single\nRGB-based methods often compromise accuracy due to their reliance on initial\npose estimates and susceptibility to rotational ambiguity, while approaches\nrequiring depth sensors or multi-view setups incur significant deployment\ncosts. To address these limitations, we introduce SplatPose, a novel framework\nthat synergizes 3D Gaussian Splatting (3DGS) with a dual-branch neural\narchitecture to achieve high-precision pose estimation using only a single RGB\nimage. Central to our approach is the Dual-Attention Ray Scoring Network\n(DARS-Net), which innovatively decouples positional and angular alignment\nthrough geometry-domain attention mechanisms, explicitly modeling directional\ndependencies to mitigate rotational ambiguity. Additionally, a coarse-to-fine\noptimization pipeline progressively refines pose estimates by aligning dense 2D\nfeatures between query images and 3DGS-synthesized views, effectively\ncorrecting feature misalignment and depth errors from sparse ray sampling.\nExperiments on three benchmark datasets demonstrate that SplatPose achieves\nstate-of-the-art 6-DoF pose estimation accuracy in single RGB settings,\nrivaling approaches that depend on depth or multi-view images.\n","authors":["Linqi Yang","Xiongwei Zhao","Qihao Sun","Ke Wang","Ao Chen","Peng Kang"],"pdf_url":"https://arxiv.org/pdf/2503.05174v1.pdf","comment":"Submitted to IROS 2025"},{"id":"http://arxiv.org/abs/2503.05170v1","updated":"2025-03-07T06:31:19Z","published":"2025-03-07T06:31:19Z","title":"Spatial Context-Driven Positive Pair Sampling for Enhanced\n  Histopathology Image Classification","summary":"  Deep learning has demonstrated great promise in cancer classification from\nwhole-slide images (WSIs) but remains constrained by the need for extensive\nannotations. Annotation-free methods, such as multiple instance learning (MIL)\nand self-supervised learning (SSL), have emerged to address this challenge;\nhowever, current SSL techniques often depend on synthetic augmentations or\ntemporal context, which may not adequately capture the intricate spatial\nrelationships inherent to histopathology. In this work, we introduce a novel\nspatial context-driven positive pair sampling strategy for SSL that leverages\nthe natural coherence of adjacent patches in WSIs. By constructing biologically\nrelevant positive pairs from spatially proximate patches, our approach\nharnesses inherent spatial coherence to enhance patch-level representations,\nultimately boosting slide-level classification performance. Experiments on\nmultiple datasets reveal that our strategy improves classification accuracy by\n5\\% to 10\\% over the standard method, paving the way for more clinically\nrelevant AI models in cancer diagnosis. The code is available at\nhttps://anonymous.4open.science/r/contextual-pairs-E72F/.\n","authors":["Willmer Rafell Quinones Robles","Sakonporn Noree","Young Sin Ko","Bryan Wong","Jongwoo Kim","Mun Yong Yi"],"pdf_url":"https://arxiv.org/pdf/2503.05170v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.00357v2","updated":"2025-03-07T06:20:13Z","published":"2025-03-01T05:42:52Z","title":"CAT-3DGS: A Context-Adaptive Triplane Approach to\n  Rate-Distortion-Optimized 3DGS Compression","summary":"  3D Gaussian Splatting (3DGS) has recently emerged as a promising 3D\nrepresentation. Much research has been focused on reducing its storage\nrequirements and memory footprint. However, the needs to compress and transmit\nthe 3DGS representation to the remote side are overlooked. This new application\ncalls for rate-distortion-optimized 3DGS compression. How to quantize and\nentropy encode sparse Gaussian primitives in the 3D space remains largely\nunexplored. Few early attempts resort to the hyperprior framework from learned\nimage compression. But, they fail to utilize fully the inter and intra\ncorrelation inherent in Gaussian primitives. Built on ScaffoldGS, this work,\ntermed CAT-3DGS, introduces a context-adaptive triplane approach to their\nrate-distortion-optimized coding. It features multi-scale triplanes, oriented\naccording to the principal axes of Gaussian primitives in the 3D space, to\ncapture their inter correlation (i.e. spatial correlation) for spatial\nautoregressive coding in the projected 2D planes. With these triplanes serving\nas the hyperprior, we further perform channel-wise autoregressive coding to\nleverage the intra correlation within each individual Gaussian primitive. Our\nCAT-3DGS incorporates a view frequency-aware masking mechanism. It actively\nskips from coding those Gaussian primitives that potentially have little impact\non the rendering quality. When trained end-to-end to strike a good\nrate-distortion trade-off, our CAT-3DGS achieves the state-of-the-art\ncompression performance on the commonly used real-world datasets.\n","authors":["Yu-Ting Zhan","Cheng-Yuan Ho","Hebi Yang","Yi-Hsin Chen","Jui Chiu Chiang","Yu-Lun Liu","Wen-Hsiao Peng"],"pdf_url":"https://arxiv.org/pdf/2503.00357v2.pdf","comment":"Accepted for Publication in International Conference on Learning\n  Representations (ICLR)"},{"id":"http://arxiv.org/abs/2502.11142v3","updated":"2025-03-07T06:06:29Z","published":"2025-02-16T14:17:36Z","title":"NavRAG: Generating User Demand Instructions for Embodied Navigation\n  through Retrieval-Augmented LLM","summary":"  Vision-and-Language Navigation (VLN) is an essential skill for embodied\nagents, allowing them to navigate in 3D environments following natural language\ninstructions. High-performance navigation models require a large amount of\ntraining data, the high cost of manually annotating data has seriously hindered\nthis field. Therefore, some previous methods translate trajectory videos into\nstep-by-step instructions for expanding data, but such instructions do not\nmatch well with users' communication styles that briefly describe destinations\nor state specific needs. Moreover, local navigation trajectories overlook\nglobal context and high-level task planning. To address these issues, we\npropose NavRAG, a retrieval-augmented generation (RAG) framework that generates\nuser demand instructions for VLN. NavRAG leverages LLM to build a hierarchical\nscene description tree for 3D scene understanding from global layout to local\ndetails, then simulates various user roles with specific demands to retrieve\nfrom the scene tree, generating diverse instructions with LLM. We annotate over\n2 million navigation instructions across 861 scenes and evaluate the data\nquality and navigation performance of trained models.\n","authors":["Zihan Wang","Yaohui Zhu","Gim Hee Lee","Yachun Fan"],"pdf_url":"https://arxiv.org/pdf/2502.11142v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2412.06234v3","updated":"2025-03-07T06:02:35Z","published":"2024-12-09T06:20:51Z","title":"Generative Densification: Learning to Densify Gaussians for\n  High-Fidelity Generalizable 3D Reconstruction","summary":"  Generalized feed-forward Gaussian models have achieved significant progress\nin sparse-view 3D reconstruction by leveraging prior knowledge from large\nmulti-view datasets. However, these models often struggle to represent\nhigh-frequency details due to the limited number of Gaussians. While the\ndensification strategy used in per-scene 3D Gaussian splatting (3D-GS)\noptimization can be adapted to the feed-forward models, it may not be ideally\nsuited for generalized scenarios. In this paper, we propose Generative\nDensification, an efficient and generalizable method to densify Gaussians\ngenerated by feed-forward models. Unlike the 3D-GS densification strategy,\nwhich iteratively splits and clones raw Gaussian parameters, our method\nup-samples feature representations from the feed-forward models and generates\ntheir corresponding fine Gaussians in a single forward pass, leveraging the\nembedded prior knowledge for enhanced generalization. Experimental results on\nboth object-level and scene-level reconstruction tasks demonstrate that our\nmethod outperforms state-of-the-art approaches with comparable or smaller model\nsizes, achieving notable improvements in representing fine details.\n","authors":["Seungtae Nam","Xiangyu Sun","Gyeongjin Kang","Younggeun Lee","Seungjun Oh","Eunbyung Park"],"pdf_url":"https://arxiv.org/pdf/2412.06234v3.pdf","comment":"Project page: https://stnamjef.github.io/GenerativeDensification/"},{"id":"http://arxiv.org/abs/2411.10831v3","updated":"2025-03-07T06:02:33Z","published":"2024-11-16T16:24:28Z","title":"Neighboring Slice Noise2Noise: Self-Supervised Medical Image Denoising\n  from Single Noisy Image Volume","summary":"  In the last few years, with the rapid development of deep learning\ntechnologies, supervised methods based on convolutional neural networks have\ngreatly enhanced the performance of medical image denoising. However, these\nmethods require large quantities of noisy-clean image pairs for training, which\ngreatly limits their practicality. Although some researchers have attempted to\ntrain denoising networks using only single noisy images, existing\nself-supervised methods, including blind-spot-based and data-splitting-based\nmethods, heavily rely on the assumption that noise is pixel-wise independent.\nHowever, this assumption often does not hold in real-world medical images.\nTherefore, in the field of medical imaging, there remains a lack of simple and\npractical denoising methods that can achieve high-quality denoising performance\nusing only single noisy images. In this paper, we propose a novel\nself-supervised medical image denoising method, Neighboring Slice Noise2Noise\n(NS-N2N). The proposed method utilizes neighboring slices within a single noisy\nimage volume to construct weighted training data, and then trains the denoising\nnetwork using a self-supervised scheme with regional consistency loss and\ninter-slice continuity loss. NS-N2N only requires a single noisy image volume\nobtained from one medical imaging procedure to achieve high-quality denoising\nof the image volume itself. Extensive experiments demonstrate that the proposed\nmethod outperforms state-of-the-art self-supervised denoising methods in both\ndenoising performance and processing efficiency. Furthermore, since NS-N2N\noperates solely in the image domain, it is free from device-specific issues\nsuch as reconstruction geometry, making it easier to apply in various clinical\npractices.\n","authors":["Langrui Zhou","Ziteng Zhou","Xinyu Huang","Huiru Wang","Xiangyu Zhang","Guang Li"],"pdf_url":"https://arxiv.org/pdf/2411.10831v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.05162v1","updated":"2025-03-07T06:01:07Z","published":"2025-03-07T06:01:07Z","title":"EvolvingGS: High-Fidelity Streamable Volumetric Video via Evolving 3D\n  Gaussian Representation","summary":"  We have recently seen great progress in 3D scene reconstruction through\nexplicit point-based 3D Gaussian Splatting (3DGS), notable for its high quality\nand fast rendering speed. However, reconstructing dynamic scenes such as\ncomplex human performances with long durations remains challenging. Prior\nefforts fall short of modeling a long-term sequence with drastic motions,\nfrequent topology changes or interactions with props, and resort to segmenting\nthe whole sequence into groups of frames that are processed independently,\nwhich undermines temporal stability and thereby leads to an unpleasant viewing\nexperience and inefficient storage footprint. In view of this, we introduce\nEvolvingGS, a two-stage strategy that first deforms the Gaussian model to\ncoarsely align with the target frame, and then refines it with minimal point\naddition/subtraction, particularly in fast-changing areas. Owing to the\nflexibility of the incrementally evolving representation, our method\noutperforms existing approaches in terms of both per-frame and temporal quality\nmetrics while maintaining fast rendering through its purely explicit\nrepresentation. Moreover, by exploiting temporal coherence between successive\nframes, we propose a simple yet effective compression algorithm that achieves\nover 50x compression rate. Extensive experiments on both public benchmarks and\nchallenging custom datasets demonstrate that our method significantly advances\nthe state-of-the-art in dynamic scene reconstruction, particularly for extended\nsequences with complex human performances.\n","authors":["Chao Zhang","Yifeng Zhou","Shuheng Wang","Wenfa Li","Degang Wang","Yi Xu","Shaohui Jiao"],"pdf_url":"https://arxiv.org/pdf/2503.05162v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.05161v1","updated":"2025-03-07T05:55:50Z","published":"2025-03-07T05:55:50Z","title":"GaussianCAD: Robust Self-Supervised CAD Reconstruction from Three\n  Orthographic Views Using 3D Gaussian Splatting","summary":"  The automatic reconstruction of 3D computer-aided design (CAD) models from\nCAD sketches has recently gained significant attention in the computer vision\ncommunity. Most existing methods, however, rely on vector CAD sketches and 3D\nground truth for supervision, which are often difficult to be obtained in\nindustrial applications and are sensitive to noise inputs. We propose viewing\nCAD reconstruction as a specific instance of sparse-view 3D reconstruction to\novercome these limitations. While this reformulation offers a promising\nperspective, existing 3D reconstruction methods typically require natural\nimages and corresponding camera poses as inputs, which introduces two major\nsignificant challenges: (1) modality discrepancy between CAD sketches and\nnatural images, and (2) difficulty of accurate camera pose estimation for CAD\nsketches. To solve these issues, we first transform the CAD sketches into\nrepresentations resembling natural images and extract corresponding masks.\nNext, we manually calculate the camera poses for the orthographic views to\nensure accurate alignment within the 3D coordinate system. Finally, we employ a\ncustomized sparse-view 3D reconstruction method to achieve high-quality\nreconstructions from aligned orthographic views. By leveraging raster CAD\nsketches for self-supervision, our approach eliminates the reliance on vector\nCAD sketches and 3D ground truth. Experiments on the Sub-Fusion360 dataset\ndemonstrate that our proposed method significantly outperforms previous\napproaches in CAD reconstruction performance and exhibits strong robustness to\nnoisy inputs.\n","authors":["Zheng Zhou","Zhe Li","Bo Yu","Lina Hu","Liang Dong","Zijian Yang","Xiaoli Liu","Ning Xu","Ziwei Wang","Yonghao Dang","Jianqin Yin"],"pdf_url":"https://arxiv.org/pdf/2503.05161v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2412.11542v3","updated":"2025-03-07T05:49:35Z","published":"2024-12-16T08:22:23Z","title":"Meta Curvature-Aware Minimization for Domain Generalization","summary":"  Domain generalization (DG) aims to enhance the ability of models trained on\nsource domains to generalize effectively to unseen domains. Recently,\nSharpness-Aware Minimization (SAM) has shown promise in this area by reducing\nthe sharpness of the loss landscape to obtain more generalized models. However,\nSAM and its variants sometimes fail to guide the model toward a flat minimum,\nand their training processes exhibit limitations, hindering further\nimprovements in model generalization. In this paper, we first propose an\nimproved model training process aimed at encouraging the model to converge to a\nflat minima. To achieve this, we design a curvature metric that has a minimal\neffect when the model is far from convergence but becomes increasingly\ninfluential in indicating the curvature of the minima as the model approaches a\nlocal minimum. Then we derive a novel algorithm from this metric, called Meta\nCurvature-Aware Minimization (MeCAM), to minimize the curvature around the\nlocal minima. Specifically, the optimization objective of MeCAM simultaneously\nminimizes the regular training loss, the surrogate gap of SAM, and the\nsurrogate gap of meta-learning. We provide theoretical analysis on MeCAM's\ngeneralization error and convergence rate, and demonstrate its superiority over\nexisting DG methods through extensive experiments on five benchmark DG\ndatasets, including PACS, VLCS, OfficeHome, TerraIncognita, and DomainNet. Code\nwill be available on GitHub.\n","authors":["Ziyang Chen","Yiwen Ye","Feilong Tang","Yongsheng Pan","Yong Xia"],"pdf_url":"https://arxiv.org/pdf/2412.11542v3.pdf","comment":"22 pages, 5 figures, 16 tables"},{"id":"http://arxiv.org/abs/2503.05156v1","updated":"2025-03-07T05:31:47Z","published":"2025-03-07T05:31:47Z","title":"Accelerating Diffusion Transformer via Gradient-Optimized Cache","summary":"  Feature caching has emerged as an effective strategy to accelerate diffusion\ntransformer (DiT) sampling through temporal feature reuse. It is a challenging\nproblem since (1) Progressive error accumulation from cached blocks\nsignificantly degrades generation quality, particularly when over 50\\% of\nblocks are cached; (2) Current error compensation approaches neglect dynamic\nperturbation patterns during the caching process, leading to suboptimal error\ncorrection. To solve these problems, we propose the Gradient-Optimized Cache\n(GOC) with two key innovations: (1) Cached Gradient Propagation: A gradient\nqueue dynamically computes the gradient differences between cached and\nrecomputed features. These gradients are weighted and propagated to subsequent\nsteps, directly compensating for the approximation errors introduced by\ncaching. (2) Inflection-Aware Optimization: Through statistical analysis of\nfeature variation patterns, we identify critical inflection points where the\ndenoising trajectory changes direction. By aligning gradient updates with these\ndetected phases, we prevent conflicting gradient directions during error\ncorrection. Extensive evaluations on ImageNet demonstrate GOC's superior\ntrade-off between efficiency and quality. With 50\\% cached blocks, GOC achieves\nIS 216.28 (26.3\\% higher) and FID 3.907 (43\\% lower) compared to baseline DiT,\nwhile maintaining identical computational costs. These improvements persist\nacross various cache ratios, demonstrating robust adaptability to different\nacceleration requirements.\n","authors":["Junxiang Qiu","Lin Liu","Shuo Wang","Jinda Lu","Kezhou Chen","Yanbin Hao"],"pdf_url":"https://arxiv.org/pdf/2503.05156v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.05149v1","updated":"2025-03-07T05:18:00Z","published":"2025-03-07T05:18:00Z","title":"Development and Enhancement of Text-to-Image Diffusion Models","summary":"  This research focuses on the development and enhancement of text-to-image\ndenoising diffusion models, addressing key challenges such as limited sample\ndiversity and training instability. By incorporating Classifier-Free Guidance\n(CFG) and Exponential Moving Average (EMA) techniques, this study significantly\nimproves image quality, diversity, and stability. Utilizing Hugging Face's\nstate-of-the-art text-to-image generation model, the proposed enhancements\nestablish new benchmarks in generative AI. This work explores the underlying\nprinciples of diffusion models, implements advanced strategies to overcome\nexisting limitations, and presents a comprehensive evaluation of the\nimprovements achieved. Results demonstrate substantial progress in generating\nstable, diverse, and high-quality images from textual descriptions, advancing\nthe field of generative artificial intelligence and providing new foundations\nfor future applications.\n  Keywords: Text-to-image, Diffusion model, Classifier-free guidance,\nExponential moving average, Image generation.\n","authors":["Rajdeep Roshan Sahu"],"pdf_url":"https://arxiv.org/pdf/2503.05149v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2404.10220v2","updated":"2025-03-07T05:09:28Z","published":"2024-04-16T02:01:56Z","title":"Closed-Loop Open-Vocabulary Mobile Manipulation with GPT-4V","summary":"  Autonomous robot navigation and manipulation in open environments require\nreasoning and replanning with closed-loop feedback. In this work, we present\nCOME-robot, the first closed-loop robotic system utilizing the GPT-4V\nvision-language foundation model for open-ended reasoning and adaptive planning\nin real-world scenarios.COME-robot incorporates two key innovative modules: (i)\na multi-level open-vocabulary perception and situated reasoning module that\nenables effective exploration of the 3D environment and target object\nidentification using commonsense knowledge and situated information, and (ii)\nan iterative closed-loop feedback and restoration mechanism that verifies task\nfeasibility, monitors execution success, and traces failure causes across\ndifferent modules for robust failure recovery. Through comprehensive\nexperiments involving 8 challenging real-world mobile and tabletop manipulation\ntasks, COME-robot demonstrates a significant improvement in task success rate\n(~35%) compared to state-of-the-art methods. We further conduct comprehensive\nanalyses to elucidate how COME-robot's design facilitates failure recovery,\nfree-form instruction following, and long-horizon task planning.\n","authors":["Peiyuan Zhi","Zhiyuan Zhang","Yu Zhao","Muzhi Han","Zeyu Zhang","Zhitian Li","Ziyuan Jiao","Baoxiong Jia","Siyuan Huang"],"pdf_url":"https://arxiv.org/pdf/2404.10220v2.pdf","comment":"6 pages, Accepted at 2025 IEEE ICRA, website:\n  https://come-robot.github.io/"},{"id":"http://arxiv.org/abs/2501.09898v3","updated":"2025-03-07T04:45:23Z","published":"2025-01-17T01:01:44Z","title":"FoundationStereo: Zero-Shot Stereo Matching","summary":"  Tremendous progress has been made in deep stereo matching to excel on\nbenchmark datasets through per-domain fine-tuning. However, achieving strong\nzero-shot generalization - a hallmark of foundation models in other computer\nvision tasks - remains challenging for stereo matching. We introduce\nFoundationStereo, a foundation model for stereo depth estimation designed to\nachieve strong zero-shot generalization. To this end, we first construct a\nlarge-scale (1M stereo pairs) synthetic training dataset featuring large\ndiversity and high photorealism, followed by an automatic self-curation\npipeline to remove ambiguous samples. We then design a number of network\narchitecture components to enhance scalability, including a side-tuning feature\nbackbone that adapts rich monocular priors from vision foundation models to\nmitigate the sim-to-real gap, and long-range context reasoning for effective\ncost volume filtering. Together, these components lead to strong robustness and\naccuracy across domains, establishing a new standard in zero-shot stereo depth\nestimation. Project page: https://nvlabs.github.io/FoundationStereo/\n","authors":["Bowen Wen","Matthew Trepte","Joseph Aribido","Jan Kautz","Orazio Gallo","Stan Birchfield"],"pdf_url":"https://arxiv.org/pdf/2501.09898v3.pdf","comment":"CVPR 2025"},{"id":"http://arxiv.org/abs/2503.05132v1","updated":"2025-03-07T04:21:47Z","published":"2025-03-07T04:21:47Z","title":"R1-Zero's \"Aha Moment\" in Visual Reasoning on a 2B Non-SFT Model","summary":"  Recently DeepSeek R1 demonstrated how reinforcement learning with simple\nrule-based incentives can enable autonomous development of complex reasoning in\nlarge language models, characterized by the \"aha moment\", in which the model\nmanifest self-reflection and increased response length during training.\nHowever, attempts to extend this success to multimodal reasoning often failed\nto reproduce these key characteristics. In this report, we present the first\nsuccessful replication of these emergent characteristics for multimodal\nreasoning on only a non-SFT 2B model. Starting with Qwen2-VL-2B and applying\nreinforcement learning directly on the SAT dataset, our model achieves 59.47%\naccuracy on CVBench, outperforming the base model by approximately ~30% and\nexceeding both SFT setting by ~2%. In addition, we share our failed attempts\nand insights in attempting to achieve R1-like reasoning using RL with instruct\nmodels. aiming to shed light on the challenges involved. Our key observations\ninclude: (1) applying RL on instruct model often results in trivial reasoning\ntrajectories, and (2) naive length reward are ineffective in eliciting\nreasoning capabilities. The project code is available at\nhttps://github.com/turningpoint-ai/VisualThinker-R1-Zero\n","authors":["Hengguang Zhou","Xirui Li","Ruochen Wang","Minhao Cheng","Tianyi Zhou","Cho-Jui Hsieh"],"pdf_url":"https://arxiv.org/pdf/2503.05132v1.pdf","comment":"10 pages, 6 figures"},{"id":"http://arxiv.org/abs/2503.05127v1","updated":"2025-03-07T04:18:55Z","published":"2025-03-07T04:18:55Z","title":"HexPlane Representation for 3D Semantic Scene Understanding","summary":"  In this paper, we introduce the HexPlane representation for 3D semantic scene\nunderstanding. Specifically, we first design the View Projection Module (VPM)\nto project the 3D point cloud into six planes to maximally retain the original\nspatial information. Features of six planes are extracted by the 2D encoder and\nsent to the HexPlane Association Module (HAM) to adaptively fuse the most\ninformative information for each point. The fused point features are further\nfed to the task head to yield the ultimate predictions. Compared to the popular\npoint and voxel representation, the HexPlane representation is efficient and\ncan utilize highly optimized 2D operations to process sparse and unordered 3D\npoint clouds. It can also leverage off-the-shelf 2D models, network weights,\nand training recipes to achieve accurate scene understanding in 3D space. On\nScanNet and SemanticKITTI benchmarks, our algorithm, dubbed HexNet3D, achieves\ncompetitive performance with previous algorithms. In particular, on the ScanNet\n3D segmentation task, our method obtains 77.0 mIoU on the validation set,\nsurpassing Point Transformer V2 by 1.6 mIoU. We also observe encouraging\nresults in indoor 3D detection tasks. Note that our method can be seamlessly\nintegrated into existing voxel-based, point-based, and range-based approaches\nand brings considerable gains without bells and whistles. The codes will be\navailable upon publication.\n","authors":["Zeren Chen","Yuenan Hou","Yulin Chen","Li Liu","Xiao Sun","Lu Sheng"],"pdf_url":"https://arxiv.org/pdf/2503.05127v1.pdf","comment":"7 pages, 2 figures"},{"id":"http://arxiv.org/abs/2503.05122v1","updated":"2025-03-07T03:47:30Z","published":"2025-03-07T03:47:30Z","title":"EDM: Efficient Deep Feature Matching","summary":"  Recent feature matching methods have achieved remarkable performance but lack\nefficiency consideration. In this paper, we revisit the mainstream\ndetector-free matching pipeline and improve all its stages considering both\naccuracy and efficiency. We propose an Efficient Deep feature Matching network,\nEDM. We first adopt a deeper CNN with fewer dimensions to extract multi-level\nfeatures. Then we present a Correlation Injection Module that conducts feature\ntransformation on high-level deep features, and progressively injects feature\ncorrelations from global to local for efficient multi-scale feature\naggregation, improving both speed and performance. In the refinement stage, a\nnovel lightweight bidirectional axis-based regression head is designed to\ndirectly predict subpixel-level correspondences from latent features, avoiding\nthe significant computational cost of explicitly locating keypoints on\nhigh-resolution local feature heatmaps. Moreover, effective selection\nstrategies are introduced to enhance matching accuracy. Extensive experiments\nshow that our EDM achieves competitive matching accuracy on various benchmarks\nand exhibits excellent efficiency, offering valuable best practices for\nreal-world applications. The code is available at\nhttps://github.com/chicleee/EDM.\n","authors":["Xi Li","Tong Rao","Cihui Pan"],"pdf_url":"https://arxiv.org/pdf/2503.05122v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2408.01167v5","updated":"2025-03-07T03:46:48Z","published":"2024-08-02T10:34:23Z","title":"Rethinking Pre-Trained Feature Extractor Selection in Multiple Instance\n  Learning for Whole Slide Image Classification","summary":"  Multiple instance learning (MIL) has become a preferred method for gigapixel\nwhole slide image (WSI) classification without requiring patch-level\nannotations. Current MIL research primarily relies on embedding-based\napproaches, which extract patch features using a pre-trained feature extractor\nand aggregate them for slide-level prediction. Despite the critical role of\nfeature extraction, there is limited guidance on selecting optimal feature\nextractors to maximize WSI performance. This study addresses this gap by\nsystematically evaluating MIL feature extractors across three dimensions:\npre-training dataset, backbone model, and pre-training method. Extensive\nexperiments were conducted on two public WSI datasets (TCGA-NSCLC and\nCamelyon16) using four state-of-the-art (SOTA) MIL models. Our findings reveal\nthat: 1) selecting a robust self-supervised learning (SSL) method has a greater\nimpact on performance than relying solely on an in-domain pre-training dataset;\n2) prioritizing Transformer-based backbones with deeper architectures over\nCNN-based models; and 3) using larger, more diverse pre-training datasets\nsignificantly enhances classification outcomes. We hope that these insights can\nprovide practical guidance for optimizing WSI classification and explain the\nreasons behind the performance advantages of the current SOTA pathology\nfoundation models. Furthermore, this work may inform the development of more\neffective pathology foundation models. Our code is publicly available at\nhttps://github.com/bryanwong17/MIL-Feature-Extractor-Selection\n","authors":["Bryan Wong","Sungrae Hong","Mun Yong Yi"],"pdf_url":"https://arxiv.org/pdf/2408.01167v5.pdf","comment":"Accepted to IEEE International Symposium on Biomedical Imaging (ISBI)\n  2025"},{"id":"http://arxiv.org/abs/2411.15811v3","updated":"2025-03-07T03:39:49Z","published":"2024-11-24T12:34:02Z","title":"FastTrackTr:Towards Fast Multi-Object Tracking with Transformers","summary":"  Transformer-based multi-object tracking (MOT) methods have captured the\nattention of many researchers in recent years. However, these models often\nsuffer from slow inference speeds due to their structure or other issues. To\naddress this problem, we revisited the Joint Detection and Tracking (JDT)\nmethod by looking back at past approaches. By integrating the original JDT\napproach with some advanced theories, this paper employs an efficient method of\ninformation transfer between frames on the DETR, constructing a fast and novel\nJDT-type MOT framework: FastTrackTr. Thanks to the superiority of this\ninformation transfer method, our approach not only reduces the number of\nqueries required during tracking but also avoids the excessive introduction of\nnetwork structures, ensuring model simplicity. Experimental results indicate\nthat our method has the potential to achieve real-time tracking and exhibits\ncompetitive tracking accuracy across multiple datasets.\n","authors":["Pan Liao","Feng Yang","Di Wu","Jinwen Yu","Wenhui Zhao","Bo Liu"],"pdf_url":"https://arxiv.org/pdf/2411.15811v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.05118v1","updated":"2025-03-07T03:31:47Z","published":"2025-03-07T03:31:47Z","title":"SMILENet: Unleashing Extra-Large Capacity Image Steganography via a\n  Synergistic Mosaic InvertibLE Hiding Network","summary":"  Existing image steganography methods face fundamental limitations in hiding\ncapacity (typically $1\\sim7$ images) due to severe information interference and\nuncoordinated capacity-distortion trade-off. We propose SMILENet, a novel\nsynergistic framework that achieves 25 image hiding through three key\ninnovations: (i) A synergistic network architecture coordinates reversible and\nnon-reversible operations to efficiently exploit information redundancy in both\nsecret and cover images. The reversible Invertible Cover-Driven Mosaic (ICDM)\nmodule and Invertible Mosaic Secret Embedding (IMSE) module establish\ncover-guided mosaic transformations and representation embedding with\nmathematically guaranteed invertibility for distortion-free embedding. The\nnon-reversible Secret Information Selection (SIS) module and Secret Detail\nEnhancement (SDE) module implement learnable feature modulation for critical\ninformation selection and enhancement. (ii) A unified training strategy that\ncoordinates complementary modules to achieve 3.0x higher capacity than existing\nmethods with superior visual quality. (iii) Last but not least, we introduce a\nnew metric to model Capacity-Distortion Trade-off for evaluating the image\nsteganography algorithms that jointly considers hiding capacity and distortion,\nand provides a unified evaluation approach for accessing results with different\nnumber of secret image. Extensive experiments on DIV2K, Paris StreetView and\nImageNet1K show that SMILENet outperforms state-of-the-art methods in terms of\nhiding capacity, recovery quality as well as security against steganalysis\nmethods.\n","authors":["Jun-Jie Huang","Zihan Chen","Tianrui Liu","Wentao Zhao","Xin Deng","Xinwang Liu","Meng Wang","Pier Luigi Dragotti"],"pdf_url":"https://arxiv.org/pdf/2503.05118v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2412.18335v2","updated":"2025-03-07T03:11:27Z","published":"2024-12-24T10:42:25Z","title":"FloNa: Floor Plan Guided Embodied Visual Navigation","summary":"  Humans naturally rely on floor plans to navigate in unfamiliar environments,\nas they are readily available, reliable, and provide rich geometrical guidance.\nHowever, existing visual navigation settings overlook this valuable prior\nknowledge, leading to limited efficiency and accuracy. To eliminate this gap,\nwe introduce a novel navigation task: Floor Plan Visual Navigation (FloNa), the\nfirst attempt to incorporate floor plan into embodied visual navigation. While\nthe floor plan offers significant advantages, two key challenges emerge: (1)\nhandling the spatial inconsistency between the floor plan and the actual scene\nlayout for collision-free navigation, and (2) aligning observed images with the\nfloor plan sketch despite their distinct modalities. To address these\nchallenges, we propose FloDiff, a novel diffusion policy framework\nincorporating a localization module to facilitate alignment between the current\nobservation and the floor plan. We further collect $20k$ navigation episodes\nacross $117$ scenes in the iGibson simulator to support the training and\nevaluation. Extensive experiments demonstrate the effectiveness and efficiency\nof our framework in unfamiliar scenes using floor plan knowledge. Project\nwebsite: https://gauleejx.github.io/flona/.\n","authors":["Jiaxin Li","Weiqi Huang","Zan Wang","Wei Liang","Huijun Di","Feng Liu"],"pdf_url":"https://arxiv.org/pdf/2412.18335v2.pdf","comment":"Accepted by AAAI 2025"},{"id":"http://arxiv.org/abs/2409.19527v2","updated":"2025-03-07T03:06:50Z","published":"2024-09-29T03:00:16Z","title":"BuildingView: Constructing Urban Building Exteriors Databases with\n  Street View Imagery and Multimodal Large Language Mode","summary":"  Urban Building Exteriors are increasingly important in urban analytics,\ndriven by advancements in Street View Imagery and its integration with urban\nresearch. Multimodal Large Language Models (LLMs) offer powerful tools for\nurban annotation, enabling deeper insights into urban environments. However,\nchallenges remain in creating accurate and detailed urban building exterior\ndatabases, identifying critical indicators for energy efficiency, environmental\nsustainability, and human-centric design, and systematically organizing these\nindicators. To address these challenges, we propose BuildingView, a novel\napproach that integrates high-resolution visual data from Google Street View\nwith spatial information from OpenStreetMap via the Overpass API. This research\nimproves the accuracy of urban building exterior data, identifies key\nsustainability and design indicators, and develops a framework for their\nextraction and categorization. Our methodology includes a systematic literature\nreview, building and Street View sampling, and annotation using the ChatGPT-4O\nAPI. The resulting database, validated with data from New York City, Amsterdam,\nand Singapore, provides a comprehensive tool for urban studies, supporting\ninformed decision-making in urban planning, architectural design, and\nenvironmental policy. The code for BuildingView is available at\nhttps://github.com/Jasper0122/BuildingView.\n","authors":["Zongrong Li","Yunlei Su","Hongrong Wang","Wufan Zhao"],"pdf_url":"https://arxiv.org/pdf/2409.19527v2.pdf","comment":"15 pages, 6 figures"},{"id":"http://arxiv.org/abs/2502.20577v3","updated":"2025-03-07T03:06:40Z","published":"2025-02-27T22:37:09Z","title":"InstaFace: Identity-Preserving Facial Editing with Single Image\n  Inference","summary":"  Facial appearance editing is crucial for digital avatars, AR/VR, and\npersonalized content creation, driving realistic user experiences. However,\npreserving identity with generative models is challenging, especially in\nscenarios with limited data availability. Traditional methods often require\nmultiple images and still struggle with unnatural face shifts, inconsistent\nhair alignment, or excessive smoothing effects. To overcome these challenges,\nwe introduce a novel diffusion-based framework, InstaFace, to generate\nrealistic images while preserving identity using only a single image. Central\nto InstaFace, we introduce an efficient guidance network that harnesses 3D\nperspectives by integrating multiple 3DMM-based conditionals without\nintroducing additional trainable parameters. Moreover, to ensure maximum\nidentity retention as well as preservation of background, hair, and other\ncontextual features like accessories, we introduce a novel module that utilizes\nfeature embeddings from a facial recognition model and a pre-trained\nvision-language model. Quantitative evaluations demonstrate that our method\noutperforms several state-of-the-art approaches in terms of identity\npreservation, photorealism, and effective control of pose, expression, and\nlighting.\n","authors":["MD Wahiduzzaman Khan","Mingshan Jia","Xiaolin Zhang","En Yu","Caifeng Shan","Kaska Musial-Gabrys"],"pdf_url":"https://arxiv.org/pdf/2502.20577v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.05107v1","updated":"2025-03-07T03:06:03Z","published":"2025-03-07T03:06:03Z","title":"We Care Each Pixel: Calibrating on Medical Segmentation Model","summary":"  Medical image segmentation is fundamental for computer-aided diagnostics,\nproviding accurate delineation of anatomical structures and pathological\nregions. While common metrics such as Accuracy, DSC, IoU, and HD primarily\nquantify spatial agreement between predictions and ground-truth labels, they do\nnot assess the calibration quality of segmentation models, which is crucial for\nclinical reliability. To address this limitation, we propose pixel-wise\nExpected Calibration Error (pECE), a novel metric that explicitly measures\nmiscalibration at the pixel level, thereby ensuring both spatial precision and\nconfidence reliability. We further introduce a morphological adaptation\nstrategy that applies morphological operations to ground-truth masks before\ncomputing calibration losses, particularly benefiting margin-based losses such\nas Margin SVLS and NACL. Additionally, we present the Signed Distance\nCalibration Loss (SDC), which aligns boundary geometry with calibration\nobjectives by penalizing discrepancies between predicted and ground-truth\nsigned distance functions (SDFs). Extensive experiments demonstrate that our\nmethod not only enhances segmentation performance but also improves calibration\nquality, yielding more trustworthy confidence estimates. Code is available at:\nhttps://github.com/EagleAdelaide/SDC-Loss.\n","authors":["Wenhao Liang","Wei Zhang","Yue Lin","Miao Xu","Olaf Maennel","Weitong Chen"],"pdf_url":"https://arxiv.org/pdf/2503.05107v1.pdf","comment":"Under Reviewing"},{"id":"http://arxiv.org/abs/2204.08027v3","updated":"2025-03-07T02:28:52Z","published":"2022-04-17T15:04:44Z","title":"Attention Mechanism based Cognition-level Scene Understanding","summary":"  Given a question-image input, the Visual Commonsense Reasoning (VCR) model\ncan predict an answer with the corresponding rationale, which requires\ninference ability from the real world. The VCR task, which calls for exploiting\nthe multi-source information as well as learning different levels of\nunderstanding and extensive commonsense knowledge, is a cognition-level scene\nunderstanding task. The VCR task has aroused researchers' interest due to its\nwide range of applications, including visual question answering, automated\nvehicle systems, and clinical decision support. Previous approaches to solving\nthe VCR task generally rely on pre-training or exploiting memory with long\ndependency relationship encoded models. However, these approaches suffer from a\nlack of generalizability and losing information in long sequences. In this\npaper, we propose a parallel attention-based cognitive VCR network PAVCR, which\nfuses visual-textual information efficiently and encodes semantic information\nin parallel to enable the model to capture rich information for cognition-level\ninference. Extensive experiments show that the proposed model yields\nsignificant improvements over existing methods on the benchmark VCR dataset.\nMoreover, the proposed model provides intuitive interpretation into visual\ncommonsense reasoning.\n","authors":["Xuejiao Tang","Wenbin Zhang"],"pdf_url":"https://arxiv.org/pdf/2204.08027v3.pdf","comment":"Published in Information"},{"id":"http://arxiv.org/abs/2503.05093v1","updated":"2025-03-07T02:25:16Z","published":"2025-03-07T02:25:16Z","title":"Visual Cues of Gender and Race are Associated with Stereotyping in\n  Vision-Language Models","summary":"  Current research on bias in Vision Language Models (VLMs) has important\nlimitations: it is focused exclusively on trait associations while ignoring\nother forms of stereotyping, it examines specific contexts where biases are\nexpected to appear, and it conceptualizes social categories like race and\ngender as binary, ignoring the multifaceted nature of these identities. Using\nstandardized facial images that vary in prototypicality, we test four VLMs for\nboth trait associations and homogeneity bias in open-ended contexts. We find\nthat VLMs consistently generate more uniform stories for women compared to men,\nwith people who are more gender prototypical in appearance being represented\nmore uniformly. By contrast, VLMs represent White Americans more uniformly than\nBlack Americans. Unlike with gender prototypicality, race prototypicality was\nnot related to stronger uniformity. In terms of trait associations, we find\nlimited evidence of stereotyping-Black Americans were consistently linked with\nbasketball across all models, while other racial associations (i.e., art,\nhealthcare, appearance) varied by specific VLM. These findings demonstrate that\nVLM stereotyping manifests in ways that go beyond simple group membership,\nsuggesting that conventional bias mitigation strategies may be insufficient to\naddress VLM stereotyping and that homogeneity bias persists even when trait\nassociations are less apparent in model outputs.\n","authors":["Messi H. J. Lee","Soyeon Jeon","Jacob M. Montgomery","Calvin K. Lai"],"pdf_url":"https://arxiv.org/pdf/2503.05093v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.05086v1","updated":"2025-03-07T02:09:38Z","published":"2025-03-07T02:09:38Z","title":"Fake It To Make It: Virtual Multiviews to Enhance Monocular Indoor\n  Semantic Scene Completion","summary":"  Monocular Indoor Semantic Scene Completion (SSC) aims to reconstruct a 3D\nsemantic occupancy map from a single RGB image of an indoor scene, inferring\nspatial layout and object categories from 2D image cues. The challenge of this\ntask arises from the depth, scale, and shape ambiguities that emerge when\ntransforming a 2D image into 3D space, particularly within the complex and\noften heavily occluded environments of indoor scenes. Current SSC methods often\nstruggle with these ambiguities, resulting in distorted or missing object\nrepresentations. To overcome these limitations, we introduce an innovative\napproach that leverages novel view synthesis and multiview fusion.\nSpecifically, we demonstrate how virtual cameras can be placed around the scene\nto emulate multiview inputs that enhance contextual scene information. We also\nintroduce a Multiview Fusion Adaptor (MVFA) to effectively combine the\nmultiview 3D scene predictions into a unified 3D semantic occupancy map.\nFinally, we identify and study the inherent limitation of generative techniques\nwhen applied to SSC, specifically the Novelty-Consistency tradeoff. Our system,\nGenFuSE, demonstrates IoU score improvements of up to 2.8% for Scene Completion\nand 4.9% for Semantic Scene Completion when integrated with existing SSC\nnetworks on the NYUv2 dataset. This work introduces GenFuSE as a standard\nframework for advancing monocular SSC with synthesized inputs.\n","authors":["Anith Selvakumar","Manasa Bharadwaj"],"pdf_url":"https://arxiv.org/pdf/2503.05086v1.pdf","comment":"Submitted to IROS 2025"},{"id":"http://arxiv.org/abs/2503.05082v1","updated":"2025-03-07T01:59:05Z","published":"2025-03-07T01:59:05Z","title":"Taming Video Diffusion Prior with Scene-Grounding Guidance for 3D\n  Gaussian Splatting from Sparse Inputs","summary":"  Despite recent successes in novel view synthesis using 3D Gaussian Splatting\n(3DGS), modeling scenes with sparse inputs remains a challenge. In this work,\nwe address two critical yet overlooked issues in real-world sparse-input\nmodeling: extrapolation and occlusion. To tackle these issues, we propose to\nuse a reconstruction by generation pipeline that leverages learned priors from\nvideo diffusion models to provide plausible interpretations for regions outside\nthe field of view or occluded. However, the generated sequences exhibit\ninconsistencies that do not fully benefit subsequent 3DGS modeling. To address\nthe challenge of inconsistencies, we introduce a novel scene-grounding guidance\nbased on rendered sequences from an optimized 3DGS, which tames the diffusion\nmodel to generate consistent sequences. This guidance is training-free and does\nnot require any fine-tuning of the diffusion model. To facilitate holistic\nscene modeling, we also propose a trajectory initialization method. It\neffectively identifies regions that are outside the field of view and occluded.\nWe further design a scheme tailored for 3DGS optimization with generated\nsequences. Experiments demonstrate that our method significantly improves upon\nthe baseline and achieves state-of-the-art performance on challenging\nbenchmarks.\n","authors":["Yingji Zhong","Zhihao Li","Dave Zhenyu Chen","Lanqing Hong","Dan Xu"],"pdf_url":"https://arxiv.org/pdf/2503.05082v1.pdf","comment":"Accepted by CVPR2025. The project page is available at\n  https://zhongyingji.github.io/guidevd-3dgs/"},{"id":"http://arxiv.org/abs/2410.00064v3","updated":"2025-03-07T01:29:54Z","published":"2024-09-30T01:43:06Z","title":"M2Distill: Multi-Modal Distillation for Lifelong Imitation Learning","summary":"  Lifelong imitation learning for manipulation tasks poses significant\nchallenges due to distribution shifts that occur in incremental learning steps.\nExisting methods often focus on unsupervised skill discovery to construct an\never-growing skill library or distillation from multiple policies, which can\nlead to scalability issues as diverse manipulation tasks are continually\nintroduced and may fail to ensure a consistent latent space throughout the\nlearning process, leading to catastrophic forgetting of previously learned\nskills. In this paper, we introduce M2Distill, a multi-modal distillation-based\nmethod for lifelong imitation learning focusing on preserving consistent latent\nspace across vision, language, and action distributions throughout the learning\nprocess. By regulating the shifts in latent representations across different\nmodalities from previous to current steps, and reducing discrepancies in\nGaussian Mixture Model (GMM) policies between consecutive learning steps, we\nensure that the learned policy retains its ability to perform previously\nlearned tasks while seamlessly integrating new skills. Extensive evaluations on\nthe LIBERO lifelong imitation learning benchmark suites, including\nLIBERO-OBJECT, LIBERO-GOAL, and LIBERO-SPATIAL, demonstrate that our method\nconsistently outperforms prior state-of-the-art methods across all evaluated\nmetrics.\n","authors":["Kaushik Roy","Akila Dissanayake","Brendan Tidd","Peyman Moghadam"],"pdf_url":"https://arxiv.org/pdf/2410.00064v3.pdf","comment":"IEEE ICRA 2025"},{"id":"http://arxiv.org/abs/2503.00371v2","updated":"2025-03-07T01:20:01Z","published":"2025-03-01T06:56:58Z","title":"Jointly Understand Your Command and Intention:Reciprocal Co-Evolution\n  between Scene-Aware 3D Human Motion Synthesis and Analysis","summary":"  As two intimate reciprocal tasks, scene-aware human motion synthesis and\nanalysis require a joint understanding between multiple modalities, including\n3D body motions, 3D scenes, and textual descriptions. In this paper, we\nintegrate these two paired processes into a Co-Evolving Synthesis-Analysis\n(CESA) pipeline and mutually benefit their learning. Specifically, scene-aware\ntext-to-human synthesis generates diverse indoor motion samples from the same\ntextual description to enrich human-scene interaction intra-class diversity,\nthus significantly benefiting training a robust human motion analysis system.\nReciprocally, human motion analysis would enforce semantic scrutiny on each\nsynthesized motion sample to ensure its semantic consistency with the given\ntextual description, thus improving realistic motion synthesis. Considering\nthat real-world indoor human motions are goal-oriented and path-guided, we\npropose a cascaded generation strategy that factorizes text-driven\nscene-specific human motion generation into three stages: goal inferring, path\nplanning, and pose synthesizing. Coupling CESA with this powerful cascaded\nmotion synthesis model, we jointly improve realistic human motion synthesis and\nrobust human motion analysis in 3D scenes.\n","authors":["Xuehao Gao","Yang Yang","Shaoyi Du","Guo-Jun Qi","Junwei Han"],"pdf_url":"https://arxiv.org/pdf/2503.00371v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2405.10948v2","updated":"2025-03-07T01:02:22Z","published":"2024-03-22T08:38:27Z","title":"Surgical-LVLM: Learning to Adapt Large Vision-Language Model for\n  Grounded Visual Question Answering in Robotic Surgery","summary":"  Recent advancements in Surgical Visual Question Answering (Surgical-VQA) and\nrelated region grounding have shown great promise for robotic and medical\napplications, addressing the critical need for automated methods in\npersonalized surgical mentorship. However, existing models primarily provide\nsimple structured answers and struggle with complex scenarios due to their\nlimited capability in recognizing long-range dependencies and aligning\nmultimodal information. In this paper, we introduce Surgical-LVLM, a novel\npersonalized large vision-language model tailored for complex surgical\nscenarios. Leveraging the pre-trained large vision-language model and\nspecialized Visual Perception LoRA (VP-LoRA) blocks, our model excels in\nunderstanding complex visual-language tasks within surgical contexts. In\naddressing the visual grounding task, we propose the Token-Interaction (TIT)\nmodule, which strengthens the interaction between the grounding module and the\nlanguage responses of the Large Visual Language Model (LVLM) after projecting\nthem into the latent space. We demonstrate the effectiveness of Surgical-LVLM\non several benchmarks, including EndoVis-17-VQLA, EndoVis-18-VQLA, and a newly\nintroduced EndoVis Conversations dataset, which sets new performance standards.\nOur work contributes to advancing the field of automated surgical mentorship by\nproviding a context-aware solution.\n","authors":["Guankun Wang","Long Bai","Wan Jun Nah","Jie Wang","Zhaoxi Zhang","Zhen Chen","Jinlin Wu","Mobarakol Islam","Hongbin Liu","Hongliang Ren"],"pdf_url":"https://arxiv.org/pdf/2405.10948v2.pdf","comment":"The manuscript is accepted by ICLR 2025 FM-Wild Workshop"},{"id":"http://arxiv.org/abs/2503.05063v1","updated":"2025-03-07T00:47:15Z","published":"2025-03-07T00:47:15Z","title":"Lightweight Hypercomplex MRI Reconstruction: A Generalized\n  Kronecker-Parameterized Approach","summary":"  Magnetic Resonance Imaging (MRI) is crucial for clinical diagnostics but is\nhindered by prolonged scan times. Current deep learning models enhance MRI\nreconstruction but are often memory-intensive and unsuitable for\nresource-limited systems. This paper introduces a lightweight MRI\nreconstruction model leveraging Kronecker-Parameterized Hypercomplex Neural\nNetworks to achieve high performance with reduced parameters. By integrating\nKronecker-based modules, including Kronecker MLP, Kronecker Window Attention,\nand Kronecker Convolution, the proposed model efficiently extracts spatial\nfeatures while preserving representational power. We introduce Kronecker U-Net\nand Kronecker SwinMR, which maintain high reconstruction quality with\napproximately 50% fewer parameters compared to existing models. Experimental\nevaluation on the FastMRI dataset demonstrates competitive PSNR, SSIM, and\nLPIPS metrics, even at high acceleration factors (8x and 16x), with no\nsignificant performance drop. Additionally, Kronecker variants exhibit superior\ngeneralization and reduced overfitting on limited datasets, facilitating\nefficient MRI reconstruction on hardware-constrained systems. This approach\nsets a new benchmark for parameter-efficient medical imaging models.\n","authors":["Haosen Zhang","Jiahao Huang","Yinzhe Wu","Congren Dai","Fanwen Wang","Zhenxuan Zhang","Guang Yang"],"pdf_url":"https://arxiv.org/pdf/2503.05063v1.pdf","comment":"11 pages, 3 figures. Submitted for publication"},{"id":"http://arxiv.org/abs/2404.19108v2","updated":"2025-03-07T00:36:20Z","published":"2024-04-29T21:19:12Z","title":"Real-Time Convolutional Neural Network-Based Star Detection and\n  Centroiding Method for CubeSat Star Tracker","summary":"  Star trackers are one of the most accurate celestial sensors used for\nabsolute attitude determination. The devices detect stars in captured images\nand accurately compute their projected centroids on an imaging focal plane with\nsubpixel precision. Traditional algorithms for star detection and centroiding\noften rely on threshold adjustments for star pixel detection and pixel\nbrightness weighting for centroid computation. However, challenges like high\nsensor noise and stray light can compromise algorithm performance. This article\nintroduces a Convolutional Neural Network (CNN)-based approach for star\ndetection and centroiding, tailored to address the issues posed by noisy star\ntracker images in the presence of stray light and other artifacts. Trained\nusing simulated star images overlayed with real sensor noise and stray light,\nthe CNN produces both a binary segmentation map distinguishing star pixels from\nthe background and a distance map indicating each pixel's proximity to the\nnearest star centroid. Leveraging this distance information alongside pixel\ncoordinates transforms centroid calculations into a set of trilateration\nproblems solvable via the least squares method. Our method employs efficient\nUNet variants for the underlying CNN architectures, and the variants'\nperformances are evaluated. Comprehensive testing has been undertaken with\nsynthetic image evaluations, hardware-in-the-loop assessments, and night sky\ntests. The tests consistently demonstrated that our method outperforms several\nexisting algorithms in centroiding accuracy and exhibits superior resilience to\nhigh sensor noise and stray light interference. An additional benefit of our\nalgorithms is that they can be executed in real-time on low-power edge AI\nprocessors.\n","authors":["Hongrui Zhao","Michael F. Lembeck","Adrian Zhuang","Riya Shah","Jesse Wei"],"pdf_url":"https://arxiv.org/pdf/2404.19108v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.05051v1","updated":"2025-03-07T00:05:43Z","published":"2025-03-07T00:05:43Z","title":"Accelerated Patient-specific Non-Cartesian MRI Reconstruction using\n  Implicit Neural Representations","summary":"  The scanning time for a fully sampled MRI can be undesirably lengthy.\nCompressed sensing has been developed to minimize image artifacts in\naccelerated scans, but the required iterative reconstruction is computationally\ncomplex and difficult to generalize on new cases. Image-domain-based deep\nlearning methods (e.g., convolutional neural networks) emerged as a faster\nalternative but face challenges in modeling continuous k-space, a problem\namplified with non-Cartesian sampling commonly used in accelerated acquisition.\nIn comparison, implicit neural representations can model continuous signals in\nthe frequency domain and thus are compatible with arbitrary k-space sampling\npatterns. The current study develops a novel generative-adversarially trained\nimplicit neural representations (k-GINR) for de novo undersampled non-Cartesian\nk-space reconstruction. k-GINR consists of two stages: 1) supervised training\non an existing patient cohort; 2) self-supervised patient-specific\noptimization. In stage 1, the network is trained with the\ngenerative-adversarial network on diverse patients of the same anatomical\nregion supervised by fully sampled acquisition. In stage 2, undersampled\nk-space data of individual patients is used to tailor the prior-embedded\nnetwork for patient-specific optimization. The UCSF StarVIBE T1-weighted liver\ndataset was evaluated on the proposed framework. k-GINR is compared with an\nimage-domain deep learning method, Deep Cascade CNN, and a compressed sensing\nmethod. k-GINR consistently outperformed the baselines with a larger\nperformance advantage observed at very high accelerations (e.g., 20 times).\nk-GINR offers great value for direct non-Cartesian k-space reconstruction for\nnew incoming patients across a wide range of accelerations liver anatomy.\n","authors":["Di Xu","Hengjie Liu","Xin Miao","Daniel O'Connor","Jessica E. Scholey","Wensha Yang","Mary Feng","Michael Ohliger","Hui Lin","Dan Ruan","Yang Yang","Ke Sheng"],"pdf_url":"https://arxiv.org/pdf/2503.05051v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2412.10525v2","updated":"2025-03-07T00:00:57Z","published":"2024-12-13T19:38:36Z","title":"RowDetr: End-to-End Row Detection Using Polynomials","summary":"  Crop row detection is essential for enabling autonomous navigation in\nGPS-denied environments, such as under-canopy agricultural settings.\nTraditional methods often struggle with occlusions, variable lighting\nconditions, and the structural variability of crop rows. To address these\nchallenges, RowDetr, a novel end-to-end neural network architecture, is\nintroduced for robust and efficient row detection. A new dataset of\napproximately 6,900 images is curated, capturing a diverse range of real-world\nagricultural conditions, including occluded rows, uneven terrain, and varying\ncrop densities. Unlike previous approaches, RowDetr leverages smooth polynomial\nfunctions to precisely delineate crop boundaries in the image space, ensuring a\nmore structured and interpretable representation of row geometry. A key\ninnovation of this approach is PolyOptLoss, a novel energy-based loss function\ndesigned to enhance learning robustness, even in the presence of noisy or\nimperfect labels. This loss function significantly improves model stability and\ngeneralization by optimizing polynomial curve fitting directly in image space.\nExtensive experiments demonstrate that RowDetr significantly outperforms\nexisting frameworks, including Agronav and RowColAttention, across key\nperformance metrics. Additionally, RowDetr achieves a sixfold speedup over\nAgronav, making it highly suitable for real-time deployment on\nresource-constrained edge devices. To facilitate better comparisons across\nfuture studies, lane detection metrics from autonomous driving research are\nadapted, providing a more standardized and meaningful evaluation framework for\ncrop row detection. This work establishes a new benchmark in under-canopy\n","authors":["Rahul Harsha Cheppally","Ajay Sharda"],"pdf_url":"https://arxiv.org/pdf/2412.10525v2.pdf","comment":"Code will be open sourced upon publication"},{"id":"http://arxiv.org/abs/2503.05600v1","updated":"2025-03-07T17:26:27Z","published":"2025-03-07T17:26:27Z","title":"D2GV: Deformable 2D Gaussian Splatting for Video Representation in\n  400FPS","summary":"  Implicit Neural Representations (INRs) have emerged as a powerful approach\nfor video representation, offering versatility across tasks such as compression\nand inpainting. However, their implicit formulation limits both\ninterpretability and efficacy, undermining their practicality as a\ncomprehensive solution. We propose a novel video representation based on\ndeformable 2D Gaussian splatting, dubbed D2GV, which aims to achieve three key\nobjectives: 1) improved efficiency while delivering superior quality; 2)\nenhanced scalability and interpretability; and 3) increased friendliness for\ndownstream tasks. Specifically, we initially divide the video sequence into\nfixed-length Groups of Pictures (GoP) to allow parallel training and linear\nscalability with video length. For each GoP, D2GV represents video frames by\napplying differentiable rasterization to 2D Gaussians, which are deformed from\na canonical space into their corresponding timestamps. Notably, leveraging\nefficient CUDA-based rasterization, D2GV converges fast and decodes at speeds\nexceeding 400 FPS, while delivering quality that matches or surpasses\nstate-of-the-art INRs. Moreover, we incorporate a learnable pruning and\nquantization strategy to streamline D2GV into a more compact representation. We\ndemonstrate D2GV's versatility in tasks including video interpolation,\ninpainting and denoising, underscoring its potential as a promising solution\nfor video representation. Code is available at:\nhttps://github.com/Evan-sudo/D2GV.\n","authors":["Mufan Liu","Qi Yang","Miaoran Zhao","He Huang","Le Yang","Zhu Li","Yiling Xu"],"pdf_url":"https://arxiv.org/pdf/2503.05600v1.pdf","comment":null}],"Machine Learning":[{"id":"http://arxiv.org/abs/2503.04704v2","updated":"2025-03-07T15:12:57Z","published":"2025-03-06T18:54:32Z","title":"Universality of Layer-Level Entropy-Weighted Quantization Beyond Model\n  Architecture and Size","summary":"  We present a novel approach to selective model quantization that transcends\nthe limitations of architecture-specific and size-dependent compression methods\nfor Large Language Models (LLMs) using Entropy-Weighted Quantization (EWQ). By\nanalyzing the entropy distribution across transformer blocks, EWQ determines\nwhich blocks can be safely quantized without causing significant performance\ndegradation, independent of model architecture or size. Our method outperforms\nuniform quantization approaches, maintaining Massive Multitask Language\nUnderstanding (MMLU) accuracy scores within 0.5% of unquantized models while\nreducing memory usage by up to 18%. We demonstrate the effectiveness of EWQ\nacross multiple architectures -- from 1.6B to 70B parameters -- and showcase\nconsistent improvements in the quality-compression trade-off regardless of\nmodel scale or architectural design. A surprising finding of EWQ is its ability\nto reduce perplexity compared to unquantized models, suggesting the presence of\nbeneficial regularization through selective precision reduction. This\nimprovement holds across different model families, indicating a fundamental\nrelationship between layer-level entropy and optimal precision requirements.\nAdditionally, we introduce FastEWQ, a rapid method for entropy distribution\nanalysis that eliminates the need for loading model weights. This technique\nleverages universal characteristics of entropy distribution that persist across\nvarious architectures and scales, enabling near-instantaneous quantization\ndecisions while maintaining 80% classification accuracy with full entropy\nanalysis. Our results demonstrate that effective quantization strategies can be\ndeveloped independently of specific architectural choices or model sizes,\nopening new possibilities for efficient LLM deployment.\n","authors":["Alireza Behtash","Marijan Fofonjka","Ethan Baird","Tyler Mauer","Hossein Moghimifam","David Stout","Joel Dennison"],"pdf_url":"https://arxiv.org/pdf/2503.04704v2.pdf","comment":"29 pages, 7 figures, 14 tables; Fixed some types, added some\n  clarifications and improvements"},{"id":"http://arxiv.org/abs/2503.04638v2","updated":"2025-03-07T09:18:06Z","published":"2025-03-06T17:25:46Z","title":"No Forgetting Learning: Memory-free Continual Learning","summary":"  Continual Learning (CL) remains a central challenge in deep learning, where\nmodels must sequentially acquire new knowledge while mitigating Catastrophic\nForgetting (CF) of prior tasks. Existing approaches often struggle with\nefficiency and scalability, requiring extensive memory or model buffers. This\nwork introduces ``No Forgetting Learning\" (NFL), a memory-free CL framework\nthat leverages knowledge distillation to maintain stability while preserving\nplasticity. Memory-free means the NFL does not rely on any memory buffer.\nThrough extensive evaluations of three benchmark datasets, we demonstrate that\nNFL achieves competitive performance while utilizing approximately 14.75 times\nless memory than state-of-the-art methods. Furthermore, we introduce a new\nmetric to better assess CL's plasticity-stability trade-off.\n","authors":["Mohammad Ali Vahedifar","Qi Zhang"],"pdf_url":"https://arxiv.org/pdf/2503.04638v2.pdf","comment":"This paper is submitted to ICCV 2025"},{"id":"http://arxiv.org/abs/2410.04166v3","updated":"2025-03-07T10:51:04Z","published":"2024-10-05T14:04:03Z","title":"Learning from negative feedback, or positive feedback or both","summary":"  Existing preference optimization methods often assume scenarios where paired\npreference feedback (preferred/positive vs. dis-preferred/negative examples) is\navailable. This requirement limits their applicability in scenarios where only\nunpaired feedback--for example, either positive or negative--is available. To\naddress this, we introduce a novel approach that decouples learning from\npositive and negative feedback. This decoupling enables control over the\ninfluence of each feedback type and, importantly, allows learning even when\nonly one feedback type is present. A key contribution is demonstrating stable\nlearning from negative feedback alone, a capability not well-addressed by\ncurrent methods. Our approach builds upon the probabilistic framework\nintroduced in (Dayan and Hinton, 1997), which uses expectation-maximization\n(EM) to directly optimize the probability of positive outcomes (as opposed to\nclassic expected reward maximization). We address a key limitation in current\nEM-based methods: they solely maximize the likelihood of positive examples,\nwhile neglecting negative ones. We show how to extend EM algorithms to\nexplicitly incorporate negative examples, leading to a theoretically grounded\nalgorithm that offers an intuitive and versatile way to learn from both\npositive and negative feedback. We evaluate our approach for training language\nmodels based on human feedback as well as training policies for sequential\ndecision-making problems, where learned value functions are available.\n","authors":["Abbas Abdolmaleki","Bilal Piot","Bobak Shahriari","Jost Tobias Springenberg","Tim Hertweck","Rishabh Joshi","Junhyuk Oh","Michael Bloesch","Thomas Lampe","Nicolas Heess","Jonas Buchli","Martin Riedmiller"],"pdf_url":"https://arxiv.org/pdf/2410.04166v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.04398v2","updated":"2025-03-07T11:41:53Z","published":"2025-03-06T12:52:22Z","title":"Speculative MoE: Communication Efficient Parallel MoE Inference with\n  Speculative Token and Expert Pre-scheduling","summary":"  MoE (Mixture of Experts) prevails as a neural architecture that can scale\nmodern transformer-based LLMs (Large Language Models) to unprecedented scales.\nNevertheless, large MoEs' great demands of computing power, memory capacity and\nmemory bandwidth make scalable serving a fundamental challenge and efficient\nparallel inference has become a requisite to attain adequate throughput under\nlatency constraints. DeepSpeed-MoE, one state-of-the-art MoE inference\nframework, adopts a 3D-parallel paradigm including EP (Expert Parallelism), TP\n(Tensor Parallel) and DP (Data Parallelism). However, our analysis shows\nDeepSpeed-MoE's inference efficiency is largely bottlenecked by EP, which is\nimplemented with costly all-to-all collectives to route token activation. Our\nwork aims to boost DeepSpeed-MoE by strategically reducing EP's communication\noverhead with a technique named Speculative MoE. Speculative MoE has two\nspeculative parallelization schemes, speculative token shuffling and\nspeculative expert grouping, which predict outstanding tokens' expert routing\npaths and pre-schedule tokens and experts across devices to losslessly trim\nEP's communication volume. Besides DeepSpeed-MoE, we also build Speculative MoE\ninto a prevailing MoE inference engine SGLang. Experiments show Speculative MoE\ncan significantly boost state-of-the-art MoE inference frameworks on fast\nhomogeneous and slow heterogeneous interconnects.\n","authors":["Yan Li","Pengfei Zheng","Shuang Chen","Zewei Xu","Yuanhao Lai","Yunfei Du","Zhengang Wang"],"pdf_url":"https://arxiv.org/pdf/2503.04398v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2412.00156v4","updated":"2025-03-07T02:43:19Z","published":"2024-11-29T08:10:49Z","title":"VISION-XL: High Definition Video Inverse Problem Solver using Latent\n  Image Diffusion Models","summary":"  In this paper, we propose a novel framework for solving high-definition video\ninverse problems using latent image diffusion models. Building on recent\nadvancements in spatio-temporal optimization for video inverse problems using\nimage diffusion models, our approach leverages latent-space diffusion models to\nachieve enhanced video quality and resolution. To address the high\ncomputational demands of processing high-resolution frames, we introduce a\npseudo-batch consistent sampling strategy, allowing efficient operation on a\nsingle GPU. Additionally, to improve temporal consistency, we present\npseudo-batch inversion, an initialization technique that incorporates\ninformative latents from the measurement. By integrating with SDXL, our\nframework achieves state-of-the-art video reconstruction across a wide range of\nspatio-temporal inverse problems, including complex combinations of frame\naveraging and various spatial degradations, such as deblurring,\nsuper-resolution, and inpainting. Unlike previous methods, our approach\nsupports multiple aspect ratios (landscape, vertical, and square) and delivers\nHD-resolution reconstructions (exceeding 1280x720) in under 6 seconds per frame\non a single NVIDIA 4090 GPU.\n","authors":["Taesung Kwon","Jong Chul Ye"],"pdf_url":"https://arxiv.org/pdf/2412.00156v4.pdf","comment":"Project page: https://vision-xl.github.io/"},{"id":"http://arxiv.org/abs/2503.04280v2","updated":"2025-03-07T10:06:29Z","published":"2025-03-06T10:08:44Z","title":"Towards Autonomous Reinforcement Learning for Real-World Robotic\n  Manipulation with Large Language Models","summary":"  Recent advancements in Large Language Models (LLMs) and Visual Language\nModels (VLMs) have significantly impacted robotics, enabling high-level\nsemantic motion planning applications. Reinforcement Learning (RL), a\ncomplementary paradigm, enables agents to autonomously optimize complex\nbehaviors through interaction and reward signals. However, designing effective\nreward functions for RL remains challenging, especially in real-world tasks\nwhere sparse rewards are insufficient and dense rewards require elaborate\ndesign. In this work, we propose Autonomous Reinforcement learning for Complex\nHumanInformed Environments (ARCHIE), an unsupervised pipeline leveraging GPT-4,\na pre-trained LLM, to generate reward functions directly from natural language\ntask descriptions. The rewards are used to train RL agents in simulated\nenvironments, where we formalize the reward generation process to enhance\nfeasibility. Additionally, GPT-4 automates the coding of task success criteria,\ncreating a fully automated, one-shot procedure for translating human-readable\ntext into deployable robot skills. Our approach is validated through extensive\nsimulated experiments on single-arm and bi-manual manipulation tasks using an\nABB YuMi collaborative robot, highlighting its practicality and effectiveness.\nTasks are demonstrated on the real robot setup.\n","authors":["Niccol Turcato","Matteo Iovino","Aris Synodinos","Alberto Dalla Libera","Ruggero Carli","Pietro Falco"],"pdf_url":"https://arxiv.org/pdf/2503.04280v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.05696v1","updated":"2025-03-07T18:58:23Z","published":"2025-03-07T18:58:23Z","title":"Multi-Fidelity Policy Gradient Algorithms","summary":"  Many reinforcement learning (RL) algorithms require large amounts of data,\nprohibiting their use in applications where frequent interactions with\noperational systems are infeasible, or high-fidelity simulations are expensive\nor unavailable. Meanwhile, low-fidelity simulators--such as reduced-order\nmodels, heuristic reward functions, or generative world models--can cheaply\nprovide useful data for RL training, even if they are too coarse for direct\nsim-to-real transfer. We propose multi-fidelity policy gradients (MFPGs), an RL\nframework that mixes a small amount of data from the target environment with a\nlarge volume of low-fidelity simulation data to form unbiased, reduced-variance\nestimators (control variates) for on-policy policy gradients. We instantiate\nthe framework by developing multi-fidelity variants of two policy gradient\nalgorithms: REINFORCE and proximal policy optimization. Experimental results\nacross a suite of simulated robotics benchmark problems demonstrate that when\ntarget-environment samples are limited, MFPG achieves up to 3.9x higher reward\nand improves training stability when compared to baselines that only use\nhigh-fidelity data. Moreover, even when the baselines are given more\nhigh-fidelity samples--up to 10x as many interactions with the target\nenvironment--MFPG continues to match or outperform them. Finally, we observe\nthat MFPG is capable of training effective policies even when the low-fidelity\nenvironment is drastically different from the target environment. MFPG thus not\nonly offers a novel paradigm for efficient sim-to-real transfer but also\nprovides a principled approach to managing the trade-off between policy\nperformance and data collection costs.\n","authors":["Xinjie Liu","Cyrus Neary","Kushagra Gupta","Christian Ellis","Ufuk Topcu","David Fridovich-Keil"],"pdf_url":"https://arxiv.org/pdf/2503.05696v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2402.18668v2","updated":"2025-03-07T18:57:52Z","published":"2024-02-28T19:28:27Z","title":"Simple linear attention language models balance the recall-throughput\n  tradeoff","summary":"  Recent work has shown that attention-based language models excel at recall,\nthe ability to ground generations in tokens previously seen in context.\nHowever, the efficiency of attention-based models is bottle-necked during\ninference by the KV-cache's aggressive memory consumption. In this work, we\nexplore whether we can improve language model efficiency (e.g. by reducing\nmemory consumption) without compromising on recall. By applying experiments and\ntheory to a broad set of architectures, we identify a key tradeoff between a\nmodel's state size and recall ability. We show that efficient alternatives to\nattention (e.g. H3, Mamba, RWKV) maintain a fixed-size recurrent state, but\nstruggle at recall. We propose BASED a simple architecture combining linear and\nsliding window attention. By varying BASED window size and linear attention\nfeature dimension, we can dial the state size and traverse the pareto frontier\nof the recall-memory tradeoff curve, recovering the full quality of attention\non one end and the small state size of attention-alternatives on the other. We\ntrain language models up to 1.3b parameters and show that BASED matches the\nstrongest sub-quadratic models (e.g. Mamba) in perplexity and outperforms them\non real-world recall-intensive tasks by 6.22 accuracy points. Implementations\nof linear attention are often less efficient than optimized standard attention\nimplementations. To make BASED competitive, we develop IO-aware algorithms that\nenable 24x higher throughput on language generation than FlashAttention-2, when\ngenerating 1024 tokens using 1.3b parameter models. Code for this work is\nprovided at: https://github.com/HazyResearch/based.\n","authors":["Simran Arora","Sabri Eyuboglu","Michael Zhang","Aman Timalsina","Silas Alberti","Dylan Zinsley","James Zou","Atri Rudra","Christopher R"],"pdf_url":"https://arxiv.org/pdf/2402.18668v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.05684v1","updated":"2025-03-07T18:49:57Z","published":"2025-03-07T18:49:57Z","title":"Fairness-Aware Low-Rank Adaptation Under Demographic Privacy Constraints","summary":"  Pre-trained foundation models can be adapted for specific tasks using\nLow-Rank Adaptation (LoRA). However, the fairness properties of these adapted\nclassifiers remain underexplored. Existing fairness-aware fine-tuning methods\nrely on direct access to sensitive attributes or their predictors, but in\npractice, these sensitive attributes are often held under strict consumer\nprivacy controls, and neither the attributes nor their predictors are available\nto model developers, hampering the development of fair models. To address this\nissue, we introduce a set of LoRA-based fine-tuning methods that can be trained\nin a distributed fashion, where model developers and fairness auditors\ncollaborate without sharing sensitive attributes or predictors. In this paper,\nwe evaluate three such methods - sensitive unlearning, adversarial training,\nand orthogonality loss - against a fairness-unaware baseline, using experiments\non the CelebA and UTK-Face datasets with an ImageNet pre-trained ViT-Base\nmodel. We find that orthogonality loss consistently reduces bias while\nmaintaining or improving utility, whereas adversarial training improves False\nPositive Rate Parity and Demographic Parity in some cases, and sensitive\nunlearning provides no clear benefit. In tasks where significant biases are\npresent, distributed fairness-aware fine-tuning methods can effectively\neliminate bias without compromising consumer privacy and, in most cases,\nimprove model utility.\n","authors":["Parameswaran Kamalaruban","Mark Anderson","Stuart Burrell","Maeve Madigan","Piotr Skalski","David Sutton"],"pdf_url":"https://arxiv.org/pdf/2503.05684v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.05683v1","updated":"2025-03-07T18:45:42Z","published":"2025-03-07T18:45:42Z","title":"Understanding the Limits of Lifelong Knowledge Editing in LLMs","summary":"  Keeping large language models factually up-to-date is crucial for deployment,\nyet costly retraining remains a challenge. Knowledge editing offers a promising\nalternative, but methods are only tested on small-scale or synthetic edit\nbenchmarks. In this work, we aim to bridge research into lifelong knowledge\nediting to real-world edits at practically relevant scale. We first introduce\nWikiBigEdit; a large-scale benchmark of real-world Wikidata edits, built to\nautomatically extend lifelong for future-proof benchmarking. In its first\ninstance, it includes over 500K question-answer pairs for knowledge editing\nalongside a comprehensive evaluation pipeline. Finally, we use WikiBigEdit to\nstudy existing knowledge editing techniques' ability to incorporate large\nvolumes of real-world facts and contrast their capabilities to generic\nmodification techniques such as retrieval augmentation and continual finetuning\nto acquire a complete picture of the practical extent of current lifelong\nknowledge editing.\n","authors":["Lukas Thede","Karsten Roth","Matthias Bethge","Zeynep Akata","Tom Hartvigsen"],"pdf_url":"https://arxiv.org/pdf/2503.05683v1.pdf","comment":"Preprint"},{"id":"http://arxiv.org/abs/2501.10605v2","updated":"2025-03-07T18:35:41Z","published":"2025-01-17T23:37:21Z","title":"Wasserstein Adaptive Value Estimation for Actor-Critic Reinforcement\n  Learning","summary":"  We present Wasserstein Adaptive Value Estimation for Actor-Critic (WAVE), an\napproach to enhance stability in deep reinforcement learning through adaptive\nWasserstein regularization. Our method addresses the inherent instability of\nactor-critic algorithms by incorporating an adaptively weighted Wasserstein\nregularization term into the critic's loss function. We prove that WAVE\nachieves $\\mathcal{O}\\left(\\frac{1}{k}\\right)$ convergence rate for the\ncritic's mean squared error and provide theoretical guarantees for stability\nthrough Wasserstein-based regularization. Using the Sinkhorn approximation for\ncomputational efficiency, our approach automatically adjusts the regularization\nbased on the agent's performance. Theoretical analysis and experimental results\ndemonstrate that WAVE achieves superior performance compared to standard\nactor-critic methods.\n","authors":["Ali Baheri","Zahra Shahrooei","Chirayu Salgarkar"],"pdf_url":"https://arxiv.org/pdf/2501.10605v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.05675v1","updated":"2025-03-07T18:35:11Z","published":"2025-03-07T18:35:11Z","title":"Algorithmic Data Minimization for Machine Learning over\n  Internet-of-Things Data Streams","summary":"  Machine learning can analyze vast amounts of data generated by IoT devices to\nidentify patterns, make predictions, and enable real-time decision-making. By\nprocessing sensor data, machine learning models can optimize processes, improve\nefficiency, and enhance personalized user experiences in smart systems.\nHowever, IoT systems are often deployed in sensitive environments such as\nhouseholds and offices, where they may inadvertently expose identifiable\ninformation, including location, habits, and personal identifiers. This raises\nsignificant privacy concerns, necessitating the application of data\nminimization -- a foundational principle in emerging data regulations, which\nmandates that service providers only collect data that is directly relevant and\nnecessary for a specified purpose. Despite its importance, data minimization\nlacks a precise technical definition in the context of sensor data, where\ncollections of weak signals make it challenging to apply a binary \"relevant and\nnecessary\" rule. This paper provides a technical interpretation of data\nminimization in the context of sensor streams, explores practical methods for\nimplementation, and addresses the challenges involved. Through our approach, we\ndemonstrate that our framework can reduce user identifiability by up to 16.7%\nwhile maintaining accuracy loss below 1%, offering a viable path toward\nprivacy-preserving IoT data processing.\n","authors":["Ted Shaowang","Shinan Liu","Jonatas Marques","Nick Feamster","Sanjay Krishnan"],"pdf_url":"https://arxiv.org/pdf/2503.05675v1.pdf","comment":"9 pages, 18 figures"},{"id":"http://arxiv.org/abs/2412.01120v2","updated":"2025-03-07T18:34:16Z","published":"2024-12-02T04:45:10Z","title":"Reliable and scalable variable importance estimation via warm-start and\n  early stopping","summary":"  As opaque black-box predictive models become more prevalent, the need to\ndevelop interpretations for these models is of great interest. The concept of\nvariable importance and Shapley values are interpretability measures that\napplies to any predictive model and assesses how much a variable or set of\nvariables improves prediction performance. When the number of variables is\nlarge, estimating variable importance presents a significant computational\nchallenge because re-training neural networks or other black-box algorithms\nrequires significant additional computation. In this paper, we address this\nchallenge for algorithms using gradient descent and gradient boosting (e.g.\nneural networks, gradient-boosted decision trees). By using the ideas of early\nstopping of gradient-based methods in combination with warm-start using the\ndropout method, we develop a scalable method to estimate variable importance\nfor any algorithm that can be expressed as an iterative kernel update equation.\nImportantly, we provide theoretical guarantees by using the theory for early\nstopping of kernel-based methods for neural networks with sufficiently large\n(but not necessarily infinite) width and gradient-boosting decision trees that\nuse symmetric trees as a weaker learner. We also demonstrate the efficacy of\nour methods through simulations and a real data example which illustrates the\ncomputational benefit of early stopping rather than fully re-training the model\nas well as the increased accuracy of our approach.\n","authors":["Zexuan Sun","Garvesh Raskutti"],"pdf_url":"https://arxiv.org/pdf/2412.01120v2.pdf","comment":"Preliminary version accepted in AISTATS, 2025"},{"id":"http://arxiv.org/abs/2502.10297v2","updated":"2025-03-07T18:31:55Z","published":"2025-02-14T16:59:05Z","title":"DeltaProduct: Increasing the Expressivity of DeltaNet Through Products\n  of Householders","summary":"  Linear Recurrent Neural Networks (linear RNNs) have emerged as competitive\nalternatives to Transformers for sequence modeling, offering efficient training\nand linear-time inference. However, existing architectures face a fundamental\ntrade-off between expressivity and efficiency, dictated by the structure of\ntheir state-transition matrices. While diagonal matrices used in architectures\nlike Mamba, GLA, or mLSTM yield fast runtime, they suffer from severely limited\nexpressivity. To address this, recent architectures such as (Gated) DeltaNet\nand RWKVv7 adopted a diagonal plus rank-1 structure, allowing simultaneous\ntoken-channel mixing, which overcomes some expressivity limitations with only a\nslight decrease in training efficiency. Building on the interpretation of\nDeltaNet's recurrence as performing one step of online gradient descent per\ntoken on an associative recall loss, we introduce DeltaProduct, which instead\ntakes multiple ($n_h$) steps per token. This naturally leads to diagonal plus\nrank-$n_h$ state-transition matrices, formed as products of $n_h$ generalized\nHouseholder transformations, providing a tunable mechanism to balance\nexpressivity and efficiency and a stable recurrence. Through extensive\nexperiments, we demonstrate that DeltaProduct achieves superior state-tracking\nand language modeling capabilities while exhibiting significantly improved\nlength extrapolation compared to DeltaNet. Additionally, we also strengthen the\ntheoretical foundation of DeltaNet's expressivity by proving that it can solve\ndihedral group word problems in just two layers.\n","authors":["Julien Siems","Timur Carstensen","Arber Zela","Frank Hutter","Massimiliano Pontil","Riccardo Grazzi"],"pdf_url":"https://arxiv.org/pdf/2502.10297v2.pdf","comment":"Accepted at ICLR 2025 Workshop on Foundation Models in the Wild"},{"id":"http://arxiv.org/abs/2503.05665v1","updated":"2025-03-07T18:26:48Z","published":"2025-03-07T18:26:48Z","title":"AIM-Fair: Advancing Algorithmic Fairness via Selectively Fine-Tuning\n  Biased Models with Contextual Synthetic Data","summary":"  Recent advances in generative models have sparked research on improving model\nfairness with AI-generated data. However, existing methods often face\nlimitations in the diversity and quality of synthetic data, leading to\ncompromised fairness and overall model accuracy. Moreover, many approaches rely\non the availability of demographic group labels, which are often costly to\nannotate. This paper proposes AIM-Fair, aiming to overcome these limitations\nand harness the potential of cutting-edge generative models in promoting\nalgorithmic fairness. We investigate a fine-tuning paradigm starting from a\nbiased model initially trained on real-world data without demographic\nannotations. This model is then fine-tuned using unbiased synthetic data\ngenerated by a state-of-the-art diffusion model to improve its fairness. Two\nkey challenges are identified in this fine-tuning paradigm, 1) the low quality\nof synthetic data, which can still happen even with advanced generative models,\nand 2) the domain and bias gap between real and synthetic data. To address the\nlimitation of synthetic data quality, we propose Contextual Synthetic Data\nGeneration (CSDG) to generate data using a text-to-image diffusion model (T2I)\nwith prompts generated by a context-aware LLM, ensuring both data diversity and\ncontrol of bias in synthetic data. To resolve domain and bias shifts, we\nintroduce a novel selective fine-tuning scheme in which only model parameters\nmore sensitive to bias and less sensitive to domain shift are updated.\nExperiments on CelebA and UTKFace datasets show that our AIM-Fair improves\nmodel fairness while maintaining utility, outperforming both fully and\npartially fine-tuned approaches to model fairness.\n","authors":["Zengqun Zhao","Ziquan Liu","Yu Cao","Shaogang Gong","Ioannis Patras"],"pdf_url":"https://arxiv.org/pdf/2503.05665v1.pdf","comment":"Accepted at CVPR 2025. Github:\n  https://github.com/zengqunzhao/AIM-Fair. Project page:\n  https://zengqunzhao.github.io/AIMFair"},{"id":"http://arxiv.org/abs/2503.05662v1","updated":"2025-03-07T18:23:58Z","published":"2025-03-07T18:23:58Z","title":"On Mitigating Affinity Bias through Bandits with Evolving Biased\n  Feedback","summary":"  Unconscious bias has been shown to influence how we assess our peers, with\nconsequences for hiring, promotions and admissions. In this work, we focus on\naffinity bias, the component of unconscious bias which leads us to prefer\npeople who are similar to us, despite no deliberate intention of favoritism. In\na world where the people hired today become part of the hiring committee of\ntomorrow, we are particularly interested in understanding (and mitigating) how\naffinity bias affects this feedback loop. This problem has two distinctive\nfeatures: 1) we only observe the biased value of a candidate, but we want to\noptimize with respect to their real value 2) the bias towards a candidate with\na specific set of traits depends on the fraction of people in the hiring\ncommittee with the same set of traits. We introduce a new bandits variant that\nexhibits those two features, which we call affinity bandits. Unsurprisingly,\nclassical algorithms such as UCB often fail to identify the best arm in this\nsetting. We prove a new instance-dependent regret lower bound, which is larger\nthan that in the standard bandit setting by a multiplicative function of $K$.\nSince we treat rewards that are time-varying and dependent on the policy's past\nactions, deriving this lower bound requires developing proof techniques beyond\nthe standard bandit techniques. Finally, we design an elimination-style\nalgorithm which nearly matches this regret, despite never observing the real\nrewards.\n","authors":["Matthew Faw","Constantine Caramanis","Jessica Hoffmann"],"pdf_url":"https://arxiv.org/pdf/2503.05662v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.02482v2","updated":"2025-03-07T18:20:38Z","published":"2024-11-04T18:59:36Z","title":"NeRF-Aug: Data Augmentation for Robotics with Neural Radiance Fields","summary":"  Training a policy that can generalize to unknown objects is a long standing\nchallenge within the field of robotics. The performance of a policy often drops\nsignificantly in situations where an object in the scene was not seen during\ntraining. To solve this problem, we present NeRF-Aug, a novel method that is\ncapable of teaching a policy to interact with objects that are not present in\nthe dataset. This approach differs from existing approaches by leveraging the\nspeed, photorealism, and 3D consistency of a neural radiance field for\naugmentation. NeRF-Aug both creates more photorealistic data and runs 63%\nfaster than existing methods. We demonstrate the effectiveness of our method on\n5 tasks with 9 novel objects that are not present in the expert demonstrations.\nWe achieve an average performance boost of 55.6% when comparing our method to\nthe next best method. You can see video results at https://nerf-aug.github.io.\n","authors":["Eric Zhu","Mara Levy","Matthew Gwilliam","Abhinav Shrivastava"],"pdf_url":"https://arxiv.org/pdf/2411.02482v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.05657v1","updated":"2025-03-07T18:19:19Z","published":"2025-03-07T18:19:19Z","title":"NoT: Federated Unlearning via Weight Negation","summary":"  Federated unlearning (FU) aims to remove a participant's data contributions\nfrom a trained federated learning (FL) model, ensuring privacy and regulatory\ncompliance. Traditional FU methods often depend on auxiliary storage on either\nthe client or server side or require direct access to the data targeted for\nremoval-a dependency that may not be feasible if the data is no longer\navailable. To overcome these limitations, we propose NoT, a novel and efficient\nFU algorithm based on weight negation (multiplying by -1), which circumvents\nthe need for additional storage and access to the target data. We argue that\neffective and efficient unlearning can be achieved by perturbing model\nparameters away from the set of optimal parameters, yet being well-positioned\nfor quick re-optimization. This technique, though seemingly contradictory, is\ntheoretically grounded: we prove that the weight negation perturbation\neffectively disrupts inter-layer co-adaptation, inducing unlearning while\npreserving an approximate optimality property, thereby enabling rapid recovery.\nExperimental results across three datasets and three model architectures\ndemonstrate that NoT significantly outperforms existing baselines in unlearning\nefficacy as well as in communication and computational efficiency.\n","authors":["Yasser H. Khalil","Leo Brunswic","Soufiane Lamghari","Xu Li","Mahdi Beitollahi","Xi Chen"],"pdf_url":"https://arxiv.org/pdf/2503.05657v1.pdf","comment":"The 42nd IEEE/CVF Conference on Computer Vision and Pattern\n  Recognition, Nashville TN, US. 2025"},{"id":"http://arxiv.org/abs/2503.05652v1","updated":"2025-03-07T18:15:21Z","published":"2025-03-07T18:15:21Z","title":"BEHAVIOR Robot Suite: Streamlining Real-World Whole-Body Manipulation\n  for Everyday Household Activities","summary":"  Real-world household tasks present significant challenges for mobile\nmanipulation robots. An analysis of existing robotics benchmarks reveals that\nsuccessful task performance hinges on three key whole-body control\ncapabilities: bimanual coordination, stable and precise navigation, and\nextensive end-effector reachability. Achieving these capabilities requires\ncareful hardware design, but the resulting system complexity further\ncomplicates visuomotor policy learning. To address these challenges, we\nintroduce the BEHAVIOR Robot Suite (BRS), a comprehensive framework for\nwhole-body manipulation in diverse household tasks. Built on a bimanual,\nwheeled robot with a 4-DoF torso, BRS integrates a cost-effective whole-body\nteleoperation interface for data collection and a novel algorithm for learning\nwhole-body visuomotor policies. We evaluate BRS on five challenging household\ntasks that not only emphasize the three core capabilities but also introduce\nadditional complexities, such as long-range navigation, interaction with\narticulated and deformable objects, and manipulation in confined spaces. We\nbelieve that BRS's integrated robotic embodiment, data collection interface,\nand learning framework mark a significant step toward enabling real-world\nwhole-body manipulation for everyday household tasks. BRS is open-sourced at\nhttps://behavior-robot-suite.github.io/\n","authors":["Yunfan Jiang","Ruohan Zhang","Josiah Wong","Chen Wang","Yanjie Ze","Hang Yin","Cem Gokmen","Shuran Song","Jiajun Wu","Li Fei-Fei"],"pdf_url":"https://arxiv.org/pdf/2503.05652v1.pdf","comment":"Project website: https://behavior-robot-suite.github.io/"},{"id":"http://arxiv.org/abs/2503.05648v1","updated":"2025-03-07T18:11:23Z","published":"2025-03-07T18:11:23Z","title":"Physics-based machine learning framework for predicting NOx emissions\n  from compression ignition engines using on-board diagnostics data","summary":"  This work presents a physics-based machine learning framework to predict and\nanalyze oxides of nitrogen (NOx) emissions from compression-ignition\nengine-powered vehicles using on-board diagnostics (OBD) data as input.\nAccurate NOx prediction from OBD datasets is difficult because NOx formation\ninside an engine combustion chamber is governed by complex processes occurring\non timescales much shorter than the data collection rate. Thus, emissions\ngenerally cannot be predicted accurately using simple empirically derived\nphysics models. Black box models like genetic algorithms or neural networks can\nbe more accurate, but have poor interpretability. The transparent model\npresented in this paper has both high accuracy and can explain potential\nsources of high emissions. The proposed framework consists of two major steps:\na physics-based NOx prediction model combined with a novel Divergent Window\nCo-occurrence (DWC) Pattern detection algorithm to analyze operating conditions\nthat are not adequately addressed by the physics-based model. The proposed\nframework is validated for generalizability with a second vehicle OBD dataset,\na sensitivity analysis is performed, and model predictions are compared with\nthat from a deep neural network. The results show that NOx emissions\npredictions using the proposed model has around 55% better root mean square\nerror, and around 60% higher mean absolute error compared to the baseline NOx\nprediction model from previously published work. The DWC Pattern Detection\nAlgorithm identified low engine power conditions to have high statistical\nsignificance, indicating an operating regime where the model can be improved.\nThis work shows that the physics-based machine learning framework is a viable\nmethod for predicting NOx emissions from engines that do not incorporate NOx\nsensing.\n","authors":["Harish Panneer Selvam","Bharat Jayaprakash","Yan Li","Shashi Shekhar","William F. Northrop"],"pdf_url":"https://arxiv.org/pdf/2503.05648v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.05641v1","updated":"2025-03-07T18:03:13Z","published":"2025-03-07T18:03:13Z","title":"Symbolic Mixture-of-Experts: Adaptive Skill-based Routing for\n  Heterogeneous Reasoning","summary":"  Combining existing pre-trained expert LLMs is a promising avenue for scalably\ntackling large-scale and diverse tasks. However, selecting experts at the task\nlevel is often too coarse-grained, as heterogeneous tasks may require different\nexpertise for each instance. To enable adaptive instance-level mixing of\npre-trained LLM experts, we propose Symbolic-MoE, a symbolic, text-based, and\ngradient-free Mixture-of-Experts framework. Symbolic-MoE takes a fine-grained\napproach to selection by emphasizing skills, e.g., algebra in math or molecular\nbiology in biomedical reasoning. We propose a skill-based recruiting strategy\nthat dynamically selects the most relevant set of expert LLMs for diverse\nreasoning tasks based on their strengths. Each selected expert then generates\nits own reasoning, resulting in k outputs from k experts, which are then\nsynthesized into a final high-quality response by an aggregator chosen based on\nits ability to integrate diverse reasoning outputs. We show that Symbolic-MoE's\ninstance-level expert selection improves performance by a large margin but --\nwhen implemented naively -- can introduce a high computational overhead due to\nthe need for constant model loading and offloading. To address this, we\nimplement a batch inference strategy that groups instances based on their\nassigned experts, loading each model only once. This allows us to integrate 16\nexpert models on 1 GPU with a time cost comparable to or better than prior\nmulti-agent baselines using 4 GPUs. Through extensive evaluations on diverse\nbenchmarks (MMLU-Pro, GPQA, AIME, and MedMCQA), we demonstrate that\nSymbolic-MoE outperforms strong LLMs like GPT4o-mini, as well as multi-agent\napproaches, with an absolute average improvement of 8.15% over the best\nmulti-agent baseline. Moreover, Symbolic-MoE removes the need for expensive\nmulti-round discussions, outperforming discussion baselines with less\ncomputation.\n","authors":["Justin Chih-Yao Chen","Sukwon Yun","Elias Stengel-Eskin","Tianlong Chen","Mohit Bansal"],"pdf_url":"https://arxiv.org/pdf/2503.05641v1.pdf","comment":"The first three authors contributed equally. Project Page:\n  https://symbolic_moe.github.io/"},{"id":"http://arxiv.org/abs/2503.05631v1","updated":"2025-03-07T17:54:05Z","published":"2025-03-07T17:54:05Z","title":"Strategy Coopetition Explains the Emergence and Transience of In-Context\n  Learning","summary":"  In-context learning (ICL) is a powerful ability that emerges in transformer\nmodels, enabling them to learn from context without weight updates. Recent work\nhas established emergent ICL as a transient phenomenon that can sometimes\ndisappear after long training times. In this work, we sought a mechanistic\nunderstanding of these transient dynamics. Firstly, we find that, after the\ndisappearance of ICL, the asymptotic strategy is a remarkable hybrid between\nin-weights and in-context learning, which we term \"context-constrained\nin-weights learning\" (CIWL). CIWL is in competition with ICL, and eventually\nreplaces it as the dominant strategy of the model (thus leading to ICL\ntransience). However, we also find that the two competing strategies actually\nshare sub-circuits, which gives rise to cooperative dynamics as well. For\nexample, in our setup, ICL is unable to emerge quickly on its own, and can only\nbe enabled through the simultaneous slow development of asymptotic CIWL. CIWL\nthus both cooperates and competes with ICL, a phenomenon we term \"strategy\ncoopetition.\" We propose a minimal mathematical model that reproduces these key\ndynamics and interactions. Informed by this model, we were able to identify a\nsetup where ICL is truly emergent and persistent.\n","authors":["Aaditya K. Singh","Ted Moskovitz","Sara Dragutinovic","Felix Hill","Stephanie C. Y. Chan","Andrew M. Saxe"],"pdf_url":"https://arxiv.org/pdf/2503.05631v1.pdf","comment":"20 pages, 18 figures"},{"id":"http://arxiv.org/abs/2503.05622v1","updated":"2025-03-07T17:49:55Z","published":"2025-03-07T17:49:55Z","title":"Decision-aware training of spatiotemporal forecasting models","summary":"  Optimal allocation of scarce resources is a common problem for decision\nmakers faced with choosing a limited number of locations for intervention.\nSpatiotemporal prediction models could make such decisions data-driven. A\nrecent performance metric called fraction of best possible reach (BPR) measures\nthe impact of using a model's recommended size K subset of sites compared to\nthe best possible top-K in hindsight. We tackle two open problems related to\nBPR. First, we explore how to rank all sites numerically given a probabilistic\nmodel that predicts event counts jointly across sites. Ranking via the per-site\nmean is suboptimal for BPR. Instead, we offer a better ranking for BPR backed\nby decision theory. Second, we explore how to train a probabilistic model's\nparameters to maximize BPR. Discrete selection of K sites implies all-zero\nparameter gradients which prevent standard gradient training. We overcome this\nbarrier via advances in perturbed optimizers. We further suggest a training\nobjective that combines likelihood with a decision-aware BPR constraint to\ndeliver high-quality top-K rankings as well as good forecasts for all sites. We\ndemonstrate our approach on two where-to-intervene applications: mitigating\nopioid-related fatal overdoses for public health and monitoring endangered\nwildlife.\n","authors":["Kyle Heuton","F. Samuel Muench","Shikhar Shrestha","Thomas J. Stopka","Michael C. Hughes"],"pdf_url":"https://arxiv.org/pdf/2503.05622v1.pdf","comment":"9 pages, 3 figures"},{"id":"http://arxiv.org/abs/2503.05618v1","updated":"2025-03-07T17:42:30Z","published":"2025-03-07T17:42:30Z","title":"Conformal Prediction for Image Segmentation Using Morphological\n  Prediction Sets","summary":"  Image segmentation is a challenging task influenced by multiple sources of\nuncertainty, such as the data labeling process or the sampling of training\ndata. In this paper we focus on binary segmentation and address these\nchallenges using conformal prediction, a family of model- and data-agnostic\nmethods for uncertainty quantification that provide finite-sample theoretical\nguarantees and applicable to any pretrained predictor. Our approach involves\ncomputing nonconformity scores, a type of prediction residual, on held-out\ncalibration data not used during training. We use dilation, one of the\nfundamental operations in mathematical morphology, to construct a margin added\nto the borders of predicted segmentation masks. At inference, the predicted set\nformed by the mask and its margin contains the ground-truth mask with high\nprobability, at a confidence level specified by the user. The size of the\nmargin serves as an indicator of predictive uncertainty for a given model and\ndataset. We work in a regime of minimal information as we do not require any\nfeedback from the predictor: only the predicted masks are needed for computing\nthe prediction sets. Hence, our method is applicable to any segmentation model,\nincluding those based on deep learning; we evaluate our approach on several\nmedical imaging applications.\n","authors":["Luca Mossina","Corentin Friedrich"],"pdf_url":"https://arxiv.org/pdf/2503.05618v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.05617v1","updated":"2025-03-07T17:42:24Z","published":"2025-03-07T17:42:24Z","title":"Can KAN CANs? Input-convex Kolmogorov-Arnold Networks (KANs) as\n  hyperelastic constitutive artificial neural networks (CANs)","summary":"  Traditional constitutive models rely on hand-crafted parametric forms with\nlimited expressivity and generalizability, while neural network-based models\ncan capture complex material behavior but often lack interpretability. To\nbalance these trade-offs, we present Input-Convex Kolmogorov-Arnold Networks\n(ICKANs) for learning polyconvex hyperelastic constitutive laws. ICKANs\nleverage the Kolmogorov-Arnold representation, decomposing the model into\ncompositions of trainable univariate spline-based activation functions for rich\nexpressivity. We introduce trainable input-convex splines within the KAN\narchitecture, ensuring physically admissible polyconvex hyperelastic models.\nThe resulting models are both compact and interpretable, enabling explicit\nextraction of analytical constitutive relationships through an input-convex\nsymbolic regression techinque. Through unsupervised training on full-field\nstrain data and limited global force measurements, ICKANs accurately capture\nnonlinear stress-strain behavior across diverse strain states. Finite element\nsimulations of unseen geometries with trained ICKAN hyperelastic constitutive\nmodels confirm the framework's robustness and generalization capability.\n","authors":["Prakash Thakolkaran","Yaqi Guo","Shivam Saini","Mathias Peirlinck","Benjamin Alheit","Siddhant Kumar"],"pdf_url":"https://arxiv.org/pdf/2503.05617v1.pdf","comment":"34 pages, 15 figures"},{"id":"http://arxiv.org/abs/2503.05613v1","updated":"2025-03-07T17:38:00Z","published":"2025-03-07T17:38:00Z","title":"A Survey on Sparse Autoencoders: Interpreting the Internal Mechanisms of\n  Large Language Models","summary":"  Large Language Models (LLMs) have revolutionized natural language processing,\nyet their internal mechanisms remain largely opaque. Recently, mechanistic\ninterpretability has attracted significant attention from the research\ncommunity as a means to understand the inner workings of LLMs. Among various\nmechanistic interpretability approaches, Sparse Autoencoders (SAEs) have\nemerged as a particularly promising method due to their ability to disentangle\nthe complex, superimposed features within LLMs into more interpretable\ncomponents. This paper presents a comprehensive examination of SAEs as a\npromising approach to interpreting and understanding LLMs. We provide a\nsystematic overview of SAE principles, architectures, and applications\nspecifically tailored for LLM analysis, covering theoretical foundations,\nimplementation strategies, and recent developments in sparsity mechanisms. We\nalso explore how SAEs can be leveraged to explain the internal workings of\nLLMs, steer model behaviors in desired directions, and develop more transparent\ntraining methodologies for future models. Despite the challenges that remain\naround SAE implementation and scaling, they continue to provide valuable tools\nfor understanding the internal mechanisms of large language models.\n","authors":["Dong Shu","Xuansheng Wu","Haiyan Zhao","Daking Rai","Ziyu Yao","Ninghao Liu","Mengnan Du"],"pdf_url":"https://arxiv.org/pdf/2503.05613v1.pdf","comment":"20 pages, 3 figures"},{"id":"http://arxiv.org/abs/2503.05602v1","updated":"2025-03-07T17:28:02Z","published":"2025-03-07T17:28:02Z","title":"On the similarity of bandwidth-tuned quantum kernels and classical\n  kernels","summary":"  Quantum kernels (QK) are widely used in quantum machine learning\napplications; yet, their potential to surpass classical machine learning\nmethods on classical datasets remains uncertain. This limitation can be\nattributed to the exponential concentration phenomenon, which can impair both\ntrainability and generalization. A common strategy to alleviate this is\nbandwidth tuning, which involves rescaling data points in the quantum model to\nimprove generalization. In this work, we numerically demonstrate that optimal\nbandwidth tuning results in QKs that closely resemble radial basis function\n(RBF) kernels, leading to a lack of quantum advantage over classical methods.\nMoreover, we reveal that the size of optimal bandwidth tuning parameters\nfurther simplifies QKs, causing them to behave like polynomial kernels,\ncorresponding to a low-order Taylor approximation of a RBF kernel. We\nthoroughly investigate this for fidelity quantum kernels and projected quantum\nkernels using various data encoding circuits across several classification\ndatasets. We provide numerical evidence and derive a simple analytical model\nthat elucidates how bandwidth tuning influences key quantities in\nclassification tasks. Overall, our findings shed light on the mechanisms that\nrender QK methods classically simulatable.\n","authors":["Roberto Flrez Ablan","Marco Roth","Jan Schnabel"],"pdf_url":"https://arxiv.org/pdf/2503.05602v1.pdf","comment":"9 main pages with 5 figures, and 9 appendix pages with 12 figures"},{"id":"http://arxiv.org/abs/2503.05598v1","updated":"2025-03-07T17:25:25Z","published":"2025-03-07T17:25:25Z","title":"From Theory to Application: A Practical Introduction to Neural Operators\n  in Scientific Computing","summary":"  This focused review explores a range of neural operator architectures for\napproximating solutions to parametric partial differential equations (PDEs),\nemphasizing high-level concepts and practical implementation strategies. The\nstudy covers foundational models such as Deep Operator Networks (DeepONet),\nPrincipal Component Analysis-based Neural Networks (PCANet), and Fourier Neural\nOperators (FNO), providing comparative insights into their core methodologies\nand performance. These architectures are demonstrated on two classical linear\nparametric PDEs: the Poisson equation and linear elastic deformation. Beyond\nforward problem-solving, the review delves into applying neural operators as\nsurrogates in Bayesian inference problems, showcasing their effectiveness in\naccelerating posterior inference while maintaining accuracy. The paper\nconcludes by discussing current challenges, particularly in controlling\nprediction accuracy and generalization. It outlines emerging strategies to\naddress these issues, such as residual-based error correction and multi-level\ntraining. This review can be seen as a comprehensive guide to implementing\nneural operators and integrating them into scientific computing workflows.\n","authors":["Prashant K. Jha"],"pdf_url":"https://arxiv.org/pdf/2503.05598v1.pdf","comment":"53 pages, 17 figures, Github repository:\n  https://github.com/CEADpx/neural_operators"},{"id":"http://arxiv.org/abs/2406.16976v3","updated":"2025-03-07T17:24:35Z","published":"2024-06-23T06:22:49Z","title":"Efficient Evolutionary Search Over Chemical Space with Large Language\n  Models","summary":"  Molecular discovery, when formulated as an optimization problem, presents\nsignificant computational challenges because optimization objectives can be\nnon-differentiable. Evolutionary Algorithms (EAs), often used to optimize\nblack-box objectives in molecular discovery, traverse chemical space by\nperforming random mutations and crossovers, leading to a large number of\nexpensive objective evaluations. In this work, we ameliorate this shortcoming\nby incorporating chemistry-aware Large Language Models (LLMs) into EAs. Namely,\nwe redesign crossover and mutation operations in EAs using LLMs trained on\nlarge corpora of chemical information. We perform extensive empirical studies\non both commercial and open-source models on multiple tasks involving property\noptimization, molecular rediscovery, and structure-based drug design,\ndemonstrating that the joint usage of LLMs with EAs yields superior performance\nover all baseline models across single- and multi-objective settings. We\ndemonstrate that our algorithm improves both the quality of the final solution\nand convergence speed, thereby reducing the number of required objective\nevaluations. Our code is available at http://github.com/zoom-wang112358/MOLLEO\n","authors":["Haorui Wang","Marta Skreta","Cher-Tian Ser","Wenhao Gao","Lingkai Kong","Felix Strieth-Kalthoff","Chenru Duan","Yuchen Zhuang","Yue Yu","Yanqiao Zhu","Yuanqi Du","Aln Aspuru-Guzik","Kirill Neklyudov","Chao Zhang"],"pdf_url":"https://arxiv.org/pdf/2406.16976v3.pdf","comment":"Published in ICLR 2025"},{"id":"http://arxiv.org/abs/2303.17251v3","updated":"2025-03-07T17:23:53Z","published":"2023-03-30T09:29:53Z","title":"Demystifying Misconceptions in Social Bots Research","summary":"  Research on social bots aims at advancing knowledge and providing solutions\nto one of the most debated forms of online manipulation. Yet, social bot\nresearch is plagued by widespread biases, hyped results, and misconceptions\nthat set the stage for ambiguities, unrealistic expectations, and seemingly\nirreconcilable findings. Overcoming such issues is instrumental towards\nensuring reliable solutions and reaffirming the validity of the scientific\nmethod. In this contribution, we review some recent results in social bots\nresearch, highlighting and revising factual errors as well as methodological\nand conceptual biases. More importantly, we demystify common misconceptions,\naddressing fundamental points on how social bots research is discussed. Our\nanalysis surfaces the need to discuss research about online disinformation and\nmanipulation in a rigorous, unbiased, and responsible way. This article\nbolsters such effort by identifying and refuting common fallacious arguments\nused by both proponents and opponents of social bots research, as well as\nproviding directions toward sound methodologies for future research in the\nfield.\n","authors":["Stefano Cresci","Kai-Cheng Yang","Angelo Spognardi","Roberto Di Pietro","Filippo Menczer","Marinella Petrocchi"],"pdf_url":"https://arxiv.org/pdf/2303.17251v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.05587v1","updated":"2025-03-07T17:11:34Z","published":"2025-03-07T17:11:34Z","title":"Quantifying the Robustness of Retrieval-Augmented Language Models\n  Against Spurious Features in Grounding Data","summary":"  Robustness has become a critical attribute for the deployment of RAG systems\nin real-world applications. Existing research focuses on robustness to explicit\nnoise (e.g., document semantics) but overlooks spurious features (a.k.a.\nimplicit noise). While previous works have explored spurious features in LLMs,\nthey are limited to specific features (e.g., formats) and narrow scenarios\n(e.g., ICL). In this work, we statistically confirm the presence of spurious\nfeatures in the RAG paradigm, a robustness problem caused by the sensitivity of\nLLMs to semantic-agnostic features. Moreover, we provide a comprehensive\ntaxonomy of spurious features and empirically quantify their impact through\ncontrolled experiments. Further analysis reveals that not all spurious features\nare harmful and they can even be beneficial sometimes. Extensive evaluation\nresults across multiple LLMs suggest that spurious features are a widespread\nand challenging problem in the field of RAG. The code and dataset will be\nreleased to facilitate future research. We release all codes and data at:\n$\\\\\\href{https://github.com/maybenotime/RAG-SpuriousFeatures}{https://github.com/maybenotime/RAG-SpuriousFeatures}$.\n","authors":["Shiping Yang","Jie Wu","Wenbiao Ding","Ning Wu","Shining Liang","Ming Gong","Hengyuan Zhang","Dongmei Zhang"],"pdf_url":"https://arxiv.org/pdf/2503.05587v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.19492v2","updated":"2025-03-07T17:08:45Z","published":"2024-10-25T11:49:40Z","title":"TRADE: Transfer of Distributions between External Conditions with\n  Normalizing Flows","summary":"  Modeling distributions that depend on external control parameters is a common\nscenario in diverse applications like molecular simulations, where system\nproperties like temperature affect molecular configurations. Despite the\nrelevance of these applications, existing solutions are unsatisfactory as they\nrequire severely restricted model architectures or rely on energy-based\ntraining, which is prone to instability. We introduce TRADE, which overcomes\nthese limitations by formulating the learning process as a boundary value\nproblem. By initially training the model for a specific condition using either\ni.i.d.~samples or backward KL training, we establish a boundary distribution.\nWe then propagate this information across other conditions using the gradient\nof the unnormalized density with respect to the external parameter. This\nformulation, akin to the principles of physics-informed neural networks, allows\nus to efficiently learn parameter-dependent distributions without restrictive\nassumptions. Experimentally, we demonstrate that TRADE achieves excellent\nresults in a wide range of applications, ranging from Bayesian inference and\nmolecular simulations to physical lattice models.\n","authors":["Stefan Wahl","Armand Rousselot","Felix Draxler","Henrik Schopmans","Ullrich Kthe"],"pdf_url":"https://arxiv.org/pdf/2410.19492v2.pdf","comment":"Accepted as Poster at AISTATS 2025"},{"id":"http://arxiv.org/abs/2503.05582v1","updated":"2025-03-07T17:07:51Z","published":"2025-03-07T17:07:51Z","title":"MPTSNet: Integrating Multiscale Periodic Local Patterns and Global\n  Dependencies for Multivariate Time Series Classification","summary":"  Multivariate Time Series Classification (MTSC) is crucial in extensive\npractical applications, such as environmental monitoring, medical EEG analysis,\nand action recognition. Real-world time series datasets typically exhibit\ncomplex dynamics. To capture this complexity, RNN-based, CNN-based,\nTransformer-based, and hybrid models have been proposed. Unfortunately, current\ndeep learning-based methods often neglect the simultaneous construction of\nlocal features and global dependencies at different time scales, lacking\nsufficient feature extraction capabilities to achieve satisfactory\nclassification accuracy. To address these challenges, we propose a novel\nMultiscale Periodic Time Series Network (MPTSNet), which integrates multiscale\nlocal patterns and global correlations to fully exploit the inherent\ninformation in time series. Recognizing the multi-periodicity and complex\nvariable correlations in time series, we use the Fourier transform to extract\nprimary periods, enabling us to decompose data into multiscale periodic\nsegments. Leveraging the inherent strengths of CNN and attention mechanism, we\nintroduce the PeriodicBlock, which adaptively captures local patterns and\nglobal dependencies while offering enhanced interpretability through attention\nintegration across different periodic scales. The experiments on UEA benchmark\ndatasets demonstrate that the proposed MPTSNet outperforms 21 existing advanced\nbaselines in the MTSC tasks.\n","authors":["Yang Mu","Muhammad Shahzad","Xiao Xiang Zhu"],"pdf_url":"https://arxiv.org/pdf/2503.05582v1.pdf","comment":"Accepted by AAAI2025"},{"id":"http://arxiv.org/abs/2503.05577v1","updated":"2025-03-07T16:59:18Z","published":"2025-03-07T16:59:18Z","title":"opXRD: Open Experimental Powder X-ray Diffraction Database","summary":"  Powder X-ray diffraction (pXRD) experiments are a cornerstone for materials\nstructure characterization. Despite their widespread application, analyzing\npXRD diffractograms still presents a significant challenge to automation and a\nbottleneck in high-throughput discovery in self-driving labs. Machine learning\npromises to resolve this bottleneck by enabling automated powder diffraction\nanalysis. A notable difficulty in applying machine learning to this domain is\nthe lack of sufficiently sized experimental datasets, which has constrained\nresearchers to train primarily on simulated data. However, models trained on\nsimulated pXRD patterns showed limited generalization to experimental patterns,\nparticularly for low-quality experimental patterns with high noise levels and\nelevated backgrounds. With the Open Experimental Powder X-Ray Diffraction\nDatabase (opXRD), we provide an openly available and easily accessible dataset\nof labeled and unlabeled experimental powder diffractograms. Labeled opXRD data\ncan be used to evaluate the performance of models on experimental data and\nunlabeled opXRD data can help improve the performance of models on experimental\ndata, e.g. through transfer learning methods. We collected \\numpatterns\ndiffractograms, 2179 of them labeled, from a wide spectrum of materials\nclasses. We hope this ongoing effort can guide machine learning research toward\nfully automated analysis of pXRD data and thus enable future self-driving\nmaterials labs.\n","authors":["Daniel Hollarek","Henrik Schopmans","Jona streicher","Jonas Teufel","Bin Cao","Adie Alwen","Simon Schweidler","Mriganka Singh","Tim Kodalle","Hanlin Hu","Gregoire Heymans","Maged Abdelsamie","Arthur Hardiagon","Alexander Wieczorek","Siarhei Zhuk","Ruth Schwaiger","Sebastian Siol","Franois-Xavier Coudert","Moritz Wolf","Carolin M. Sutter-Fella","Ben Breitung","Andrea M. Hodge","Tong-yi Zhang","Pascal Friederich"],"pdf_url":"https://arxiv.org/pdf/2503.05577v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2408.06525v3","updated":"2025-03-07T16:58:08Z","published":"2024-08-12T23:04:30Z","title":"The NP-hardness of the Gromov-Wasserstein distance","summary":"  This note addresses the property frequently mentioned in the literature that\nthe Gromov-Wasserstein (GW) distance is NP-hard. We provide the details on the\nnon-convex nature of the GW optimization problem that imply NP-hardness of the\nGW distance between finite spaces for any instance of an input data. We further\nillustrate the non-convexity of the problem with several explicit examples.\n","authors":["Natalia Kravtsova"],"pdf_url":"https://arxiv.org/pdf/2408.06525v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.05574v1","updated":"2025-03-07T16:56:09Z","published":"2025-03-07T16:56:09Z","title":"BARK: A Fully Bayesian Tree Kernel for Black-box Optimization","summary":"  We perform Bayesian optimization using a Gaussian process perspective on\nBayesian Additive Regression Trees (BART). Our BART Kernel (BARK) uses tree\nagreement to define a posterior over piecewise-constant functions, and we\nexplore the space of tree kernels using a Markov chain Monte Carlo approach.\nWhere BART only samples functions, the resulting BARK model obtains samples of\nGaussian processes defining distributions over functions, which allow us to\nbuild acquisition functions for Bayesian optimization. Our tree-based approach\nenables global optimization over the surrogate, even for mixed-feature spaces.\nMoreover, where many previous tree-based kernels provide uncertainty\nquantification over function values, our sampling scheme captures uncertainty\nover the tree structure itself. Our experiments show the strong performance of\nBARK on both synthetic and applied benchmarks, due to the combination of our\nfully Bayesian surrogate and the optimization procedure.\n","authors":["Toby Boyne","Jose Pablo Folch","Robert M Lee","Behrang Shafei","Ruth Misener"],"pdf_url":"https://arxiv.org/pdf/2503.05574v1.pdf","comment":"8 main pages, 22 total pages, 10 figures, 6 tables"},{"id":"http://arxiv.org/abs/2503.05573v1","updated":"2025-03-07T16:56:00Z","published":"2025-03-07T16:56:00Z","title":"InDRiVE: Intrinsic Disagreement based Reinforcement for Vehicle\n  Exploration through Curiosity Driven Generalized World Model","summary":"  Model-based Reinforcement Learning (MBRL) has emerged as a promising paradigm\nfor autonomous driving, where data efficiency and robustness are critical. Yet,\nexisting solutions often rely on carefully crafted, task specific extrinsic\nrewards, limiting generalization to new tasks or environments. In this paper,\nwe propose InDRiVE (Intrinsic Disagreement based Reinforcement for Vehicle\nExploration), a method that leverages purely intrinsic, disagreement based\nrewards within a Dreamer based MBRL framework. By training an ensemble of world\nmodels, the agent actively explores high uncertainty regions of environments\nwithout any task specific feedback. This approach yields a task agnostic latent\nrepresentation, allowing for rapid zero shot or few shot fine tuning on\ndownstream driving tasks such as lane following and collision avoidance.\nExperimental results in both seen and unseen environments demonstrate that\nInDRiVE achieves higher success rates and fewer infractions compared to\nDreamerV2 and DreamerV3 baselines despite using significantly fewer training\nsteps. Our findings highlight the effectiveness of purely intrinsic exploration\nfor learning robust vehicle control behaviors, paving the way for more scalable\nand adaptable autonomous driving systems.\n","authors":["Feeza Khan Khanzada","Jaerock Kwon"],"pdf_url":"https://arxiv.org/pdf/2503.05573v1.pdf","comment":"This work has been submitted to IROS 2025 and is currently under\n  review"},{"id":"http://arxiv.org/abs/2212.11805v2","updated":"2025-03-07T16:52:17Z","published":"2022-12-22T15:36:15Z","title":"BSAC-CoEx: Coexistence of URLLC and Distributed Learning Services via\n  Device Selection","summary":"  Recent advances in distributed intelligence have driven impressive progress\nacross a diverse range of applications, from industrial automation to\nautonomous transportation. Nevertheless, deploying distributed learning\nservices over wireless networks poses numerous challenges. These arise from\ninherent uncertainties in wireless environments (e.g., random channel\nfluctuations), limited resources (e.g., bandwidth and transmit power), and the\npresence of coexisting services on the network. In this paper, we investigate a\nmixed service scenario wherein high-priority ultra-reliable low latency\ncommunication (URLLC) and low-priority distributed learning services run\nconcurrently over a network. Utilizing device selection, we aim to minimize the\nconvergence time of distributed learning while simultaneously fulfilling the\nrequirements of the URLLC service. We formulate this problem as a Markov\ndecision process and address it via BSAC-CoEx, a framework based on the\nbranching soft actor-critic (BSAC) algorithm that determines each device's\nparticipation decision through distinct branches in the actor's neural network.\nWe evaluate our solution with a realistic simulator that is compliant with 3GPP\nstandards for factory automation use cases. Our simulation results confirm that\nour solution can significantly decrease the training delays of the distributed\nlearning service while keeping the URLLC availability above its required\nthreshold and close to the scenario where URLLC solely consumes all wireless\nresources.\n","authors":["Milad Ganjalizadeh","Hossein Shokri Ghadikolaei","Deniz Gndz","Marina Petrova"],"pdf_url":"https://arxiv.org/pdf/2212.11805v2.pdf","comment":"This work has been submitted to the IEEE for possible publication"},{"id":"http://arxiv.org/abs/2503.05563v1","updated":"2025-03-07T16:43:25Z","published":"2025-03-07T16:43:25Z","title":"Tractable Representations for Convergent Approximation of Distributional\n  HJB Equations","summary":"  In reinforcement learning (RL), the long-term behavior of decision-making\npolicies is evaluated based on their average returns. Distributional RL has\nemerged, presenting techniques for learning return distributions, which provide\nadditional statistics for evaluating policies, incorporating risk-sensitive\nconsiderations. When the passage of time cannot naturally be divided into\ndiscrete time increments, researchers have studied the continuous-time RL\n(CTRL) problem, where agent states and decisions evolve continuously. In this\nsetting, the Hamilton-Jacobi-Bellman (HJB) equation is well established as the\ncharacterization of the expected return, and many solution methods exist.\nHowever, the study of distributional RL in the continuous-time setting is in\nits infancy. Recent work has established a distributional HJB (DHJB) equation,\nproviding the first characterization of return distributions in CTRL. These\nequations and their solutions are intractable to solve and represent exactly,\nrequiring novel approximation techniques. This work takes strides towards this\nend, establishing conditions on the method of parameterizing return\ndistributions under which the DHJB equation can be approximately solved.\nParticularly, we show that under a certain topological property of the mapping\nbetween statistics learned by a distributional RL algorithm and corresponding\ndistributions, approximation of these statistics leads to close approximations\nof the solution of the DHJB equation. Concretely, we demonstrate that the\nquantile representation common in distributional RL satisfies this topological\nproperty, certifying an efficient approximation algorithm for continuous-time\ndistributional RL.\n","authors":["Julie Alhosh","Harley Wiltzer","David Meger"],"pdf_url":"https://arxiv.org/pdf/2503.05563v1.pdf","comment":"Accepted to RLDM 2025"},{"id":"http://arxiv.org/abs/2503.05560v1","updated":"2025-03-07T16:38:41Z","published":"2025-03-07T16:38:41Z","title":"Global graph features unveiled by unsupervised geometric deep learning","summary":"  Graphs provide a powerful framework for modeling complex systems, but their\nstructural variability makes analysis and classification challenging. To\naddress this, we introduce GAUDI (Graph Autoencoder Uncovering Descriptive\nInformation), a novel unsupervised geometric deep learning framework that\ncaptures both local details and global structure. GAUDI employs an innovative\nhourglass architecture with hierarchical pooling and upsampling layers, linked\nthrough skip connections to preserve essential connectivity information\nthroughout the encoding-decoding process. By mapping different realizations of\na system - generated from the same underlying parameters - into a continuous,\nstructured latent space, GAUDI disentangles invariant process-level features\nfrom stochastic noise. We demonstrate its power across multiple applications,\nincluding modeling small-world networks, characterizing protein assemblies from\nsuper-resolution microscopy, analyzing collective motion in the Vicsek model,\nand capturing age-related changes in brain connectivity. This approach not only\nimproves the analysis of complex graphs but also provides new insights into\nemergent phenomena across diverse scientific domains.\n","authors":["Mirja Granfors","Jess Pineda","Blanca Zufiria Gerbols","Joana B. Pereira","Carlo Manzo","Giovanni Volpe"],"pdf_url":"https://arxiv.org/pdf/2503.05560v1.pdf","comment":"23 pages, 5 figures"},{"id":"http://arxiv.org/abs/2503.05558v1","updated":"2025-03-07T16:33:16Z","published":"2025-03-07T16:33:16Z","title":"Diffusion Models for Cayley Graphs","summary":"  We review the problem of finding paths in Cayley graphs of groups and group\nactions, using the Rubik's cube as an example, and we list several more\nexamples of significant mathematical interest. We then show how to formulate\nthese problems in the framework of diffusion models. The exploration of the\ngraph is carried out by the forward process, while finding the target nodes is\ndone by the inverse backward process. This systematizes the discussion and\nsuggests many generalizations. To improve exploration, we propose a ``reversed\nscore'' ansatz which substantially improves over previous comparable\nalgorithms.\n","authors":["Michael R. Douglas","Cristofero Fraser-Taliente"],"pdf_url":"https://arxiv.org/pdf/2503.05558v1.pdf","comment":"25 pages, 5 figures"},{"id":"http://arxiv.org/abs/2406.17975v3","updated":"2025-03-07T16:30:07Z","published":"2024-06-25T23:12:07Z","title":"SoK: Membership Inference Attacks on LLMs are Rushing Nowhere (and How\n  to Fix It)","summary":"  Whether LLMs memorize their training data and what this means, from measuring\nprivacy leakage to detecting copyright violations, has become a rapidly growing\narea of research. In the last few months, more than 10 new methods have been\nproposed to perform Membership Inference Attacks (MIAs) against LLMs. Contrary\nto traditional MIAs which rely on fixed-but randomized-records or models, these\nmethods are mostly trained and tested on datasets collected post-hoc. Sets of\nmembers and non-members, used to evaluate the MIA, are constructed using\ninformed guesses after the release of a model. This lack of randomization\nraises concerns of a distribution shift between members and non-members. In\nthis work, we first extensively review the literature on MIAs against LLMs and\nshow that, while most work focuses on sequence-level MIAs evaluated in post-hoc\nsetups, a range of target models, motivations and units of interest are\nconsidered. We then quantify distribution shifts present in 6 datasets used in\nthe literature using a model-less bag of word classifier and show that all\ndatasets constructed post-hoc suffer from strong distribution shifts. These\nshifts invalidate the claims of LLMs memorizing strongly in real-world\nscenarios and, potentially, also the methodological contributions of the recent\npapers based on these datasets. Yet, all hope might not be lost. We introduce\nimportant considerations to properly evaluate MIAs against LLMs and discuss, in\nturn, potential ways forwards: randomized test splits, injections of randomized\n(unique) sequences, randomized fine-tuning, and several post-hoc control\nmethods. While each option comes with its advantages and limitations, we\nbelieve they collectively provide solid grounds to guide MIA development and\nstudy LLM memorization. We conclude with an overview of recommended approaches\nto benchmark sequence-level and document-level MIAs against LLMs.\n","authors":["Matthieu Meeus","Igor Shilov","Shubham Jain","Manuel Faysse","Marek Rei","Yves-Alexandre de Montjoye"],"pdf_url":"https://arxiv.org/pdf/2406.17975v3.pdf","comment":"IEEE Conference on Secure and Trustworthy Machine Learning (SaTML\n  2025)"},{"id":"http://arxiv.org/abs/2411.02975v2","updated":"2025-03-07T16:28:13Z","published":"2024-11-05T10:24:45Z","title":"Transformer-Based Fault-Tolerant Control for Fixed-Wing UAVs Using\n  Knowledge Distillation and In-Context Adaptation","summary":"  This study presents a transformer-based approach for fault-tolerant control\nin fixed-wing Unmanned Aerial Vehicles (UAVs), designed to adapt in real time\nto dynamic changes caused by structural damage or actuator failures. Unlike\ntraditional Flight Control Systems (FCSs) that rely on classical control theory\nand struggle under severe alterations in dynamics, our method directly maps\nouter-loop reference values -- altitude, heading, and airspeed -- into control\ncommands using the in-context learning and attention mechanisms of\ntransformers, thus bypassing inner-loop controllers and fault-detection layers.\nEmploying a teacher-student knowledge distillation framework, the proposed\napproach trains a student agent with partial observations by transferring\nknowledge from a privileged expert agent with full observability, enabling\nrobust performance across diverse failure scenarios. Experimental results\ndemonstrate that our transformer-based controller outperforms industry-standard\nFCS and state-of-the-art reinforcement learning (RL) methods, maintaining high\ntracking accuracy and stability in nominal conditions and extreme failure\ncases, highlighting its potential for enhancing UAV operational safety and\nreliability.\n","authors":["Francisco Giral","Ignacio Gmez","Ricardo Vinuesa","Soledad Le Clainche"],"pdf_url":"https://arxiv.org/pdf/2411.02975v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.05551v1","updated":"2025-03-07T16:25:09Z","published":"2025-03-07T16:25:09Z","title":"Revitalizing Saturated Benchmarks: A Weighted Metric Approach for\n  Differentiating Large Language Model Performance","summary":"  Existing benchmarks are becoming saturated and struggle to separate model\nperformances due to factors like data contamination and advancing LLM\ncapabilities. This paper introduces EMDM (Enhanced Model Differentiation\nMetric), a novel weighted metric that revitalizes benchmarks by enhancing model\nseparation. EMDM integrates final answer and Chain-of-Thought (CoT) reasoning\ncorrectness, assigning weights based on the complexity and reasoning depth\nrequired to solve a given sample in the evaluation data. Using a baseline LLM\nin two setups-Unguided, where the model has no prior exposure to test samples,\nand Guided, where the model has prior knowledge of the desired answer-EMDM\ndistinguishes instances of varying difficulty. The CoT and answer correctness\nfrom these setups inform an optimization objective for weight assignment,\nresulting in a more nuanced evaluation of model performance. Compared to the\nexact match (EM) metric, which achieves 17% separation on ARC-Challenge, EMDM\nachieves 46%, demonstrating its effectiveness in differentiating models based\non reasoning and knowledge requirements.\n","authors":["Bryan Etzine","Masoud Hashemi","Nishanth Madhusudhan","Sagar Davasam","Roshnee Sharma","Sathwik Tejaswi Madhusudhan","Vikas Yadav"],"pdf_url":"https://arxiv.org/pdf/2503.05551v1.pdf","comment":"conference NAACL, TrustNLP Workshop"},{"id":"http://arxiv.org/abs/2503.05546v1","updated":"2025-03-07T16:19:19Z","published":"2025-03-07T16:19:19Z","title":"Impoola: The Power of Average Pooling for Image-Based Deep Reinforcement\n  Learning","summary":"  As image-based deep reinforcement learning tackles more challenging tasks,\nincreasing model size has become an important factor in improving performance.\nRecent studies achieved this by focusing on the parameter efficiency of scaled\nnetworks, typically using Impala-CNN, a 15-layer ResNet-inspired network, as\nthe image encoder. However, while Impala-CNN evidently outperforms older CNN\narchitectures, potential advancements in network design for deep reinforcement\nlearning-specific image encoders remain largely unexplored. We find that\nreplacing the flattening of output feature maps in Impala-CNN with global\naverage pooling leads to a notable performance improvement. This approach\noutperforms larger and more complex models in the Procgen Benchmark,\nparticularly in terms of generalization. We call our proposed encoder model\nImpoola-CNN. A decrease in the network's translation sensitivity may be central\nto this improvement, as we observe the most significant gains in games without\nagent-centered observations. Our results demonstrate that network scaling is\nnot just about increasing model size - efficient network design is also an\nessential factor.\n","authors":["Raphael Trumpp","Ansgar Schfftlein","Mirco Theile","Marco Caccamo"],"pdf_url":"https://arxiv.org/pdf/2503.05546v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2402.10457v2","updated":"2025-03-07T16:10:36Z","published":"2024-02-16T05:27:13Z","title":"Learning-Augmented Search Data Structures","summary":"  We study the integration of machine learning advice to improve upon\ntraditional data structure designed for efficient search queries. Although\nthere has been recent effort in improving the performance of binary search\ntrees using machine learning advice, e.g., Lin et. al. (ICML 2022), the\nresulting constructions nevertheless suffer from inherent weaknesses of binary\nsearch trees, such as complexity of maintaining balance across multiple updates\nand the inability to handle partially-ordered or high-dimensional datasets. For\nthese reasons, we focus on skip lists and KD trees in this work. Given access\nto a possibly erroneous oracle that outputs estimated fractional frequencies\nfor search queries on a set of items, we construct skip lists and KD trees that\nprovably provides the optimal expected search time, within nearly a factor of\ntwo. In fact, our learning-augmented skip lists and KD trees are still optimal\nup to a constant factor, even if the oracle is only accurate within a constant\nfactor. We also demonstrate robustness by showing that our data structures\nachieves an expected search time that is within a constant factor of an\noblivious skip list/KD tree construction even when the predictions are\narbitrarily incorrect. Finally, we empirically show that our learning-augmented\nsearch data structures outperforms their corresponding traditional analogs on\nboth synthetic and real-world datasets.\n","authors":["Chunkai Fu","Brandon G. Nguyen","Jung Hoon Seo","Ryan Zesch","Samson Zhou"],"pdf_url":"https://arxiv.org/pdf/2402.10457v2.pdf","comment":"ICLR 2025"},{"id":"http://arxiv.org/abs/2503.05540v1","updated":"2025-03-07T16:08:53Z","published":"2025-03-07T16:08:53Z","title":"Riemann$^2$: Learning Riemannian Submanifolds from Riemannian Data","summary":"  Latent variable models are powerful tools for learning low-dimensional\nmanifolds from high-dimensional data. However, when dealing with constrained\ndata such as unit-norm vectors or symmetric positive-definite matrices,\nexisting approaches ignore the underlying geometric constraints or fail to\nprovide meaningful metrics in the latent space. To address these limitations,\nwe propose to learn Riemannian latent representations of such geometric data.\nTo do so, we estimate the pullback metric induced by a Wrapped Gaussian Process\nLatent Variable Model, which explicitly accounts for the data geometry. This\nenables us to define geometry-aware notions of distance and shortest paths in\nthe latent space, while ensuring that our model only assigns probability mass\nto the data manifold. This generalizes previous work and allows us to handle\ncomplex tasks in various domains, including robot motion synthesis and analysis\nof brain connectomes.\n","authors":["Leonel Rozo","Miguel Gonzlez-Duque","Nomie Jaquier","Sren Hauberg"],"pdf_url":"https://arxiv.org/pdf/2503.05540v1.pdf","comment":"Accepted at AISTATS 2025"},{"id":"http://arxiv.org/abs/2503.05538v1","updated":"2025-03-07T16:04:34Z","published":"2025-03-07T16:04:34Z","title":"Additive Model Boosting: New Insights and Path(ologie)s","summary":"  Additive models (AMs) have sparked a lot of interest in machine learning\nrecently, allowing the incorporation of interpretable structures into a wide\nrange of model classes. Many commonly used approaches to fit a wide variety of\npotentially complex additive models build on the idea of boosting additive\nmodels. While boosted additive models (BAMs) work well in practice, certain\ntheoretical aspects are still poorly understood, including general convergence\nbehavior and what optimization problem is being solved when accounting for the\nimplicit regularizing nature of boosting. In this work, we study the solution\npaths of BAMs and establish connections with other approaches for certain\nclasses of problems. Along these lines, we derive novel convergence results for\nBAMs, which yield crucial insights into the inner workings of the method. While\nour results generally provide reassuring theoretical evidence for the practical\nuse of BAMs, they also uncover some ``pathologies'' of boosting for certain\nadditive model classes concerning their convergence behavior that require\ncaution in practice. We empirically validate our theoretical findings through\nseveral numerical experiments.\n","authors":["Rickmer Schulte","David Rgamer"],"pdf_url":"https://arxiv.org/pdf/2503.05538v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2402.04836v3","updated":"2025-03-07T15:55:55Z","published":"2024-02-07T13:32:53Z","title":"On the Completeness of Invariant Geometric Deep Learning Models","summary":"  Invariant models, one important class of geometric deep learning models, are\ncapable of generating meaningful geometric representations by leveraging\ninformative geometric features in point clouds. These models are characterized\nby their simplicity, good experimental results and computational efficiency.\nHowever, their theoretical expressive power still remains unclear, restricting\na deeper understanding of the potential of such models. In this work, we\nconcentrate on characterizing the theoretical expressiveness of a wide range of\ninvariant models under fully-connected conditions. We first rigorously\ncharacterize the expressiveness of the most classic invariant model,\nmessage-passing neural networks incorporating distance (DisGNN), restricting\nits unidentifiable cases to be only highly symmetric point clouds. We then\nprove that GeoNGNN, the geometric counterpart of one of the simplest subgraph\ngraph neural networks, can effectively break these corner cases' symmetry and\nthus achieve E(3)-completeness. By leveraging GeoNGNN as a theoretical tool, we\nfurther prove that: 1) most subgraph GNNs developed in traditional graph\nlearning can be seamlessly extended to geometric scenarios with\nE(3)-completeness; 2) DimeNet, GemNet and SphereNet, three well-established\ninvariant models, are also all capable of achieving E(3)-completeness. Our\ntheoretical results fill the gap in the expressive power of invariant models,\ncontributing to a rigorous and comprehensive understanding of their\ncapabilities.\n","authors":["Zian Li","Xiyuan Wang","Shijia Kang","Muhan Zhang"],"pdf_url":"https://arxiv.org/pdf/2402.04836v3.pdf","comment":"The Thirteenth International Conference on Learning Representations"},{"id":"http://arxiv.org/abs/2503.05530v1","updated":"2025-03-07T15:54:04Z","published":"2025-03-07T15:54:04Z","title":"Leveraging Approximate Caching for Faster Retrieval-Augmented Generation","summary":"  Retrieval-augmented generation (RAG) enhances the reliability of large\nlanguage model (LLM) answers by integrating external knowledge. However, RAG\nincreases the end-to-end inference time since looking for relevant documents\nfrom large vector databases is computationally expensive. To address this, we\nintroduce Proximity, an approximate key-value cache that optimizes the RAG\nworkflow by leveraging similarities in user queries. Instead of treating each\nquery independently, Proximity reuses previously retrieved documents when\nsimilar queries appear, reducing reliance on expensive vector database lookups.\nWe evaluate Proximity on the MMLU and MedRAG benchmarks, demonstrating that it\nsignificantly improves retrieval efficiency while maintaining response\naccuracy. Proximity reduces retrieval latency by up to 59% while maintaining\naccuracy and lowers the computational burden on the vector database. We also\nexperiment with different similarity thresholds and quantify the trade-off\nbetween speed and recall. Our work shows that approximate caching is a viable\nand effective strategy for optimizing RAG-based systems.\n","authors":["Shai Bergman","Zhang Ji","Anne-Marie Kermarrec","Diana Petrescu","Rafael Pires","Mathis Randl","Martijn de Vos"],"pdf_url":"https://arxiv.org/pdf/2503.05530v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.05525v1","updated":"2025-03-07T15:46:30Z","published":"2025-03-07T15:46:30Z","title":"Machine Learning for Improved Density Functional Theory Thermodynamics","summary":"  The predictive accuracy of density functional theory (DFT) for alloy\nformation enthalpies is often limited by intrinsic energy resolution errors,\nparticularly in ternary phase stability calculations. In this work, we present\na machine learning (ML) approach to systematically correct these errors,\nimproving the reliability of first-principles predictions. A neural network\nmodel has been trained to predict the discrepancy between DFT-calculated and\nexperimentally measured enthalpies for binary and ternary alloys and compounds.\nThe model utilizes a structured feature set comprising elemental\nconcentrations, atomic numbers, and interaction terms to capture key chemical\nand structural effects. By applying supervised learning and rigorous data\ncuration we ensure a robust and physically meaningful correction. The model is\nimplemented as a multi-layer perceptron (MLP) regressor with three hidden\nlayers, optimized through leave-one-out cross-validation (LOOCV) and k-fold\ncross-validation to prevent overfitting. We illustrate the effectiveness of\nthis method by applying it to the Al-Ni-Pd and Al-Ni-Ti systems, which are of\ninterest for high-temperature applications in aerospace and protective\ncoatings.\n","authors":["Sergei I. Simak","Erna K. Delczeg-Czirjak","Olle Eriksson"],"pdf_url":"https://arxiv.org/pdf/2503.05525v1.pdf","comment":"9 pages, 5 figures, 1 table"},{"id":"http://arxiv.org/abs/2503.05522v1","updated":"2025-03-07T15:45:43Z","published":"2025-03-07T15:45:43Z","title":"Post-Hoc Concept Disentanglement: From Correlated to Isolated Concept\n  Representations","summary":"  Concept Activation Vectors (CAVs) are widely used to model\nhuman-understandable concepts as directions within the latent space of neural\nnetworks. They are trained by identifying directions from the activations of\nconcept samples to those of non-concept samples. However, this method often\nproduces similar, non-orthogonal directions for correlated concepts, such as\n\"beard\" and \"necktie\" within the CelebA dataset, which frequently co-occur in\nimages of men. This entanglement complicates the interpretation of concepts in\nisolation and can lead to undesired effects in CAV applications, such as\nactivation steering. To address this issue, we introduce a post-hoc concept\ndisentanglement method that employs a non-orthogonality loss, facilitating the\nidentification of orthogonal concept directions while preserving directional\ncorrectness. We evaluate our approach with real-world and controlled correlated\nconcepts in CelebA and a synthetic FunnyBirds dataset with VGG16 and ResNet18\narchitectures. We further demonstrate the superiority of orthogonalized concept\nrepresentations in activation steering tasks, allowing (1) the insertion of\nisolated concepts into input images through generative models and (2) the\nremoval of concepts for effective shortcut suppression with reduced impact on\ncorrelated concepts in comparison to baseline CAVs.\n","authors":["Eren Erogullari","Sebastian Lapuschkin","Wojciech Samek","Frederik Pahde"],"pdf_url":"https://arxiv.org/pdf/2503.05522v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.05520v1","updated":"2025-03-07T15:42:51Z","published":"2025-03-07T15:42:51Z","title":"Removing Geometric Bias in One-Class Anomaly Detection with Adaptive\n  Feature Perturbation","summary":"  One-class anomaly detection aims to detect objects that do not belong to a\npredefined normal class. In practice training data lack those anomalous\nsamples; hence state-of-the-art methods are trained to discriminate between\nnormal and synthetically-generated pseudo-anomalous data. Most methods use data\naugmentation techniques on normal images to simulate anomalies. However the\nbest-performing ones implicitly leverage a geometric bias present in the\nbenchmarking datasets. This limits their usability in more general conditions.\nOthers are relying on basic noising schemes that may be suboptimal in capturing\nthe underlying structure of normal data. In addition most still favour the\nimage domain to generate pseudo-anomalies training models end-to-end from only\nthe normal class and overlooking richer representations of the information. To\novercome these limitations we consider frozen yet rich feature spaces given by\npretrained models and create pseudo-anomalous features with a novel adaptive\nlinear feature perturbation technique. It adapts the noise distribution to each\nsample applies decaying linear perturbations to feature vectors and further\nguides the classification process using a contrastive learning objective.\nExperimental evaluation conducted on both standard and geometric bias-free\ndatasets demonstrates the superiority of our approach with respect to\ncomparable baselines. The codebase is accessible via our public repository.\n","authors":["Romain Hermary","Vincent Gaudillire","Abd El Rahman Shabayek","Djamila Aouada"],"pdf_url":"https://arxiv.org/pdf/2503.05520v1.pdf","comment":"Published in WACV 2025"},{"id":"http://arxiv.org/abs/2406.09760v2","updated":"2025-03-07T15:26:03Z","published":"2024-06-14T06:57:18Z","title":"Bootstrapping Language Models with DPO Implicit Rewards","summary":"  Human alignment in large language models (LLMs) is an active area of\nresearch. A recent groundbreaking work, direct preference optimization (DPO),\nhas greatly simplified the process from past work in reinforcement learning\nfrom human feedback (RLHF) by bypassing the reward learning stage in RLHF. DPO,\nafter training, provides an implicit reward model. In this work, we make a\nnovel observation that this implicit reward model can by itself be used in a\nbootstrapping fashion to further align the LLM. Our approach is to use the\nrewards from a current LLM to construct a preference dataset, which is then\nused in subsequent DPO rounds. We incorporate two refinements to further\nimprove our approach: 1) length-regularized reward shaping to make the\npreference dataset length-unbiased; 2) experience replay to enhance the quality\nof the preference dataset. Our approach, named self-alignment with DPO ImpliCit\nrEwards (DICE), shows great improvements in alignment. It achieves an increase\nof more than 8$\\\\%$ in lengthcontrolled win rate on AlpacaEval 2 for all the\ndifferent base models that we tried, without relying on external feedback. Our\ncode is available at https://github.com/sail-sg/dice.\n","authors":["Changyu Chen","Zichen Liu","Chao Du","Tianyu Pang","Qian Liu","Arunesh Sinha","Pradeep Varakantham","Min Lin"],"pdf_url":"https://arxiv.org/pdf/2406.09760v2.pdf","comment":"Accepted in ICLR 2025"},{"id":"http://arxiv.org/abs/2411.02126v2","updated":"2025-03-07T15:21:42Z","published":"2024-11-04T14:37:07Z","title":"Unsupervised detection of semantic correlations in big data","summary":"  In real-world data, information is stored in extremely large feature vectors.\nThese variables are typically correlated due to complex interactions involving\nmany features simultaneously. Such correlations qualitatively correspond to\nsemantic roles and are naturally recognized by both the human brain and\nartificial neural networks. This recognition enables, for instance, the\nprediction of missing parts of an image or text based on their context. We\npresent a method to detect these correlations in high-dimensional data\nrepresented as binary numbers. We estimate the binary intrinsic dimension of a\ndataset, which quantifies the minimum number of independent coordinates needed\nto describe the data, and is therefore a proxy of semantic complexity. The\nproposed algorithm is largely insensitive to the so-called curse of\ndimensionality, and can therefore be used in big data analysis. We test this\napproach identifying phase transitions in model magnetic systems and we then\napply it to the detection of semantic correlations of images and text inside\ndeep neural networks.\n","authors":["Santiago Acevedo","Alex Rodriguez","Alessandro Laio"],"pdf_url":"https://arxiv.org/pdf/2411.02126v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2409.03463v3","updated":"2025-03-07T15:17:02Z","published":"2024-09-05T12:19:07Z","title":"Massive Activations in Graph Neural Networks: Decoding Attention for\n  Domain-Dependent Interpretability","summary":"  Graph Neural Networks (GNNs) have become increasingly popular for effectively\nmodeling graph-structured data, and attention mechanisms have been pivotal in\nenabling these models to capture complex patterns. In our study, we reveal a\ncritical yet underexplored consequence of integrating attention into\nedge-featured GNNs: the emergence of Massive Activations (MAs) within attention\nlayers. By developing a novel method for detecting MAs on edge features, we\nshow that these extreme activations are not only activation anomalies but\nencode domain-relevant signals. Our post-hoc interpretability analysis\ndemonstrates that, in molecular graphs, MAs aggregate predominantly on common\nbond types (e.g., single and double bonds) while sparing more informative ones\n(e.g., triple bonds). Furthermore, our ablation studies confirm that MAs can\nserve as natural attribution indicators, reallocating to less informative\nedges. Our study assesses various edge-featured attention-based GNN models\nusing benchmark datasets, including ZINC, TOX21, and PROTEINS. Key\ncontributions include (1) establishing the direct link between attention\nmechanisms and MAs generation in edge-featured GNNs, (2) developing a robust\ndefinition and detection method for MAs enabling reliable post-hoc\ninterpretability. Overall, our study reveals the complex interplay between\nattention mechanisms, edge-featured GNNs model, and MAs emergence, providing\ncrucial insights for relating GNNs internals to domain knowledge.\n","authors":["Lorenzo Bini","Marco Sorbi","Stephane Marchand-Maillet"],"pdf_url":"https://arxiv.org/pdf/2409.03463v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2308.05239v4","updated":"2025-03-07T15:13:45Z","published":"2023-08-09T21:54:34Z","title":"Enhancing Architecture Frameworks by Including Modern Stakeholders and\n  their Views/Viewpoints","summary":"  Various architecture frameworks for software, systems, and enterprises have\nbeen proposed in the literature. They identified several stakeholders and\ndefined modeling perspectives, architecture viewpoints, and views to frame and\naddress stakeholder concerns. However, the stakeholders with data science and\nMachine Learning (ML) related concerns, such as data scientists and data\nengineers, are yet to be included in existing architecture frameworks. Only\nthis way can we envision a holistic system architecture description of an\nML-enabled system. Note that the ML component behavior and functionalities are\nspecial and should be distinguished from traditional software system behavior\nand functionalities. The main reason is that the actual functionality should be\ninferred from data instead of being specified at design time. Additionally, the\nstructural models of ML components, such as ML model architectures, are\ntypically specified using different notations and formalisms from what the\nSoftware Engineering (SE) community uses for software structural models. Yet,\nthese two aspects, namely ML and non-ML, are becoming so intertwined that it\nnecessitates an extension of software architecture frameworks and modeling\npractices toward supporting ML-enabled system architectures. In this paper, we\naddress this gap through an empirical study using an online survey instrument.\nWe surveyed 61 subject matter experts from over 25 organizations in 10\ncountries.\n","authors":["Armin Moin","Atta Badii","Stephan Gnnemann","Moharram Challenger"],"pdf_url":"https://arxiv.org/pdf/2308.05239v4.pdf","comment":"ICICT 2025"},{"id":"http://arxiv.org/abs/2404.10386v2","updated":"2025-03-07T15:11:30Z","published":"2024-04-16T08:37:36Z","title":"I/O in Machine Learning Applications on HPC Systems: A 360-degree Survey","summary":"  Growing interest in Artificial Intelligence (AI) has resulted in a surge in\ndemand for faster methods of Machine Learning (ML) model training and\ninference. This demand for speed has prompted the use of high performance\ncomputing (HPC) systems that excel in managing distributed workloads. Because\ndata is the main fuel for AI applications, the performance of the storage and\nI/O subsystem of HPC systems is critical. In the past, HPC applications\naccessed large portions of data written by simulations or experiments or\ningested data for visualizations or analysis tasks. ML workloads perform small\nreads spread across a large number of random files. This shift of I/O access\npatterns poses several challenges to modern parallel storage systems. In this\npaper, we survey I/O in ML applications on HPC systems, and target literature\nwithin a 6-year time window from 2019 to 2024. We define the scope of the\nsurvey, provide an overview of the common phases of ML, review available\nprofilers and benchmarks, examine the I/O patterns encountered during offline\ndata preparation, training, and inference, and explore I/O optimizations\nutilized in modern ML frameworks and proposed in recent literature. Lastly, we\nseek to expose research gaps that could spawn further R&D.\n","authors":["Noah Lewis","Jean Luca Bez","Surendra Byna"],"pdf_url":"https://arxiv.org/pdf/2404.10386v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.05499v1","updated":"2025-03-07T15:10:37Z","published":"2025-03-07T15:10:37Z","title":"Mol-CADiff: Causality-Aware Autoregressive Diffusion for Molecule\n  Generation","summary":"  The design of novel molecules with desired properties is a key challenge in\ndrug discovery and materials science. Traditional methods rely on\ntrial-and-error, while recent deep learning approaches have accelerated\nmolecular generation. However, existing models struggle with generating\nmolecules based on specific textual descriptions. We introduce Mol-CADiff, a\nnovel diffusion-based framework that uses causal attention mechanisms for\ntext-conditional molecular generation. Our approach explicitly models the\ncausal relationship between textual prompts and molecular structures,\novercoming key limitations in existing methods. We enhance dependency modeling\nboth within and across modalities, enabling precise control over the generation\nprocess. Our extensive experiments demonstrate that Mol-CADiff outperforms\nstate-of-the-art methods in generating diverse, novel, and chemically valid\nmolecules, with better alignment to specified properties, enabling more\nintuitive language-driven molecular design.\n","authors":["Md Atik Ahamed","Qiang Ye","Qiang Cheng"],"pdf_url":"https://arxiv.org/pdf/2503.05499v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.05491v1","updated":"2025-03-07T15:00:28Z","published":"2025-03-07T15:00:28Z","title":"Statistical Deficiency for Task Inclusion Estimation","summary":"  Tasks are central in machine learning, as they are the most natural objects\nto assess the capabilities of current models. The trend is to build general\nmodels able to address any task. Even though transfer learning and multitask\nlearning try to leverage the underlying task space, no well-founded tools are\navailable to study its structure. This study proposes a theoretically grounded\nsetup to define the notion of task and to compute the {\\bf inclusion} between\ntwo tasks from a statistical deficiency point of view. We propose a tractable\nproxy as information sufficiency to estimate the degree of inclusion between\ntasks, show its soundness on synthetic data, and use it to reconstruct\nempirically the classic NLP pipeline.\n","authors":["Loc Fosse","Frdric Bchet","Benot Favre","Graldine Damnati","Gwnol Lecorv","Maxime Darrin","Philippe Formont","Pablo Piantanida"],"pdf_url":"https://arxiv.org/pdf/2503.05491v1.pdf","comment":"34 pages"},{"id":"http://arxiv.org/abs/2501.08998v2","updated":"2025-03-07T14:55:40Z","published":"2025-01-15T18:26:35Z","title":"CrystalGRW: Generative Modeling of Crystal Structures with Targeted\n  Properties via Geodesic Random Walks","summary":"  Determining whether a candidate crystalline material is thermodynamically\nstable depends on identifying its true ground-state structure, a central\nchallenge in computational materials science. We introduce CrystalGRW, a\ndiffusion-based generative model on Riemannian manifolds that proposes novel\ncrystal configurations and can predict stable phases validated by density\nfunctional theory. The crystal properties, such as fractional coordinates,\natomic types, and lattice matrices, are represented on suitable Riemannian\nmanifolds, ensuring that new predictions generated through the diffusion\nprocess preserve the periodicity of crystal structures. We incorporate an\nequivariant graph neural network to also account for rotational and\ntranslational symmetries during the generation process. CrystalGRW demonstrates\nthe ability to generate realistic crystal structures that are close to their\nground states with accuracy comparable to existing models, while also enabling\nconditional control, such as specifying a desired crystallographic point group.\nThese features help accelerate materials discovery and inverse design by\noffering stable, symmetry-consistent crystal candidates for experimental\nvalidation.\n","authors":["Krit Tangsongcharoen","Teerachote Pakornchote","Chayanon Atthapak","Natthaphon Choomphon-anomakhun","Annop Ektarawong","Bjrn Alling","Christopher Sutton","Thiti Bovornratanaraks","Thiparat Chotibut"],"pdf_url":"https://arxiv.org/pdf/2501.08998v2.pdf","comment":"10+12 pages, 10 figures"},{"id":"http://arxiv.org/abs/2503.05482v1","updated":"2025-03-07T14:51:32Z","published":"2025-03-07T14:51:32Z","title":"Bridging the Semantic Gap in Virtual Machine Introspection and Forensic\n  Memory Analysis","summary":"  Forensic Memory Analysis (FMA) and Virtual Machine Introspection (VMI) are\ncritical tools for security in a virtualization-based approach. VMI and FMA\ninvolves using digital forensic methods to extract information from the system\nto identify and explain security incidents. A key challenge in both FMA and VMI\nis the \"Semantic Gap\", which is the difficulty of interpreting raw memory data\nwithout specialized tools and expertise. In this work, we investigate how a\npriori knowledge, metadata and engineered features can aid VMI and FMA,\nleveraging machine learning to automate information extraction and reduce the\nworkload of forensic investigators. We choose OpenSSH as our use case to test\ndifferent methods to extract high level structures. We also test our method on\ncomplete physical memory dumps to showcase the effectiveness of the engineered\nfeatures. Our features range from basic statistical features to advanced\ngraph-based representations using malloc headers and pointer translations. The\ntraining and testing are carried out on public datasets that we compare against\nalready recognized baseline methods. We show that using metadata, we can\nimprove the performance of the algorithm when there is very little training\ndata and also quantify how having more data results in better generalization\nperformance. The final contribution is an open dataset of physical memory\ndumps, totalling more than 1 TB of different memory state, software\nenvironments, main memory capacities and operating system versions. Our methods\nshow that having more metadata boosts performance with all methods obtaining an\nF1-Score of over 80%. Our research underscores the possibility of using feature\nengineering and machine learning techniques to bridge the semantic gap.\n","authors":["Christofer Fellicious","Hans P. Reiser","Michael Granitzer"],"pdf_url":"https://arxiv.org/pdf/2503.05482v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.02694v4","updated":"2025-03-07T14:49:07Z","published":"2024-03-05T06:23:50Z","title":"MeanCache: User-Centric Semantic Caching for LLM Web Services","summary":"  Large Language Models (LLMs) like ChatGPT and Llama have revolutionized\nnatural language processing and search engine dynamics. However, these models\nincur exceptionally high computational costs. For instance, GPT-3 consists of\n175 billion parameters, where inference demands billions of floating-point\noperations. Caching is a natural solution to reduce LLM inference costs on\nrepeated queries, which constitute about 31% of the total queries. However,\nexisting caching methods are incapable of finding semantic similarities among\nLLM queries nor do they operate on contextual queries, leading to unacceptable\nfalse hit-and-miss rates. This paper introduces MeanCache, a user-centric\nsemantic cache for LLM-based services that identifies semantically similar\nqueries to determine cache hit or miss. Using MeanCache, the response to a\nuser's semantically similar query can be retrieved from a local cache rather\nthan re-querying the LLM, thus reducing costs, service provider load, and\nenvironmental impact. MeanCache leverages Federated Learning (FL) to\ncollaboratively train a query similarity model without violating user privacy.\nBy placing a local cache in each user's device and using FL, MeanCache reduces\nthe latency and costs and enhances model performance, resulting in lower false\nhit rates. MeanCache also encodes context chains for every cached query,\noffering a simple yet highly effective mechanism to discern contextual query\nresponses from standalone. Our experiments benchmarked against the\nstate-of-the-art caching method, reveal that MeanCache attains an approximately\n17% higher F-score and a 20% increase in precision during semantic cache\nhit-and-miss decisions while performing even better on contextual queries. It\nalso reduces the storage requirement by 83% and accelerates semantic cache\nhit-and-miss decisions by 11%.\n","authors":["Waris Gill","Mohamed Elidrisi","Pallavi Kalapatapu","Ammar Ahmed","Ali Anwar","Muhammad Ali Gulzar"],"pdf_url":"https://arxiv.org/pdf/2403.02694v4.pdf","comment":"Accepted at 2025 IEEE 39th International Parallel and Distributed\n  Processing Symposium (IPDPS)"},{"id":"http://arxiv.org/abs/2503.05477v1","updated":"2025-03-07T14:47:56Z","published":"2025-03-07T14:47:56Z","title":"Enhancing Network Security: A Hybrid Approach for Detection and\n  Mitigation of Distributed Denial-of-Service Attacks Using Machine Learning","summary":"  The distributed denial-of-service (DDoS) attack stands out as a highly\nformidable cyber threat, representing an advanced form of the denial-of-service\n(DoS) attack. A DDoS attack involves multiple computers working together to\noverwhelm a system, making it unavailable. On the other hand, a DoS attack is a\none-on-one attempt to make a system or website inaccessible. Thus, it is\ncrucial to construct an effective model for identifying various DDoS incidents.\nAlthough extensive research has focused on binary detection models for DDoS\nidentification, they face challenges to adapt evolving threats, necessitating\nfrequent updates. Whereas multiclass detection models offer a comprehensive\ndefense against diverse DDoS attacks, ensuring adaptability in the\never-changing cyber threat landscape. In this paper, we propose a Hybrid Model\nto strengthen network security by combining the featureextraction abilities of\n1D Convolutional Neural Networks (CNNs) with the classification skills of\nRandom Forest (RF) and Multi-layer Perceptron (MLP) classifiers. Using the\nCIC-DDoS2019 dataset, we perform multiclass classification of various DDoS\nattacks and conduct a comparative analysis of evaluation metrics for RF, MLP,\nand our proposed Hybrid Model. After analyzing the results, we draw meaningful\nconclusions and confirm the superiority of our Hybrid Model by performing\nthorough cross-validation. Additionally, we integrate our machine learning\nmodel with Snort, which provides a robust and adaptive solution for detecting\nand mitigating various DDoS attacks.\n","authors":["Nizo Jaman Shohan","Gazi Tanbhir","Faria Elahi","Ahsan Ullah","Md. Nazmus Sakib"],"pdf_url":"https://arxiv.org/pdf/2503.05477v1.pdf","comment":"Part of the book series: Communications in Computer and Information\n  Science ((CCIS,volume 2091))"},{"id":"http://arxiv.org/abs/2503.05474v1","updated":"2025-03-07T14:47:03Z","published":"2025-03-07T14:47:03Z","title":"Personalized Federated Learning via Learning Dynamic Graphs","summary":"  Personalized Federated Learning (PFL) aims to train a personalized model for\neach client that is tailored to its local data distribution, learning fails to\nperform well on individual clients due to variations in their local data\ndistributions. Most existing PFL methods focus on personalizing the aggregated\nglobal model for each client, neglecting the fundamental aspect of federated\nlearning: the regulation of how client models are aggregated. Additionally,\nalmost all of them overlook the graph structure formed by clients in federated\nlearning. In this paper, we propose a novel method, Personalized Federated\nLearning with Graph Attention Network (pFedGAT), which captures the latent\ngraph structure between clients and dynamically determines the importance of\nother clients for each client, enabling fine-grained control over the\naggregation process. We evaluate pFedGAT across multiple data distribution\nscenarios, comparing it with twelve state of the art methods on three datasets:\nFashion MNIST, CIFAR-10, and CIFAR-100, and find that it consistently performs\nwell.\n","authors":["Ziran Zhou","Guanyu Gao","Xiaohu Wu","Yan Lyu"],"pdf_url":"https://arxiv.org/pdf/2503.05474v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2408.12481v2","updated":"2025-03-07T14:46:22Z","published":"2024-08-22T15:17:02Z","title":"Self-Learning for Personalized Keyword Spotting on Ultra-Low-Power Audio\n  Sensors","summary":"  This paper proposes a self-learning method to incrementally train (fine-tune)\na personalized Keyword Spotting (KWS) model after the deployment on ultra-low\npower smart audio sensors. We address the fundamental problem of the absence of\nlabeled training data by assigning pseudo-labels to the new recorded audio\nframes based on a similarity score with respect to few user recordings. By\nexperimenting with multiple KWS models with a number of parameters up to 0.5M\non two public datasets, we show an accuracy improvement of up to +19.2% and\n+16.0% vs. the initial models pretrained on a large set of generic keywords.\nThe labeling task is demonstrated on a sensor system composed of a low-power\nmicrophone and an energy-efficient Microcontroller (MCU). By efficiently\nexploiting the heterogeneous processing engines of the MCU, the always-on\nlabeling task runs in real-time with an average power cost of up to 8.2 mW. On\nthe same platform, we estimate an energy cost for on-device training 10x lower\nthan the labeling energy if sampling a new utterance every 6.1 s or 18.8 s with\na DS-CNN-S or a DS-CNN-M model. Our empirical result paves the way to\nself-adaptive personalized KWS sensors at the extreme edge.\n","authors":["Manuele Rusci","Francesco Paci","Marco Fariselli","Eric Flamand","Tinne Tuytelaars"],"pdf_url":"https://arxiv.org/pdf/2408.12481v2.pdf","comment":"Published on IEEE IoT Journal"},{"id":"http://arxiv.org/abs/2410.04209v2","updated":"2025-03-07T14:32:12Z","published":"2024-10-05T15:56:57Z","title":"Equivariant Neural Functional Networks for Transformers","summary":"  This paper systematically explores neural functional networks (NFN) for\ntransformer architectures. NFN are specialized neural networks that treat the\nweights, gradients, or sparsity patterns of a deep neural network (DNN) as\ninput data and have proven valuable for tasks such as learnable optimizers,\nimplicit data representations, and weight editing. While NFN have been\nextensively developed for MLP and CNN, no prior work has addressed their design\nfor transformers, despite the importance of transformers in modern deep\nlearning. This paper aims to address this gap by providing a systematic study\nof NFN for transformers. We first determine the maximal symmetric group of the\nweights in a multi-head attention module as well as a necessary and sufficient\ncondition under which two sets of hyperparameters of the multi-head attention\nmodule define the same function. We then define the weight space of transformer\narchitectures and its associated group action, which leads to the design\nprinciples for NFN in transformers. Based on these, we introduce\nTransformer-NFN, an NFN that is equivariant under this group action.\nAdditionally, we release a dataset of more than 125,000 Transformers model\ncheckpoints trained on two datasets with two different tasks, providing a\nbenchmark for evaluating Transformer-NFN and encouraging further research on\ntransformer training and performance.\n","authors":["Viet-Hoang Tran","Thieu N. Vo","An Nguyen The","Tho Tran Huu","Minh-Khoi Nguyen-Nhat","Thanh Tran","Duy-Tung Pham","Tan Minh Nguyen"],"pdf_url":"https://arxiv.org/pdf/2410.04209v2.pdf","comment":"Accepted in ICLR 2025"},{"id":"http://arxiv.org/abs/2502.09685v2","updated":"2025-03-07T14:32:04Z","published":"2025-02-13T14:30:11Z","title":"A Novel Hybrid Approach to Contraceptive Demand Forecasting: Integrating\n  Point Predictions with Probabilistic Distributions","summary":"  Accurate demand forecasting is vital for ensuring reliable access to\ncontraceptive products, supporting key processes like procurement, inventory,\nand distribution. However, forecasting contraceptive demand in developing\ncountries presents challenges, including incomplete data, poor data quality,\nand the need to account for multiple geographical and product factors. Current\nmethods often rely on simple forecasting techniques, which fail to capture\ndemand uncertainties arising from these factors, warranting expert involvement.\nOur study aims to improve contraceptive demand forecasting by combining\nprobabilistic forecasting methods with expert knowledge. We developed a hybrid\nmodel that combines point forecasts from domain-specific model with\nprobabilistic distributions from statistical and machine learning approaches,\nenabling human input to fine-tune and enhance the system-generated forecasts.\nThis approach helps address the uncertainties in demand and is particularly\nuseful in resource-limited settings. We evaluate different forecasting methods,\nincluding time series, Bayesian, machine learning, and foundational time series\nmethods alongside our new hybrid approach. By comparing these methods, we\nprovide insights into their strengths, weaknesses, and computational\nrequirements. Our research fills a gap in forecasting contraceptive demand and\noffers a practical framework that combines algorithmic and human expertise. Our\nproposed model can also be generalized to other humanitarian contexts with\nsimilar data patterns.\n","authors":["Harsha Chamara Hewage","Bahman Rostami-Tabar","Aris Syntetos","Federico Liberatore","Glenn Milano"],"pdf_url":"https://arxiv.org/pdf/2502.09685v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.01639v2","updated":"2025-03-07T14:31:52Z","published":"2025-03-03T15:19:16Z","title":"Cauchy-Schwarz Regularizers","summary":"  We introduce a novel class of regularization functions, called Cauchy-Schwarz\n(CS) regularizers, which can be designed to induce a wide range of properties\nin solution vectors of optimization problems. To demonstrate the versatility of\nCS regularizers, we derive regularization functions that promote\ndiscrete-valued vectors, eigenvectors of a given matrix, and orthogonal\nmatrices. The resulting CS regularizers are simple, differentiable, and can be\nfree of spurious stationary points, making them suitable for gradient-based\nsolvers and large-scale optimization problems. In addition, CS regularizers\nautomatically adapt to the appropriate scale, which is, for example, beneficial\nwhen discretizing the weights of neural networks. To demonstrate the efficacy\nof CS regularizers, we provide results for solving underdetermined systems of\nlinear equations and weight quantization in neural networks. Furthermore, we\ndiscuss specializations, variations, and generalizations, which lead to an even\nbroader class of new and possibly more powerful regularizers.\n","authors":["Sueda Taner","Ziyi Wang","Christoph Studer"],"pdf_url":"https://arxiv.org/pdf/2503.01639v2.pdf","comment":"Accepted to ICLR 2025"},{"id":"http://arxiv.org/abs/2501.00962v3","updated":"2025-03-07T14:31:49Z","published":"2025-01-01T21:47:52Z","title":"OASIS Uncovers: High-Quality T2I Models, Same Old Stereotypes","summary":"  Images generated by text-to-image (T2I) models often exhibit visual biases\nand stereotypes of concepts such as culture and profession. Existing\nquantitative measures of stereotypes are based on statistical parity that does\nnot align with the sociological definition of stereotypes and, therefore,\nincorrectly categorizes biases as stereotypes. Instead of oversimplifying\nstereotypes as biases, we propose a quantitative measure of stereotypes that\naligns with its sociological definition. We then propose OASIS to measure the\nstereotypes in a generated dataset and understand their origins within the T2I\nmodel. OASIS includes two scores to measure stereotypes from a generated image\ndataset: (M1) Stereotype Score to measure the distributional violation of\nstereotypical attributes, and (M2) WALS to measure spectral variance in the\nimages along a stereotypical attribute. OASIS also includes two methods to\nunderstand the origins of stereotypes in T2I models: (U1) StOP to discover\nattributes that the T2I model internally associates with a given concept, and\n(U2) SPI to quantify the emergence of stereotypical attributes in the latent\nspace of the T2I model during image generation. Despite the considerable\nprogress in image fidelity, using OASIS, we conclude that newer T2I models such\nas FLUX.1 and SDv3 contain strong stereotypical predispositions about concepts\nand still generate images with widespread stereotypical attributes.\nAdditionally, the quantity of stereotypes worsens for nationalities with lower\nInternet footprints.\n","authors":["Sepehr Dehdashtian","Gautam Sreekumar","Vishnu Naresh Boddeti"],"pdf_url":"https://arxiv.org/pdf/2501.00962v3.pdf","comment":"Accepted as a Spotlight paper at ICLR 2025"},{"id":"http://arxiv.org/abs/2503.05453v1","updated":"2025-03-07T14:23:40Z","published":"2025-03-07T14:23:40Z","title":"Soft Policy Optimization: Online Off-Policy RL for Sequence Models","summary":"  RL-based post-training of language models is almost exclusively done using\non-policy methods such as PPO. These methods cannot learn from arbitrary\nsequences such as those produced earlier in training, in earlier runs, by human\nexperts or other policies, or by decoding and exploration methods. This results\nin severe sample inefficiency and exploration difficulties, as well as a\npotential loss of diversity in the policy responses. Moreover, asynchronous PPO\nimplementations require frequent and costly model transfers, and typically use\nvalue models which require a large amount of memory. In this paper we introduce\nSoft Policy Optimization (SPO), a simple, scalable and principled Soft RL\nmethod for sequence model policies that can learn from arbitrary online and\noffline trajectories and does not require a separate value model. In\nexperiments on code contests, we shows that SPO outperforms PPO on pass@10, is\nsignificantly faster and more memory efficient, is able to benefit from\noff-policy data, enjoys improved stability, and learns more diverse (i.e. soft)\npolicies.\n","authors":["Taco Cohen","David W. Zhang","Kunhao Zheng","Yunhao Tang","Remi Munos","Gabriel Synnaeve"],"pdf_url":"https://arxiv.org/pdf/2503.05453v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2402.06287v3","updated":"2025-03-07T14:20:58Z","published":"2024-02-09T09:54:01Z","title":"AI, Meet Human: Learning Paradigms for Hybrid Decision Making Systems","summary":"  Everyday we increasingly rely on machine learning models to automate and\nsupport high-stake tasks and decisions. This growing presence means that humans\nare now constantly interacting with machine learning-based systems, training\nand using models everyday. Several different techniques in computer science\nliterature account for the human interaction with machine learning systems, but\ntheir classification is sparse and the goals varied. This survey proposes a\ntaxonomy of Hybrid Decision Making Systems, providing both a conceptual and\ntechnical framework for understanding how current computer science literature\nmodels interaction between humans and machines.\n","authors":["Clara Punzi","Roberto Pellungrini","Mattia Setzu","Fosca Giannotti","Dino Pedreschi"],"pdf_url":"https://arxiv.org/pdf/2402.06287v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2409.19798v2","updated":"2025-03-07T14:20:23Z","published":"2024-09-29T21:49:32Z","title":"Membership Inference Attacks Cannot Prove that a Model Was Trained On\n  Your Data","summary":"  We consider the problem of a training data proof, where a data creator or\nowner wants to demonstrate to a third party that some machine learning model\nwas trained on their data. Training data proofs play a key role in recent\nlawsuits against foundation models trained on web-scale data. Many prior works\nsuggest to instantiate training data proofs using membership inference attacks.\nWe argue that this approach is fundamentally unsound: to provide convincing\nevidence, the data creator needs to demonstrate that their attack has a low\nfalse positive rate, i.e., that the attack's output is unlikely under the null\nhypothesis that the model was not trained on the target data. Yet, sampling\nfrom this null hypothesis is impossible, as we do not know the exact contents\nof the training set, nor can we (efficiently) retrain a large foundation model.\nWe conclude by offering two paths forward, by showing that data extraction\nattacks and membership inference on special canary data can be used to create\nsound training data proofs.\n","authors":["Jie Zhang","Debeshee Das","Gautam Kamath","Florian Tramr"],"pdf_url":"https://arxiv.org/pdf/2409.19798v2.pdf","comment":"position paper at IEEE SaTML 2025"},{"id":"http://arxiv.org/abs/2503.05447v1","updated":"2025-03-07T14:17:45Z","published":"2025-03-07T14:17:45Z","title":"Linear-MoE: Linear Sequence Modeling Meets Mixture-of-Experts","summary":"  Linear Sequence Modeling (LSM) like linear attention, state space models and\nlinear RNNs, and Mixture-of-Experts (MoE) have recently emerged as significant\narchitectural improvements. In this paper, we introduce Linear-MoE, a\nproduction-level system for modeling and training large-scale models that\nintegrate LSM with MoE. Linear-MoE leverages the advantages of both LSM modules\nfor linear-complexity sequence modeling and MoE layers for sparsely activation,\naiming to offer high performance with efficient training. The Linear-MoE system\ncomprises: 1) Modeling subsystem, which provides a unified framework supporting\nall instances of LSM. and 2) Training subsystem, which facilitates efficient\ntraining by incorporating various advanced parallelism technologies,\nparticularly Sequence Parallelism designed for Linear-MoE models. Additionally,\nwe explore hybrid models that combine Linear-MoE layers with standard\nTransformer-MoE layers with its Sequence Parallelism to further enhance model\nflexibility and performance. Evaluations on two model series, A0.3B-2B and\nA1B-7B, demonstrate Linear-MoE achieves efficiency gains while maintaining\ncompetitive performance on various benchmarks, showcasing its potential as a\nnext-generation foundational model architecture. Code:\nhttps://github.com/OpenSparseLLMs/Linear-MoE.\n","authors":["Weigao Sun","Disen Lan","Tong Zhu","Xiaoye Qu","Yu Cheng"],"pdf_url":"https://arxiv.org/pdf/2503.05447v1.pdf","comment":"Technical report, 17 pages"},{"id":"http://arxiv.org/abs/2503.05431v1","updated":"2025-03-07T14:01:25Z","published":"2025-03-07T14:01:25Z","title":"Quantum-PEFT: Ultra parameter-efficient fine-tuning","summary":"  This paper introduces Quantum-PEFT that leverages quantum computations for\nparameter-efficient fine-tuning (PEFT). Unlike other additive PEFT methods,\nsuch as low-rank adaptation (LoRA), Quantum-PEFT exploits an underlying\nfull-rank yet surprisingly parameter efficient quantum unitary\nparameterization. With the use of Pauli parameterization, the number of\ntrainable parameters grows only logarithmically with the ambient dimension, as\nopposed to linearly as in LoRA-based PEFT methods. Quantum-PEFT achieves\nvanishingly smaller number of trainable parameters than the lowest-rank LoRA as\ndimensions grow, enhancing parameter efficiency while maintaining a competitive\nperformance. We apply Quantum-PEFT to several transfer learning benchmarks in\nlanguage and vision, demonstrating significant advantages in parameter\nefficiency.\n","authors":["Toshiaki Koike-Akino","Francesco Tonin","Yongtao Wu","Frank Zhengqing Wu","Leyla Naz Candogan","Volkan Cevher"],"pdf_url":"https://arxiv.org/pdf/2503.05431v1.pdf","comment":"ICLR 2025"},{"id":"http://arxiv.org/abs/2410.03292v2","updated":"2025-03-07T13:54:48Z","published":"2024-10-04T10:06:17Z","title":"Demystifying the Token Dynamics of Deep Selective State Space Models","summary":"  Selective state space models (SSM), such as Mamba, have gained prominence for\ntheir effectiveness in modeling sequential data. Despite their outstanding\nempirical performance, a comprehensive theoretical understanding of deep\nselective SSM remains elusive, hindering their further development and adoption\nfor applications that need high fidelity. In this paper, we investigate the\ndynamical properties of tokens in a pre-trained Mamba model. In particular, we\nderive the dynamical system governing the continuous-time limit of the Mamba\nmodel and characterize the asymptotic behavior of its solutions. In the\none-dimensional case, we prove that only one of the following two scenarios\nhappens: either all tokens converge to zero, or all tokens diverge to infinity.\nWe provide criteria based on model parameters to determine when each scenario\noccurs. For the convergent scenario, we empirically verify that this scenario\nnegatively impacts the model's performance. For the divergent scenario, we\nprove that different tokens will diverge to infinity at different rates,\nthereby contributing unequally to the updates during model training. Based on\nthese investigations, we propose two refinements for the model: excluding the\nconvergent scenario and reordering tokens based on their importance scores,\nboth aimed at improving practical performance. Our experimental results\nvalidate these refinements, offering insights into enhancing Mamba's\neffectiveness in real-world applications.\n","authors":["Thieu N Vo","Tung D. Pham","Xin T. Tong","Tan Minh Nguyen"],"pdf_url":"https://arxiv.org/pdf/2410.03292v2.pdf","comment":"Accepted at ICLR 2025 (spotlight)"},{"id":"http://arxiv.org/abs/2503.05424v1","updated":"2025-03-07T13:50:37Z","published":"2025-03-07T13:50:37Z","title":"Towards Locally Explaining Prediction Behavior via Gradual Interventions\n  and Measuring Property Gradients","summary":"  Deep learning models achieve high predictive performance but lack intrinsic\ninterpretability, hindering our understanding of the learned prediction\nbehavior. Existing local explainability methods focus on associations,\nneglecting the causal drivers of model predictions. Other approaches adopt a\ncausal perspective but primarily provide more general global explanations.\nHowever, for specific inputs, it's unclear whether globally identified factors\napply locally. To address this limitation, we introduce a novel framework for\nlocal interventional explanations by leveraging recent advances in\nimage-to-image editing models. Our approach performs gradual interventions on\nsemantic properties to quantify the corresponding impact on a model's\npredictions using a novel score, the expected property gradient magnitude. We\ndemonstrate the effectiveness of our approach through an extensive empirical\nevaluation on a wide range of architectures and tasks. First, we validate it in\na synthetic scenario and demonstrate its ability to locally identify biases.\nAfterward, we apply our approach to analyze network training dynamics,\ninvestigate medical skin lesion classifiers, and study a pre-trained CLIP model\nwith real-life interventional data. Our results highlight the potential of\ninterventional explanations on the property level to reveal new insights into\nthe behavior of deep models.\n","authors":["Niklas Penzel","Joachim Denzler"],"pdf_url":"https://arxiv.org/pdf/2503.05424v1.pdf","comment":"44 pages, 39 figures, 14 tables"},{"id":"http://arxiv.org/abs/2503.05423v1","updated":"2025-03-07T13:50:29Z","published":"2025-03-07T13:50:29Z","title":"Semantic Shift Estimation via Dual-Projection and Classifier\n  Reconstruction for Exemplar-Free Class-Incremental Learning","summary":"  Exemplar-Free Class-Incremental Learning (EFCIL) aims to sequentially learn\nfrom distinct categories without retaining exemplars but easily suffers from\ncatastrophic forgetting of learned knowledge. While existing EFCIL methods\nleverage knowledge distillation to alleviate forgetting, they still face two\ncritical challenges: semantic shift and decision bias. Specifically, the\nembeddings of old tasks shift in the embedding space after learning new tasks,\nand the classifier becomes biased towards new tasks due to training solely with\nnew data, thereby hindering the balance between old and new knowledge. To\naddress these issues, we propose the Dual-Projection Shift Estimation and\nClassifier Reconstruction (DPCR) approach for EFCIL. DPCR effectively estimates\nsemantic shift through a dual-projection, which combines a learnable\ntransformation with a row-space projection to capture both task-wise and\ncategory-wise shifts. Furthermore, to mitigate decision bias, DPCR employs\nridge regression to reformulate classifier training as a reconstruction\nprocess. This reconstruction exploits previous information encoded in\ncovariance and prototype of each class after calibration with estimated shift,\nthereby reducing decision bias. Extensive experiments demonstrate that, across\nvarious datasets, DPCR effectively balances old and new tasks, outperforming\nstate-of-the-art EFCIL methods.\n","authors":["Run He","Di Fang","Yicheng Xu","Yawen Cui","Ming Li","Cen Chen","Ziqian Zeng","Huiping Zhuang"],"pdf_url":"https://arxiv.org/pdf/2503.05423v1.pdf","comment":"14 pages, 7 figures"},{"id":"http://arxiv.org/abs/2502.13593v2","updated":"2025-03-07T13:45:22Z","published":"2025-02-19T10:12:19Z","title":"Toward Robust Non-Transferable Learning: A Survey and Benchmark","summary":"  Over the past decades, researchers have primarily focused on improving the\ngeneralization abilities of models, with limited attention given to regulating\nsuch generalization. However, the ability of models to generalize to unintended\ndata (e.g., harmful or unauthorized data) can be exploited by malicious\nadversaries in unforeseen ways, potentially resulting in violations of model\nethics. Non-transferable learning (NTL), a task aimed at reshaping the\ngeneralization abilities of deep learning models, was proposed to address these\nchallenges. While numerous methods have been proposed in this field, a\ncomprehensive review of existing progress and a thorough analysis of current\nlimitations remain lacking. In this paper, we bridge this gap by presenting the\nfirst comprehensive survey on NTL and introducing NTLBench, the first benchmark\nto evaluate NTL performance and robustness within a unified framework.\nSpecifically, we first introduce the task settings, general framework, and\ncriteria of NTL, followed by a summary of NTL approaches. Furthermore, we\nemphasize the often-overlooked issue of robustness against various attacks that\ncan destroy the non-transferable mechanism established by NTL. Experiments\nconducted via NTLBench verify the limitations of existing NTL methods in\nrobustness. Finally, we discuss the practical applications of NTL, along with\nits future directions and associated challenges.\n","authors":["Ziming Hong","Yongli Xiang","Tongliang Liu"],"pdf_url":"https://arxiv.org/pdf/2502.13593v2.pdf","comment":"Code is available at https://github.com/tmllab/NTLBench"},{"id":"http://arxiv.org/abs/2503.05419v1","updated":"2025-03-07T13:45:06Z","published":"2025-03-07T13:45:06Z","title":"Physics-based machine learning for fatigue lifetime prediction under\n  non-uniform loading scenarios","summary":"  Accurate lifetime prediction of structures subjected to cyclic loading is\nvital, especially in scenarios involving non-uniform loading histories where\nload sequencing critically influences structural durability. Addressing this\ncomplexity requires advanced modeling approaches capable of capturing the\nintricate relationship between loading sequences and fatigue lifetime.\nTraditional fatigue simulations are computationally prohibitive, necessitating\nmore efficient methods. This study highlights the potential of physics-based\nmachine learning ($\\phi$ML) to predict the fatigue lifetime of materials.\nSpecifically, a FFNN is designed to embed physical constraints from\nexperimental evidence directly into its architecture to enhance prediction\naccuracy. It is trained using numerical simulations generated by a physically\nbased anisotropic continuum damage fatigue model. The model is calibrated and\nvalidated against experimental fatigue data of concrete cylinder specimens\ntested in uniaxial compression. The proposed approach demonstrates superior\naccuracy compared to purely data-driven neural networks, particularly in\nsituations with limited training data, achieving realistic predictions of\ndamage accumulation. Thus, a general algorithm is developed and successfully\napplied to predict fatigue lifetimes under complex loading scenarios with\nmultiple loading ranges. Hereby, the $\\phi$ML model serves as a surrogate to\ncapture damage evolution across load transitions. The $\\phi$ML based algorithm\nis subsequently employed to investigate the influence of multiple loading\ntransitions on accumulated fatigue life, and its predictions align with trends\nobserved in recent experimental studies. This work demonstrates $\\phi$ML as a\npromising technique for efficient and reliable fatigue life prediction in\nengineering structures, with possible integration into digital twin models for\nreal-time assessment.\n","authors":["Abedulgader Baktheer","Fadi Aldakheel"],"pdf_url":"https://arxiv.org/pdf/2503.05419v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2402.03467v2","updated":"2025-03-07T13:43:19Z","published":"2024-02-02T14:29:38Z","title":"Stochastic Modified Flows for Riemannian Stochastic Gradient Descent","summary":"  We give quantitative estimates for the rate of convergence of Riemannian\nstochastic gradient descent (RSGD) to Riemannian gradient flow and to a\ndiffusion process, the so-called Riemannian stochastic modified flow (RSMF).\nUsing tools from stochastic differential geometry we show that, in the small\nlearning rate regime, RSGD can be approximated by the solution to the RSMF\ndriven by an infinite-dimensional Wiener process. The RSMF accounts for the\nrandom fluctuations of RSGD and, thereby, increases the order of approximation\ncompared to the deterministic Riemannian gradient flow. The RSGD is build using\nthe concept of a retraction map, that is, a cost efficient approximation of the\nexponential map, and we prove quantitative bounds for the weak error of the\ndiffusion approximation under assumptions on the retraction map, the geometry\nof the manifold, and the random estimators of the gradient.\n","authors":["Benjamin Gess","Sebastian Kassing","Nimit Rana"],"pdf_url":"https://arxiv.org/pdf/2402.03467v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2405.09787v2","updated":"2025-03-07T13:25:18Z","published":"2024-05-16T03:23:57Z","title":"Analysis of the BraTS 2023 Intracranial Meningioma Segmentation\n  Challenge","summary":"  We describe the design and results from the BraTS 2023 Intracranial\nMeningioma Segmentation Challenge. The BraTS Meningioma Challenge differed from\nprior BraTS Glioma challenges in that it focused on meningiomas, which are\ntypically benign extra-axial tumors with diverse radiologic and anatomical\npresentation and a propensity for multiplicity. Nine participating teams each\ndeveloped deep-learning automated segmentation models using image data from the\nlargest multi-institutional systematically expert annotated multilabel\nmulti-sequence meningioma MRI dataset to date, which included 1000 training set\ncases, 141 validation set cases, and 283 hidden test set cases. Each case\nincluded T2, FLAIR, T1, and T1Gd brain MRI sequences with associated tumor\ncompartment labels delineating enhancing tumor, non-enhancing tumor, and\nsurrounding non-enhancing FLAIR hyperintensity. Participant automated\nsegmentation models were evaluated and ranked based on a scoring system\nevaluating lesion-wise metrics including dice similarity coefficient (DSC) and\n95% Hausdorff Distance. The top ranked team had a lesion-wise median dice\nsimilarity coefficient (DSC) of 0.976, 0.976, and 0.964 for enhancing tumor,\ntumor core, and whole tumor, respectively and a corresponding average DSC of\n0.899, 0.904, and 0.871, respectively. These results serve as state-of-the-art\nbenchmarks for future pre-operative meningioma automated segmentation\nalgorithms. Additionally, we found that 1286 of 1424 cases (90.3%) had at least\n1 compartment voxel abutting the edge of the skull-stripped image edge, which\nrequires further investigation into optimal pre-processing face anonymization\nsteps.\n","authors":["Dominic LaBella","Ujjwal Baid","Omaditya Khanna","Shan McBurney-Lin","Ryan McLean","Pierre Nedelec","Arif Rashid","Nourel Hoda Tahon","Talissa Altes","Radhika Bhalerao","Yaseen Dhemesh","Devon Godfrey","Fathi Hilal","Scott Floyd","Anastasia Janas","Anahita Fathi Kazerooni","John Kirkpatrick","Collin Kent","Florian Kofler","Kevin Leu","Nazanin Maleki","Bjoern Menze","Maxence Pajot","Zachary J. Reitman","Jeffrey D. Rudie","Rachit Saluja","Yury Velichko","Chunhao Wang","Pranav Warman","Maruf Adewole","Jake Albrecht","Udunna Anazodo","Syed Muhammad Anwar","Timothy Bergquist","Sully Francis Chen","Verena Chung","Rong Chai","Gian-Marco Conte","Farouk Dako","James Eddy","Ivan Ezhov","Nastaran Khalili","Juan Eugenio Iglesias","Zhifan Jiang","Elaine Johanson","Koen Van Leemput","Hongwei Bran Li","Marius George Linguraru","Xinyang Liu","Aria Mahtabfar","Zeke Meier","Ahmed W. Moawad","John Mongan","Marie Piraud","Russell Takeshi Shinohara","Walter F. Wiggins","Aly H. Abayazeed","Rachel Akinola","Andrs Jakab","Michel Bilello","Maria Correia de Verdier","Priscila Crivellaro","Christos Davatzikos","Keyvan Farahani","John Freymann","Christopher Hess","Raymond Huang","Philipp Lohmann","Mana Moassefi","Matthew W. Pease","Phillipp Vollmuth","Nico Sollmann","David Diffley","Khanak K. Nandolia","Daniel I. Warren","Ali Hussain","Pascal Fehringer","Yulia Bronstein","Lisa Deptula","Evan G. Stein","Mahsa Taherzadeh","Eduardo Portela de Oliveira","Aoife Haughey","Marinos Kontzialis","Luca Saba","Benjamin Turner","Melanie M. T. Breler","Shehbaz Ansari","Athanasios Gkampenis","David Maximilian Weiss","Aya Mansour","Islam H. Shawali","Nikolay Yordanov","Joel M. Stein","Roula Hourani","Mohammed Yahya Moshebah","Ahmed Magdy Abouelatta","Tanvir Rizvi","Klara Willms","Dann C. Martin","Abdullah Okar","Gennaro D'Anna","Ahmed Taha","Yasaman Sharifi","Shahriar Faghani","Dominic Kite","Marco Pinho","Muhammad Ammar Haider","Alejandro Aristizabal","Alexandros Karargyris","Hasan Kassem","Sarthak Pati","Micah Sheller","Michelle Alonso-Basanta","Javier Villanueva-Meyer","Andreas M. Rauschecker","Ayman Nada","Mariam Aboian","Adam E. Flanders","Benedikt Wiestler","Spyridon Bakas","Evan Calabrese"],"pdf_url":"https://arxiv.org/pdf/2405.09787v2.pdf","comment":"Accepted for publication at the Journal of Machine Learning for\n  Biomedical Imaging (MELBA) https://melba-journal.org/2025:003 22 pages, 6\n  tables, 12 figures, MICCAI, MELBA"},{"id":"http://arxiv.org/abs/2503.05379v1","updated":"2025-03-07T12:46:42Z","published":"2025-03-07T12:46:42Z","title":"R1-Omni: Explainable Omni-Multimodal Emotion Recognition with\n  Reinforcing Learning","summary":"  In this work, we present the first application of Reinforcement Learning with\nVerifiable Reward (RLVR) to an Omni-multimodal large language model in the\ncontext of emotion recognition, a task where both visual and audio modalities\nplay crucial roles. We leverage RLVR to optimize the Omni model, significantly\nenhancing its performance in three key aspects: reasoning capability, emotion\nrecognition accuracy, and generalization ability. The introduction of RLVR not\nonly improves the model's overall performance on in-distribution data but also\ndemonstrates superior robustness when evaluated on out-of-distribution\ndatasets. More importantly, the improved reasoning capability enables clear\nanalysis of the contributions of different modalities, particularly visual and\naudio information, in the emotion recognition process. This provides valuable\ninsights into the optimization of multimodal large language models.\n","authors":["Jiaxing Zhao","Xihan Wei","Liefeng Bo"],"pdf_url":"https://arxiv.org/pdf/2503.05379v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2406.05053v2","updated":"2025-03-07T12:46:14Z","published":"2024-06-07T16:22:51Z","title":"Hints-In-Browser: Benchmarking Language Models for Programming Feedback\n  Generation","summary":"  Generative AI and large language models hold great promise in enhancing\nprogramming education by generating individualized feedback and hints for\nlearners. Recent works have primarily focused on improving the quality of\ngenerated feedback to achieve human tutors' quality. While quality is an\nimportant performance criterion, it is not the only criterion to optimize for\nreal-world educational deployments. In this paper, we benchmark language models\nfor programming feedback generation across several performance criteria,\nincluding quality, cost, time, and data privacy. The key idea is to leverage\nrecent advances in the new paradigm of in-browser inference that allow running\nthese models directly in the browser, thereby providing direct benefits across\ncost and data privacy. To boost the feedback quality of small models compatible\nwith in-browser inference engines, we develop a fine-tuning pipeline based on\nGPT-4 generated synthetic data. We showcase the efficacy of fine-tuned\nLlama3-8B and Phi3-3.8B 4-bit quantized models using WebLLM's in-browser\ninference engine on three different Python programming datasets. We will\nrelease the full implementation along with a web app and datasets to facilitate\nfurther research on in-browser language models.\n","authors":["Nachiket Kotalwar","Alkis Gotovos","Adish Singla"],"pdf_url":"https://arxiv.org/pdf/2406.05053v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2308.01196v3","updated":"2025-03-07T12:31:27Z","published":"2023-07-27T22:57:55Z","title":"Sustainable transparency in Recommender Systems: Bayesian Ranking of\n  Images for Explainability","summary":"  Recommender Systems have become crucial in the modern world, commonly guiding\nusers towards relevant content or products, and having a large influence over\nthe decisions of users and citizens. However, ensuring transparency and user\ntrust in these systems remains a challenge; personalized explanations have\nemerged as a solution, offering justifications for recommendations. Among the\nexisting approaches for generating personalized explanations, using existing\nvisual content created by users is a promising option to maximize transparency\nand user trust. State-of-the-art models that follow this approach, despite\nleveraging highly optimized architectures, employ surrogate learning tasks that\ndo not efficiently model the objective of ranking images as explanations for a\ngiven recommendation; this leads to a suboptimal training process with high\ncomputational costs that may not be reduced without affecting model\nperformance. This work presents BRIE, a novel model where we leverage Bayesian\nPairwise Ranking to enhance the training process, allowing us to consistently\noutperform state-of-the-art models in six real-world datasets while reducing\nits model size by up to 64 times and its CO2 emissions by up to 75% in training\nand inference.\n","authors":["Jorge Paz-Ruza","Amparo Alonso-Betanzos","Berta Guijarro-Berdias","Brais Cancela","Carlos Eiras-Franco"],"pdf_url":"https://arxiv.org/pdf/2308.01196v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2405.01614v2","updated":"2025-03-07T12:31:27Z","published":"2024-05-02T16:17:29Z","title":"RULSurv: A probabilistic survival-based method for early censoring-aware\n  prediction of remaining useful life in ball bearings","summary":"  Censored data refers to situations where the full information about a\nparticular event or process is only partially known. In survival analysis,\ncensoring plays an important role, as ignoring such observations can bias the\nmodel parameters and overestimate the probability of when the event is likely\nto occur. There has been a renewed interest in using data-driven methods to\npredict the remaining useful life (RUL) of ball bearings for predictive\nmaintenance. However, few studies have explicitly addressed the challenge of\nhandling censored data. To address this issue, we introduce a novel and\nflexible method for early fault detection using Kullback-Leibler (KL)\ndivergence and RUL estimation using survival analysis that naturally supports\ncensored data. We demonstrate our approach in the XJTU-SY dataset using a\n5-fold cross-validation across three different operating conditions. When\npredicting the time to failure for bearings under the highest load (C1, 12.0 kN\nand 2100 RPM) with 25\\% random censoring, our approach achieves a mean absolute\nerror (MAE) of 14.7 minutes (95\\% CI 13.6-15.8) using a linear CoxPH model, and\nan MAE of 12.6 minutes (95\\% CI 11.8-13.4) using a nonlinear Random Survival\nForests model, compared to an MAE of 18.5 minutes (95\\% 17.4-19.6) using a\nlinear LASSO model that does not support censoring. Moreover, our approach\nachieves a mean cumulative relative accuracy (CRA) of 0.7586 over 5 bearings\nunder the highest load, which improves over several state-of-the-art baselines.\nOur work highlights the importance of considering censored observations as part\nof the model design when building predictive models for early fault detection\nand RUL estimation.\n","authors":["Christian Marius Lillelund","Fernando Pannullo","Morten Opprud Jakobsen","Manuel Morante","Christian Fischer Pedersen"],"pdf_url":"https://arxiv.org/pdf/2405.01614v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.05371v1","updated":"2025-03-07T12:25:29Z","published":"2025-03-07T12:25:29Z","title":"Shifting Perspectives: Steering Vector Ensembles for Robust Bias\n  Mitigation in LLMs","summary":"  We present a novel approach to bias mitigation in large language models\n(LLMs) by applying steering vectors to modify model activations in forward\npasses. We employ Bayesian optimization to systematically identify effective\ncontrastive pair datasets across nine bias axes. When optimized on the BBQ\ndataset, our individually tuned steering vectors achieve average improvements\nof 12.2%, 4.7%, and 3.2% over the baseline for Mistral, Llama, and Qwen,\nrespectively. Building on these promising results, we introduce Steering Vector\nEnsembles (SVE), a method that averages multiple individually optimized\nsteering vectors, each targeting a specific bias axis such as age, race, or\ngender. By leveraging their collective strength, SVE outperforms individual\nsteering vectors in both bias reduction and maintaining model performance. The\nwork presents the first systematic investigation of steering vectors for bias\nmitigation, and we demonstrate that SVE is a powerful and computationally\nefficient strategy for reducing bias in LLMs, with broader implications for\nenhancing AI safety.\n","authors":["Zara Siddique","Irtaza Khalid","Liam D. Turner","Luis Espinosa-Anke"],"pdf_url":"https://arxiv.org/pdf/2503.05371v1.pdf","comment":"Submitted to ACL 2025"},{"id":"http://arxiv.org/abs/2406.09898v2","updated":"2025-03-07T12:25:03Z","published":"2024-06-14T10:14:01Z","title":"Positive-Unlabelled Learning for identifying new candidate Dietary\n  Restriction-related genes among Ageing-related genes","summary":"  Dietary Restriction (DR) is one of the most popular anti-ageing\ninterventions; recently, Machine Learning (ML) has been explored to identify\npotential DR-related genes among ageing-related genes, aiming to minimize\ncostly wet lab experiments needed to expand our knowledge on DR. However, to\ntrain a model from positive (DR-related) and negative (non-DR-related)\nexamples, the existing ML approach naively labels genes without known DR\nrelation as negative examples, assuming that lack of DR-related annotation for\na gene represents evidence of absence of DR-relatedness, rather than absence of\nevidence. This hinders the reliability of the negative examples (non-DR-related\ngenes) and the method's ability to identify novel DR-related genes. This work\nintroduces a novel gene prioritisation method based on the two-step\nPositive-Unlabelled (PU) Learning paradigm: using a similarity-based,\nKNN-inspired approach, our method first selects reliable negative examples\namong the genes without known DR associations. Then, these reliable negatives\nand all known positives are used to train a classifier that effectively\ndifferentiates DR-related and non-DR-related genes, which is finally employed\nto generate a more reliable ranking of promising genes for novel\nDR-relatedness. Our method significantly outperforms (p<0.05) the existing\nstate-of-the-art approach in three predictive accuracy metrics with up to 40%\nlower computational cost in the best case, and we identify 4 new promising\nDR-related genes (PRKAB1, PRKAB2, IRS2, PRKAG1), all with evidence from the\nexisting literature supporting their potential DR-related role.\n","authors":["Jorge Paz-Ruza","Alex A. Freitas","Amparo Alonso-Betanzos","Bertha Guijarro-Berdias"],"pdf_url":"https://arxiv.org/pdf/2406.09898v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.05367v1","updated":"2025-03-07T12:21:09Z","published":"2025-03-07T12:21:09Z","title":"Semi-Supervised Learning for Dose Prediction in Targeted Radionuclide: A\n  Synthetic Data Study","summary":"  Targeted Radionuclide Therapy (TRT) is a modern strategy in radiation\noncology that aims to administer a potent radiation dose specifically to cancer\ncells using cancer-targeting radiopharmaceuticals. Accurate radiation dose\nestimation tailored to individual patients is crucial. Deep learning,\nparticularly with pre-therapy imaging, holds promise for personalizing TRT\ndoses. However, current methods require large time series of SPECT imaging,\nwhich is hardly achievable in routine clinical practice, and thus raises issues\nof data availability. Our objective is to develop a semi-supervised learning\n(SSL) solution to personalize dosimetry using pre-therapy images. The aim is to\ndevelop an approach that achieves accurate results when PET/CT images are\navailable, but are associated with only a few post-therapy dosimetry data\nprovided by SPECT images. In this work, we introduce an SSL method using a\npseudo-label generation approach for regression tasks inspired by the FixMatch\nframework. The feasibility of the proposed solution was preliminarily evaluated\nthrough an in-silico study using synthetic data and Monte Carlo simulation.\nExperimental results for organ dose prediction yielded promising outcomes,\nshowing that the use of pseudo-labeled data provides better accuracy compared\nto using only labeled data.\n","authors":["Jing Zhang","Alexandre Bousse","Laetitia Imbert","Song Xue","Kuangyu Shi","Julien Bert"],"pdf_url":"https://arxiv.org/pdf/2503.05367v1.pdf","comment":"12 pages, 13 figures, 5 tables"},{"id":"http://arxiv.org/abs/2410.04263v2","updated":"2025-03-07T12:18:32Z","published":"2024-10-05T18:52:54Z","title":"DeFoG: Discrete Flow Matching for Graph Generation","summary":"  Graph generative models are essential across diverse scientific domains by\ncapturing complex distributions over relational data. Among them, graph\ndiffusion models achieve superior performance but face inefficient sampling and\nlimited flexibility due to the tight coupling between training and sampling\nstages. We introduce DeFoG, a novel graph generative framework that\ndisentangles sampling from training, enabling a broader design space for more\neffective and efficient model optimization. DeFoG employs a discrete\nflow-matching formulation that respects the inherent symmetries of graphs. We\ntheoretically ground this disentangled formulation by explicitly relating the\ntraining loss to the sampling algorithm and showing that DeFoG faithfully\nreplicates the ground truth graph distribution. Building on these foundations,\nwe thoroughly investigate DeFoG's design space and propose novel sampling\nmethods that significantly enhance performance and reduce the required number\nof refinement steps. Extensive experiments demonstrate state-of-the-art\nperformance across synthetic, molecular, and digital pathology datasets,\ncovering both unconditional and conditional generation settings. It also\noutperforms most diffusion-based models with just 5-10% of their sampling\nsteps.\n","authors":["Yiming Qin","Manuel Madeira","Dorina Thanou","Pascal Frossard"],"pdf_url":"https://arxiv.org/pdf/2410.04263v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.05357v1","updated":"2025-03-07T12:01:02Z","published":"2025-03-07T12:01:02Z","title":"Improving Hate Speech Classification with Cross-Taxonomy Dataset\n  Integration","summary":"  Algorithmic hate speech detection faces significant challenges due to the\ndiverse definitions and datasets used in research and practice. Social media\nplatforms, legal frameworks, and institutions each apply distinct yet\noverlapping definitions, complicating classification efforts. This study\naddresses these challenges by demonstrating that existing datasets and\ntaxonomies can be integrated into a unified model, enhancing prediction\nperformance and reducing reliance on multiple specialized classifiers. The work\nintroduces a universal taxonomy and a hate speech classifier capable of\ndetecting a wide range of definitions within a single framework. Our approach\nis validated by combining two widely used but differently annotated datasets,\nshowing improved classification performance on an independent test set. This\nwork highlights the potential of dataset and taxonomy integration in advancing\nhate speech detection, increasing efficiency, and ensuring broader\napplicability across contexts.\n","authors":["Jan Fillies","Adrian Paschke"],"pdf_url":"https://arxiv.org/pdf/2503.05357v1.pdf","comment":"Accepted for publication at LaTeCH-CLfL 2025. The 9th Joint ACL\n  Special Interest Group on Language Technologies for the Socio-Economic\n  Sciences and Humanities (SIGHUM) Workshop on Computational Linguistics for\n  Cultural Heritage, Social Sciences, Humanities and Literature"},{"id":"http://arxiv.org/abs/2310.17332v2","updated":"2025-03-07T11:58:06Z","published":"2023-10-26T11:55:30Z","title":"On Forecast Stability","summary":"  Forecasts are typically not produced in a vacuum but in a business context,\nwhere forecasts are generated on a regular basis and interact with each other.\nFor decisions, it may be important that forecasts do not change arbitrarily,\nand are stable in some sense. However, this area has received only limited\nattention in the forecasting literature. In this paper, we explore two types of\nforecast stability that we call vertical stability and horizontal stability.\nThe existing works in the literature are only applicable to certain base models\nand extending these frameworks to be compatible with any base model is not\nstraightforward. Furthermore, these frameworks can only stabilise the forecasts\nvertically. To fill this gap, we propose a simple linear-interpolation-based\napproach that is applicable to stabilise the forecasts provided by any base\nmodel vertically and horizontally. The approach can produce both accurate and\nstable forecasts. Using N-BEATS, Pooled Regression and LightGBM as the base\nmodels, in our evaluation on four publicly available datasets, the proposed\nframework is able to achieve significantly higher stability and/or accuracy\ncompared to a set of benchmarks including a state-of-the-art forecast\nstabilisation method across three error metrics and six stability metrics.\n","authors":["Rakshitha Godahewa","Christoph Bergmeir","Zeynep Erkin Baz","Chengjun Zhu","Zhangdi Song","Salvador Garca","Dario Benavides"],"pdf_url":"https://arxiv.org/pdf/2310.17332v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.05349v1","updated":"2025-03-07T11:44:49Z","published":"2025-03-07T11:44:49Z","title":"Spatial Distillation based Distribution Alignment (SDDA) for\n  Cross-Headset EEG Classification","summary":"  A non-invasive brain-computer interface (BCI) enables direct interaction\nbetween the user and external devices, typically via electroencephalogram (EEG)\nsignals. However, decoding EEG signals across different headsets remains a\nsignificant challenge due to differences in the number and locations of the\nelectrodes. To address this challenge, we propose a spatial distillation based\ndistribution alignment (SDDA) approach for heterogeneous cross-headset transfer\nin non-invasive BCIs. SDDA uses first spatial distillation to make use of the\nfull set of electrodes, and then input/feature/output space distribution\nalignments to cope with the significant differences between the source and\ntarget domains. To our knowledge, this is the first work to use knowledge\ndistillation in cross-headset transfers. Extensive experiments on six EEG\ndatasets from two BCI paradigms demonstrated that SDDA achieved superior\nperformance in both offline unsupervised domain adaptation and online\nsupervised domain adaptation scenarios, consistently outperforming 10 classical\nand state-of-the-art transfer learning algorithms.\n","authors":["Dingkun Liu","Siyang Li","Ziwei Wang","Wei Li","Dongrui Wu"],"pdf_url":"https://arxiv.org/pdf/2503.05349v1.pdf","comment":"10 pages, 5 figures"},{"id":"http://arxiv.org/abs/2503.05336v1","updated":"2025-03-07T11:23:48Z","published":"2025-03-07T11:23:48Z","title":"Toward an Evaluation Science for Generative AI Systems","summary":"  There is an increasing imperative to anticipate and understand the\nperformance and safety of generative AI systems in real-world deployment\ncontexts. However, the current evaluation ecosystem is insufficient: Commonly\nused static benchmarks face validity challenges, and ad hoc case-by-case audits\nrarely scale. In this piece, we advocate for maturing an evaluation science for\ngenerative AI systems. While generative AI creates unique challenges for system\nsafety engineering and measurement science, the field can draw valuable\ninsights from the development of safety evaluation practices in other fields,\nincluding transportation, aerospace, and pharmaceutical engineering. In\nparticular, we present three key lessons: Evaluation metrics must be applicable\nto real-world performance, metrics must be iteratively refined, and evaluation\ninstitutions and norms must be established. Applying these insights, we outline\na concrete path toward a more rigorous approach for evaluating generative AI\nsystems.\n","authors":["Laura Weidinger","Deb Raji","Hanna Wallach","Margaret Mitchell","Angelina Wang","Olawale Salaudeen","Rishi Bommasani","Sayash Kapoor","Deep Ganguli","Sanmi Koyejo","William Isaac"],"pdf_url":"https://arxiv.org/pdf/2503.05336v1.pdf","comment":"First two authors contributed equally to this work"},{"id":"http://arxiv.org/abs/2310.08944v3","updated":"2025-03-07T11:23:19Z","published":"2023-10-13T08:19:31Z","title":"A Confidence-based Acquisition Model for Self-supervised Active Learning\n  and Label Correction","summary":"  Supervised neural approaches are hindered by their dependence on large,\nmeticulously annotated datasets, a requirement that is particularly cumbersome\nfor sequential tasks. The quality of annotations tends to deteriorate with the\ntransition from expert-based to crowd-sourced labelling. To address these\nchallenges, we present CAMEL (Confidence-based Acquisition Model for Efficient\nself-supervised active Learning), a pool-based active learning framework\ntailored to sequential multi-output problems. CAMEL possesses two core\nfeatures: (1) it requires expert annotators to label only a fraction of a\nchosen sequence, and (2) it facilitates self-supervision for the remainder of\nthe sequence. By deploying a label correction mechanism, CAMEL can also be\nutilised for data cleaning. We evaluate CAMEL on two sequential tasks, with a\nspecial emphasis on dialogue belief tracking, a task plagued by the constraints\nof limited and noisy datasets. Our experiments demonstrate that CAMEL\nsignificantly outperforms the baselines in terms of efficiency. Furthermore,\nthe data corrections suggested by our method contribute to an overall\nimprovement in the quality of the resulting datasets.\n","authors":["Carel van Niekerk","Christian Geishauser","Michael Heck","Shutong Feng","Hsien-chin Lin","Nurul Lubis","Benjamin Ruppik","Renato Vukovic","Milica Gai"],"pdf_url":"https://arxiv.org/pdf/2310.08944v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2412.15429v3","updated":"2025-03-07T11:20:12Z","published":"2024-12-19T22:29:03Z","title":"Offline Safe Reinforcement Learning Using Trajectory Classification","summary":"  Offline safe reinforcement learning (RL) has emerged as a promising approach\nfor learning safe behaviors without engaging in risky online interactions with\nthe environment. Most existing methods in offline safe RL rely on cost\nconstraints at each time step (derived from global cost constraints) and this\ncan result in either overly conservative policies or violation of safety\nconstraints. In this paper, we propose to learn a policy that generates\ndesirable trajectories and avoids undesirable trajectories. To be specific, we\nfirst partition the pre-collected dataset of state-action trajectories into\ndesirable and undesirable subsets. Intuitively, the desirable set contains high\nreward and safe trajectories, and undesirable set contains unsafe trajectories\nand low-reward safe trajectories. Second, we learn a policy that generates\ndesirable trajectories and avoids undesirable trajectories, where\n(un)desirability scores are provided by a classifier learnt from the dataset of\ndesirable and undesirable trajectories. This approach bypasses the\ncomputational complexity and stability issues of a min-max objective that is\nemployed in existing methods. Theoretically, we also show our approach's strong\nconnections to existing learning paradigms involving human feedback. Finally,\nwe extensively evaluate our method using the DSRL benchmark for offline safe\nRL. Empirically, our method outperforms competitive baselines, achieving higher\nrewards and better constraint satisfaction across a wide variety of benchmark\ntasks.\n","authors":["Ze Gong","Akshat Kumar","Pradeep Varakantham"],"pdf_url":"https://arxiv.org/pdf/2412.15429v3.pdf","comment":"AAAI 2025"},{"id":"http://arxiv.org/abs/2308.14352v2","updated":"2025-03-07T11:16:40Z","published":"2023-08-28T06:56:08Z","title":"EdgeMoE: Empowering Sparse Large Language Models on Mobile Devices","summary":"  Large language models (LLMs) such as GPTs and Mixtral-8x7B have\nrevolutionized machine intelligence due to their exceptional abilities in\ngeneric ML tasks. Transiting LLMs from datacenters to edge devices brings\nbenefits like better privacy and availability, but is challenged by their\nmassive parameter size and thus unbearable runtime costs. To this end, we\npresent EdgeMoE, an on-device inference engine for mixture-of-expert (MoE) LLMs\n-- a popular form of sparse LLM that scales its parameter size with almost\nconstant computing complexity. EdgeMoE achieves both memory- and\ncompute-efficiency by partitioning the model into the storage hierarchy:\nnon-expert weights are held in device memory; while expert weights are held on\nexternal storage and fetched to memory only when activated. This design is\nmotivated by a key observation that expert weights are bulky but infrequently\nused due to sparse activation. To further reduce the expert I/O swapping\noverhead, EdgeMoE incorporates two novel techniques: (1) expert-wise bitwidth\nadaptation that reduces the expert sizes with tolerable accuracy loss; (2)\nexpert preloading that predicts the activated experts ahead of time and\npreloads it with the compute-I/O pipeline. On popular MoE LLMs and edge\ndevices, EdgeMoE showcase significant memory savings and speedup over\ncompetitive baselines. The code is available at\nhttps://github.com/UbiquitousLearning/mllm.\n","authors":["Rongjie Yi","Liwei Guo","Shiyun Wei","Ao Zhou","Shangguang Wang","Mengwei Xu"],"pdf_url":"https://arxiv.org/pdf/2308.14352v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2408.02361v2","updated":"2025-03-07T11:12:17Z","published":"2024-08-05T10:10:01Z","title":"Dialogue Ontology Relation Extraction via Constrained Chain-of-Thought\n  Decoding","summary":"  State-of-the-art task-oriented dialogue systems typically rely on\ntask-specific ontologies for fulfilling user queries. The majority of\ntask-oriented dialogue data, such as customer service recordings, comes without\nontology and annotation. Such ontologies are normally built manually, limiting\nthe application of specialised systems. Dialogue ontology construction is an\napproach for automating that process and typically consists of two steps: term\nextraction and relation extraction. In this work, we focus on relation\nextraction in a transfer learning set-up. To improve the generalisation, we\npropose an extension to the decoding mechanism of large language models. We\nadapt Chain-of-Thought (CoT) decoding, recently developed for reasoning\nproblems, to generative relation extraction. Here, we generate multiple\nbranches in the decoding space and select the relations based on a confidence\nthreshold. By constraining the decoding to ontology terms and relations, we aim\nto decrease the risk of hallucination. We conduct extensive experimentation on\ntwo widely used datasets and find improvements in performance on target\nontology for source fine-tuned and one-shot prompted large language models.\n","authors":["Renato Vukovic","David Arps","Carel van Niekerk","Benjamin Matthias Ruppik","Hsien-Chin Lin","Michael Heck","Milica Gai"],"pdf_url":"https://arxiv.org/pdf/2408.02361v2.pdf","comment":"Accepted to appear at SIGDIAL 2024. 9 pages, 4 figures"},{"id":"http://arxiv.org/abs/2503.05324v1","updated":"2025-03-07T11:02:17Z","published":"2025-03-07T11:02:17Z","title":"Routing for Large ML Models","summary":"  Training large language models (LLMs), and other large machine learning\nmodels, involves repeated communication of large volumes of data across a data\ncenter network. The communication patterns induced by these training process\nexhibit high regularity and persistence, giving rise to significant\nopportunities for optimizing the manner in which flows are routed across the\nnetwork. We present an algorithmic framework for \\textit{quantifying}\nnetwork-wide efficiency in the context of training LLMs (and other large-scale\nML models), and for periodically \\textit{optimizing} routing with respect to\nthis global metric.\n","authors":["Ofir Cohen","Jose Yallouz Michael Schapira","Shahar Belkar","Tal Mizrahi"],"pdf_url":"https://arxiv.org/pdf/2503.05324v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.05323v1","updated":"2025-03-07T11:01:35Z","published":"2025-03-07T11:01:35Z","title":"Graph Alignment via Birkhoff Relaxation","summary":"  We consider the graph alignment problem, wherein the objective is to find a\nvertex correspondence between two graphs that maximizes the edge overlap. The\ngraph alignment problem is an instance of the quadratic assignment problem\n(QAP), known to be NP-hard in the worst case even to approximately solve. In\nthis paper, we analyze Birkhoff relaxation, a tight convex relaxation of QAP,\nand present theoretical guarantees on its performance when the inputs follow\nthe Gaussian Wigner Model. More specifically, the weighted adjacency matrices\nare correlated Gaussian Orthogonal Ensemble with correlation\n$1/\\sqrt{1+\\sigma^2}$. Denote the optimal solutions of the QAP and Birkhoff\nrelaxation by $\\Pi^\\star$ and $X^\\star$ respectively. We show that\n$\\|X^\\star-\\Pi^\\star\\|_F^2 = o(n)$ when $\\sigma = o(n^{-1.25})$ and\n$\\|X^\\star-\\Pi^\\star\\|_F^2 = \\Omega(n)$ when $\\sigma = \\Omega(n^{-0.5})$. Thus,\nthe optimal solution $X^\\star$ transitions from a small perturbation of\n$\\Pi^\\star$ for small $\\sigma$ to being well separated from $\\Pi^\\star$ as\n$\\sigma$ becomes larger than $n^{-0.5}$. This result allows us to guarantee\nthat simple rounding procedures on $X^\\star$ align $1-o(1)$ fraction of\nvertices correctly whenever $\\sigma = o(n^{-1.25})$. This condition on $\\sigma$\nto ensure the success of the Birkhoff relaxation is state-of-the-art.\n","authors":["Sushil Mahavir Varma","Irne Waldspurger","Laurent Massouli"],"pdf_url":"https://arxiv.org/pdf/2503.05323v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.05321v1","updated":"2025-03-07T11:00:29Z","published":"2025-03-07T11:00:29Z","title":"Riemannian Metric Learning: Closer to You than You Imagine","summary":"  Riemannian metric learning is an emerging field in machine learning,\nunlocking new ways to encode complex data structures beyond traditional\ndistance metric learning. While classical approaches rely on global distances\nin Euclidean space, they often fall short in capturing intrinsic data geometry.\nEnter Riemannian metric learning: a powerful generalization that leverages\ndifferential geometry to model the data according to their underlying\nRiemannian manifold. This approach has demonstrated remarkable success across\ndiverse domains, from causal inference and optimal transport to generative\nmodeling and representation learning. In this review, we bridge the gap between\nclassical metric learning and Riemannian geometry, providing a structured and\naccessible overview of key methods, applications, and recent advances. We argue\nthat Riemannian metric learning is not merely a technical refinement but a\nfundamental shift in how we think about data representations. Thus, this review\nshould serve as a valuable resource for researchers and practitioners\ninterested in exploring Riemannian metric learning and convince them that it is\ncloser to them than they might imagine-both in theory and in practice.\n","authors":["Samuel Gruffaz","Josua Sassen"],"pdf_url":"https://arxiv.org/pdf/2503.05321v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.05320v1","updated":"2025-03-07T11:00:24Z","published":"2025-03-07T11:00:24Z","title":"Disentangling Task Interference within Neurons: Model Merging in\n  Alignment with Neuronal Mechanisms","summary":"  Fine-tuning pre-trained models on targeted datasets enhances task-specific\nperformance but often comes at the expense of generalization. Model merging\ntechniques, which integrate multiple fine-tuned models into a single multi-task\nmodel through task arithmetic at various levels: model, layer, or parameter,\noffer a promising solution. However, task interference remains a fundamental\nchallenge, leading to performance degradation and suboptimal merged models.\nExisting approaches largely overlook the fundamental role of individual neurons\nand their connectivity, resulting in a lack of interpretability in both the\nmerging process and the merged models. In this work, we present the first study\non the impact of neuronal alignment in model merging. We decompose\ntask-specific representations into two complementary neuronal subspaces that\nregulate neuron sensitivity and input adaptability. Leveraging this\ndecomposition, we introduce NeuroMerging, a novel merging framework developed\nto mitigate task interference within neuronal subspaces, enabling training-free\nmodel fusion across diverse tasks. Through extensive experiments, we\ndemonstrate that NeuroMerging achieves superior performance compared to\nexisting methods on multi-task benchmarks across both vision and natural\nlanguage domains. Our findings highlight the importance of aligning neuronal\nmechanisms in model merging, offering new insights into mitigating task\ninterference and improving knowledge fusion.\n","authors":["Zitao Fang","Guodong DU","Shuyang Yu","Yifei Guo","Yiwei Zhang","Jing Li","Ho-Kin Tang","Sim Kuan Goh"],"pdf_url":"https://arxiv.org/pdf/2503.05320v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2412.05657v2","updated":"2025-03-07T10:55:23Z","published":"2024-12-07T14:02:57Z","title":"Long-Term Auto-Regressive Prediction using Lightweight AI Models:\n  Adams-Bashforth Time Integration with Adaptive Multi-Step Rollout","summary":"  This study addresses the critical challenge of error accumulation in\nspatio-temporal auto-regressive predictions within scientific machine learning\nmodels by introducing innovative temporal integration schemes and adaptive\nmulti-step rollout strategies. We present a comprehensive analysis of time\nintegration methods, highlighting the adaptation of the two-step\nAdams-Bashforth scheme to enhance long-term prediction robustness in\nauto-regressive models. Additionally, we improve temporal prediction accuracy\nthrough a multi-step rollout strategy that incorporates multiple future time\nsteps during training, supported by three newly proposed approaches that\ndynamically adjust the importance of each future step. Despite using an\nextremely lightweight graph neural network with just 1,177 trainable parameters\nand training on only 50 snapshots, our framework accurately predicts 350 future\ntime steps (a 7:1 prediction-to-training ratio) achieving an error of only 1.6%\ncompared to the vanilla auto-regressive approach. Moreover, our framework\ndemonstrates an 83% improvement in rollout performance over the standard noise\ninjection method, a standard technique for enhancing long-term rollout\nperformance. Its effectiveness is further validated in more challenging\nscenarios with truncated meshes, showcasing its adaptability and robustness in\npractical applications. This work introduces a versatile framework for robust\nlong-term spatio-temporal auto-regressive predictions that shows potential for\nmitigating error accumulation across various model types and engineering\ndisciplines.\n","authors":["Sunwoong Yang","Ricardo Vinuesa","Namwoo Kang"],"pdf_url":"https://arxiv.org/pdf/2412.05657v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.05318v1","updated":"2025-03-07T10:55:12Z","published":"2025-03-07T10:55:12Z","title":"Uncertainty-Aware Decoding with Minimum Bayes Risk","summary":"  Despite their outstanding performance in the majority of scenarios,\ncontemporary language models still occasionally generate undesirable outputs,\nfor example, hallucinated text. While such behaviors have previously been\nlinked to uncertainty, there is a notable lack of methods that actively\nconsider uncertainty during text generation. In this work, we show how Minimum\nBayes Risk (MBR) decoding, which selects model generations according to an\nexpected risk, can be generalized into a principled uncertainty-aware decoding\nmethod. In short, we account for model uncertainty during decoding by\nincorporating a posterior over model parameters into MBR's computation of\nexpected risk. We show that this modified expected risk is useful for both\nchoosing outputs and deciding when to abstain from generation and can provide\nimprovements without incurring overhead. We benchmark different methods for\nlearning posteriors and show that performance improves with prediction\ndiversity. We release our code publicly.\n","authors":["Nico Daheim","Clara Meister","Thomas Mllenhoff","Iryna Gurevych"],"pdf_url":"https://arxiv.org/pdf/2503.05318v1.pdf","comment":"ICLR 2025 (Poster)"},{"id":"http://arxiv.org/abs/2503.05316v1","updated":"2025-03-07T10:50:58Z","published":"2025-03-07T10:50:58Z","title":"CoinRobot: Generalized End-to-end Robotic Learning for Physical\n  Intelligence","summary":"  Physical intelligence holds immense promise for advancing embodied\nintelligence, enabling robots to acquire complex behaviors from demonstrations.\nHowever, achieving generalization and transfer across diverse robotic platforms\nand environments requires careful design of model architectures, training\nstrategies, and data diversity. Meanwhile existing systems often struggle with\nscalability, adaptability to heterogeneous hardware, and objective evaluation\nin real-world settings. We present a generalized end-to-end robotic learning\nframework designed to bridge this gap. Our framework introduces a unified\narchitecture that supports cross-platform adaptability, enabling seamless\ndeployment across industrial-grade robots, collaborative arms, and novel\nembodiments without task-specific modifications. By integrating multi-task\nlearning with streamlined network designs, it achieves more robust performance\nthan conventional approaches, while maintaining compatibility with varying\nsensor configurations and action spaces. We validate our framework through\nextensive experiments on seven manipulation tasks. Notably, Diffusion-based\nmodels trained in our framework demonstrated superior performance and\ngeneralizability compared to the LeRobot framework, achieving performance\nimprovements across diverse robotic platforms and environmental conditions.\n","authors":["Yu Zhao","Huxian Liu","Xiang Chen","Jiankai Sun","Jiahuan Yan","Luhui Hu"],"pdf_url":"https://arxiv.org/pdf/2503.05316v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.05315v1","updated":"2025-03-07T10:50:45Z","published":"2025-03-07T10:50:45Z","title":"LoRACode: LoRA Adapters for Code Embeddings","summary":"  Code embeddings are essential for semantic code search; however, current\napproaches often struggle to capture the precise syntactic and contextual\nnuances inherent in code. Open-source models such as CodeBERT and UniXcoder\nexhibit limitations in scalability and efficiency, while high-performing\nproprietary systems impose substantial computational costs. We introduce a\nparameter-efficient fine-tuning method based on Low-Rank Adaptation (LoRA) to\nconstruct task-specific adapters for code retrieval. Our approach reduces the\nnumber of trainable parameters to less than two percent of the base model,\nenabling rapid fine-tuning on extensive code corpora (2 million samples in 25\nminutes on two H100 GPUs). Experiments demonstrate an increase of up to 9.1% in\nMean Reciprocal Rank (MRR) for Code2Code search, and up to 86.69% for Text2Code\nsearch tasks across multiple programming languages. Distinction in task-wise\nand language-wise adaptation helps explore the sensitivity of code retrieval\nfor syntactical and linguistic variations.\n","authors":["Saumya Chaturvedi","Aman Chadha","Laurent Bindschaedler"],"pdf_url":"https://arxiv.org/pdf/2503.05315v1.pdf","comment":"Accepted at the Deep Learning for Code (DL4C) Workshop at ICLR 2025"},{"id":"http://arxiv.org/abs/2412.03983v2","updated":"2025-03-07T10:39:01Z","published":"2024-12-05T08:58:41Z","title":"Safe and Efficient Online Convex Optimization with Linear Budget\n  Constraints and Partial Feedback","summary":"  This paper studies online convex optimization with unknown linear budget\nconstraints, where only the gradient information of the objective and the\nbandit feedback of constraint functions are observed. We propose a safe and\nefficient Lyapunov-optimization algorithm (SELO) that can achieve an\n$O(\\sqrt{T})$ regret and zero cumulative constraint violation. The result also\nimplies SELO achieves $O(\\sqrt{T})$ regret when the budget is hard and not\nallowed to be violated. The proposed algorithm is computationally efficient as\nit resembles a primal-dual algorithm where the primal problem is an\nunconstrained, strongly convex and smooth problem, and the dual problem has a\nsimple gradient-type update. The algorithm and theory are further justified in\na simulated application of energy-efficient task processing in distributed data\ncenters.\n","authors":["Shanqi Liu","Xin Liu"],"pdf_url":"https://arxiv.org/pdf/2412.03983v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.05306v1","updated":"2025-03-07T10:35:01Z","published":"2025-03-07T10:35:01Z","title":"Adversarial Policy Optimization for Offline Preference-based\n  Reinforcement Learning","summary":"  In this paper, we study offline preference-based reinforcement learning\n(PbRL), where learning is based on pre-collected preference feedback over pairs\nof trajectories. While offline PbRL has demonstrated remarkable empirical\nsuccess, existing theoretical approaches face challenges in ensuring\nconservatism under uncertainty, requiring computationally intractable\nconfidence set constructions. We address this limitation by proposing\nAdversarial Preference-based Policy Optimization (APPO), a computationally\nefficient algorithm for offline PbRL that guarantees sample complexity bounds\nwithout relying on explicit confidence sets. By framing PbRL as a two-player\ngame between a policy and a model, our approach enforces conservatism in a\ntractable manner. Using standard assumptions on function approximation and\nbounded trajectory concentrability, we derive a sample complexity bound. To our\nknowledge, APPO is the first offline PbRL algorithm to offer both statistical\nefficiency and practical applicability. Experimental results on continuous\ncontrol tasks demonstrate that APPO effectively learns from complex datasets,\nshowing comparable performance with existing state-of-the-art methods.\n","authors":["Hyungkyu Kang","Min-hwan Oh"],"pdf_url":"https://arxiv.org/pdf/2503.05306v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.05303v1","updated":"2025-03-07T10:31:59Z","published":"2025-03-07T10:31:59Z","title":"Robust Intrusion Detection System with Explainable Artificial\n  Intelligence","summary":"  Machine learning (ML) models serve as powerful tools for threat detection and\nmitigation; however, they also introduce potential new risks. Adversarial input\ncan exploit these models through standard interfaces, thus creating new attack\npathways that threaten critical network operations. As ML advancements\nprogress, adversarial strategies become more advanced, and conventional\ndefenses such as adversarial training are costly in computational terms and\noften fail to provide real-time detection. These methods typically require a\nbalance between robustness and model performance, which presents challenges for\napplications that demand instant response. To further investigate this\nvulnerability, we suggest a novel strategy for detecting and mitigating\nadversarial attacks using eXplainable Artificial Intelligence (XAI). This\napproach is evaluated in real time within intrusion detection systems (IDS),\nleading to the development of a zero-touch mitigation strategy. Additionally,\nwe explore various scenarios in the Radio Resource Control (RRC) layer within\nthe Open Radio Access Network (O-RAN) framework, emphasizing the critical need\nfor enhanced mitigation techniques to strengthen IDS defenses against advanced\nthreats and implement a zero-touch mitigation solution. Extensive testing\nacross different scenarios in the RRC layer of the O-RAN infrastructure\nvalidates the ability of the framework to detect and counteract integrated\nRRC-layer attacks when paired with adversarial strategies, emphasizing the\nessential need for robust defensive mechanisms to strengthen IDS against\ncomplex threats.\n","authors":["Betl Gven Paltun","Ramin Fuladi","Rim El Malki"],"pdf_url":"https://arxiv.org/pdf/2503.05303v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2306.16838v7","updated":"2025-03-07T10:15:41Z","published":"2023-06-29T10:29:29Z","title":"Fast Robust Kernel Regression through Sign Gradient Descent with Early\n  Stopping","summary":"  Kernel ridge regression, KRR, is a generalization of linear ridge regression\nthat is non-linear in the data, but linear in the model parameters. Here, we\nintroduce an equivalent formulation of the objective function of KRR, which\nopens up for replacing the ridge penalty with the $\\ell_\\infty$ and $\\ell_1$\npenalties. Using the $\\ell_\\infty$ and $\\ell_1$ penalties, we obtain robust and\nsparse kernel regression, respectively. We study the similarities between\nexplicitly regularized kernel regression and the solutions obtained by early\nstopping of iterative gradient-based methods, where we connect $\\ell_\\infty$\nregularization to sign gradient descent, $\\ell_1$ regularization to forward\nstagewise regression (also known as coordinate descent), and $\\ell_2$\nregularization to gradient descent, and, in the last case, theoretically bound\nfor the differences. We exploit the close relations between $\\ell_\\infty$\nregularization and sign gradient descent, and between $\\ell_1$ regularization\nand coordinate descent to propose computationally efficient methods for robust\nand sparse kernel regression. We finally compare robust kernel regression\nthrough sign gradient descent to existing methods for robust kernel regression\non five real data sets, demonstrating that our method is one to two orders of\nmagnitude faster, without compromised accuracy.\n","authors":["Oskar Allerbo"],"pdf_url":"https://arxiv.org/pdf/2306.16838v7.pdf","comment":"Article arXiv:2306.16838v1 has been updated and split into two\n  articles: this article and arXiv:2311.01762. Thus, some of the content in\n  arXiv:2306.16838v1 is not a part of arXiv:2306.16838v2, but of\n  arXiv:2311.01762"},{"id":"http://arxiv.org/abs/2503.05289v1","updated":"2025-03-07T10:09:16Z","published":"2025-03-07T10:09:16Z","title":"An Analytical Model for Overparameterized Learning Under Class Imbalance","summary":"  We study class-imbalanced linear classification in a high-dimensional\nGaussian mixture model. We develop a tight, closed form approximation for the\ntest error of several practical learning methods, including logit adjustment\nand class dependent temperature. Our approximation allows us to analytically\ntune and compare these methods, highlighting how and when they overcome the\npitfalls of standard cross-entropy minimization. We test our theoretical\nfindings on simulated data and imbalanced CIFAR10, MNIST and FashionMNIST\ndatasets.\n","authors":["Eliav Mor","Yair Carmon"],"pdf_url":"https://arxiv.org/pdf/2503.05289v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.15247v2","updated":"2025-03-07T10:07:37Z","published":"2024-11-22T08:00:20Z","title":"Reward Fine-Tuning Two-Step Diffusion Models via Learning Differentiable\n  Latent-Space Surrogate Reward","summary":"  Recent research has shown that fine-tuning diffusion models (DMs) with\narbitrary rewards, including non-differentiable ones, is feasible with\nreinforcement learning (RL) techniques, enabling flexible model alignment.\nHowever, applying existing RL methods to timestep-distilled DMs is challenging\nfor ultra-fast ($\\le2$-step) image generation. Our analysis suggests several\nlimitations of policy-based RL methods such as PPO or DPO toward this goal.\nBased on the insights, we propose fine-tuning DMs with learned differentiable\nsurrogate rewards. Our method, named LaSRO, learns surrogate reward models in\nthe latent space of SDXL to convert arbitrary rewards into differentiable ones\nfor efficient reward gradient guidance. LaSRO leverages pre-trained latent DMs\nfor reward modeling and specifically targets image generation $\\le2$ steps for\nreward optimization, enhancing generalizability and efficiency. LaSRO is\neffective and stable for improving ultra-fast image generation with different\nreward objectives, outperforming popular RL methods including PPO and DPO. We\nfurther show LaSRO's connection to value-based RL, providing theoretical\ninsights. See our webpage at https://sites.google.com/view/lasro.\n","authors":["Zhiwei Jia","Yuesong Nan","Huixi Zhao","Gengdai Liu"],"pdf_url":"https://arxiv.org/pdf/2411.15247v2.pdf","comment":"CVPR 2025"},{"id":"http://arxiv.org/abs/2411.03315v2","updated":"2025-03-07T10:05:23Z","published":"2024-10-08T11:01:12Z","title":"Learning Force Distribution Estimation for the GelSight Mini Optical\n  Tactile Sensor Based on Finite Element Analysis","summary":"  Contact-rich manipulation remains a major challenge in robotics. Optical\ntactile sensors like GelSight Mini offer a low-cost solution for contact\nsensing by capturing soft-body deformations of the silicone gel. However,\naccurately inferring shear and normal force distributions from these gel\ndeformations has yet to be fully addressed. In this work, we propose a machine\nlearning approach using a U-net architecture to predict force distributions\ndirectly from the sensor's raw images. Our model, trained on force\ndistributions inferred from Finite Element Analysis (FEA), demonstrates\npromising accuracy in predicting normal and shear force distributions for the\ncommercially available GelSight Mini sensor. It also shows potential for\ngeneralization across indenters, sensors of the same type, and for enabling\nreal-time application. The codebase, dataset and models are open-sourced and\navailable at https://feats-ai.github.io .\n","authors":["Erik Helmut","Luca Dziarski","Niklas Funk","Boris Belousov","Jan Peters"],"pdf_url":"https://arxiv.org/pdf/2411.03315v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.01743v2","updated":"2025-03-07T09:05:58Z","published":"2025-03-03T17:05:52Z","title":"Phi-4-Mini Technical Report: Compact yet Powerful Multimodal Language\n  Models via Mixture-of-LoRAs","summary":"  We introduce Phi-4-Mini and Phi-4-Multimodal, compact yet highly capable\nlanguage and multimodal models. Phi-4-Mini is a 3.8-billion-parameter language\nmodel trained on high-quality web and synthetic data, significantly\noutperforming recent open-source models of similar size and matching the\nperformance of models twice its size on math and coding tasks requiring complex\nreasoning. This achievement is driven by a carefully curated synthetic data\nrecipe emphasizing high-quality math and coding datasets. Compared to its\npredecessor, Phi-3.5-Mini, Phi-4-Mini features an expanded vocabulary size of\n200K tokens to better support multilingual applications, as well as group query\nattention for more efficient long-sequence generation. Phi-4-Multimodal is a\nmultimodal model that integrates text, vision, and speech/audio input\nmodalities into a single model. Its novel modality extension approach leverages\nLoRA adapters and modality-specific routers to allow multiple inference modes\ncombining various modalities without interference. For example, it now ranks\nfirst in the OpenASR leaderboard to date, although the LoRA component of the\nspeech/audio modality has just 460 million parameters. Phi-4-Multimodal\nsupports scenarios involving (vision + language), (vision + speech), and\n(speech/audio) inputs, outperforming larger vision-language and speech-language\nmodels on a wide range of tasks. Additionally, we experiment to further train\nPhi-4-Mini to enhance its reasoning capabilities. Despite its compact\n3.8-billion-parameter size, this experimental version achieves reasoning\nperformance on par with or surpassing significantly larger models, including\nDeepSeek-R1-Distill-Qwen-7B and DeepSeek-R1-Distill-Llama-8B.\n","authors":[" Microsoft"," :","Abdelrahman Abouelenin","Atabak Ashfaq","Adam Atkinson","Hany Awadalla","Nguyen Bach","Jianmin Bao","Alon Benhaim","Martin Cai","Vishrav Chaudhary","Congcong Chen","Dong Chen","Dongdong Chen","Junkun Chen","Weizhu Chen","Yen-Chun Chen","Yi-ling Chen","Qi Dai","Xiyang Dai","Ruchao Fan","Mei Gao","Min Gao","Amit Garg","Abhishek Goswami","Junheng Hao","Amr Hendy","Yuxuan Hu","Xin Jin","Mahmoud Khademi","Dongwoo Kim","Young Jin Kim","Gina Lee","Jinyu Li","Yunsheng Li","Chen Liang","Xihui Lin","Zeqi Lin","Mengchen Liu","Yang Liu","Gilsinia Lopez","Chong Luo","Piyush Madan","Vadim Mazalov","Arindam Mitra","Ali Mousavi","Anh Nguyen","Jing Pan","Daniel Perez-Becker","Jacob Platin","Thomas Portet","Kai Qiu","Bo Ren","Liliang Ren","Sambuddha Roy","Ning Shang","Yelong Shen","Saksham Singhal","Subhojit Som","Xia Song","Tetyana Sych","Praneetha Vaddamanu","Shuohang Wang","Yiming Wang","Zhenghao Wang","Haibin Wu","Haoran Xu","Weijian Xu","Yifan Yang","Ziyi Yang","Donghan Yu","Ishmam Zabir","Jianwen Zhang","Li Lyna Zhang","Yunan Zhang","Xiren Zhou"],"pdf_url":"https://arxiv.org/pdf/2503.01743v2.pdf","comment":"39 pages"},{"id":"http://arxiv.org/abs/2503.05246v1","updated":"2025-03-07T08:58:07Z","published":"2025-03-07T08:58:07Z","title":"Mastering Continual Reinforcement Learning through Fine-Grained Sparse\n  Network Allocation and Dormant Neuron Exploration","summary":"  Continual Reinforcement Learning (CRL) is essential for developing agents\nthat can learn, adapt, and accumulate knowledge over time. However, a\nfundamental challenge persists as agents must strike a delicate balance between\nplasticity, which enables rapid skill acquisition, and stability, which ensures\nlong-term knowledge retention while preventing catastrophic forgetting. In this\npaper, we introduce SSDE, a novel structure-based approach that enhances\nplasticity through a fine-grained allocation strategy with Structured Sparsity\nand Dormant-guided Exploration. SSDE decomposes the parameter space into\nforward-transfer (frozen) parameters and task-specific (trainable) parameters.\nCrucially, these parameters are allocated by an efficient co-allocation scheme\nunder sparse coding, ensuring sufficient trainable capacity for new tasks while\npromoting efficient forward transfer through frozen parameters. However,\nstructure-based methods often suffer from rigidity due to the accumulation of\nnon-trainable parameters, limiting exploration and adaptability. To address\nthis, we further introduce a sensitivity-guided neuron reactivation mechanism\nthat systematically identifies and resets dormant neurons, which exhibit\nminimal influence in the sparse policy network during inference. This approach\neffectively enhance exploration while preserving structural efficiency.\nExtensive experiments on the CW10-v1 Continual World benchmark demonstrate that\nSSDE achieves state-of-the-art performance, reaching a success rate of 95%,\nsurpassing prior methods significantly in both plasticity and stability\ntrade-offs (code is available at: https://github.com/chengqiArchy/SSDE).\n","authors":["Chengqi Zheng","Haiyan Yin","Jianda Chen","Terrence Ng","Yew-Soon Ong","Ivor Tsang"],"pdf_url":"https://arxiv.org/pdf/2503.05246v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.03360v2","updated":"2025-03-07T08:55:13Z","published":"2025-03-05T10:40:09Z","title":"Transformers for molecular property prediction: Domain adaptation\n  efficiently improves performance","summary":"  Most of the current transformer-based chemical language models are\npre-trained on millions to billions of molecules. However, the improvement from\nsuch scaling in dataset size is not confidently linked to improved molecular\nproperty prediction. The aim of this study is to investigate and overcome some\nof the limitations of transformer models in predicting molecular properties.\nSpecifically, we examine the impact of pre-training dataset size and diversity\non the performance of transformer models and investigate the use of domain\nadaptation as a technique for improving model performance. First, our findings\nindicate that increasing pretraining dataset size beyond 400K molecules from\nthe GuacaMol dataset does not result in a significant improvement on four ADME\nendpoints, namely, solubility, permeability, microsomal stability, and plasma\nprotein binding. Second, our results demonstrate that using domain adaptation\nby further training the transformer model on a small set of domain-relevant\nmolecules, i.e., a few hundred to a few thousand, using multi-task regression\nof physicochemical properties was sufficient to significantly improve\nperformance for three out of the four investigated ADME endpoints (P-value <\n0.001). Finally, we observe that a model pre-trained on 400K molecules and\ndomain adopted on a few hundred/thousand molecules performs similarly (P-value\n> 0.05) to more complicated transformer models like MolBERT(pre-trained on 1.3M\nmolecules) and MolFormer (pre-trained on 100M molecules). A comparison to a\nrandom forest model trained on basic physicochemical properties showed similar\nperformance to the examined transformer models. We believe that current\ntransformer models can be improved through further systematic analysis of\npre-training and downstream data, pre-training objectives, and scaling laws,\nultimately leading to better and more helpful models.\n","authors":["Afnan Sultan","Max Rausch-Dupont","Shahrukh Khan","Olga Kalinina","Andrea Volkamer","Dietrich Klakow"],"pdf_url":"https://arxiv.org/pdf/2503.03360v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2104.11977v2","updated":"2025-03-07T08:52:46Z","published":"2021-04-24T16:16:30Z","title":"Generalized moduli of continuity under irregular or random deformations\n  via multiscale analysis","summary":"  Motivated by the problem of robustness to deformations of the input for deep\nconvolutional neural networks, we identify signal classes which are inherently\nstable to irregular deformations induced by distortion fields $\\tau\\in\nL^\\infty(\\mathbb{R}^d;\\mathbb{R}^d)$, to be characterized in terms of a\ngeneralized modulus of continuity associated with the deformation operator.\nResorting to ideas of harmonic and multiscale analysis, we prove that for\nsignals in multiresolution approximation spaces $U_s$ at scale $s$, stability\nin $L^2$ holds in the regime $\\|\\tau\\|_{L^\\infty}/s\\ll 1$ - essentially as an\neffect of the uncertainty principle. Instability occurs when\n$\\|\\tau\\|_{L^\\infty}/s\\gg 1$, and we provide a sharp upper bound for the\nasymptotic growth rate. The stability results are then extended to signals in\nthe Besov space $B^{d/2}_{2,1}$ tailored to the given multiresolution\napproximation. We also consider the case of more general time-frequency\ndeformations. Finally, we provide stochastic versions of the aforementioned\nresults, namely we study the issue of stability in mean when $\\tau(x)$ is\nmodeled as a random field (not bounded, in general) with identically\ndistributed variables $|\\tau(x)|$, $x\\in\\mathbb{R}^d$.\n","authors":["Fabio Nicola","S. Ivan Trapasso"],"pdf_url":"https://arxiv.org/pdf/2104.11977v2.pdf","comment":"25 pages"},{"id":"http://arxiv.org/abs/2503.05239v1","updated":"2025-03-07T08:41:53Z","published":"2025-03-07T08:41:53Z","title":"Robust Conformal Prediction with a Single Binary Certificate","summary":"  Conformal prediction (CP) converts any model's output to prediction sets with\na guarantee to cover the true label with (adjustable) high probability. Robust\nCP extends this guarantee to worst-case (adversarial) inputs. Existing\nbaselines achieve robustness by bounding randomly smoothed conformity scores.\nIn practice, they need expensive Monte-Carlo (MC) sampling (e.g. $\\sim10^4$\nsamples per point) to maintain an acceptable set size. We propose a robust\nconformal prediction that produces smaller sets even with significantly lower\nMC samples (e.g. 150 for CIFAR10). Our approach binarizes samples with an\nadjustable (or automatically adjusted) threshold selected to preserve the\ncoverage guarantee. Remarkably, we prove that robustness can be achieved by\ncomputing only one binary certificate, unlike previous methods that certify\neach calibration (or test) point. Thus, our method is faster and returns\nsmaller robust sets. We also eliminate a previous limitation that requires a\nbounded score function.\n","authors":["Soroush H. Zargarbashi","Aleksandar Bojchevski"],"pdf_url":"https://arxiv.org/pdf/2503.05239v1.pdf","comment":"Published as a conference paper at ICLR 2025"},{"id":"http://arxiv.org/abs/2503.05238v1","updated":"2025-03-07T08:40:41Z","published":"2025-03-07T08:40:41Z","title":"Guaranteeing Out-Of-Distribution Detection in Deep RL via Transition\n  Estimation","summary":"  An issue concerning the use of deep reinforcement learning (RL) agents is\nwhether they can be trusted to perform reliably when deployed, as training\nenvironments may not reflect real-life environments. Anticipating instances\noutside their training scope, learning-enabled systems are often equipped with\nout-of-distribution (OOD) detectors that alert when a trained system encounters\na state it does not recognize or in which it exhibits uncertainty. There exists\nlimited work conducted on the problem of OOD detection within RL, with prior\nstudies being unable to achieve a consensus on the definition of OOD execution\nwithin the context of RL. By framing our problem using a Markov Decision\nProcess, we assume there is a transition distribution mapping each state-action\npair to another state with some probability. Based on this, we consider the\nfollowing definition of OOD execution within RL: A transition is OOD if its\nprobability during real-life deployment differs from the transition\ndistribution encountered during training. As such, we utilize conditional\nvariational autoencoders (CVAE) to approximate the transition dynamics of the\ntraining environment and implement a conformity-based detector using\nreconstruction loss that is able to guarantee OOD detection with a\npre-determined confidence level. We evaluate our detector by adapting existing\nbenchmarks and compare it with existing OOD detection models for RL.\n","authors":["Mohit Prashant","Arvind Easwaran","Suman Das","Michael Yuhas"],"pdf_url":"https://arxiv.org/pdf/2503.05238v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2401.10690v4","updated":"2025-03-07T08:40:19Z","published":"2024-01-19T13:41:08Z","title":"Beyond RMSE and MAE: Introducing EAUC to unmask hidden bias and\n  unfairness in dyadic regression models","summary":"  Dyadic regression models, which output real-valued predictions for pairs of\nentities, are fundamental in many domains (e.g. obtaining user-product ratings\nin Recommender Systems) and promising and under exploration in others (e.g.\ntuning patient-drug dosages in precision pharmacology). In this work, we prove\nthat non-uniform observed value distributions of individual entities lead to\nsevere biases in state-of-the-art models, skewing predictions towards the\naverage of observed past values for the entity and providing worse-than-random\npredictive power in eccentric yet crucial cases; we name this phenomenon\neccentricity bias. We show that global error metrics like Root Mean Squared\nError (RMSE) are insufficient to capture this bias, and we introduce\nEccentricity-Area Under the Curve (EAUC) as a novel metric that can quantify it\nin all studied domains and models. We prove the intuitive interpretation of\nEAUC by experimenting with naive post-training bias corrections, and theorize\nother options to use EAUC to guide the construction of fair models. This work\ncontributes a bias-aware evaluation of dyadic regression to prevent unfairness\nin critical real-world applications of such systems.\n","authors":["Jorge Paz-Ruza","Amparo Alonso-Betanzos","Bertha Guijarro-Berdias","Brais Cancela","Carlos Eiras-Franco"],"pdf_url":"https://arxiv.org/pdf/2401.10690v4.pdf","comment":null},{"id":"http://arxiv.org/abs/2502.05605v2","updated":"2025-03-07T08:35:00Z","published":"2025-02-08T15:21:55Z","title":"ARIES: Stimulating Self-Refinement of Large Language Models by Iterative\n  Preference Optimization","summary":"  A truly intelligent Large Language Model (LLM) should be capable of\ncorrecting errors in its responses through external interactions. However, even\nthe most advanced models often face challenges in improving their outputs. In\nthis paper, we explore how to cultivate LLMs with the self-refinement\ncapability through iterative preference training, and how this ability can be\nleveraged to improve model performance during inference. To this end, we\nintroduce a novel post-training and inference framework, called ARIES: Adaptive\nRefinement and Iterative Enhancement Structure. This method iteratively\nperforms preference training and self-refinement-based data collection. During\ntraining, ARIES strengthen the model's direct question-answering capability\nwhile simultaneously unlocking its self-refinement potential. During inference,\nARIES harnesses this self-refinement capability to generate a series of\nprogressively refined responses, which are then filtered using either the\nReward Model Scoring or a simple yet effective Rule-Based Selection mechanism,\nspecifically tailored to our approach, to construct a dataset for the next\nround of preference training. Experimental results demonstrate the remarkable\nperformance of ARIES. When applied to the Llama-3.1-8B model and under the\nself-refinement setting, ARIES surpasses powerful models such as GPT-4o,\nachieving 62.3% length-controlled (LC) and a 63.3% raw win rates on AlpacaEval\n2, outperforming Iterative DPO by 27.8% and 35.5% respectively, as well as a\n50.3% win rate on Arena-Hard, surpassing Iterative DPO by 26.6%. Furthermore,\nARIES consistently enhances performance on mathematical reasoning tasks like\nGSM8K and MATH.\n","authors":["Yongcheng Zeng","Xinyu Cui","Xuanfa Jin","Guoqing Liu","Zexu Sun","Quan He","Dong Li","Ning Yang","Jianye Hao","Haifeng Zhang","Jun Wang"],"pdf_url":"https://arxiv.org/pdf/2502.05605v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.05224v1","updated":"2025-03-07T08:22:50Z","published":"2025-03-07T08:22:50Z","title":"Deep Sequence Models for Predicting Average Shear Wave Velocity from\n  Strong Motion Records","summary":"  This study explores the use of deep learning for predicting the time averaged\nshear wave velocity in the top 30 m of the subsurface ($V_{s30}$) at strong\nmotion recording stations in T\\\"urkiye. $V_{s30}$ is a key parameter in site\ncharacterization and, as a result for seismic hazard assessment. However, it is\noften unavailable due to the lack of direct measurements and is therefore\nestimated using empirical correlations. Such correlations however are commonly\ninadequate in capturing complex, site-specific variability and this motivates\nthe need for data-driven approaches. In this study, we employ a hybrid deep\nlearning model combining convolutional neural networks (CNNs) and long\nshort-term memory (LSTM) networks to capture both spatial and temporal\ndependencies in strong motion records. Furthermore, we explore how using\ndifferent parts of the signal influence our deep learning model. Our results\nsuggest that the hybrid approach effectively learns complex, nonlinear\nrelationships within seismic signals. We observed that an improved P-wave\narrival time model increased the prediction accuracy of $V_{s30}$. We believe\nthe study provides valuable insights into improving $V_{s30}$ predictions using\na CNN-LSTM framework, demonstrating its potential for improving site\ncharacterization for seismic studies. Our codes are available via this repo:\nhttps://github.com/brsylmz23/CNNLSTM_DeepEQ\n","authors":["Baris Yilmaz","Erdem Akagndz","Salih Tileylioglu"],"pdf_url":"https://arxiv.org/pdf/2503.05224v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.05223v1","updated":"2025-03-07T08:21:48Z","published":"2025-03-07T08:21:48Z","title":"DiVISe: Direct Visual-Input Speech Synthesis Preserving Speaker\n  Characteristics And Intelligibility","summary":"  Video-to-speech (V2S) synthesis, the task of generating speech directly from\nsilent video input, is inherently more challenging than other speech synthesis\ntasks due to the need to accurately reconstruct both speech content and speaker\ncharacteristics from visual cues alone. Recently, audio-visual pre-training has\neliminated the need for additional acoustic hints in V2S, which previous\nmethods often relied on to ensure training convergence. However, even with\npre-training, existing methods continue to face challenges in achieving a\nbalance between acoustic intelligibility and the preservation of\nspeaker-specific characteristics. We analyzed this limitation and were\nmotivated to introduce DiVISe (Direct Visual-Input Speech Synthesis), an\nend-to-end V2S model that predicts Mel-spectrograms directly from video frames\nalone. Despite not taking any acoustic hints, DiVISe effectively preserves\nspeaker characteristics in the generated audio, and achieves superior\nperformance on both objective and subjective metrics across the LRS2 and LRS3\ndatasets. Our results demonstrate that DiVISe not only outperforms existing V2S\nmodels in acoustic intelligibility but also scales more effectively with\nincreased data and model parameters. Code and weights can be found at\nhttps://github.com/PussyCat0700/DiVISe.\n","authors":["Yifan Liu","Yu Fang","Zhouhan Lin"],"pdf_url":"https://arxiv.org/pdf/2503.05223v1.pdf","comment":"to be published in NAACL 25"},{"id":"http://arxiv.org/abs/2503.05215v1","updated":"2025-03-07T08:10:45Z","published":"2025-03-07T08:10:45Z","title":"Robustness of Generalized Median Computation for Consensus Learning in\n  Arbitrary Spaces","summary":"  Robustness in terms of outliers is an important topic and has been formally\nstudied for a variety of problems in machine learning and computer vision.\nGeneralized median computation is a special instance of consensus learning and\na common approach to finding prototypes. Related research can be found in\nnumerous problem domains with a broad range of applications. So far, however,\nrobustness of generalized median has only been studied in a few specific\nspaces. To our knowledge, there is no robustness characterization in a general\nsetting, i.e. for arbitrary spaces. We address this open issue in our work. The\nbreakdown point >=0.5 is proved for generalized median with metric distance\nfunctions in general. We also study the detailed behavior in case of outliers\nfrom different perspectives. In addition, we present robustness results for\nweighted generalized median computation and non-metric distance functions.\nGiven the importance of robustness, our work contributes to closing a gap in\nthe literature. The presented results have general impact and applicability,\ne.g. providing deeper understanding of generalized median computation and\npractical guidance to avoid non-robust computation.\n","authors":["Andreas Nienktter","Sandro Vega-Pons","Xiaoyi Jiang"],"pdf_url":"https://arxiv.org/pdf/2503.05215v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.19346v2","updated":"2025-03-07T08:08:18Z","published":"2024-11-28T19:48:54Z","title":"CLIP meets DINO for Tuning Zero-Shot Classifier using Unlabeled Image\n  Collections","summary":"  In the era of foundation models, CLIP has emerged as a powerful tool for\naligning text & visual modalities into a common embedding space. However, the\nalignment objective used to train CLIP often results in subpar visual features\nfor fine-grained tasks. In contrast, SSL-pretrained models like DINO excel at\nextracting rich visual features due to their specialized training paradigm.\nYet, these SSL models require an additional supervised linear probing step,\nwhich relies on fully labeled data which is often expensive and difficult to\nobtain at scale. In this paper, we propose a label-free prompt-tuning method\nthat leverages the rich visual features of self-supervised learning models\n(DINO) and the broad textual knowledge of large language models (LLMs) to\nlargely enhance CLIP-based image classification performance using unlabeled\nimages. Our approach unfolds in three key steps: (1) We generate robust textual\nfeature embeddings that more accurately represent object classes by leveraging\nclass-specific descriptions from LLMs, enabling more effective zero-shot\nclassification compared to CLIP's default name-specific prompts. (2) These\ntextual embeddings are then used to produce pseudo-labels to train an alignment\nmodule that integrates the complementary strengths of LLM description-based\ntextual embeddings & DINO's visual features. (3) Finally, we prompt-tune CLIP's\nvision encoder through DINO-assisted supervision using the trained alignment\nmodule. This three-step process allows us to harness the best of visual &\ntextual foundation models, resulting in a powerful and efficient approach that\nsurpasses state-of-the-art label-free classification methods. Notably, our\nframework, NoLA (No Labels Attached), achieves an average absolute gain of 3.6%\nover the state-of-the-art LaFTer across 11 diverse image classification\ndatasets. Our code & models can be found at https://github.com/fazliimam/NoLA.\n","authors":["Mohamed Fazli Imam","Rufael Fedaku Marew","Jameel Hassan","Mustansar Fiaz","Alham Fikri Aji","Hisham Cholakkal"],"pdf_url":"https://arxiv.org/pdf/2411.19346v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.03796v2","updated":"2025-03-07T08:06:15Z","published":"2025-03-05T14:33:18Z","title":"Human Implicit Preference-Based Policy Fine-tuning for Multi-Agent\n  Reinforcement Learning in USV Swarm","summary":"  Multi-Agent Reinforcement Learning (MARL) has shown promise in solving\ncomplex problems involving cooperation and competition among agents, such as an\nUnmanned Surface Vehicle (USV) swarm used in search and rescue, surveillance,\nand vessel protection. However, aligning system behavior with user preferences\nis challenging due to the difficulty of encoding expert intuition into reward\nfunctions. To address the issue, we propose a Reinforcement Learning with Human\nFeedback (RLHF) approach for MARL that resolves credit-assignment challenges\nthrough an Agent-Level Feedback system categorizing feedback into intra-agent,\ninter-agent, and intra-team types. To overcome the challenges of direct human\nfeedback, we employ a Large Language Model (LLM) evaluator to validate our\napproach using feedback scenarios such as region constraints, collision\navoidance, and task allocation. Our method effectively refines USV swarm\npolicies, addressing key challenges in multi-agent systems while maintaining\nfairness and performance consistency.\n","authors":["Hyeonjun Kim","Kanghoon Lee","Junho Park","Jiachen Li","Jinkyoo Park"],"pdf_url":"https://arxiv.org/pdf/2503.03796v2.pdf","comment":"7 pages, 4 figures"},{"id":"http://arxiv.org/abs/2503.05207v1","updated":"2025-03-07T07:55:51Z","published":"2025-03-07T07:55:51Z","title":"Policy Constraint by Only Support Constraint for Offline Reinforcement\n  Learning","summary":"  Offline reinforcement learning (RL) aims to optimize a policy by using\npre-collected datasets, to maximize cumulative rewards. However, offline\nreinforcement learning suffers challenges due to the distributional shift\nbetween the learned and behavior policies, leading to errors when computing\nQ-values for out-of-distribution (OOD) actions. To mitigate this issue, policy\nconstraint methods aim to constrain the learned policy's distribution with the\ndistribution of the behavior policy or confine action selection within the\nsupport of the behavior policy. However, current policy constraint methods tend\nto exhibit excessive conservatism, hindering the policy from further surpassing\nthe behavior policy's performance. In this work, we present Only Support\nConstraint (OSC) which is derived from maximizing the total probability of\nlearned policy in the support of behavior policy, to address the conservatism\nof policy constraint. OSC presents a regularization term that only restricts\npolicies to the support without imposing extra constraints on actions within\nthe support. Additionally, to fully harness the performance of the new policy\nconstraints, OSC utilizes a diffusion model to effectively characterize the\nsupport of behavior policies. Experimental evaluations across a variety of\noffline RL benchmarks demonstrate that OSC significantly enhances performance,\nalleviating the challenges associated with distributional shifts and mitigating\nconservatism of policy constraints. Code is available at\nhttps://github.com/MoreanP/OSC.\n","authors":["Yunkai Gao","Jiaming Guo","Fan Wu","Rui Zhang"],"pdf_url":"https://arxiv.org/pdf/2503.05207v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2407.01194v2","updated":"2025-03-07T07:47:19Z","published":"2024-07-01T11:39:15Z","title":"A Learned Generalized Geodesic Distance Function-Based Approach for Node\n  Feature Augmentation on Graphs","summary":"  Geodesic distances on manifolds have numerous applications in image\nprocessing, computer graphics and computer vision. In this work, we introduce\nan approach called `LGGD' (Learned Generalized Geodesic Distances). This method\ninvolves generating node features by learning a generalized geodesic distance\nfunction through a training pipeline that incorporates training data, graph\ntopology and the node content features. The strength of this method lies in the\nproven robustness of the generalized geodesic distances to noise and outliers.\nOur contributions encompass improved performance in node classification tasks,\ncompetitive results with state-of-the-art methods on real-world graph datasets,\nthe demonstration of the learnability of parameters within the generalized\ngeodesic equation on graph, and dynamic inclusion of new labels.\n","authors":["Amitoz Azad","Yuan Fang"],"pdf_url":"https://arxiv.org/pdf/2407.01194v2.pdf","comment":"Accepted at KDD 2024 Research Track"},{"id":"http://arxiv.org/abs/2503.02407v2","updated":"2025-03-07T07:46:34Z","published":"2025-03-04T08:50:10Z","title":"Wyckoff Transformer: Generation of Symmetric Crystals","summary":"  Symmetry rules that atoms obey when they bond together to form an ordered\ncrystal play a fundamental role in determining their physical, chemical, and\nelectronic properties such as electrical and thermal conductivity, optical and\npolarization behavior, and mechanical strength. Almost all known crystalline\nmaterials have internal symmetry. Consistently generating stable crystal\nstructures is still an open challenge, specifically because such symmetry rules\nare not accounted for. To address this issue, we propose WyFormer, a generative\nmodel for materials conditioned on space group symmetry. We use Wyckoff\npositions as the basis for an elegant, compressed, and discrete structure\nrepresentation. To model the distribution, we develop a permutation-invariant\nautoregressive model based on the Transformer and an absence of positional\nencoding. WyFormer has a unique and powerful synergy of attributes, proven by\nextensive experimentation: best-in-class symmetry-conditioned generation,\nphysics-motivated inductive bias, competitive stability of the generated\nstructures, competitive material property prediction quality, and unparalleled\ninference speed.\n","authors":["Nikita Kazeev","Wei Nong","Ignat Romanov","Ruiming Zhu","Andrey Ustyuzhanin","Shuya Yamazaki","Kedar Hippalgaonkar"],"pdf_url":"https://arxiv.org/pdf/2503.02407v2.pdf","comment":"https://github.com/SymmetryAdvantage/WyckoffTransformer"},{"id":"http://arxiv.org/abs/2503.05201v1","updated":"2025-03-07T07:46:26Z","published":"2025-03-07T07:46:26Z","title":"Deep Muscle EMG construction using A Physics-Integrated Deep Learning\n  approach","summary":"  Electromyography (EMG)--based computational musculoskeletal modeling is a\nnon-invasive method for studying musculotendon function, human movement, and\nneuromuscular control, providing estimates of internal variables like muscle\nforces and joint torques. However, EMG signals from deeper muscles are often\nchallenging to measure by placing the surface EMG electrodes and unfeasible to\nmeasure directly using invasive methods. The restriction to the access of EMG\ndata from deeper muscles poses a considerable obstacle to the broad adoption of\nEMG-driven modeling techniques. A strategic alternative is to use an estimation\nalgorithm to approximate the missing EMG signals from deeper muscle. A similar\nstrategy is used in physics-informed deep learning, where the features of\nphysical systems are learned without labeled data. In this work, we propose a\nhybrid deep learning algorithm, namely the neural musculoskeletal model (NMM),\nthat integrates physics-informed and data-driven deep learning to approximate\nthe EMG signals from the deeper muscles. While data-driven modeling is used to\npredict the missing EMG signals, physics-based modeling engraves the\nsubject-specific information into the predictions. Experimental verifications\non five test subjects are carried out to investigate the performance of the\nproposed hybrid framework. The proposed NMM is validated against the joint\ntorque computed from 'OpenSim' software. The predicted deep EMG signals are\nalso compared against the state-of-the-art muscle synergy extrapolation (MSE)\napproach, where the proposed NMM completely outperforms the existing MSE\nframework by a significant margin.\n","authors":["Rajnish Kumar","Tapas Tripura","Souvik Chakraborty","Sitikantha Roy"],"pdf_url":"https://arxiv.org/pdf/2503.05201v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.05194v1","updated":"2025-03-07T07:29:48Z","published":"2025-03-07T07:29:48Z","title":"Uncertainty-Aware Explainable Federated Learning","summary":"  Federated Learning (FL) is a collaborative machine learning paradigm for\nenhancing data privacy preservation. Its privacy-preserving nature complicates\nthe explanation of the decision-making processes and the evaluation of the\nreliability of the generated explanations. In this paper, we propose the\nUncertainty-aware eXplainable Federated Learning (UncertainXFL) to address\nthese challenges. It generates explanations for decision-making processes under\nFL settings and provides information regarding the uncertainty of these\nexplanations. UncertainXFL is the first framework to explicitly offer\nuncertainty evaluation for explanations within the FL context. Explanatory\ninformation is initially generated by the FL clients and then aggregated by the\nserver in a comprehensive and conflict-free manner during FL training. The\nquality of the explanations, including the uncertainty score and tested\nvalidity, guides the FL training process by prioritizing clients with the most\nreliable explanations through higher weights during model aggregation.\nExtensive experimental evaluation results demonstrate that UncertainXFL\nachieves superior model accuracy and explanation accuracy, surpassing the\ncurrent state-of-the-art model that does not incorporate uncertainty\ninformation by 2.71% and 1.77%, respectively. By integrating and quantifying\nuncertainty in the data into the explanation process, UncertainXFL not only\nclearly presents the explanation alongside its uncertainty, but also leverages\nthis uncertainty to guide the FL training process, thereby enhancing the\nrobustness and reliability of the resulting models.\n","authors":["Yanci Zhang","Han Yu"],"pdf_url":"https://arxiv.org/pdf/2503.05194v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2502.16927v2","updated":"2025-03-07T07:28:39Z","published":"2025-02-24T07:37:29Z","title":"BigMac: A Communication-Efficient Mixture-of-Experts Model Structure for\n  Fast Training and Inference","summary":"  The Mixture-of-Experts (MoE) structure scales the Transformer-based large\nlanguage models (LLMs) and improves their performance with only the sub-linear\nincrease in computation resources. Recently, a fine-grained DeepSeekMoE\nstructure is proposed, which can further improve the computing efficiency of\nMoE without performance degradation. However, the All-to-All communication\nintroduced by MoE has become a bottleneck, especially for the fine-grained\nstructure, which typically involves and activates more experts, hence\ncontributing to heavier communication overhead.\n  In this paper, we propose a novel MoE structure named BigMac, which is also\nfine-grained but with high communication efficiency. The innovation of BigMac\nis mainly due to that we abandon the\n\\textbf{c}ommunicate-\\textbf{d}escend-\\textbf{a}scend-\\textbf{c}ommunicate\n(CDAC) manner used by fine-grained MoE, which leads to the All-to-All\ncommunication always taking place at the highest dimension. Instead, BigMac\ndesigns an efficient\n\\textbf{d}escend-\\textbf{c}ommunicate-\\textbf{c}ommunicate-\\textbf{a}scend\n(DCCA) manner. Specifically, we add a descending and ascending projection at\nthe entrance and exit of the expert, respectively, which enables the\ncommunication to perform at a very low dimension. Furthermore, to adapt to\nDCCA, we re-design the structure of small experts, ensuring that the expert in\nBigMac has enough complexity to address tokens. Experimental results show that\nBigMac achieves comparable or even better model quality than fine-grained MoEs\nwith the same number of experts and a similar number of total parameters.\nEqually importantly, BigMac reduces the end-to-end latency by up to\n3.09$\\times$ for training and increases the throughput by up to 3.11$\\times$\nfor inference on state-of-the-art AI computing frameworks including Megatron,\nTutel, and DeepSpeed-Inference.\n","authors":["Zewen Jin","Shengnan Wang","Jiaan Zhu","Hongrui Zhan","Youhui Bai","Lin Zhang","Zhenyu Ming","Cheng Li"],"pdf_url":"https://arxiv.org/pdf/2502.16927v2.pdf","comment":"Typo Fixed"},{"id":"http://arxiv.org/abs/2503.05180v1","updated":"2025-03-07T06:59:27Z","published":"2025-03-07T06:59:27Z","title":"Safety-Critical Traffic Simulation with Adversarial Transfer of Driving\n  Intentions","summary":"  Traffic simulation, complementing real-world data with a long-tail\ndistribution, allows for effective evaluation and enhancement of the ability of\nautonomous vehicles to handle accident-prone scenarios. Simulating such\nsafety-critical scenarios is nontrivial, however, from log data that are\ntypically regular scenarios, especially in consideration of dynamic adversarial\ninteractions between the future motions of autonomous vehicles and surrounding\ntraffic participants. To address it, this paper proposes an innovative and\nefficient strategy, termed IntSim, that explicitly decouples the driving\nintentions of surrounding actors from their motion planning for realistic and\nefficient safety-critical simulation. We formulate the adversarial transfer of\ndriving intention as an optimization problem, facilitating extensive\nexploration of diverse attack behaviors and efficient solution convergence.\nSimultaneously, intention-conditioned motion planning benefits from powerful\ndeep models and large-scale real-world data, permitting the simulation of\nrealistic motion behaviors for actors. Specially, through adapting driving\nintentions based on environments, IntSim facilitates the flexible realization\nof dynamic adversarial interactions with autonomous vehicles. Finally,\nextensive open-loop and closed-loop experiments on real-world datasets,\nincluding nuScenes and Waymo, demonstrate that the proposed IntSim achieves\nstate-of-the-art performance in simulating realistic safety-critical scenarios\nand further improves planners in handling such scenarios.\n","authors":["Zherui Huang","Xing Gao","Guanjie Zheng","Licheng Wen","Xuemeng Yang","Xiao Sun"],"pdf_url":"https://arxiv.org/pdf/2503.05180v1.pdf","comment":"Accepted by ICRA 2025"},{"id":"http://arxiv.org/abs/2503.05179v1","updated":"2025-03-07T06:57:17Z","published":"2025-03-07T06:57:17Z","title":"Sketch-of-Thought: Efficient LLM Reasoning with Adaptive\n  Cognitive-Inspired Sketching","summary":"  Recent advances in large language models have demonstrated remarkable\nreasoning capabilities through Chain of Thought (CoT) prompting, but often at\nthe cost of excessive verbosity in their intermediate outputs, which increases\ncomputational overhead. We introduce Sketch-of-Thought (SoT), a novel prompting\nframework that combines cognitive-inspired reasoning paradigms with linguistic\nconstraints to minimize token usage while preserving reasoning accuracy. SoT is\ndesigned as a flexible framework that can incorporate any custom reasoning\nparadigms based on cognitive science, and we instantiate it with three such\nparadigms - Conceptual Chaining, Chunked Symbolism, and Expert Lexicons - each\ntailored to different reasoning tasks and selected dynamically via a\nlightweight routing model. Through comprehensive evaluation across 15 reasoning\ndatasets with multiple languages and multimodal scenarios, we demonstrate that\nSoT achieves token reductions of 76% with negligible accuracy impact. In\ncertain domains like mathematical and multi-hop reasoning, it even improves\naccuracy while using significantly fewer tokens. Our code is publicly\navailable: https://www.github.com/SimonAytes/SoT.\n","authors":["Simon A. Aytes","Jinheon Baek","Sung Ju Hwang"],"pdf_url":"https://arxiv.org/pdf/2503.05179v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.05175v1","updated":"2025-03-07T06:42:17Z","published":"2025-03-07T06:42:17Z","title":"Self-Supervised Penalty-Based Learning for Robust Constrained\n  Optimization","summary":"  We propose a new methodology for parameterized constrained robust\noptimization, an important class of optimization problems under uncertainty,\nbased on learning with a self-supervised penalty-based loss function. Whereas\nsupervised learning requires pre-solved instances for training, our approach\nleverages a custom loss function derived from the exact penalty method in\noptimization to learn an approximation, typically defined by a neural network\nmodel, of the parameterized optimal solution mapping. Additionally, we adapt\nour approach to robust constrained combinatorial optimization problems by\nincorporating a surrogate linear cost over mixed integer domains, and a smooth\napproximations thereof, into the final layer of the network architecture. We\nperform computational experiments to test our approach on three different\napplications: multidimensional knapsack with continuous variables,\ncombinatorial multidimensional knapsack with discrete variables, and an\ninventory management problem. Our results demonstrate that our self-supervised\napproach is able to effectively learn neural network approximations whose\ninference time is significantly smaller than the computation time of\ntraditional solvers for this class of robust optimization problems.\nFurthermore, our results demonstrate that by varying the penalty parameter we\nare able to effectively balance the trade-off between sub-optimality and robust\nfeasibility of the obtained solutions.\n","authors":["Wyame Benslimane","Paul Grigas"],"pdf_url":"https://arxiv.org/pdf/2503.05175v1.pdf","comment":"To appear in the proceedings of CPAIOR 2025"},{"id":"http://arxiv.org/abs/2503.05169v1","updated":"2025-03-07T06:25:20Z","published":"2025-03-07T06:25:20Z","title":"phepy: Visual Benchmarks and Improvements for Out-of-Distribution\n  Detectors","summary":"  Applying machine learning to increasingly high-dimensional problems with\nsparse or biased training data increases the risk that a model is used on\ninputs outside its training domain. For such out-of-distribution (OOD) inputs,\nthe model can no longer make valid predictions, and its error is potentially\nunbounded.\n  Testing OOD detection methods on real-world datasets is complicated by the\nambiguity around which inputs are in-distribution (ID) or OOD. We design a\nbenchmark for OOD detection, which includes three novel and easily-visualisable\ntoy examples. These simple examples provide direct and intuitive insight into\nwhether the detector is able to detect (1) linear and (2) non-linear concepts\nand (3) identify thin ID subspaces (needles) within high-dimensional spaces\n(haystacks). We use our benchmark to evaluate the performance of various\nmethods from the literature.\n  Since tactile examples of OOD inputs may benefit OOD detection, we also\nreview several simple methods to synthesise OOD inputs for supervised training.\nWe introduce two improvements, $t$-poking and OOD sample weighting, to make\nsupervised detectors more precise at the ID-OOD boundary. This is especially\nimportant when conflicts between real ID and synthetic OOD sample blur the\ndecision boundary.\n  Finally, we provide recommendations for constructing and applying\nout-of-distribution detectors in machine learning.\n","authors":["Juniper Tyree","Andreas Rupp","Petri S. Clusius","Michael H. Boy"],"pdf_url":"https://arxiv.org/pdf/2503.05169v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.05167v1","updated":"2025-03-07T06:14:26Z","published":"2025-03-07T06:14:26Z","title":"FMCHS: Advancing Traditional Chinese Medicine Herb Recommendation with\n  Fusion of Multiscale Correlations of Herbs and Symptoms","summary":"  Traditional Chinese medicine (TCM) exhibits remarkable therapeutic efficacy\nin disease treatment and healthcare through personalized herb prescriptions.\nHowever, current herb recommendation models inadequately capture the multiscale\nrelations between herbs and clinical symptoms, particularly neglecting latent\ncorrelations at the chemical-molecular scale. To address these limitations, we\npropose the Fusion of Multiscale Correlations of Herbs and Symptoms (FMCHS), an\ninnovative framework that synergistically integrates molecular-scale chemical\ncharacteristics of herbs with clinical symptoms. The framework employs\nmulti-relational graph transformer layers to generate enriched embeddings that\npreserve both structural and semantic features within herbs and symptoms.\nThrough systematic incorporation of herb chemical profiles into node embeddings\nand implementation of attention-based feature fusion, FMCHS effectively\nutilizes multiscale correlations. Comprehensive evaluations demonstrate FMCHS's\nsuperior performance over the state-of-the-art (SOTA) baseline, achieving\nrelative improvements of 8.85% in Precision@5, 12.30% in Recall@5, and 10.86%\nin F1@5 compared to the SOTA model on benchmark datasets. This work facilitates\nthe practical application of TCM in disease treatment and healthcare.\n","authors":["Xinhan Zheng","Huyu Wu","Haopeng Jin","Ruotai Li"],"pdf_url":"https://arxiv.org/pdf/2503.05167v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2412.11542v3","updated":"2025-03-07T05:49:35Z","published":"2024-12-16T08:22:23Z","title":"Meta Curvature-Aware Minimization for Domain Generalization","summary":"  Domain generalization (DG) aims to enhance the ability of models trained on\nsource domains to generalize effectively to unseen domains. Recently,\nSharpness-Aware Minimization (SAM) has shown promise in this area by reducing\nthe sharpness of the loss landscape to obtain more generalized models. However,\nSAM and its variants sometimes fail to guide the model toward a flat minimum,\nand their training processes exhibit limitations, hindering further\nimprovements in model generalization. In this paper, we first propose an\nimproved model training process aimed at encouraging the model to converge to a\nflat minima. To achieve this, we design a curvature metric that has a minimal\neffect when the model is far from convergence but becomes increasingly\ninfluential in indicating the curvature of the minima as the model approaches a\nlocal minimum. Then we derive a novel algorithm from this metric, called Meta\nCurvature-Aware Minimization (MeCAM), to minimize the curvature around the\nlocal minima. Specifically, the optimization objective of MeCAM simultaneously\nminimizes the regular training loss, the surrogate gap of SAM, and the\nsurrogate gap of meta-learning. We provide theoretical analysis on MeCAM's\ngeneralization error and convergence rate, and demonstrate its superiority over\nexisting DG methods through extensive experiments on five benchmark DG\ndatasets, including PACS, VLCS, OfficeHome, TerraIncognita, and DomainNet. Code\nwill be available on GitHub.\n","authors":["Ziyang Chen","Yiwen Ye","Feilong Tang","Yongsheng Pan","Yong Xia"],"pdf_url":"https://arxiv.org/pdf/2412.11542v3.pdf","comment":"22 pages, 5 figures, 16 tables"},{"id":"http://arxiv.org/abs/2407.12282v2","updated":"2025-03-07T05:47:20Z","published":"2024-07-17T03:02:24Z","title":"Chip Placement with Diffusion Models","summary":"  Macro placement is a vital step in digital circuit design that defines the\nphysical location of large collections of components, known as macros, on a 2D\nchip. Because key performance metrics of the chip are determined by the\nplacement, optimizing it is crucial. Existing learning-based methods typically\nfall short because of their reliance on reinforcement learning (RL), which is\nslow and struggles to generalize, requiring online training on each new\ncircuit. Instead, we train a diffusion model capable of placing new circuits\nzero-shot, using guided sampling in lieu of RL to optimize placement quality.\nTo enable such models to train at scale, we designed a capable yet efficient\narchitecture for the denoising model, and propose a novel algorithm to generate\nlarge synthetic datasets for pre-training. To allow zero-shot transfer to real\ncircuits, we empirically study the design decisions of our dataset generation\nalgorithm, and identify several key factors enabling generalization. When\ntrained on our synthetic data, our models generate high-quality placements on\nunseen, realistic circuits, achieving competitive performance on placement\nbenchmarks compared to state-of-the-art methods.\n","authors":["Vint Lee","Minh Nguyen","Leena Elzeiny","Chun Deng","Pieter Abbeel","John Wawrzynek"],"pdf_url":"https://arxiv.org/pdf/2407.12282v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2401.10510v3","updated":"2025-03-07T05:29:18Z","published":"2024-01-19T05:58:30Z","title":"When Large Language Models Meet Evolutionary Algorithms: Potential\n  Enhancements and Challenges","summary":"  Pre-trained large language models (LLMs) exhibit powerful capabilities for\ngenerating natural text. Evolutionary algorithms (EAs) can discover diverse\nsolutions to complex real-world problems. Motivated by the common collective\nand directionality of text generation and evolution, this paper first\nillustrates the conceptual parallels between LLMs and EAs at a micro level,\nwhich includes multiple one-to-one key characteristics: token representation\nand individual representation, position encoding and fitness shaping, position\nembedding and selection, Transformers block and reproduction, and model\ntraining and parameter adaptation. These parallels highlight potential\nopportunities for technical advancements in both LLMs and EAs. Subsequently, we\nanalyze existing interdisciplinary research from a macro perspective to uncover\ncritical challenges, with a particular focus on evolutionary fine-tuning and\nLLM-enhanced EAs. These analyses not only provide insights into the\nevolutionary mechanisms behind LLMs but also offer potential directions for\nenhancing the capabilities of artificial agents.\n","authors":["Chao Wang","Jiaxuan Zhao","Licheng Jiao","Lingling Li","Fang Liu","Shuyuan Yang"],"pdf_url":"https://arxiv.org/pdf/2401.10510v3.pdf","comment":"The article has been accepted for publication in Research"},{"id":"http://arxiv.org/abs/2411.06042v2","updated":"2025-03-07T05:25:46Z","published":"2024-11-09T02:41:53Z","title":"Personalized Hierarchical Split Federated Learning in Wireless Networks","summary":"  Extreme resource constraints make large-scale machine learning (ML) with\ndistributed clients challenging in wireless networks. On the one hand,\nlarge-scale ML requires massive information exchange between clients and\nserver(s). On the other hand, these clients have limited battery and\ncomputation powers that are often dedicated to operational computations. Split\nfederated learning (SFL) is emerging as a potential solution to mitigate these\nchallenges, by splitting the ML model into client-side and server-side model\nblocks, where only the client-side block is trained on the client device.\nHowever, practical applications require personalized models that are suitable\nfor the client's personal task. Motivated by this, we propose a personalized\nhierarchical split federated learning (PHSFL) algorithm that is specially\ndesigned to achieve better personalization performance. More specially, owing\nto the fact that regardless of the severity of the statistical data\ndistributions across the clients, many of the features have similar attributes,\nwe only train the body part of the federated learning (FL) model while keeping\nthe (randomly initialized) classifier frozen during the training phase. We\nfirst perform extensive theoretical analysis to understand the impact of model\nsplitting and hierarchical model aggregations on the global model. Once the\nglobal model is trained, we fine-tune each client classifier to obtain the\npersonalized models. Our empirical findings suggest that while the globally\ntrained model with the untrained classifier performs quite similarly to other\nexisting solutions, the fine-tuned models show significantly improved\npersonalized performance.\n","authors":["Md-Ferdous Pervej","Andreas F. Molisch"],"pdf_url":"https://arxiv.org/pdf/2411.06042v2.pdf","comment":"Accepted for publication in IEEE ICC 2025"},{"id":"http://arxiv.org/abs/2503.05153v1","updated":"2025-03-07T05:22:52Z","published":"2025-03-07T05:22:52Z","title":"Generative Trajectory Stitching through Diffusion Composition","summary":"  Effective trajectory stitching for long-horizon planning is a significant\nchallenge in robotic decision-making. While diffusion models have shown promise\nin planning, they are limited to solving tasks similar to those seen in their\ntraining data. We propose CompDiffuser, a novel generative approach that can\nsolve new tasks by learning to compositionally stitch together shorter\ntrajectory chunks from previously seen tasks. Our key insight is modeling the\ntrajectory distribution by subdividing it into overlapping chunks and learning\ntheir conditional relationships through a single bidirectional diffusion model.\nThis allows information to propagate between segments during generation,\nensuring physically consistent connections. We conduct experiments on benchmark\ntasks of various difficulties, covering different environment sizes, agent\nstate dimension, trajectory types, training data quality, and show that\nCompDiffuser significantly outperforms existing methods.\n","authors":["Yunhao Luo","Utkarsh A. Mishra","Yilun Du","Danfei Xu"],"pdf_url":"https://arxiv.org/pdf/2503.05153v1.pdf","comment":"Project page: https://comp-diffuser.github.io/"},{"id":"http://arxiv.org/abs/2404.10220v2","updated":"2025-03-07T05:09:28Z","published":"2024-04-16T02:01:56Z","title":"Closed-Loop Open-Vocabulary Mobile Manipulation with GPT-4V","summary":"  Autonomous robot navigation and manipulation in open environments require\nreasoning and replanning with closed-loop feedback. In this work, we present\nCOME-robot, the first closed-loop robotic system utilizing the GPT-4V\nvision-language foundation model for open-ended reasoning and adaptive planning\nin real-world scenarios.COME-robot incorporates two key innovative modules: (i)\na multi-level open-vocabulary perception and situated reasoning module that\nenables effective exploration of the 3D environment and target object\nidentification using commonsense knowledge and situated information, and (ii)\nan iterative closed-loop feedback and restoration mechanism that verifies task\nfeasibility, monitors execution success, and traces failure causes across\ndifferent modules for robust failure recovery. Through comprehensive\nexperiments involving 8 challenging real-world mobile and tabletop manipulation\ntasks, COME-robot demonstrates a significant improvement in task success rate\n(~35%) compared to state-of-the-art methods. We further conduct comprehensive\nanalyses to elucidate how COME-robot's design facilitates failure recovery,\nfree-form instruction following, and long-horizon task planning.\n","authors":["Peiyuan Zhi","Zhiyuan Zhang","Yu Zhao","Muzhi Han","Zeyu Zhang","Zhitian Li","Ziyuan Jiao","Baoxiong Jia","Siyuan Huang"],"pdf_url":"https://arxiv.org/pdf/2404.10220v2.pdf","comment":"6 pages, Accepted at 2025 IEEE ICRA, website:\n  https://come-robot.github.io/"},{"id":"http://arxiv.org/abs/2503.05146v1","updated":"2025-03-07T05:08:23Z","published":"2025-03-07T05:08:23Z","title":"Unity RL Playground: A Versatile Reinforcement Learning Framework for\n  Mobile Robots","summary":"  This paper introduces Unity RL Playground, an open-source reinforcement\nlearning framework built on top of Unity ML-Agents. Unity RL Playground\nautomates the process of training mobile robots to perform various locomotion\ntasks such as walking, running, and jumping in simulation, with the potential\nfor seamless transfer to real hardware. Key features include one-click training\nfor imported robot models, universal compatibility with diverse robot\nconfigurations, multi-mode motion learning capabilities, and extreme\nperformance testing to aid in robot design optimization and morphological\nevolution. The attached video can be found at\nhttps://linqi-ye.github.io/video/iros25.mp4 and the code is coming soon.\n","authors":["Linqi Ye","Rankun Li","Xiaowen Hu","Jiayi Li","Boyang Xing","Yan Peng","Bin Liang"],"pdf_url":"https://arxiv.org/pdf/2503.05146v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.05143v1","updated":"2025-03-07T04:52:20Z","published":"2025-03-07T04:52:20Z","title":"FedMABench: Benchmarking Mobile Agents on Decentralized Heterogeneous\n  User Data","summary":"  Mobile agents have attracted tremendous research participation recently.\nTraditional approaches to mobile agent training rely on centralized data\ncollection, leading to high cost and limited scalability. Distributed training\nutilizing federated learning offers an alternative by harnessing real-world\nuser data, providing scalability and reducing costs. However, pivotal\nchallenges, including the absence of standardized benchmarks, hinder progress\nin this field.\n  To tackle the challenges, we introduce FedMABench, the first benchmark for\nfederated training and evaluation of mobile agents, specifically designed for\nheterogeneous scenarios. FedMABench features 6 datasets with 30+ subsets, 8\nfederated algorithms, 10+ base models, and over 800 apps across 5 categories,\nproviding a comprehensive framework for evaluating mobile agents across diverse\nenvironments. Through extensive experiments, we uncover several key insights:\nfederated algorithms consistently outperform local training; the distribution\nof specific apps plays a crucial role in heterogeneity; and, even apps from\ndistinct categories can exhibit correlations during training. FedMABench is\npublicly available at: https://github.com/wwh0411/FedMABench with the datasets\nat: https://huggingface.co/datasets/wwh0411/FedMABench.\n","authors":["Wenhao Wang","Zijie Yu","Rui Ye","Jianqing Zhang","Siheng Chen","Yanfeng Wang"],"pdf_url":"https://arxiv.org/pdf/2503.05143v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2501.09898v3","updated":"2025-03-07T04:45:23Z","published":"2025-01-17T01:01:44Z","title":"FoundationStereo: Zero-Shot Stereo Matching","summary":"  Tremendous progress has been made in deep stereo matching to excel on\nbenchmark datasets through per-domain fine-tuning. However, achieving strong\nzero-shot generalization - a hallmark of foundation models in other computer\nvision tasks - remains challenging for stereo matching. We introduce\nFoundationStereo, a foundation model for stereo depth estimation designed to\nachieve strong zero-shot generalization. To this end, we first construct a\nlarge-scale (1M stereo pairs) synthetic training dataset featuring large\ndiversity and high photorealism, followed by an automatic self-curation\npipeline to remove ambiguous samples. We then design a number of network\narchitecture components to enhance scalability, including a side-tuning feature\nbackbone that adapts rich monocular priors from vision foundation models to\nmitigate the sim-to-real gap, and long-range context reasoning for effective\ncost volume filtering. Together, these components lead to strong robustness and\naccuracy across domains, establishing a new standard in zero-shot stereo depth\nestimation. Project page: https://nvlabs.github.io/FoundationStereo/\n","authors":["Bowen Wen","Matthew Trepte","Joseph Aribido","Jan Kautz","Orazio Gallo","Stan Birchfield"],"pdf_url":"https://arxiv.org/pdf/2501.09898v3.pdf","comment":"CVPR 2025"},{"id":"http://arxiv.org/abs/2503.05139v1","updated":"2025-03-07T04:43:39Z","published":"2025-03-07T04:43:39Z","title":"Every FLOP Counts: Scaling a 300B Mixture-of-Experts LING LLM without\n  Premium GPUs","summary":"  In this technical report, we tackle the challenges of training large-scale\nMixture of Experts (MoE) models, focusing on overcoming cost inefficiency and\nresource limitations prevalent in such systems. To address these issues, we\npresent two differently sized MoE large language models (LLMs), namely\nLing-Lite and Ling-Plus (referred to as \"Bailing\" in Chinese, spelled\nB\\v{a}il\\'ing in Pinyin). Ling-Lite contains 16.8 billion parameters with 2.75\nbillion activated parameters, while Ling-Plus boasts 290 billion parameters\nwith 28.8 billion activated parameters. Both models exhibit comparable\nperformance to leading industry benchmarks. This report offers actionable\ninsights to improve the efficiency and accessibility of AI development in\nresource-constrained settings, promoting more scalable and sustainable\ntechnologies. Specifically, to reduce training costs for large-scale MoE\nmodels, we propose innovative methods for (1) optimization of model\narchitecture and training processes, (2) refinement of training anomaly\nhandling, and (3) enhancement of model evaluation efficiency. Additionally,\nleveraging high-quality data generated from knowledge graphs, our models\ndemonstrate superior capabilities in tool use compared to other models.\nUltimately, our experimental findings demonstrate that a 300B MoE LLM can be\neffectively trained on lower-performance devices while achieving comparable\nperformance to models of a similar scale, including dense and MoE models.\nCompared to high-performance devices, utilizing a lower-specification hardware\nsystem during the pre-training phase demonstrates significant cost savings,\nreducing computing costs by approximately 20%. The models can be accessed at\nhttps://huggingface.co/inclusionAI.\n","authors":[" Ling Team","Binwei Zeng","Chao Huang","Chao Zhang","Changxin Tian","Cong Chen","Dingnan Jin","Feng Yu","Feng Zhu","Feng Yuan","Fakang Wang","Gangshan Wang","Guangyao Zhai","Haitao Zhang","Huizhong Li","Jun Zhou","Jia Liu","Junpeng Fang","Junjie Ou","Jun Hu","Ji Luo","Ji Zhang","Jian Liu","Jian Sha","Jianxue Qian","Jiewei Wu","Junping Zhao","Jianguo Li","Jubao Feng","Jingchao Di","Junming Xu","Jinghua Yao","Kuan Xu","Kewei Du","Longfei Li","Lei Liang","Lu Yu","Li Tang","Lin Ju","Peng Xu","Qing Cui","Song Liu","Shicheng Li","Shun Song","Song Yan","Tengwei Cai","Tianyi Chen","Ting Guo","Ting Huang","Tao Feng","Tao Wu","Wei Wu","Xiaolu Zhang","Xueming Yang","Xin Zhao","Xiaobo Hu","Xin Lin","Yao Zhao","Yilong Wang","Yongzhen Guo","Yuanyuan Wang","Yue Yang","Yang Cao","Yuhao Fu","Yi Xiong","Yanzhe Li","Zhe Li","Zhiqiang Zhang","Ziqi Liu","Zhaoxin Huan","Zujie Wen","Zhenhang Sun","Zhuoxuan Du","Zhengyu He"],"pdf_url":"https://arxiv.org/pdf/2503.05139v1.pdf","comment":"34 pages"},{"id":"http://arxiv.org/abs/2411.11521v2","updated":"2025-03-07T04:39:05Z","published":"2024-11-18T12:31:22Z","title":"Preempting Text Sanitization Utility in Resource-Constrained\n  Privacy-Preserving LLM Interactions","summary":"  Interactions with online Large Language Models raise privacy issues where\nproviders can gather sensitive information about users and their companies from\nthe prompts. While Differential Privacy can be applied on textual prompts\nthrough the Multidimensional Laplace Mechanism, we show that it is difficult to\nanticipate the utility of such sanitized prompt. Poor utility has clear\nmonetary consequences for LLM services charging on a pay-per-use model as well\nas great amount of computing resources wasted. To this end, we propose an\narchitecture to predict the utility of a given sanitized prompt before it is\nsent to the LLM. We experimentally show that our architecture helps prevent\nsuch resource waste for up to 12% of the prompts. We also reproduce experiments\nfrom one of the most cited paper on distance-based DP for text sanitization and\nshow that a potential performance-driven implementation choice completely\nchanges the output while not being explicitly defined in the paper.\n","authors":["Robin Carpentier","Benjamin Zi Hao Zhao","Hassan Jameel Asghar","Dali Kaafar"],"pdf_url":"https://arxiv.org/pdf/2411.11521v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2502.10020v3","updated":"2025-03-07T04:29:35Z","published":"2025-02-14T09:01:12Z","title":"Improved Online Confidence Bounds for Multinomial Logistic Bandits","summary":"  In this paper, we propose an improved online confidence bound for multinomial\nlogistic (MNL) models and apply this result to MNL bandits, achieving\nvariance-dependent optimal regret. Recently, Lee & Oh (2024) established an\nonline confidence bound for MNL models and achieved nearly minimax-optimal\nregret in MNL bandits. However, their results still depend on the\nnorm-boundedness of the unknown parameter $B$ and the maximum size of possible\noutcomes $K$. To address this, we first derive an online confidence bound of\n$O\\left(\\sqrt{d \\log t} + B \\right)$, which is a significant improvement over\nthe previous bound of $O (B \\sqrt{d} \\log t \\log K )$ (Lee & Oh, 2024). This is\nmainly achieved by establishing tighter self-concordant properties of the MNL\nloss and introducing a novel intermediary term to bound the estimation error.\nUsing this new online confidence bound, we propose a constant-time algorithm,\nOFU-MNL++, which achieves a variance-dependent regret bound of $O \\Big( d \\log\nT \\sqrt{ \\sum_{t=1}^T \\sigma_t^2 } \\Big) $ for sufficiently large $T$, where\n$\\sigma_t^2$ denotes the variance of the rewards at round $t$, $d$ is the\ndimension of the contexts, and $T$ is the total number of rounds. Furthermore,\nwe introduce a Maximum Likelihood Estimation (MLE)-based algorithm,\nOFU-MN$^2$L, which achieves an anytime poly(B)-free regret of $O \\Big( d \\log\n(BT) \\sqrt{ \\sum_{t=1}^T \\sigma_t^2 } \\Big) $.\n","authors":["Joongkyu Lee","Min-hwan Oh"],"pdf_url":"https://arxiv.org/pdf/2502.10020v3.pdf","comment":"Preprint. Under review"},{"id":"http://arxiv.org/abs/2410.21357v4","updated":"2025-03-07T04:28:45Z","published":"2024-10-28T17:25:56Z","title":"Energy-Based Diffusion Language Models for Text Generation","summary":"  Despite remarkable progress in autoregressive language models, alternative\ngenerative paradigms beyond left-to-right generation are still being actively\nexplored. Discrete diffusion models, with the capacity for parallel generation,\nhave recently emerged as a promising alternative. Unfortunately, these models\nstill underperform the autoregressive counterparts, with the performance gap\nincreasing when reducing the number of sampling steps. Our analysis reveals\nthat this degradation is a consequence of an imperfect approximation used by\ndiffusion models. In this work, we propose Energy-based Diffusion Language\nModel (EDLM), an energy-based model operating at the full sequence level for\neach diffusion step, introduced to improve the underlying approximation used by\ndiffusion models. More specifically, we introduce an EBM in a residual form,\nand show that its parameters can be obtained by leveraging a pretrained\nautoregressive model or by finetuning a bidirectional transformer via noise\ncontrastive estimation. We also propose an efficient generation algorithm via\nparallel important sampling. Comprehensive experiments on language modeling\nbenchmarks show that our model can consistently outperform state-of-the-art\ndiffusion models by a significant margin, and approaches autoregressive models'\nperplexity. We further show that, without any generation performance drop, our\nframework offers a 1.3$\\times$ sampling speedup over existing diffusion models.\nReproduced code is available at\nhttps://github.com/MinkaiXu/Energy-Diffusion-LLM.\n","authors":["Minkai Xu","Tomas Geffner","Karsten Kreis","Weili Nie","Yilun Xu","Jure Leskovec","Stefano Ermon","Arash Vahdat"],"pdf_url":"https://arxiv.org/pdf/2410.21357v4.pdf","comment":null},{"id":"http://arxiv.org/abs/2405.09831v8","updated":"2025-03-07T04:23:19Z","published":"2024-05-16T06:07:31Z","title":"Nearly Minimax Optimal Regret for Multinomial Logistic Bandit","summary":"  In this paper, we study the contextual multinomial logit (MNL) bandit problem\nin which a learning agent sequentially selects an assortment based on\ncontextual information, and user feedback follows an MNL choice model. There\nhas been a significant discrepancy between lower and upper regret bounds,\nparticularly regarding the maximum assortment size $K$. Additionally, the\nvariation in reward structures between these bounds complicates the quest for\noptimality. Under uniform rewards, where all items have the same expected\nreward, we establish a regret lower bound of $\\Omega(d\\sqrt{T/K})$ and propose\na constant-time algorithm, OFU-MNL+, that achieves a matching upper bound of\n$\\tilde{O}(d\\sqrt{T/K})$. We also provide instance-dependent minimax regret\nbounds under uniform rewards. Under non-uniform rewards, we prove a lower bound\nof $\\Omega(d\\sqrt{T})$ and an upper bound of $\\tilde{O}(d\\sqrt{T})$, also\nachievable by OFU-MNL+. Our empirical studies support these theoretical\nfindings. To the best of our knowledge, this is the first work in the\ncontextual MNL bandit literature to prove minimax optimality -- for either\nuniform or non-uniform reward setting -- and to propose a computationally\nefficient algorithm that achieves this optimality up to logarithmic factors.\n","authors":["Joongkyu Lee","Min-hwan Oh"],"pdf_url":"https://arxiv.org/pdf/2405.09831v8.pdf","comment":"Accepted in NeurIPS 2024"}],"Information Retrieval":[{"id":"http://arxiv.org/abs/2503.05659v1","updated":"2025-03-07T18:20:30Z","published":"2025-03-07T18:20:30Z","title":"A Survey of Large Language Model Empowered Agents for Recommendation and\n  Search: Towards Next-Generation Information Retrieval","summary":"  Information technology has profoundly altered the way humans interact with\ninformation. The vast amount of content created, shared, and disseminated\nonline has made it increasingly difficult to access relevant information. Over\nthe past two decades, search and recommendation systems (collectively referred\nto as information retrieval systems) have evolved significantly to address\nthese challenges. Recent advances in large language models (LLMs) have\ndemonstrated capabilities that surpass human performance in various\nlanguage-related tasks and exhibit general understanding, reasoning, and\ndecision-making abilities. This paper explores the transformative potential of\nlarge language model agents in enhancing search and recommendation systems. We\ndiscuss the motivations and roles of LLM agents, and establish a classification\nframework to elaborate on the existing research. We highlight the immense\npotential of LLM agents in addressing current challenges in search and\nrecommendation, providing insights into future research directions. This paper\nis the first to systematically review and classify the research on LLM agents\nin these domains, offering a novel perspective on leveraging this advanced AI\ntechnology for information retrieval. To help understand the existing works, we\nlist the existing papers on agent-based simulation with large language models\nat this link:\nhttps://github.com/tsinghua-fib-lab/LLM-Agent-for-Recommendation-and-Search.\n","authors":["Yu Zhang","Shutong Qiao","Jiaqi Zhang","Tzu-Heng Lin","Chen Gao","Yong Li"],"pdf_url":"https://arxiv.org/pdf/2503.05659v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.05596v1","updated":"2025-03-07T17:24:00Z","published":"2025-03-07T17:24:00Z","title":"Bridging Classical and Quantum String Matching: A Computational\n  Reformulation of Bit-Parallelism","summary":"  String matching is a fundamental problem in computer science, with critical\napplications in text retrieval, bioinformatics, and data analysis. Among the\nnumerous solutions that have emerged for this problem in recent decades,\nbit-parallelism has significantly enhanced their practical efficiency, leading\nto the development of several optimized approaches for both exact and\napproximate string matching. However, their potential in quantum computing\nremains largely unexplored. This paper presents a novel pathway that not only\ntranslates bit-parallel string matching algorithms into the quantum framework\nbut also enhances their performance to achieve a quadratic speedup through\nGrover's search. By embedding quantum search within a bit-parallel model, we\nreduce the time complexity of string matching, establishing a structured\npathway for transforming classical algorithms into quantum solutions with\nprovable computational advantages. Beyond exact matching, this technique offers\na foundation for tackling a wide range of non-standard string matching\nproblems, opening new avenues for efficient text searching in the quantum era.\nTo demonstrate the simplicity and adaptability of the technique presented in\nthis paper, we apply this translation and adaptation process to two landmark\nbit-parallel algorithms: Shift-And for exact pattern matching and Shift-Add for\napproximate string matching with up to k errors.\n","authors":["Simone Faro","Arianna Pavone","Caterina Viola"],"pdf_url":"https://arxiv.org/pdf/2503.05596v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.05592v1","updated":"2025-03-07T17:14:44Z","published":"2025-03-07T17:14:44Z","title":"R1-Searcher: Incentivizing the Search Capability in LLMs via\n  Reinforcement Learning","summary":"  Existing Large Reasoning Models (LRMs) have shown the potential of\nreinforcement learning (RL) to enhance the complex reasoning capabilities of\nLarge Language Models~(LLMs). While they achieve remarkable performance on\nchallenging tasks such as mathematics and coding, they often rely on their\ninternal knowledge to solve problems, which can be inadequate for\ntime-sensitive or knowledge-intensive questions, leading to inaccuracies and\nhallucinations. To address this, we propose \\textbf{R1-Searcher}, a novel\ntwo-stage outcome-based RL approach designed to enhance the search capabilities\nof LLMs. This method allows LLMs to autonomously invoke external search systems\nto access additional knowledge during the reasoning process. Our framework\nrelies exclusively on RL, without requiring process rewards or distillation for\na cold start. % effectively generalizing to out-of-domain datasets and\nsupporting both Base and Instruct models. Our experiments demonstrate that our\nmethod significantly outperforms previous strong RAG methods, even when\ncompared to the closed-source GPT-4o-mini.\n","authors":["Huatong Song","Jinhao Jiang","Yingqian Min","Jie Chen","Zhipeng Chen","Wayne Xin Zhao","Lei Fang","Ji-Rong Wen"],"pdf_url":"https://arxiv.org/pdf/2503.05592v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.05493v1","updated":"2025-03-07T15:05:23Z","published":"2025-03-07T15:05:23Z","title":"Benchmarking LLMs in Recommendation Tasks: A Comparative Evaluation with\n  Conventional Recommenders","summary":"  In recent years, integrating large language models (LLMs) into recommender\nsystems has created new opportunities for improving recommendation quality.\nHowever, a comprehensive benchmark is needed to thoroughly evaluate and compare\nthe recommendation capabilities of LLMs with traditional recommender systems.\nIn this paper, we introduce RecBench, which systematically investigates various\nitem representation forms (including unique identifier, text, semantic\nembedding, and semantic identifier) and evaluates two primary recommendation\ntasks, i.e., click-through rate prediction (CTR) and sequential recommendation\n(SeqRec). Our extensive experiments cover up to 17 large models and are\nconducted across five diverse datasets from fashion, news, video, books, and\nmusic domains. Our findings indicate that LLM-based recommenders outperform\nconventional recommenders, achieving up to a 5% AUC improvement in the CTR\nscenario and up to a 170% NDCG@10 improvement in the SeqRec scenario. However,\nthese substantial performance gains come at the expense of significantly\nreduced inference efficiency, rendering the LLM-as-RS paradigm impractical for\nreal-time recommendation environments. We aim for our findings to inspire\nfuture research, including recommendation-specific model acceleration methods.\nWe will release our code, data, configurations, and platform to enable other\nresearchers to reproduce and build upon our experimental results.\n","authors":["Qijiong Liu","Jieming Zhu","Lu Fan","Kun Wang","Hengchang Hu","Wei Guo","Yong Liu","Xiao-Ming Wu"],"pdf_url":"https://arxiv.org/pdf/2503.05493v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2308.01196v3","updated":"2025-03-07T12:31:27Z","published":"2023-07-27T22:57:55Z","title":"Sustainable transparency in Recommender Systems: Bayesian Ranking of\n  Images for Explainability","summary":"  Recommender Systems have become crucial in the modern world, commonly guiding\nusers towards relevant content or products, and having a large influence over\nthe decisions of users and citizens. However, ensuring transparency and user\ntrust in these systems remains a challenge; personalized explanations have\nemerged as a solution, offering justifications for recommendations. Among the\nexisting approaches for generating personalized explanations, using existing\nvisual content created by users is a promising option to maximize transparency\nand user trust. State-of-the-art models that follow this approach, despite\nleveraging highly optimized architectures, employ surrogate learning tasks that\ndo not efficiently model the objective of ranking images as explanations for a\ngiven recommendation; this leads to a suboptimal training process with high\ncomputational costs that may not be reduced without affecting model\nperformance. This work presents BRIE, a novel model where we leverage Bayesian\nPairwise Ranking to enhance the training process, allowing us to consistently\noutperform state-of-the-art models in six real-world datasets while reducing\nits model size by up to 64 times and its CO2 emissions by up to 75% in training\nand inference.\n","authors":["Jorge Paz-Ruza","Amparo Alonso-Betanzos","Berta Guijarro-Berdias","Brais Cancela","Carlos Eiras-Franco"],"pdf_url":"https://arxiv.org/pdf/2308.01196v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.05315v1","updated":"2025-03-07T10:50:45Z","published":"2025-03-07T10:50:45Z","title":"LoRACode: LoRA Adapters for Code Embeddings","summary":"  Code embeddings are essential for semantic code search; however, current\napproaches often struggle to capture the precise syntactic and contextual\nnuances inherent in code. Open-source models such as CodeBERT and UniXcoder\nexhibit limitations in scalability and efficiency, while high-performing\nproprietary systems impose substantial computational costs. We introduce a\nparameter-efficient fine-tuning method based on Low-Rank Adaptation (LoRA) to\nconstruct task-specific adapters for code retrieval. Our approach reduces the\nnumber of trainable parameters to less than two percent of the base model,\nenabling rapid fine-tuning on extensive code corpora (2 million samples in 25\nminutes on two H100 GPUs). Experiments demonstrate an increase of up to 9.1% in\nMean Reciprocal Rank (MRR) for Code2Code search, and up to 86.69% for Text2Code\nsearch tasks across multiple programming languages. Distinction in task-wise\nand language-wise adaptation helps explore the sensitivity of code retrieval\nfor syntactical and linguistic variations.\n","authors":["Saumya Chaturvedi","Aman Chadha","Laurent Bindschaedler"],"pdf_url":"https://arxiv.org/pdf/2503.05315v1.pdf","comment":"Accepted at the Deep Learning for Code (DL4C) Workshop at ICLR 2025"},{"id":"http://arxiv.org/abs/2401.10690v4","updated":"2025-03-07T08:40:19Z","published":"2024-01-19T13:41:08Z","title":"Beyond RMSE and MAE: Introducing EAUC to unmask hidden bias and\n  unfairness in dyadic regression models","summary":"  Dyadic regression models, which output real-valued predictions for pairs of\nentities, are fundamental in many domains (e.g. obtaining user-product ratings\nin Recommender Systems) and promising and under exploration in others (e.g.\ntuning patient-drug dosages in precision pharmacology). In this work, we prove\nthat non-uniform observed value distributions of individual entities lead to\nsevere biases in state-of-the-art models, skewing predictions towards the\naverage of observed past values for the entity and providing worse-than-random\npredictive power in eccentric yet crucial cases; we name this phenomenon\neccentricity bias. We show that global error metrics like Root Mean Squared\nError (RMSE) are insufficient to capture this bias, and we introduce\nEccentricity-Area Under the Curve (EAUC) as a novel metric that can quantify it\nin all studied domains and models. We prove the intuitive interpretation of\nEAUC by experimenting with naive post-training bias corrections, and theorize\nother options to use EAUC to guide the construction of fair models. This work\ncontributes a bias-aware evaluation of dyadic regression to prevent unfairness\nin critical real-world applications of such systems.\n","authors":["Jorge Paz-Ruza","Amparo Alonso-Betanzos","Bertha Guijarro-Berdias","Brais Cancela","Carlos Eiras-Franco"],"pdf_url":"https://arxiv.org/pdf/2401.10690v4.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.05227v1","updated":"2025-03-07T08:25:08Z","published":"2025-03-07T08:25:08Z","title":"MOHPER: Multi-objective Hyperparameter Optimization Framework for\n  E-commerce Retrieval System","summary":"  E-commerce search optimization has evolved to include a wider range of\nmetrics that reflect user engagement and business objectives. Modern search\nframeworks now incorporate advanced quality features, such as sales counts and\ndocument-query relevance, to better align search results with these goals.\nTraditional methods typically focus on click-through rate (CTR) as a measure of\nengagement or relevance, but this can miss true purchase intent, creating a gap\nbetween user interest and actual conversions. Joint training with the\nclick-through conversion rate (CTCVR) has become essential for understanding\nbuying behavior, although its sparsity poses challenges for reliable\noptimization. This study presents MOHPER, a Multi-Objective Hyperparameter\nOptimization framework for E-commerce Retrieval systems. Utilizing Bayesian\noptimization and sampling, it jointly optimizes both CTR, CTCVR, and relevant\nobjectives, focusing on engagement and conversion of the users. In addition, to\nimprove the selection of the best configuration from multi-objective\noptimization, we suggest advanced methods for hyperparameter selection,\nincluding a meta-configuration voting strategy and a cumulative training\napproach that leverages prior optimal configurations, to improve speeds of\ntraining and efficiency. Currently deployed in a live setting, our proposed\nframework substantiates its practical efficacy in achieving a balanced\noptimization that aligns with both user satisfaction and revenue goals.\n","authors":["Jungbae Park","Heonseok Jang"],"pdf_url":"https://arxiv.org/pdf/2503.05227v1.pdf","comment":null}]}}